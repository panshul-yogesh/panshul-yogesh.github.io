{
  "title": "Install storage provisioner chart",
  "content": "<div class=\"mw-parser-output\">\n<p>If you have created local persistent volumes (<span class=\"nanospell-typo\">LPVs</span>) on Embedded <span class=\"nanospell-typo\">Kubernetes</span> for the OPTIC Data Lake, as described in Create Local Persistent Volumes on worker nodes page, you must follow the instructions below to deploy the local storage <span class=\"nanospell-typo\">provisioner</span>. Otherwise, skip this topic, for example, when using External <span class=\"nanospell-typo\">Kubernetes</span>.</p>\n<p>The helm install of the storage <span class=\"nanospell-typo\">provisioner</span> chart converts the <span class=\"nanospell-typo\">filesystem</span> mount points you created on the worker nodes (see Create Local Persistent Volumes on worker nodes) into <span class=\"nanospell-typo\">Kubernetes</span> persistent volumes. This gets claimed via the helm installation step according to the Operations Platform values <span class=\"nanospell-typo\">YAML</span> file and deployment <span class=\"nanospell-typo\">YAML</span> specifications. </p>\n<p>As mentioned in the Create Local Persistent Volumes on worker nodes topic, you should have at least three workers for a production implementation of OPTIC Data Lake, each provisioned with <span class=\"nanospell-typo\">filesystems</span> mounted under the OPTIC Data Lake path.</p>\n<p>The OPTIC Data Lake path for <span class=\"nanospell-typo\">LPVs</span> is <code>/<span class=\"nanospell-typo\">mnt</span>/disks</code>, or you may have chosen an alternative. The available free space needs to be greater than the amount you obtained from the sizing calculator for the <code>ledger, bookkeeper</code> and <code>zookeeper</code> volumes, which will get attached to the three directories under the OPTIC Data Lake path. If you chose not to use <code>/<span class=\"nanospell-typo\">mnt</span>/disks</code> as the OPTIC Data Lake path, then in this step you must create a <code><span class=\"nanospell-typo\">lpv</span>.<span class=\"nanospell-typo\">yaml</span></code> file that specifies your chosen OPTIC Data Lake path as the <code><span class=\"nanospell-typo\">hostDir</span></code>. If you are unsure, you should be able to use the <code>mount</code> command on your workers to verify the directory name.  The workers you will use for OPTIC Data Lake (default three workers) need to have the same structure under the OPTIC Data Lake path.</p>\n<p>Example for a worker node in an environment using the default OPTIC Data Lake path:</p>\n<pre><code># mount | grep disks\n/dev/sdc on /mnt/disks/lpv1 type ext4 (rw,relatime)\n/dev/sdb on /mnt/disks/lpv2 type ext4 (rw,relatime)\n/dev/sdd on /mnt/disks/lpv3 type ext4 (rw,relatime)</code></pre>\n<p>Example for a worker node in an environment using non-default OPTIC Data Lake path:</p>\n<pre><code># mount | grep coso\n/dev/sdb1 on /&lt;cosodir&gt;/lpv1 type xfs (rw,relatime,attr2,inode64,noquota)\n/dev/sdb2 on /&lt;cosodir&gt;/lpv2 type xfs (rw,relatime,attr2,inode64,noquota)\n/dev/sdb3 on /&lt;cosodir&gt;/lpv3 type xfs (rw,relatime,attr2,inode64,noquota)</code></pre>\n<p>Use this format to create the <code><span class=\"nanospell-typo\">lpv</span>.<span class=\"nanospell-typo\">yaml</span> </code>file if needed on your master (control plane) node. Preserve the exact indentation as shown:</p>\n<pre><code>classes:\n  - name: fast-disks\n    hostDir: /mnt/pulsar\n    volumeMode: Filesystem\n    fsType: xfs\n    namePattern: \"*\"\n    storageClass:\n      reclaimPolicy: Delete\n    skipMountPointCheck: true </code></pre>\n<p>On the master (control plane) node, execute the following command to install the storage <span class=\"nanospell-typo\">provisioner</span> chart:</p>\n<p><code>helm install &lt;Deployment Name&gt; --<span class=\"nanospell-typo\">namespace</span> &lt;Deployment <span class=\"nanospell-typo\">namespace</span>&gt; &lt;Storage-<span class=\"nanospell-typo\">Provisioner</span>-Chart location&gt; -f &lt;values.<span class=\"nanospell-typo\">yaml</span> file&gt; --set global.<span class=\"nanospell-typo\">docker</span>.<span class=\"nanospell-typo\">orgName</span>=&lt;<span class=\"nanospell-typo\">OrgName</span>&gt; --set global.<span class=\"nanospell-typo\">docker</span>.registry=&lt;<span class=\"nanospell-typo\">Docker</span> registry&gt;</code></p>\n<p><strong>where:</strong><br/>\n<code>&lt;helm_deployment_name&gt;:</code> Any name you choose as the helm local storage provision chart deployment name. for example: <code><span class=\"nanospell-typo\">lpv</span></code>.<br/>\n<code>global.<span class=\"nanospell-typo\">docker</span>.registry</code>: The default value is <code><span class=\"nanospell-typo\">localhost</span>:5000</code>. If you specified a non-default value when you installed <span class=\"nanospell-typo\">OMT</span>, you must give the same value here.<br/>\n<code>global.<span class=\"nanospell-typo\">docker</span>.<span class=\"nanospell-typo\">orgName</span>:</code> The default value is <code><span class=\"nanospell-typo\">hpeswitom</span></code>. If you specified a non-default value when you installed <span class=\"nanospell-typo\">OMT</span>, you must give the same value here.<br/>\n<code>&lt;<span class=\"nanospell-typo\">YAML</span> file&gt;:</code> This is an optional parameter. The default path to mount new disks is <code>/<span class=\"nanospell-typo\">mnt</span>/disks.</code> If you have used a non-default OPTIC Data Lake path during Create local persistent volumes on all worker nodes, then as mentioned earlier you should specify your newly created <code><span class=\"nanospell-typo\">lpv</span>.<span class=\"nanospell-typo\">yaml</span></code> file.</p>\n<h2><a id=\"Verify_the_installation_of_storage_provisioner_chart\" name=\"Verify_the_installation_of_storage_provisioner_chart\" title=\"Verify the installation of storage provisioner chart\"></a><a id=\"Verify-the-installation-of-storage-provisioner-chart\" name=\"Verify-the-installation-of-storage-provisioner-chart\" title=\"Verify the installation of storage provisioner chart\"></a>Verify the installation of storage <span class=\"nanospell-typo\">provisioner</span> chart</h2>\n<p>Wait about 2 minutes for the provisioning process, then verify the creation of <span class=\"nanospell-typo\">provisioner</span> pods.</p>\n<p><code><span class=\"nanospell-typo\">kubectl</span> get pod -n core | <span class=\"nanospell-typo\">grep</span> local-volume</code><br/>\n<br/>\nExample:</p>\n<pre><code>#kubectl get pod -n core | grep local-volume                                         \nlocal-volume-provisioner-gn8jk    1/1      Running         0                37m\nlocal-volume-provisioner-kcxrn    1/1      Running         0                37m\nlocal-volume-provisioner-ltmdz    1/1      Running         0                37m\n</code></pre>\n<p>Verify that the Operations Platform creates the correct number of <span class=\"nanospell-typo\">LPVs</span>, three for a low-footprint deployment (one worker), and nine for a medium or large deployment (three workers with <span class=\"nanospell-typo\">LPVs</span>), and that their sizes meets or exceeds the sizes output from the sizing calculator:</p>\n<p><code># <span class=\"nanospell-typo\">kubectl</span> get pv </code></p>\n<pre><code># kubectl get pv | grep local\nNAME                CAPACITY   ACCESS   MODES    RECLAIM POLICY  STATUS      CLAIM                                  STORAGECLASS      REASON     AGE\nlocal-pv-103b7ed2   97Gi      RWO                Delete          Available                                          fast-disks                   37m\nlocal-pv-27af0bf4   97Gi      RWO                Delete          Available                                          fast-disks                   37m\nlocal-pv-2a35e15b   97Gi      RWO                Delete          Available                                          fast-disks                   37m\nlocal-pv-79250ee7   97Gi      RWO                Delete          Available                                          fast-disks                   37m\nlocal-pv-7d27e148   97Gi      RWO                Delete          Available                                          fast-disks                   37m\nlocal-pv-93f9f3cd   97Gi      RWO                Delete          Available                                          fast-disks                   37m\nlocal-pv-958e562d   97Gi      RWO                Delete          Available                                          fast-disks                   37m\nlocal-pv-be24c2a6   97Gi      RWO                Delete          Available                                          fast-disks                   37m\nlocal-pv-e68eb868   97Gi      RWO                Delete          Available                                          fast-disks                   37m\n</code></pre>\n<p>If the <code>get pv</code> command does not display the expected number of available <code>local-pv</code> volumes for your intended deployment size, do not proceed to the deployment step until you have determined why the <span class=\"nanospell-typo\">LPV</span> provisioning did not succeed as expected. In all cases, when you deploy, you need to edit the Operations Platform values <span class=\"nanospell-typo\">YAML</span> file size fields for the <span class=\"nanospell-typo\">LPVs</span> to be equal to or smaller than the \"CAPACITY\" field shown by this command.</p>\n</div>",
  "modifiedon": "2026-01-30 13:52:30"
}