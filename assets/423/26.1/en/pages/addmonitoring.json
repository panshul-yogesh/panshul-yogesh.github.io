{
  "title": "Enable the monitoring capability",
  "content": "<div class=\"mw-parser-output\"><span class=\"snippet-start\" data-sname=\"423-25.4-423-25.3-AddMonitoring||N\"></span><p class=\"mw-empty-elt\"></p><div class=\"mw-parser-output\"><p class=\"mw-empty-elt\">\n</p><p>The monitoring capability enables you to monitor your deployment using Prometheus and to display the results using Grafana dashboards.</p>\n<div class=\"admonition\">\n<div class=\"admonition-icon admonition-note-icon\"></div>\n<div class=\"admonition-content admonition-note-content\">The monitoring capability isn't supported on Red Hat OpenShift. However, you can install an instance of Grafana and enable the monitoring content of OMT and suite on OpenShift to monitor specific metrics. Refer to the section \"Enable monitoring content on OpenShift\" for more information.</div>\n</div>\n<h2>Set up persistent volumes</h2>\n<p>Depending on your existing environment, you might need to set up persistent volumes (PVs).</p>\n<div class=\"admonition\">\n<div class=\"admonition-icon admonition-note-icon\"></div>\n<div class=\"admonition-content admonition-note-content\">If you've set the capability <code>NfsProvisioner=true</code> during OMT installation, the PVs are created automatically and you can skip the step in this section.</div>\n</div>\n<p>If you've already enabled some capabilities, you can use the existing PVs as shared resources. If you want to enable the capabilities in an environment with no AppHub chart installed, you should create all the PVs needed for the capabilities. Refer to the \"Create a values.yaml file to enable capabilities after installation\" section to decide how many PVs you need and then create these PVs same as the process of setting up prerequisites for a fresh installation.</p>\n<div class=\"admonition\">\n<div class=\"admonition-icon admonition-important-icon\"></div>\n<div class=\"admonition-content admonition-important-content\">\n<ul>\n<li>You must configure the PVs properly for Azure. Otherwise, the Prometheus and Grafana pod will fail to start.</li>\n<li>If the PVs are based on a self-hosted NFS server, you mustn't set <code>no_root_squash</code> for the exported NFS directory used by the monitoring capability. For other exported NFS directories, you can set them either to <code>root_squash</code> or to <code>no_root_squash</code>.</li>\n<li>It's highly advisable to use a storage provisioner with high performance. For example, EBS for AWS environment, or a local provisioner for the embedded environment.</li>\n</ul>\n</div>\n</div>\n<h2>Configure values.yaml</h2>\n<p>To enable the capabilities, you need to prepare a <code>values.yaml</code> file to set the configurations. There are no mandatory configurations specific to the monitoring capability besides the <code>global</code> configurations. If you've already enabled the cluster management capability or the deployment management capability, you can enable the monitoring capability by setting <code>global.services.monitoring</code> to <code>true</code>.</p>\n<p>However, if you are enabling the monitoring capability in an environment with no AppHub chart installed, you need to provide configurations for the portal ingress controller. The configurations are used to access the Grafana UI. And you also need to provide most of the <code>global</code> configurations, including admin password, docker registry, external access, PVC, user ID or group ID.</p>\n<p>If you want to customize the Prometheus components, you can refer to the default <code>values.yaml</code> file in the <code>prometheus-operator</code> chart. The chart provides a full configuration list for Prometheus. You can find the file by unpacking the AppHub chart and it's in the folder <code>apphub/charts/prometheus-operator</code>. The <code>prometheus-operator</code> chart is a sub chart of the AppHub chart, when setting the keys provided by <code>prometheus-operator</code>, you should put all the additional keys under the <code>prometheus</code> section in the <code>values.yaml</code> file of the AppHub chart. For example, if you want to set a key <code>prometheus.serviceMonitor.internal</code> in the <code>values.yaml</code> file of the <code>prometheus-operator</code> chart with the <code>values.yaml</code> file of the AppHub chart, you should set it with <code>prometheus.prometheus.serviceMonitor.internal</code>. You can refer to the example in the \"Change default configurations of the monitoring capability\" section for how to configure retention and alert receivers of Prometheus.</p>\n<p>An example of the <code>values.yaml</code> file used in an environment with no AppHub chart installed resembles below:</p>\n<div contenteditable=\"false\" tabindex=\"-1\">\n<pre><code>global:\n  services:\n    clusterManagement: false\n    deploymentManagement: false\n    monitoring: true\n    logCollection: false\n\n  cluster:\n    k8sProvideer: cdf\n \n  apphubAdmin:\n    userPassword: Admin@123\n   \n  docker:\n    imagePullSecret: registrypullsecret\n    orgName: hpeswitom\n    registry: localhost:5000\n  externalAccessHost: www.example.com\n  externalAccessPort: 5443\n   \n  securityContext:\n    user: 2009\n    fsGroup: 2009\n \n  persistence:\n    enabled: true\n    dataVolumeClaim: \"\"\n    logVolumeClaim: \"\"\n    dbVolumeClaim: \"\"</code></pre>\n</div>\n<h2 id=\"Install_the_prometheus-crds_chart\">Install the prometheus-crds chart</h2>\n<p>If you've already installed the AppHub chart in your environment, perform this step. If you are enabling the monitoring capability in an environment with no AppHub chart installed, skip this step and install the AppHub chart directly.</p>\n<p>Run the following command to install the <code>prometheus-crds</code> chart:</p>\n<div contenteditable=\"false\" tabindex=\"-1\">\n<pre><code>helm install prom-crds -n $CDF_NAMESPACE &lt;chart&gt;.tgz [--set global.docker.registry=&lt;repository&gt; --set global.docker.orgName=&lt;org_name&gt; --set global.securityContext.user=&lt;user_id&gt; --set global.securityContext.fsGroup=&lt;group_id&gt;</code></pre>\n</div>\n<p>This command contains the following placeholders:</p>\n<ul>\n<li><code>&lt;chart&gt;</code> The absolute path to the <code>prometheus-crds</code> chart. The chart file name resembles <code>itom-prometheus-crds-1.2.11.tgz</code>. You can find the chart in the <code>$CDF_HOME/charts</code> directory, and also in the OMT installation package. </li>\n<li><code>&lt;repository&gt;</code> The image registry URL. The default value is <strong>localhost:5000</strong>.</li>\n<li><code>&lt;org_name&gt;</code> The image registry organization name. The default value is <strong>hpeswitom</strong>.</li>\n<li><code>&lt;user_id&gt;</code> The user ID that has ownership of persistent storage and the runtime deployment. The default value is <b>1999</b>.</li>\n<li><code>&lt;group_id&gt;</code> The group ID that has ownership of persistent storage and the runtime deployment. The default value is <b>1999</b>.</li>\n</ul>\n<p>The actual values of these placeholders must be the same as those that you used to configure existing capabilities. To check these values, run the following command:</p>\n<div contenteditable=\"false\" tabindex=\"-1\">\n<pre><code>helm get values -n $CDF_NAMESPACE apphub</code></pre>\n</div>\n<p>For example, you run the following command:</p>\n<div contenteditable=\"false\" tabindex=\"-1\">\n<pre><code>helm install prom-crds -n $CDF_NAMESPACE itom-prometheus-crds-1.2.11.tgz --set global.docker.registry=localhost:5000 --set global.docker.orgName=hpeswitom --set global.securityContext.user=1999 --set global.securityContext.fsGroup=1999</code></pre>\n</div>\n<h2 id=\"Run_the_Helm_command_to_enable_the_capabilities\">Run the Helm command to enable the monitoring capability</h2>\n<p>Run the following command to enable the monitoring capability. Don't change the release name from <strong>apphub</strong>.</p>\n<div contenteditable=\"false\" tabindex=\"-1\">\n<pre><code>helm upgrade apphub -n $CDF_NAMESPACE &lt;chart&gt;.tgz --install --reuse-values --set global.services.monitoring=true [-f values.yaml]</code></pre>\n</div>\n<p>Replace the <code>&lt;chart&gt;</code> placeholder with the absolute path to the OMT composite chart package. The chart file name resembles <code>apphub-1.xx.x+2x.x.x-xxx.tgz</code>. You can find the chart in the <code>$CDF_HOME/charts</code> directory, and also in the OMT installation package. Provide <code>values.yaml</code> when you are enabling the monitoring capability in an environment with no AppHub chart installed. For example:</p>\n<div contenteditable=\"false\" tabindex=\"-1\">\n<pre><code>helm upgrade apphub -n $CDF_NAMESPACE apphub-1.xx.x+2x.x.x-xxx.tgz --reuse-values --set global.services.monitoring=true</code></pre>\n</div>\n<h2>Change default configurations of the monitoring capability</h2>\n<p>In some cases, you may provide customer configurations to change the default behavior of the monitoring capability. To change the configurations, provide a <code>values.yaml</code> file and run the following command to apply these configurations:</p>\n<pre><code>helm upgrade apphub -n $CDF_NAMESPACE &lt;chart&gt;.tgz --reuse-values -f values.yaml</code></pre>\n<p>Replace the <code>&lt;chart&gt;</code> placeholder with the absolute path to the OMT composite chart package. <br/>\nHere are some example cases for customer configurations, you can combine the cases or provide more parameters depending on the actual requirement.</p>\n<h3>Case 1. Increase the memory limit of Grafana and Prometheus pod</h3>\n<p>OMT usually has a limited amount of monitoring targets and the actual memory consumption will be less than the limit set to the pods. However, applications or users might add more monitoring targets. A large amount of targets might cause memory consumption exceeding the limit and the pods will be <code>OOMkilled</code>. In that case, you can increase the memory limit to prevent the pods from being killed. An example <code>values.yaml</code> file resembles as follows:</p>\n<div contenteditable=\"false\" tabindex=\"-1\">\n<pre><code>prometheus:\n  grafana:\n    resources:\n      limits:\n        memory: 4000Mi\n  prometheus:\n    prometheusSpec:\n      resources:\n        limits:\n          # Set the limit to a larger value to prevent the pod from being OOMkilled. The default value is 9000Mi.\n          memory: 16Gi</code></pre>\n</div>\n<h3>Case 2. Change the retention of monitoring data</h3>\n<p>You can change the retention of monitoring data. The default period is 10 days. If you want to keep a longer period for the monitoring data. You can set it to a larger value, for example, 10w, which means 10 weeks. Be careful when you try to increase the value. Because a longer period will consume more disk space and memory. If the retention has to be increased, it's advisable that you also increase the memory limit and keep enough disk space. On the contrary, you can set the retention to a shorter period to save disk space and memory consumption. The following example <code>values.yaml</code> file indicates how to increase the retention period with a larger memory limit and a specified retention size which avoids unstoppable growth of disk usage:</p>\n<pre><code>prometheus:\n  grafana:\n    resources:\n      limits:\n        memory: 4000Mi\n  prometheus:\n    prometheusSpec:\n      # Maximum number of bytes that can be stored for blocks. By default it's 0 which means no limitation. Units supported: KB, MB, GB, TB, PB. \n      # Be caution to set this parameter because it may cause the metrics data being thrown though it's within the retention period.\n      retentionSize: 100GB\n\n      # How long to retain metrics data in storage. The retention period defaults to 10d. Units Supported: y, w, d, h, m, s, ms.\n      retention: 20d\n\n      # If the retention period is set too long, the prometheus pod may cost too much memory, to prevent the pod from being OOMkilled, need to set the memory limit to a large value. The default value is 9000Mi.\n      resources:\n        limits:\n          memory: 16Gi</code>\n</pre>\n<h3>Case 3. Change the scrape interval for monitoring targets</h3>\n<p>The default scrape interval of Prometheus is 30 seconds, which means how often to scrape the metrics data from the specific target services. The interval also impacts the frequency of writing scraped data to disk. If the disk is under high IO pressure, you can increase the interval to improve the performance. The following example sets the default interval to 60 seconds.</p>\n<pre><code>prometheus:\n  prometheus:\n    prometheusSpec:\n      scrapeInterval: \"60s\"</code></pre>\n<p>Note that this parameter only sets the default interval of targets. For example, all targets of OMT installer use the default interval instead of a custom value in the target specification, so they can be changed through this parameter. If the targets from an application already have a custom value or you've already specified the targets with a custom value, it will override the default value here. Then you have to change the interval of these targets individually to improve the performance. You can specify these configurations through the <code>ServiceMonitor</code> kind of Kubernetes. Run the following command to list the configuration and then you can edit the listed objects individually if some of them contain a custom interval value:</p>\n<pre><code>kubectl get servicemonitors -A</code></pre>\n<h3>Case 4. Enable the email and webhook notification for monitoring alerts</h3>\n<p>By default, you can view the alerts through the Grafana dashboard. You can also enable an email and webhook notification through the following configuration. An example <code>values.yaml</code> file resembles as follows:</p>\n<pre><code>prometheus:\n  alertmanager:\n    alertmanagerSpec:\n      secrets:\n      - tls-secret\n    config:\n      global:\n        resolve_timeout: 5m\n        smtp_smarthost: 'provide your email host'\n        smtp_from: 'email address of sender'\n        smtp_auth_username: 'monitor_admin'\n        smtp_auth_password: 'monitor_admin'\n        smtp_require_tls: false\n      route:\n        group_by: ['job']\n        group_wait: 30s\n        group_interval: 5m\n        repeat_interval: 12h\n        receiver: 'default-receiver'\n        routes:\n        - match:\n            alertname: Watchdog\n          receiver: 'webhook-receiver'\n      receivers:\n      - name: 'default-receiver'\n        email_configs:\n        - to: 'your email address 01'\n          send_resolved: true\n          tls_config:\n            insecure_skip_verify: false\n            ca_file: /etc/alertmanager/secrets/tls-secret/ca.crt\n            cert_file: /etc/alertmanager/secrets/tls-secret/client.crt\n            key_file: /etc/alertmanager/secrets/tls-secret/client.key   \n        - to: 'your email address 02'\n          send_resolved: true\n      - name: 'webhook-receiver'\n        webhook_configs:\n        - url: 'your webhook url'</code>\n</pre>\n<p>The parameters <strong>alertmanagerSpec.secrets</strong> and <strong>tls_config</strong> for email receiver are optional. It’s required only if you enable the certificate authentication for email server. You can find the paths of certificates for <strong>tls_config</strong> inside the <strong>alertmanager container</strong> that are mounted from an existing secret. You must first create the secret for <strong>tls_config</strong> by running the following command:</p>\n<pre>kubectl create secret generic tls-secret -n $CDF_NAMESPACE --from-file=&lt;local path&gt;/ca.crt --from-file=&lt;local path&gt;/client.crt --from-file=&lt;local path&gt;/client.key</pre>\n<p><br/>\nReplace the <strong>&lt;local path&gt;</strong> with the real path where you put the certificates. Name the certificate files and secret name as mentioned in the previous example. You can change the paths of <strong>tls_config</strong> to match the <strong>/etc/alertmanager/secrets/&lt;secret name&gt;/&lt;file name&gt; </strong>pattern and change the secret name for <strong>alertmanagerSpec.secrets</strong>.</p>\n<h3>Case 5: Increase replicas to support high availability</h3>\n<p>By default, there is only one instance of Prometheus and alertmanager pod, you can increase the replicas to support high availability. However, pay attention while increasing the value because it will also cause more resource consumption. An example <code>values.yaml</code> file resembles as follows:</p>\n<pre>prometheus:\n  prometheus:\n    prometheusSpec:\n      replicas: 2\n  alertmanager:\n    alertmanagerSpec:\n      replicas: 2</pre>\n<h2>Enable the monitoring content capability (optional)</h2>\n<p>By enabling the monitoring content capability, specific monitoring rules and dashboards for applications will be deployed besides the default Prometheus content for the Kubernetes status, including the <code>prometheus-cert-exporter</code> chart. Run the following command to enable the monitoring content capability:</p>\n<div contenteditable=\"false\" tabindex=\"-1\">\n<pre><code>helm upgrade apphub -n $CDF_NAMESPACE &lt;chart&gt;.tgz --reuse-values --set global.prometheus.deployPrometheusConfig=true --set global.prometheus.deployGrafanaConfig=true</code></pre>\n</div>\n<p>Replace the &lt;<code>chart&gt;</code> placeholder with the absolute path to the OMT composite chart package.</p>\n<div class=\"admonition\">\n<div class=\"admonition-icon admonition-note-icon\"></div>\n<div class=\"admonition-content admonition-note-content\">For other applications, even though the monitoring content has already been enabled during initial installation, you might need to enable the content again after enabling the monitoring capability. Because the <code>Prometheus CRD kinds</code>, such as <code>ServiceMonitor</code> or <code>PrometheusRule,</code> aren't defined when the monitoring capability hasn't been enabled, you need to deploy the resources of these kinds again after enabling the monitoring capability.</div>\n</div>\n<h2>Enable monitoring content on OpenShift</h2>\n<p>OpenShift has already provided an embedded monitoring and it will conflict with the Prometheus chart in OMT. However, you can install an instance of Grafana and enable the monitoring content of OMT and suites on OpenShift to monitor specific metrics.<br/>\nFollow the following steps to install a Grafana instance and enable the monitoring content.</p>\n<ol>\n<li>Prepare a <code>values.yaml</code> file to install the Grafana chart:\n\n\t<div contenteditable=\"false\" tabindex=\"-1\">\n<pre><code>sidecar:\n  # enable the sidecar container for dashboard to load the dashboards dynamically, the label selector here should be the default value as apphub composition chart\n  dashboards:\n    enabled: true\n    label: grafana_dashboard\n    labelValue: 1\n    searchNamespace: ALL\n    provider:      \n      foldersFromFilesStructure: true   \n  # enable the sidecar container for datasource to load the dashboards dynamically\n  datasources:\n    enabled: true\n    label: grafana_datasource\n    labelValue: 1\n    searchNamespace: ALL\n# enable the persistence for grafana storage, the pvc could be an existing one or could be empty and set the storageClass to bind to a new PV\npersistence:\n  enabled: true\n  existingClaim: itom-logging-vol\n# the user and group should be same as the configuration for NFS server\nsecurityContext:\n  runAsUser: 1999\n  fsGroup: 1999\n# psp could be disabled because psp is already deprecated by kubernetes\nrbac:\n  pspEnabled: false</code></pre>\n</div>\n<div class=\"admonition\">\n<div class=\"admonition-icon admonition-note-icon\"></div>\n<div class=\"admonition-content admonition-note-content\">You can update the configurations according to your actual environment and requirements. We recommend you to install the chart into OMT core namespace, which is used in the following shell command examples. If you use other namespaces, you need to configure the <code>scc</code> to make Grafana work successfully. And we've used \"Grafana\" as the release name of the chart, ensure that you've used the same resource names as stated in this document.</div>\n</div>\n</li>\n<li>Run the following commands to install the Grafana chart:\n\t<div contenteditable=\"false\" tabindex=\"-1\">\n<pre><code>helm repo add grafana https://grafana.github.io/helm-charts\nhelm repo update\nhelm install grafana -n core grafana/grafana -f values.yaml\n\n# get the admin password\nkubectl get secret --namespace core grafana -o jsonpath=\"{.data.admin-password}\" | base64 --decode ; echo</code></pre>\n</div>\n</li>\n<li>After the <code>grafana</code> pod is running, run the following command to expose the <code>grafana</code> service with OpenShift route. Then, you can log in to Grafana through the route host with the admin password you get in step 2.\n\t<div contenteditable=\"false\" tabindex=\"-1\">\n<pre><code>oc create route edge grafana --service=grafana -n core\nkubectl get route -n core grafana</code></pre>\n</div>\n</li>\n<li>Edit the ConfigMap <code>cluster-monitoring-config</code> under the  <code>openshift-monitoring</code> namespace to enable the <code>user-workload </code>project for monitoring in OpenShift. If the ConfigMap doesn't exist, create one.\n\t<div contenteditable=\"false\" tabindex=\"-1\">\n<pre><code>apiVersion: v1\ndata:\n  config.yaml: |\n    enableUserWorkload: true\nkind: ConfigMap\nmetadata:\n  name: cluster-monitoring-config\n  namespace: openshift-monitoring</code></pre>\n</div>\n\tAfter that, there are some new pods running under the <code>openshift-user-workload-monitoring</code> namespace.</li>\n<li>Run the following command to grant permission to the Grafana <code>serviceaccount</code>:\n\t<div contenteditable=\"false\" tabindex=\"-1\">\n<pre><code>oc adm policy add-cluster-role-to-user cluster-monitoring-view -z grafana -n core</code></pre>\n</div>\n</li>\n<li> Run the following command to get the token of the Grafana <code>serviceaccount</code>:\n\t<div contenteditable=\"false\" tabindex=\"-1\">\n<pre><code>oc serviceaccounts get-token grafana -n core</code></pre>\n</div>\n</li>\n<li>Prepare a <code>datasource.yaml</code> file with the following content and replace the placeholder with the token you get in step 6.\n\t<div contenteditable=\"false\" tabindex=\"-1\">\n<pre><code>apiVersion: v1\ndata:\n  datasource.yaml: |-\n    apiVersion: 1\n    datasources:\n    - name: Prometheus\n      type: prometheus\n      url: https://thanos-querier.openshift-monitoring.svc.cluster.local:9091/\n      access: proxy\n      isDefault: true\n      jsonData:\n        timeInterval: 30s\n        tlsAuth: false\n        tlsAuthWithCACert: false\n        tlsSkipVerify: true\n        httpHeaderName1: 'Authorization'\n      secureJsonData:\n        httpHeaderValue1: 'Bearer &lt;Put your token here&gt;'\nkind: ConfigMap\nmetadata:\n  labels:\n    grafana_datasource: \"1\"\n  name: grafana-datasource\n  namespace: core\n</code></pre>\n</div>\n</li>\n<li>Run the following command to create the ConfigMap.\n\t<div contenteditable=\"false\" tabindex=\"-1\">\n<pre><code>kubectl create -f datasource.yaml</code></pre>\n</div>\n<p> <br/>\n</p>\n\tThen, there is a valid <code>datasource</code> called \"Prometheus\" in the Grafana configuration page.</li>\n<li>Run the following command to enable the monitoring content of OMT.\n\t<div contenteditable=\"false\" tabindex=\"-1\">\n<pre><code>helm upgrade -n core apphub apphub-1.xx.x+2x.x.x-xxx.tgz --reuse-values --set global.prometheus.deployPrometheusConfig=true --set global.prometheus.deployGrafanaConfig=true</code></pre>\n</div>\n<p> <br/>\n</p>\n\tAfter that, the dashboards of OMT could be displayed in Grafana UI. For the monitoring content of the suites, you need to enable them according to the guide from each suite.</li>\n</ol>\n<h2>Expose Prometheus</h2>\n<p id=\"Expose_Prometheus\">By default, the Prometheus service can't be reached from outside the cluster. If you need to expose Prometheus to a Grafana installation or users outside of the cluster (for example, for debugging purposes), follow these steps.</p>\n<div class=\"admonition\">\n<div class=\"admonition-icon admonition-important-icon\"></div>\n<div class=\"admonition-content admonition-important-content\">By default, Prometheus isn't secured. By exposing Prometheus, you are exposing the system to increased security risks. You understand and agree to assume all associated risks and hold OpenText harmless for the same. It always remains your sole responsibility to assess your own regulatory and business requirements. OpenText doesn't represent or warrant that its products comply with any specific legal or regulatory standards applicable to you in conducting your business.</div>\n</div>\n<ol>\n<li>Open a text editor and create a YAML file that has the following contents:\n\t<pre><code>apiVersion: v1\nkind: Service\nmetadata:\n  name: prometheus-web\n  namespace: &lt;OMT_NAMESPACE&gt;\n  labels:\n    app: prometheus\nspec:\n  type: NodePort\n  ports:\n  - name: http-web\n    port: 9090\n    targetPort: 9099\n    nodePort: 31466\n  selector:\n    app.kubernetes.io/name: prometheus\n    prometheus: itom-prometheus-prometheus</code>\n</pre>\n<p>Update the <code>&lt;OMT_NAMESPACE&gt;</code> placeholder with the OMT namespace. The default value is <strong>core</strong>.</p>\n</li>\n<li>Run the following command. Replace <code>&lt;YAML_file&gt;</code> with the name of the YAML file that you created in the previous step.\n\t<pre><code>kubectl create -f &lt;YAML_file&gt;.yaml</code></pre>\n<p> <br/>\n\tIf the operation is a success, the following message appears on the console:\n</p>\n<pre><code>service/prometheus-web created</code></pre>\n</li>\n<li>To verify that you have successfully exposed Prometheus, open a browser on a node that's outside of the cluster, and then visit the following URL:\n\t<pre><code>https://&lt;EXTERNAL_ACCESS_HOST&gt;:31466</code></pre>\n</li>\n</ol>\n<p>For more information about how to connect Prometheus to an external Grafana installation, visit the following Grafana website: <a href=\"https://grafana.com/docs/grafana/latest/datasources/add-a-data-source/\" title=\"https://grafana.com/docs/grafana/latest/datasources/add-a-data-source/\">https://grafana.com/docs/grafana/latest/datasources/add-a-data-source/</a></p>\n<p><br/>\n</p><p><br/>\n</p>\n<p class=\"mw-empty-elt\"></p></div>\n<p class=\"mw-empty-elt\"></p><span class=\"snippet-end\" data-sname=\"423-25.4-423-25.3-AddMonitoring||N\"></span></div>",
  "modifiedon": "2025-10-24 08:51:12"
}