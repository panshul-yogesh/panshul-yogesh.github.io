{
  "title": "AKS deployment FAQs",
  "content": "<div class=\"mw-parser-output\"><p><br/>\nThis topic answers certain most frequently asked questions about deploying the suite in an AKS environment.</p>\n<h2 class=\"mw-headline\" id=\"General\">General</h2>\n<div class=\"transcontent stn-begin--General\"></div>\n<p>The following are general questions that apply to all supported cloud platforms.</p>\n<h3 id=\"Can_I_use_machine_types_other_than_those_specified_in_the_sizing_guide?\"><span class=\"mw-headline\" id=\"Can_I_use_machine_types_other_than_those_specified_in_the_sizing_guide.3F\">Can I use machine types other than those specified in the sizing guide?</span></h3>\n<p>No.</p>\n<p>One VM with 8vCPU can have better performance than 2 VMs with 4vCPU in some scenarios. VMs have their own limitations, so you can't improve system performance simply by adding more VMs. Additionally, all our sizing recommendations, tuning and tests are based on certain requirements for each node. You can't guarantee the performance if using VMs that don't meet the requirements for a node.</p>\n<h3 id=\"Can_I_share_storage_between_development_and_test_environments?\"><span class=\"mw-headline\" id=\"Can_I_share_storage_between_development_and_test_environments.3F\">Can I share storage between development and test environments?</span></h3>\n<p>Technically, you can. However, we don't recommend it.</p>\n<p>This is because all our sizing recommendations, tuning and tests are based on an assumption that each environment uses their dedicated storage. Sharing the same storage between two environments may cause the environments to interfere with each other, leading to poor stability and performance.  </p>\n<h3 id=\"Can_I_start_with_fewer_worker_nodes_and_add_more_later?\"><span class=\"mw-headline\" id=\"Can_I_start_with_fewer_worker_nodes_and_add_more_later.3F\">Can I start with fewer worker nodes and add more later?</span></h3>\n<p>Technically, you can. However, we strongly recommend that you install the suite according to our sizing recommendations. By providing enough worker nodes, you can avoid installation failures because of insufficient resources. </p>\n<h3 id=\"What_version_of_Kubernetes_should_I_choose?_Always_the_latest?\"><span class=\"mw-headline\" id=\"What_version_of_Kubernetes_should_I_choose.3F_Always_the_latest.3F\">What version of Kubernetes should I choose? Always the latest?</span></h3>\n<p>We use EKS, AKS, or GKE to fully manage Kubernetes in the suite. When you create or update the Kubernetes cluster, you need to select a Kubernetes version. Each release of Kubernetes may have some changes that may affect SMA deployment. For this reason, we verify a new Kubernetes version before SMA can adopt it. The latest version and any other versions that we haven't certified may be incompatible with SMA.</p>\n<p>Always select the Kubernetes version that's described in the suite installation documentation. This version has been certified for the current SMA version.  </p>\n<h3 id=\"What_is_the_minimum_disk_requirement_for_SMA?\"><span class=\"mw-headline\" id=\"What_is_the_minimum_disk_requirement_for_SMA.3F\">What is the minimum disk requirement for SMA?</span></h3>\n<p>We provide sizing recommendations for SMA deployment on different cloud platforms. The sizing recommendations provide the minimum resources needed for setting up an SMA environment on each cloud. You must install SMA according to the sizing recommendations to avoid installation failures caused by resource insufficiency; otherwise, even if you have successfully installed the suite, issues may still occur when the suite is running.</p>\n<h3 id=\"Can_I_change_the_SMA_sizing_profile_dynamically_after_installation?\"><span class=\"mw-headline\" id=\"Can_I_change_the_SMA_sizing_profile_dynamically_after_installation.3F\">Can I change the SMA sizing profile dynamically after installation?</span></h3>\n<p>Yes, you can, but only as part of a suite upgrade process. That is, you need to change the deployment size first and then upgrade the suite to a newer version. The new deployment size takes effect only when the suite upgrade process is completed. For details, see <a href=\"/doc/423/26.1/upgrademanagedk8s\" title=\"SMAX:25.1/UpgdManagedK8SSuite\">Upgrade the suite (managed Kubernetes)</a>.</p>\n<h3 id=\"Can_SMA_share_the_Kubernetes_cluster_with_other_products?\"><span class=\"mw-headline\" id=\"Can_SMA_share_the_Kubernetes_cluster_with_other_products.3F\">Can SMA share the Kubernetes cluster with other products?</span></h3>\n<p>No.  When SMA shares the Kubernetes cluster with other products, they will compete for resources, which will impact the system stability and performance. Additionally, sharing the same Kubernetes cluster may cause incompatibility and security problems, because the products may require different versions of Kubernetes.</p>\n<h3 id=\"What_is_the_organization_name_for_an_image_repository?\"><span class=\"mw-headline\" id=\"What_is_the_organization_name_for_an_image_repository.3F\">What's the organization name for an image repository?</span></h3>\n<p>An organization is a collection of teams and repositories that can be managed together.</p>\n<p>All the images for SMA in each release should be pushed to the same organization. </p>\n<table>\n<tbody>\n<tr>\n<th> Platform</th>\n<th>Image registry</th>\n</tr>\n<tr>\n<td>Azure</td>\n<td>The address of an image in an Azure container registry includes the following elements:\n\t\t\t<p><code>[loginUrl]/[namespace]/[artifact:][tag]</code></p>\n<ul>\n<li>loginUrl - The fully qualified name of the registry host. The registry host in an Azure container registry is in this format: <i>myregistry</i>.azurecr.io (all lowercase). You must specify the loginUrl when using Docker or other client tools to pull or push artifacts to an Azure container registry.</li>\n<li>namespace - Slash-delimited logical grouping of related images or artifacts - for example, for a workgroup or app.</li>\n<li>artifact - The name of a repository for a particular image or artifact.</li>\n<li>tag - A specific version of an image or artifact stored in a repository.</li>\n</ul>\n<p>An organization name in our documentation refers to a \"namespace\" in Azure.</p>\n<p>For example, the full name of an image in an Azure container registry might look like the following:</p>\n<p><em>itomsma.azurecr.io/hpeswitomsandbox/itom-idm:1.26.0</em></p>\n<p>The organization name in this example is hpeswitomsandbox.</p>\n</td>\n</tr>\n<tr>\n<td>GCP</td>\n<td>The address of an image in an GCP container registry includes the following elements:\n\t\t\t<p><code>gcr.io/[your-project-id]/[image]:[tag]</code></p>\n<p>An organization name in our documentation refers to a \"project-id\" in GCR. A project-id is the ID of your Google Cloud project. For example, the full name of an image in GCR may look like the following:</p>\n<p><em>gcr.io/itom-smax-nonprod/itom-cdf-controller:0.2.0-005</em></p>\n<p>The organization name in this example is itom-smax-nonprod.</p>\n</td>\n</tr>\n<tr>\n<td>AWS</td>\n<td>The address of an image in an AWS container registry includes the following elements:\n\t\t\t<p><code>[aws_account_id].dkr.ecr.[region].amazonaws.com/[Repository name]:[tag]</code></p>\n<p>You can push images to ECR like this:</p>\n<p><em>114706266704.dkr.ecr.us-east-1.amazonaws.com/hpeswitomsandbox/itom-autopass-lms:latest</em></p>\n<p>In this example, the organization name for ECR is hpeswitomsandbox.</p>\n</td>\n</tr>\n<tr>\n<td colspan=\"1\">Docker hub</td>\n<td colspan=\"1\">\n<p>Organizations are collections of teams and repositories that can be managed together. SMA uses an organization name of \"hpeswitom\" to manage all SMA repositories.</p>\n<p>You can pull images from Docker Hub like this:</p>\n<p><em>itom-docker.shcartifactory.swinfra.net/hpeswitom/vault:0.12.0-0016</em></p>\n<p>The organization name for all Docker Hub repositories for SMA is hpeswitom.</p>\n</td>\n</tr>\n</tbody>\n</table>\n<h3 id=\"Is_the_load_balancer_working_on_layer_4_or_layer_7?_Why_do_we_need_both_layer_4_and_layer_7_load_balancers?\"><span class=\"mw-headline\" id=\"Is_the_load_balancer_working_on_layer_4_or_layer_7.3F_Why_do_we_need_both_layer_4_and_layer_7_load_balancers.3F\">Is the load balancer working on layer 4 or layer 7?  Why do we need both layer 4 and layer 7 load balancers?</span></h3>\n<p>Basically, we leverage solutions with both layer 4 and layer 7 load balancers. They work together to serve different purposes.</p>\n<p>A layer 7 load balancer is introduced for application level scenarios:</p>\n<ul>\n<li>Rule-based routing. In a production environment, there may be multiple applications behind the load balancer, such as SMA and HCM. You may need a load balancer to redirect you to different applications based on the context path. For example, requests against <a class=\"external text\" href=\"http://www.microfocus.com/saw\" rel=\"nofollow\" target=\"1\" title=\"www.microfocus.com/saw\">www.microfocus.com/saw</a> and <a class=\"external text\" href=\"http://www.microfocus.com/bo\" rel=\"nofollow\" target=\"1\" title=\"www.microfocus.com/bo\">www.microfocus.com/bo</a> should be redirected to SMA, and requests against <a class=\"external text\" href=\"http://www.microfocus.com/hcm\" rel=\"nofollow\" target=\"1\" title=\"www.microfocus.com/hcm\">www.microfocus.com/hcm</a> to HCM.</li>\n<li>Working with a Web Application Firewall for security considerations</li>\n<li>Providing SSL/TLS encryption at the load balancer level</li>\n</ul>\n<p>A layer 4 load balancer is introduced for infrastructure and network level scenarios:</p>\n<ul>\n<li>A layer 4 load balancer can work with cloud-native Kubernetes so that it can notice any node-level changes and update its backend pool</li>\n<li>It provides the capacity for handling thousands to millions of requests with very low latency</li>\n</ul>\n<h3 id=\"Is_it_possible_for_a_worker_node_to_run_out_of_disk_space_over_time?\"><span class=\"mw-headline\" id=\"Is_it_possible_for_a_worker_node_to_run_out_of_disk_space_over_time.3F\">Is it possible for a worker node to run out of disk space over time?</span></h3>\n<p>Yes, it's possible, but not very likely. There are always some unused files left on a worker node (for example, image files, old version resources). You can monitor your disk usage on a regular basis just in case. </p>\n<h3 id=\"Can_I_choose_for_a_worker_node_an_instance_type_other_than_the_one_required_in_the_sizing_guide?\"><span class=\"mw-headline\" id=\"Can_I_choose_for_a_worker_node_an_instance_type_other_than_the_one_required_in_the_sizing_guide.3F\">Can I choose for a worker node an instance type other than the one required in the sizing guide? </span></h3>\n<p>Technically, you can, but with certain limitations. You can only choose an instance type with the same or a higher configuration than the requirements (disk size, CPU, etc) documented in the sizing guide, to avoid problems caused by resource insufficiency.</p>\n<h3 id=\"Can_I_choose_other_operating_systems_than_CentOS_for_the_Bastion_node?\"><span class=\"mw-headline\" id=\"Can_I_choose_other_operating_systems_than_CentOS_for_the_Bastion_node.3F\">Can I choose other operating systems than CentOS for the Bastion node? </span></h3>\n<p>Technically, you can, but we recommend using CentOS. We use the bastion node as a jump box to connect to our Kubernetes cluster and other resources in the private subnet. Operating systems don't matter in this scenario. The SMA documentation provides steps that have been verified. So you can use the documentation for reference. </p>\n<h3 id=\"Can_I_use_the_same_PostgreSQL_server_for_all_SMA_services?\"><span class=\"mw-headline\" id=\"Can_I_use_the_same_PostgreSQL_server_for_all_SMA_services.3F\">Can I use the same PostgreSQL server for all SMA services? </span></h3>\n<p>Yes, our sizing recommendations are provided assuming all SMA services use the same PostgreSQL server. You can follow the suite documentation to prepare a PostgreSQL server that meets the requirements. </p>\n<h3 id=\"Do_I_have_to_clean_up_the_NFS_server_and_PostgreSQL_database_before_re-installation?\"><span class=\"mw-headline\" id=\"Do_I_have_to_clean_up_the_NFS_server_and_PostgreSQL_database_before_re-installation.3F\">Do I have to clean up the NFS server and PostgreSQL database before re-installation?</span></h3>\n<p>Yes, you do. The NFS server and PostgreSQL database keep some data from the last installation.</p>\n<ul>\n<li>If you don't clean up the old data in the NFS volumes, some services can't start because of the old dirty data.</li>\n<li>On the other hand, during the suite installation, the suite installer automatically creates certain databases and users in the PostgreSQL server. If you don't clean up these databases and users from the PostgreSQL server, the next installation will fail.</li>\n</ul>\n<h3 id=\"Why_should_I_specify_the_max_pods_per_node_when_creating_a_K8s_cluster?_How_do_I_calculate_this_value?\"><span class=\"mw-headline\" id=\"Why_should_I_specify_the_max_pods_per_node_when_creating_a_K8s_cluster.3F_How_do_I_calculate_this_value.3F\">Why should I specify the max pods per node when creating a K8s cluster? How do I calculate this value?</span></h3>\n<p>This parameter controls the maximum number of pods that are allowed to run on each node, so that you can balance your pods. If you can configure more nodes in the cluster than required in the sizing guide, you can adjust this parameter value. For example, for AKS, the value is 60. If the sizing guide states that you need to prepare 3 nodes for your specific sizing profile and you want to use 4 nodes for better stability, you can recalculate the parameter value as follows: 3*60/4 = 45. So you can specify a value of 45 to better balance the pods.</p>\n<h3 id=\"_What_kind_of_data_is_stored_on_NFS_storage?\"><span class=\"mw-headline\" id=\"_What_kind_of_data_is_stored_on_NFS_storage.3F\"> What kind of data is stored on NFS storage?</span></h3>\n<table>\n<tbody>\n<tr>\n<th>Data</th>\n<th>Description</th>\n<th>Details</th>\n</tr>\n<tr>\n<td>Certificates</td>\n<td>Certificates for authentication and authorization</td>\n<td>The &lt;config-volume&gt;/certificate folder stores all certificate file for authentication/authorization between components in SMA.</td>\n</tr>\n<tr>\n<td>YAML files</td>\n<td>Kubernetes resources' YAML files</td>\n<td>The itom-vol-claim volume stores certain YAML templates used by OMT.\n\t\t\t<p>The OMT core volume is used to retain infra component data such as suitedb, internal image registry, idm, and YAML templates.</p>\n<p>The SMA global volume stores all services' yaml files.</p>\n</td>\n</tr>\n<tr>\n<td colspan=\"1\">Log files</td>\n<td colspan=\"1\">System, container, Kubernetes logs, and so on</td>\n<td colspan=\"1\">The itom-logging-vol volume stores OMT deployment log, container log. system log, and Kubernetes log.\n\t\t\t<p>The SMA global volume stores all services logs.</p>\n</td>\n</tr>\n<tr>\n<td colspan=\"1\">Attachments</td>\n<td colspan=\"1\">Attachments in your tickets</td>\n<td colspan=\"1\">The &lt;data-volume&gt;/share1 and &lt;data-volume&gt;/share2 folders store attachments in your tickets.</td>\n</tr>\n<tr>\n<td colspan=\"1\">Rabbitmq data</td>\n<td colspan=\"1\">Some message queue data</td>\n<td colspan=\"1\">The SMA rabbitmq volumes store some rabbitmq data related to message queuing.</td>\n</tr>\n<tr>\n<td colspan=\"1\">Search service data</td>\n<td colspan=\"1\">Data related to the search functionality</td>\n<td colspan=\"1\">For example, the SMA Smart Analytics volume.</td>\n</tr>\n</tbody>\n</table>\n<div class=\"transcontent stn-end--General\"></div>\n<h2 class=\"mw-headline\" id=\"AKS\">AKS</h2>\n<p>The following are questions specific to deployments on AKS.</p>\n<div class=\"transcontent stn-begin--AKS\"></div>\n<h3>Do I really need 500 private IPs for SMA deployment on AKS?</h3>\n<p>Yes. Azure recommends using the CNI network plugin for AKS, which allocates a private IP address for each pod in the same IP space as a worker node. A cluster of full capacity for SMA (plus the AKS system pods) has about 200 pods, which means 200 IPs are needed. However, during the system upgrade, because of the rolling update strategy, the number of pods will be doubled. That's why 500 IPs are required to make sure the upgrade will succeed.</p>\n<h3 id=\"What_is_the_difference_between_a_bastion_node_and_the_Azure_bastion_service?\"><span class=\"mw-headline\" id=\"What_is_the_difference_between_a_bastion_node_and_the_Azure_bastion_service.3F\">What is the difference between a bastion node and the Azure bastion service?</span></h3>\n<p>A <a class=\"external text\" href=\"https://docs.stackery.io/docs/api/nodes/Bastion\" rel=\"nofollow\" target=\"1\" title=\"Bastion node\">Bastion node</a> is simply a normal instance, which is configured to allow you to easily grant specific users <a class=\"extiw\" href=\"https://en.wikipedia.org/wiki/Secure_Shell\" title=\"wikipedia:Secure Shell\">SSH access</a> to a server inside the Virtual Network so that the users can access your private resources.  </p>\n<p>The Azure bastion service is a new fully platform-managed PaaS service that you provision inside your virtual network. It provides secure and seamless connectivity to your virtual machines directly. </p>\n<p>The following table describes the difference between a bastion node and Azure bastion service.</p>\n<table>\n<tbody>\n<tr>\n<th></th>\n<th>Bastion node</th>\n<th>Azure bastion service</th>\n</tr>\n<tr>\n<td colspan=\"1\">Management</td>\n<td colspan=\"1\">A normal instance, managed by the customer. The customer needs to configure the instance according to their security or other requirements.</td>\n<td colspan=\"1\">Fully managed by the Azure platform</td>\n</tr>\n<tr>\n<td>Connection</td>\n<td>Using SSH and RDP with public IP addresses</td>\n<td>Enables you to log in to your Azure virtual machines and avoid public Internet exposure using SSH and RDP with private IP addresses only</td>\n</tr>\n<tr>\n<td>Public IP address</td>\n<td>Usually have public IP addresses exposed to the internet.</td>\n<td>No public IP address exposed</td>\n</tr>\n</tbody>\n</table>\n<h3 id=\"Why_do_I_need_to_use_Self-Hosted_PostgreSQL_instead_of_an_Azure_PostgreSQL_server_for_SMA?\"></h3>\n<h3 id=\"Can_I_change_the_instance_type_of_a_worker_node_after_AKS_cluster_creation?\"><span class=\"mw-headline\" id=\"Can_I_change_the_instance_type_of_a_worker_node_after_AKS_cluster_creation.3F\">Can I change the instance type of a worker node after AKS cluster creation?</span></h3>\n<p>Yes, you can. You can edit your VM's size individually. However, Azure doesn't recommend changing the instance type on the worker node directly. The recommended procedure and best practice is to add a second agentpool to the cluster and choose the new VM Size you want for that new agentpool. Then you can delete the old one. For details, see <a class=\"external free\" href=\"https://docs.microsoft.com/en-us/azure/aks/use-multiple-node-pools\" rel=\"nofollow\" target=\"1\" title=\"https://docs.microsoft.com/en-us/azure/aks/use-multiple-node-pools\">https://docs.microsoft.com/en-us/azure/aks/use-multiple-node-pools</a>.</p>\n<h3 id=\"Can_I_use_Kubenet_network_plugins_than_Azure_Container_Networking_Interface_(CNI)_when_setting_up_an_AKS_cluster?_Why?\"><span class=\"mw-headline\" id=\"Can_I_use_Kubenet_network_plugins_than_Azure_Container_Networking_Interface_.28CNI.29_when_setting_up_an_AKS_cluster.3F_Why.3F\">Can I use Kubenet network plugins other than Azure Container Networking Interface (CNI) when setting up an AKS cluster? Why?</span></h3>\n<p>Yes.  Both Kubenet and Azure CNI are certified for SMA with AKS. See the <a href=\"https://docs.microsoft.com/en-us/azure/aks/operator-best-practices-network#kubenet-networking\" title=\"best practices\">best practices</a> recommended by Azure to choose the plugins based on your needs. </p>\n<h3 id=\"For_Azure_File,_can_I_use_standard_Azure_File_Service_Level?\"><span class=\"mw-headline\" id=\"For_Azure_File.2C_can_I_use_standard_Azure_File_Service_Level.3F\">For Azure File, can I use standard Azure File Service Level?</span></h3>\n<p>No. You can only use the premium size, because only Premium meets the performance requirements. So Premium is the minimum required Azure File Service Level in our sizing requirements. Using the standard level will cause performance issues. </p>\n<div class=\"transcontent stn-end--AKS\"></div>\n</div>",
  "modifiedon": "2025-10-24 08:51:12"
}