{
  "title": "Aviator overview",
  "content": "<div class=\"mw-parser-output\"><br/><div> </div>\n<p>This topic provides an overview of the Aviator support matrix and includes the architecture diagram to help you understand how Aviator functions.</p>\n<h2>Support matrix</h2>\n<p>Aviator supports Service Management <code>25.1.2</code> and <code>25.1.1</code>.</p>\n<h2>Architecture</h2>\n<p>This architecture diagram shows how Aviator interacts with the various components.</p>\n<p><br/>\n<a class=\"image\" href=\"\"> <img alt=\"Aviator architecture diagram\" height=\"528\" src=\"../../../images/AviatorArchitecture244_20049261.png\" width=\"800\"/> </a></p>\n<p>The Aviator service, as depicted in the diagram, operates within the OpenText Public Cloud and runs on AWS infrastructure. This architecture is designed to deliver advanced AI-driven operations management for multiple tenants through a secure, scalable, and multi-tiered solution. The Aviator service provides the following key features.</p>\n<h3><strong>Multi-tenancy platform</strong></h3>\n<p>The ESM SaaS platform supports multiple tenants, each operating in an isolated environment. This ensures data security and separation between clients.</p>\n<p>Tenants interact with the Aviator service while maintaining isolation through the Vector database (Milvus), which manages the indexed knowledge and context data from different ESM tenants, enabling efficient and secure operations.</p>\n<h3><strong>Data processing and isolation</strong></h3>\n<p>The Vector database (Milvus) is crucial in indexing and storing knowledge and context from multiple tenants, ensuring that data remains isolated between tenants. Each tenant’s context is processed independently, and queries are handled by the Llama 3 AI model within the Aviator service to deliver intelligent operations.</p>\n<h3><strong>Llama 3 (AI model)</strong></h3>\n<p>Llama 3 is the core AI engine within the Aviator service, providing advanced AI-driven capabilities. It is responsible for:</p>\n<ul>\n<li>Natural language processing (NLP): Llama 3 can understand and generate human-like responses, allowing tenants to interact with the system using natural language queries.</li>\n<li>Contextual understanding: By utilizing indexed data from the Milvus Vector database, Llama 3 provides relevant and accurate responses, tailored to the specific knowledge and context of each tenant.</li>\n<li>Automation and intelligence: Through its AI capabilities, Llama 3 helps automate routine operations and offers intelligent insights, enhancing overall service management efficiency.</li>\n</ul>\n<h3>Connection and communication</h3>\n<p>The API gateway hosted on AWS acts as the intermediary between ESM SaaS tenants and the Aviator service. It ensures that the API requests are securely routed to the Aviator service, enabling smooth interactions across tenants.</p>\n<p>On-premises Service Management systems can connect to the Aviator platform through an HTTPS proxy or directly, depending on the network setup, providing flexibility in deployment and maintaining security.</p>\n<h3>AI Operations Management</h3>\n<p>AI Operations Management connects to the Aviator service via the ESM SaaS platform to enable event analysis by leveraging AI-driven insights.</p>\n<div> </div>\n<div> </div>\n</div>",
  "modifiedon": "2025-10-24 08:51:12"
}