{
  "title": "Set up Velero",
  "content": "<div class=\"mw-parser-output\"><br/><p>You need to use Velero to back up and restore your Kubernetes configurations and cluster. Velero comes pre-installed with OMT, refer to the <a href=\"/doc/omt/25.4/systemreqsembed#Third_party_component_versions\" title=\"OMT third party component versions\">OMT support matrix</a> to see which version of velero ships with your OMT. If your OMT doesn't include Velero, you will first need to set up Velero according to your deployment. This topic describes how to set up Velero for different deployments.</p><h2>Set up Velero for Managed Kubernetes</h2><p>Use the steps to set up Velero for managed Kubernetes.</p><h3>Preparation</h3><p>Refer to the tasks according to your cloud platform.</p><h4><span style=\"font-family: Roboto, sans-serif;\">Preparation steps fo</span><span style=\"font-family: Roboto, sans-serif;\">r AWS</span></h4><span class=\"snippet-start\" data-sname=\"423-25.4-423-25.3-VeleroBackup|prepareaws|N\"></span><ol><li><a href=\"https://github.com/vmware-tanzu/velero-plugin-for-aws#Create-S3-bucket\">Create S3 bucket</a> to store the backup data. Make sure the bucket region is the same as that of your Kubernetes cluster. If you already have one, skip this step.</li><li><a href=\"https://github.com/vmware-tanzu/velero-plugin-for-aws/tree/v1.3.0#Set-permissions-for-Velero\">Set permission for Velero</a> and use <a href=\"https://github.com/vmware-tanzu/velero-plugin-for-aws/tree/v1.3.0#option-1-set-permissions-with-an-iam-user\">Option 1: Set permission with an IAM user</a>. </li></ol><p><br/></p><span class=\"snippet-end\" data-sname=\"423-25.4-423-25.3-VeleroBackup|prepareaws|N\"></span><h4>Preparation steps for Azure</h4><span class=\"snippet-start\" data-sname=\"423-25.4-423-25.3-VeleroBackup|prepareazure|N\"></span><ol><li>Run the command on the bastion node: <code>az login</code></li><li><a href=\"https://github.com/vmware-tanzu/velero-plugin-for-microsoft-azure/tree/v1.3.1#Create-Azure-storage-account-and-blob-container\">Create an Azure storage account and blob container </a>to store the backup data. Make sure the subscription and location are the same as those of your Kubernetes cluster. If you already have one, skip this step.</li><li><a href=\"https://github.com/vmware-tanzu/velero-plugin-for-microsoft-azure/tree/v1.3.1#Get-resource-group-containing-your-VMs-and-disks\">Get the resource group containing your VMs and disks</a>.</li><li><a href=\"https://github.com/vmware-tanzu/velero-plugin-for-microsoft-azure/tree/v1.3.1#Set-permissions-for-Velero\">Set permission for Velero</a> and use <a href=\"https://github.com/vmware-tanzu/velero-plugin-for-microsoft-azure/tree/v1.3.1#option-1-create-service-principal\">Option 1: Create service principal</a>.\n\t<div class=\"Admonition_Note\"><span class=\"autonumber\">Note</span><br/>\n\tYour account needs to have the <strong>application administrator</strong> role.</div></li></ol><p><br/></p><span class=\"snippet-end\" data-sname=\"423-25.4-423-25.3-VeleroBackup|prepareazure|N\"></span><h4>Preparation steps for GCP</h4><span class=\"snippet-start\" data-sname=\"423-25.4-423-25.3-VeleroBackup|preparegcp|N\"></span><ol><li><a href=\"https://github.com/vmware-tanzu/velero-plugin-for-gcp/tree/v1.3.0#create-an-gcs-bucket\" title=\"Create a GCS bucket\">Create a GCS bucket</a> to store the backup data. If you already have one, skip this step.</li><li>Set permissions for Velero. For instructions, see <a href=\"https://github.com/vmware-tanzu/velero-plugin-for-gcp/tree/v1.3.0#option-1-set-permissions-with-a-service-account\" title=\"Option 1: Set permission with a service account\">Option 1: Set permission with a service account</a> of <a href=\"https://github.com/vmware-tanzu/velero-plugin-for-gcp/tree/v1.3.0#set-permissions-for-velero\" title=\"Set permission for Velero\">Set permission for Velero</a>.</li><li>Make sure you add <strong>compute.projects.get</strong> permission to <code>ROLE_PERMISSIONS</code> for Suite backup tasks. For details, see <strong>Attach policies to give Velero the required permissions</strong> section of <a href=\"https://github.com/vmware-tanzu/velero-plugin-for-gcp/tree/v1.3.0#option-1-set-permissions-with-a-service-account\" title=\"Option 1: Set permission with a service account\">Option 1: Set permission with a service account</a>. The updated <code>ROLE_PERMISSIONS</code> should resemble the following example:\t<pre><code> ROLE_PERMISSIONS=(    compute.projects.get    compute.disks.get    compute.disks.create    compute.disks.createSnapshot    compute.snapshots.get    compute.snapshots.create    compute.snapshots.useReadOnly    compute.snapshots.delete    compute.zones.get)</code></pre><div> </div></li></ol><p>The following roles are required for your current IAM user. </p><ul><li><code>roles/iam.serviceAccountAdmin</code></li><li><code>roles/iam.organizationRoleAdmin</code></li><li><code>roles/iam.securityAdmin</code></li><li><code>roles/iam.serviceAccountKeyAdmin</code></li><li><code>roles/storage.legacyBucketReader</code></li></ul><div class=\"admonition\"><div class=\"admonition-icon admonition-note-icon\"> </div><div class=\"admonition-content admonition-note-content\"> <p>If any permission is missing, you might get the following error:<br/><code>AccessDeniedException: 403 xxxxxxxxxxx-xxxxx@xxxxx.gserviceaccount.com doesn't have storage.buckets.getIamPolicy access to the Google Cloud Storage bucket.</code></p>Follow <a href=\"https://cloud.google.com/iam/docs/granting-changing-revoking-access\" title=\"the guidance\">the guidance</a> to apply required roles to your IAM user. </div></div><p> </p><span class=\"snippet-end\" data-sname=\"423-25.4-423-25.3-VeleroBackup|preparegcp|N\"></span><h4>Preparation steps for OpenShift</h4><span class=\"snippet-start\" data-sname=\"423-25.4-423-25.3-VeleroBackup|prepareopenshift|N\"></span><ol><li>Set up S3-Compatible object store provider on OpenShift Kubernetes cluster. <br/>\n\tFor Velero supported S3-Compatible object store providers, refer to <a href=\"https://velero.io/docs/v1.8/supported-providers/#s3-compatible-object-store-providers\">https://velero.io/docs/v1.8/supported-providers/#s3-compatible-object-store-providers</a>. Among all the supported S3-Compatible object store providers, <code>Minio</code> is certified.</li><li>Deploy the <code>minio</code> server in OpenShift Kubernetes cluster, refer to: <br/><a href=\"https://velero.io/docs/v1.8/contributions/minio/#set-up-server\">https://velero.io/docs/v1.8/contributions/minio/#set-up-server</a> and <a href=\"https://github.com/vmware-tanzu/velero/blob/main/examples/minio/00-minio-deployment.yaml\">https://github.com/vmware-tanzu/velero/blob/main/examples/minio/00-minio-deployment.yaml</a></li><li>For security concerns, we strongly recommend you enable TLS for the <code>minio</code> server. Refer to <a href=\"https://github.com/minio/minio/tree/master/docs/tls/kubernetes\">https://github.com/minio/minio/tree/master/docs/tls/kubernetes</a>.</li></ol><p><br/></p><span class=\"snippet-end\" data-sname=\"423-25.4-423-25.3-VeleroBackup|prepareopenshift|N\"></span><h3>Enable Kubernetes backup capability</h3><p>You can either enable the Kubernetes backup capability through installation or you can enable the capability manually after installation.</p><h4>Upload Velero image to the registry</h4><p>Before you enable Kubernetes backup capability, if you do not have OMT installed in your environment, you must upload the Velero image to the Google Cloud Registry (GCR). If you have installed OMT in your environment, since OMT includes the required Velero image, you can skip this task.</p><p>Complete the following steps to upload the Velero image to the registry.</p><ol><li>Create a file <strong>image-set.json</strong> and add the following content to it:\n\n\t<pre><code>{\n  \"org_name\": \"&lt;registry org name&gt;\",\n  \"images\": [\n    {\n      \"image\": \"itom-velero:&lt;image version&gt;\"\n    }\n  ]\n}</code></pre><p>For example:</p><pre><code>{\n  \"org_name\": \"hpeswitom\",\n  \"images\": [\n    {\n      \"image\": \"itom-velero:1.7.0-00160\"\n    }\n  ]\n}</code></pre></li><li>Run the following command to download the Velero image. Replace<em>&lt;image download directory&gt;</em> with the directory where you plan to download the Velero image. The default value is /var/opt/cdf/offline\n\t<pre><code>./downloadimages.sh -u &lt;registry user name&gt; -p &lt;registry password&gt; -d &lt;image download directory&gt;</code></pre></li><li>After you download the image, run the following command to get the to get GCP password:\n\t<pre><code>gcrpwd=$(gcloud auth print-access-token --impersonate-service-account $saccount 2&gt; /dev/null) \n</code></pre></li><li>Use the GCP password to run the following command and upload the image to the GCR:\n\t<pre><code>./uploadimages.sh -r '&lt;gcr registry name&gt;' -u oauth2accesstoken -p $gcrpwd -d &lt;image download directory&gt; -o '&lt;gcr registry org name&gt;' -F ./image-set.json</code></pre>\n\tFor example:\n\n\t<pre><code>./uploadimages.sh -r 'gcr.io' -u oauth2accesstoken -p $gcrpwd -d ./images -o example.org -F ./image-set.json</code></pre></li></ol><h4>Enable the capability with installation</h4><span class=\"snippet-start\" data-sname=\"423-25.4-423-25.3-VeleroBackup|enableawsgcp|N\"></span><ul><li>For AWS and GCP cloud platforms, you must set the following CLI parameters when running installation:\n\t<ul><li><code>--capability K8sBackup=true</code></li><li><code>--backup-storage-bucket &lt;bucket name&gt;</code>: Specifies the storage bucket name for backup when Kubernetes backup capability is enabled.</li><li><code>--backup-storage-credential-file &lt;absolute path of the credential file on bastion node&gt;</code>: Specifies the credential file used for accessing the storage bucket.<br/>\n\t\tOr <code>--backup-storage-secret &lt;secret name&gt;</code>: Specifies the secret name which contains the credential for accessing the storage bucket.</li></ul></li></ul><div class=\"Admonition_Important\"><span class=\"autonumber\">Important</span><br/><p>For AWS, if the cluster has been configured <code>aws-load-balancer-controller</code>, you need to add one label on the <code>targetgroupbindings</code> resources after OMT installation.\n</p><ol><li>Run the following command to get the <code>targetgroupbindings</code> name under <code>CDF_namespace</code>:\n\n\t<div contenteditable=\"false\" tabindex=\"-1\"><pre><code>kubectl get targetgroupbindings -n &lt;cdf namespace&gt;</code></pre></div></li><li>Run the following command to label the <code>targetgroupbindings</code> resources:\n\t<div contenteditable=\"false\" tabindex=\"-1\"><pre><code>kubectl label targetgroupbindings &lt;target group binding name&gt; velero.io/exclude-from-backup=true -n &lt;cdf namespace&gt;</code></pre></div></li></ol></div><p><br/></p><span class=\"snippet-end\" data-sname=\"423-25.4-423-25.3-VeleroBackup|enableawsgcp|N\"></span><span class=\"snippet-start\" data-sname=\"423-25.4-423-25.3-VeleroBackup|enableazure|N\"></span><ul><li>For Azure cloud platform, you must set the following CLI parameters when running installation:\n\t<ul><li><code>--capability K8sBackup=true</code></li><li><code>--backup-storage-bucket &lt;blob container&gt;</code>: Specifies the storage bucket name for backup when Kubernetes backup capability is enabled. It's the blob container name for Azure.</li><li><code>--backup-resource-group &lt;resource group name&gt;</code>: Specifies the resource group name used for backup.</li><li><code>--backup-storage-account &lt;storage account name&gt;</code>: Specifies the storage account name used for backup.</li><li><code>--backup-storage-credential-file &lt;absolute path of the credential file on bastion node&gt;</code>: Specifies the credential file used for accessing the storage bucket.<br/>\n\t\tOr <code>--backup-storage-secret &lt;secret name&gt;</code>: Specifies the secret name which contains the credential for accessing the storage bucket.</li></ul></li></ul><p><br/></p><span class=\"snippet-end\" data-sname=\"423-25.4-423-25.3-VeleroBackup|enableazure|N\"></span><span class=\"snippet-start\" data-sname=\"423-25.4-423-25.3-VeleroBackup|enableopenshift|N\"></span><ul><li>For OpenShift platform, you must set the following CLI parameters when running installation:\n\t<ul><li><code>--capability K8sBackup=true</code></li><li><code>--backup-storage-bucket &lt;bucket name&gt;</code>: Specifies the storage bucket name for backup when Kubernetes backup capability is enabled.</li><li><code>--backup-storage-credential-file &lt;absolute path of the credential file on bastion node&gt;</code>: Specifies the credential file used for accessing the storage bucket.<br/>\n\t\tOr <code>--backup-storage-secret &lt;secret name&gt;</code>: Specifies the secret name which contains the credential for accessing the storage bucket.</li><li><code>--bakcup-storage-api-url &lt;api url&gt;</code>: Specifies the storage API URL for backup.</li><li><code>--backup-storage-api-ca &lt;api ca&gt;</code>: Optional, specifies only when the API URL is HTTPS protocol.</li></ul><p><br/></p></li></ul><span class=\"snippet-end\" data-sname=\"423-25.4-423-25.3-VeleroBackup|enableopenshift|N\"></span><span class=\"snippet-start\" data-sname=\"423-25.4-423-25.3-VeleroBackup|noteforcredentialfile|N\"></span><div class=\"Admonition_Note\"><span class=\"autonumber\">Notes</span><ul><li>The content of the credential file for the <code>minio</code> server resembles below:\n\n\t\t<div contenteditable=\"false\" tabindex=\"-1\"><pre><code>[default]\naws_access_key_id = &lt;minio access key or minio root user&gt;\naws_secret_access_key = &lt;minio secret key or minio root password&gt;</code></pre></div></li><li>The API URL should be accessible in Kubernetes cluster, the format should be: <code>http(s)://&lt;service name&gt;.&lt;namespace&gt;:&lt;service port&gt;</code>. For example, <code>https://minio-svc.minio:9000</code>.</li></ul></div><p><br/></p><p><br/></p><span class=\"snippet-end\" data-sname=\"423-25.4-423-25.3-VeleroBackup|noteforcredentialfile|N\"></span><span class=\"snippet-start\" data-sname=\"423-25.4-423-25.3-VeleroBackup|noteforinstallwithsecret|N\"></span><div class=\"Admonition_Note\"><span class=\"autonumber\">Note</span><br/><p>If you want to set <code>--backup-storage-secret &lt;secret name&gt;</code>, run the following command to create the secret:\n</p><pre><code>kubectl create secret generic &lt;secret name&gt; --from-file=cloud=&lt;absolute path of the credential file&gt; -n &lt;cdf ns&gt;</code></pre></div><p><br/></p><span class=\"snippet-end\" data-sname=\"423-25.4-423-25.3-VeleroBackup|noteforinstallwithsecret|N\"></span><h4>Enable the capability manually after installation</h4><span class=\"snippet-start\" data-sname=\"423-25.4-423-25.3-VeleroBackup|enableafterinstall|N\"></span><ol>\n<li>After performing the preparation steps, run the following command on the bastion node:\n\t<div contenteditable=\"false\" tabindex=\"-1\">\n<div contenteditable=\"false\" tabindex=\"-1\">\n<pre><code>echo \"export VELERO_NAMESPACE=${CDF_NAMESPACE}\" &gt;&gt; $HOME/itom-cdf.sh\nsource $HOME/itom-cdf.sh\nsource $CDF_HOME/properties/images/charts.properties</code></pre>\n</div>\n</div>\n</li>\n<li>Run the following commands according to your cloud platform with the credential file to enable the capability and deploy Velero. You must replace the placeholders with real values.\n\t<div class=\"Admonition_Note\"><span class=\"autonumber\">Note</span><br/>\n<p>\tIf you want to deploy Velero with a secret name, run the following command to create the secret:\n</p>\n<div contenteditable=\"false\" tabindex=\"-1\">\n<div contenteditable=\"false\" tabindex=\"-1\">\n<pre><code>kubectl create secret generic &lt;secret name&gt; --from-file=cloud=&lt;absolute path of the credential file&gt; -n &lt;cdf ns&gt;</code></pre>\n</div>\n</div>\n\tAnd then, replace <code>--set-file credentials.secretContents.cloud=&lt;credential file absolute path&gt;</code> with <code>--set credentials.existingSecret=&lt;secret name&gt;</code> when running the helm command.</div>\n<p>\tRefer to the following commands according to your cloud platforms:\n</p>\n<ul>\n<li><strong>AWS</strong>\n<div contenteditable=\"false\" tabindex=\"-1\">\n<div contenteditable=\"false\" tabindex=\"-1\">\n<pre><code>helm install itom-velero $CDF_HOME/charts/$CHART_ITOM_VELERO \\\n-n $CDF_NAMESPACE \\\n--set fullnameOverride=velero \\\n--set cleanUpCRDs=true \\\n--set upgradeCRDs=true \\\n--set global.cluster.k8sProvider=aws \\\n--set global.docker.imagePullSecret=registrypullsecret \\\n--set global.docker.registry=&lt;contianer image registry url&gt; \\\n--set global.docker.orgName=&lt;registry organization name&gt; \\\n--set global.securityContext.user=&lt;system user id&gt; \\\n--set global.securityContext.fsGroup=&lt;system group id&gt; \\\n--set configuration.provider=aws \\\n--set configuration.backupStorageLocation.bucket=&lt;bucket name&gt; \\\n--set-file credentials.secretContents.cloud=&lt;credential file absolute path&gt; \\\n--set configuration.backupStorageLocation.config.region=&lt;aws bucket region&gt; \\\n--set configuration.backupStorageLocation.config.serverSideEncryption=AES256 \\\n--set configuration.volumeSnapshotLocation.config.region=&lt;aws bucket region&gt; \\\n--set cloudserver.deployment.enabled=false</code></pre>\n</div>\n</div>\n</li>\n<li><strong>Azure</strong>\n<div contenteditable=\"false\" tabindex=\"-1\">\n<div contenteditable=\"false\" tabindex=\"-1\">\n<pre><code>helm install itom-velero $CDF_HOME/charts/$CHART_ITOM_VELERO \\\n-n $CDF_NAMESPACE \\\n--set fullnameOverride=velero \\\n--set cleanUpCRDs=true \\\n--set upgradeCRDs=true \\\n--set global.cluster.k8sProvider=azure \\\n--set global.docker.imagePullSecret=registrypullsecret \\\n--set global.docker.registry=&lt;contianer image registry url&gt; \\\n--set global.docker.orgName=&lt;registry organization name&gt; \\\n--set global.securityContext.user=&lt;system user id&gt; \\\n--set global.securityContext.fsGroup=&lt;system group id&gt; \\\n--set configuration.provider=azure \\\n--set configuration.backupStorageLocation.bucket=&lt;bucket name&gt; \\\n--set-file credentials.secretContents.cloud=&lt;credential file absolute path&gt; \\\n--set configuration.backupStorageLocation.config.resourceGroup=&lt;resource group name&gt; \\\n--set configuration.backupStorageLocation.config.storageAccount=&lt;storage account name&gt; \\\n--set configuration.volumeSnapshotLocation.config.apiTimeout=5m \\\n--set cloudserver.deployment.enabled=false</code></pre>\n</div>\n</div>\n</li>\n<li><strong>GCP</strong>\n<div contenteditable=\"false\" tabindex=\"-1\">\n<div contenteditable=\"false\" tabindex=\"-1\">\n<pre><code>helm install itom-velero $CDF_HOME/chart/$CHART_ITOM_VELERO \\\n-n $CDF_NAMESPACE \\\n--set fullnameOverride=velero \\\n--set cleanUpCRDs=true \\\n--set upgradeCRDs=true \\\n--set global.cluster.k8sProvider=gcp \\\n--set global.docker.imagePullSecret=registrypullsecret \\\n--set global.docker.registry=&lt;contianer image registry url&gt; \\\n--set global.docker.orgName=&lt;registry organization name&gt; \\\n--set global.securityContext.user=&lt;system user id&gt; \\\n--set global.securityContext.fsGroup=&lt;system group id&gt; \\\n--set configuration.provider=gcp \\\n--set configuration.backupStorageLocation.bucket=&lt;bucket name&gt; \\\n--set-file credentials.secretContents.cloud=&lt;credential file absolute path&gt; \\\n--set cloudserver.deployment.enabled=false</code></pre>\n</div>\n</div>\n</li>\n<li><strong>OpenShift</strong>\n<div contenteditable=\"false\" tabindex=\"-1\">\n<pre><code>helm install itom-velero $CDF_HOME/chart/$CHART_ITOM_VELERO \\\n-n $CDF_NAMESPACE \\\n--set fullnameOverride=velero \\\n--set cleanUpCRDs=true \\\n--set upgradeCRDs=true \\\n--set global.cluster.k8sProvider=aws \\\n--set global.docker.imagePullSecret=registrypullsecret \\\n--set global.docker.registry=&lt;contianer image registry url&gt; \\\n--set global.docker.orgName=&lt;registry organization name&gt; \\\n--set global.securityContext.user=&lt;system user id&gt; \\\n--set global.securityContext.fsGroup=&lt;system group id&gt; \\\n--set configuration.provider=aws \\\n--set configuration.backupStorageLocation.bucket=&lt;bucket name&gt; \\\n--set-file credentials.secretContents.cloud=&lt;credential file absolute path&gt; \\\n--set snapshotsEnabled=false \\\n--set configuration.backupStorageLocation.config.region=minio \\\n--set configuration.backupStorageLocation.config.s3ForcePathStyle=true \\\n--set configuration.backupStorageLocation.config.s3Url=&lt;storage api url&gt; \\\n--set configuration.backupStorageLocation.caCert=$(cat &lt;absolute path of api ca file&gt; | base64 -w0) \\\n--set cloudserver.deployment.enabled=false</code></pre>\n</div>\n</li>\n</ul>\n<p>Where:</p>\n<ul>\n<li><code>global.docker.registry</code>: The container image registry URL</li>\n<li><code>global.docker.orgName</code>: The container image registry organization name</li>\n<li><code>global.securityContext.user</code>: The user ID that has the ownership of the persistent storage and the runtime deployment</li>\n<li><code>global.securityContext.fsGroup</code>: The group ID that has the ownership of the persistent storage and the runtime deployment</li>\n<li><code>configuration.backupStorageLocation.bucket</code>: The bucket name used to store the backup. The name of the blob container for Azure AKS</li>\n<li><code>credentials.secretContents.cloud</code>: The absolute path of the credential file on the bastion node</li>\n<li><code>credentials.existingSecret</code>: (optional) The secret name containing the credential file</li>\n<li><code>configuration.backupStorageLocation.config.region</code>: (AWS EKS only) The region of the bucket</li>\n<li><code>configuration.volumeSnapshotLocation.config.region</code>: (AWS EKS only) The region of the bucket</li>\n<li><code>configuration.backupStorageLocation.config.resourceGroup</code>: (Azure AKS only) The resource group name</li>\n<li><code>configuration.backupStorageLocation.config.storageAccount</code>: (Azure AKS only) The storage account name</li>\n<li><code>configuration.backupStorageLocation.config.s3Url:(</code>OpenShift only) The storage API URL.</li>\n<li><code>configuration.backupStorageLocation.caCert:(</code>OpenShift only) The absolute path of the CA certificate of the storage API. Only needed when the storage API URL is HTTPS protocol.</li>\n</ul>\n</li>\n<li>Run the following commands to create a scheduled backup:\n\t<pre><code>velero create schedule k8s-backup --schedule=\"0 0 * * *\" --exclude-namespaces='kube-system,default'</code></pre>\n<p>\tFor OpenShift, run the following command to create the schedule:\n</p>\n<pre><code>velero create schedule k8s-backup --schedule=\"0 0 * * *\" --exclude-namespaces='kube-system,default,openshift*'</code></pre>\n<div class=\"Admonition_Important\"><span class=\"autonumber\">Important</span><br/>\n<p>\tFor AWS, if the cluster has been configured <code>aws-load-balancer-controller</code>, you need to add one label on the <code>targetgroupbindings</code> resources before creating a scheduled backup.\n</p>\n<ol>\n<li>Run the following command to get the <code>targetgroupbindings</code> name under <code>CDF_namespace</code>:\n\n\t\t<pre><code>kubectl get targetgroupbindings -n &lt;cdf namespace&gt;</code></pre>\n</li>\n<li>Run the following command to label the <code>targetgroupbindings</code> resources:\n\t\t<pre><code>kubectl label targetgroupbindings &lt;target group binding name&gt; velero.io/exclude-from-backup=true -n &lt;cdf namespace&gt;</code></pre>\n</li>\n</ol>\n</div>\n</li>\n<li>Run the following commands to check if the schedule and backup are enabled. Make sure the backup is in the <strong>Completed</strong> status.\n\t<pre><code>velero get schedule\nvelero get backup</code></pre>\n</li>\n</ol>\n<p><br/>\n</p><span class=\"snippet-end\" data-sname=\"423-25.4-423-25.3-VeleroBackup|enableafterinstall|N\"></span><h2>Set up Velero on Embedded Kubernetes</h2><p>For embedded Kubernetes, you use Velero for client encryption. Use the same Velero master key from the source system, to enable Velero access and decrypt the backup file stored in CloudServer.</p><p>If Velero and CloudServer are already installed on the target system, uninstall them and then re-install them with the same Velero master key from the source system.</p><h3>Enable Kubernetes backup capability</h3><ol><li>Sign the certificate for the CloudServer, and run the below commands on the control plane node.\n\t<pre>source /etc/profile.d/itom-cdf.sh\ncd $CDF_HOME/ssl\ncert=itom-cloudserver\ncertDays='2000'\nsubjContent=\"/CN=${cert}\"\nextContent=\"basicConstraints=CA:FALSE\\nkeyUsage=digitalSignature,keyEncipherment,keyAgreement\\nextendedKeyUsage=serverAuth,clientAuth\\nsubjectAltName=DNS:localhost,DNS:${cert}\"\nopenssl genrsa -out ${cert}.key 4096\nopenssl req -new -key ${cert}.key -subj \"${subjContent}\" -out ${cert}.csr\nopenssl x509 -req -sha256 -in ${cert}.csr -CA ca.crt -CAkey ca.key -CAcreateserial -out ${cert}.crt -days ${certDays} -extfile &lt;(printf \"${extContent}\")\nrm -rf ca.srl ${cert}.csr\n</pre></li><li>Run the following command in the source system to get the Velero master key. Be sure to save the Velero master key in a secure place, to prevent issues if you lose access to the source system.\n\t<pre>helm get values itom-velero -n core -o json | jq .cloudserver.deployment.masterKey\n</pre></li><li>Run the following commands to enable Kubernetes backup capability.\n\t<pre>source $CDF_HOME/properties/images/charts.properties\nTAINT_MASTER_KEY=\"node-role.kubernetes.io/control-plane\"\naccessKey=cloudserver\nsecretKey=$(date +%s | sha1sum | cut -c 1-32)\nmasterKey=&lt;velero_masterkey&gt;\ncert=itom-cloudserver\nhelm upgrade --install itom-velero $CDF_HOME/charts/$CHART_ITOM_VELERO -n $CDF_NAMESPACE \\\n        --set global.docker.imagePullSecret=registrypullsecret \\\n        --set global.docker.registry=&lt;docker_repository&gt; \\\n        --set global.docker.orgName=&lt;registry_orgname&gt; \\\n        --set global.securityContext.user=&lt;system_user_id&gt; \\\n        --set global.securityContext.fsGroup=&lt;system_group_id&gt; \\\n        --set global.cluster.tolerations[0].key=$TAINT_MASTER_KEY \\\n        --set global.cluster.tolerations[0].operator=Exists \\\n        --set global.cluster.tolerations[0].effect=NoSchedule \\\n        --set global.nodeSelector.\"node-role\\.kubernetes\\.io/control-plane\"=\"\" \\\n        --set fullnameOverride=velero \\\n        --set configuration.provider=aws \\\n        --set snapshotsEnabled=false \\\n        --set cleanUpCRDs=true \\\n        --set upgradeCRDs=true \\\n        --set cloudserver.deployment.accessKey=${accessKey} \\\n        --set cloudserver.deployment.secretKey=${secretKey} \\\n        --set cloudserver.deployment.masterKey=${masterKey} \\\n        --set cloudserver.deployment.tls.crt=$(cat $CDF_HOME/ssl/$cert.crt | base64 -w0) \\\n        --set cloudserver.deployment.tls.key=$(cat $CDF_HOME/ssl/$cert.key | base64 -w0) \\\n        --set cloudserver.deployment.tls.ca=$(cat $CDF_HOME/ssl/ca.crt | base64 -w0) \\\n        --set configuration.backupStorageLocation.caCert=$(cat $CDF_HOME/ssl/ca.crt | base64 -w0)\n</pre><p>Where:</p><ul><li><code>&lt;velero_masterKey&gt;</code>: Your Velero master key.</li><li><code>&lt;docker_repository&gt;</code>: Your container registry URL.</li><li><code>&lt;registry_orgname&gt;</code>: The organization in the image registry that contains the images.</li><li><code>&lt;system_user_id&gt;</code> and <code>&lt;system_group_id&gt;</code> must be the same as the user ID and group ID that you specified when configuring NFS volumes (see <a href=\"/doc/423/26.1/confignfsshareshelm\" title=\"Configure NFS volumes\">configure NFS volumes</a>).</li></ul></li><li>Run the commands below to set the <em>VELERO_NAMESPACE</em> environment parameter:\n\t<pre>echo \"export VELERO_NAMESPACE=$CDF_NAMESPACE\" &gt;&gt;/etc/profile.d/itom-cdf.sh\nsource /etc/profile.d/itom-cdf.sh</pre></li></ol><h3>Disable Kubernetes backup capability</h3><p>Use the following steps to disable the backup capability.</p><ol><li>Run the command below to uninstall <code>itom-velero</code> chart release.\n\n\t<pre>helm uninstall itom-velero -n $CDF_NAMESPACE</pre></li><li>Run the command below to remove VELERO_NAMESPACE environment parameter.\n\t<pre>sed -i -e '/VELERO_NAMESPACE=/d' /etc/profile.d/itom-cdf.sh</pre></li></ol><h3>Get MinIO backups after upgrade to CloudServer</h3><p>This release replaces MinIO with Zenko CloudServer as the internal S3 storage server consumed by Velero. </p><p>If you've installed a previous OMT with Kubernetes capabilities enabled on the environment, upgrading to the latest release will remove the MinIO artifacts. However, the MinIO backups are saved on the NFS server. If you want to get the MinIO backups, perform the following steps:</p><ol><li>Get the current revision of <code>itom-velero</code> helm release:\n\n\t<pre>currentRev=$(helm list -n $CDF_NAMESPACE -o json | jq -r '.[] | select(.name == \"itom-velero\") | .revision')</pre></li><li>Roll back helm release <code>itom-velero</code> to the first revision:\n\t<pre>helm rollback itom-velero 1 -n $CDF_NAMESPACE</pre></li><li>Check the status of <code>bsl</code> and make sure it's <code>Available</code>:\n\t<pre>watch kubectl get bsl -n $CDF_NAMESPACE</pre></li><li>Roll back helm release <code>itom-velero</code> to the revision with CloudServer:\n\t<pre>helm rollback itom-velero $currentRev -n $CDF_NAMESPACE</pre></li></ol></div>",
  "modifiedon": "2025-10-24 08:51:12"
}