{
  "title": "RabbitMQ isn't ready",
  "content": "<div class=\"mw-parser-output\">\n<p><br/>\nThe <b>infra-rabbitmq-&lt;n&gt;</b> (&lt;n&gt;=0, 1, or 2) pod isn't ready and its readiness state is stuck in <code>1/2</code>. For example:</p>\n<pre>NAME                         READY       STATUS        RESTARTS    AGE\n\ninfra-rabbitmq-0             1/2         Running       0           16h\n</pre>\n<h2 class=\"mw-headline\" id=\"Cause\"><a id=\"Cause\" name=\"Cause\" title=\"Cause\"></a>Cause</h2>\n<p>This issue has many causes. For example:</p>\n<ul style=\"padding-left: 0px;\"><li style=\"margin-left: 28px; position: relative;\">The environment wasn't shut down gracefully. For example, you powered off the environment without first shutting down Service Management and OMT.</li><li style=\"margin-left: 28px; position: relative;\">Your system has insufficient hardware resources.</li><li style=\"margin-left: 28px; position: relative;\">There are network connectivity issues between the NFS server and the worker nodes.</li></ul>\n<h2><a id=\"Solution\" name=\"Solution\" title=\"Solution\"></a>Solution</h2>\n<p>When RabbitMQ fails to start twice, the system automatically performs a fresh start of RabbitMQ. Therefore, when this issue occurs, first wait 15 minutes, and then check if the issue is resolved automatically.</p>\n<p>If the problem still persists, check the system resources and network connectivity.</p>\n<p>If there's no resource or network issue, manually restart RabbitMQ. To do this, follow these steps:</p>\n<ol style=\"padding-left: 0px;\"><li style=\"--number-width: 10px; --number-spacing: 24px; margin-left: 36px; position: relative;\">Run the following command on a master node (embedded Kubernetes) or the bastion node (managed Kubernetes) to stop RabbitMQ:\n\n\t<pre>kubectl scale statefulset infra-rabbitmq -n &lt;suite namespace&gt; --replicas=0</pre>\n</li><li style=\"--number-width: 13px; --number-spacing: 24px; margin-left: 36px; position: relative;\">Wait until all RabbitMQ pods are terminated. </li><li style=\"--number-width: 13px; --number-spacing: 24px; margin-left: 36px; position: relative;\">Remove the <code>&lt;rabbitmq-infra-rabbitmq-n&gt;/data/xservices/rabbitmq/x.x.x.xx/mnesia</code> folders on the NFS server. Perform this for all three RabbitMQ folders. For example, remove the following folders: \n\t<pre>/var/vols/itom/itsma/rabbitmq-infra-rabbitmq-0/data/xservices/rabbitmq/x.x.x.xx/mnesia\n/var/vols/itom/itsma/rabbitmq-infra-rabbitmq-1/data/xservices/rabbitmq/x.x.x.xx/mnesia\n/var/vols/itom/itsma/rabbitmq-infra-rabbitmq-2/data/xservices/rabbitmq/x.x.x.xx/mnesia\n</pre>\n<div class=\"admonition\"><div class=\"admonition-icon admonition-note-icon\"></div><div class=\"admonition-content admonition-note-content\"><div>If you use managed NFS, please ask your cloud service administrator to delete the content in the RabbitMQ Persistent Volumes (PVs). The corresponding Persistent Volume Claims (PVCs) are rabbitmq-infra-rabbitmq-0, rabbitmq-infra-rabbitmq-1, and rabbitmq-infra-rabbitmq-2.</div></div></div>\n</li><li style=\"--number-width: 13px; --number-spacing: 24px; margin-left: 36px; position: relative;\">\n<p>Run the following command on a master node (embedded Kubernetes) or the bastion node (managed Kubernetes) to restart RabbitMQ.  Make sure all RabbitMQ  pods are up and running with a readiness state of 2/2.</p>\n<pre>kubectl scale statefulset infra-rabbitmq -n &lt;suite namespace&gt; --replicas=3</pre>\n</li></ol>\n</div>",
  "modifiedon": "2025-12-01 11:34:02"
}