{
  "title": "Monitoring with open source tools",
  "content": "<div class=\"mw-parser-output\">\n<p>Once you have successfully deployed the suite, it is important to set up a monitoring system to track potential issues with your worker nodes, pods, and services. This section explains how to utilize Prometheus, an open-source tool, to gather statistical data on CPU usage, memory consumption, network I/O, and disk I/O for the worker nodes, pods, and services within the suite system.</p>\n<div class=\"admonition\"><div class=\"admonition-icon admonition-note-icon\"></div><div class=\"admonition-content admonition-note-content\"><div>Any mention of SMAX in this document refers to OpenText Service Management, which was formerly known as SMAX.</div></div></div>\n<h2 class=\"mw-headline\" id=\"Overview\"><a id=\"Overview\" name=\"Overview\" title=\"Overview\"></a>Overview</h2>\n<p>The following diagram illustrates the architecture of this monitoring solution.<br/>\n<a class=\"image\" href=\"\"> <img alt=\"SMA 2019.05 monitoring.png\" data-file-height=\"547\" data-file-width=\"960\" src=\"../../../images/SMA_2019.05_monitoring_fb424cd8.png\" style=\"width: 960px; height: 547px;\"/> </a></p>\n<h3 class=\"mw-headline\" id=\"Grafana\"><a id=\"Grafana\" name=\"Grafana\" title=\"Grafana\"></a>Grafana</h3>\n<p>Grafana is a popular dashboarding solution that allows users to create and manage separate access to dashboards for different individuals and teams. Additionally, Grafana uses the concept of organizations to support multi-tenancy, enabling you to group resources and assign access privileges to specific users.</p>\n<p>Grafana offers numerous plug-ins for various data sources, including InfluxDB, Graphite, Elasticsearch, and Prometheus. Using Grafana, you can create custom visualization panels that include graphs, tables, and lists based on queries against a particular data source. You can also query different data sources from the same dashboard, as each panel features a settings-like query, alert thresholds, and data source all of which are easily configurable through the Grafana web UI.</p>\n<h3 class=\"mw-headline\" id=\"Prometheus\"><a id=\"Prometheus\" name=\"Prometheus\" title=\"Prometheus\"></a>Prometheus</h3>\n<p>Prometheus is an open-source system monitoring and alerting toolkit. The main features of Prometheus include:</p>\n<ul style=\"padding-left: 0px;\"><li style=\"margin-left: 28px; position: relative;\">A multi-dimensional data model with time series data is identified by metric name and key/value pairs</li><li style=\"margin-left: 28px; position: relative;\">A flexible query language leverages this dimensionality</li><li style=\"margin-left: 28px; position: relative;\">There is no reliance on distributed storage; single server nodes are autonomous</li><li style=\"margin-left: 28px; position: relative;\">Time series collection happens via a pull model over HTTP</li><li style=\"margin-left: 28px; position: relative;\">Pushing time series is supported via an intermediary gateway</li><li style=\"margin-left: 28px; position: relative;\">Targets are discovered via service discovery or static configuration</li><li style=\"margin-left: 28px; position: relative;\">Multiple modes of graphing and dashboarding support</li></ul>\n<div>For more information, refer to the official Prometheus documentation.</div>\n<h2 class=\"mw-headline\" id=\"Install_Prometheus\"><a id=\"Confirm_the_monitoring_tools_status\" name=\"Confirm_the_monitoring_tools_status\" title=\"Confirm the monitoring tools status\"></a>Confirm the monitoring tools status</h2>\n<p>The monitoring tools are preinstalled on the suite and are enabled by default. Run the following commands to confirm their status</p>\n<pre>helm list -n core\nkubectl get pods -n core |grep grafana  </pre>\n<h2 class=\"mw-headline\" id=\"Configure_Prometheus\"><a id=\"Configure_Prometheus\" name=\"Configure_Prometheus\" title=\"Configure Prometheus\"></a>Configure Prometheus</h2>\n<p>Prometheus uses service monitors to collect metric data, such as protocol (HTTP vs. HTTPS) usage, endpoint information (port name and secret path), and service selector. The service monitor is deployed as part of the Suite installation. This topic describes how to configure Prometheus to collect metrics.</p>\n<p>The ServiceMonitor-Prometheus architecture looks as below:</p>\n<div><a class=\"image\" href=\"\"> <img alt=\"ServiceMonitor-Prometheus architecture\" border=\"0\" hspace=\"0\" src=\"../../../images/pn_image_65f1187066f3d6.83214026_c09cd87b.png\" style=\"width:600px;height:328px;margin-top:0px;margin-bottom:0px;margin-left:0px;margin-right:0px;border:0px solid black;\" vspace=\"0\"/> </a></div>\n<div class=\"admonition\"><div class=\"admonition-icon admonition-note-icon\"></div><div class=\"admonition-content admonition-note-content\"><div>Before proceeding further, go to the <a href=\"http://marketplace.opentext.com/itom/content/service-management-automation-monitor\" target=\"_blank\" title=\"ITOM Marketplace\">ITOM Marketplace</a> to download the Service Management Automation Monitor zip file.</div></div></div>\n<p>All service monitors are now part of the<code> itom-sma-monitor-helm</code> subchart, available under the ESM Helm chart package.</p>\n<p>The <code>global.prometheus.deployPrometheusConfig</code><strong> </strong>capability needs to be set to <strong>true </strong>before running the helm install in the <strong>values.yaml </strong>file. By default, it is set to false.</p>\n<p>The metrics for the following existing services are now conditionally enabled based on the <code>global.prometheus.deployPrometheusConfig</code> status in the values.yaml.</p>\n<ul style=\"padding-left: 0px;\"><li style=\"margin-left: 28px; position: relative;\">itom-xruntime-redis-svc</li><li style=\"margin-left: 28px; position: relative;\">itom-xruntime-platform-svc</li><li style=\"margin-left: 28px; position: relative;\">itom-xruntime-platform-offline-svc</li><li style=\"margin-left: 28px; position: relative;\">itom-xruntime-platform-offline-ng-svc</li><li style=\"margin-left: 28px; position: relative;\">itom-xruntime-platform-readonly-svc</li><li style=\"margin-left: 28px; position: relative;\">itom-xruntime-gateway-svc</li><li style=\"margin-left: 28px; position: relative;\">itom-xruntime-serviceportal-svc</li><li style=\"margin-left: 28px; position: relative;\">itom-ingress-controller-metrics-svc</li><li style=\"margin-left: 28px; position: relative;\">idm-svc</li></ul>\n<h3 class=\"mw-headline\" id=\"Configure_alert_rules\"><a id=\"Configure_alert_rules\" name=\"Configure_alert_rules\" title=\"Configure alert rules\"></a>Configure alert rules</h3>\n<p>Create an alert configuration file named <strong>alert.yaml</strong> as shown below.<br/>\n </p>\n<div class=\"admonition\"><div class=\"admonition-icon admonition-note-icon\"></div><div class=\"admonition-content admonition-note-content\"><div>Change release: apphub to release, if you've used a different release name during <your name=\"\" own=\"\" release=\"\">installation. To check your release name, run the command helm list -n core. </your></div></div></div>\n<pre><code>apiVersion: monitoring.coreos.com/v1\nkind: PrometheusRule\nmetadata:\n  labels:\n    app: prometheus-operator\n    heritage: Helm\n    prometheus_config: \"1\"\n    release: apphub            ##chart release name, be default: cdf-prometheus\n  name: cdf-prometheus-prometheus-smax.rules\n  namespace: core\nspec:\n  groups:\n  - name: k8s.rules\n    rules:\n    - alert: SMANodeCpuUsageTooHigh\n      annotations:\n        description: \"High CPU load (instance {{ $labels.instance }})\"\n        summary: \"CPU load is &gt; 70%\\n  VALUE = {{ printf \\\"%0.0f\\\" $value }}%\\n  LABELS: {{ $labels }}\"\n      expr: 100 - (avg by(instance) (irate(node_cpu_seconds_total{mode=\"idle\"}[2m])) * 100) &gt; 70\n      for: 2m\n      labels:\n        severity: warning\n    - alert: SMANodeCpuUsageRiskHigh\n      annotations:\n        description: \"High CPU load (instance {{ $labels.instance }})\"\n        summary: \"CPU load is &gt; 80%\\n  VALUE = {{ printf \\\"%0.0f\\\" $value }}%\\n  LABELS: {{ $labels }}\"\n      expr: 100 - (avg by(instance) (irate(node_cpu_seconds_total{mode=\"idle\"}[2m])) * 100) &gt; 80\n      for: 2m\n      labels:\n        severity: critical\n    - alert: SMANodeMemoryUsageTooHigh\n      annotations:\n        description: \"Worker node ({{$labels.instance}}) Memory usage is too high\"\n        summary: SMAX Cluster Memory usage is high, avaiable RAM less than {{ printf \"%0.2f\" $value }}%\n      expr: node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes * 100 &lt; 30\n      for: 2m\n      labels:\n        severity: warning\n    - alert: SMANodeMemoryUsageRiskHigh\n      annotations:\n        description: \"Worker node ({{$labels.instance}}) Memory usage is risk\"\n        summary: SMAX Cluster Memory usage is risk high, avaiable RAM less than {{ printf \"%0.2f\" $value }}%, please take action as soon as possible.\n      expr: node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes * 100 &lt; 20\n      for: 2m\n      labels:\n        severity: critical\n    - alert: SMASmartAnalyticsContentDataCompactAlert\n      annotations:\n        summary: Smart Analytics Data Compact issue\n        description: \"Smart Analytics content has data compact issue {{ printf \\\"%0.2f\\\" $value }}%, please follow document to fix it: /itom/SMAX:2021.05/Searchslow\"\n        step_1: \"Log in to Suite Administration, click Configurations &gt; on the Smart Analytics tab, click Go to Smart Analytics. In Smart Analytics Assistant, double-click XService DIH\"\n        step_2: \"Enter the following action and click RUN: https://smarta-saw-dih-svc:1444/DRECOMPACT?backup=false&amp;noarchive=true\"\n        step_3: \"Double-click XService DIH, select View Index Status from the drop-down list and click RUN\"\n      expr: (sum(sma_smartanalytics_con_committed_document_number{host=~\"smarta-sawarc-con-0\"})/sum(sma_smartanalytics_con_document_number{host=~\"smarta-sawarc-con-0\"}))*100-100\n        &gt; 20\n      for: 1m\n      labels:\n        severity: warning\n    - alert: SMAPodNotReady\n      annotations:\n        description: \"Deployment {{ $labels.namespace }}/{{ $labels.deployment }} is not availablek\"\n        summary: \"Deployment ({{ $labels.namespace }}/{{ $labels.deployment }}) has pod ({{ $value }}) not available, please contact IT admin to check it\"\n        step_1: \"Restart POD: kubectl delete pod &lt;pod_name&gt; -n {{ $labels.namespace }} \"\n        step_2: \"If outage occurs and restart pod does not work, please restart SMAX cluster: /itom/SMAX:2021.05/RestartSMASuite (change 2021.05 to your SMAX version)\"\n        step_2_1: \"cd $CDF_HOME/scripts\"\n        step_2_2: \"./cdfctl.sh runlevel set -l DOWN -n {{ $labels.namespace }}\"\n        step_2_3: \"./cdfctl.sh runlevel set -l UP -n {{ $labels.namespace }}\"\n        step_3: \"Reboot whole cluster include hard reboot VMs for all masters and worker nodes\"\n      expr: kube_deployment_status_replicas_unavailable{namespace=~\"core|itsma.*\"} &gt; 0\n      for: 1m\n      labels:\n        severity: warning\n    - alert: SMAHttpClientUsageTooHigh\n      annotations:\n        description: \"POD ({{$labels.kubernetes_pod_name}}) httpclient usage is too high\"\n        summary: \"SMAX pod httpclient {{$labels.kubernetes_pod_name}} inUse is too high, current value is {{ $value }}, please consider to restart this pod by below command: kubectl delete pod -n {{ $labels.namespace }} {{$labels.kubernetes_pod_name}}\"\n      expr: mf_maas_infra{attr=~\"InUse\"} &gt; 20\n      for: 2m\n      labels:\n        severity: warning\n    - alert: SMAHttpClientUsageRiskHigh\n      annotations:\n        description: \"POD ({{$labels.kubernetes_pod_name}}) httpclient usage is risk high\"\n        summary: \"SMAX pod httpclient {{$labels.kubernetes_pod_name}} (inUse) is risk high, current value is {{ $value }}, please contact Administrator ASAP and consider to restart this pod by below command: kubectl delete pod -n {{ $labels.namespace }} {{$labels.kubernetes_pod_name}}\"\n      expr: mf_maas_infra{attr=~\"InUse\"} &gt; 50\n      for: 2m\n      labels:\n        severity: critical\n    - alert: SMATomcatThreadUsageTooHigh\n      annotations:\n        description: \"POD ({{$labels.kubernetes_pod_name}}) tomcat thread usage is too high\"\n        summary: \"SMAX pod tomcat thread {{$labels.kubernetes_pod_name}} is too high, current value is {{ $value }}, please consider to restart this pod by below command: kubectl delete pod -n {{ $labels.namespace }} {{$labels.kubernetes_pod_name}}\"\n      expr: mf_tomcat_threadpool{attr=~\"currentThreadCount\", exported_name=\"\\\"https-jsse-nio-8443\\\"\"}  &gt; 50\n      for: 2m\n      labels:\n        severity: warning\n    - alert: SMATomcatThreadUsageRiskHigh\n      annotations:\n        description: \"POD ({{$labels.kubernetes_pod_name}}) tomcat thread usage is risk high\"\n        summary: \"SMAX pod tomcat thread {{$labels.kubernetes_pod_name}} is risk high, current value is {{  $value }}, please contact Platform Administrator ASAP and  consider to restart this pod by below command: kubectl delete pod -n {{ $labels.namespace }} {{$labels.kubernetes_pod_name}}\"\n      expr: mf_tomcat_threadpool{attr=~\"currentThreadCount\", exported_name=\"\\\"https-jsse-nio-8443\\\"\"} &gt; 200\n      for: 2m\n      labels:\n        severity: critical\n</code></pre>\n<ul style=\"padding-left: 0px;\"><li style=\"margin-left: 28px; position: relative;\"><strong>SMANodeCpuUsageTooHigh:</strong> If the CPU usage for one Cluster Node is higher than 70%, a warning level message is sent out.</li></ul>\n<ul style=\"padding-left: 0px;\"><li style=\"margin-left: 28px; position: relative;\"><strong>SMANodeCpuUsageRiskHigh:</strong> If the CPU usage for one Cluster Node is higher than 80%, a critical level message is sent out</li></ul>\n<ul style=\"padding-left: 0px;\"><li style=\"margin-left: 28px; position: relative;\"><strong>SMANodeMemoryUsageTooHigh:</strong> If the RAM usage for one Cluster Node is higher than 70%, a warning level message is sent out</li></ul>\n<ul style=\"padding-left: 0px;\"><li style=\"margin-left: 28px; position: relative;\"><strong>SMANodeMemoryUsageRiskHigh:</strong> If the RAM usage for one Cluster Node is higher than 80%, a critical level message is sent out</li></ul>\n<ul style=\"padding-left: 0px;\"><li style=\"margin-left: 28px; position: relative;\"><strong>SMASmartAnalyticsContentDataCompactAlert:</strong> This is a known issue in the Suite. When the ratio of the number of committed documents to the number of documents is larger than 1.2, you need to take action on compaction.</li></ul>\n<ul style=\"padding-left: 0px;\"><li style=\"margin-left: 28px; position: relative;\"><strong>SMAPodNotReady:</strong> When one or more Suite  pods aren't ready, an email is sent to the administrator with possible solutions.</li><li style=\"margin-left: 28px; position: relative;\"><strong>SMAHttpClientUsageTooHigh:</strong> When httpclient usage is higher than 20, a warnning level message is sent out. The higher usage of httpclient will cause 504 timeout error when accessing Service Portal.</li><li style=\"margin-left: 28px; position: relative;\"><strong>SMAHttpClientUsageRiskHigh:</strong> When httpclient usage is higher than 50, a critical level message is sent out. The higher usage of httpclient will cause 504 timeout error when accessing Service Portal.</li><li style=\"margin-left: 28px; position: relative;\"><strong>SMATomcatThreadUsageTooHigh:</strong> When tomcat threadpool number is higher than 50, a warnning level message is sent out. The higher usage of tomcat thread poll will causes slowness login and Service Management cluster crashes.</li><li style=\"margin-left: 28px; position: relative;\"><strong>SMATomcatThreadUsageRiskHigh:</strong> When tomcat thradpool number is higher than 200, a critical level message is sent out. The higher usage of tomcat thread poll will causes slowness login and Service Managementcluster crashes.</li></ul>\n<p>You can customize these alert rules. For details, see the topic on <strong>Alerting rules</strong> in the offical documentation for Prometheus.</p>\n<h2><a id=\"Customize_JMX_metrics_configurations\" name=\"Customize_JMX_metrics_configurations\" title=\"Customize JMX metrics configurations\"></a>Customize JMX metrics configurations</h2>\n<p>Starting from version 2021.05, new JMX metrics are implemented for the xruntime platform, gateway, and service portal services. By default, there are only a few metrics exposed because of performance considerations, and you can add more by changing the configmap settings. By default, the metrics come from the out-of-the-box configuration.</p>\n<pre><code>  config.yml: |\n    attrNameSnakeCase: true\n    lowercaseOutputLabelNames: true\n    lowercaseOutputName: true\n    whitelistObjectNames:\n    - \"HP.MAAS.PLATFORM-WEBAPP:domain=INFRA,name=HttpPoolStats,*\"\n    - \"HP.MAAS.GATEWAY:domain=INFRA,name=HttpPoolStats,*\"\n    - \"HP.MAAS.ESS-WEBAPP:domain=INFRA,name=HttpPoolStats,*\"\n    - \"Catalina:type=*,*\"\n    - \"java.lang:type=*,*\"\n    rules:\n    - pattern: \"HP.MAAS.*&lt;domain=INFRA, name=(.*)&gt;&lt;&gt;(.*):\"\n      name: mf_maas_infra\n      labels:\n        name: \"$1\"\n        attr: \"$2\"\n      type: COUNTER\n    - pattern: \"Catalina&lt;type=(.*), name=(.*)&gt;&lt;&gt;(.*):\"\n      name: mf_tomcat_$1\n      labels:\n        name: \"$2\"\n        attr: \"$3\"\n      type: COUNTER\n    - pattern: \"java.lang&lt;type=(.*), name=(.*)&gt;&lt;&gt;(.*):\"\n      name: mf_java_lang_$1\n      labels:\n        name: \"$2\"\n        attr: \"$3\"\n      type: COUNTER\n    - pattern: 'java.lang&lt;type=Memory&gt;&lt;(\\w+)MemoryUsage&gt;(\\w+):'\n      name: mf_java_memory_usage_$2_bytes\n      labels:\n        name: \"$1\"\n      type: GAUGE\n</code></pre>\n<p>For information on how to change the settings by running commands, refer to the configuration YAML files samples in <b>https://github.com/prometheus/jmx_exporter/examples</b>. Run the following command to edit your configuration file. Make sure you replace <strong>&lt;ESM_NAMESPACE&gt; </strong>with the suite namespace.</p>\n<pre><code>kubectl edit cm itom-xruntime-infra-config -n &lt;ESM_NAMESPACE&gt;\n</code></pre>\n<p>Refer to the following sample to edit the config YAML file:</p>\n<pre><code>  config.yml: |\n    attrNameSnakeCase: true\n    lowercaseOutputLabelNames: true\n    lowercaseOutputName: true\n    whitelistObjectNames:\n    - \"HP.MAAS.PLATFORM-WEBAPP:domain=INFRA,name=HttpPoolStats,*\"\n    - \"HP.MAAS.GATEWAY:domain=INFRA,name=HttpPoolStats,*\"\n    - \"HP.MAAS.ESS-WEBAPP:domain=INFRA,name=HttpPoolStats,*\"\n    - \"Catalina:type=ThreadPool,*\"\n    - \"Catalina:type=GlobalRequestProcessor,*\"\n    - \"Catalina:type=Executor,*\"\n    - \"java.lang:type=MemoryPool,*\"\n    rules:\n     rules:\n    - pattern: \"HP.MAAS.*&lt;domain=INFRA, name=(.*)&gt;&lt;&gt;(.*):\"\n      name: mf_maas_infra\n      labels:\n        name: \"$1\"\n        attr: \"$2\"\n      type: COUNTER\n    - pattern: \"Catalina&lt;type=(.*), name=(.*)&gt;&lt;&gt;(.*):\"\n      name: mf_tomcat_$1\n      labels:\n        name: \"$2\"\n        attr: \"$3\"\n      type: COUNTER\n    - pattern: \"java.lang&lt;type=(.*), name=(.*)&gt;&lt;&gt;(.*):\"\n      name: mf_java_lang_$1\n      labels:\n        name: \"$2\"\n        attr: \"$3\"\n      type: COUNTER\n    - pattern: 'java.lang&lt;type=Memory&gt;&lt;(\\w+)MemoryUsage&gt;(\\w+):'\n      name: mf_java_memory_usage_$2_bytes\n      labels:\n        name: \"$1\"\n      type: GAUGE\n    - pattern: \"Catalina&lt;type=GlobalRequestProcessor, name=(.*)&gt;&lt;&gt;(.*):\"\n      name: mf_tomcat_processor\n      labels:\n        name: \"$1\"\n        attr: \"$2\"\n      type: COUNTER\n    - pattern: \"Catalina&lt;type=Executor, name=(.*)&gt;&lt;&gt;(.*):\"\n      name: mf_tomcat_executor\n      labels:\n        name: \"$1\"\n        attr: \"$2\"\n      type: COUNTER\n</code></pre>\n<p><strong>Note</strong>: The format is JSON-based. Make sure it's a valid format and make changes if needed. Note that only the following Service Management application metrics are currently supported:</p>\n<pre><code>#Domain\nHP.MAAS.PLATFORM-WEBAPP:domain=INFRA,name=AnalyticsETLJmx\nHP.MAAS.PLATFORM-WEBAPP:domain=INFRA,name=CircuitBreaker_POSTGRESQL-MASTER\nHP.MAAS.PLATFORM-WEBAPP:domain=INFRA,name=DbConnectionFactory\nHP.MAAS.PLATFORM-WEBAPP:domain=INFRA,name=HttpPoolStats\nHP.MAAS.PLATFORM-WEBAPP:domain=INFRA,name=RedisGeneralAvailabilityCommand,subcategory=SYSTEM_HEALTH\nHP.MAAS.PLATFORM-WEBAPP:domain=INFRA,name=IdolDAHAvailabilityCommand,subcategory=SYSTEM_HEALTH\nHP.MAAS.PLATFORM-WEBAPP:domain=INFRA,name=IdolDIHAvailabilityCommand,subcategory=SYSTEM_HEALTH\nHP.MAAS.PLATFORM-WEBAPP:domain=INFRA,name=ManagementPostgresGeneralAvailabilityCommand,subcategory=SYSTEM_HEALTH\nHP.MAAS.PLATFORM-WEBAPP:domain=INFRA,name=RabbitGeneralAvailabilityCommand,subcategory=SYSTEM_HEALTH</code></pre>\n<h2 class=\"mw-headline\"><a id=\"Out_of_the_box_dashboards\" name=\"Out_of_the_box_dashboards\" title=\"Out-of-the-box dashboards\"></a><a id=\"Out-of-the-box_dashboards\" name=\"Out-of-the-box_dashboards\" title=\"Out-of-the-box dashboards\"></a>Out-of-the-box dashboards</h2>\n<div><span style=\"font-size: 14px;\">The following list describes them:</span></div>\n<ul style=\"padding-left: 0px;\"><li style=\"margin-left: 28px; position: relative;\"><strong>SMAX Overview:</strong> A central dashboard displaying key indicators for every application.</li><li style=\"margin-left: 28px; position: relative;\"><b>General OS Metrics: </b>Displays general Operating System information, including CPU, memory, disk, and other indicators.</li><li style=\"margin-left: 28px; position: relative;\"><strong>Kubernetes Cluster Metrics: </strong>Displays the status of Kubernetes pods, including availability, CPU, memory, and network usage.</li><li style=\"margin-left: 28px; position: relative;\"><strong>Kubernetes Pods Metrics:</strong> displays pod-level metrics with time and spike information.</li><li style=\"margin-left: 28px; position: relative;\"><strong>SMAX Nginx Ingress Metrics:</strong> displays Nginx metrics with connection state and CPU/memory usage.</li><li style=\"margin-left: 28px; position: relative;\"><strong>SMAX Redis Metrics:</strong> displays Redis-related metrics including client numbers, memory usage, Network I/O, and DB items.</li><li style=\"margin-left: 28px; position: relative;\"><strong>SMAX RabbitMQ Metrics:</strong> displays RabbitMQ metrics including node status, connections, channels, and queues.</li><li style=\"margin-left: 28px; position: relative;\"><strong>Virtual Agent Metrics:</strong> displays search traffic, performance, and errors from Virtual Agent.</li><li style=\"margin-left: 28px; position: relative;\"><strong>Smart Analytics Metrics:</strong> displays Smart Analytics metrics with Index Queue and Received Speed information.</li><li style=\"margin-left: 28px; position: relative;\"><strong>Smart Search Metrics: </strong>displays search traffic, performance, and errors from the Service Portal.</li><li style=\"margin-left: 28px; position: relative;\"><strong>IdM Active User Metrics:</strong> displays the suite IdM-related information including active users, user sessions, and all sessions.</li><li style=\"margin-left: 28px; position: relative;\"><strong>Xruntime JMX Metrics</strong>:\n\t<ul style=\"padding-left: 0px;\"><li style=\"margin-left: 40px; position: relative;\">Displays JMX metrics including HTTP clients and server pool numbers of the platform, service portal, and gateway.</li><li style=\"margin-left: 40px; position: relative;\">Monitors c3p0 DataSources for platform pods including online, offline, offline-ng and readonly pods.</li><li style=\"margin-left: 40px; position: relative;\">Monitors the following Native SACM metrics \n\t\t<ul style=\"padding-left: 0px;\"><li style=\"margin-left: 52px; position: relative;\">Configuration item (CI) queues in an offline pod.</li><li style=\"margin-left: 52px; position: relative;\">Overall CI processing rate for the farm and each tenant.</li><li style=\"margin-left: 52px; position: relative;\">CI processing rate for different CI types in each tenant.</li></ul>\n</li></ul>\n</li><li style=\"margin-left: 28px; position: relative;\"><strong>Audit Service Metrics: </strong>displays audit service traffic, performance and errors.</li><li style=\"margin-left: 28px; position: relative;\"><strong>Integration Studio Metrics: </strong>displays the following metrics: \n\t<ul style=\"padding-left: 0px;\"><li style=\"margin-left: 40px; position: relative;\"><strong>Ready Online Pods</strong></li><li style=\"margin-left: 40px; position: relative;\"><strong>Ready Offline Pods</strong></li><li style=\"margin-left: 40px; position: relative;\"><strong>Recursive Trigger by Tenant</strong>: displays the number of long running triggers. This helps to identify and address misconfigured business rules that may cause execution issues.</li><li style=\"margin-left: 40px; position: relative;\"><strong>Scenario Trigger Message (RabbitMQ): </strong>displays the number of messages added to RabbitMQ by business rules and consumed by the Integration Studio clients.</li><li style=\"margin-left: 40px; position: relative;\"><strong>Scenario and Rule Execution: </strong>displays the number of scenarios and rules executed at the farm level with tenant-wise breakup.</li><li style=\"margin-left: 40px; position: relative;\"><strong>Online Scenario and Rule Execution</strong>: displays the number of scenarios and rules executed by online pods at farm level with tenant-wise breakup.</li><li style=\"margin-left: 40px; position: relative;\"><strong>Offline Scenario and Rule Execution</strong>: displays the number of scenarios and rules executed by offline pods at farm level with tenant-wise breakup.</li><li style=\"margin-left: 40px; position: relative;\"><strong>Online / Offline Deployment</strong>: Resource limits and usage metrics for CPU and Memory for online and offline deployments.</li><li style=\"margin-left: 40px; position: relative;\">Database connection pool and incoming queued messages metrics along with the application status.</li></ul>\n</li><li style=\"margin-left: 28px; position: relative;\"><strong>Aviator Metrics:</strong> displays search traffic, performance, and errors from the Aviator capability.</li></ul>\n<h2 class=\"mw-headline\"><a id=\"Covered_component\" name=\"Covered_component\" title=\"Covered component\"></a>Covered component</h2>\n<p>See the following diagram to check which component has been covered. </p>\n<div><a class=\"image\" href=\"\"> <img alt=\"SMA monitoring covered component\" border=\"0\" file=\"/mediawiki/images/0/0e/SMA202205_monitoring_covered_component.png\" hspace=\"0\" src=\"../../../images/SMA202205_monitoring_covered_component_6b93b3b6.png\" style=\"width: 800px; height: 440px; margin: 0px; border: 0px solid black;\" vspace=\"0\"/> </a></div>\n<p class=\"mw-headline\"><strong>What's covered:</strong></p>\n<ul style=\"padding-left: 0px;\"><li style=\"margin-left: 28px; position: relative;\">Generic OS</li><li style=\"margin-left: 28px; position: relative;\">Generic Container</li><li style=\"margin-left: 28px; position: relative;\">JVM</li><li style=\"margin-left: 28px; position: relative;\">IDM</li><li style=\"margin-left: 28px; position: relative;\">Redis</li><li style=\"margin-left: 28px; position: relative;\">RabbitMQ</li><li style=\"margin-left: 28px; position: relative;\">Nginx</li><li style=\"margin-left: 28px; position: relative;\">Smart Analytics</li><li style=\"margin-left: 28px; position: relative;\">Smart Search</li><li style=\"margin-left: 28px; position: relative;\">Audit Service</li><li style=\"margin-left: 28px; position: relative;\">Integration Studio</li><li style=\"margin-left: 28px; position: relative;\">External Database</li></ul>\n<p><strong>What's not covered:</strong></p>\n<ul style=\"padding-left: 0px;\"><li style=\"margin-left: 28px; position: relative;\">Persistent Volume</li><li style=\"margin-left: 28px; position: relative;\">Other application components</li></ul>\n<h2 class=\"mw-headline\"><a id=\"Use_cases\" name=\"Use_cases\" title=\"Use cases\"></a>Use cases</h2>\n<p class=\"mw-headline\" id=\"Access_the_Grafana_homepage\"><span style=\"font-size: 14px;\">To access the Grafana homepage on the browser, go to </span><strong style=\"font-size: 14px;\">https://&lt;external_access_host&gt;:5443/grafana</strong><span style=\"font-size: 14px;\">. You can change the password or add more users on the privilege management page. </span></p>\n<h3 id=\"Dashboard-1:_General-os-metrics\"><a id=\"Dashboard_1_General_os_metrics\" name=\"Dashboard_1_General_os_metrics\" title=\"Dashboard-1: General-os-metrics\"></a><a id=\"Dashboard-1:_General-os-metrics\" name=\"Dashboard-1:_General-os-metrics\" title=\"Dashboard-1: General-os-metrics\"></a>Dashboard-1: General-os-metrics<a id=\"fragment-navigation~/doc/423/25.4/smamonitoring#Dashboard-1:_General-os-metrics\" title=\"link text\"></a></h3>\n<p>This dashboard lists OS-level metrics such as CPU cores, memory, CPU usage, CPU iowait, memory usage, system load, and disk IOPS.</p>\n<h4><a id=\"User_case_1\" name=\"User_case_1\" title=\"User case 1\"></a>User case 1</h4>\n<p>As a Cluster Admin, to check if all pods are running with resources balanced across all worker nodes.</p>\n<ul style=\"padding-left: 0px;\"><li style=\"margin-left: 28px; position: relative;\">\n<p><b>Solution</b>: Go to 1. General OS metrics and check the CPU and Memory usage for each worker node.<br/>\n\tIn the following sample screenshots for 3 worker nodes in a running system, you can see from the <strong>Mem Usage</strong> widget that the memory usage across the three nodes are not balanced (64%, 22%, and 81%).<br/>\n<a class=\"image\" href=\"\"> <img alt=\"case1-1.1.png\" data-file-height=\"183\" data-file-width=\"1233\" src=\"../../../images/case1-1.1_1fb7dca5.png\" style=\"width: 1233px; height: 183px;\"/> </a><br/>\n<a class=\"image\" href=\"\"> <img alt=\"case1-1.2.png\" data-file-height=\"170\" data-file-width=\"1228\" src=\"../../../images/case1-1.2_b66f4105.png\" style=\"width: 1228px; height: 170px;\"/> </a><br/>\n<a class=\"image\" href=\"\"> <img alt=\"case1-1.3.png\" data-file-height=\"171\" data-file-width=\"1231\" src=\"../../../images/case1-1.3_1eac68af.png\" style=\"width: 1231px; height: 171px;\"/> </a></p>\n</li><li style=\"margin-left: 28px; position: relative;\">To re-balance the system, we recommend that the you run the following command as the cluster-admin. Make sure you replace <strong>&lt;ESM_NAMESPACE&gt;</strong> with the suite namespace.\n\t<pre>export namespace=<code>&lt;ESM_NAMESPACE&gt;</code>\nkubectl patch deploy/itom-xruntime-platform -n $namespace -p '{\"spec\":{\"template\":{\"spec\":{\"containers\":[{\"name\":\"itom-xruntime-platform\",\"env\":\n[{\"name\":\"RESTART_\",\"value\":\"'$(date +%s)'\"}]}]}}}}' kubectl patch deploy/itom-xruntime-gateway -n $namespace -p '{\"spec\":{\"template\":{\"spec\":{\"containers\":[{\"name\":\"gateway\",\"env\":[{\"name\":\"RESTART_\",\"value\":\"'$(date +%s)'\"}]}]}}}}'\nkubectl patch deploy/itom-xruntime-serviceportal -n $namespace -p '{\"spec\":{\"template\":{\"spec\":{\"containers\":[{\"name\":\"itom-xruntime-serviceportal\",\"env\":\n</pre>\n\tSee the following sample screenshots showing the balanced <strong>Mem Usage</strong> metrics<br/>\n<a class=\"image\" href=\"\"> <img alt=\"case1-2.1.png\" data-file-height=\"169\" data-file-width=\"1243\" src=\"../../../images/case1-2.1_7ec5be81.png\" style=\"width: 1243px; height: 169px;\"/> </a><br/>\n<a class=\"image\" href=\"\"> <img alt=\"case1-2.2.png\" data-file-height=\"171\" data-file-width=\"1233\" src=\"../../../images/case1-2.2_48bcab9e.png\" style=\"width: 1233px; height: 171px;\"/> </a><br/>\n<a class=\"image\" href=\"\"> <img alt=\"case1-2.3.png\" data-file-height=\"170\" data-file-width=\"1231\" src=\"../../../images/case1-2.3_bacdaa42.png\" style=\"width: 1231px; height: 170px;\"/> </a></li></ul>\n<h4><a id=\"User_case_2\" name=\"User_case_2\" title=\"User case 2\"></a>User case 2</h4>\n<p>As a Cluster admin, you can check the system load in the past 3 hours.</p>\n<ul style=\"padding-left: 0px;\"><li style=\"margin-left: 28px; position: relative;\"><b>Solution</b>:  Go to 1. General OS metrics, check the <strong>System Load</strong> dashboard. Click Text <b>System Load,</b> and choose <b>View</b> from the dropdown list.\n\n\t<div><a class=\"image\" href=\"\"> <img alt=\"case2.png\" data-file-height=\"414\" data-file-width=\"1343\" src=\"../../../images/case2_bc4433ad.png\" style=\"width: 1343px; height: 414px;\"/> </a></div>\n</li></ul>\n<h3 id=\"Dashboard-2:_Kubernetes-cluster-metrics\"><a id=\"Dashboard_2_Kubernetes_cluster_metrics\" name=\"Dashboard_2_Kubernetes_cluster_metrics\" title=\"Dashboard-2: Kubernetes-cluster-metrics\"></a><a id=\"Dashboard-2:_Kubernetes-cluster-metrics\" name=\"Dashboard-2:_Kubernetes-cluster-metrics\" title=\"Dashboard-2: Kubernetes-cluster-metrics\"></a>Dashboard-2: Kubernetes-cluster-metrics<a id=\"fragment-navigation~/doc/423/25.4/smamonitoring#Dashboard-2:_Kubernetes-cluster-metrics\" title=\"link text\"></a></h3>\n<p>This dashboard provides information about the Kubernetes cluster system, including system running time, pod availability status, and CPU/memory/network usage for individual pods.</p>\n<h4><a id=\"User_case_3\" name=\"User_case_3\" title=\"User case 3\"></a>User case 3 </h4>\n<p>As a Cluster Admin, I want to know the system status in the past 3 hours, and see if there are any abnormal pods.</p>\n<ul style=\"padding-left: 0px;\"><li style=\"margin-left: 28px; position: relative;\"><b>Solution</b>: Go to 2. Kubernetes cluster metrics, and then check the <strong>Unavailable Replicas</strong> and <strong>Unavailable Pods</strong> dashboards.</li><li style=\"margin-left: 28px; position: relative;\"><b>Explanation</b>: The following dashboard shows that two pods are currently not available, indicating that there may be something wrong with this cluster, and at 2017-07-26 13:57:45, itom-xruntime-platform and itom-xruntime-platform-offline were not ready. You can change the time series to a smaller one so that the dashboard is clearer.<br/>\n<a class=\"image\" href=\"\"> <img alt=\"case3.png\" data-file-height=\"262\" data-file-width=\"1072\" src=\"../../../images/case3_9e30a39f.png\" style=\"width: 1072px; height: 262px;\"/> </a></li></ul>\n<h4><a id=\"User_case_4\" name=\"User_case_4\" title=\"User case 4\"></a>User case 4</h4>\n<p>As a Cluster Admin, I want to know the CPU and Memory usage of certain pods (for example, itom-xruntime-platform), to monitor the usage and trend.</p>\n<ul style=\"padding-left: 0px;\"><li style=\"margin-left: 28px; position: relative;\"><b>Solution</b>: Go to 2. Kubernetes cluster metrics, filter Deployments by keyword <strong>platform </strong>and choose <b>itom-xruntime-platform</b>.</li><li style=\"margin-left: 28px; position: relative;\"><b>Explanation</b>: in this dashboard, you can see that the platform pod memory increases from 470 MB to 3.7 GB in 10 minutes, and then becomes stable. <a class=\"image\" href=\"\"> <img alt=\"case4.png\" data-file-height=\"706\" data-file-width=\"1839\" src=\"../../../images/case4_7c59a0d5.png\" style=\"width: 1839px; height: 706px;\"/> </a></li></ul>\n<h4><a id=\"User_case_5\" name=\"User_case_5\" title=\"User case 5\"></a>User case 5</h4>\n<p>As a Cluster Admin, I want to know the compaction ratio of Smart Analytics documents to make sure that there is no search performance issue.</p>\n<ul style=\"padding-left: 0px;\"><li style=\"margin-left: 28px; position: relative;\"><b>Symptom</b>: If the Suite cluster has been running for a long time and Smart Analytics has a compaction issue, it will consume lots of disk space. If it's on AWS EFS, you will see that the EFS burst credit keeps going down in several days.</li><li style=\"margin-left: 28px; position: relative;\"><b>Root cause</b>: The number of documents and the number of committed documents aren't the same for Smart Analytics Content. See the following sample screenshot. <a class=\"image\" href=\"\"> <img alt=\"SMA 2020.02prometheus usecase5 1.png\" data-file-height=\"433\" data-file-width=\"1839\" src=\"../../../images/SMA_2020.02prometheus_usecase5_1_aae058f0.png\" style=\"width: 1839px; height: 433px;\"/> </a></li><br/><li style=\"margin-left: 28px; position: relative;\"><b>Solution</b>: For details, see the troubleshooting topic <strong>Search is slow</strong> under <strong>Troubleshoot Smart Analytics.  </strong>Run the following commands:\n\t<pre>kubectl get pods -n &lt;namespace&gt; -o wide | grep dih\ncurl \"http://&lt;ip&gt;:31371/DRECOMPACT?backup=false&amp;noarchive=true\" \n</pre>\n\tSee the following sample screenshots:<br/>\n<a class=\"image\" href=\"\"> <img alt=\"SMA 2020.02prometheus usecase5 2.png\" data-file-height=\"434\" data-file-width=\"1837\" src=\"../../../images/SMA_2020.02prometheus_usecase5_2_9bbd7c1e.png\" style=\"width: 1837px; height: 434px;\"/> </a></li></ul>\n<h3 class=\"mw-headline\" id=\" Enable_PostgreSQL_metrics\"><a id=\"Enable_PostgreSQL_metrics\" name=\"Enable_PostgreSQL_metrics\" title=\"Enable PostgreSQL metrics\"></a>Enable PostgreSQL metrics</h3>\n<p>You can use the Postgres metrics to display metrics for external PostgreSQL databases. These metrics include resource consumption, active sessions, total sessions, etc.  For instructions on how to enable database metrics, see <strong>Use the PostgreSQL exporter to monitor the external</strong> topic.</p>\n</div>",
  "modifiedon": "2025-11-27 05:47:31"
}