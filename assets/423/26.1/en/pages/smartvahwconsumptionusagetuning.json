{
  "title": "Hardware resource consumption for smart virtual agent",
  "content": "<div class=\"mw-parser-output\"><p class=\"mw-empty-elt\">\n</p><p><!--cke_bookmark_60805S--><!--cke_bookmark_60805E-->This topic describes the hardware resource consumption for the training and user input parsing processes for the smart virtual agent functionality. It also lists various limits that are related with hardware consumption, and how to change the limits.</p>\n<p>In general, the hardware consumption for both training and user input parsing is determined by the following factors: the number of intents, the number of training sentences per intent, the total number of training sentences, the complexity of training sentences, and the language of intents and training sentences.</p>\n<p>This topic helps you understand how many hardware resources you need to support the smart virtual agent functionality, and how to configure primary models and various limits to achieve optimized performance.</p>\n<h2>Hardware consumption for the training process</h2>\n<p>The following table gives you some idea about how many intents and training sentences (in two languages) a small and medium deployment can support for the training process, based on our lab test results against some sample data. Use this as a benchmark when evaluating your hardware requirements for training.</p>\n<table border=\"1\" cellpadding=\"1\" cellspacing=\"1\" style=\"width: 500px;\">\n<thead>\n<tr>\n<th scope=\"col\">Number of<br/>\n\t\t\tCPU cores</th>\n<th scope=\"col\">Memory</th>\n<th scope=\"col\">Language</th>\n<th scope=\"col\">Number of intents</th>\n<th scope=\"col\">Number of sentences per intent</th>\n<th scope=\"col\">Total number of sentences</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>1</td>\n<td>2 GB</td>\n<td>English</td>\n<td>20</td>\n<td>10</td>\n<td>200</td>\n</tr>\n<tr>\n<td>1</td>\n<td>2 GB</td>\n<td>Japanese</td>\n<td>12</td>\n<td>10</td>\n<td>120</td>\n</tr>\n<tr>\n<td>2</td>\n<td>4 GB</td>\n<td>English</td>\n<td>300</td>\n<td>7</td>\n<td>2100</td>\n</tr>\n<tr>\n<td>2</td>\n<td>4 GB</td>\n<td>Japanese</td>\n<td>125</td>\n<td>8</td>\n<td>1000</td>\n</tr>\n</tbody>\n</table>\n<p>To prevent huge data volume from overloading the system during the training process, Service Management imposes the following limits per tenant:</p>\n<ul>\n<li>Number of intents: 300<sup>*</sup></li>\n<li>Number of training sentences per intent: 20<sup>*</sup></li>\n<li>\n<p>Total number of training sentences: 1000 for East Asian languages (Simplified Chinese, Japanese, Korean); 2400 for other languages. You can increase these limits after you add resources (or increase the limit) for the <code>nlu</code> pod, which is the pod that handles training and input parsing. See the \"How to change the limits for training sentences\" section below.</p>\n</li>\n</ul>\n<p>* These numbers represent the industry's best practices and can't be changed.</p>\n<h2>Memory consumption for user input parsing</h2>\n<p>The input parsing process mainly consumes a lot of memory resources. This section explains how data models are loaded to the memory during input parsing and the memory footprint for different data models.</p>\n<h3>How data models are loaded to the memory</h3>\n<p>Service Management uses data models generated during the training process to parse the user input and predict user intent. The training process generates one data model per language and tenant combination. For example, if the deployment includes two tenants, and in each tenant, you define training sentences and intents in two languages, the training process will generate four data models.</p>\n<p>When user input is received, Service Management loads a data model for a particular language to the memory according to the language of the user input.</p>\n<p>To enhance the responsiveness of the smart virtual agent, you can make Service Management pre-load some data models in the memory. In those tenants, users will experience quicker responses when they interact with the virtual agent using the corresponding languages. To achieve this, a suite administrator can turn on the \"Enable cache configuration\" option, and specify tenant-language combinations whose models (referred to as <em>primary models</em>) will be pre-loaded in the memory.</p>\n<h3><span style='color: rgb(51, 51, 51); font-family: Roboto, \"Apple Color Emoji\", \"Segoe UI Emoji\", \"Segoe UI Symbol\"; font-size: 16px;'>Service Management loads data models to the memory as follows:</span></h3>\n<ul>\n<li>If \"Enable cache configuration\" is OFF, the system loads required models to the memory on demand when user input is received. The available memory for data models is the total memory minus the memory used by the base <code>nlu</code> service (around 500 MB). If the loaded models use up all the available memory, existing models will be released from memory so that the system can serve new requests.</li>\n<li>\n<p>If \"Enable cache configuration\" is ON, the system pre-loads the primary models to the memory and loads other models to the memory on demand.</p>\n<p>Primary models will be pre-loaded to the memory according to the configured rank. Note that if a primary model is too big to fit into the remaining memory for primary models, the system will check the next primary model (as per the rank) to see if it can fit into the memory, and if yes, pre-load the next model, and so on.</p>\n<p>When the system uses up the memory available to primary models, primary models that can't be pre-loaded will be loaded on demand instead, and share the same reserved memory (see the section below) with other normal models.</p>\n<p>Unlike models loaded on demand, pre-loaded models will stay in the memory and will not be released regardless of system workload.</p>\n</li>\n</ul>\n<h3>Available memory for primary models</h3>\n<p>When \"Enable cache configuration\" is ON, the system reserves 400 MB of memory for all models that are loaded on demand by default. Since the base <code>nlu</code> service uses 400-500 MB of memory, you can calculate the approximate memory available to primary models by using this formula:</p>\n<p><code>&lt;Total memory for nlu pod in MB&gt; - 400 - 500</code></p>\n<p>The following image shows the memory allocation for a small deployment size (with 2GB memory). The orange, blue, and green boxes represent the memory allocation/usage for the base <code>nlu</code> service, models loaded on demand, and primary models, respectively.</p>\n<p><a class=\"image\" href=\"/file/images/e/e1/%E4%B8%89%E8%89%B2%E5%9B%BE.png\" title=\"/file/images/e/e1/%E4%B8%89%E8%89%B2%E5%9B%BE.png\"> <img alt=\"\" border=\"0\" file=\"/mediawiki/images/e/e1/%E4%B8%89%E8%89%B2%E5%9B%BE.png\" height=\"83\" hspace=\"0\" src=\"../../../images/E4B889E889B2E59BBE_d83d42e8.png\" vspace=\"0\" width=\"800\"/> </a></p>\n<p>You can change the default reserved memory size (400). See the \"How to change the reserved memory size\" section below for instructions.</p>\n<h3>Memory footprint of data models</h3>\n<p>The memory footprint for different models varies with a lot of factors, such as the number of intents, the number of training sentences in each intent, and the language of the intents and training sentences, and so on. Models for Simplified Chinese and Japanese languages consume much more memory than other languages because they use a different, pre-trained mechanism. Simplified Chinese models usually consume more than 600 MB, Japanese models more than 200 MB, and models in other languages only less than 100 MB of memory.</p>\n<p>You can get a more accurate estimation of the memory footprint for primary models from the primary language models list (Suite Administration &gt; Configurations &gt; Virtual agent tab &gt; Estimated model size column).</p>\n<h2>How to change various limits related with hardware consumption</h2>\n<h3 id=\"ChgTotalNo\">How to change the limits for training sentences</h3>\n<p>You can change the limits for the total number of training sentences per tenant, as follows:</p>\n<div class=\"Admonition_Note\"><span class=\"autonumber\">Note</span>: This section describes how to change the limit for western languages. You can use the same commands to change the limit for east Asian languages (Simplified Chinese, Japanese, and Korean). Just replace <code>WESTERN_SAMPLE_LIMIT</code> with <code>ASIAN_SAMPLE_LIMIT</code>.</div>\n<h4 class=\"Admonition_Note\">Method 1</h4>\n<ol>\n<li>\n<p>Log in to the control plane node or bastion node of the suite, and run the following command:</p>\n<pre>kubectl edit deployment virtual-agent-nlu -n &lt;suite_namespace&gt;</pre>\n</li>\n<li>\n<p>Add a name-value pair for the <code>WESTERN_SAMPLE_LIMIT</code> parameter in the <code>env</code> section, and specify the desired limit:</p>\n<pre><code class=\"language-yaml\"> - name: WESTERN_SAMPLE_LIMIT\n   value: \"3000\"</code></pre>\n</li>\n<li>\n<p>Restart the <code>virtual-agent-nlu</code> deployment by using the following command:</p>\n<pre>kubectl rollout restart deployment virtual-agent-nlu -n &lt;suite_namespace&gt;</pre>\n</li>\n</ol>\n<h4>Method 2</h4>\n<ol>\n<li>\n<p>Log in to the control plane node or bastion node, and then run the following command to edit the ConfigMap file:</p>\n<pre>kubectl edit cm itom-sma-smarta-configuration -n &lt;suite_namespace&gt;</pre>\n</li>\n<li>\n<p>Add a key-value pair for the <code>WESTERN_SAMPLE_LIMIT</code> parameter in the <code>data</code> section, and specify the desired limit:</p>\n<pre><code class=\"language-yaml\">WESTERN_SAMPLE_LIMIT: \"3000\"</code></pre>\n</li>\n<li>\n<p>Edit the <code>virtual-agent-nlu</code> deployment by using the following command:</p>\n<pre>kubectl edit deployment virtual-agent-nlu -n &lt;suite_namespace&gt;</pre>\n<!--cke_bookmark_61322S--><!--cke_bookmark_61322E--></li>\n<li>\n<p>Add the following in the <font face=\"monospace\">env</font> section:</p>\n<!--cke_bookmark_60650S-->\n<pre><code class=\"language-yaml\">- name: WESTERN_SAMPLE_LIMIT \n  valueFrom:\n      configMapKeyRef:\n         key: WESTERN_SAMPLE_LIMIT\n         name: itom-sma-smarta-configuration</code></pre>\n<!--<!--cke_bookmark_60650E--></li>\n<li>\n<p>Restart the <code>virtual-agent-nlu</code> deployment by using the following command:</p>\n<pre>kubectl rollout restart deployment virtual-agent-nlu -n &lt;suite_namespace&gt;</pre>\n</li>\n</ol>\n<h3 id=\"ChgReserved\">How to change the reserved memory size</h3>\n<p>When you adjust the reserved memory size, you must ensure the reserved memory can accommodate the largest data model that could be loaded in that memory section. Otherwise, when users in that tenant interact with the smart virtual agent in the corresponding language, the system can't load the data model and the virtual agent won't work appropriately.</p>\n<div class=\"Admonition_Tip\"><span class=\"autonumber\">Tip</span>: To figure out the maximum size of training data models in your deployment, you can add all tenants with Chinese training sentences configured to the primary models list in Suite Administration (Configurations &gt; Virtual agent tab), and then check the maximum value in the Estimated model size column.</div>\n<p>You can change the reserved memory for models loaded on demand, as follows:</p>\n<h4>Method 1</h4>\n<ol>\n<li>\n<p>Log in to the control plane node or bastion node of the suite, and run the following command:</p>\n<pre>kubectl edit deployment virtual-agent-nlu -n &lt;suite_namespace&gt;</pre>\n</li>\n<li>\n<p>Add a name-value pair for the <code>MAX_ RESERVE_ MEMORY</code> parameter in the <code>env</code> section, and specify the desired memory size:</p>\n<pre><code class=\"language-yaml\">- name: MAX_RESERVE_MEMORY\n  value: \"900\"</code></pre>\n<p><span id=\"cke_bm_52559C\" style=\"display: none;\"> </span></p>\n</li>\n<li>\n<p>Restart the <code>virtual-agent-nlu</code> deployment by using the following command:</p>\n<pre>kubectl rollout restart deployment virtual-agent-nlu -n &lt;suite_namespace&gt;</pre>\n</li>\n</ol>\n<h4>Method 2</h4>\n<ol>\n<li>\n<p>Log in to the control plane node or bastion node, and then run the following command to edit the ConfigMap file:</p>\n<pre>kubectl edit cm itom-sma-smarta-configuration -n &lt;suite_namespace&gt;</pre>\n</li>\n<li>\n<p>Add a key-value pair for the <code>MAX_RESERVE_MEMORY</code> parameter in the <code>data</code> section, and specify the desired limit:</p>\n<pre><code class=\"language-yaml\">MAX_RESERVE_MEMORY: \"900\"</code></pre>\n</li>\n<li>\n<p>Edit the <code>virtual-agent-nlu</code> deployment by using the following command:</p>\n<pre>kubectl edit deployment virtual-agent-nlu -n &lt;suite_namespace&gt;</pre>\n</li>\n<li>\n<p>Add the following in the <code>env</code> section:</p>\n<pre><code class=\"language-yaml\">- name: MAX_RESERVE_MEMORY\n  valueFrom:\n      configMapKeyRef:\n         key: MAX_RESERVE_MEMORY\n         name: itom-sma-smarta-configuration</code></pre>\n</li>\n<li>\n<p>Restart the <code>virtual-agent-nlu</code> deployment by using the following command:</p>\n<pre>kubectl rollout restart deployment virtual-agent-nlu -n &lt;suite_namespace&gt;</pre>\n</li>\n</ol>\n<p class=\"mw-empty-elt\"></p></div>",
  "modifiedon": "2025-10-24 08:51:12"
}