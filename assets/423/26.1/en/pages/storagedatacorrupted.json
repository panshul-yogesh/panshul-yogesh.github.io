{
  "title": "Scenario 2: Persistent storage data has been corrupted",
  "content": "<div class=\"mw-parser-output\">\n<p>In this scenario, some files on the persistent storage are corrupted or deleted by accident or mistakenly. You need to restore these files to the latest backup. Choose the restore solution according to your deployment platforms.</p>\n<h2 id=\"Prerequisite\">Prerequisites</h2>\n<p>Before you start, make sure:</p>\n<ul>\n<li>You have backed up the storage.</li>\n<li>The Kubernetes cluster is functioning.</li>\n<li>There's no data corruption in your databases.</li>\n</ul>\n<h2>Restore EFS on AWS</h2>\n<p>If your suite is deployed on AWS, follow these steps to restore EFS:</p>\n<ol>\n<li>Run this command on the bastion to stop the system:\n\t<pre>./cdfctl.sh runlevel set -l DOWN -n core,itsma-xxxxx</pre>\n</li>\n<li>Restore EFS by navigating to the AWS Backup console at <a href=\"https://console.aws.amazon.com/backup\" target=\"_blank\" title=\"https://console.aws.amazon.com/backup\">https://console.aws.amazon.com/backup</a> and following the instructions at <a href=\"https://docs.aws.amazon.com/aws-backup/latest/devguide/restore-resource.html\" title=\"Restore a backup\">Restore a backup</a>.\n\t<ul>\n<li>\n<p>If your EFS instance still exists,</p>\n<ul>\n<li>For <b>Restore type</b>, select <b>Full restore</b>.</li>\n<li>For <b>Restore location</b>, select <b>Restore to directory in source file system</b>.</li>\n<li>Leave the remaining settings as is.</li>\n</ul>\n</li>\n<li>\n<p>If your EFS instance doesn't exist,</p>\n<ul>\n<li>For <b>Restore type</b>, select <b>Full restore</b>.</li>\n<li>For <b>Restore location</b>, select <b>Restore to a new file system</b>.</li>\n<li>Leave the remaining settings as is.</li>\n</ul>\n<p>After the EFS instance is restored successfully, perform the following two tasks as required. Note that if your EFS instance still exists before restoration, there is <strong>NO</strong> need to do these tasks.</p>\n<ul>\n<li>Select the instance and update its network settings by clicking <b>Manage </b>under <b>Network</b> and configuring as below:\n\n\t\t\t<ul>\n<li>For <b>VPC, </b>select the same VPC as the old EFS.</li>\n<li>For <b>Availability Zone</b>, select the same availability zone as the old EFS.</li>\n<li>For <b>Subnet ID</b>, select the same subnet as the old EFS.</li>\n<li>For <b>Security group</b>, select the same security group as the old EFS.</li>\n</ul>\n</li>\n<li>Run the following commands on the bastion to recreate persistent volumes by replacing the old server information in the <code>/tmp/pv.yaml</code> file with the new one. You can get <strong>&lt;efs-dns-name&gt;</strong> from the AWS Management Console.\n\t\t\t<pre>SMAX_NAMESPACE=$(kubectl get namespaces|grep itsma|head -n 1|awk '{print $1}') \nkubectl get pv  | grep -E \"core|$SMAX_NAMESPACE\"| awk '{print $1}' &gt; /tmp/pvList \nfor i in $(cat /tmp/pvList); do kubectl get pv $i -o yaml &gt;&gt; /tmp/pv.yaml; echo \"---\" &gt;&gt; /tmp/pv.yaml;done \nkubectl delete -f /tmp/pv.yaml \nkubectl get pv | grep -E \"core|$SMAX_NAMESPACE\" | awk '{print $1}' | xargs  kubectl patch pv  -p '{\"metadata\":{\"finalizers\":null}}' \nsed -i.bak 's/&lt;old-efs-dns-name&gt;/&lt;new-efs-dns-name&gt;/g' /tmp/pv.yaml \nkubectl create -f /tmp/pv.yaml\n</pre>\n</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>Mount the EFS volumes to the bastion:\n\t<pre>mount -t nfs4 -o nfsvers=4.1,rsize=1048576,wsize=1048576,hard,timeo=600,retrans=2 &lt;EFS endpoint&gt;:/  path/</pre>\n<p>To get &lt;EFS endpoint&gt;, first navigate to <strong>All services</strong> &gt; <strong>EFS</strong> &gt; <strong>File systems</strong> &gt; the EFS you created to get your <strong>File system ID</strong>. Your new EFS endpoint should like this: <code>&lt;File_system_ID &gt;.efs.&lt;region&gt;.amazonaws.com</code>.</p>\n<p>Now you can check if the folder <code>aws-backup-restore-xxxxx/var</code> is mounted successfully.</p>\n</li>\n<li>Modify the mounted path to <code>/var/xx</code> with these steps:\n\t<ul>\n<li>Run the command below :\n\t\t<pre>cd path/</pre>\n</li>\n<li>Check if folder <strong>var</strong> already exists. If yes, rename the folder, for example <code>mv var/ oldvar/</code><strong> </strong> and then proceed to the next step.</li>\n<li>Run the command below:\n\t\t<pre>mv aws-backup-restore-xxxxx/var var/</pre>\n</li>\n</ul>\n<div class=\"admonition\"><div class=\"admonition-icon admonition-note-icon\"></div><div class=\"admonition-content admonition-note-content\"><div>  Now folder <code>var</code> stores all the restored data of OMT and suite and you can delete the other folders. Note that the deletion might take a long time so you can choose to delete them after the restoration is completely done.</div></div></div>\n</li>\n<li>After the new EFS instance is created and configured successfully, run this command on the bastion to restart the system:\n\t<pre>./cdfctl.sh runlevel set -l UP -n core,itsma-xxxxx</pre>\n</li>\n<li>Run this command on the bastion to verify the restoration:\n\t<pre>kubectl get pod --all-namespaces|grep -v 1/1|grep -v 2/2|grep -v 3/3|grep -v 4/4|grep -v Completed </pre>\n\tThis command returns a list of abnormal pods. If RabbitMQ isn't ready, see <a href=\"/doc/423/26.1/rabbitmqnotstart\" title=\"RabbitMQ isn't ready\">RabbitMQ isn't ready</a>. When it returns no result, all of the suite pods are ready and you can perform quick tests to make sure the restoration has been completed successfully.</li>\n</ol>\n<h2>Restore storage on Azure</h2>\n<div class=\"admonition\"><div class=\"admonition-icon admonition-note-icon\"></div><div class=\"admonition-content admonition-note-content\"><div>  If you use Azure NetApp Files as the storage service, refer to <a href=\"https://docs.microsoft.com/en-gb/azure/azure-netapp-files/\" rel=\"noreferrer noopener\" tabindex=\"-1\" target=\"_blank\" title=\"https://docs.microsoft.com/en-gb/azure/azure-netapp-files/\">https://docs.microsoft.com/en-gb/azure/azure-netapp-files/</a> for the backup and restore solution.</div></div></div>\n<p>If your suite uses Azure Files &amp; Azure Disks, follow these steps to restore the storage:</p>\n<ol>\n<li>Run this command on the bastion to stop the system:\n\t<pre><code>./cdfctl.sh runlevel set -l DOWN -n core,itsma-xxxxx</code></pre>\n</li>\n<li>Restore<strong> Azure file</strong> shares:\n\t<ul>\n<li>If your file share was deleted accidentally, you can restore it easily according to the Azure documentation: <a href=\"https://docs.microsoft.com/en-us/azure/storage/files/storage-files-enable-soft-delete?tabs=azure-portal#restore-soft-deleted-file-share\" title=\"https://docs.microsoft.com/en-us/azure/storage/files/storage-files-enable-soft-delete?tabs=azure-portal#restore-soft-deleted-file-share\">https://docs.microsoft.com/en-us/azure/storage/files/storage-files-enable-soft-delete?tabs=azure-portal#restore-soft-deleted-file-share</a>.</li>\n<li>If your file share still exists with corrupt data, you can restore it according to the Azure documentation: <a href=\"https://docs.microsoft.com/en-us/azure/backup/restore-afs\" title=\"https://docs.microsoft.com/en-us/azure/backup/restore-afs\">https://docs.microsoft.com/en-us/azure/backup/restore-afs</a>.\n\t\t<p>Note the following items:</p>\n<ul>\n<li>For <strong>Restore Location</strong>, select <strong>Original Location</strong>.</li>\n<li>Restore selected files or folders to the same file share as the original source.\n\t\t\t<p><span style=\"display: none;\"> </span></p>\n</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>After the file share is restored successfully, run this command on the bastion to restart the system:\n\t<pre>./cdfctl.sh runlevel set -l UP -n core,itsma-xxxxx</pre>\n</li>\n<li>Run this command on the bastion to verify the restoration:\n\t<pre>kubectl get pod --all-namespaces|grep -v 1/1|grep -v 2/2|grep -v 3/3|grep -v 4/4|grep -v Completed </pre>\n\tThis command returns a list of abnormal pods. If RabbitMQ isn't ready, see <a href=\"/doc/423/26.1/rabbitmqnotstart\" title=\"RabbitMQ isn't ready\">RabbitMQ isn't ready</a>. When it returns no result, all of the suite pods are ready and you can perform quick tests to make sure the restoration has been completed successfully.</li>\n<li>The <strong>Azure Disks</strong> storage (to store the Smart Analytics and RabbitMQ data) hasn't been backed up. But to ensure your suite's functionality and performance, you need to perform a <a href=\"/doc/423/26.1/fullreindex#Full_reindex_for_the_suite_that_is_deployed_on_AWS_(EKS),_Azure_(AKS),_or_GCP\" title=\"full reindex\">full reindex</a> for Smart Analytics. \n\t<div class=\"admonition\"><div class=\"admonition-icon admonition-note-icon\"></div><div class=\"admonition-content admonition-note-content\"><div>If you've accidentally deleted your Azure Disk, see <a href=\"/doc/423/26.1/azurediskdeleted\" title=\"Azure Disk has been deleted accidentally\">Azure Disk has been deleted accidentally</a> on how to restore it.</div></div></div>\n</li>\n</ol>\n<h2>Restore storage on GCP</h2>\n<p>If your suite is deployed on GCP, follow these steps to restore Filestore data:</p>\n<ol>\n<li>Run this command on the bastion to stop the system:\n\t<pre>./cdfctl.sh runlevel set -l DOWN -n core,itsma-xxxxx</pre>\n</li>\n<li>Restore the Filestore file share according to the GCP document <a href=\"https://cloud.google.com/filestore/docs/backup-restore?authuser=1#restoring_a_file_share\" title=\"https://cloud.google.com/filestore/docs/backup-restore?authuser=1#restoring_a_file_share\">https://cloud.google.com/filestore/docs/backup-restore?authuser=1#restoring_a_file_share</a>.\n\t<ul>\n<li>\n<p>If your file share still exists, select <strong>Source instance</strong> as the target instance and follow the steps at <a href=\"https://cloud.google.com/filestore/docs/backup-restore?authuser=1#restoring_to_an_existing_instance\" title=\"https://cloud.google.com/filestore/docs/backup-restore?authuser=1#restoring_to_an_existing_instance\">https://cloud.google.com/filestore/docs/backup-restore?authuser=1#restoring_to_an_existing_instance</a>.</p>\n</li>\n<li>\n<p>If your file share doesn't exist, select <strong>New instance</strong> as the target instance and follow the steps at <a href=\"https://cloud.google.com/filestore/docs/backup-restore?authuser=1#restoring_to_a_new_instance\" title=\"https://cloud.google.com/filestore/docs/backup-restore?authuser=1#restoring_to_a_new_instance\">https://cloud.google.com/filestore/docs/backup-restore?authuser=1#restoring_to_a_new_instance</a>.</p>\n<ul>\n<li>For <b>Storage type</b>, <b>Allocate capacity</b>, and <b>VPC network</b>, use the same value as your old Filestore instance.</li>\n<li>For <b>Configure your file share</b> &gt;<b> File share name</b>, use the same value as your old file share name.</li>\n<li>Leave the remaining settings as is.</li>\n</ul>\n<p>After the file share is restored successfully, perform the following task as required. Note that if your file share still exists before restoration, there is <strong>NO</strong> need to do these tasks.</p>\n<p>Run the following commands on the bastion to recreate persistent volumes by replacing the old server information in the <code>/tmp/pv.yaml</code> file with the new one.</p>\n<pre>SMAX_NAMESPACE=$(kubectl get namespaces|grep itsma|head -n 1|awk '{print $1}') \nkubectl get pv  | grep -E \"core|$SMAX_NAMESPACE\"| awk '{print $1}' &gt; /tmp/pvList \nfor i in $(cat /tmp/pvList); do kubectl get pv $i -o yaml &gt;&gt; /tmp/pv.yaml; echo \"---\" &gt;&gt; /tmp/pv.yaml;done \nkubectl delete -f /tmp/pv.yaml \nkubectl get pv | grep -E \"core|$SMAX_NAMESPACE\" | awk '{print $1}' | xargs  kubectl patch pv  -p '{\"metadata\":{\"finalizers\":null}}' \nsed -i.bak 's/&lt;old-filestore-instance-IP&gt;/&lt;new-filestore-instance-IP&gt;/g' /tmp/pv.yaml \nkubectl create -f /tmp/pv.yaml \n</pre>\n</li>\n</ul>\n</li>\n<li>After the new file share is created and configured successfully, run this command on the bastion to restart the system:\n\t<pre>./cdfctl.sh runlevel set -l UP -n core,itsma-xxxxx</pre>\n</li>\n<li>Run this command on the bastion to verify the restoration:\n\t<pre>kubectl get pod --all-namespaces|grep -v 1/1|grep -v 2/2|grep -v 3/3|grep -v 4/4|grep -v Completed </pre>\n\tThis command returns a list of abnormal pods. If RabbitMQ isn't ready, see <a href=\"/doc/423/26.1/rabbitmqnotstart\" title=\"RabbitMQ isn't ready\">RabbitMQ isn't ready</a>. When it returns no result, all of the suite pods are ready and you can perform quick tests to make sure the restoration has been completed successfully.</li>\n<li>Remount the file share to your bastion. See the detailed steps <a href=\"https://cloud.google.com/filestore/docs/mounting-fileshares?authuser=1&amp;_ga=2.3903155.-2043935199.1615887959&amp;_gac=1.185871195.1622611334.CjwKCAjwtdeFBhBAEiwAKOIy59TvaE3ktrswcjjnnYmK2azc7DJsLhm4aIW1ahnuMbONfEQSSQUHIhoCpY4QAvD_BwE#mounting_a_file_share_on_a_vm_instance\" title=\"here\">here</a>.</li>\n</ol>\n<h2>Restore storage for OpenShift deployments</h2>\n<p>If the suite is running on OpenShift:</p>\n<ol>\n<li>Restore storage by following the instructions in your storage documentation.</li>\n<li>After the storage restore, run this command on the bastion to restart the system:\n\t<pre>./cdfctl.sh runlevel set -l UP -n core,itsma-xxxxx</pre>\n</li>\n<li>Run this command on the bastion to verify the restore:\n\t<pre>kubectl get pod --all-namespaces|grep -v 1/1|grep -v 2/2|grep -v 3/3|grep -v 4/4|grep -v Completed </pre>\n\tThis command returns a list of abnormal pods. If RabbitMQ isn't ready, see <a href=\"/doc/423/26.1/rabbitmqnotstart\" title=\"RabbitMQ isn't ready\">RabbitMQ isn't ready</a>. When it returns no result, all of the suite pods are ready and you can perform quick tests to make sure the restoration has been completed successfully.</li>\n</ol>\n<h2>Restore storage for Embedded Kubernetes</h2>\n<p>If SMA is deployed using the embedded Kubernetes in OMT, there are two methods to restore your NFS data:</p>\n<ul>\n<li>Use the original NFS server to restore the NFS data.</li>\n<li>Use a new NFS server to restore the NFS data</li>\n</ul>\n<h3>Use the original NFS server to restore the original data</h3>\n<p>Before you restore the NFS, stop the suite; otherwise, pods may fail.</p>\n<ol>\n<li>Run this command on the control plane node to stop the system:\n\t<pre>./cdfctl.sh runlevel set -l DOWN -n core,itsma-xxxxx</pre>\n</li>\n<li>Use any file copying tool to restore the data on the NFS server.</li>\n<li>After restoring the data on the NFS server, run this command on the control plane node to restart the system:\n\t<pre>./cdfctl.sh runlevel set -l UP -n core,itsma-xxxxx</pre>\n</li>\n<li>Run this command on the control plane node to verify the restoration:\n\t<pre>kubectl get pod --all-namespaces|grep -v 1/1|grep -v 2/2|grep -v 3/3|grep -v 4/4|grep -v Completed</pre>\n<p>This command returns a list of abnormal pods. If RabbitMQ isn't ready, see <a href=\"/doc/423/26.1/rabbitmqnotstart\" title=\"RabbitMQ isn't ready\">RabbitMQ isn't ready</a>. When it returns no result, all of the suite pods are ready and you can perform quick tests to make sure the restoration has been completed successfully.</p>\n</li>\n</ol>\n<h3>Use a new NFS server to restore the NFS data</h3>\n<p>Use the following steps to restore the NFS data to a new NFS server. You can use any file copying tool to restore the NFS data. </p>\n<ol>\n<li>Run this command on the control plane node to stop the system:\n\t<pre>./cdfctl.sh runlevel set -l DOWN -n core,itsma-xxxxx</pre>\n</li>\n<li>Use any file copying tool to move data from old NFS Server to the new NFS server. You may use rsync for this. Ensure that the directory paths, structure, and file and directory permissions are identical between the old and new NFS servers.</li>\n<li>Run the following commands on the control plane node to recreate persistent volumes by replacing the old server information in the <code>/tmp/pv.yaml</code> file with the new one:\n\t<pre>SMAX_NAMESPACE=$(kubectl get namespaces|grep itsma|head -n 1|awk '{print $1}')\nkubectl get pv | grep -E \"core|$SMAX_NAMESPACE\"| awk '{print $1}' &gt; /tmp/pvList\nfor i in $(cat /tmp/pvList); do kubectl get pv $i -o yaml &gt;&gt; /tmp/pv.yaml; echo \"---\" &gt;&gt; /tmp/pv.yaml;done\nkubectl get pv | grep -E \"core|$SMAX_NAMESPACE\" | awk '{print $1}' | xargs kubectl patch pv -p '{\"metadata\":{\"finalizers\":null}}'\nkubectl delete -f /tmp/pv.yaml\n\n# Recreate persistent volumes by replacing the old NFS server information in the pv.yaml file with information of the new NFS server\nsed -i.bak 's/&lt;old-nfs-dns-name&gt;/&lt;new-nfs-dns-name&gt;/g' /tmp/pv.yaml\nkubectl create -f /tmp/pv.yaml\n</pre>\n</li>\n<li>Run this command on the control plane node to restart the system:\n\t<pre> ./cdfctl.sh runlevel set -l UP -n core,itsma-xxxxx </pre>\n</li>\n<li>Run this command on the control plane node to verify the restoration:\n\t<pre> kubectl get pod --all-namespaces|grep -v 1/1|grep -v 2/2|grep -v 3/3|grep -v 4/4|grep -v Completed</pre>\n<p>This command returns a list of abnormal pods. If RabbitMQ isn't ready, see <a href=\"/doc/423/26.1/rabbitmqnotstart\" title=\"RabbitMQ isn't ready\">RabbitMQ isn't ready</a>. When it returns no result, all of the suite pods are ready and you can perform quick tests to make sure the restoration has been completed successfully.</p>\n</li>\n</ol>\n</div>",
  "modifiedon": "2025-10-24 08:51:12"
}