[
  {
    "title": "Release notes",
    "content": "This incremental release of Service Management introduces new features and enhancements, in addition to defect fixes. Aviator updates Model Upgrade: The Llama model has been replaced with Gemma to improve performance and accuracy.Language Detection: Issues in the previous language detection library have been resolved by implementing LLM based detection for better reliability. The model type appears as Gemma only when Service Management is set to 26.1.Logging: Tenant level logging is now enabled to improve monitoring and troubleshooting. Service Management updates Configure Azure internal load balancer for Service Management and UCMDB communication Enhance security and optimize performance with our new capability to configure an Azure Internal Load Balancer (ILB) for Helm-based deployments. This feature enables seamless internal communication between Service Management (SM) and containerized UD/UCMDB on Azure, while isolating integration traffic from external access. By maintaining a cl",
    "url": "releasenotes",
    "filename": "releasenotes",
    "headings": [
      "Aviator updates",
      "Service Management updates",
      "Configure Azure internal load balancer for Service Management and UCMDB communication",
      "Portal entity filters",
      "Number formatting option",
      "Platform updates",
      "RLAC: Support for users with more than 250 groups",
      "Use external data in user options",
      "Restrict/allow attachments",
      "Edit or delete system comments",
      "Integration Studio",
      "Mobile updates",
      "Automation Center",
      "Security and compliance content updates",
      "Cloud Management",
      "Support matrix updates",
      "Added support",
      "K8s support changes",
      "OO Containerized support changes",
      "Related topics"
    ],
    "keywords": [
      "4.17",
      "0.17",
      "17.62",
      "5.5.1",
      "25.2",
      "UI.Does",
      "17.0.17",
      "17.62.17",
      "3.5.6",
      "1.49",
      "26.1",
      "5.26",
      "4.20",
      "10.1.49",
      "4.19",
      "4.18",
      "2.0.0",
      "4.33",
      "1.32",
      "release",
      "notes",
      "aviator",
      "updates",
      "service",
      "management",
      "configure",
      "azure",
      "internal",
      "load",
      "balancer",
      "ucmdb",
      "communication",
      "portal",
      "entity",
      "filters",
      "number",
      "formatting",
      "option",
      "platform",
      "rlac",
      "support",
      "users",
      "250",
      "groups",
      "external",
      "data",
      "user",
      "options",
      "restrict",
      "allow",
      "attachments",
      "edit",
      "delete",
      "system",
      "comments",
      "integration",
      "studio",
      "mobile",
      "automation",
      "center",
      "security",
      "compliance",
      "content",
      "cloud",
      "matrix",
      "added",
      "k8s",
      "changes",
      "oo",
      "containerized",
      "related",
      "topics",
      "incremental",
      "introduces",
      "new",
      "features",
      "enhancements",
      "addition",
      "defect",
      "fixes.",
      "model",
      "upgrade",
      "llama",
      "replaced",
      "gemma",
      "improve",
      "performance",
      "accuracy.language",
      "detection",
      "issues",
      "previous",
      "language",
      "library",
      "resolved",
      "implementing",
      "llm",
      "based",
      "better",
      "reliability.",
      "type"
    ],
    "language": "en",
    "word_count": 100,
    "importance_score": 6.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "release notes",
    "contentLower": "this incremental release of service management introduces new features and enhancements, in addition to defect fixes. aviator updates model upgrade: the llama model has been replaced with gemma to improve performance and accuracy.language detection: issues in the previous language detection library have been resolved by implementing llm based detection for better reliability. the model type appears as gemma only when service management is set to 26.1.logging: tenant level logging is now enabled to improve monitoring and troubleshooting. service management updates configure azure internal load balancer for service management and ucmdb communication enhance security and optimize performance with our new capability to configure an azure internal load balancer (ilb) for helm-based deployments. this feature enables seamless internal communication between service management (sm) and containerized ud/ucmdb on azure, while isolating integration traffic from external access. by maintaining a cl",
    "keywordsLower": [
      "4.17",
      "0.17",
      "17.62",
      "5.5.1",
      "25.2",
      "ui.does",
      "17.0.17",
      "17.62.17",
      "3.5.6",
      "1.49",
      "26.1",
      "5.26",
      "4.20",
      "10.1.49",
      "4.19",
      "4.18",
      "2.0.0",
      "4.33",
      "1.32",
      "release",
      "notes",
      "aviator",
      "updates",
      "service",
      "management",
      "configure",
      "azure",
      "internal",
      "load",
      "balancer",
      "ucmdb",
      "communication",
      "portal",
      "entity",
      "filters",
      "number",
      "formatting",
      "option",
      "platform",
      "rlac",
      "support",
      "users",
      "250",
      "groups",
      "external",
      "data",
      "user",
      "options",
      "restrict",
      "allow",
      "attachments",
      "edit",
      "delete",
      "system",
      "comments",
      "integration",
      "studio",
      "mobile",
      "automation",
      "center",
      "security",
      "compliance",
      "content",
      "cloud",
      "matrix",
      "added",
      "k8s",
      "changes",
      "oo",
      "containerized",
      "related",
      "topics",
      "incremental",
      "introduces",
      "new",
      "features",
      "enhancements",
      "addition",
      "defect",
      "fixes.",
      "model",
      "upgrade",
      "llama",
      "replaced",
      "gemma",
      "improve",
      "performance",
      "accuracy.language",
      "detection",
      "issues",
      "previous",
      "language",
      "library",
      "resolved",
      "implementing",
      "llm",
      "based",
      "better",
      "reliability.",
      "type"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Service Management 26.1.1 patch release notes",
    "content": "Software release date: February 2026 See the SMA-SM patch release notes if you have enabled the SMA-SM Service Portal. This patch release includes updates to version 26.1 of Service Management, including Audit and Aviator, OO, and UCMDB. It also contains improvements and fixes related to security, and is recommended to minimize any potential security risks. What's new Fixed issues This patch release includes the following fixes. Service Management Version 26.1.1 Category Issue ID Description Service Management OCTCR19XW2722110 ESM API get offering returning wrong datatype Service Management OCTCR19XW2745149 PS - excessive warnings on package simulation Service Management OCTCR19XW2722410 Live Support - Comment can be lost if dialog opened too early Service Management OCTCR19XW2732603 Rule search in Studio does not work correctly for Japanese and English strings in combination with special characters Service Management OCTCR19XW2732797 During Dynamic field validation cursor hangs with s",
    "url": "2611",
    "filename": "2611",
    "headings": [
      "What's new",
      "Fixed issues",
      "Service Management Version 26.1.1",
      "Containerized UD/UCMDB Version 26.1.1",
      "Apply the patch",
      "Apply OMT 26.1.1 patch",
      "Apply Service Management 26.1.1 patch",
      "Apply Audit 26.1.1 patch",
      "Apply Containerized UCMDB 26.1.1 patch",
      "Apply OO Containerized 26.1.1 patch"
    ],
    "keywords": [
      "26.1",
      "26.1.1",
      "K8s.zip",
      "1.zip",
      "sign.pub",
      "25.3",
      "25.4",
      "24.1",
      "xxx-15001",
      "service",
      "management",
      "patch",
      "release",
      "notes",
      "what",
      "new",
      "fixed",
      "issues",
      "version",
      "containerized",
      "ud",
      "ucmdb",
      "apply",
      "omt",
      "audit",
      "oo",
      "software",
      "date",
      "february",
      "2026",
      "see",
      "sma-sm",
      "enabled",
      "portal.",
      "includes",
      "updates",
      "including",
      "aviator",
      "ucmdb.",
      "contains",
      "improvements",
      "fixes",
      "related",
      "security",
      "recommended",
      "minimize",
      "any",
      "potential",
      "risks.",
      "following",
      "fixes.",
      "category",
      "issue",
      "id",
      "description",
      "octcr19xw2722110",
      "esm",
      "api",
      "get",
      "offering",
      "returning",
      "wrong",
      "datatype",
      "octcr19xw2745149",
      "ps",
      "excessive",
      "warnings",
      "package",
      "simulation",
      "octcr19xw2722410",
      "live",
      "support",
      "comment",
      "lost",
      "dialog",
      "opened",
      "too",
      "early",
      "octcr19xw2732603",
      "rule",
      "search",
      "studio",
      "work",
      "correctly",
      "japanese",
      "english",
      "strings",
      "combination",
      "special",
      "characters",
      "octcr19xw2732797",
      "during",
      "dynamic",
      "field",
      "validation",
      "cursor",
      "hangs",
      "spinning",
      "icon",
      "octcr19xw2733758"
    ],
    "language": "en",
    "word_count": 115,
    "importance_score": 5.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "service management 26.1.1 patch release notes",
    "contentLower": "software release date: february 2026 see the sma-sm patch release notes if you have enabled the sma-sm service portal. this patch release includes updates to version 26.1 of service management, including audit and aviator, oo, and ucmdb. it also contains improvements and fixes related to security, and is recommended to minimize any potential security risks. what's new fixed issues this patch release includes the following fixes. service management version 26.1.1 category issue id description service management octcr19xw2722110 esm api get offering returning wrong datatype service management octcr19xw2745149 ps - excessive warnings on package simulation service management octcr19xw2722410 live support - comment can be lost if dialog opened too early service management octcr19xw2732603 rule search in studio does not work correctly for japanese and english strings in combination with special characters service management octcr19xw2732797 during dynamic field validation cursor hangs with s",
    "keywordsLower": [
      "26.1",
      "26.1.1",
      "k8s.zip",
      "1.zip",
      "sign.pub",
      "25.3",
      "25.4",
      "24.1",
      "xxx-15001",
      "service",
      "management",
      "patch",
      "release",
      "notes",
      "what",
      "new",
      "fixed",
      "issues",
      "version",
      "containerized",
      "ud",
      "ucmdb",
      "apply",
      "omt",
      "audit",
      "oo",
      "software",
      "date",
      "february",
      "2026",
      "see",
      "sma-sm",
      "enabled",
      "portal.",
      "includes",
      "updates",
      "including",
      "aviator",
      "ucmdb.",
      "contains",
      "improvements",
      "fixes",
      "related",
      "security",
      "recommended",
      "minimize",
      "any",
      "potential",
      "risks.",
      "following",
      "fixes.",
      "category",
      "issue",
      "id",
      "description",
      "octcr19xw2722110",
      "esm",
      "api",
      "get",
      "offering",
      "returning",
      "wrong",
      "datatype",
      "octcr19xw2745149",
      "ps",
      "excessive",
      "warnings",
      "package",
      "simulation",
      "octcr19xw2722410",
      "live",
      "support",
      "comment",
      "lost",
      "dialog",
      "opened",
      "too",
      "early",
      "octcr19xw2732603",
      "rule",
      "search",
      "studio",
      "work",
      "correctly",
      "japanese",
      "english",
      "strings",
      "combination",
      "special",
      "characters",
      "octcr19xw2732797",
      "during",
      "dynamic",
      "field",
      "validation",
      "cursor",
      "hangs",
      "spinning",
      "icon",
      "octcr19xw2733758"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Release log",
    "content": "The Service Management release log is a cumulative list of features introduced in each release. This log helps you with a quick review of all the new features that were added for each release version.25.4Aviator updatesAviator Agents Administrators can create Aviator Agents and define a task plan (with serial or parallel tasks) that the agent will perform when called. An Aviator Agent Record enables the execution of all standard manual and automatic tasks, including calls to Aviator and Orchestration flows, as well as Integration Studio. Administrators can use the Standard Studio Business rule process to initiate a call to an Aviator Agent and create an Aviator Agent Session record.The Agent Session record includes the full audit history of all the actions taken by the Aviator Agent. Service Management updatesCustomer Service ManagementService and Support requests and Live Support have been extended to work with Products and Entitlements. This feature enables a Service and Support requ",
    "url": "releaselogsmax",
    "filename": "releaselogsmax",
    "headings": [
      "25.4",
      "Aviator updates",
      "Aviator Agents",
      "Service Management updates",
      "Customer Service Management",
      "Studio updates",
      "Platform updates",
      "Native SACM",
      "Integration Studio",
      "Mobile updates",
      "Asset Management",
      "Automation Center",
      "Operations Orchestration Containerized",
      "Cloud Management",
      "Support matrix updates",
      "Added support",
      "K8s support changes",
      "OO Containerized support changes",
      "25.3",
      "Dev2Prod support for Models"
    ],
    "keywords": [
      "Connectors.New",
      "added.New",
      "product.New",
      "4.14",
      "option.The",
      "Studio.You",
      "Portal.You",
      "2018.02",
      "list.When",
      "bubble.The",
      "order.You",
      "needed.For",
      "text.The",
      "3.11",
      "2020.02.001",
      "details.In",
      "1.0",
      "17.60",
      "enhancements.UI",
      "data.For",
      "Upgrade.HCM",
      "1.44",
      "offerings.The",
      "settings.UI",
      "disk.See",
      "2022.05",
      "not.You",
      "3.12.11",
      "namespace.If",
      "clean_images.sh",
      "7.8",
      "agent.You",
      "AKS.OO",
      "screen.One",
      "2019.05",
      "app.Edit",
      "tenants.For",
      "setting.The",
      "contacts.Note",
      "12.0",
      "Storage.The",
      "dashboards.Note",
      "manually.The",
      "entities.SAM",
      "1.24",
      "record.CSM",
      "package.2017",
      "deployments.The",
      "time.Note",
      "enhancements.ITOM",
      "examples.Two",
      "CIs.The",
      "UCMDB.For",
      "8.0OEL",
      "future.In",
      "collection.See",
      "support.FIPS",
      "policy.2019",
      "page.See",
      "tasks.You",
      "4.16",
      "3.12.1025",
      "Contract.For",
      "improvements.User",
      "replaceExternalAccessHost.sh",
      "products.You",
      "9.5",
      "modeling.Note",
      "Teams.See",
      "History.New",
      "synchronized.AMX",
      "1.18",
      "support.Show",
      "7.4",
      "support.The",
      "experience.The",
      "reports.IaC",
      "details.When",
      "1.28",
      "version.Use",
      "pages.You",
      "25.3",
      "cluster.The",
      "required.See",
      "cdfctl.sh",
      "2019.02",
      "etc.This",
      "handling.PDF",
      "values.The",
      "optimization.The",
      "vCenter.OOTB",
      "1.27",
      "tools.2020",
      "1.31",
      "software.In",
      "24.1.0",
      "Aviator.New",
      "card.The",
      "Rightsizing.Cost",
      "rules.The"
    ],
    "language": "en",
    "word_count": 99,
    "importance_score": 6.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "release log",
    "contentLower": "the service management release log is a cumulative list of features introduced in each release. this log helps you with a quick review of all the new features that were added for each release version.25.4aviator updatesaviator agents administrators can create aviator agents and define a task plan (with serial or parallel tasks) that the agent will perform when called. an aviator agent record enables the execution of all standard manual and automatic tasks, including calls to aviator and orchestration flows, as well as integration studio. administrators can use the standard studio business rule process to initiate a call to an aviator agent and create an aviator agent session record.the agent session record includes the full audit history of all the actions taken by the aviator agent. service management updatescustomer service managementservice and support requests and live support have been extended to work with products and entitlements. this feature enables a service and support requ",
    "keywordsLower": [
      "connectors.new",
      "added.new",
      "product.new",
      "4.14",
      "option.the",
      "studio.you",
      "portal.you",
      "2018.02",
      "list.when",
      "bubble.the",
      "order.you",
      "needed.for",
      "text.the",
      "3.11",
      "2020.02.001",
      "details.in",
      "1.0",
      "17.60",
      "enhancements.ui",
      "data.for",
      "upgrade.hcm",
      "1.44",
      "offerings.the",
      "settings.ui",
      "disk.see",
      "2022.05",
      "not.you",
      "3.12.11",
      "namespace.if",
      "clean_images.sh",
      "7.8",
      "agent.you",
      "aks.oo",
      "screen.one",
      "2019.05",
      "app.edit",
      "tenants.for",
      "setting.the",
      "contacts.note",
      "12.0",
      "storage.the",
      "dashboards.note",
      "manually.the",
      "entities.sam",
      "1.24",
      "record.csm",
      "package.2017",
      "deployments.the",
      "time.note",
      "enhancements.itom",
      "examples.two",
      "cis.the",
      "ucmdb.for",
      "8.0oel",
      "future.in",
      "collection.see",
      "support.fips",
      "policy.2019",
      "page.see",
      "tasks.you",
      "4.16",
      "3.12.1025",
      "contract.for",
      "improvements.user",
      "replaceexternalaccesshost.sh",
      "products.you",
      "9.5",
      "modeling.note",
      "teams.see",
      "history.new",
      "synchronized.amx",
      "1.18",
      "support.show",
      "7.4",
      "support.the",
      "experience.the",
      "reports.iac",
      "details.when",
      "1.28",
      "version.use",
      "pages.you",
      "25.3",
      "cluster.the",
      "required.see",
      "cdfctl.sh",
      "2019.02",
      "etc.this",
      "handling.pdf",
      "values.the",
      "optimization.the",
      "vcenter.ootb",
      "1.27",
      "tools.2020",
      "1.31",
      "software.in",
      "24.1.0",
      "aviator.new",
      "card.the",
      "rightsizing.cost",
      "rules.the"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Suite user roles",
    "content": "This solution has the following roles: Suite administrator Has full access to the Suite Administration interface and IdM Admin Portal. The default user name is suite-admin whose initial password is specified during the suite installation. The suite-admin user can add additional suite administrators in the Suite Administration interface. Tenant administrator Has full administration control over the assigned tenant. For information about a list of management tasks that are performed by the tenant administrator, see Service Management Administration. Agent Has access to the agent interface, as well as the Service Portal interface. Agents can be assigned different roles with permissions that enable them to complete their daily work. For example, the Catalog Administrator role manages the Service Catalog. For more information about roles, see Roles. Service Portal user Has access to the Service Portal interface only.",
    "url": "personas",
    "filename": "personas",
    "headings": [],
    "keywords": [
      "suite",
      "user",
      "roles",
      "solution",
      "following",
      "administrator",
      "full",
      "access",
      "administration",
      "interface",
      "idm",
      "admin",
      "portal.",
      "default",
      "name",
      "suite-admin",
      "whose",
      "initial",
      "password",
      "specified",
      "during",
      "installation.",
      "add",
      "additional",
      "administrators",
      "interface.",
      "tenant",
      "control",
      "over",
      "assigned",
      "tenant.",
      "information",
      "about",
      "list",
      "management",
      "tasks",
      "performed",
      "see",
      "service",
      "administration.",
      "agent",
      "well",
      "portal",
      "agents",
      "different",
      "permissions",
      "enable",
      "complete",
      "daily",
      "work.",
      "example",
      "catalog",
      "role",
      "manages",
      "catalog.",
      "roles.",
      "only."
    ],
    "language": "en",
    "word_count": 93,
    "importance_score": 3.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "suite user roles",
    "contentLower": "this solution has the following roles: suite administrator has full access to the suite administration interface and idm admin portal. the default user name is suite-admin whose initial password is specified during the suite installation. the suite-admin user can add additional suite administrators in the suite administration interface. tenant administrator has full administration control over the assigned tenant. for information about a list of management tasks that are performed by the tenant administrator, see service management administration. agent has access to the agent interface, as well as the service portal interface. agents can be assigned different roles with permissions that enable them to complete their daily work. for example, the catalog administrator role manages the service catalog. for more information about roles, see roles. service portal user has access to the service portal interface only.",
    "keywordsLower": [
      "suite",
      "user",
      "roles",
      "solution",
      "following",
      "administrator",
      "full",
      "access",
      "administration",
      "interface",
      "idm",
      "admin",
      "portal.",
      "default",
      "name",
      "suite-admin",
      "whose",
      "initial",
      "password",
      "specified",
      "during",
      "installation.",
      "add",
      "additional",
      "administrators",
      "interface.",
      "tenant",
      "control",
      "over",
      "assigned",
      "tenant.",
      "information",
      "about",
      "list",
      "management",
      "tasks",
      "performed",
      "see",
      "service",
      "administration.",
      "agent",
      "well",
      "portal",
      "agents",
      "different",
      "permissions",
      "enable",
      "complete",
      "daily",
      "work.",
      "example",
      "catalog",
      "role",
      "manages",
      "catalog.",
      "roles.",
      "only."
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Suite enterprise readiness",
    "content": "This page provides a brief overview of the enterprise readiness of the suite. Deployment mode You can deploy the suite on-premises, in the cloud, or on OpenShift. High availability (HA) The suite can achieve high availability through failure recovery, failover, and load balancing. Failure recovery Failure recovery follows the restart policy of Kubernetes. The policy is specified as Always, all pods should be restarted automatically after a failure occurs. As designed in Kubernetes, failed containers are restarted by kubelet with an exponential back-off delay (10s, 20s, 40s, and so on) capped at five minutes, and are reset after ten minutes of successful execution. Failover The suite will fail over a resource to protect against a failed service. For example, when the pod hosting the resource becomes inactive, or the resources within the pod fail. During a failover process, the service will switch from the failed pod/resource to another redundant one. A pod is the smallest deployable obj",
    "url": "smaenterprisereadiness",
    "filename": "smaenterprisereadiness",
    "headings": [
      "Deployment mode",
      "High availability (HA)",
      "Failure recovery",
      "Failover",
      "Load balancing",
      "Scalability",
      "Backup and restore",
      "Update",
      "Sizing",
      "Security",
      "Observability",
      "Openl10n support",
      "Appendix",
      "Supportability",
      "Pod failure recovery time report"
    ],
    "keywords": [
      "1.8",
      "1.5",
      "7.7",
      "12.35",
      "2.5",
      "1.9",
      "7.65",
      "2.1",
      "3.1",
      "2.23",
      "2.2",
      "1.1",
      "0.9",
      "2.8",
      "1.2",
      "0.5",
      "1.4",
      "0.8",
      "0.1",
      "5.56",
      "3.2",
      "3.28",
      "12.16",
      "6.5",
      "0.2",
      "9.2",
      "1.0",
      "2.9",
      "3.4",
      "0.3",
      "9.7",
      "1.3",
      "8.4",
      "0.6",
      "3.8",
      "suite",
      "enterprise",
      "readiness",
      "deployment",
      "mode",
      "high",
      "availability",
      "ha",
      "failure",
      "recovery",
      "failover",
      "load",
      "balancing",
      "scalability",
      "backup",
      "restore",
      "update",
      "sizing",
      "security",
      "observability",
      "openl10n",
      "support",
      "appendix",
      "supportability",
      "pod",
      "time",
      "report",
      "page",
      "provides",
      "brief",
      "overview",
      "suite.",
      "deploy",
      "on-premises",
      "cloud",
      "openshift.",
      "achieve",
      "through",
      "balancing.",
      "follows",
      "restart",
      "policy",
      "kubernetes.",
      "specified",
      "always",
      "all",
      "pods",
      "restarted",
      "automatically",
      "after",
      "occurs.",
      "designed",
      "kubernetes",
      "failed",
      "containers",
      "kubelet",
      "exponential",
      "back-off",
      "delay",
      "10s",
      "20s",
      "40s",
      "capped",
      "five",
      "minutes"
    ],
    "language": "en",
    "word_count": 102,
    "importance_score": 6.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "suite enterprise readiness",
    "contentLower": "this page provides a brief overview of the enterprise readiness of the suite. deployment mode you can deploy the suite on-premises, in the cloud, or on openshift. high availability (ha) the suite can achieve high availability through failure recovery, failover, and load balancing. failure recovery failure recovery follows the restart policy of kubernetes. the policy is specified as always, all pods should be restarted automatically after a failure occurs. as designed in kubernetes, failed containers are restarted by kubelet with an exponential back-off delay (10s, 20s, 40s, and so on) capped at five minutes, and are reset after ten minutes of successful execution. failover the suite will fail over a resource to protect against a failed service. for example, when the pod hosting the resource becomes inactive, or the resources within the pod fail. during a failover process, the service will switch from the failed pod/resource to another redundant one. a pod is the smallest deployable obj",
    "keywordsLower": [
      "1.8",
      "1.5",
      "7.7",
      "12.35",
      "2.5",
      "1.9",
      "7.65",
      "2.1",
      "3.1",
      "2.23",
      "2.2",
      "1.1",
      "0.9",
      "2.8",
      "1.2",
      "0.5",
      "1.4",
      "0.8",
      "0.1",
      "5.56",
      "3.2",
      "3.28",
      "12.16",
      "6.5",
      "0.2",
      "9.2",
      "1.0",
      "2.9",
      "3.4",
      "0.3",
      "9.7",
      "1.3",
      "8.4",
      "0.6",
      "3.8",
      "suite",
      "enterprise",
      "readiness",
      "deployment",
      "mode",
      "high",
      "availability",
      "ha",
      "failure",
      "recovery",
      "failover",
      "load",
      "balancing",
      "scalability",
      "backup",
      "restore",
      "update",
      "sizing",
      "security",
      "observability",
      "openl10n",
      "support",
      "appendix",
      "supportability",
      "pod",
      "time",
      "report",
      "page",
      "provides",
      "brief",
      "overview",
      "suite.",
      "deploy",
      "on-premises",
      "cloud",
      "openshift.",
      "achieve",
      "through",
      "balancing.",
      "follows",
      "restart",
      "policy",
      "kubernetes.",
      "specified",
      "always",
      "all",
      "pods",
      "restarted",
      "automatically",
      "after",
      "occurs.",
      "designed",
      "kubernetes",
      "failed",
      "containers",
      "kubelet",
      "exponential",
      "back-off",
      "delay",
      "10s",
      "20s",
      "40s",
      "capped",
      "five",
      "minutes"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Service dependency",
    "content": "This section describes the services and their dependencies for both OPTIC Management Toolkit (OMT) and Service Management. OMT servicesSuite common servicesSmart Analytics servicesVirtual Agent servicesSuite servicesSuite Administration services System architecture diagram The following is a high-level architecture diagram of the suite. OMT services For details, see the OMT documentation. Suite common services Service Description Dependency idm The Identity Manager (IdM) service, which manages user identities and user security-related information. kubernetes-vault, PostgreSQL database autopass-lm-v2 A service for license management. kubernetes-vault, PostgreSQL database itom-ingress-controller A service that, as the entry point for external requests to SMA, routes HTTP and HTTPS traffic from external sources to internal Kubernetes services. It uses the Nginx web server as a reverse proxy and load balancer to distribute traffic to the appropriate Kubernetes pods. None itom-itsma-certifi",
    "url": "servicedependency",
    "filename": "servicedependency",
    "headings": [
      "System architecture diagram",
      "OMT services",
      "Suite common services",
      "Smart Analytics services",
      "Virtual Agent services",
      "Suite services",
      "Suite Administration services",
      "Cloud Management services"
    ],
    "keywords": [
      "service",
      "dependency",
      "system",
      "architecture",
      "diagram",
      "omt",
      "services",
      "suite",
      "common",
      "smart",
      "analytics",
      "virtual",
      "agent",
      "administration",
      "cloud",
      "management",
      "section",
      "describes",
      "dependencies",
      "both",
      "optic",
      "toolkit",
      "management.",
      "servicessuite",
      "servicessmart",
      "servicesvirtual",
      "following",
      "high-level",
      "suite.",
      "details",
      "see",
      "documentation.",
      "description",
      "idm",
      "identity",
      "manager",
      "manages",
      "user",
      "identities",
      "security-related",
      "information.",
      "kubernetes-vault",
      "postgresql",
      "database",
      "autopass-lm-v2",
      "license",
      "itom-ingress-controller",
      "entry",
      "point",
      "external",
      "requests",
      "sma",
      "routes",
      "http",
      "https",
      "traffic",
      "sources",
      "internal",
      "kubernetes",
      "services.",
      "uses",
      "nginx",
      "web",
      "server",
      "reverse",
      "proxy",
      "load",
      "balancer",
      "distribute",
      "appropriate",
      "pods.",
      "none",
      "itom-itsma-certificate-deployment",
      "certificate",
      "outbound",
      "integration.",
      "smarta-admin-ui-backend",
      "config",
      "ui",
      "analytics.",
      "smarta-data-source",
      "fetching",
      "data",
      "postgres",
      "ticket.",
      "smarta-installer",
      "installs",
      "all",
      "components.",
      "smarta-ocr",
      "retrieves",
      "text",
      "images",
      "smarta-saw-con",
      "stores",
      "indexed",
      "records",
      "latest",
      "months",
      "search."
    ],
    "language": "en",
    "word_count": 96,
    "importance_score": 6.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "service dependency",
    "contentLower": "this section describes the services and their dependencies for both optic management toolkit (omt) and service management. omt servicessuite common servicessmart analytics servicesvirtual agent servicessuite servicessuite administration services system architecture diagram the following is a high-level architecture diagram of the suite. omt services for details, see the omt documentation. suite common services service description dependency idm the identity manager (idm) service, which manages user identities and user security-related information. kubernetes-vault, postgresql database autopass-lm-v2 a service for license management. kubernetes-vault, postgresql database itom-ingress-controller a service that, as the entry point for external requests to sma, routes http and https traffic from external sources to internal kubernetes services. it uses the nginx web server as a reverse proxy and load balancer to distribute traffic to the appropriate kubernetes pods. none itom-itsma-certifi",
    "keywordsLower": [
      "service",
      "dependency",
      "system",
      "architecture",
      "diagram",
      "omt",
      "services",
      "suite",
      "common",
      "smart",
      "analytics",
      "virtual",
      "agent",
      "administration",
      "cloud",
      "management",
      "section",
      "describes",
      "dependencies",
      "both",
      "optic",
      "toolkit",
      "management.",
      "servicessuite",
      "servicessmart",
      "servicesvirtual",
      "following",
      "high-level",
      "suite.",
      "details",
      "see",
      "documentation.",
      "description",
      "idm",
      "identity",
      "manager",
      "manages",
      "user",
      "identities",
      "security-related",
      "information.",
      "kubernetes-vault",
      "postgresql",
      "database",
      "autopass-lm-v2",
      "license",
      "itom-ingress-controller",
      "entry",
      "point",
      "external",
      "requests",
      "sma",
      "routes",
      "http",
      "https",
      "traffic",
      "sources",
      "internal",
      "kubernetes",
      "services.",
      "uses",
      "nginx",
      "web",
      "server",
      "reverse",
      "proxy",
      "load",
      "balancer",
      "distribute",
      "appropriate",
      "pods.",
      "none",
      "itom-itsma-certificate-deployment",
      "certificate",
      "outbound",
      "integration.",
      "smarta-admin-ui-backend",
      "config",
      "ui",
      "analytics.",
      "smarta-data-source",
      "fetching",
      "data",
      "postgres",
      "ticket.",
      "smarta-installer",
      "installs",
      "all",
      "components.",
      "smarta-ocr",
      "retrieves",
      "text",
      "images",
      "smarta-saw-con",
      "stores",
      "indexed",
      "records",
      "latest",
      "months",
      "search."
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Search behaviors",
    "content": "Service Management implements different search policies and strategies in different locations within its various search UI areas. Global search in Service Portal/Service Management/Live Support This table compares the different search behaviors in Service Portal, Service Management (Agent interface), and Live Support. Service Portal Service Management (Agent interface) Live Support Number of searchable record types 10, including: Article News QNA ServiceOffering SupportOffering HumanResourceOffering ServiceRequest SupportRequest HRRequest Idea 43, including: AccountingPeriod ActualService Article AssetModel Brand Budget BudgetCenter BudgetLine Change Contract CostCenter CostType DashboardDefinition Device RemoteArticle PersonGroup HRRequest Idea Incident InfrastructurePeripheral KnownError License Location News SupportOffering ServiceOffering HumanResourceOffering Optimization Person Portfolio Problem Program Project ProjectPortfolio Proposal Release SupportRequest ServiceRequest Servi",
    "url": "searchbehaviors",
    "filename": "searchbehaviors",
    "headings": [
      "Global search in Service Portal/Service Management/Live Support",
      "Global search in Service Portal",
      "Global search in Service Management",
      "Search in Live Support",
      "Indexed fields",
      "Why search results don't match the search keyword",
      "Related topics"
    ],
    "keywords": [
      "action.log",
      "search",
      "behaviors",
      "global",
      "service",
      "portal",
      "management",
      "live",
      "support",
      "indexed",
      "fields",
      "results",
      "don",
      "match",
      "keyword",
      "related",
      "topics",
      "implements",
      "different",
      "policies",
      "strategies",
      "locations",
      "various",
      "ui",
      "areas.",
      "table",
      "compares",
      "agent",
      "interface",
      "support.",
      "number",
      "searchable",
      "record",
      "types",
      "10",
      "including",
      "article",
      "news",
      "qna",
      "serviceoffering",
      "supportoffering",
      "humanresourceoffering",
      "servicerequest",
      "supportrequest",
      "hrrequest",
      "idea",
      "43",
      "accountingperiod",
      "actualservice",
      "assetmodel",
      "brand",
      "budget",
      "budgetcenter",
      "budgetline",
      "change",
      "contract",
      "costcenter",
      "costtype",
      "dashboarddefinition",
      "device",
      "remotearticle",
      "persongroup",
      "incident",
      "infrastructureperipheral",
      "knownerror",
      "license",
      "location",
      "optimization",
      "person",
      "portfolio",
      "problem",
      "program",
      "project",
      "projectportfolio",
      "proposal",
      "release",
      "servicecomponent",
      "servicedefinition",
      "systemelement",
      "company",
      "minimum",
      "result",
      "relevance",
      "threshold",
      "based",
      "value",
      "specified",
      "smart",
      "analytics",
      "settings",
      "default",
      "30",
      "maximum",
      "returned",
      "50",
      "return",
      "requested",
      "user",
      "searching",
      "restricted"
    ],
    "language": "en",
    "word_count": 101,
    "importance_score": 6.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "search behaviors",
    "contentLower": "service management implements different search policies and strategies in different locations within its various search ui areas. global search in service portal/service management/live support this table compares the different search behaviors in service portal, service management (agent interface), and live support. service portal service management (agent interface) live support number of searchable record types 10, including: article news qna serviceoffering supportoffering humanresourceoffering servicerequest supportrequest hrrequest idea 43, including: accountingperiod actualservice article assetmodel brand budget budgetcenter budgetline change contract costcenter costtype dashboarddefinition device remotearticle persongroup hrrequest idea incident infrastructureperipheral knownerror license location news supportoffering serviceoffering humanresourceoffering optimization person portfolio problem program project projectportfolio proposal release supportrequest servicerequest servi",
    "keywordsLower": [
      "action.log",
      "search",
      "behaviors",
      "global",
      "service",
      "portal",
      "management",
      "live",
      "support",
      "indexed",
      "fields",
      "results",
      "don",
      "match",
      "keyword",
      "related",
      "topics",
      "implements",
      "different",
      "policies",
      "strategies",
      "locations",
      "various",
      "ui",
      "areas.",
      "table",
      "compares",
      "agent",
      "interface",
      "support.",
      "number",
      "searchable",
      "record",
      "types",
      "10",
      "including",
      "article",
      "news",
      "qna",
      "serviceoffering",
      "supportoffering",
      "humanresourceoffering",
      "servicerequest",
      "supportrequest",
      "hrrequest",
      "idea",
      "43",
      "accountingperiod",
      "actualservice",
      "assetmodel",
      "brand",
      "budget",
      "budgetcenter",
      "budgetline",
      "change",
      "contract",
      "costcenter",
      "costtype",
      "dashboarddefinition",
      "device",
      "remotearticle",
      "persongroup",
      "incident",
      "infrastructureperipheral",
      "knownerror",
      "license",
      "location",
      "optimization",
      "person",
      "portfolio",
      "problem",
      "program",
      "project",
      "projectportfolio",
      "proposal",
      "release",
      "servicecomponent",
      "servicedefinition",
      "systemelement",
      "company",
      "minimum",
      "result",
      "relevance",
      "threshold",
      "based",
      "value",
      "specified",
      "smart",
      "analytics",
      "settings",
      "default",
      "30",
      "maximum",
      "returned",
      "50",
      "return",
      "requested",
      "user",
      "searching",
      "restricted"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Service Management",
    "content": "Service Management is a comprehensive helpdesk solution that manages support and service requests, incidents, change requests, and problems. Service Management includes these modules that adhere to ITIL v3 best practice recommendations: Plan Service Portfolio Management to define and manage service definitions Service Catalog Management to categorize and manage services and offerings Time Period Management to define and manage maintenance windows, blackout periods, work schedules, holidays, and events, for use in Change and Service Level Management Service Level Management to define and track review and resolution metrics for Incident and Service Request Management Vendor Management and Contract Management to organize internal and external vendors, and contracts with these vendors Idea and Proposal Management to collect and track service-related ideas and proposals, and align proposals with business objectives Application Portfolio Management to assess and prioritize the current applic",
    "url": "servicemgmtoverview",
    "filename": "servicemgmtoverview",
    "headings": [
      "Plan",
      "Build",
      "Run",
      "Related topics"
    ],
    "keywords": [
      "service",
      "management",
      "plan",
      "build",
      "run",
      "related",
      "topics",
      "comprehensive",
      "helpdesk",
      "solution",
      "manages",
      "support",
      "requests",
      "incidents",
      "change",
      "problems.",
      "includes",
      "modules",
      "adhere",
      "itil",
      "v3",
      "best",
      "practice",
      "recommendations",
      "portfolio",
      "define",
      "manage",
      "definitions",
      "catalog",
      "categorize",
      "services",
      "offerings",
      "time",
      "period",
      "maintenance",
      "windows",
      "blackout",
      "periods",
      "work",
      "schedules",
      "holidays",
      "events",
      "level",
      "track",
      "review",
      "resolution",
      "metrics",
      "incident",
      "request",
      "vendor",
      "contract",
      "organize",
      "internal",
      "external",
      "vendors",
      "contracts",
      "idea",
      "proposal",
      "collect",
      "service-related",
      "ideas",
      "proposals",
      "align",
      "business",
      "objectives",
      "application",
      "assess",
      "prioritize",
      "current",
      "determine",
      "applications",
      "need",
      "modernized",
      "project",
      "program",
      "projects",
      "programs",
      "portfolios",
      "embedded",
      "normal",
      "standard",
      "emergency",
      "workflows",
      "task",
      "models",
      "release",
      "workflow",
      "knowledge",
      "reuse",
      "resources",
      "such",
      "articles",
      "solutions",
      "user",
      "input",
      "historical",
      "asset",
      "configuration",
      "integrated",
      "on-premises"
    ],
    "language": "en",
    "word_count": 98,
    "importance_score": 5.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "service management",
    "contentLower": "service management is a comprehensive helpdesk solution that manages support and service requests, incidents, change requests, and problems. service management includes these modules that adhere to itil v3 best practice recommendations: plan service portfolio management to define and manage service definitions service catalog management to categorize and manage services and offerings time period management to define and manage maintenance windows, blackout periods, work schedules, holidays, and events, for use in change and service level management service level management to define and track review and resolution metrics for incident and service request management vendor management and contract management to organize internal and external vendors, and contracts with these vendors idea and proposal management to collect and track service-related ideas and proposals, and align proposals with business objectives application portfolio management to assess and prioritize the current applic",
    "keywordsLower": [
      "service",
      "management",
      "plan",
      "build",
      "run",
      "related",
      "topics",
      "comprehensive",
      "helpdesk",
      "solution",
      "manages",
      "support",
      "requests",
      "incidents",
      "change",
      "problems.",
      "includes",
      "modules",
      "adhere",
      "itil",
      "v3",
      "best",
      "practice",
      "recommendations",
      "portfolio",
      "define",
      "manage",
      "definitions",
      "catalog",
      "categorize",
      "services",
      "offerings",
      "time",
      "period",
      "maintenance",
      "windows",
      "blackout",
      "periods",
      "work",
      "schedules",
      "holidays",
      "events",
      "level",
      "track",
      "review",
      "resolution",
      "metrics",
      "incident",
      "request",
      "vendor",
      "contract",
      "organize",
      "internal",
      "external",
      "vendors",
      "contracts",
      "idea",
      "proposal",
      "collect",
      "service-related",
      "ideas",
      "proposals",
      "align",
      "business",
      "objectives",
      "application",
      "assess",
      "prioritize",
      "current",
      "determine",
      "applications",
      "need",
      "modernized",
      "project",
      "program",
      "projects",
      "programs",
      "portfolios",
      "embedded",
      "normal",
      "standard",
      "emergency",
      "workflows",
      "task",
      "models",
      "release",
      "workflow",
      "knowledge",
      "reuse",
      "resources",
      "such",
      "articles",
      "solutions",
      "user",
      "input",
      "historical",
      "asset",
      "configuration",
      "integrated",
      "on-premises"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "SACM Overview",
    "content": "In this section, Glenn will define the services that his IT department provides as part of the service portfolio, and the high level components that make up those services in the Service Asset and Configuration Management (SACM) module. SACM maintains information about the configuration items (and their relationships) required to deliver an IT service. Providing the service definitions he will support is also the first step in defining the service portfolio within Service Management. These definitions will continue to fill in the overall Service Management data model. By the end of this section Glenn will: Work with IT to create a list of all business services provided to the consumers/clients Create the service definitions within the service portfolio Define each instance as an actual service in Service Asset and Configuration Management (SACM) module Define the service components and system elements for the actual services in SACM Providing Services One of the first differences I not",
    "url": "sacmoverview",
    "filename": "sacmoverview",
    "headings": [
      "Providing Services"
    ],
    "keywords": [
      "started.Hey",
      "sacm",
      "overview",
      "providing",
      "services",
      "section",
      "glenn",
      "define",
      "department",
      "provides",
      "part",
      "service",
      "portfolio",
      "high",
      "level",
      "components",
      "make",
      "asset",
      "configuration",
      "management",
      "module.",
      "maintains",
      "information",
      "about",
      "items",
      "relationships",
      "required",
      "deliver",
      "service.",
      "definitions",
      "support",
      "first",
      "step",
      "defining",
      "management.",
      "continue",
      "fill",
      "overall",
      "data",
      "model.",
      "end",
      "work",
      "create",
      "list",
      "all",
      "business",
      "provided",
      "consumers",
      "clients",
      "instance",
      "actual",
      "module",
      "system",
      "elements",
      "one",
      "differences",
      "noticed",
      "compared",
      "options",
      "out",
      "there",
      "designed",
      "around",
      "services.",
      "users",
      "makes",
      "sense",
      "focus",
      "solution",
      "them.",
      "things",
      "need",
      "customers.",
      "start",
      "here",
      "well",
      "specifically",
      "calling",
      "see",
      "ton",
      "problems.",
      "get",
      "calls",
      "emails",
      "control",
      "over.",
      "requests",
      "relating",
      "products",
      "simply",
      "do.",
      "limits",
      "responsibilities",
      "refines",
      "team",
      "providers.",
      "clearly",
      "specifying",
      "what",
      "provide"
    ],
    "language": "en",
    "word_count": 91,
    "importance_score": 3.5,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "sacm overview",
    "contentLower": "in this section, glenn will define the services that his it department provides as part of the service portfolio, and the high level components that make up those services in the service asset and configuration management (sacm) module. sacm maintains information about the configuration items (and their relationships) required to deliver an it service. providing the service definitions he will support is also the first step in defining the service portfolio within service management. these definitions will continue to fill in the overall service management data model. by the end of this section glenn will: work with it to create a list of all business services provided to the consumers/clients create the service definitions within the service portfolio define each instance as an actual service in service asset and configuration management (sacm) module define the service components and system elements for the actual services in sacm providing services one of the first differences i not",
    "keywordsLower": [
      "started.hey",
      "sacm",
      "overview",
      "providing",
      "services",
      "section",
      "glenn",
      "define",
      "department",
      "provides",
      "part",
      "service",
      "portfolio",
      "high",
      "level",
      "components",
      "make",
      "asset",
      "configuration",
      "management",
      "module.",
      "maintains",
      "information",
      "about",
      "items",
      "relationships",
      "required",
      "deliver",
      "service.",
      "definitions",
      "support",
      "first",
      "step",
      "defining",
      "management.",
      "continue",
      "fill",
      "overall",
      "data",
      "model.",
      "end",
      "work",
      "create",
      "list",
      "all",
      "business",
      "provided",
      "consumers",
      "clients",
      "instance",
      "actual",
      "module",
      "system",
      "elements",
      "one",
      "differences",
      "noticed",
      "compared",
      "options",
      "out",
      "there",
      "designed",
      "around",
      "services.",
      "users",
      "makes",
      "sense",
      "focus",
      "solution",
      "them.",
      "things",
      "need",
      "customers.",
      "start",
      "here",
      "well",
      "specifically",
      "calling",
      "see",
      "ton",
      "problems.",
      "get",
      "calls",
      "emails",
      "control",
      "over.",
      "requests",
      "relating",
      "products",
      "simply",
      "do.",
      "limits",
      "responsibilities",
      "refines",
      "team",
      "providers.",
      "clearly",
      "specifying",
      "what",
      "provide"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Service Catalog",
    "content": "To consume the services IT provides, the end users need to have a way of discovering the services available and what actions or requests they can perform against them. The service catalog provides the means of creating those available choices for both the Service Portal (accessed by the end users) and request management (accessed by the agents). Creating a complete service catalog can be one of the more time-consuming parts of creating the complete Service Management implementation, but also can create the most value. A well-crafted service catalog will reduce the manual effort needed by the Service Desk Agents by allowing the End Users to create a well-formed request that we can automatically route to the correct groups—or even fulfill by an automated process that never needs an agent’s intervention. By the end of this section Glenn will: Understand what makes up the service catalog and how they are displayed to the end user in the Service Portal Learn where the system defines the spe",
    "url": "servicecatalog",
    "filename": "servicecatalog",
    "headings": [
      "The Catalog Structure",
      "Service Category",
      "Service Definition",
      "Offering",
      "Localization",
      "Shopping Cart",
      "Public, Private and Confidential Requests",
      "Public Requests",
      "Private Requests",
      "Confidential Requests",
      "Subscriptions",
      "Tailoring the Service Portal"
    ],
    "keywords": [
      "peripheral.This",
      "service",
      "catalog",
      "structure",
      "category",
      "definition",
      "offering",
      "localization",
      "shopping",
      "cart",
      "public",
      "private",
      "confidential",
      "requests",
      "subscriptions",
      "tailoring",
      "portal",
      "consume",
      "services",
      "provides",
      "end",
      "users",
      "need",
      "way",
      "discovering",
      "available",
      "what",
      "actions",
      "perform",
      "against",
      "them.",
      "means",
      "creating",
      "choices",
      "both",
      "accessed",
      "request",
      "management",
      "agents",
      "complete",
      "one",
      "time-consuming",
      "parts",
      "implementation",
      "create",
      "most",
      "value.",
      "well-crafted",
      "reduce",
      "manual",
      "effort",
      "needed",
      "desk",
      "allowing",
      "well-formed",
      "automatically",
      "route",
      "correct",
      "groups",
      "even",
      "fulfill",
      "automated",
      "process",
      "never",
      "needs",
      "agent",
      "intervention.",
      "section",
      "glenn",
      "understand",
      "makes",
      "displayed",
      "user",
      "learn",
      "system",
      "defines",
      "specific",
      "offerings",
      "ask",
      "via",
      "see",
      "task",
      "plans",
      "guide",
      "through",
      "find",
      "out",
      "reusable",
      "fulfillment",
      "created",
      "duplicate",
      "work",
      "similar",
      "limit",
      "entitlement",
      "rules",
      "tailor",
      "look",
      "feel",
      "well"
    ],
    "language": "en",
    "word_count": 96,
    "importance_score": 6.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "service catalog",
    "contentLower": "to consume the services it provides, the end users need to have a way of discovering the services available and what actions or requests they can perform against them. the service catalog provides the means of creating those available choices for both the service portal (accessed by the end users) and request management (accessed by the agents). creating a complete service catalog can be one of the more time-consuming parts of creating the complete service management implementation, but also can create the most value. a well-crafted service catalog will reduce the manual effort needed by the service desk agents by allowing the end users to create a well-formed request that we can automatically route to the correct groups—or even fulfill by an automated process that never needs an agent’s intervention. by the end of this section glenn will: understand what makes up the service catalog and how they are displayed to the end user in the service portal learn where the system defines the spe",
    "keywordsLower": [
      "peripheral.this",
      "service",
      "catalog",
      "structure",
      "category",
      "definition",
      "offering",
      "localization",
      "shopping",
      "cart",
      "public",
      "private",
      "confidential",
      "requests",
      "subscriptions",
      "tailoring",
      "portal",
      "consume",
      "services",
      "provides",
      "end",
      "users",
      "need",
      "way",
      "discovering",
      "available",
      "what",
      "actions",
      "perform",
      "against",
      "them.",
      "means",
      "creating",
      "choices",
      "both",
      "accessed",
      "request",
      "management",
      "agents",
      "complete",
      "one",
      "time-consuming",
      "parts",
      "implementation",
      "create",
      "most",
      "value.",
      "well-crafted",
      "reduce",
      "manual",
      "effort",
      "needed",
      "desk",
      "allowing",
      "well-formed",
      "automatically",
      "route",
      "correct",
      "groups",
      "even",
      "fulfill",
      "automated",
      "process",
      "never",
      "needs",
      "agent",
      "intervention.",
      "section",
      "glenn",
      "understand",
      "makes",
      "displayed",
      "user",
      "learn",
      "system",
      "defines",
      "specific",
      "offerings",
      "ask",
      "via",
      "see",
      "task",
      "plans",
      "guide",
      "through",
      "find",
      "out",
      "reusable",
      "fulfillment",
      "created",
      "duplicate",
      "work",
      "similar",
      "limit",
      "entitlement",
      "rules",
      "tailor",
      "look",
      "feel",
      "well"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Request Management",
    "content": "Request Management Request management handles the end to end process of receiving a request from an end user and fulfilling it. A properly prepared request management process reduces the load on agents by allowing end users to fulfill their own requests without agent involvement either by automating common request offerings (such as password resets) or providing knowledge that will allow the end user to answer a question by themselves. In order to direct the implementation towards this end, the service desk managers must take the time to investigate the requests that don't fit an existing offering or can't be resolved using the existing knowledge base. With this information, new pre-defined offerings (with specified task plans) may be created and new knowledge articles may be added to the system to improve the experience for the next request of the same type. The ability to assist end users with their requests may also be measured in targeted surveys. These surveys can gather feedback ",
    "url": "requestmanagement",
    "filename": "requestmanagement",
    "headings": [
      "Setting up Service Request",
      "Setting up our Record Categories",
      "Creating Views and Reports for the Dashboard",
      "Live Support",
      "Importing Existing Knowledge",
      "Surveys"
    ],
    "keywords": [
      "request",
      "management",
      "setting",
      "service",
      "record",
      "categories",
      "creating",
      "views",
      "reports",
      "dashboard",
      "live",
      "support",
      "importing",
      "existing",
      "knowledge",
      "surveys",
      "handles",
      "end",
      "process",
      "receiving",
      "user",
      "fulfilling",
      "it.",
      "properly",
      "prepared",
      "reduces",
      "load",
      "agents",
      "allowing",
      "users",
      "fulfill",
      "own",
      "requests",
      "agent",
      "involvement",
      "either",
      "automating",
      "common",
      "offerings",
      "such",
      "password",
      "resets",
      "providing",
      "allow",
      "answer",
      "question",
      "themselves.",
      "order",
      "direct",
      "implementation",
      "towards",
      "desk",
      "managers",
      "take",
      "time",
      "investigate",
      "don",
      "fit",
      "offering",
      "resolved",
      "base.",
      "information",
      "new",
      "pre-defined",
      "specified",
      "task",
      "plans",
      "created",
      "articles",
      "added",
      "system",
      "improve",
      "experience",
      "next",
      "same",
      "type.",
      "ability",
      "assist",
      "measured",
      "targeted",
      "surveys.",
      "gather",
      "feedback",
      "areas",
      "ranging",
      "performance",
      "overall",
      "satisfaction",
      "particular",
      "service.",
      "section",
      "glenn",
      "learn",
      "setup",
      "create",
      "help",
      "find",
      "show",
      "feature",
      "helps"
    ],
    "language": "en",
    "word_count": 100,
    "importance_score": 6.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "request management",
    "contentLower": "request management request management handles the end to end process of receiving a request from an end user and fulfilling it. a properly prepared request management process reduces the load on agents by allowing end users to fulfill their own requests without agent involvement either by automating common request offerings (such as password resets) or providing knowledge that will allow the end user to answer a question by themselves. in order to direct the implementation towards this end, the service desk managers must take the time to investigate the requests that don't fit an existing offering or can't be resolved using the existing knowledge base. with this information, new pre-defined offerings (with specified task plans) may be created and new knowledge articles may be added to the system to improve the experience for the next request of the same type. the ability to assist end users with their requests may also be measured in targeted surveys. these surveys can gather feedback ",
    "keywordsLower": [
      "request",
      "management",
      "setting",
      "service",
      "record",
      "categories",
      "creating",
      "views",
      "reports",
      "dashboard",
      "live",
      "support",
      "importing",
      "existing",
      "knowledge",
      "surveys",
      "handles",
      "end",
      "process",
      "receiving",
      "user",
      "fulfilling",
      "it.",
      "properly",
      "prepared",
      "reduces",
      "load",
      "agents",
      "allowing",
      "users",
      "fulfill",
      "own",
      "requests",
      "agent",
      "involvement",
      "either",
      "automating",
      "common",
      "offerings",
      "such",
      "password",
      "resets",
      "providing",
      "allow",
      "answer",
      "question",
      "themselves.",
      "order",
      "direct",
      "implementation",
      "towards",
      "desk",
      "managers",
      "take",
      "time",
      "investigate",
      "don",
      "fit",
      "offering",
      "resolved",
      "base.",
      "information",
      "new",
      "pre-defined",
      "specified",
      "task",
      "plans",
      "created",
      "articles",
      "added",
      "system",
      "improve",
      "experience",
      "next",
      "same",
      "type.",
      "ability",
      "assist",
      "measured",
      "targeted",
      "surveys.",
      "gather",
      "feedback",
      "areas",
      "ranging",
      "performance",
      "overall",
      "satisfaction",
      "particular",
      "service.",
      "section",
      "glenn",
      "learn",
      "setup",
      "create",
      "help",
      "find",
      "show",
      "feature",
      "helps"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Request Flows",
    "content": "At this point, we have created a functional request management process and have a good start on the complete data model we defined earlier. While we still have a good bit of definition to do, we now have a fairly robust system capable of serving our service request needs. To expand on what we have built, we will now inspect the actual processes the system uses to fulfill a user request. Request Management Workflows Now that we have set up our request management process components, I thought it would be a good idea to take a step back and see how the process flows from beginning to end. We know the basics of what a request is, right? Someone who consumes one of our services is either: requesting something we have pre-defined in our service catalog requesting something we don’t have defined, but still related to one of our services requesting help with an issue that's causing them to not be able to consume the service requesting a service we aren't providing at this time requesting somet",
    "url": "requestflows",
    "filename": "requestflows",
    "headings": [
      "Request Management Workflows",
      "Service Workflow",
      "Classification",
      "Approval",
      "Fulfillment",
      "Validation",
      "Support Workflow",
      "Classification",
      "Approval",
      "Fulfillment",
      "Validation",
      "HR Support Workflow",
      "Classification",
      "Fulfillment",
      "Validation",
      "Cart Workflow",
      "Classification",
      "Approval",
      "Service Level Targets"
    ],
    "keywords": [
      "request",
      "flows",
      "management",
      "workflows",
      "service",
      "workflow",
      "classification",
      "approval",
      "fulfillment",
      "validation",
      "support",
      "hr",
      "cart",
      "level",
      "targets",
      "point",
      "created",
      "functional",
      "process",
      "good",
      "start",
      "complete",
      "data",
      "model",
      "defined",
      "earlier.",
      "while",
      "still",
      "bit",
      "definition",
      "now",
      "fairly",
      "robust",
      "system",
      "capable",
      "serving",
      "needs.",
      "expand",
      "what",
      "built",
      "inspect",
      "actual",
      "processes",
      "uses",
      "fulfill",
      "user",
      "request.",
      "set",
      "components",
      "thought",
      "idea",
      "take",
      "step",
      "back",
      "see",
      "beginning",
      "end.",
      "know",
      "basics",
      "right",
      "someone",
      "consumes",
      "one",
      "services",
      "either",
      "requesting",
      "something",
      "pre-defined",
      "catalog",
      "don",
      "related",
      "help",
      "issue",
      "causing",
      "able",
      "consume",
      "aren",
      "providing",
      "time",
      "multiple",
      "items",
      "same",
      "few",
      "different",
      "requests",
      "handle",
      "possibilities.",
      "certain",
      "run.",
      "three",
      "primary",
      "let",
      "names",
      "confuse",
      "all",
      "deal",
      "just",
      "short",
      "first",
      "handles"
    ],
    "language": "en",
    "word_count": 101,
    "importance_score": 6.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "request flows",
    "contentLower": "at this point, we have created a functional request management process and have a good start on the complete data model we defined earlier. while we still have a good bit of definition to do, we now have a fairly robust system capable of serving our service request needs. to expand on what we have built, we will now inspect the actual processes the system uses to fulfill a user request. request management workflows now that we have set up our request management process components, i thought it would be a good idea to take a step back and see how the process flows from beginning to end. we know the basics of what a request is, right? someone who consumes one of our services is either: requesting something we have pre-defined in our service catalog requesting something we don’t have defined, but still related to one of our services requesting help with an issue that's causing them to not be able to consume the service requesting a service we aren't providing at this time requesting somet",
    "keywordsLower": [
      "request",
      "flows",
      "management",
      "workflows",
      "service",
      "workflow",
      "classification",
      "approval",
      "fulfillment",
      "validation",
      "support",
      "hr",
      "cart",
      "level",
      "targets",
      "point",
      "created",
      "functional",
      "process",
      "good",
      "start",
      "complete",
      "data",
      "model",
      "defined",
      "earlier.",
      "while",
      "still",
      "bit",
      "definition",
      "now",
      "fairly",
      "robust",
      "system",
      "capable",
      "serving",
      "needs.",
      "expand",
      "what",
      "built",
      "inspect",
      "actual",
      "processes",
      "uses",
      "fulfill",
      "user",
      "request.",
      "set",
      "components",
      "thought",
      "idea",
      "take",
      "step",
      "back",
      "see",
      "beginning",
      "end.",
      "know",
      "basics",
      "right",
      "someone",
      "consumes",
      "one",
      "services",
      "either",
      "requesting",
      "something",
      "pre-defined",
      "catalog",
      "don",
      "related",
      "help",
      "issue",
      "causing",
      "able",
      "consume",
      "aren",
      "providing",
      "time",
      "multiple",
      "items",
      "same",
      "few",
      "different",
      "requests",
      "handle",
      "possibilities.",
      "certain",
      "run.",
      "three",
      "primary",
      "let",
      "names",
      "confuse",
      "all",
      "deal",
      "just",
      "short",
      "first",
      "handles"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Service Level Management",
    "content": "In this chapter, Glenn will look at the service level management area of Service Management. Service level management (SLM) allows you to measure the quality of service delivery by defining service level agreements with your customers to deliver their required services within pre-defined objectives. Service Management allows the organization to measure both customer focused and internal focused objectives. The service level targets created in these agreements are reflected in the requests, incidents, changes, tasks, problems, and custom records created in the system, allowing agents to better prioritize their workload by tackling the issues that will breach a target first. Service level data may be collected and reported upon to allow you to change existing service level targets with your customers or highlight trouble areas where you may need more resources or need to make changes in the current process. Service Levels There are tools to take requests, incidents, changes, tasks, probl",
    "url": "servicelevelmanagement",
    "filename": "servicelevelmanagement",
    "headings": [
      "Service Levels",
      "Agreements",
      "Service Agreements",
      "Support and Case Agreements",
      "Time Periods",
      "Service Agreements in Action",
      "Example #1: Incident",
      "Example #2: Service Request",
      "Prioritizing Work using Service Targets",
      "Reporting on Service Targets",
      "Timing and Caching"
    ],
    "keywords": [
      "service",
      "level",
      "management",
      "levels",
      "agreements",
      "support",
      "case",
      "time",
      "periods",
      "action",
      "example",
      "incident",
      "request",
      "prioritizing",
      "work",
      "targets",
      "reporting",
      "timing",
      "caching",
      "chapter",
      "glenn",
      "look",
      "area",
      "management.",
      "slm",
      "allows",
      "measure",
      "quality",
      "delivery",
      "defining",
      "customers",
      "deliver",
      "required",
      "services",
      "pre-defined",
      "objectives.",
      "organization",
      "both",
      "customer",
      "focused",
      "internal",
      "created",
      "reflected",
      "requests",
      "incidents",
      "changes",
      "tasks",
      "problems",
      "custom",
      "records",
      "system",
      "allowing",
      "agents",
      "better",
      "prioritize",
      "workload",
      "tackling",
      "issues",
      "breach",
      "target",
      "first.",
      "data",
      "collected",
      "reported",
      "upon",
      "allow",
      "change",
      "existing",
      "highlight",
      "trouble",
      "areas",
      "need",
      "resources",
      "make",
      "current",
      "process.",
      "there",
      "tools",
      "take",
      "records.",
      "what",
      "don",
      "yet",
      "way",
      "let",
      "know",
      "ones",
      "similarly",
      "quantify",
      "end",
      "users.",
      "one",
      "believe",
      "just",
      "say",
      "re",
      "doing",
      "good",
      "job",
      "measuring"
    ],
    "language": "en",
    "word_count": 100,
    "importance_score": 6.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "service level management",
    "contentLower": "in this chapter, glenn will look at the service level management area of service management. service level management (slm) allows you to measure the quality of service delivery by defining service level agreements with your customers to deliver their required services within pre-defined objectives. service management allows the organization to measure both customer focused and internal focused objectives. the service level targets created in these agreements are reflected in the requests, incidents, changes, tasks, problems, and custom records created in the system, allowing agents to better prioritize their workload by tackling the issues that will breach a target first. service level data may be collected and reported upon to allow you to change existing service level targets with your customers or highlight trouble areas where you may need more resources or need to make changes in the current process. service levels there are tools to take requests, incidents, changes, tasks, probl",
    "keywordsLower": [
      "service",
      "level",
      "management",
      "levels",
      "agreements",
      "support",
      "case",
      "time",
      "periods",
      "action",
      "example",
      "incident",
      "request",
      "prioritizing",
      "work",
      "targets",
      "reporting",
      "timing",
      "caching",
      "chapter",
      "glenn",
      "look",
      "area",
      "management.",
      "slm",
      "allows",
      "measure",
      "quality",
      "delivery",
      "defining",
      "customers",
      "deliver",
      "required",
      "services",
      "pre-defined",
      "objectives.",
      "organization",
      "both",
      "customer",
      "focused",
      "internal",
      "created",
      "reflected",
      "requests",
      "incidents",
      "changes",
      "tasks",
      "problems",
      "custom",
      "records",
      "system",
      "allowing",
      "agents",
      "better",
      "prioritize",
      "workload",
      "tackling",
      "issues",
      "breach",
      "target",
      "first.",
      "data",
      "collected",
      "reported",
      "upon",
      "allow",
      "change",
      "existing",
      "highlight",
      "trouble",
      "areas",
      "need",
      "resources",
      "make",
      "current",
      "process.",
      "there",
      "tools",
      "take",
      "records.",
      "what",
      "don",
      "yet",
      "way",
      "let",
      "know",
      "ones",
      "similarly",
      "quantify",
      "end",
      "users.",
      "one",
      "believe",
      "just",
      "say",
      "re",
      "doing",
      "good",
      "job",
      "measuring"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Surveys",
    "content": "The survey management module enables Service Management to send surveys to end users and consume the data collected by these surveys. In this topic, we will follow Glenn as he investigates how to create and schedule a survey and investigate the results. Surveys may be connected to any other record type in the system, such as incidents, changes, or requests, or can be stand-alone. These surveys allow the IT department to gather input from the consumers on how they are performing, how they can improve, what new services they could offer, or any other questions they might have. Once an end user completes a survey, Service Management gives Glenn the ability to analyze both the structured and unstructured data that was gathered. This allows him to see problem areas and create plans to improve them. Surveys At this point, Service Management is allowing us to do some pretty important things. We are tracking the services we provide to our consumers, taking requests from our end users, and reso",
    "url": "surveys",
    "filename": "surveys",
    "headings": [
      "Surveys",
      "Creating a survey",
      "Adding questions",
      "Setting up reports",
      "Survey workflow",
      "Creation",
      "Publication",
      "Consumption",
      "Retirement",
      "Sending out a survey",
      "Sending a survey manually",
      "Sending a survey automatically",
      "Analyzing the survey results",
      "Reports",
      "Hot Topics"
    ],
    "keywords": [
      "surveys",
      "creating",
      "survey",
      "adding",
      "questions",
      "setting",
      "reports",
      "workflow",
      "creation",
      "publication",
      "consumption",
      "retirement",
      "sending",
      "out",
      "manually",
      "automatically",
      "analyzing",
      "results",
      "hot",
      "topics",
      "management",
      "module",
      "enables",
      "service",
      "send",
      "end",
      "users",
      "consume",
      "data",
      "collected",
      "surveys.",
      "topic",
      "follow",
      "glenn",
      "investigates",
      "create",
      "schedule",
      "investigate",
      "results.",
      "connected",
      "any",
      "record",
      "type",
      "system",
      "such",
      "incidents",
      "changes",
      "requests",
      "stand-alone.",
      "allow",
      "department",
      "gather",
      "input",
      "consumers",
      "performing",
      "improve",
      "what",
      "new",
      "services",
      "offer",
      "have.",
      "once",
      "user",
      "completes",
      "gives",
      "ability",
      "analyze",
      "both",
      "structured",
      "unstructured",
      "gathered.",
      "allows",
      "see",
      "problem",
      "areas",
      "plans",
      "them.",
      "point",
      "allowing",
      "pretty",
      "important",
      "things.",
      "tracking",
      "provide",
      "taking",
      "resolving",
      "affect",
      "services.",
      "doing",
      "least",
      "eyes",
      "well",
      "don",
      "ask",
      "users.",
      "provides",
      "all",
      "tools",
      "need",
      "get"
    ],
    "language": "en",
    "word_count": 91,
    "importance_score": 6.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "surveys",
    "contentLower": "the survey management module enables service management to send surveys to end users and consume the data collected by these surveys. in this topic, we will follow glenn as he investigates how to create and schedule a survey and investigate the results. surveys may be connected to any other record type in the system, such as incidents, changes, or requests, or can be stand-alone. these surveys allow the it department to gather input from the consumers on how they are performing, how they can improve, what new services they could offer, or any other questions they might have. once an end user completes a survey, service management gives glenn the ability to analyze both the structured and unstructured data that was gathered. this allows him to see problem areas and create plans to improve them. surveys at this point, service management is allowing us to do some pretty important things. we are tracking the services we provide to our consumers, taking requests from our end users, and reso",
    "keywordsLower": [
      "surveys",
      "creating",
      "survey",
      "adding",
      "questions",
      "setting",
      "reports",
      "workflow",
      "creation",
      "publication",
      "consumption",
      "retirement",
      "sending",
      "out",
      "manually",
      "automatically",
      "analyzing",
      "results",
      "hot",
      "topics",
      "management",
      "module",
      "enables",
      "service",
      "send",
      "end",
      "users",
      "consume",
      "data",
      "collected",
      "surveys.",
      "topic",
      "follow",
      "glenn",
      "investigates",
      "create",
      "schedule",
      "investigate",
      "results.",
      "connected",
      "any",
      "record",
      "type",
      "system",
      "such",
      "incidents",
      "changes",
      "requests",
      "stand-alone.",
      "allow",
      "department",
      "gather",
      "input",
      "consumers",
      "performing",
      "improve",
      "what",
      "new",
      "services",
      "offer",
      "have.",
      "once",
      "user",
      "completes",
      "gives",
      "ability",
      "analyze",
      "both",
      "structured",
      "unstructured",
      "gathered.",
      "allows",
      "see",
      "problem",
      "areas",
      "plans",
      "them.",
      "point",
      "allowing",
      "pretty",
      "important",
      "things.",
      "tracking",
      "provide",
      "taking",
      "resolving",
      "affect",
      "services.",
      "doing",
      "least",
      "eyes",
      "well",
      "don",
      "ask",
      "users.",
      "provides",
      "all",
      "tools",
      "need",
      "get"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "SACM Details",
    "content": "The primary focus of Service Asset and Configuration Management is to maintain information about all the configuration items required to deliver an IT service. This includes specific information about each configuration item and the relationships between multiple CIs. There are multiple sub-processes within the overall SACM process, each with their own objectives: • Configuration Identification - define and maintain the underlying structure of the UD/UCMDB via the configuration model so it may contain all the information regarding configuration items. This includes specifying the attributes that describe all CI types and their components and defining their relationships to other CIs and CI types. • Configuration Control - ensure that no changes are made to configuration items (including adding new CIs) without the proper authorization and procedures and ensure that all changes made are properly recorded in the UD/UCMDB. • Configuration Verification and Audit - perform regular checks to",
    "url": "sacmdetails",
    "filename": "sacmdetails",
    "headings": [
      "Using Service Asset and Configuration Management",
      "Configuration Identification",
      "Actual Services",
      "Service Components",
      "System Elements",
      "Devices",
      "Using Discovery for Configuration Control, Verification, and Audit",
      "Universal Discovery",
      "UCMDB",
      "Setting up SACM"
    ],
    "keywords": [
      "sacm",
      "details",
      "service",
      "asset",
      "configuration",
      "management",
      "identification",
      "actual",
      "services",
      "components",
      "system",
      "elements",
      "devices",
      "discovery",
      "control",
      "verification",
      "audit",
      "universal",
      "ucmdb",
      "setting",
      "primary",
      "focus",
      "maintain",
      "information",
      "about",
      "all",
      "items",
      "required",
      "deliver",
      "service.",
      "includes",
      "specific",
      "item",
      "relationships",
      "between",
      "multiple",
      "cis.",
      "there",
      "sub-processes",
      "overall",
      "process",
      "own",
      "objectives",
      "define",
      "underlying",
      "structure",
      "ud",
      "via",
      "model",
      "contain",
      "regarding",
      "items.",
      "specifying",
      "attributes",
      "describe",
      "ci",
      "types",
      "defining",
      "cis",
      "types.",
      "ensure",
      "changes",
      "made",
      "including",
      "adding",
      "new",
      "proper",
      "authorization",
      "procedures",
      "properly",
      "recorded",
      "ucmdb.",
      "perform",
      "regular",
      "checks",
      "accurately",
      "represents",
      "installed",
      "production",
      "environment.",
      "provides",
      "starting",
      "system.",
      "alternatively",
      "external",
      "database",
      "integrate",
      "provide",
      "copy",
      "processes.",
      "vital",
      "many",
      "areas",
      "limited",
      "identifying",
      "impact",
      "requested",
      "providing",
      "diagnostic",
      "desk"
    ],
    "language": "en",
    "word_count": 93,
    "importance_score": 6.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "sacm details",
    "contentLower": "the primary focus of service asset and configuration management is to maintain information about all the configuration items required to deliver an it service. this includes specific information about each configuration item and the relationships between multiple cis. there are multiple sub-processes within the overall sacm process, each with their own objectives: • configuration identification - define and maintain the underlying structure of the ud/ucmdb via the configuration model so it may contain all the information regarding configuration items. this includes specifying the attributes that describe all ci types and their components and defining their relationships to other cis and ci types. • configuration control - ensure that no changes are made to configuration items (including adding new cis) without the proper authorization and procedures and ensure that all changes made are properly recorded in the ud/ucmdb. • configuration verification and audit - perform regular checks to",
    "keywordsLower": [
      "sacm",
      "details",
      "service",
      "asset",
      "configuration",
      "management",
      "identification",
      "actual",
      "services",
      "components",
      "system",
      "elements",
      "devices",
      "discovery",
      "control",
      "verification",
      "audit",
      "universal",
      "ucmdb",
      "setting",
      "primary",
      "focus",
      "maintain",
      "information",
      "about",
      "all",
      "items",
      "required",
      "deliver",
      "service.",
      "includes",
      "specific",
      "item",
      "relationships",
      "between",
      "multiple",
      "cis.",
      "there",
      "sub-processes",
      "overall",
      "process",
      "own",
      "objectives",
      "define",
      "underlying",
      "structure",
      "ud",
      "via",
      "model",
      "contain",
      "regarding",
      "items.",
      "specifying",
      "attributes",
      "describe",
      "ci",
      "types",
      "defining",
      "cis",
      "types.",
      "ensure",
      "changes",
      "made",
      "including",
      "adding",
      "new",
      "proper",
      "authorization",
      "procedures",
      "properly",
      "recorded",
      "ucmdb.",
      "perform",
      "regular",
      "checks",
      "accurately",
      "represents",
      "installed",
      "production",
      "environment.",
      "provides",
      "starting",
      "system.",
      "alternatively",
      "external",
      "database",
      "integrate",
      "provide",
      "copy",
      "processes.",
      "vital",
      "many",
      "areas",
      "limited",
      "identifying",
      "impact",
      "requested",
      "providing",
      "diagnostic",
      "desk"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Service Design",
    "content": "Designs are the recipes for automating the cloud and include reusable service components. Service components and their relationships in a design define the framework for creating the service. Create, configure, and change service designs to give on-demand, automated service delivery. Designs also offer a structure for options that consumers can select when ordering service. You can re-use designs for multiple service offerings, with each service offering customized to meet the needs of different consumer organizations and groups. For information on how to add or edit a service design, and to learn more about design-related options, see Service Designer.",
    "url": "getstartedservicedesign",
    "filename": "getstartedservicedesign",
    "headings": [],
    "keywords": [
      "service",
      "design",
      "designs",
      "recipes",
      "automating",
      "cloud",
      "include",
      "reusable",
      "components.",
      "components",
      "relationships",
      "define",
      "framework",
      "creating",
      "service.",
      "create",
      "configure",
      "change",
      "give",
      "on-demand",
      "automated",
      "delivery.",
      "offer",
      "structure",
      "options",
      "consumers",
      "select",
      "ordering",
      "re-use",
      "multiple",
      "offerings",
      "offering",
      "customized",
      "meet",
      "needs",
      "different",
      "consumer",
      "organizations",
      "groups.",
      "information",
      "add",
      "edit",
      "learn",
      "about",
      "design-related",
      "see",
      "designer."
    ],
    "language": "en",
    "word_count": 62,
    "importance_score": 2.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "service design",
    "contentLower": "designs are the recipes for automating the cloud and include reusable service components. service components and their relationships in a design define the framework for creating the service. create, configure, and change service designs to give on-demand, automated service delivery. designs also offer a structure for options that consumers can select when ordering service. you can re-use designs for multiple service offerings, with each service offering customized to meet the needs of different consumer organizations and groups. for information on how to add or edit a service design, and to learn more about design-related options, see service designer.",
    "keywordsLower": [
      "service",
      "design",
      "designs",
      "recipes",
      "automating",
      "cloud",
      "include",
      "reusable",
      "components.",
      "components",
      "relationships",
      "define",
      "framework",
      "creating",
      "service.",
      "create",
      "configure",
      "change",
      "give",
      "on-demand",
      "automated",
      "delivery.",
      "offer",
      "structure",
      "options",
      "consumers",
      "select",
      "ordering",
      "re-use",
      "multiple",
      "offerings",
      "offering",
      "customized",
      "meet",
      "needs",
      "different",
      "consumer",
      "organizations",
      "groups.",
      "information",
      "add",
      "edit",
      "learn",
      "about",
      "design-related",
      "see",
      "designer."
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Service offerings",
    "content": "Service offerings provide the information consumers need to select the most appropriate services. Each service offering references a service design, which defines the service options and components of the service. You can tailor service offerings for each consumer group with details such as customized terms and conditions, option visibility, and pricing. Create a service offering from a sequenced or topology service design. When you are ready to expose the design to subscribers, publish the service offering in a catalog in the Service Portal. You can create an offering from a sequenced or topology design. Pricing is configured on a service offering and supports initial, recurring, and option-specific pricing. You can choose to show or hide the initial or recurring price details to a subscriber or an approver in the Service Portal. You can also attach documents to a standard service offering (such as service level agreements, terms, and conditions) and screenshots, which are images and ",
    "url": "getstartedserviceoffering",
    "filename": "getstartedserviceoffering",
    "headings": [
      "Customize service offerings",
      "Catalogs"
    ],
    "keywords": [
      "service",
      "offerings",
      "customize",
      "catalogs",
      "provide",
      "information",
      "consumers",
      "need",
      "select",
      "most",
      "appropriate",
      "services.",
      "offering",
      "references",
      "design",
      "defines",
      "options",
      "components",
      "service.",
      "tailor",
      "consumer",
      "group",
      "details",
      "such",
      "customized",
      "terms",
      "conditions",
      "option",
      "visibility",
      "pricing.",
      "create",
      "sequenced",
      "topology",
      "design.",
      "ready",
      "expose",
      "subscribers",
      "publish",
      "catalog",
      "portal.",
      "pricing",
      "configured",
      "supports",
      "initial",
      "recurring",
      "option-specific",
      "choose",
      "show",
      "hide",
      "price",
      "subscriber",
      "approver",
      "attach",
      "documents",
      "standard",
      "level",
      "agreements",
      "screenshots",
      "images",
      "captions",
      "user",
      "visual",
      "representation",
      "different",
      "target",
      "groups.",
      "base",
      "same",
      "attributes",
      "group.",
      "visible",
      "configure",
      "following",
      "name",
      "description",
      "image",
      "tags",
      "based",
      "designs",
      "subscription",
      "attached",
      "associated",
      "multiple",
      "versions",
      "per",
      "link",
      "publishing",
      "cloud",
      "management",
      "uses",
      "constrain",
      "displayed",
      "user.",
      "portal",
      "displays",
      "published",
      "one",
      "hidden",
      "offering.",
      "map"
    ],
    "language": "en",
    "word_count": 90,
    "importance_score": 4.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "service offerings",
    "contentLower": "service offerings provide the information consumers need to select the most appropriate services. each service offering references a service design, which defines the service options and components of the service. you can tailor service offerings for each consumer group with details such as customized terms and conditions, option visibility, and pricing. create a service offering from a sequenced or topology service design. when you are ready to expose the design to subscribers, publish the service offering in a catalog in the service portal. you can create an offering from a sequenced or topology design. pricing is configured on a service offering and supports initial, recurring, and option-specific pricing. you can choose to show or hide the initial or recurring price details to a subscriber or an approver in the service portal. you can also attach documents to a standard service offering (such as service level agreements, terms, and conditions) and screenshots, which are images and ",
    "keywordsLower": [
      "service",
      "offerings",
      "customize",
      "catalogs",
      "provide",
      "information",
      "consumers",
      "need",
      "select",
      "most",
      "appropriate",
      "services.",
      "offering",
      "references",
      "design",
      "defines",
      "options",
      "components",
      "service.",
      "tailor",
      "consumer",
      "group",
      "details",
      "such",
      "customized",
      "terms",
      "conditions",
      "option",
      "visibility",
      "pricing.",
      "create",
      "sequenced",
      "topology",
      "design.",
      "ready",
      "expose",
      "subscribers",
      "publish",
      "catalog",
      "portal.",
      "pricing",
      "configured",
      "supports",
      "initial",
      "recurring",
      "option-specific",
      "choose",
      "show",
      "hide",
      "price",
      "subscriber",
      "approver",
      "attach",
      "documents",
      "standard",
      "level",
      "agreements",
      "screenshots",
      "images",
      "captions",
      "user",
      "visual",
      "representation",
      "different",
      "target",
      "groups.",
      "base",
      "same",
      "attributes",
      "group.",
      "visible",
      "configure",
      "following",
      "name",
      "description",
      "image",
      "tags",
      "based",
      "designs",
      "subscription",
      "attached",
      "associated",
      "multiple",
      "versions",
      "per",
      "link",
      "publishing",
      "cloud",
      "management",
      "uses",
      "constrain",
      "displayed",
      "user.",
      "portal",
      "displays",
      "published",
      "one",
      "hidden",
      "offering.",
      "map"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Service Instance",
    "content": "A subscription originates with a subscription request, which is a request for delivery of cloud services that are initiated by the subscriber (end-user) using a catalog in the Service Portal. After a subscription request is approved, a service instance is created. The system constructs service instance artifacts during service deployment and updates service instances during service management. Service instances provide all details of the deployed service and its components; for example, provisioned IP details for a network segment component. Service instances are based on the service design configured for the service offering, and on consumer demand. For more information, see Service Instance Management.",
    "url": "getstartedserviceinstances",
    "filename": "getstartedserviceinstances",
    "headings": [],
    "keywords": [
      "service",
      "instance",
      "subscription",
      "originates",
      "request",
      "delivery",
      "cloud",
      "services",
      "initiated",
      "subscriber",
      "end-user",
      "catalog",
      "portal.",
      "after",
      "approved",
      "created.",
      "system",
      "constructs",
      "artifacts",
      "during",
      "deployment",
      "updates",
      "instances",
      "management.",
      "provide",
      "all",
      "details",
      "deployed",
      "components",
      "example",
      "provisioned",
      "ip",
      "network",
      "segment",
      "component.",
      "based",
      "design",
      "configured",
      "offering",
      "consumer",
      "demand.",
      "information",
      "see"
    ],
    "language": "en",
    "word_count": 67,
    "importance_score": 3.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "service instance",
    "contentLower": "a subscription originates with a subscription request, which is a request for delivery of cloud services that are initiated by the subscriber (end-user) using a catalog in the service portal. after a subscription request is approved, a service instance is created. the system constructs service instance artifacts during service deployment and updates service instances during service management. service instances provide all details of the deployed service and its components; for example, provisioned ip details for a network segment component. service instances are based on the service design configured for the service offering, and on consumer demand. for more information, see service instance management.",
    "keywordsLower": [
      "service",
      "instance",
      "subscription",
      "originates",
      "request",
      "delivery",
      "cloud",
      "services",
      "initiated",
      "subscriber",
      "end-user",
      "catalog",
      "portal.",
      "after",
      "approved",
      "created.",
      "system",
      "constructs",
      "artifacts",
      "during",
      "deployment",
      "updates",
      "instances",
      "management.",
      "provide",
      "all",
      "details",
      "deployed",
      "components",
      "example",
      "provisioned",
      "ip",
      "network",
      "segment",
      "component.",
      "based",
      "design",
      "configured",
      "offering",
      "consumer",
      "demand.",
      "information",
      "see"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Service Design Components",
    "content": "Components are elements of service design. Only topology components are displayed in the Components tab. Sequenced components aren't associated with providers or provider types. From the Components tab, you can view the topology components associated with a specific provider instance and manage the topological components. For more information, see Service Design Components.",
    "url": "servicedesigncomponents",
    "filename": "servicedesigncomponents",
    "headings": [],
    "keywords": [
      "service",
      "design",
      "components",
      "elements",
      "design.",
      "topology",
      "displayed",
      "tab.",
      "sequenced",
      "aren",
      "associated",
      "providers",
      "provider",
      "types.",
      "tab",
      "view",
      "specific",
      "instance",
      "manage",
      "topological",
      "components.",
      "information",
      "see"
    ],
    "language": "en",
    "word_count": 37,
    "importance_score": 2.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "service design components",
    "contentLower": "components are elements of service design. only topology components are displayed in the components tab. sequenced components aren't associated with providers or provider types. from the components tab, you can view the topology components associated with a specific provider instance and manage the topological components. for more information, see service design components.",
    "keywordsLower": [
      "service",
      "design",
      "components",
      "elements",
      "design.",
      "topology",
      "displayed",
      "tab.",
      "sequenced",
      "aren",
      "associated",
      "providers",
      "provider",
      "types.",
      "tab",
      "view",
      "specific",
      "instance",
      "manage",
      "topological",
      "components.",
      "information",
      "see"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Resource providers",
    "content": "Deployment resource providers are management platforms that offer centralized control over the infrastructure and resources used in a cloud computing environment. For example, a provider such as VMware vCenter can deploy virtual machines, while a provider such as SiteScope can monitor applications. A provider corresponds to a specific instance of an application that can provision service designs. For example, to provision service designs that target VMware vCenter, you must first create a provider (with a provider type of VMware vCenter). For more information, see Deployment Resource Providers",
    "url": "getstartedreourceproviders",
    "filename": "getstartedreourceproviders",
    "headings": [],
    "keywords": [
      "resource",
      "providers",
      "deployment",
      "management",
      "platforms",
      "offer",
      "centralized",
      "control",
      "over",
      "infrastructure",
      "resources",
      "cloud",
      "computing",
      "environment.",
      "example",
      "provider",
      "such",
      "vmware",
      "vcenter",
      "deploy",
      "virtual",
      "machines",
      "while",
      "sitescope",
      "monitor",
      "applications.",
      "corresponds",
      "specific",
      "instance",
      "application",
      "provision",
      "service",
      "designs.",
      "designs",
      "target",
      "first",
      "create",
      "type",
      "information",
      "see"
    ],
    "language": "en",
    "word_count": 57,
    "importance_score": 2.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "resource providers",
    "contentLower": "deployment resource providers are management platforms that offer centralized control over the infrastructure and resources used in a cloud computing environment. for example, a provider such as vmware vcenter can deploy virtual machines, while a provider such as sitescope can monitor applications. a provider corresponds to a specific instance of an application that can provision service designs. for example, to provision service designs that target vmware vcenter, you must first create a provider (with a provider type of vmware vcenter). for more information, see deployment resource providers",
    "keywordsLower": [
      "resource",
      "providers",
      "deployment",
      "management",
      "platforms",
      "offer",
      "centralized",
      "control",
      "over",
      "infrastructure",
      "resources",
      "cloud",
      "computing",
      "environment.",
      "example",
      "provider",
      "such",
      "vmware",
      "vcenter",
      "deploy",
      "virtual",
      "machines",
      "while",
      "sitescope",
      "monitor",
      "applications.",
      "corresponds",
      "specific",
      "instance",
      "application",
      "provision",
      "service",
      "designs.",
      "designs",
      "target",
      "first",
      "create",
      "type",
      "information",
      "see"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Release Management",
    "content": "Release Release management allows a release manager to plan, schedule, and control multiple changes and additions to existing services. The release provides a single pane of glass to organize and coordinate many related changes implemented by different people or teams. The Service Management release management module: Helps you create, manage, and deploy releases, and the changes in a release. Helps you schedule and track the status of included changes. Provides standard methods and procedures. Provides release level reporting, with actionable tiles that drill into changes in different release statuses. Release management allows you to create specific tasks and/or approvals for the release. These activities are tied to the release itself and not to the underlying tasks and are useful for specific actions that must be performed either before or after the changes are implemented. Using Release Management Now we have our change management processes under control, and we can handle changin",
    "url": "releasemanagement",
    "filename": "releasemanagement",
    "headings": [
      "Using Release Management",
      "Setting up Release Management",
      "Creating Release Models"
    ],
    "keywords": [
      "release",
      "management",
      "setting",
      "creating",
      "models",
      "allows",
      "manager",
      "plan",
      "schedule",
      "control",
      "multiple",
      "changes",
      "additions",
      "existing",
      "services.",
      "provides",
      "single",
      "pane",
      "glass",
      "organize",
      "coordinate",
      "many",
      "related",
      "implemented",
      "different",
      "people",
      "teams.",
      "service",
      "module",
      "helps",
      "create",
      "manage",
      "deploy",
      "releases",
      "release.",
      "track",
      "status",
      "included",
      "changes.",
      "standard",
      "methods",
      "procedures.",
      "level",
      "reporting",
      "actionable",
      "tiles",
      "drill",
      "statuses.",
      "specific",
      "tasks",
      "approvals",
      "activities",
      "tied",
      "itself",
      "underlying",
      "useful",
      "actions",
      "performed",
      "either",
      "before",
      "after",
      "implemented.",
      "now",
      "change",
      "processes",
      "under",
      "handle",
      "changing",
      "environment.",
      "what",
      "happens",
      "need",
      "make",
      "bunch",
      "environment",
      "same",
      "time",
      "all",
      "interconnected",
      "going",
      "order",
      "process",
      "just",
      "purpose.",
      "design",
      "build",
      "configure",
      "test",
      "controlled",
      "manner.",
      "comprise",
      "distinct",
      "components",
      "simply",
      "easy",
      "way",
      "keeping",
      "eye",
      "once",
      "entire"
    ],
    "language": "en",
    "word_count": 96,
    "importance_score": 4.5,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "release management",
    "contentLower": "release release management allows a release manager to plan, schedule, and control multiple changes and additions to existing services. the release provides a single pane of glass to organize and coordinate many related changes implemented by different people or teams. the service management release management module: helps you create, manage, and deploy releases, and the changes in a release. helps you schedule and track the status of included changes. provides standard methods and procedures. provides release level reporting, with actionable tiles that drill into changes in different release statuses. release management allows you to create specific tasks and/or approvals for the release. these activities are tied to the release itself and not to the underlying tasks and are useful for specific actions that must be performed either before or after the changes are implemented. using release management now we have our change management processes under control, and we can handle changin",
    "keywordsLower": [
      "release",
      "management",
      "setting",
      "creating",
      "models",
      "allows",
      "manager",
      "plan",
      "schedule",
      "control",
      "multiple",
      "changes",
      "additions",
      "existing",
      "services.",
      "provides",
      "single",
      "pane",
      "glass",
      "organize",
      "coordinate",
      "many",
      "related",
      "implemented",
      "different",
      "people",
      "teams.",
      "service",
      "module",
      "helps",
      "create",
      "manage",
      "deploy",
      "releases",
      "release.",
      "track",
      "status",
      "included",
      "changes.",
      "standard",
      "methods",
      "procedures.",
      "level",
      "reporting",
      "actionable",
      "tiles",
      "drill",
      "statuses.",
      "specific",
      "tasks",
      "approvals",
      "activities",
      "tied",
      "itself",
      "underlying",
      "useful",
      "actions",
      "performed",
      "either",
      "before",
      "after",
      "implemented.",
      "now",
      "change",
      "processes",
      "under",
      "handle",
      "changing",
      "environment.",
      "what",
      "happens",
      "need",
      "make",
      "bunch",
      "environment",
      "same",
      "time",
      "all",
      "interconnected",
      "going",
      "order",
      "process",
      "just",
      "purpose.",
      "design",
      "build",
      "configure",
      "test",
      "controlled",
      "manner.",
      "comprise",
      "distinct",
      "components",
      "simply",
      "easy",
      "way",
      "keeping",
      "eye",
      "once",
      "entire"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Release Flow",
    "content": "Release Flow Each release is governed by the release management workflow. This workflow defines the activities that happen before and after the actual changes that make up the release are implemented and determines what happens if the changes aren't successful. Classification When creating a release, the release coordinator must supply all of the relevant details. This includes filling out the following fields during the 'Log' phase: Title - A short description of the Release Release type - Whether this is a minor, major, or emergency release Description - A detailed description of the release Service - What service is driving the release (the release might affect multiple services, but this specifies which one is the primary reason the release was required) Release model - What pre-defined model will this release follow Reason for release - Why the release is necessary (selected from a list of reasons) Justification - A detailed explanation of why this release is necessary The release",
    "url": "releaseflow",
    "filename": "releaseflow",
    "headings": [
      "Classification",
      "Planning",
      "Deployment",
      "Validation"
    ],
    "keywords": [
      "release",
      "flow",
      "classification",
      "planning",
      "deployment",
      "validation",
      "governed",
      "management",
      "workflow.",
      "workflow",
      "defines",
      "activities",
      "happen",
      "before",
      "after",
      "actual",
      "changes",
      "make",
      "implemented",
      "determines",
      "what",
      "happens",
      "aren",
      "successful.",
      "creating",
      "coordinator",
      "supply",
      "all",
      "relevant",
      "details.",
      "includes",
      "filling",
      "out",
      "following",
      "fields",
      "during",
      "log",
      "phase",
      "title",
      "short",
      "description",
      "type",
      "whether",
      "minor",
      "major",
      "emergency",
      "detailed",
      "service",
      "driving",
      "affect",
      "multiple",
      "services",
      "specifies",
      "one",
      "primary",
      "reason",
      "required",
      "model",
      "pre-defined",
      "follow",
      "necessary",
      "selected",
      "list",
      "reasons",
      "justification",
      "explanation",
      "specify",
      "latest",
      "execution",
      "date",
      "categorize",
      "set",
      "urgency.",
      "next",
      "evaluate",
      "review",
      "previous",
      "information",
      "assign",
      "owning",
      "group",
      "owner.",
      "identifies",
      "ensures",
      "part",
      "linking",
      "them.",
      "once",
      "move",
      "forward",
      "step.",
      "step",
      "allows",
      "plan",
      "resources",
      "tasks",
      "release.",
      "design",
      "analyzes",
      "based"
    ],
    "language": "en",
    "word_count": 94,
    "importance_score": 5.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "release flow",
    "contentLower": "release flow each release is governed by the release management workflow. this workflow defines the activities that happen before and after the actual changes that make up the release are implemented and determines what happens if the changes aren't successful. classification when creating a release, the release coordinator must supply all of the relevant details. this includes filling out the following fields during the 'log' phase: title - a short description of the release release type - whether this is a minor, major, or emergency release description - a detailed description of the release service - what service is driving the release (the release might affect multiple services, but this specifies which one is the primary reason the release was required) release model - what pre-defined model will this release follow reason for release - why the release is necessary (selected from a list of reasons) justification - a detailed explanation of why this release is necessary the release",
    "keywordsLower": [
      "release",
      "flow",
      "classification",
      "planning",
      "deployment",
      "validation",
      "governed",
      "management",
      "workflow.",
      "workflow",
      "defines",
      "activities",
      "happen",
      "before",
      "after",
      "actual",
      "changes",
      "make",
      "implemented",
      "determines",
      "what",
      "happens",
      "aren",
      "successful.",
      "creating",
      "coordinator",
      "supply",
      "all",
      "relevant",
      "details.",
      "includes",
      "filling",
      "out",
      "following",
      "fields",
      "during",
      "log",
      "phase",
      "title",
      "short",
      "description",
      "type",
      "whether",
      "minor",
      "major",
      "emergency",
      "detailed",
      "service",
      "driving",
      "affect",
      "multiple",
      "services",
      "specifies",
      "one",
      "primary",
      "reason",
      "required",
      "model",
      "pre-defined",
      "follow",
      "necessary",
      "selected",
      "list",
      "reasons",
      "justification",
      "explanation",
      "specify",
      "latest",
      "execution",
      "date",
      "categorize",
      "set",
      "urgency.",
      "next",
      "evaluate",
      "review",
      "previous",
      "information",
      "assign",
      "owning",
      "group",
      "owner.",
      "identifies",
      "ensures",
      "part",
      "linking",
      "them.",
      "once",
      "move",
      "forward",
      "step.",
      "step",
      "allows",
      "plan",
      "resources",
      "tasks",
      "release.",
      "design",
      "analyzes",
      "based"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "System Configuration",
    "content": "Configuring SMAX Dev2Prod Data Configuration",
    "url": "systemconfiguration",
    "filename": "systemconfiguration",
    "headings": [],
    "keywords": [
      "system",
      "configuration",
      "configuring",
      "smax",
      "dev2prod",
      "data"
    ],
    "language": "en",
    "word_count": 7,
    "importance_score": 2.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "system configuration",
    "contentLower": "configuring smax dev2prod data configuration",
    "keywordsLower": [
      "system",
      "configuration",
      "configuring",
      "smax",
      "dev2prod",
      "data"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Service Management data access control tools",
    "content": "OpenText Service Management uses the following tools to restrict user access to data records: Role-based access control: by defining role permissions for record types, you can allow users to access only the records of selected record types. For details, see Roles. Domain-based access control: by defining a list of data domains and assigning data records to different domains, you can allow users to access only data records that belong to their data domains. For details, see Data domain segmentation. Person-based access control: By enabling Record Level Access Control (RLAC) in Studio for record types, you can implement more granular data access control for agent users, in the context of the current user. For details, see Record level access control. Entitlement rules: by defining entitlement rules in offerings, knowledge articles, service definitions, and categories, you make these records in the Service Portal available only to relevant audiences in specified locations, and belonging t",
    "url": "smdataaccesscontrol",
    "filename": "smdataaccesscontrol",
    "headings": [
      "Comparison of the tools",
      "Data domain assignments and entitlement rules",
      "Data domain segmentation and RLAC",
      "Record types that have no impact on Service Portal",
      "Certain typical use cases",
      "Browse and search in Service Portal",
      "Access customized tabs in Service Portal",
      "Access custom fields on the request form in Service Portal",
      "Access offering user options in Service Portal",
      "Work with Hot Topic Analytics and Change Analytics",
      "Run business rules"
    ],
    "keywords": [
      "service",
      "management",
      "data",
      "access",
      "control",
      "tools",
      "comparison",
      "domain",
      "assignments",
      "entitlement",
      "rules",
      "segmentation",
      "rlac",
      "record",
      "types",
      "impact",
      "portal",
      "certain",
      "typical",
      "cases",
      "browse",
      "search",
      "customized",
      "tabs",
      "custom",
      "fields",
      "request",
      "form",
      "offering",
      "user",
      "options",
      "work",
      "hot",
      "topic",
      "analytics",
      "change",
      "run",
      "business",
      "opentext",
      "uses",
      "following",
      "restrict",
      "records",
      "role-based",
      "defining",
      "role",
      "permissions",
      "allow",
      "users",
      "selected",
      "types.",
      "details",
      "see",
      "roles.",
      "domain-based",
      "list",
      "domains",
      "assigning",
      "different",
      "belong",
      "domains.",
      "segmentation.",
      "person-based",
      "enabling",
      "level",
      "studio",
      "implement",
      "granular",
      "agent",
      "context",
      "current",
      "user.",
      "control.",
      "offerings",
      "knowledge",
      "articles",
      "definitions",
      "categories",
      "make",
      "available",
      "relevant",
      "audiences",
      "specified",
      "locations",
      "belonging",
      "groups.",
      "manage",
      "rules.",
      "together",
      "system.",
      "tool",
      "implements",
      "type",
      "highest",
      "mechanisms",
      "sections",
      "compare",
      "three",
      "take",
      "effect"
    ],
    "language": "en",
    "word_count": 110,
    "importance_score": 5.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "service management data access control tools",
    "contentLower": "opentext service management uses the following tools to restrict user access to data records: role-based access control: by defining role permissions for record types, you can allow users to access only the records of selected record types. for details, see roles. domain-based access control: by defining a list of data domains and assigning data records to different domains, you can allow users to access only data records that belong to their data domains. for details, see data domain segmentation. person-based access control: by enabling record level access control (rlac) in studio for record types, you can implement more granular data access control for agent users, in the context of the current user. for details, see record level access control. entitlement rules: by defining entitlement rules in offerings, knowledge articles, service definitions, and categories, you make these records in the service portal available only to relevant audiences in specified locations, and belonging t",
    "keywordsLower": [
      "service",
      "management",
      "data",
      "access",
      "control",
      "tools",
      "comparison",
      "domain",
      "assignments",
      "entitlement",
      "rules",
      "segmentation",
      "rlac",
      "record",
      "types",
      "impact",
      "portal",
      "certain",
      "typical",
      "cases",
      "browse",
      "search",
      "customized",
      "tabs",
      "custom",
      "fields",
      "request",
      "form",
      "offering",
      "user",
      "options",
      "work",
      "hot",
      "topic",
      "analytics",
      "change",
      "run",
      "business",
      "opentext",
      "uses",
      "following",
      "restrict",
      "records",
      "role-based",
      "defining",
      "role",
      "permissions",
      "allow",
      "users",
      "selected",
      "types.",
      "details",
      "see",
      "roles.",
      "domain-based",
      "list",
      "domains",
      "assigning",
      "different",
      "belong",
      "domains.",
      "segmentation.",
      "person-based",
      "enabling",
      "level",
      "studio",
      "implement",
      "granular",
      "agent",
      "context",
      "current",
      "user.",
      "control.",
      "offerings",
      "knowledge",
      "articles",
      "definitions",
      "categories",
      "make",
      "available",
      "relevant",
      "audiences",
      "specified",
      "locations",
      "belonging",
      "groups.",
      "manage",
      "rules.",
      "together",
      "system.",
      "tool",
      "implements",
      "type",
      "highest",
      "mechanisms",
      "sections",
      "compare",
      "three",
      "take",
      "effect"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Service Management/SM Dual Mode",
    "content": "Introduction While Service Manager (SM) and OpenText Service Management (Service Management) are both end-to-end, stand-alone, solutions for IT and Extended Service Management, they can also be used together. Customers looking for a modern self-service portal while leveraging the SM request catalog can deploy the Service Management Service Portal with SM; this deployment combination is called “Mixed Mode” for short. Customers looking to transform the entire Service Request process, that is, the Self-service Portal, Service Catalog, End-user Knowledge Management, and Service Request functions, can deploy Service Management with SM for the remaining processes such as Incident, Problem, and Change; this deployment combination is called “Dual Mode” for short. Mixed and Dual Modes are considered by customers looking to improve the self-service experience, advance the entire service request process, revamp the service catalog, or transition to Service Management. SM unloads and accompanying ",
    "url": "dualmode",
    "filename": "dualmode",
    "headings": [
      "Introduction",
      "What is Dual Mode?",
      "Dual Mode vs. Mixed Mode"
    ],
    "keywords": [
      "managementsm",
      "https://marketplace.opentext.com/itom/content/dual-mode-recipe",
      "opentext.com",
      "service",
      "management",
      "sm",
      "dual",
      "mode",
      "introduction",
      "what",
      "vs.",
      "mixed",
      "while",
      "manager",
      "opentext",
      "both",
      "end-to-end",
      "stand-alone",
      "solutions",
      "extended",
      "together.",
      "customers",
      "looking",
      "modern",
      "self-service",
      "portal",
      "leveraging",
      "request",
      "catalog",
      "deploy",
      "deployment",
      "combination",
      "called",
      "short.",
      "transform",
      "entire",
      "process",
      "end-user",
      "knowledge",
      "functions",
      "remaining",
      "processes",
      "such",
      "incident",
      "problem",
      "change",
      "modes",
      "considered",
      "improve",
      "experience",
      "advance",
      "revamp",
      "transition",
      "management.",
      "unloads",
      "accompanying",
      "documentation",
      "provided",
      "setting",
      "systems",
      "mode.",
      "information",
      "well",
      "recipes",
      "offerings",
      "fulfillment",
      "either",
      "center",
      "found",
      "following",
      "link",
      "https",
      "marketplace.opentext.com",
      "itom",
      "content",
      "dual-mode-recipe",
      "run",
      "inside",
      "includes",
      "functions.",
      "all",
      "configuration",
      "specifically",
      "done",
      "handled",
      "sm.",
      "change.",
      "create",
      "related",
      "any",
      "passed",
      "case",
      "exchange",
      "capabilities",
      "shared",
      "two",
      "products.",
      "bi-directional",
      "necessary",
      "status"
    ],
    "language": "en",
    "word_count": 101,
    "importance_score": 4.5,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "service management/sm dual mode",
    "contentLower": "introduction while service manager (sm) and opentext service management (service management) are both end-to-end, stand-alone, solutions for it and extended service management, they can also be used together. customers looking for a modern self-service portal while leveraging the sm request catalog can deploy the service management service portal with sm; this deployment combination is called “mixed mode” for short. customers looking to transform the entire service request process, that is, the self-service portal, service catalog, end-user knowledge management, and service request functions, can deploy service management with sm for the remaining processes such as incident, problem, and change; this deployment combination is called “dual mode” for short. mixed and dual modes are considered by customers looking to improve the self-service experience, advance the entire service request process, revamp the service catalog, or transition to service management. sm unloads and accompanying ",
    "keywordsLower": [
      "managementsm",
      "https://marketplace.opentext.com/itom/content/dual-mode-recipe",
      "opentext.com",
      "service",
      "management",
      "sm",
      "dual",
      "mode",
      "introduction",
      "what",
      "vs.",
      "mixed",
      "while",
      "manager",
      "opentext",
      "both",
      "end-to-end",
      "stand-alone",
      "solutions",
      "extended",
      "together.",
      "customers",
      "looking",
      "modern",
      "self-service",
      "portal",
      "leveraging",
      "request",
      "catalog",
      "deploy",
      "deployment",
      "combination",
      "called",
      "short.",
      "transform",
      "entire",
      "process",
      "end-user",
      "knowledge",
      "functions",
      "remaining",
      "processes",
      "such",
      "incident",
      "problem",
      "change",
      "modes",
      "considered",
      "improve",
      "experience",
      "advance",
      "revamp",
      "transition",
      "management.",
      "unloads",
      "accompanying",
      "documentation",
      "provided",
      "setting",
      "systems",
      "mode.",
      "information",
      "well",
      "recipes",
      "offerings",
      "fulfillment",
      "either",
      "center",
      "found",
      "following",
      "link",
      "https",
      "marketplace.opentext.com",
      "itom",
      "content",
      "dual-mode-recipe",
      "run",
      "inside",
      "includes",
      "functions.",
      "all",
      "configuration",
      "specifically",
      "done",
      "handled",
      "sm.",
      "change.",
      "create",
      "related",
      "any",
      "passed",
      "case",
      "exchange",
      "capabilities",
      "shared",
      "two",
      "products.",
      "bi-directional",
      "necessary",
      "status"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Services and the Service Catalog",
    "content": "Introduction Some customers new to Service Management (or ITIL v3 in general) are confused about what IT services are and what services they themselves support. ITIL defines it as \"a service provided to one or more customers by an IT service provider.\" In more simple terms, if an end user contacts the Service Desk with a request and the agent's answer is anything but \"we don't support that\", that request is somehow related to a supported IT Service. What are Services? Services that IT provides to end users are called Business Services. Examples could include collaboration services, email services, or mobile device support. Services that are used internally by IT are called Infrastructure Services. Some examples of these might include data storage or networking services. Some services can even be made up of other services. More information on Services and how they are defined can be found here: SACM Overview Finding and defining the IT Services can be one of the most time-consuming part",
    "url": "servicesandtheservicecatalog",
    "filename": "servicesandtheservicecatalog",
    "headings": [
      "Introduction",
      "What are Services?",
      "Designing the Service Catalog",
      "Design for the End User",
      "Design for Search",
      "Design a Catalog, not an Entry Form",
      "Creating the Offering Description",
      "What to include in the Offering description",
      "Supplement the Service Catalog with Knowledge Articles",
      "Do's and Don'ts for Knowledge Articles",
      "Using Naming Conventions and Models in Articles",
      "Writing User-friendly Articles: An Example"
    ],
    "keywords": [
      "services",
      "service",
      "catalog",
      "introduction",
      "what",
      "designing",
      "design",
      "end",
      "user",
      "search",
      "entry",
      "form",
      "creating",
      "offering",
      "description",
      "include",
      "supplement",
      "knowledge",
      "articles",
      "don",
      "ts",
      "naming",
      "conventions",
      "models",
      "writing",
      "user-friendly",
      "example",
      "customers",
      "new",
      "management",
      "itil",
      "v3",
      "general",
      "confused",
      "about",
      "themselves",
      "support.",
      "defines",
      "provided",
      "one",
      "provider.",
      "simple",
      "terms",
      "contacts",
      "desk",
      "request",
      "agent",
      "answer",
      "anything",
      "support",
      "somehow",
      "related",
      "supported",
      "service.",
      "provides",
      "users",
      "called",
      "business",
      "services.",
      "examples",
      "collaboration",
      "email",
      "mobile",
      "device",
      "internally",
      "infrastructure",
      "data",
      "storage",
      "networking",
      "even",
      "made",
      "information",
      "defined",
      "found",
      "here",
      "sacm",
      "overview",
      "finding",
      "defining",
      "most",
      "time-consuming",
      "parts",
      "any",
      "implementation",
      "create",
      "value.",
      "knowing",
      "entirety",
      "doesn",
      "invaluable",
      "piece",
      "information.",
      "once",
      "high-level",
      "known",
      "creation",
      "begin",
      "earnest.",
      "separated",
      "three"
    ],
    "language": "en",
    "word_count": 94,
    "importance_score": 6.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "services and the service catalog",
    "contentLower": "introduction some customers new to service management (or itil v3 in general) are confused about what it services are and what services they themselves support. itil defines it as \"a service provided to one or more customers by an it service provider.\" in more simple terms, if an end user contacts the service desk with a request and the agent's answer is anything but \"we don't support that\", that request is somehow related to a supported it service. what are services? services that it provides to end users are called business services. examples could include collaboration services, email services, or mobile device support. services that are used internally by it are called infrastructure services. some examples of these might include data storage or networking services. some services can even be made up of other services. more information on services and how they are defined can be found here: sacm overview finding and defining the it services can be one of the most time-consuming part",
    "keywordsLower": [
      "services",
      "service",
      "catalog",
      "introduction",
      "what",
      "designing",
      "design",
      "end",
      "user",
      "search",
      "entry",
      "form",
      "creating",
      "offering",
      "description",
      "include",
      "supplement",
      "knowledge",
      "articles",
      "don",
      "ts",
      "naming",
      "conventions",
      "models",
      "writing",
      "user-friendly",
      "example",
      "customers",
      "new",
      "management",
      "itil",
      "v3",
      "general",
      "confused",
      "about",
      "themselves",
      "support.",
      "defines",
      "provided",
      "one",
      "provider.",
      "simple",
      "terms",
      "contacts",
      "desk",
      "request",
      "agent",
      "answer",
      "anything",
      "support",
      "somehow",
      "related",
      "supported",
      "service.",
      "provides",
      "users",
      "called",
      "business",
      "services.",
      "examples",
      "collaboration",
      "email",
      "mobile",
      "device",
      "internally",
      "infrastructure",
      "data",
      "storage",
      "networking",
      "even",
      "made",
      "information",
      "defined",
      "found",
      "here",
      "sacm",
      "overview",
      "finding",
      "defining",
      "most",
      "time-consuming",
      "parts",
      "any",
      "implementation",
      "create",
      "value.",
      "knowing",
      "entirety",
      "doesn",
      "invaluable",
      "piece",
      "information.",
      "once",
      "high-level",
      "known",
      "creation",
      "begin",
      "earnest.",
      "separated",
      "three"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Reporting Options",
    "content": "Reporting The ability to process and investigate the data gathered in a service management system is of utmost importance. The Service Management application provides several methods for reporting on this data, including handling both operational and analytical type reports. Due to the differences in technology and functionality between Service Manager and Service Management, automatic migration of existing reports is not possible. Therefore, it is important to understand the reporting options that Service Management provides in order to decide where and how the existing reporting requirements should be met. Internal Reporting In-tool reports enable the view of the current and past status of The Service Management system. Data may be grouped or filtered to display specific information and data relevant to an agent or a supervisor. Reports may be saved publically and made available to agents with appropriate permissions or may be set for private use. An overview of Service Management in",
    "url": "smaev_reporting",
    "filename": "smaev_reporting",
    "headings": [
      "Reporting",
      "Internal Reporting",
      "External Reporting",
      "PostgreSQL Views",
      "Business Intelligence Integration"
    ],
    "keywords": [
      "reporting",
      "options",
      "internal",
      "external",
      "postgresql",
      "views",
      "business",
      "intelligence",
      "integration",
      "ability",
      "process",
      "investigate",
      "data",
      "gathered",
      "service",
      "management",
      "system",
      "utmost",
      "importance.",
      "application",
      "provides",
      "several",
      "methods",
      "including",
      "handling",
      "both",
      "operational",
      "analytical",
      "type",
      "reports.",
      "due",
      "differences",
      "technology",
      "functionality",
      "between",
      "manager",
      "automatic",
      "migration",
      "existing",
      "reports",
      "possible.",
      "therefore",
      "important",
      "understand",
      "order",
      "decide",
      "requirements",
      "met.",
      "in-tool",
      "enable",
      "view",
      "current",
      "past",
      "status",
      "system.",
      "grouped",
      "filtered",
      "display",
      "specific",
      "information",
      "relevant",
      "agent",
      "supervisor.",
      "saved",
      "publically",
      "made",
      "available",
      "agents",
      "appropriate",
      "permissions",
      "set",
      "private",
      "use.",
      "overview",
      "found",
      "here.",
      "built-in",
      "dashboards",
      "provide",
      "quick",
      "useful",
      "way",
      "define",
      "many",
      "simple",
      "analytic",
      "meanwhile",
      "complex",
      "kpi",
      "determination",
      "need",
      "advanced",
      "queries",
      "involve",
      "multiple",
      "tables.",
      "better",
      "addressed",
      "tools",
      "crafted"
    ],
    "language": "en",
    "word_count": 92,
    "importance_score": 5.5,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "reporting options",
    "contentLower": "reporting the ability to process and investigate the data gathered in a service management system is of utmost importance. the service management application provides several methods for reporting on this data, including handling both operational and analytical type reports. due to the differences in technology and functionality between service manager and service management, automatic migration of existing reports is not possible. therefore, it is important to understand the reporting options that service management provides in order to decide where and how the existing reporting requirements should be met. internal reporting in-tool reports enable the view of the current and past status of the service management system. data may be grouped or filtered to display specific information and data relevant to an agent or a supervisor. reports may be saved publically and made available to agents with appropriate permissions or may be set for private use. an overview of service management in",
    "keywordsLower": [
      "reporting",
      "options",
      "internal",
      "external",
      "postgresql",
      "views",
      "business",
      "intelligence",
      "integration",
      "ability",
      "process",
      "investigate",
      "data",
      "gathered",
      "service",
      "management",
      "system",
      "utmost",
      "importance.",
      "application",
      "provides",
      "several",
      "methods",
      "including",
      "handling",
      "both",
      "operational",
      "analytical",
      "type",
      "reports.",
      "due",
      "differences",
      "technology",
      "functionality",
      "between",
      "manager",
      "automatic",
      "migration",
      "existing",
      "reports",
      "possible.",
      "therefore",
      "important",
      "understand",
      "order",
      "decide",
      "requirements",
      "met.",
      "in-tool",
      "enable",
      "view",
      "current",
      "past",
      "status",
      "system.",
      "grouped",
      "filtered",
      "display",
      "specific",
      "information",
      "relevant",
      "agent",
      "supervisor.",
      "saved",
      "publically",
      "made",
      "available",
      "agents",
      "appropriate",
      "permissions",
      "set",
      "private",
      "use.",
      "overview",
      "found",
      "here.",
      "built-in",
      "dashboards",
      "provide",
      "quick",
      "useful",
      "way",
      "define",
      "many",
      "simple",
      "analytic",
      "meanwhile",
      "complex",
      "kpi",
      "determination",
      "need",
      "advanced",
      "queries",
      "involve",
      "multiple",
      "tables.",
      "better",
      "addressed",
      "tools",
      "crafted"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Reporting",
    "content": "This section gives specific examples and use cases in the area of reporting.",
    "url": "wowreporting",
    "filename": "wowreporting",
    "headings": [],
    "keywords": [
      "reporting",
      "section",
      "gives",
      "specific",
      "examples",
      "cases",
      "area",
      "reporting."
    ],
    "language": "en",
    "word_count": 8,
    "importance_score": 2.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "reporting",
    "contentLower": "this section gives specific examples and use cases in the area of reporting.",
    "keywordsLower": [
      "reporting",
      "section",
      "gives",
      "specific",
      "examples",
      "cases",
      "area",
      "reporting."
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "REST API",
    "content": "Introduction This section provides specific examples and use cases in the area of the REST API.",
    "url": "integration_rest",
    "filename": "integration_rest",
    "headings": [
      "Introduction"
    ],
    "keywords": [
      "rest",
      "api",
      "introduction",
      "section",
      "provides",
      "specific",
      "examples",
      "cases",
      "area",
      "api."
    ],
    "language": "en",
    "word_count": 11,
    "importance_score": 2.5,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "rest api",
    "contentLower": "introduction this section provides specific examples and use cases in the area of the rest api.",
    "keywordsLower": [
      "rest",
      "api",
      "introduction",
      "section",
      "provides",
      "specific",
      "examples",
      "cases",
      "area",
      "api."
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Request vs. Incident",
    "content": "In planning your IT Service Management (ITSM) solution, it's important to understand the differences between Service Request Management and Incident Management, as well as the types of processes served by each discipline. I know that users are often confused by these two types of management, so I want to clearly describe their differences to you.The overall goal of ITSM is to provide a business service that provides meaningful value to the users of that service.  It's important not only to define the service itself, but also several important sub-processes that the consumers have access to such as: How can someone become a user of the service? How can someone stop being a user of the service? How can someone ask questions about the usage of the service? How can someone make a complaint about the service? How can someone get help on an issue they are having with the service? How can someone request a modification to how they are using/receiving the service? How can someone can make a su",
    "url": "requestvsincident",
    "filename": "requestvsincident",
    "headings": [],
    "keywords": [
      "possible.The",
      "you.The",
      "service.It",
      "satisfaction.The",
      "service.From",
      "Management.Here",
      "process.The",
      "request",
      "vs.",
      "incident",
      "planning",
      "service",
      "management",
      "itsm",
      "solution",
      "important",
      "understand",
      "differences",
      "between",
      "well",
      "types",
      "processes",
      "served",
      "discipline.",
      "know",
      "users",
      "often",
      "confused",
      "two",
      "want",
      "clearly",
      "describe",
      "overall",
      "goal",
      "provide",
      "business",
      "provides",
      "meaningful",
      "value",
      "service.",
      "define",
      "itself",
      "several",
      "sub-processes",
      "consumers",
      "access",
      "such",
      "someone",
      "become",
      "user",
      "stop",
      "ask",
      "questions",
      "about",
      "usage",
      "make",
      "complaint",
      "get",
      "help",
      "issue",
      "having",
      "modification",
      "receiving",
      "suggestion",
      "improve",
      "all",
      "above",
      "part",
      "definition.",
      "department",
      "expects",
      "day-to-day",
      "operation",
      "consumption",
      "derive",
      "high",
      "level",
      "definition",
      "process.",
      "encompasses",
      "consumer-facing",
      "expected",
      "day",
      "activities",
      "involved",
      "providing",
      "individual",
      "group.these",
      "defined",
      "either",
      "requests",
      "support",
      "requests.",
      "set",
      "pre-defined",
      "performed",
      "against",
      "increasing",
      "size",
      "standard"
    ],
    "language": "en",
    "word_count": 90,
    "importance_score": 3.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "request vs. incident",
    "contentLower": "in planning your it service management (itsm) solution, it's important to understand the differences between service request management and incident management, as well as the types of processes served by each discipline. i know that users are often confused by these two types of management, so i want to clearly describe their differences to you.the overall goal of itsm is to provide a business service that provides meaningful value to the users of that service.  it's important not only to define the service itself, but also several important sub-processes that the consumers have access to such as: how can someone become a user of the service? how can someone stop being a user of the service? how can someone ask questions about the usage of the service? how can someone make a complaint about the service? how can someone get help on an issue they are having with the service? how can someone request a modification to how they are using/receiving the service? how can someone can make a su",
    "keywordsLower": [
      "possible.the",
      "you.the",
      "service.it",
      "satisfaction.the",
      "service.from",
      "management.here",
      "process.the",
      "request",
      "vs.",
      "incident",
      "planning",
      "service",
      "management",
      "itsm",
      "solution",
      "important",
      "understand",
      "differences",
      "between",
      "well",
      "types",
      "processes",
      "served",
      "discipline.",
      "know",
      "users",
      "often",
      "confused",
      "two",
      "want",
      "clearly",
      "describe",
      "overall",
      "goal",
      "provide",
      "business",
      "provides",
      "meaningful",
      "value",
      "service.",
      "define",
      "itself",
      "several",
      "sub-processes",
      "consumers",
      "access",
      "such",
      "someone",
      "become",
      "user",
      "stop",
      "ask",
      "questions",
      "about",
      "usage",
      "make",
      "complaint",
      "get",
      "help",
      "issue",
      "having",
      "modification",
      "receiving",
      "suggestion",
      "improve",
      "all",
      "above",
      "part",
      "definition.",
      "department",
      "expects",
      "day-to-day",
      "operation",
      "consumption",
      "derive",
      "high",
      "level",
      "definition",
      "process.",
      "encompasses",
      "consumer-facing",
      "expected",
      "day",
      "activities",
      "involved",
      "providing",
      "individual",
      "group.these",
      "defined",
      "either",
      "requests",
      "support",
      "requests.",
      "set",
      "pre-defined",
      "performed",
      "against",
      "increasing",
      "size",
      "standard"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Solution planning using Service Management",
    "content": "Service Management includes two important modules that are involved in planning service solutions, Service Request Management and Incident Management. It's important to understand the differences between these modules, as well as the types of processes served by each one. Service Request Management Service Request Management (SRM) encompasses the consumer-facing processes that make up the expected, day-to-day activities involved in providing a service to an individual or group. These activities can be defined at a high level as either service requests or support requests. Service requests are the set of predefined activities that can be performed against the service itself (such as increasing the size of a standard email mailbox, requesting additional memory for a virtual machine, or resetting a password for a specific application). Service requests usually require the same type of information from the user each time (such as a user id or application name), and often lend themselves to",
    "url": "incidentrequest",
    "filename": "incidentrequest",
    "headings": [
      "Service Request Management",
      "Incident Management",
      "Understanding the difference",
      "Related topics"
    ],
    "keywords": [
      "solution",
      "planning",
      "service",
      "management",
      "request",
      "incident",
      "understanding",
      "difference",
      "related",
      "topics",
      "includes",
      "two",
      "important",
      "modules",
      "involved",
      "solutions",
      "management.",
      "understand",
      "differences",
      "between",
      "well",
      "types",
      "processes",
      "served",
      "one.",
      "srm",
      "encompasses",
      "consumer-facing",
      "make",
      "expected",
      "day-to-day",
      "activities",
      "providing",
      "individual",
      "group.",
      "defined",
      "high",
      "level",
      "either",
      "requests",
      "support",
      "requests.",
      "set",
      "predefined",
      "performed",
      "against",
      "itself",
      "such",
      "increasing",
      "size",
      "standard",
      "email",
      "mailbox",
      "requesting",
      "additional",
      "memory",
      "virtual",
      "machine",
      "resetting",
      "password",
      "specific",
      "application",
      "usually",
      "require",
      "same",
      "type",
      "information",
      "user",
      "time",
      "id",
      "name",
      "often",
      "lend",
      "themselves",
      "automation.",
      "contrast",
      "encompass",
      "haven",
      "even",
      "owner.",
      "include",
      "questions",
      "suggestions",
      "complaints.",
      "many",
      "good",
      "knowledge",
      "base",
      "enable",
      "consumer",
      "self-answer",
      "remove",
      "need",
      "desk",
      "agent",
      "manually",
      "respond",
      "request.",
      "however",
      "involves"
    ],
    "language": "en",
    "word_count": 99,
    "importance_score": 5.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "solution planning using service management",
    "contentLower": "service management includes two important modules that are involved in planning service solutions, service request management and incident management. it's important to understand the differences between these modules, as well as the types of processes served by each one. service request management service request management (srm) encompasses the consumer-facing processes that make up the expected, day-to-day activities involved in providing a service to an individual or group. these activities can be defined at a high level as either service requests or support requests. service requests are the set of predefined activities that can be performed against the service itself (such as increasing the size of a standard email mailbox, requesting additional memory for a virtual machine, or resetting a password for a specific application). service requests usually require the same type of information from the user each time (such as a user id or application name), and often lend themselves to",
    "keywordsLower": [
      "solution",
      "planning",
      "service",
      "management",
      "request",
      "incident",
      "understanding",
      "difference",
      "related",
      "topics",
      "includes",
      "two",
      "important",
      "modules",
      "involved",
      "solutions",
      "management.",
      "understand",
      "differences",
      "between",
      "well",
      "types",
      "processes",
      "served",
      "one.",
      "srm",
      "encompasses",
      "consumer-facing",
      "make",
      "expected",
      "day-to-day",
      "activities",
      "providing",
      "individual",
      "group.",
      "defined",
      "high",
      "level",
      "either",
      "requests",
      "support",
      "requests.",
      "set",
      "predefined",
      "performed",
      "against",
      "itself",
      "such",
      "increasing",
      "size",
      "standard",
      "email",
      "mailbox",
      "requesting",
      "additional",
      "memory",
      "virtual",
      "machine",
      "resetting",
      "password",
      "specific",
      "application",
      "usually",
      "require",
      "same",
      "type",
      "information",
      "user",
      "time",
      "id",
      "name",
      "often",
      "lend",
      "themselves",
      "automation.",
      "contrast",
      "encompass",
      "haven",
      "even",
      "owner.",
      "include",
      "questions",
      "suggestions",
      "complaints.",
      "many",
      "good",
      "knowledge",
      "base",
      "enable",
      "consumer",
      "self-answer",
      "remove",
      "need",
      "desk",
      "agent",
      "manually",
      "respond",
      "request.",
      "however",
      "involves"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Service Portal",
    "content": "The Service Portal provides one centralized location for all employee issues related to IT. Its easy-to-use interface enables users to independently request support, search a self-help knowledge base, and browse a service catalog. Users can even ask their friends for help using an intuitive question and answer (Q&A) interface in which questions are routed to other employees, based on their skills and expertise. The Service Portal also enables employees to track support and service requests. The portal's sophisticated search capabilities enable users to independently find relevant information. Search results are gathered from multiple sources and can include multimedia-rich articles, user Q&A, relevant services and forms, and targeted support – all displayed in one, user-friendly interface. You use Service Management to configure the portal to present valuable information and forms to end users. The catalog, support offerings, and articles are managed in the Service Catalog Management a",
    "url": "essoverview",
    "filename": "essoverview",
    "headings": [
      "Category tiles",
      "Grid view of requests",
      "Related topics"
    ],
    "keywords": [
      "service",
      "portal",
      "category",
      "tiles",
      "grid",
      "view",
      "requests",
      "related",
      "topics",
      "provides",
      "one",
      "centralized",
      "location",
      "all",
      "employee",
      "issues",
      "it.",
      "easy-to-use",
      "interface",
      "enables",
      "users",
      "independently",
      "request",
      "support",
      "search",
      "self-help",
      "knowledge",
      "base",
      "browse",
      "catalog.",
      "even",
      "ask",
      "friends",
      "help",
      "intuitive",
      "question",
      "answer",
      "questions",
      "routed",
      "employees",
      "based",
      "skills",
      "expertise.",
      "track",
      "requests.",
      "sophisticated",
      "capabilities",
      "enable",
      "find",
      "relevant",
      "information.",
      "results",
      "gathered",
      "multiple",
      "sources",
      "include",
      "multimedia-rich",
      "articles",
      "user",
      "services",
      "forms",
      "targeted",
      "displayed",
      "user-friendly",
      "interface.",
      "management",
      "configure",
      "present",
      "valuable",
      "information",
      "end",
      "users.",
      "catalog",
      "offerings",
      "managed",
      "modules.",
      "clicks",
      "tile",
      "page",
      "three",
      "tabbed",
      "sections",
      "featured",
      "hidden",
      "default",
      "displays",
      "news",
      "recommended",
      "popular",
      "belong",
      "includes",
      "enhanced",
      "drop-down",
      "option",
      "allowing",
      "selected",
      "categories.",
      "about",
      "settings",
      "see"
    ],
    "language": "en",
    "word_count": 100,
    "importance_score": 4.5,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "service portal",
    "contentLower": "the service portal provides one centralized location for all employee issues related to it. its easy-to-use interface enables users to independently request support, search a self-help knowledge base, and browse a service catalog. users can even ask their friends for help using an intuitive question and answer (q&a) interface in which questions are routed to other employees, based on their skills and expertise. the service portal also enables employees to track support and service requests. the portal's sophisticated search capabilities enable users to independently find relevant information. search results are gathered from multiple sources and can include multimedia-rich articles, user q&a, relevant services and forms, and targeted support – all displayed in one, user-friendly interface. you use service management to configure the portal to present valuable information and forms to end users. the catalog, support offerings, and articles are managed in the service catalog management a",
    "keywordsLower": [
      "service",
      "portal",
      "category",
      "tiles",
      "grid",
      "view",
      "requests",
      "related",
      "topics",
      "provides",
      "one",
      "centralized",
      "location",
      "all",
      "employee",
      "issues",
      "it.",
      "easy-to-use",
      "interface",
      "enables",
      "users",
      "independently",
      "request",
      "support",
      "search",
      "self-help",
      "knowledge",
      "base",
      "browse",
      "catalog.",
      "even",
      "ask",
      "friends",
      "help",
      "intuitive",
      "question",
      "answer",
      "questions",
      "routed",
      "employees",
      "based",
      "skills",
      "expertise.",
      "track",
      "requests.",
      "sophisticated",
      "capabilities",
      "enable",
      "find",
      "relevant",
      "information.",
      "results",
      "gathered",
      "multiple",
      "sources",
      "include",
      "multimedia-rich",
      "articles",
      "user",
      "services",
      "forms",
      "targeted",
      "displayed",
      "user-friendly",
      "interface.",
      "management",
      "configure",
      "present",
      "valuable",
      "information",
      "end",
      "users.",
      "catalog",
      "offerings",
      "managed",
      "modules.",
      "clicks",
      "tile",
      "page",
      "three",
      "tabbed",
      "sections",
      "featured",
      "hidden",
      "default",
      "displays",
      "news",
      "recommended",
      "popular",
      "belong",
      "includes",
      "enhanced",
      "drop-down",
      "option",
      "allowing",
      "selected",
      "categories.",
      "about",
      "settings",
      "see"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "System requirements",
    "content": "The Kubernetes instance embedded in OPTIC Management Toolkit (OMT) is also known as the \"embedded Kubernetes.\" When planning a new installation or an upgrade of an existing deployment that uses the embedded Kubernetes, review the following support matrix information.We always recommend that you follow the installation instructions and install the latest version of the suite. If you have a reason to install an older release, please contact our product management team. Version with .n in the support matrix means that all sub-versions of that major version are supported.Compute environmentsYou can deploy the OPTIC Management Toolkit (OMT) cluster in the following computing environments.Bare metalSee below for the supported operating systems.HypervisorsVirtualization – see belowVirtual Machine host operating systems - see belowVMware ESXi and Microsoft Windows Hyper-V are validated platforms. Other virtualization platforms are technically supported, but haven't been validated by OpenText. ",
    "url": "supportmatrixonprem",
    "filename": "supportmatrixonprem",
    "headings": [
      "Compute environments",
      "Bare metal",
      "Hypervisors",
      "Operating systems",
      "Load balancers",
      "Helm",
      "Databases",
      "NFS",
      "LDAP servers",
      "LDAP authentication in IdM",
      "OPB-based LDAP integration",
      "On-Premises Bridge (OPB)",
      "Federated Identity technologies",
      "SAML 2.0",
      "OAuth 2.0",
      "Browsers",
      "The following are the supported browsers:",
      "Safe-list browsers",
      "Mobile app",
      "Screen resolution"
    ],
    "keywords": [
      "8.8",
      "3.17",
      "2.Load",
      "8.9",
      "9.4",
      "26.2",
      "tenant.The",
      "supports.OMT",
      "9.n10",
      "pages.In",
      "v4.1",
      "view.In",
      "font.For",
      "25.2",
      "25.3",
      "expressions.RTL",
      "v4.2",
      "information.We",
      "2.0On",
      "8.11",
      "elements.When",
      "environments.Bare",
      "2.0",
      "font.In",
      "languages.On",
      "side.When",
      "consistent.In",
      "language.The",
      "aligned.RTL",
      "system",
      "requirements",
      "compute",
      "environments",
      "bare",
      "metal",
      "hypervisors",
      "operating",
      "systems",
      "load",
      "balancers",
      "helm",
      "databases",
      "nfs",
      "ldap",
      "servers",
      "authentication",
      "idm",
      "opb-based",
      "integration",
      "on-premises",
      "bridge",
      "opb",
      "federated",
      "identity",
      "technologies",
      "saml",
      "oauth",
      "browsers",
      "following",
      "supported",
      "safe-list",
      "mobile",
      "app",
      "screen",
      "resolution",
      "language",
      "support",
      "ui",
      "fonts",
      "aviator",
      "virtual",
      "agent",
      "arabic",
      "hebrew",
      "portuguese",
      "portugal",
      "optical",
      "character",
      "recognition",
      "ocr",
      "omt",
      "management",
      "portal",
      "integrations",
      "related",
      "topics",
      "kubernetes",
      "instance",
      "embedded",
      "optic",
      "toolkit",
      "known",
      "kubernetes.",
      "planning",
      "new",
      "installation",
      "upgrade",
      "existing",
      "deployment",
      "uses"
    ],
    "language": "en",
    "word_count": 91,
    "importance_score": 6.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "system requirements",
    "contentLower": "the kubernetes instance embedded in optic management toolkit (omt) is also known as the \"embedded kubernetes.\" when planning a new installation or an upgrade of an existing deployment that uses the embedded kubernetes, review the following support matrix information.we always recommend that you follow the installation instructions and install the latest version of the suite. if you have a reason to install an older release, please contact our product management team. version with .n in the support matrix means that all sub-versions of that major version are supported.compute environmentsyou can deploy the optic management toolkit (omt) cluster in the following computing environments.bare metalsee below for the supported operating systems.hypervisorsvirtualization – see belowvirtual machine host operating systems - see belowvmware esxi and microsoft windows hyper-v are validated platforms. other virtualization platforms are technically supported, but haven't been validated by opentext. ",
    "keywordsLower": [
      "8.8",
      "3.17",
      "2.load",
      "8.9",
      "9.4",
      "26.2",
      "tenant.the",
      "supports.omt",
      "9.n10",
      "pages.in",
      "v4.1",
      "view.in",
      "font.for",
      "25.2",
      "25.3",
      "expressions.rtl",
      "v4.2",
      "information.we",
      "2.0on",
      "8.11",
      "elements.when",
      "environments.bare",
      "2.0",
      "font.in",
      "languages.on",
      "side.when",
      "consistent.in",
      "language.the",
      "aligned.rtl",
      "system",
      "requirements",
      "compute",
      "environments",
      "bare",
      "metal",
      "hypervisors",
      "operating",
      "systems",
      "load",
      "balancers",
      "helm",
      "databases",
      "nfs",
      "ldap",
      "servers",
      "authentication",
      "idm",
      "opb-based",
      "integration",
      "on-premises",
      "bridge",
      "opb",
      "federated",
      "identity",
      "technologies",
      "saml",
      "oauth",
      "browsers",
      "following",
      "supported",
      "safe-list",
      "mobile",
      "app",
      "screen",
      "resolution",
      "language",
      "support",
      "ui",
      "fonts",
      "aviator",
      "virtual",
      "agent",
      "arabic",
      "hebrew",
      "portuguese",
      "portugal",
      "optical",
      "character",
      "recognition",
      "ocr",
      "omt",
      "management",
      "portal",
      "integrations",
      "related",
      "topics",
      "kubernetes",
      "instance",
      "embedded",
      "optic",
      "toolkit",
      "known",
      "kubernetes.",
      "planning",
      "new",
      "installation",
      "upgrade",
      "existing",
      "deployment",
      "uses"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Support matrix for EKS deployment",
    "content": "Cloud deployments and on-premises deployments of the suite basically share the same support matrix (see Support matrix for on-premises deployment), except for the following aspects. We always recommend that you follow the support matrix and use the installation instructions to install the latest version of the suite. If you have a reason to install an older release, please contact our product management team. Version with .n in the support matrix means that all sub-versions of that major version are supported. Supported environments AWS public cloudAWS GovCloud Docker image registry AWS Elastic Container Registry (ECR) Managed Kubernetes clusters Amazon Elastic Kubernetes Service (EKS) versions: 1.33.n, 1.32.n If you are installing your suite, please create an EKS cluster using the latest supported version. If you are upgrading your suite, we recommend that you upgrade the suite first and then upgrade the EKS cluster to the latest supported version. This will help ensure compatibility ",
    "url": "ekssupportmatrix",
    "filename": "ekssupportmatrix",
    "headings": [
      "Supported environments",
      "Docker image registry",
      "Managed Kubernetes clusters",
      "Helm",
      "Operating systems",
      "Databases",
      "Persistent storage"
    ],
    "keywords": [
      "3.17",
      "1.32",
      "1.33",
      "25.3",
      "support",
      "matrix",
      "eks",
      "deployment",
      "supported",
      "environments",
      "docker",
      "image",
      "registry",
      "managed",
      "kubernetes",
      "clusters",
      "helm",
      "operating",
      "systems",
      "databases",
      "persistent",
      "storage",
      "cloud",
      "deployments",
      "on-premises",
      "suite",
      "basically",
      "share",
      "same",
      "see",
      "except",
      "following",
      "aspects.",
      "always",
      "recommend",
      "follow",
      "installation",
      "instructions",
      "install",
      "latest",
      "version",
      "suite.",
      "reason",
      "older",
      "release",
      "please",
      "contact",
      "product",
      "management",
      "team.",
      ".n",
      "means",
      "all",
      "sub-versions",
      "major",
      "supported.",
      "aws",
      "public",
      "cloudaws",
      "govcloud",
      "elastic",
      "container",
      "ecr",
      "amazon",
      "service",
      "versions",
      "1.33.n",
      "1.32.n",
      "installing",
      "create",
      "cluster",
      "version.",
      "upgrading",
      "upgrade",
      "first",
      "help",
      "ensure",
      "compatibility",
      "reduce",
      "risk",
      "issues.",
      "3.17.n",
      "bastion",
      "linux",
      "2023",
      "relational",
      "database",
      "rds",
      "postgresql",
      "17.n",
      "16.n",
      "15.n",
      "14.n",
      "linux.vertica",
      "since",
      "finops",
      "configured",
      "operations",
      "platform",
      "op"
    ],
    "language": "en",
    "word_count": 101,
    "importance_score": 6.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "support matrix for eks deployment",
    "contentLower": "cloud deployments and on-premises deployments of the suite basically share the same support matrix (see support matrix for on-premises deployment), except for the following aspects. we always recommend that you follow the support matrix and use the installation instructions to install the latest version of the suite. if you have a reason to install an older release, please contact our product management team. version with .n in the support matrix means that all sub-versions of that major version are supported. supported environments aws public cloudaws govcloud docker image registry aws elastic container registry (ecr) managed kubernetes clusters amazon elastic kubernetes service (eks) versions: 1.33.n, 1.32.n if you are installing your suite, please create an eks cluster using the latest supported version. if you are upgrading your suite, we recommend that you upgrade the suite first and then upgrade the eks cluster to the latest supported version. this will help ensure compatibility ",
    "keywordsLower": [
      "3.17",
      "1.32",
      "1.33",
      "25.3",
      "support",
      "matrix",
      "eks",
      "deployment",
      "supported",
      "environments",
      "docker",
      "image",
      "registry",
      "managed",
      "kubernetes",
      "clusters",
      "helm",
      "operating",
      "systems",
      "databases",
      "persistent",
      "storage",
      "cloud",
      "deployments",
      "on-premises",
      "suite",
      "basically",
      "share",
      "same",
      "see",
      "except",
      "following",
      "aspects.",
      "always",
      "recommend",
      "follow",
      "installation",
      "instructions",
      "install",
      "latest",
      "version",
      "suite.",
      "reason",
      "older",
      "release",
      "please",
      "contact",
      "product",
      "management",
      "team.",
      ".n",
      "means",
      "all",
      "sub-versions",
      "major",
      "supported.",
      "aws",
      "public",
      "cloudaws",
      "govcloud",
      "elastic",
      "container",
      "ecr",
      "amazon",
      "service",
      "versions",
      "1.33.n",
      "1.32.n",
      "installing",
      "create",
      "cluster",
      "version.",
      "upgrading",
      "upgrade",
      "first",
      "help",
      "ensure",
      "compatibility",
      "reduce",
      "risk",
      "issues.",
      "3.17.n",
      "bastion",
      "linux",
      "2023",
      "relational",
      "database",
      "rds",
      "postgresql",
      "17.n",
      "16.n",
      "15.n",
      "14.n",
      "linux.vertica",
      "since",
      "finops",
      "configured",
      "operations",
      "platform",
      "op"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Sizing considerations for EKS deployment",
    "content": "The performance information provided here is based on tests in an out-of-box environment and for your reference only. Your implementation may consume more resources or require more resources to perform in an acceptable manner. Suite size definitions When you run the suite installer, you will need to select a suite size: Small, Medium, or Large. Different suite sizes require different hardware configurations. The following table describes the available suite sizes. Suite size Small Medium Large Notes Maximum number of concurrent users (including both ESS and IT agent users) 100~400 400~1000 1000~3000 Concurrent users are active users who have logged in to the system to perform operations and consume system resources. There are two types of concurrent users, service portal users and IT agent users. The workload for each user type is defined as: For service portal users: After logging in to the system, each portal user has about 30-minute session duration on the system and will create 1 ~",
    "url": "ekssizing",
    "filename": "ekssizing",
    "headings": [
      "Suite size definitions",
      "Hardware requirements for Service Management (only)",
      "Storage requirements",
      "Hardware requirements for bastion",
      "Additional hardware requirements for OO Containerized",
      "Additional hardware requirements for DND and OO Containerized",
      "Additional hardware requirements for OO Containerized with a dedicated database",
      "Additional hardware requirements for CMP FinOps",
      "Performance tuning for CMP FinOps",
      "Configure node group on your AWS cluster",
      "Update the nodeSelector parameter",
      "Separate ETL and query workloads",
      "Additional hardware requirements for SAM",
      "Additional hardware requirements for UCMDB",
      "Classic UCMDB",
      "Containerized UCMDB",
      "Plan resources for OData integration",
      "Related topics"
    ],
    "keywords": [
      "1.5",
      "2.5",
      "cgro_nodeSelector.yaml",
      "db.r5",
      "0.1",
      "global.oo",
      "1.0.0",
      "0.01",
      "values.yaml",
      "showback.yaml",
      "cgro_copy_stream.yaml",
      "5.2",
      "m5.2x",
      "0.7",
      "1.6",
      "xxx.tgz",
      "r5.4x",
      "5.8",
      "db.m6g",
      "db.r6g",
      "sizing",
      "considerations",
      "eks",
      "deployment",
      "suite",
      "size",
      "definitions",
      "hardware",
      "requirements",
      "service",
      "management",
      "storage",
      "bastion",
      "additional",
      "oo",
      "containerized",
      "dnd",
      "dedicated",
      "database",
      "cmp",
      "finops",
      "performance",
      "tuning",
      "configure",
      "node",
      "group",
      "aws",
      "cluster",
      "update",
      "nodeselector",
      "parameter",
      "separate",
      "etl",
      "query",
      "workloads",
      "sam",
      "ucmdb",
      "classic",
      "plan",
      "resources",
      "odata",
      "integration",
      "related",
      "topics",
      "information",
      "provided",
      "here",
      "based",
      "tests",
      "out-of-box",
      "environment",
      "reference",
      "only.",
      "implementation",
      "consume",
      "require",
      "perform",
      "acceptable",
      "manner.",
      "run",
      "installer",
      "need",
      "select",
      "small",
      "medium",
      "large.",
      "different",
      "sizes",
      "configurations.",
      "following",
      "table",
      "describes",
      "available",
      "sizes.",
      "large",
      "notes",
      "maximum",
      "number",
      "concurrent",
      "users"
    ],
    "language": "en",
    "word_count": 109,
    "importance_score": 6.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "sizing considerations for eks deployment",
    "contentLower": "the performance information provided here is based on tests in an out-of-box environment and for your reference only. your implementation may consume more resources or require more resources to perform in an acceptable manner. suite size definitions when you run the suite installer, you will need to select a suite size: small, medium, or large. different suite sizes require different hardware configurations. the following table describes the available suite sizes. suite size small medium large notes maximum number of concurrent users (including both ess and it agent users) 100~400 400~1000 1000~3000 concurrent users are active users who have logged in to the system to perform operations and consume system resources. there are two types of concurrent users, service portal users and it agent users. the workload for each user type is defined as: for service portal users: after logging in to the system, each portal user has about 30-minute session duration on the system and will create 1 ~",
    "keywordsLower": [
      "1.5",
      "2.5",
      "cgro_nodeselector.yaml",
      "db.r5",
      "0.1",
      "global.oo",
      "1.0.0",
      "0.01",
      "values.yaml",
      "showback.yaml",
      "cgro_copy_stream.yaml",
      "5.2",
      "m5.2x",
      "0.7",
      "1.6",
      "xxx.tgz",
      "r5.4x",
      "5.8",
      "db.m6g",
      "db.r6g",
      "sizing",
      "considerations",
      "eks",
      "deployment",
      "suite",
      "size",
      "definitions",
      "hardware",
      "requirements",
      "service",
      "management",
      "storage",
      "bastion",
      "additional",
      "oo",
      "containerized",
      "dnd",
      "dedicated",
      "database",
      "cmp",
      "finops",
      "performance",
      "tuning",
      "configure",
      "node",
      "group",
      "aws",
      "cluster",
      "update",
      "nodeselector",
      "parameter",
      "separate",
      "etl",
      "query",
      "workloads",
      "sam",
      "ucmdb",
      "classic",
      "plan",
      "resources",
      "odata",
      "integration",
      "related",
      "topics",
      "information",
      "provided",
      "here",
      "based",
      "tests",
      "out-of-box",
      "environment",
      "reference",
      "only.",
      "implementation",
      "consume",
      "require",
      "perform",
      "acceptable",
      "manner.",
      "run",
      "installer",
      "need",
      "select",
      "small",
      "medium",
      "large.",
      "different",
      "sizes",
      "configurations.",
      "following",
      "table",
      "describes",
      "available",
      "sizes.",
      "large",
      "notes",
      "maximum",
      "number",
      "concurrent",
      "users"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Transfer images beforehand",
    "content": "Role Location Suite administrator Bastion node Before you deploy the suite, you need to download the suite images from Docker Hub or other registries and then upload the images to your registry. If you have already uploaded images to your registry, skip this step. Generate the Image Set Before downloading and uploading the images, you need to generate the image set for your installation. Use the steps below to generate a download bundle for helm based installations. Log on to the bastion or first control plane node, and then navigate to the $CDF_HOME/tools/generate-download directory. Run the generate_download_bundle.sh command together with the options required by your deployment. For the full list of command options, run the command with the -h option. generate_download_bundle.sh -f <image_set_file> [ -d <output_directory>] Where: <image_set_file>: The absolute path to the image set file. To locate this file, untar the esm-1.0.0+2x.x-xxx.tar  and check the scripts folder. <output_dir",
    "url": "eksdownloadimage",
    "filename": "eksdownloadimage",
    "headings": [
      "Generate the Image Set",
      "Download the required installation images",
      "Upload the images"
    ],
    "keywords": [
      "downloadimages.sh",
      "dkr.ecr",
      "xxx.tar",
      "download.zip",
      "https://PROXY_SERVER:PORT",
      "1.0.0",
      "set.json",
      "amazonaws.com",
      "uploadimages.sh",
      "generate_download_bundle.sh",
      "20240129084204.log",
      "http://PROXY_SERVER:PORT",
      "transfer",
      "images",
      "beforehand",
      "generate",
      "image",
      "set",
      "download",
      "required",
      "installation",
      "upload",
      "role",
      "location",
      "suite",
      "administrator",
      "bastion",
      "node",
      "before",
      "deploy",
      "need",
      "docker",
      "hub",
      "registries",
      "registry.",
      "already",
      "uploaded",
      "registry",
      "skip",
      "step.",
      "downloading",
      "uploading",
      "installation.",
      "steps",
      "below",
      "bundle",
      "helm",
      "based",
      "installations.",
      "log",
      "first",
      "control",
      "plane",
      "navigate",
      "tools",
      "generate-download",
      "directory.",
      "run",
      "command",
      "together",
      "options",
      "deployment.",
      "full",
      "list",
      "-h",
      "option.",
      "-f",
      "-d",
      "absolute",
      "path",
      "file.",
      "locate",
      "file",
      "untar",
      "esm-1.0.0",
      "2x.x-xxx.tar",
      "check",
      "scripts",
      "folder.",
      "directory",
      "script",
      "saves",
      "offline-download.zip",
      "don",
      "specify",
      "value",
      "default",
      "current",
      "working",
      "example",
      "commercial",
      "deployment",
      "tmp",
      "fedramp",
      "see",
      "similar",
      "message",
      "indicating",
      "successfully",
      "generated"
    ],
    "language": "en",
    "word_count": 91,
    "importance_score": 4.5,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "transfer images beforehand",
    "contentLower": "role location suite administrator bastion node before you deploy the suite, you need to download the suite images from docker hub or other registries and then upload the images to your registry. if you have already uploaded images to your registry, skip this step. generate the image set before downloading and uploading the images, you need to generate the image set for your installation. use the steps below to generate a download bundle for helm based installations. log on to the bastion or first control plane node, and then navigate to the $cdf_home/tools/generate-download directory. run the generate_download_bundle.sh command together with the options required by your deployment. for the full list of command options, run the command with the -h option. generate_download_bundle.sh -f <image_set_file> [ -d <output_directory>] where: <image_set_file>: the absolute path to the image set file. to locate this file, untar the esm-1.0.0+2x.x-xxx.tar  and check the scripts folder. <output_dir",
    "keywordsLower": [
      "downloadimages.sh",
      "dkr.ecr",
      "xxx.tar",
      "download.zip",
      "https://proxy_server:port",
      "1.0.0",
      "set.json",
      "amazonaws.com",
      "uploadimages.sh",
      "generate_download_bundle.sh",
      "20240129084204.log",
      "http://proxy_server:port",
      "transfer",
      "images",
      "beforehand",
      "generate",
      "image",
      "set",
      "download",
      "required",
      "installation",
      "upload",
      "role",
      "location",
      "suite",
      "administrator",
      "bastion",
      "node",
      "before",
      "deploy",
      "need",
      "docker",
      "hub",
      "registries",
      "registry.",
      "already",
      "uploaded",
      "registry",
      "skip",
      "step.",
      "downloading",
      "uploading",
      "installation.",
      "steps",
      "below",
      "bundle",
      "helm",
      "based",
      "installations.",
      "log",
      "first",
      "control",
      "plane",
      "navigate",
      "tools",
      "generate-download",
      "directory.",
      "run",
      "command",
      "together",
      "options",
      "deployment.",
      "full",
      "list",
      "-h",
      "option.",
      "-f",
      "-d",
      "absolute",
      "path",
      "file.",
      "locate",
      "file",
      "untar",
      "esm-1.0.0",
      "2x.x-xxx.tar",
      "check",
      "scripts",
      "folder.",
      "directory",
      "script",
      "saves",
      "offline-download.zip",
      "don",
      "specify",
      "value",
      "default",
      "current",
      "working",
      "example",
      "commercial",
      "deployment",
      "tmp",
      "fedramp",
      "see",
      "similar",
      "message",
      "indicating",
      "successfully",
      "generated"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Support matrix for Azure deployment",
    "content": "Cloud deployments and on-premises deployments of the suite share the same support matrix (see Support matrix for on-premises deployment), except for the following aspects. We always recommend that you follow the support matrix and use the installation instructions to install the latest version of the suite. If you have a reason to install an older release, please contact our product management team. Version with .n in the support matrix means that all sub-versions of that major version are supported. Supported environments Azure public cloud Docker image registry Azure Container Registry (ACR) Managed Kubernetes clusters Azure Kubernetes Service (AKS) versions: 1.33.n, 1.32.n If you are installing your suite, please create an AKS cluster using the latest supported version. If you are upgrading your suite, we recommend that you upgrade the suite first and then upgrade the AKS cluster to the latest supported version. This will help ensure compatibility and reduce the risk of issues. Helm",
    "url": "akssupportmatrix",
    "filename": "akssupportmatrix",
    "headings": [
      "Supported environments",
      "Docker image registry",
      "Managed Kubernetes clusters",
      "Helm",
      "Operating systems",
      "Databases",
      "Persistent storage"
    ],
    "keywords": [
      "3.17",
      "25.3",
      "22.04",
      "1.32",
      "1.33",
      "support",
      "matrix",
      "azure",
      "deployment",
      "supported",
      "environments",
      "docker",
      "image",
      "registry",
      "managed",
      "kubernetes",
      "clusters",
      "helm",
      "operating",
      "systems",
      "databases",
      "persistent",
      "storage",
      "cloud",
      "deployments",
      "on-premises",
      "suite",
      "share",
      "same",
      "see",
      "except",
      "following",
      "aspects.",
      "always",
      "recommend",
      "follow",
      "installation",
      "instructions",
      "install",
      "latest",
      "version",
      "suite.",
      "reason",
      "older",
      "release",
      "please",
      "contact",
      "product",
      "management",
      "team.",
      ".n",
      "means",
      "all",
      "sub-versions",
      "major",
      "supported.",
      "public",
      "container",
      "acr",
      "service",
      "aks",
      "versions",
      "1.33.n",
      "1.32.n",
      "installing",
      "create",
      "cluster",
      "version.",
      "upgrading",
      "upgrade",
      "first",
      "help",
      "ensure",
      "compatibility",
      "reduce",
      "risk",
      "issues.",
      "3.17.n",
      "bastion",
      "rocky",
      "linux",
      "9.n",
      "minor",
      "ubuntu",
      "cloud-based",
      "production",
      "environment",
      "requires",
      "external",
      "database",
      "instance",
      "postgresql",
      "flexible",
      "server",
      "17.n",
      "16.n",
      "15.n",
      "14.nvertica",
      "since",
      "finops"
    ],
    "language": "en",
    "word_count": 101,
    "importance_score": 6.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "support matrix for azure deployment",
    "contentLower": "cloud deployments and on-premises deployments of the suite share the same support matrix (see support matrix for on-premises deployment), except for the following aspects. we always recommend that you follow the support matrix and use the installation instructions to install the latest version of the suite. if you have a reason to install an older release, please contact our product management team. version with .n in the support matrix means that all sub-versions of that major version are supported. supported environments azure public cloud docker image registry azure container registry (acr) managed kubernetes clusters azure kubernetes service (aks) versions: 1.33.n, 1.32.n if you are installing your suite, please create an aks cluster using the latest supported version. if you are upgrading your suite, we recommend that you upgrade the suite first and then upgrade the aks cluster to the latest supported version. this will help ensure compatibility and reduce the risk of issues. helm",
    "keywordsLower": [
      "3.17",
      "25.3",
      "22.04",
      "1.32",
      "1.33",
      "support",
      "matrix",
      "azure",
      "deployment",
      "supported",
      "environments",
      "docker",
      "image",
      "registry",
      "managed",
      "kubernetes",
      "clusters",
      "helm",
      "operating",
      "systems",
      "databases",
      "persistent",
      "storage",
      "cloud",
      "deployments",
      "on-premises",
      "suite",
      "share",
      "same",
      "see",
      "except",
      "following",
      "aspects.",
      "always",
      "recommend",
      "follow",
      "installation",
      "instructions",
      "install",
      "latest",
      "version",
      "suite.",
      "reason",
      "older",
      "release",
      "please",
      "contact",
      "product",
      "management",
      "team.",
      ".n",
      "means",
      "all",
      "sub-versions",
      "major",
      "supported.",
      "public",
      "container",
      "acr",
      "service",
      "aks",
      "versions",
      "1.33.n",
      "1.32.n",
      "installing",
      "create",
      "cluster",
      "version.",
      "upgrading",
      "upgrade",
      "first",
      "help",
      "ensure",
      "compatibility",
      "reduce",
      "risk",
      "issues.",
      "3.17.n",
      "bastion",
      "rocky",
      "linux",
      "9.n",
      "minor",
      "ubuntu",
      "cloud-based",
      "production",
      "environment",
      "requires",
      "external",
      "database",
      "instance",
      "postgresql",
      "flexible",
      "server",
      "17.n",
      "16.n",
      "15.n",
      "14.nvertica",
      "since",
      "finops"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Sizing considerations for Azure deployment",
    "content": "The performance information provided here is based on tests in an out-of-box environment and for your reference only. Your implementation may consume more resources or require more resources to perform in an acceptable manner. SMA size definitions When you run the suite installer, you will need to select a suite size: Small, Medium, or Large. Different suite sizes require different hardware configurations. The following table describes the available suite sizes. Suite size Small Medium Large Notes Maximum number of concurrent users (including both ESS and IT agent users) 100~400 400~1000 1000~3000 Concurrent users are active users who have logged in to the system to perform operations and consume system resources. There are two types of concurrent users, service portal users and IT agent users. Workload for each user type is defined as: For service portal users: After logging in to the system, each portal user has an about 30 minutes duration session on the system and will create 1 ~ 2",
    "url": "akssizing",
    "filename": "akssizing",
    "headings": [
      "SMA size definitions",
      "Hardware requirements for SMA (SMA only)",
      "Storage requirement",
      "Minimal Azure NetApp Files Service Level",
      "Minimal Azure Files Service Level",
      "Hardware requirements for bastion",
      "Additional hardware requirements for OO Containerized",
      "Additional hardware requirements for DND & OO Containerized",
      "Additional hardware requirements for CMP FinOps",
      "Performance tuning for CMP FinOps",
      "Configure node group on your Azure cluster",
      "Update the nodeSelector parameter",
      "Separate ETL and query workloads",
      "Additional hardware requirements for UCMDB",
      "Classic UCMDB",
      "Containerized UCMDB",
      "Tuning configurations"
    ],
    "keywords": [
      "1.5",
      "showback.yaml",
      "cgro_copy_stream.yaml",
      "5.2",
      "1.0.0",
      "cgro_nodeSelector.yaml",
      "0.7",
      "requests.For",
      "values.yaml",
      "1.6",
      "oo_size_values.yaml",
      "5.8",
      "xxx.tgz",
      "sizing",
      "considerations",
      "azure",
      "deployment",
      "sma",
      "size",
      "definitions",
      "hardware",
      "requirements",
      "storage",
      "requirement",
      "minimal",
      "netapp",
      "files",
      "service",
      "level",
      "bastion",
      "additional",
      "oo",
      "containerized",
      "dnd",
      "cmp",
      "finops",
      "performance",
      "tuning",
      "configure",
      "node",
      "group",
      "cluster",
      "update",
      "nodeselector",
      "parameter",
      "separate",
      "etl",
      "query",
      "workloads",
      "ucmdb",
      "classic",
      "configurations",
      "information",
      "provided",
      "here",
      "based",
      "tests",
      "out-of-box",
      "environment",
      "reference",
      "only.",
      "implementation",
      "consume",
      "resources",
      "require",
      "perform",
      "acceptable",
      "manner.",
      "run",
      "suite",
      "installer",
      "need",
      "select",
      "small",
      "medium",
      "large.",
      "different",
      "sizes",
      "configurations.",
      "following",
      "table",
      "describes",
      "available",
      "sizes.",
      "large",
      "notes",
      "maximum",
      "number",
      "concurrent",
      "users",
      "including",
      "both",
      "ess",
      "agent",
      "100",
      "400",
      "1000",
      "3000",
      "active",
      "logged"
    ],
    "language": "en",
    "word_count": 111,
    "importance_score": 6.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "sizing considerations for azure deployment",
    "contentLower": "the performance information provided here is based on tests in an out-of-box environment and for your reference only. your implementation may consume more resources or require more resources to perform in an acceptable manner. sma size definitions when you run the suite installer, you will need to select a suite size: small, medium, or large. different suite sizes require different hardware configurations. the following table describes the available suite sizes. suite size small medium large notes maximum number of concurrent users (including both ess and it agent users) 100~400 400~1000 1000~3000 concurrent users are active users who have logged in to the system to perform operations and consume system resources. there are two types of concurrent users, service portal users and it agent users. workload for each user type is defined as: for service portal users: after logging in to the system, each portal user has an about 30 minutes duration session on the system and will create 1 ~ 2",
    "keywordsLower": [
      "1.5",
      "showback.yaml",
      "cgro_copy_stream.yaml",
      "5.2",
      "1.0.0",
      "cgro_nodeselector.yaml",
      "0.7",
      "requests.for",
      "values.yaml",
      "1.6",
      "oo_size_values.yaml",
      "5.8",
      "xxx.tgz",
      "sizing",
      "considerations",
      "azure",
      "deployment",
      "sma",
      "size",
      "definitions",
      "hardware",
      "requirements",
      "storage",
      "requirement",
      "minimal",
      "netapp",
      "files",
      "service",
      "level",
      "bastion",
      "additional",
      "oo",
      "containerized",
      "dnd",
      "cmp",
      "finops",
      "performance",
      "tuning",
      "configure",
      "node",
      "group",
      "cluster",
      "update",
      "nodeselector",
      "parameter",
      "separate",
      "etl",
      "query",
      "workloads",
      "ucmdb",
      "classic",
      "configurations",
      "information",
      "provided",
      "here",
      "based",
      "tests",
      "out-of-box",
      "environment",
      "reference",
      "only.",
      "implementation",
      "consume",
      "resources",
      "require",
      "perform",
      "acceptable",
      "manner.",
      "run",
      "suite",
      "installer",
      "need",
      "select",
      "small",
      "medium",
      "large.",
      "different",
      "sizes",
      "configurations.",
      "following",
      "table",
      "describes",
      "available",
      "sizes.",
      "large",
      "notes",
      "maximum",
      "number",
      "concurrent",
      "users",
      "including",
      "both",
      "ess",
      "agent",
      "100",
      "400",
      "1000",
      "3000",
      "active",
      "logged"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Transfer images beforehand",
    "content": "Role Location Suite administrator Bastion node Before you deploy the suite, you need to download the suite images from Docker Hub or other registries and then upload the images to your registry. If you have already uploaded images to your registry, skip this step. Generate the image set for Helm installation Before downloading and uploading the images, you need to generate the image set. Use the steps below to generate a download bundle for Helm based installations. Log on to the bastion node, and then navigate to the $CDF_HOME/tools/generate-download directory. Run the generate_download_bundle.sh command together with the options required by your deployment. For the full list of command options, run the command with the -h option. generate_download_bundle.sh -f <image_set_file> [ -d <output_directory>] Where: <image_set_file>: The absolute path to the image set file. To locate this file, unzip ESM_Helm_Chart-2x.x.x.zip and check the /scripts/image_sets folder. <output_directory>: The ",
    "url": "aksdownloadimage",
    "filename": "aksdownloadimage",
    "headings": [
      "Generate the image set for Helm installation",
      "Download the container images",
      "Upload the images"
    ],
    "keywords": [
      "downloadimages.sh",
      "http://PROXY_SERVER:PORT",
      "https://PROXY_SERVER:PORT",
      "download.zip",
      "http://image-registry.com",
      "set.json",
      "x.zip",
      "20240129084204.log",
      "generate_download_bundle.sh",
      "uploadimages.sh",
      "https://image-registry.com",
      "registry.com",
      "transfer",
      "images",
      "beforehand",
      "generate",
      "image",
      "set",
      "helm",
      "installation",
      "download",
      "container",
      "upload",
      "role",
      "location",
      "suite",
      "administrator",
      "bastion",
      "node",
      "before",
      "deploy",
      "need",
      "docker",
      "hub",
      "registries",
      "registry.",
      "already",
      "uploaded",
      "registry",
      "skip",
      "step.",
      "downloading",
      "uploading",
      "set.",
      "steps",
      "below",
      "bundle",
      "based",
      "installations.",
      "log",
      "navigate",
      "tools",
      "generate-download",
      "directory.",
      "run",
      "command",
      "together",
      "options",
      "required",
      "deployment.",
      "full",
      "list",
      "-h",
      "option.",
      "-f",
      "-d",
      "absolute",
      "path",
      "file.",
      "locate",
      "file",
      "unzip",
      "check",
      "scripts",
      "folder.",
      "directory",
      "script",
      "saves",
      "offline-download.zip",
      "don",
      "specify",
      "value",
      "default",
      "current",
      "working",
      "example",
      "tmp",
      "see",
      "similar",
      "message",
      "indicating",
      "successfully",
      "generated",
      "info",
      "under",
      "details",
      "please",
      "refer",
      "contains",
      "bundle."
    ],
    "language": "en",
    "word_count": 88,
    "importance_score": 4.5,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "transfer images beforehand",
    "contentLower": "role location suite administrator bastion node before you deploy the suite, you need to download the suite images from docker hub or other registries and then upload the images to your registry. if you have already uploaded images to your registry, skip this step. generate the image set for helm installation before downloading and uploading the images, you need to generate the image set. use the steps below to generate a download bundle for helm based installations. log on to the bastion node, and then navigate to the $cdf_home/tools/generate-download directory. run the generate_download_bundle.sh command together with the options required by your deployment. for the full list of command options, run the command with the -h option. generate_download_bundle.sh -f <image_set_file> [ -d <output_directory>] where: <image_set_file>: the absolute path to the image set file. to locate this file, unzip esm_helm_chart-2x.x.x.zip and check the /scripts/image_sets folder. <output_directory>: the ",
    "keywordsLower": [
      "downloadimages.sh",
      "http://proxy_server:port",
      "https://proxy_server:port",
      "download.zip",
      "http://image-registry.com",
      "set.json",
      "x.zip",
      "20240129084204.log",
      "generate_download_bundle.sh",
      "uploadimages.sh",
      "https://image-registry.com",
      "registry.com",
      "transfer",
      "images",
      "beforehand",
      "generate",
      "image",
      "set",
      "helm",
      "installation",
      "download",
      "container",
      "upload",
      "role",
      "location",
      "suite",
      "administrator",
      "bastion",
      "node",
      "before",
      "deploy",
      "need",
      "docker",
      "hub",
      "registries",
      "registry.",
      "already",
      "uploaded",
      "registry",
      "skip",
      "step.",
      "downloading",
      "uploading",
      "set.",
      "steps",
      "below",
      "bundle",
      "based",
      "installations.",
      "log",
      "navigate",
      "tools",
      "generate-download",
      "directory.",
      "run",
      "command",
      "together",
      "options",
      "required",
      "deployment.",
      "full",
      "list",
      "-h",
      "option.",
      "-f",
      "-d",
      "absolute",
      "path",
      "file.",
      "locate",
      "file",
      "unzip",
      "check",
      "scripts",
      "folder.",
      "directory",
      "script",
      "saves",
      "offline-download.zip",
      "don",
      "specify",
      "value",
      "default",
      "current",
      "working",
      "example",
      "tmp",
      "see",
      "similar",
      "message",
      "indicating",
      "successfully",
      "generated",
      "info",
      "under",
      "details",
      "please",
      "refer",
      "contains",
      "bundle."
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Subscribe premium Azure Files for UD/UCMDB",
    "content": "This release only supports Azure Files as the storage service of CMS on Azure. Follow the steps in this section to create and configure Azure file shares. Create premium Azure file shares Role Location Storage Admin Bastion node To create and configure premium Azure file shares for CMS, log on to the bastion and follow these steps: The FileStorage account to use CMS Azure file share is the same one that you created when you create premium Azure file shares for SMAX. Run the following command to get the key of the created FileStorage account: az storage account keys list \\ --resource-group <resource_group_name> \\ --account-name <storage_account_name> \\ --query \"[0].value\" | tr -d '\"' In this command, <resource_group_name> is the name of the resource group you created on the Build AKS cluster page. Do NOT use your cluster's resource group name with the format MC_<resource_group>_<aks_cluster_name>_<location>. <storage_account_name> is the name of the created FileStorage account when you ",
    "url": "aksazurefilecms",
    "filename": "aksazurefilecms",
    "headings": [
      "Create premium Azure file shares",
      "Configure UD/UCMDB volumes"
    ],
    "keywords": [
      "uducmdb",
      "71.8",
      "i.yaml",
      "requirement.Copy",
      "createCMSPV.sh",
      "azurepvtemplate.yaml",
      "5.0",
      "0.0713496",
      "5.1",
      "small.img",
      "mountazurefile.sh",
      "volumeName.yaml",
      "subscribe",
      "premium",
      "azure",
      "files",
      "ud",
      "ucmdb",
      "create",
      "file",
      "shares",
      "configure",
      "volumes",
      "release",
      "supports",
      "storage",
      "service",
      "cms",
      "azure.",
      "follow",
      "steps",
      "section",
      "shares.",
      "role",
      "location",
      "admin",
      "bastion",
      "node",
      "log",
      "filestorage",
      "account",
      "share",
      "same",
      "one",
      "created",
      "smax.",
      "run",
      "following",
      "command",
      "get",
      "key",
      "az",
      "keys",
      "list",
      "--resource-group",
      "--account-name",
      "--query",
      ".value",
      "tr",
      "-d",
      "name",
      "resource",
      "group",
      "build",
      "aks",
      "cluster",
      "page.",
      "format",
      "running",
      "command.",
      "--account-key",
      "--name",
      "--quota",
      "got",
      "previous",
      "step.",
      "specify",
      "cms.",
      "example",
      "size",
      "gb",
      "referring",
      "sizing",
      "recommendations.",
      "greater",
      "less",
      "equal",
      "tb",
      "5120",
      "once",
      "ready",
      "set",
      "store",
      "all",
      "data",
      "mount",
      "storing",
      "sudo",
      "commands",
      "creating"
    ],
    "language": "en",
    "word_count": 99,
    "importance_score": 3.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "subscribe premium azure files for ud/ucmdb",
    "contentLower": "this release only supports azure files as the storage service of cms on azure. follow the steps in this section to create and configure azure file shares. create premium azure file shares role location storage admin bastion node to create and configure premium azure file shares for cms, log on to the bastion and follow these steps: the filestorage account to use cms azure file share is the same one that you created when you create premium azure file shares for smax. run the following command to get the key of the created filestorage account: az storage account keys list \\ --resource-group <resource_group_name> \\ --account-name <storage_account_name> \\ --query \"[0].value\" | tr -d '\"' in this command, <resource_group_name> is the name of the resource group you created on the build aks cluster page. do not use your cluster's resource group name with the format mc_<resource_group>_<aks_cluster_name>_<location>. <storage_account_name> is the name of the created filestorage account when you ",
    "keywordsLower": [
      "uducmdb",
      "71.8",
      "i.yaml",
      "requirement.copy",
      "createcmspv.sh",
      "azurepvtemplate.yaml",
      "5.0",
      "0.0713496",
      "5.1",
      "small.img",
      "mountazurefile.sh",
      "volumename.yaml",
      "subscribe",
      "premium",
      "azure",
      "files",
      "ud",
      "ucmdb",
      "create",
      "file",
      "shares",
      "configure",
      "volumes",
      "release",
      "supports",
      "storage",
      "service",
      "cms",
      "azure.",
      "follow",
      "steps",
      "section",
      "shares.",
      "role",
      "location",
      "admin",
      "bastion",
      "node",
      "log",
      "filestorage",
      "account",
      "share",
      "same",
      "one",
      "created",
      "smax.",
      "run",
      "following",
      "command",
      "get",
      "key",
      "az",
      "keys",
      "list",
      "--resource-group",
      "--account-name",
      "--query",
      ".value",
      "tr",
      "-d",
      "name",
      "resource",
      "group",
      "build",
      "aks",
      "cluster",
      "page.",
      "format",
      "running",
      "command.",
      "--account-key",
      "--name",
      "--quota",
      "got",
      "previous",
      "step.",
      "specify",
      "cms.",
      "example",
      "size",
      "gb",
      "referring",
      "sizing",
      "recommendations.",
      "greater",
      "less",
      "equal",
      "tb",
      "5120",
      "once",
      "ready",
      "set",
      "store",
      "all",
      "data",
      "mount",
      "storing",
      "sudo",
      "commands",
      "creating"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "System requirements",
    "content": "This section provides information about the software and hardware requirements for installing the Audit service. Helm chart v3.6.3 and later SMAX environment 25.1 and later Operating systems Same as that recommended by SMAX. Kubernetes Same as that recommended by SMAX. Database Same as that recommended by SMAX. NFS Same as that recommended by SMAX. Browsers Latest Edge and Chromium based Edge Latest Chrome Latest Firefox Screen resolution Same as that recommended by SMAX. Language support Same as that recommended by SMAX for the Service Portal. Related topic For more information on the system requirements for SMAX, see System requirements.",
    "url": "131-systemreqs",
    "filename": "131-systemreqs",
    "headings": [
      "Helm chart",
      "SMAX environment",
      "Operating systems",
      "Kubernetes",
      "Database",
      "NFS",
      "Browsers",
      "Screen resolution",
      "Language support",
      "Related topic"
    ],
    "keywords": [
      "v3.6.3",
      "25.1",
      "system",
      "requirements",
      "helm",
      "chart",
      "smax",
      "environment",
      "operating",
      "systems",
      "kubernetes",
      "database",
      "nfs",
      "browsers",
      "screen",
      "resolution",
      "language",
      "support",
      "related",
      "topic",
      "section",
      "provides",
      "information",
      "about",
      "software",
      "hardware",
      "installing",
      "audit",
      "service.",
      "later",
      "same",
      "recommended",
      "smax.",
      "latest",
      "edge",
      "chromium",
      "based",
      "chrome",
      "firefox",
      "service",
      "portal.",
      "see",
      "requirements."
    ],
    "language": "en",
    "word_count": 68,
    "importance_score": 5.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "system requirements",
    "contentLower": "this section provides information about the software and hardware requirements for installing the audit service. helm chart v3.6.3 and later smax environment 25.1 and later operating systems same as that recommended by smax. kubernetes same as that recommended by smax. database same as that recommended by smax. nfs same as that recommended by smax. browsers latest edge and chromium based edge latest chrome latest firefox screen resolution same as that recommended by smax. language support same as that recommended by smax for the service portal. related topic for more information on the system requirements for smax, see system requirements.",
    "keywordsLower": [
      "v3.6.3",
      "25.1",
      "system",
      "requirements",
      "helm",
      "chart",
      "smax",
      "environment",
      "operating",
      "systems",
      "kubernetes",
      "database",
      "nfs",
      "browsers",
      "screen",
      "resolution",
      "language",
      "support",
      "related",
      "topic",
      "section",
      "provides",
      "information",
      "about",
      "software",
      "hardware",
      "installing",
      "audit",
      "service.",
      "later",
      "same",
      "recommended",
      "smax.",
      "latest",
      "edge",
      "chromium",
      "based",
      "chrome",
      "firefox",
      "service",
      "portal.",
      "see",
      "requirements."
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Support matrix for GCP deployment",
    "content": "Cloud deployments and on-premises deployments of the suite share the same support matrix (see Support matrix for on-premises deployment), except for the following aspects. We always recommend that you follow the support matrix and use the installation instructions to install the latest version of the suite. If you have a reason to install an older release, please contact our product management team. You can't install the following capabilities on GCP: Operations Orchestration (OO) Containerized, Design and Deploy (DND), and Cloud Management Platform (CMP) FinOps. Version with .n in the support matrix means that all sub-versions of that major version are supported. Supported environments Google Public Cloud Docker image registry Artifact Registry Managed Kubernetes clusters Google Kubernetes Engine (GKE) versions: 1.32.n, 133.n If you are installing the Suite, please create a GKE cluster using the latest supported version of Kubernetes. If you are upgrading the Suite, we recommend that ",
    "url": "gcpsupportmatrix",
    "filename": "gcpsupportmatrix",
    "headings": [
      "Supported environments",
      "Docker image registry",
      "Managed Kubernetes clusters",
      "Helm",
      "Operating systems",
      "Databases",
      "Persistent storage"
    ],
    "keywords": [
      "1.32",
      "3.17",
      "support",
      "matrix",
      "gcp",
      "deployment",
      "supported",
      "environments",
      "docker",
      "image",
      "registry",
      "managed",
      "kubernetes",
      "clusters",
      "helm",
      "operating",
      "systems",
      "databases",
      "persistent",
      "storage",
      "cloud",
      "deployments",
      "on-premises",
      "suite",
      "share",
      "same",
      "see",
      "except",
      "following",
      "aspects.",
      "always",
      "recommend",
      "follow",
      "installation",
      "instructions",
      "install",
      "latest",
      "version",
      "suite.",
      "reason",
      "older",
      "release",
      "please",
      "contact",
      "product",
      "management",
      "team.",
      "capabilities",
      "operations",
      "orchestration",
      "oo",
      "containerized",
      "design",
      "deploy",
      "dnd",
      "platform",
      "cmp",
      "finops.",
      ".n",
      "means",
      "all",
      "sub-versions",
      "major",
      "supported.",
      "google",
      "public",
      "artifact",
      "engine",
      "gke",
      "versions",
      "1.32.n",
      "133.n",
      "installing",
      "create",
      "cluster",
      "kubernetes.",
      "upgrading",
      "upgrade",
      "first",
      "version.",
      "help",
      "ensure",
      "compatibility",
      "reduce",
      "risk",
      "issues.",
      "3.17.n",
      "bastion",
      "rocky",
      "linux",
      "9.n",
      "minor",
      "postgresql",
      "17.n",
      "16.n",
      "15.n",
      "14.n",
      "linuxalloydb",
      "omni",
      "cloud-based"
    ],
    "language": "en",
    "word_count": 101,
    "importance_score": 6.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "support matrix for gcp deployment",
    "contentLower": "cloud deployments and on-premises deployments of the suite share the same support matrix (see support matrix for on-premises deployment), except for the following aspects. we always recommend that you follow the support matrix and use the installation instructions to install the latest version of the suite. if you have a reason to install an older release, please contact our product management team. you can't install the following capabilities on gcp: operations orchestration (oo) containerized, design and deploy (dnd), and cloud management platform (cmp) finops. version with .n in the support matrix means that all sub-versions of that major version are supported. supported environments google public cloud docker image registry artifact registry managed kubernetes clusters google kubernetes engine (gke) versions: 1.32.n, 133.n if you are installing the suite, please create a gke cluster using the latest supported version of kubernetes. if you are upgrading the suite, we recommend that ",
    "keywordsLower": [
      "1.32",
      "3.17",
      "support",
      "matrix",
      "gcp",
      "deployment",
      "supported",
      "environments",
      "docker",
      "image",
      "registry",
      "managed",
      "kubernetes",
      "clusters",
      "helm",
      "operating",
      "systems",
      "databases",
      "persistent",
      "storage",
      "cloud",
      "deployments",
      "on-premises",
      "suite",
      "share",
      "same",
      "see",
      "except",
      "following",
      "aspects.",
      "always",
      "recommend",
      "follow",
      "installation",
      "instructions",
      "install",
      "latest",
      "version",
      "suite.",
      "reason",
      "older",
      "release",
      "please",
      "contact",
      "product",
      "management",
      "team.",
      "capabilities",
      "operations",
      "orchestration",
      "oo",
      "containerized",
      "design",
      "deploy",
      "dnd",
      "platform",
      "cmp",
      "finops.",
      ".n",
      "means",
      "all",
      "sub-versions",
      "major",
      "supported.",
      "google",
      "public",
      "artifact",
      "engine",
      "gke",
      "versions",
      "1.32.n",
      "133.n",
      "installing",
      "create",
      "cluster",
      "kubernetes.",
      "upgrading",
      "upgrade",
      "first",
      "version.",
      "help",
      "ensure",
      "compatibility",
      "reduce",
      "risk",
      "issues.",
      "3.17.n",
      "bastion",
      "rocky",
      "linux",
      "9.n",
      "minor",
      "postgresql",
      "17.n",
      "16.n",
      "15.n",
      "14.n",
      "linuxalloydb",
      "omni",
      "cloud-based"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Sizing considerations for GCP deployment",
    "content": "The performance information provided in this section is based on tests in an out-of-box environment and for your reference only. Your implementation may consume more resources or require more resources to perform in an acceptable manner. Suite size definitions When you run the suite installer, you will need to select a suite size: Small, Medium, or Large. Different suite sizes require different hardware configurations. The following table describes the available suite sizes. Suite size Small Medium Large Notes Maximum number of concurrent users (including both ESS and IT agent users) 100~400 400~1000 1000~3000 Concurrent users are active users who have logged on to the system to perform operations and consume system resources. There are two types of concurrent users, service portal users and IT agent users. The workload for each user type is defined as: For service portal users: After logging in to the system, each portal user has about a 30-minute session duration on the system and wi",
    "url": "gcpsizing",
    "filename": "gcpsizing",
    "headings": [
      "Suite size definitions",
      "Hardware requirements for Suite (Suite only)",
      "Hardware requirements for bastion",
      "Additional hardware requirements for SAM",
      "Additional hardware requirements for UD/UCMDB",
      "UD/UCMDB size definitions",
      "Hardware requirements",
      "Databases",
      "Tuning configuration"
    ],
    "keywords": [
      "1.5",
      "2.5",
      "3.75",
      "information.UD",
      "0.7",
      "requests.For",
      "sizing",
      "considerations",
      "gcp",
      "deployment",
      "suite",
      "size",
      "definitions",
      "hardware",
      "requirements",
      "bastion",
      "additional",
      "sam",
      "ud",
      "ucmdb",
      "databases",
      "tuning",
      "configuration",
      "performance",
      "information",
      "provided",
      "section",
      "based",
      "tests",
      "out-of-box",
      "environment",
      "reference",
      "only.",
      "implementation",
      "consume",
      "resources",
      "require",
      "perform",
      "acceptable",
      "manner.",
      "run",
      "installer",
      "need",
      "select",
      "small",
      "medium",
      "large.",
      "different",
      "sizes",
      "configurations.",
      "following",
      "table",
      "describes",
      "available",
      "sizes.",
      "large",
      "notes",
      "maximum",
      "number",
      "concurrent",
      "users",
      "including",
      "both",
      "ess",
      "agent",
      "100",
      "400",
      "1000",
      "3000",
      "active",
      "logged",
      "system",
      "operations",
      "resources.",
      "there",
      "two",
      "types",
      "service",
      "portal",
      "users.",
      "workload",
      "user",
      "type",
      "defined",
      "after",
      "logging",
      "about",
      "30-minute",
      "session",
      "duration",
      "create",
      "orders",
      "longer",
      "hours",
      "logon",
      "handle",
      "tickets.",
      "assumption",
      "above",
      "calculate"
    ],
    "language": "en",
    "word_count": 108,
    "importance_score": 6.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "sizing considerations for gcp deployment",
    "contentLower": "the performance information provided in this section is based on tests in an out-of-box environment and for your reference only. your implementation may consume more resources or require more resources to perform in an acceptable manner. suite size definitions when you run the suite installer, you will need to select a suite size: small, medium, or large. different suite sizes require different hardware configurations. the following table describes the available suite sizes. suite size small medium large notes maximum number of concurrent users (including both ess and it agent users) 100~400 400~1000 1000~3000 concurrent users are active users who have logged on to the system to perform operations and consume system resources. there are two types of concurrent users, service portal users and it agent users. the workload for each user type is defined as: for service portal users: after logging in to the system, each portal user has about a 30-minute session duration on the system and wi",
    "keywordsLower": [
      "1.5",
      "2.5",
      "3.75",
      "information.ud",
      "0.7",
      "requests.for",
      "sizing",
      "considerations",
      "gcp",
      "deployment",
      "suite",
      "size",
      "definitions",
      "hardware",
      "requirements",
      "bastion",
      "additional",
      "sam",
      "ud",
      "ucmdb",
      "databases",
      "tuning",
      "configuration",
      "performance",
      "information",
      "provided",
      "section",
      "based",
      "tests",
      "out-of-box",
      "environment",
      "reference",
      "only.",
      "implementation",
      "consume",
      "resources",
      "require",
      "perform",
      "acceptable",
      "manner.",
      "run",
      "installer",
      "need",
      "select",
      "small",
      "medium",
      "large.",
      "different",
      "sizes",
      "configurations.",
      "following",
      "table",
      "describes",
      "available",
      "sizes.",
      "large",
      "notes",
      "maximum",
      "number",
      "concurrent",
      "users",
      "including",
      "both",
      "ess",
      "agent",
      "100",
      "400",
      "1000",
      "3000",
      "active",
      "logged",
      "system",
      "operations",
      "resources.",
      "there",
      "two",
      "types",
      "service",
      "portal",
      "users.",
      "workload",
      "user",
      "type",
      "defined",
      "after",
      "logging",
      "about",
      "30-minute",
      "session",
      "duration",
      "create",
      "orders",
      "longer",
      "hours",
      "logon",
      "handle",
      "tickets.",
      "assumption",
      "above",
      "calculate"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Set up IP and external access hostname",
    "content": "Role Location IT / Network administrator GCP Console and DNS provider Since the suite distributes workloads by load balancer, you need to prepare an external access hostname from your DNS provider's side and reserve a static IP address for the load balancer from the GCP Console. Then, bind the hostname with this static IP to allow users to access SMA services using the bound external access hostname. Follow the steps below to generate a static IP for the suite from the GCP Console: Navigate to VPC network > External IP addresses > RESERVE EXTERNAL STATIC ADDRESS. Give a name to this IP. For example, smax-static-ip. Under Network Service Tier, select the current project-level tier. Note If you choose a different tier from the current project-level tier, the installation will fail. Under Type, select Regional. Under Region, select the same region as the prepared VPC. Click RESERVE to save all the settings. After the static IP is reserved successfully, you can map it to your external acce",
    "url": "gcpsetip",
    "filename": "gcpsetip",
    "headings": [
      "External references"
    ],
    "keywords": [
      "set",
      "ip",
      "external",
      "access",
      "hostname",
      "references",
      "role",
      "location",
      "network",
      "administrator",
      "gcp",
      "console",
      "dns",
      "provider",
      "since",
      "suite",
      "distributes",
      "workloads",
      "load",
      "balancer",
      "need",
      "prepare",
      "side",
      "reserve",
      "static",
      "address",
      "console.",
      "bind",
      "allow",
      "users",
      "sma",
      "services",
      "bound",
      "hostname.",
      "follow",
      "steps",
      "below",
      "generate",
      "navigate",
      "vpc",
      "addresses",
      "address.",
      "give",
      "name",
      "ip.",
      "example",
      "smax-static-ip.",
      "under",
      "service",
      "tier",
      "select",
      "current",
      "project-level",
      "tier.",
      "note",
      "choose",
      "different",
      "installation",
      "fail.",
      "type",
      "regional.",
      "region",
      "same",
      "prepared",
      "vpc.",
      "click",
      "save",
      "all",
      "settings.",
      "after",
      "reserved",
      "successfully",
      "map",
      "allocated",
      "side.",
      "information",
      "see",
      "overview."
    ],
    "language": "en",
    "word_count": 114,
    "importance_score": 2.5,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "set up ip and external access hostname",
    "contentLower": "role location it / network administrator gcp console and dns provider since the suite distributes workloads by load balancer, you need to prepare an external access hostname from your dns provider's side and reserve a static ip address for the load balancer from the gcp console. then, bind the hostname with this static ip to allow users to access sma services using the bound external access hostname. follow the steps below to generate a static ip for the suite from the gcp console: navigate to vpc network > external ip addresses > reserve external static address. give a name to this ip. for example, smax-static-ip. under network service tier, select the current project-level tier. note if you choose a different tier from the current project-level tier, the installation will fail. under type, select regional. under region, select the same region as the prepared vpc. click reserve to save all the settings. after the static ip is reserved successfully, you can map it to your external acce",
    "keywordsLower": [
      "set",
      "ip",
      "external",
      "access",
      "hostname",
      "references",
      "role",
      "location",
      "network",
      "administrator",
      "gcp",
      "console",
      "dns",
      "provider",
      "since",
      "suite",
      "distributes",
      "workloads",
      "load",
      "balancer",
      "need",
      "prepare",
      "side",
      "reserve",
      "static",
      "address",
      "console.",
      "bind",
      "allow",
      "users",
      "sma",
      "services",
      "bound",
      "hostname.",
      "follow",
      "steps",
      "below",
      "generate",
      "navigate",
      "vpc",
      "addresses",
      "address.",
      "give",
      "name",
      "ip.",
      "example",
      "smax-static-ip.",
      "under",
      "service",
      "tier",
      "select",
      "current",
      "project-level",
      "tier.",
      "note",
      "choose",
      "different",
      "installation",
      "fail.",
      "type",
      "regional.",
      "region",
      "same",
      "prepared",
      "vpc.",
      "click",
      "save",
      "all",
      "settings.",
      "after",
      "reserved",
      "successfully",
      "map",
      "allocated",
      "side.",
      "information",
      "see",
      "overview."
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Subscribe Cloud Filestore",
    "content": "Role Location Storage administrator GCP Console This topic describes how to use Filestore and Persistent Disk storage services from Google to store the OMT and suite data on GCP. For information about storage sizing and management, see Manage persistent storage for the suite. This release supports Filestore and Persistent Disk storage services  on GCP. FileStore stores data attachments, certificates, and logs used by containerized applications in Kubernetes. It serves as the backend storage for data-volume, config-volume, and logging-volume. Persistent Disk offers high-performance and highly durable block storage for search engines and RabbitMQ. It serves as the backend storage for other volumes. We provide static solution for volumes that use FileStore. For volumes that use Persistent Disks, we provide dynamic solution. Plan the storage solution Filestore static provision and Peristent Disk dynamic provision Enable Filestore and Persistent Disks APIs Subscribe to Filestore service The",
    "url": "gcpstorage",
    "filename": "gcpstorage",
    "headings": [
      "Plan the storage solution",
      "Enabled Filestore and Persistent Disk APIs",
      "Subscribe to Filestore service",
      "Create Filestore instance",
      "Configure NFS volumes",
      "External references"
    ],
    "keywords": [
      "https://console.cloud.google.com",
      "createFileStore.sh",
      "google.com",
      "subscribe",
      "cloud",
      "filestore",
      "plan",
      "storage",
      "solution",
      "enabled",
      "persistent",
      "disk",
      "apis",
      "service",
      "create",
      "instance",
      "configure",
      "nfs",
      "volumes",
      "external",
      "references",
      "role",
      "location",
      "administrator",
      "gcp",
      "console",
      "topic",
      "describes",
      "services",
      "google",
      "store",
      "omt",
      "suite",
      "data",
      "gcp.",
      "information",
      "about",
      "sizing",
      "management",
      "see",
      "manage",
      "suite.",
      "release",
      "supports",
      "stores",
      "attachments",
      "certificates",
      "logs",
      "containerized",
      "applications",
      "kubernetes.",
      "serves",
      "backend",
      "data-volume",
      "config-volume",
      "logging-volume.",
      "offers",
      "high-performance",
      "highly",
      "durable",
      "block",
      "search",
      "engines",
      "rabbitmq.",
      "volumes.",
      "provide",
      "static",
      "filestore.",
      "disks",
      "dynamic",
      "solution.",
      "provision",
      "peristent",
      "enable",
      "instructions",
      "setting",
      "option",
      "provided",
      "following",
      "sections.",
      "either",
      "perisistent",
      "first",
      "them.",
      "enabling",
      "refer",
      "official",
      "documentation",
      "api.",
      "complete",
      "steps",
      "log",
      "platform",
      "https",
      "console.cloud.google.com",
      "click",
      "instances",
      "instance.",
      "under",
      "name"
    ],
    "language": "en",
    "word_count": 99,
    "importance_score": 6.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "subscribe cloud filestore",
    "contentLower": "role location storage administrator gcp console this topic describes how to use filestore and persistent disk storage services from google to store the omt and suite data on gcp. for information about storage sizing and management, see manage persistent storage for the suite. this release supports filestore and persistent disk storage services  on gcp. filestore stores data attachments, certificates, and logs used by containerized applications in kubernetes. it serves as the backend storage for data-volume, config-volume, and logging-volume. persistent disk offers high-performance and highly durable block storage for search engines and rabbitmq. it serves as the backend storage for other volumes. we provide static solution for volumes that use filestore. for volumes that use persistent disks, we provide dynamic solution. plan the storage solution filestore static provision and peristent disk dynamic provision enable filestore and persistent disks apis subscribe to filestore service the",
    "keywordsLower": [
      "https://console.cloud.google.com",
      "createfilestore.sh",
      "google.com",
      "subscribe",
      "cloud",
      "filestore",
      "plan",
      "storage",
      "solution",
      "enabled",
      "persistent",
      "disk",
      "apis",
      "service",
      "create",
      "instance",
      "configure",
      "nfs",
      "volumes",
      "external",
      "references",
      "role",
      "location",
      "administrator",
      "gcp",
      "console",
      "topic",
      "describes",
      "services",
      "google",
      "store",
      "omt",
      "suite",
      "data",
      "gcp.",
      "information",
      "about",
      "sizing",
      "management",
      "see",
      "manage",
      "suite.",
      "release",
      "supports",
      "stores",
      "attachments",
      "certificates",
      "logs",
      "containerized",
      "applications",
      "kubernetes.",
      "serves",
      "backend",
      "data-volume",
      "config-volume",
      "logging-volume.",
      "offers",
      "high-performance",
      "highly",
      "durable",
      "block",
      "search",
      "engines",
      "rabbitmq.",
      "volumes.",
      "provide",
      "static",
      "filestore.",
      "disks",
      "dynamic",
      "solution.",
      "provision",
      "peristent",
      "enable",
      "instructions",
      "setting",
      "option",
      "provided",
      "following",
      "sections.",
      "either",
      "perisistent",
      "first",
      "them.",
      "enabling",
      "refer",
      "official",
      "documentation",
      "api.",
      "complete",
      "steps",
      "log",
      "platform",
      "https",
      "console.cloud.google.com",
      "click",
      "instances",
      "instance.",
      "under",
      "name"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Select the deployment configuration",
    "content": "Log in to the installation portal Copy the installation portal URL to a supported browser. The URL uses the following format: https://<external_access_host>:3000. Log in to the installation portal with the administrator credentials that you created in the bootstrap installation: Username: admin Password: the password you set up when running the bootstrap installation command Click LOGIN. If you exit the installation portal at any point, the installation process pauses. The next time you log in to the portal, the installation process resumes from the point where you stopped earlier. Select the deployment configuration In the installation portal, configure the deployment. Select the suite metadata package on your local machine, and then click UPLOAD. Choose the 24.3 version, and then click NEXT. On the End User License Agreement page, accept the license agreements and data policy. Click Next. The Capabilities page opens. Option Description Notes Service Management Automation (SMA) Servic",
    "url": "gcpselectdeploy",
    "filename": "gcpselectdeploy",
    "headings": [
      "Log in to the installation portal",
      "Select the deployment configuration"
    ],
    "keywords": [
      "24.3",
      "https://<external_access_host>:3000",
      "server.crt",
      "select",
      "deployment",
      "configuration",
      "log",
      "installation",
      "portal",
      "copy",
      "url",
      "supported",
      "browser.",
      "uses",
      "following",
      "format",
      "https",
      "3000.",
      "administrator",
      "credentials",
      "created",
      "bootstrap",
      "username",
      "admin",
      "password",
      "set",
      "running",
      "command",
      "click",
      "login.",
      "exit",
      "any",
      "point",
      "process",
      "pauses.",
      "next",
      "time",
      "resumes",
      "stopped",
      "earlier.",
      "configure",
      "deployment.",
      "suite",
      "metadata",
      "package",
      "local",
      "machine",
      "upload.",
      "choose",
      "version",
      "next.",
      "end",
      "user",
      "license",
      "agreement",
      "page",
      "accept",
      "agreements",
      "data",
      "policy.",
      "capabilities",
      "opens.",
      "option",
      "description",
      "notes",
      "service",
      "management",
      "automation",
      "sma",
      "services",
      "suite.",
      "mandatory",
      "all",
      "customers",
      "manager",
      "smps",
      "required",
      "integrate",
      "external",
      "system",
      "portal.",
      "sma-sm",
      "optional",
      "smax",
      "want",
      "additionally",
      "deploy",
      "one",
      "tenants",
      "environment",
      "software",
      "asset",
      "sam",
      "hardware",
      "discovered",
      "ud",
      "retrieved",
      "new",
      "capability",
      "enables"
    ],
    "language": "en",
    "word_count": 98,
    "importance_score": 4.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "select the deployment configuration",
    "contentLower": "log in to the installation portal copy the installation portal url to a supported browser. the url uses the following format: https://<external_access_host>:3000. log in to the installation portal with the administrator credentials that you created in the bootstrap installation: username: admin password: the password you set up when running the bootstrap installation command click login. if you exit the installation portal at any point, the installation process pauses. the next time you log in to the portal, the installation process resumes from the point where you stopped earlier. select the deployment configuration in the installation portal, configure the deployment. select the suite metadata package on your local machine, and then click upload. choose the 24.3 version, and then click next. on the end user license agreement page, accept the license agreements and data policy. click next. the capabilities page opens. option description notes service management automation (sma) servic",
    "keywordsLower": [
      "24.3",
      "https://<external_access_host>:3000",
      "server.crt",
      "select",
      "deployment",
      "configuration",
      "log",
      "installation",
      "portal",
      "copy",
      "url",
      "supported",
      "browser.",
      "uses",
      "following",
      "format",
      "https",
      "3000.",
      "administrator",
      "credentials",
      "created",
      "bootstrap",
      "username",
      "admin",
      "password",
      "set",
      "running",
      "command",
      "click",
      "login.",
      "exit",
      "any",
      "point",
      "process",
      "pauses.",
      "next",
      "time",
      "resumes",
      "stopped",
      "earlier.",
      "configure",
      "deployment.",
      "suite",
      "metadata",
      "package",
      "local",
      "machine",
      "upload.",
      "choose",
      "version",
      "next.",
      "end",
      "user",
      "license",
      "agreement",
      "page",
      "accept",
      "agreements",
      "data",
      "policy.",
      "capabilities",
      "opens.",
      "option",
      "description",
      "notes",
      "service",
      "management",
      "automation",
      "sma",
      "services",
      "suite.",
      "mandatory",
      "all",
      "customers",
      "manager",
      "smps",
      "required",
      "integrate",
      "external",
      "system",
      "portal.",
      "sma-sm",
      "optional",
      "smax",
      "want",
      "additionally",
      "deploy",
      "one",
      "tenants",
      "environment",
      "software",
      "asset",
      "sam",
      "hardware",
      "discovered",
      "ud",
      "retrieved",
      "new",
      "capability",
      "enables"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Support matrix for OO Containerized in GKE deployment",
    "content": "Cloud deployments and on-premises deployments of the Operations Orchestration (OO) Containerized share the same support matrix, except for the following aspects: Supported environments Google public cloud Docker image registry Google Container Registry (GCR) Managed Kubernetes clusters Google Kubernetes Engine (GKE) v 1.28.x, 1.29.x, 1.30.x Helm If you plan to install OO on the same OMT cluster as the next deployment, where Service Management is the primary deployment, the required Helm version is: Helm 3.16.x Operating systems Bastion:  Rocky Linux 9.x Databases Cloud-based OO production environments require an external database instance. The table below lists the supported and certified databases: Cloud Provider OO external database version Suite external database version GCP PostgreSQL 13.x, 14.x, 15.x, 16.x for Linux PostgreSQL 13.x, 14.x, 15.x, 16.x for Linux for OO Persistent storage Google Cloud Filestore. OO shares the same GCF server with the rest of the suite components. OO o",
    "url": "399-gcpoocsupportmatrix",
    "filename": "399-gcpoocsupportmatrix",
    "headings": [
      "Supported environments",
      "Docker image registry",
      "Managed Kubernetes clusters",
      "Helm",
      "Operating systems",
      "Databases",
      "Persistent storage"
    ],
    "keywords": [
      "1.30",
      "1.28",
      "1.29",
      "3.16",
      "supported.OO",
      "support",
      "matrix",
      "oo",
      "containerized",
      "gke",
      "deployment",
      "supported",
      "environments",
      "docker",
      "image",
      "registry",
      "managed",
      "kubernetes",
      "clusters",
      "helm",
      "operating",
      "systems",
      "databases",
      "persistent",
      "storage",
      "cloud",
      "deployments",
      "on-premises",
      "operations",
      "orchestration",
      "share",
      "same",
      "except",
      "following",
      "aspects",
      "google",
      "public",
      "container",
      "gcr",
      "engine",
      "1.28.x",
      "1.29.x",
      "1.30.x",
      "plan",
      "install",
      "omt",
      "cluster",
      "next",
      "service",
      "management",
      "primary",
      "required",
      "version",
      "3.16.x",
      "bastion",
      "rocky",
      "linux",
      "9.x",
      "cloud-based",
      "production",
      "require",
      "external",
      "database",
      "instance.",
      "table",
      "below",
      "lists",
      "certified",
      "provider",
      "suite",
      "gcp",
      "postgresql",
      "13.x",
      "14.x",
      "15.x",
      "16.x",
      "filestore.",
      "shares",
      "gcf",
      "server",
      "rest",
      "components.",
      "autopilot",
      "operates",
      "independently",
      "sm",
      "both",
      "layers.",
      "volume",
      "pv",
      "claim",
      "pvc",
      "separation",
      "mandatory.",
      "deployed",
      "completely",
      "separate",
      "domains",
      "any",
      "functional"
    ],
    "language": "en",
    "word_count": 122,
    "importance_score": 5.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "support matrix for oo containerized in gke deployment",
    "contentLower": "cloud deployments and on-premises deployments of the operations orchestration (oo) containerized share the same support matrix, except for the following aspects: supported environments google public cloud docker image registry google container registry (gcr) managed kubernetes clusters google kubernetes engine (gke) v 1.28.x, 1.29.x, 1.30.x helm if you plan to install oo on the same omt cluster as the next deployment, where service management is the primary deployment, the required helm version is: helm 3.16.x operating systems bastion:  rocky linux 9.x databases cloud-based oo production environments require an external database instance. the table below lists the supported and certified databases: cloud provider oo external database version suite external database version gcp postgresql 13.x, 14.x, 15.x, 16.x for linux postgresql 13.x, 14.x, 15.x, 16.x for linux for oo persistent storage google cloud filestore. oo shares the same gcf server with the rest of the suite components. oo o",
    "keywordsLower": [
      "1.30",
      "1.28",
      "1.29",
      "3.16",
      "supported.oo",
      "support",
      "matrix",
      "oo",
      "containerized",
      "gke",
      "deployment",
      "supported",
      "environments",
      "docker",
      "image",
      "registry",
      "managed",
      "kubernetes",
      "clusters",
      "helm",
      "operating",
      "systems",
      "databases",
      "persistent",
      "storage",
      "cloud",
      "deployments",
      "on-premises",
      "operations",
      "orchestration",
      "share",
      "same",
      "except",
      "following",
      "aspects",
      "google",
      "public",
      "container",
      "gcr",
      "engine",
      "1.28.x",
      "1.29.x",
      "1.30.x",
      "plan",
      "install",
      "omt",
      "cluster",
      "next",
      "service",
      "management",
      "primary",
      "required",
      "version",
      "3.16.x",
      "bastion",
      "rocky",
      "linux",
      "9.x",
      "cloud-based",
      "production",
      "require",
      "external",
      "database",
      "instance.",
      "table",
      "below",
      "lists",
      "certified",
      "provider",
      "suite",
      "gcp",
      "postgresql",
      "13.x",
      "14.x",
      "15.x",
      "16.x",
      "filestore.",
      "shares",
      "gcf",
      "server",
      "rest",
      "components.",
      "autopilot",
      "operates",
      "independently",
      "sm",
      "both",
      "layers.",
      "volume",
      "pv",
      "claim",
      "pvc",
      "separation",
      "mandatory.",
      "deployed",
      "completely",
      "separate",
      "domains",
      "any",
      "functional"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Set up IP and external access hostname",
    "content": "Role Location IT / Network administrator GCP Console and DNS provider Since the suite distributes workloads by load balancer, you need to prepare an external access hostname from your DNS provider's side and reserve a static IP address for the load balancer from the GCP Console. Then, bind the hostname with this static IP to allow users to access Service Management services using the bound external access hostname. Follow the steps to generate a static IP for the suite from the GCP Console: Navigate to VPC network > External IP addresses > RESERVE EXTERNAL STATIC ADDRESS. Give a name to this IP. For example, smax-static-ip. Under Network Service Tier, select the current project-level tier. If you choose a different tier from the current project-level tier, the installation will fail. Under Type, select Regional. Under Region, select the same region as the prepared VPC. Click RESERVE to save all the settings. After the static IP is reserved successfully, you can map it to your external ",
    "url": "399-gcpoocsetip",
    "filename": "399-gcpoocsetip",
    "headings": [
      "External references"
    ],
    "keywords": [
      "set",
      "ip",
      "external",
      "access",
      "hostname",
      "references",
      "role",
      "location",
      "network",
      "administrator",
      "gcp",
      "console",
      "dns",
      "provider",
      "since",
      "suite",
      "distributes",
      "workloads",
      "load",
      "balancer",
      "need",
      "prepare",
      "side",
      "reserve",
      "static",
      "address",
      "console.",
      "bind",
      "allow",
      "users",
      "service",
      "management",
      "services",
      "bound",
      "hostname.",
      "follow",
      "steps",
      "generate",
      "navigate",
      "vpc",
      "addresses",
      "address.",
      "give",
      "name",
      "ip.",
      "example",
      "smax-static-ip.",
      "under",
      "tier",
      "select",
      "current",
      "project-level",
      "tier.",
      "choose",
      "different",
      "installation",
      "fail.",
      "type",
      "regional.",
      "region",
      "same",
      "prepared",
      "vpc.",
      "click",
      "save",
      "all",
      "settings.",
      "after",
      "reserved",
      "successfully",
      "map",
      "allocated",
      "side.",
      "information",
      "see",
      "overview."
    ],
    "language": "en",
    "word_count": 112,
    "importance_score": 2.5,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "set up ip and external access hostname",
    "contentLower": "role location it / network administrator gcp console and dns provider since the suite distributes workloads by load balancer, you need to prepare an external access hostname from your dns provider's side and reserve a static ip address for the load balancer from the gcp console. then, bind the hostname with this static ip to allow users to access service management services using the bound external access hostname. follow the steps to generate a static ip for the suite from the gcp console: navigate to vpc network > external ip addresses > reserve external static address. give a name to this ip. for example, smax-static-ip. under network service tier, select the current project-level tier. if you choose a different tier from the current project-level tier, the installation will fail. under type, select regional. under region, select the same region as the prepared vpc. click reserve to save all the settings. after the static ip is reserved successfully, you can map it to your external ",
    "keywordsLower": [
      "set",
      "ip",
      "external",
      "access",
      "hostname",
      "references",
      "role",
      "location",
      "network",
      "administrator",
      "gcp",
      "console",
      "dns",
      "provider",
      "since",
      "suite",
      "distributes",
      "workloads",
      "load",
      "balancer",
      "need",
      "prepare",
      "side",
      "reserve",
      "static",
      "address",
      "console.",
      "bind",
      "allow",
      "users",
      "service",
      "management",
      "services",
      "bound",
      "hostname.",
      "follow",
      "steps",
      "generate",
      "navigate",
      "vpc",
      "addresses",
      "address.",
      "give",
      "name",
      "ip.",
      "example",
      "smax-static-ip.",
      "under",
      "tier",
      "select",
      "current",
      "project-level",
      "tier.",
      "choose",
      "different",
      "installation",
      "fail.",
      "type",
      "regional.",
      "region",
      "same",
      "prepared",
      "vpc.",
      "click",
      "save",
      "all",
      "settings.",
      "after",
      "reserved",
      "successfully",
      "map",
      "allocated",
      "side.",
      "information",
      "see",
      "overview."
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Subscribe NFS Filestore",
    "content": "Role Location Storage administrator GCP Console This topic describes how to use Filestore and Persistent Disk storage services from Google to store the OMT and suite data on GCP. For information about storage sizing and management, see Manage persistent storage for the suite. This release supports Filestore and Persistent Disk storage services on GCP. FileStore stores data attachments, certificates, and logs used by containerized applications in Kubernetes. It serves as the backend storage for data-volume, config-volume, and logging-volume. Persistent Disk offers high-performance and highly durable block storage for search engines and RabbitMQ. It serves as the backend storage for other volumes. We provide static and dynamic solutions for volumes that use FileStore. For volumes that use Persistent Disks, we only provide dynamic solutions. To take advantage of the benefits such as ease of use and reliability, we recommend using the dynamic solution. Plan the storage solution See the fol",
    "url": "399-gcpoocstorage",
    "filename": "399-gcpoocstorage",
    "headings": [
      "Plan the storage solution",
      "Enabled Filestore and Persistent Disk APIs",
      "Subscribe to Filestore service",
      "Create Filestore instance",
      "Configure NFS volumes",
      "External references"
    ],
    "keywords": [
      "https://console.cloud.google.com",
      "createFileStore.sh",
      "google.com",
      "subscribe",
      "nfs",
      "filestore",
      "plan",
      "storage",
      "solution",
      "enabled",
      "persistent",
      "disk",
      "apis",
      "service",
      "create",
      "instance",
      "configure",
      "volumes",
      "external",
      "references",
      "role",
      "location",
      "administrator",
      "gcp",
      "console",
      "topic",
      "describes",
      "services",
      "google",
      "store",
      "omt",
      "suite",
      "data",
      "gcp.",
      "information",
      "about",
      "sizing",
      "management",
      "see",
      "manage",
      "suite.",
      "release",
      "supports",
      "stores",
      "attachments",
      "certificates",
      "logs",
      "containerized",
      "applications",
      "kubernetes.",
      "serves",
      "backend",
      "data-volume",
      "config-volume",
      "logging-volume.",
      "offers",
      "high-performance",
      "highly",
      "durable",
      "block",
      "search",
      "engines",
      "rabbitmq.",
      "volumes.",
      "provide",
      "static",
      "dynamic",
      "solutions",
      "filestore.",
      "disks",
      "solutions.",
      "take",
      "advantage",
      "benefits",
      "such",
      "ease",
      "reliability",
      "recommend",
      "solution.",
      "following",
      "options",
      "combine",
      "deployment.",
      "option",
      "lists",
      "tasks",
      "involved",
      "setting",
      "provision",
      "recommended",
      "enable",
      "instructions",
      "provided",
      "sections.",
      "either",
      "first",
      "them.",
      "enabling",
      "refer",
      "official"
    ],
    "language": "en",
    "word_count": 96,
    "importance_score": 6.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "subscribe nfs filestore",
    "contentLower": "role location storage administrator gcp console this topic describes how to use filestore and persistent disk storage services from google to store the omt and suite data on gcp. for information about storage sizing and management, see manage persistent storage for the suite. this release supports filestore and persistent disk storage services on gcp. filestore stores data attachments, certificates, and logs used by containerized applications in kubernetes. it serves as the backend storage for data-volume, config-volume, and logging-volume. persistent disk offers high-performance and highly durable block storage for search engines and rabbitmq. it serves as the backend storage for other volumes. we provide static and dynamic solutions for volumes that use filestore. for volumes that use persistent disks, we only provide dynamic solutions. to take advantage of the benefits such as ease of use and reliability, we recommend using the dynamic solution. plan the storage solution see the fol",
    "keywordsLower": [
      "https://console.cloud.google.com",
      "createfilestore.sh",
      "google.com",
      "subscribe",
      "nfs",
      "filestore",
      "plan",
      "storage",
      "solution",
      "enabled",
      "persistent",
      "disk",
      "apis",
      "service",
      "create",
      "instance",
      "configure",
      "volumes",
      "external",
      "references",
      "role",
      "location",
      "administrator",
      "gcp",
      "console",
      "topic",
      "describes",
      "services",
      "google",
      "store",
      "omt",
      "suite",
      "data",
      "gcp.",
      "information",
      "about",
      "sizing",
      "management",
      "see",
      "manage",
      "suite.",
      "release",
      "supports",
      "stores",
      "attachments",
      "certificates",
      "logs",
      "containerized",
      "applications",
      "kubernetes.",
      "serves",
      "backend",
      "data-volume",
      "config-volume",
      "logging-volume.",
      "offers",
      "high-performance",
      "highly",
      "durable",
      "block",
      "search",
      "engines",
      "rabbitmq.",
      "volumes.",
      "provide",
      "static",
      "dynamic",
      "solutions",
      "filestore.",
      "disks",
      "solutions.",
      "take",
      "advantage",
      "benefits",
      "such",
      "ease",
      "reliability",
      "recommend",
      "solution.",
      "following",
      "options",
      "combine",
      "deployment.",
      "option",
      "lists",
      "tasks",
      "involved",
      "setting",
      "provision",
      "recommended",
      "enable",
      "instructions",
      "provided",
      "sections.",
      "either",
      "first",
      "them.",
      "enabling",
      "refer",
      "official"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Set up IP and external access hostname",
    "content": "Role Location IT / Network administrator GCP Console and DNS provider Since UD/UCMDB distributes workloads by load balancer, you need to prepare an external access hostname from your DNS provider's side and reserve a static IP address for the load balancer from the GCP Console. Then, bind the hostname with this static IP to allow users to access UD/UCMDB services using the bound external access hostname. To generate a static IP for UD/UCMDB from the GCP Console, follow these steps: Navigate to VPC network > External IP addresses > RESERVE EXTERNAL STATIC ADDRESS. Give a name to this IP. For example, ucmdb-static-ip. Under Network Service Tier, select the current project-level tier. If you choose a different tier from the current project-level tier, the installation will fail. Under Type, select Regional. Under Region, select the same region as the prepared VPC. Click RESERVE to save all the settings. After the static IP is successfully reserved, you can map it to your external access h",
    "url": "403-ucmdbgcpsetip",
    "filename": "403-ucmdbgcpsetip",
    "headings": [
      "External references"
    ],
    "keywords": [
      "set",
      "ip",
      "external",
      "access",
      "hostname",
      "references",
      "role",
      "location",
      "network",
      "administrator",
      "gcp",
      "console",
      "dns",
      "provider",
      "since",
      "ud",
      "ucmdb",
      "distributes",
      "workloads",
      "load",
      "balancer",
      "need",
      "prepare",
      "side",
      "reserve",
      "static",
      "address",
      "console.",
      "bind",
      "allow",
      "users",
      "services",
      "bound",
      "hostname.",
      "generate",
      "follow",
      "steps",
      "navigate",
      "vpc",
      "addresses",
      "address.",
      "give",
      "name",
      "ip.",
      "example",
      "ucmdb-static-ip.",
      "under",
      "service",
      "tier",
      "select",
      "current",
      "project-level",
      "tier.",
      "choose",
      "different",
      "installation",
      "fail.",
      "type",
      "regional.",
      "region",
      "same",
      "prepared",
      "vpc.",
      "click",
      "save",
      "all",
      "settings.",
      "after",
      "successfully",
      "reserved",
      "map",
      "allocated",
      "side.",
      "information",
      "see",
      "overview."
    ],
    "language": "en",
    "word_count": 116,
    "importance_score": 2.5,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "set up ip and external access hostname",
    "contentLower": "role location it / network administrator gcp console and dns provider since ud/ucmdb distributes workloads by load balancer, you need to prepare an external access hostname from your dns provider's side and reserve a static ip address for the load balancer from the gcp console. then, bind the hostname with this static ip to allow users to access ud/ucmdb services using the bound external access hostname. to generate a static ip for ud/ucmdb from the gcp console, follow these steps: navigate to vpc network > external ip addresses > reserve external static address. give a name to this ip. for example, ucmdb-static-ip. under network service tier, select the current project-level tier. if you choose a different tier from the current project-level tier, the installation will fail. under type, select regional. under region, select the same region as the prepared vpc. click reserve to save all the settings. after the static ip is successfully reserved, you can map it to your external access h",
    "keywordsLower": [
      "set",
      "ip",
      "external",
      "access",
      "hostname",
      "references",
      "role",
      "location",
      "network",
      "administrator",
      "gcp",
      "console",
      "dns",
      "provider",
      "since",
      "ud",
      "ucmdb",
      "distributes",
      "workloads",
      "load",
      "balancer",
      "need",
      "prepare",
      "side",
      "reserve",
      "static",
      "address",
      "console.",
      "bind",
      "allow",
      "users",
      "services",
      "bound",
      "hostname.",
      "generate",
      "follow",
      "steps",
      "navigate",
      "vpc",
      "addresses",
      "address.",
      "give",
      "name",
      "ip.",
      "example",
      "ucmdb-static-ip.",
      "under",
      "service",
      "tier",
      "select",
      "current",
      "project-level",
      "tier.",
      "choose",
      "different",
      "installation",
      "fail.",
      "type",
      "regional.",
      "region",
      "same",
      "prepared",
      "vpc.",
      "click",
      "save",
      "all",
      "settings.",
      "after",
      "successfully",
      "reserved",
      "map",
      "allocated",
      "side.",
      "information",
      "see",
      "overview."
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Subscribe Cloud Filestore",
    "content": "Role Location Storage administrator GCP Console This topic describes how to use Google's Filestore storage service to store the OMT and UD/UCMDB data on GCP. Filestore stores data attachments, certificates, and logs used by containerized applications in Kubernetes. It serves as the backend storage for data-volume,config-volume, and logging-volume. Configure NFS volumes Role Location Storage administrator Bastion node Once the Filestore instance is ready, log on to the bastion and set up the NFS volumes to store global data, Smart Analytics data, and database data of the UD/UCMDB. To set up the NFS volumes, follow these steps: Copy the following script content and save it as configureFilestore.sh: #!/bin/bash if [ $# -lt 1 ]; then echo \"Usage: $0 \" exit 1 fi CURRENTDIR=$(cd \"$(dirname \"$0\")\";pwd) fs_server=$1 file_share_name=$2 suite_user_uid=$3 suite_user_gid=$4 mount_point=/mnt/uducmdb if [ ! -d $mount_point ]; then sudo mkdir -p $mount_point fi export TIMEOUT_FOR_SERVICES=120 mountFS",
    "url": "403-ucmdbgcpfilestore",
    "filename": "403-ucmdbgcpfilestore",
    "headings": [
      "Configure NFS volumes",
      "External references"
    ],
    "keywords": [
      "10.180",
      "97.66",
      "configureFilestore.sh",
      "10.180.97.66",
      "10.180.97",
      "subscribe",
      "cloud",
      "filestore",
      "configure",
      "nfs",
      "volumes",
      "external",
      "references",
      "role",
      "location",
      "storage",
      "administrator",
      "gcp",
      "console",
      "topic",
      "describes",
      "google",
      "service",
      "store",
      "omt",
      "ud",
      "ucmdb",
      "data",
      "gcp.",
      "stores",
      "attachments",
      "certificates",
      "logs",
      "containerized",
      "applications",
      "kubernetes.",
      "serves",
      "backend",
      "data-volume",
      "config-volume",
      "logging-volume.",
      "bastion",
      "node",
      "once",
      "instance",
      "ready",
      "log",
      "set",
      "global",
      "smart",
      "analytics",
      "database",
      "ucmdb.",
      "follow",
      "steps",
      "copy",
      "following",
      "script",
      "content",
      "save",
      "bin",
      "bash",
      "-lt",
      "echo",
      "usage",
      "exit",
      "fi",
      "currentdir",
      "cd",
      "dirname",
      "pwd",
      "mnt",
      "uducmdb",
      "-d",
      "sudo",
      "mkdir",
      "-p",
      "export",
      "120",
      "mountfs",
      "local",
      "while",
      "-ge",
      "check",
      "timeout",
      "mount",
      "returncode",
      "-t",
      "-o",
      "vers",
      "-eq",
      "32",
      "successfully",
      "sed",
      "-i",
      "etc",
      "fstab",
      "break",
      "sleep",
      "15"
    ],
    "language": "en",
    "word_count": 113,
    "importance_score": 4.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "subscribe cloud filestore",
    "contentLower": "role location storage administrator gcp console this topic describes how to use google's filestore storage service to store the omt and ud/ucmdb data on gcp. filestore stores data attachments, certificates, and logs used by containerized applications in kubernetes. it serves as the backend storage for data-volume,config-volume, and logging-volume. configure nfs volumes role location storage administrator bastion node once the filestore instance is ready, log on to the bastion and set up the nfs volumes to store global data, smart analytics data, and database data of the ud/ucmdb. to set up the nfs volumes, follow these steps: copy the following script content and save it as configurefilestore.sh: #!/bin/bash if [ $# -lt 1 ]; then echo \"usage: $0 \" exit 1 fi currentdir=$(cd \"$(dirname \"$0\")\";pwd) fs_server=$1 file_share_name=$2 suite_user_uid=$3 suite_user_gid=$4 mount_point=/mnt/uducmdb if [ ! -d $mount_point ]; then sudo mkdir -p $mount_point fi export timeout_for_services=120 mountfs",
    "keywordsLower": [
      "10.180",
      "97.66",
      "configurefilestore.sh",
      "10.180.97.66",
      "10.180.97",
      "subscribe",
      "cloud",
      "filestore",
      "configure",
      "nfs",
      "volumes",
      "external",
      "references",
      "role",
      "location",
      "storage",
      "administrator",
      "gcp",
      "console",
      "topic",
      "describes",
      "google",
      "service",
      "store",
      "omt",
      "ud",
      "ucmdb",
      "data",
      "gcp.",
      "stores",
      "attachments",
      "certificates",
      "logs",
      "containerized",
      "applications",
      "kubernetes.",
      "serves",
      "backend",
      "data-volume",
      "config-volume",
      "logging-volume.",
      "bastion",
      "node",
      "once",
      "instance",
      "ready",
      "log",
      "set",
      "global",
      "smart",
      "analytics",
      "database",
      "ucmdb.",
      "follow",
      "steps",
      "copy",
      "following",
      "script",
      "content",
      "save",
      "bin",
      "bash",
      "-lt",
      "echo",
      "usage",
      "exit",
      "fi",
      "currentdir",
      "cd",
      "dirname",
      "pwd",
      "mnt",
      "uducmdb",
      "-d",
      "sudo",
      "mkdir",
      "-p",
      "export",
      "120",
      "mountfs",
      "local",
      "while",
      "-ge",
      "check",
      "timeout",
      "mount",
      "returncode",
      "-t",
      "-o",
      "vers",
      "-eq",
      "32",
      "successfully",
      "sed",
      "-i",
      "etc",
      "fstab",
      "break",
      "sleep",
      "15"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Support matrix (BYOK)",
    "content": "Cloud deployments and on-premises deployments of the suite basically share the same support matrix (see Support matrix for on-premises deployment), except for the following components: KubernetesHelmDatabasesNFS If you're going to install or upgrade the suite deployment on your BYOK environment, review the support information in the following sections. We always recommend that you follow the support matrix and use the installation instructions to install the latest version of the suite. If you have a reason to install an older release, please contact our Product Management team. The .n in the version indicates that all sub-versions of that major version are supported. Kubernetes versions 1.32.n, 1.33.n Helm Helm 3.17.n Databases PostgreSQL 17.n, 16.n, 15.n, 14.n for Linux Vertica versions: Since FinOps is configured in Operations Platform mode, refer to the support matrix of OP 25.3 NFS Supported NFS versions NFS v4.0, v4.1, v4.2 NFS storage types Self-hosted NFS storage (Linux-based) ",
    "url": "installonbyoksupportmatrixforbyok",
    "filename": "installonbyoksupportmatrixforbyok",
    "headings": [
      "Kubernetes versions",
      "Helm",
      "Databases",
      "NFS",
      "Supported NFS versions",
      "NFS storage types"
    ],
    "keywords": [
      "v4.0",
      "v4.1",
      "3.17",
      "25.3",
      "v4.2",
      "1.32",
      "1.33",
      "support",
      "matrix",
      "byok",
      "kubernetes",
      "versions",
      "helm",
      "databases",
      "nfs",
      "supported",
      "storage",
      "types",
      "cloud",
      "deployments",
      "on-premises",
      "suite",
      "basically",
      "share",
      "same",
      "see",
      "deployment",
      "except",
      "following",
      "components",
      "kuberneteshelmdatabasesnfs",
      "re",
      "going",
      "install",
      "upgrade",
      "environment",
      "review",
      "information",
      "sections.",
      "always",
      "recommend",
      "follow",
      "installation",
      "instructions",
      "latest",
      "version",
      "suite.",
      "reason",
      "older",
      "release",
      "please",
      "contact",
      "product",
      "management",
      "team.",
      ".n",
      "indicates",
      "all",
      "sub-versions",
      "major",
      "supported.",
      "1.32.n",
      "1.33.n",
      "3.17.n",
      "postgresql",
      "17.n",
      "16.n",
      "15.n",
      "14.n",
      "linux",
      "vertica",
      "since",
      "finops",
      "configured",
      "operations",
      "platform",
      "mode",
      "refer",
      "op",
      "self-hosted",
      "linux-based",
      "managed",
      "configure",
      "volumes."
    ],
    "language": "en",
    "word_count": 105,
    "importance_score": 6.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "support matrix (byok)",
    "contentLower": "cloud deployments and on-premises deployments of the suite basically share the same support matrix (see support matrix for on-premises deployment), except for the following components: kuberneteshelmdatabasesnfs if you're going to install or upgrade the suite deployment on your byok environment, review the support information in the following sections. we always recommend that you follow the support matrix and use the installation instructions to install the latest version of the suite. if you have a reason to install an older release, please contact our product management team. the .n in the version indicates that all sub-versions of that major version are supported. kubernetes versions 1.32.n, 1.33.n helm helm 3.17.n databases postgresql 17.n, 16.n, 15.n, 14.n for linux vertica versions: since finops is configured in operations platform mode, refer to the support matrix of op 25.3 nfs supported nfs versions nfs v4.0, v4.1, v4.2 nfs storage types self-hosted nfs storage (linux-based) ",
    "keywordsLower": [
      "v4.0",
      "v4.1",
      "3.17",
      "25.3",
      "v4.2",
      "1.32",
      "1.33",
      "support",
      "matrix",
      "byok",
      "kubernetes",
      "versions",
      "helm",
      "databases",
      "nfs",
      "supported",
      "storage",
      "types",
      "cloud",
      "deployments",
      "on-premises",
      "suite",
      "basically",
      "share",
      "same",
      "see",
      "deployment",
      "except",
      "following",
      "components",
      "kuberneteshelmdatabasesnfs",
      "re",
      "going",
      "install",
      "upgrade",
      "environment",
      "review",
      "information",
      "sections.",
      "always",
      "recommend",
      "follow",
      "installation",
      "instructions",
      "latest",
      "version",
      "suite.",
      "reason",
      "older",
      "release",
      "please",
      "contact",
      "product",
      "management",
      "team.",
      ".n",
      "indicates",
      "all",
      "sub-versions",
      "major",
      "supported.",
      "1.32.n",
      "1.33.n",
      "3.17.n",
      "postgresql",
      "17.n",
      "16.n",
      "15.n",
      "14.n",
      "linux",
      "vertica",
      "since",
      "finops",
      "configured",
      "operations",
      "platform",
      "mode",
      "refer",
      "op",
      "self-hosted",
      "linux-based",
      "managed",
      "configure",
      "volumes."
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Sizing considerations (BYOK)",
    "content": "For sizing guidelines for your kubernetes cluster, refer to the the kubernetes platform's official documentation. This section provides information about the minimum dedicated hardware resources required for the suite. Determine the capability deployment sizes The suite installation may include the following capabilities: The suite Design and Deploy (DND) Cloud Management Platform (CMP) FinOps Operations Orchestration (OO) Containerized Containerized UD/UCMDB Software Asset Management (SAM) Among them, the suite capability is mandatory and the others are optional. As the first step for sizing, you need to determine the capabilities that you need and their deployment size according to your business needs. For the deployment size definitions of each capability, see Determine the capability deployment sizes. Hardware requirements for suite (suite only) suite deployment size Worker node NFS Database Configuration Storage Quantity Configuration Storage Quantity Configuration Storage Quantit",
    "url": "installonbyoksizingcondiderationforbyok",
    "filename": "installonbyoksizingcondiderationforbyok",
    "headings": [
      "Determine the capability deployment sizes",
      "Hardware requirements for suite (suite only)",
      "Hardware requirements for bastion",
      "Additional hardware requirements for SAM",
      "Additional hardware requirements for DND",
      "Additional hardware requirements for CMP FinOps",
      "Additional hardware requirements for UD/UCMDB",
      "If using a classic UD/UCMDB",
      "If using the containerized UD/UCMDB",
      "Additional hardware requirements for OO Containerized"
    ],
    "keywords": [
      "3.75",
      "sizing",
      "considerations",
      "byok",
      "determine",
      "capability",
      "deployment",
      "sizes",
      "hardware",
      "requirements",
      "suite",
      "bastion",
      "additional",
      "sam",
      "dnd",
      "cmp",
      "finops",
      "ud",
      "ucmdb",
      "classic",
      "containerized",
      "oo",
      "guidelines",
      "kubernetes",
      "cluster",
      "refer",
      "platform",
      "official",
      "documentation.",
      "section",
      "provides",
      "information",
      "about",
      "minimum",
      "dedicated",
      "resources",
      "required",
      "suite.",
      "installation",
      "include",
      "following",
      "capabilities",
      "design",
      "deploy",
      "cloud",
      "management",
      "operations",
      "orchestration",
      "software",
      "asset",
      "among",
      "mandatory",
      "others",
      "optional.",
      "first",
      "step",
      "need",
      "size",
      "according",
      "business",
      "needs.",
      "definitions",
      "see",
      "sizes.",
      "worker",
      "node",
      "nfs",
      "database",
      "configuration",
      "storage",
      "quantity",
      "small",
      "cpu",
      "32",
      "ram",
      "40",
      "140",
      "12",
      "681",
      "200",
      "medium",
      "16",
      "1263",
      "48",
      "96",
      "large",
      "2481",
      "64",
      "gb",
      "24",
      "128",
      "400",
      "table",
      "lists",
      "needed",
      "setting",
      "cloud.",
      "instance",
      "type",
      "boot"
    ],
    "language": "en",
    "word_count": 99,
    "importance_score": 6.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "sizing considerations (byok)",
    "contentLower": "for sizing guidelines for your kubernetes cluster, refer to the the kubernetes platform's official documentation. this section provides information about the minimum dedicated hardware resources required for the suite. determine the capability deployment sizes the suite installation may include the following capabilities: the suite design and deploy (dnd) cloud management platform (cmp) finops operations orchestration (oo) containerized containerized ud/ucmdb software asset management (sam) among them, the suite capability is mandatory and the others are optional. as the first step for sizing, you need to determine the capabilities that you need and their deployment size according to your business needs. for the deployment size definitions of each capability, see determine the capability deployment sizes. hardware requirements for suite (suite only) suite deployment size worker node nfs database configuration storage quantity configuration storage quantity configuration storage quantit",
    "keywordsLower": [
      "3.75",
      "sizing",
      "considerations",
      "byok",
      "determine",
      "capability",
      "deployment",
      "sizes",
      "hardware",
      "requirements",
      "suite",
      "bastion",
      "additional",
      "sam",
      "dnd",
      "cmp",
      "finops",
      "ud",
      "ucmdb",
      "classic",
      "containerized",
      "oo",
      "guidelines",
      "kubernetes",
      "cluster",
      "refer",
      "platform",
      "official",
      "documentation.",
      "section",
      "provides",
      "information",
      "about",
      "minimum",
      "dedicated",
      "resources",
      "required",
      "suite.",
      "installation",
      "include",
      "following",
      "capabilities",
      "design",
      "deploy",
      "cloud",
      "management",
      "operations",
      "orchestration",
      "software",
      "asset",
      "among",
      "mandatory",
      "others",
      "optional.",
      "first",
      "step",
      "need",
      "size",
      "according",
      "business",
      "needs.",
      "definitions",
      "see",
      "sizes.",
      "worker",
      "node",
      "nfs",
      "database",
      "configuration",
      "storage",
      "quantity",
      "small",
      "cpu",
      "32",
      "ram",
      "40",
      "140",
      "12",
      "681",
      "200",
      "medium",
      "16",
      "1263",
      "48",
      "96",
      "large",
      "2481",
      "64",
      "gb",
      "24",
      "128",
      "400",
      "table",
      "lists",
      "needed",
      "setting",
      "cloud.",
      "instance",
      "type",
      "boot"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Support matrix (OpenShift)",
    "content": "Review the support matrix information below if you're going to install the suite on your Kubernetes or upgrade an existing deployment of the suite on your Kubernetes. We always recommend that you follow the support matrix and use the installation instructions to install the latest version of the suite. If you have a reason to install an older release, please contact our product management team.You can't deploy the monitoring capability on OpenShift. .n in the version means that all sub-versions of that major version are supported.OpenShiftOpenShift Container Platform versions: 4.20, 4.19, 4.18, 4.17.KubernetesVersions: 1.33.nHelmVersion: 3.17.nDatabasesPostgreSQL versions: 17.n, 16.n, 15.n, 14.n for LinuxVertica versions: Since FinOps is configured in Operations Platform (OP) mode, refer to the support matrix of OP 25.3. NFSNFS versions: 4.2, 4.1, 4.0Supported NFS storage typesSelf-hosted NFS storage (Linux-based)Managed NFS storageSee Configure NFS volumes.LDAP serversYou can configur",
    "url": "supportmatrixopenshift",
    "filename": "supportmatrixopenshift",
    "headings": [
      "OpenShift",
      "Kubernetes",
      "Helm",
      "Databases",
      "NFS",
      "LDAP servers",
      "LDAP authentication in IdM",
      "OPB-based LDAP integration",
      "On-Premises Bridge (OPB)",
      "Federated Identity technologies",
      "SAML 2.0",
      "OAuth 2.0",
      "Browsers",
      "Safe-list browsers",
      "Mobile app",
      "Screen resolution",
      "Language support",
      "UI fonts",
      "Aviator language support",
      "Virtual agent language support"
    ],
    "keywords": [
      "8.8",
      "4.17",
      "4.1",
      "3.17",
      "volumes.LDAP",
      "tenant.The",
      "supports.OMT",
      "9.n10",
      "pages.In",
      "view.In",
      "8.n9",
      "font.For",
      "25.2",
      "25.3",
      "4.2",
      "expressions.RTL",
      "team.You",
      "2.0On",
      "elements.When",
      "2.0",
      "font.In",
      "1.33",
      "side.When",
      "4.20",
      "4.19",
      "consistent.In",
      "4.18",
      "language.The",
      "aligned.RTL",
      "support",
      "matrix",
      "openshift",
      "kubernetes",
      "helm",
      "databases",
      "nfs",
      "ldap",
      "servers",
      "authentication",
      "idm",
      "opb-based",
      "integration",
      "on-premises",
      "bridge",
      "opb",
      "federated",
      "identity",
      "technologies",
      "saml",
      "oauth",
      "browsers",
      "safe-list",
      "mobile",
      "app",
      "screen",
      "resolution",
      "language",
      "ui",
      "fonts",
      "aviator",
      "virtual",
      "agent",
      "arabic",
      "hebrew",
      "portuguese",
      "portugal",
      "optical",
      "character",
      "recognition",
      "ocr",
      "omt",
      "management",
      "portal",
      "integrations",
      "review",
      "information",
      "below",
      "re",
      "going",
      "install",
      "suite",
      "upgrade",
      "existing",
      "deployment",
      "kubernetes.",
      "always",
      "recommend",
      "follow",
      "installation",
      "instructions",
      "latest",
      "version",
      "suite.",
      "reason",
      "older",
      "release",
      "please",
      "contact",
      "product",
      "deploy"
    ],
    "language": "en",
    "word_count": 98,
    "importance_score": 6.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "support matrix (openshift)",
    "contentLower": "review the support matrix information below if you're going to install the suite on your kubernetes or upgrade an existing deployment of the suite on your kubernetes. we always recommend that you follow the support matrix and use the installation instructions to install the latest version of the suite. if you have a reason to install an older release, please contact our product management team.you can't deploy the monitoring capability on openshift. .n in the version means that all sub-versions of that major version are supported.openshiftopenshift container platform versions: 4.20, 4.19, 4.18, 4.17.kubernetesversions: 1.33.nhelmversion: 3.17.ndatabasespostgresql versions: 17.n, 16.n, 15.n, 14.n for linuxvertica versions: since finops is configured in operations platform (op) mode, refer to the support matrix of op 25.3. nfsnfs versions: 4.2, 4.1, 4.0supported nfs storage typesself-hosted nfs storage (linux-based)managed nfs storagesee configure nfs volumes.ldap serversyou can configur",
    "keywordsLower": [
      "8.8",
      "4.17",
      "4.1",
      "3.17",
      "volumes.ldap",
      "tenant.the",
      "supports.omt",
      "9.n10",
      "pages.in",
      "view.in",
      "8.n9",
      "font.for",
      "25.2",
      "25.3",
      "4.2",
      "expressions.rtl",
      "team.you",
      "2.0on",
      "elements.when",
      "2.0",
      "font.in",
      "1.33",
      "side.when",
      "4.20",
      "4.19",
      "consistent.in",
      "4.18",
      "language.the",
      "aligned.rtl",
      "support",
      "matrix",
      "openshift",
      "kubernetes",
      "helm",
      "databases",
      "nfs",
      "ldap",
      "servers",
      "authentication",
      "idm",
      "opb-based",
      "integration",
      "on-premises",
      "bridge",
      "opb",
      "federated",
      "identity",
      "technologies",
      "saml",
      "oauth",
      "browsers",
      "safe-list",
      "mobile",
      "app",
      "screen",
      "resolution",
      "language",
      "ui",
      "fonts",
      "aviator",
      "virtual",
      "agent",
      "arabic",
      "hebrew",
      "portuguese",
      "portugal",
      "optical",
      "character",
      "recognition",
      "ocr",
      "omt",
      "management",
      "portal",
      "integrations",
      "review",
      "information",
      "below",
      "re",
      "going",
      "install",
      "suite",
      "upgrade",
      "existing",
      "deployment",
      "kubernetes.",
      "always",
      "recommend",
      "follow",
      "installation",
      "instructions",
      "latest",
      "version",
      "suite.",
      "reason",
      "older",
      "release",
      "please",
      "contact",
      "product",
      "deploy"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Sizing considerations",
    "content": "For sizing guidelines for your kubernetes cluster, refer to the the kubernetes platform's official documentation. This section provides information about the minimum dedicated hardware resources required for the suite. Determine the capability deployment sizes The suite installation may include the following capabilities: Service Management Automation (SMA) Design and Deploy (DND) Cloud Management Platform (CMP) FinOps Operations Orchestration (OO) Containerized Containerized UCMDB Software Asset Management (SAM) Among them, the SMA capability is mandatory and the others are optional. As the first step for sizing, you need to determine the capabilities that you need and their deployment size according to your business needs. For the deployment size definitions of each capability, see Determine the capability deployment sizes. Hardware requirements for SMA (SMA only) SMA deployment size Worker node NFS Database Configuration Storage Quantity Configuration Storage Quantity Configuration ",
    "url": "sizingforopenshift",
    "filename": "sizingforopenshift",
    "headings": [
      "Determine the capability deployment sizes",
      "Hardware requirements for SMA (SMA only)",
      "Hardware requirements for bastion",
      "Additional hardware requirements for SAM",
      "Additional hardware requirements for DND",
      "Additional hardware requirements for CMP FinOps",
      "Additional hardware requirements for UCMDB",
      "If using a classic UCMDB",
      "If using the containerized UCMDB",
      "Additional hardware requirements for OO Containerized"
    ],
    "keywords": [
      "3.75",
      "sizing",
      "considerations",
      "determine",
      "capability",
      "deployment",
      "sizes",
      "hardware",
      "requirements",
      "sma",
      "bastion",
      "additional",
      "sam",
      "dnd",
      "cmp",
      "finops",
      "ucmdb",
      "classic",
      "containerized",
      "oo",
      "guidelines",
      "kubernetes",
      "cluster",
      "refer",
      "platform",
      "official",
      "documentation.",
      "section",
      "provides",
      "information",
      "about",
      "minimum",
      "dedicated",
      "resources",
      "required",
      "suite.",
      "suite",
      "installation",
      "include",
      "following",
      "capabilities",
      "service",
      "management",
      "automation",
      "design",
      "deploy",
      "cloud",
      "operations",
      "orchestration",
      "software",
      "asset",
      "among",
      "mandatory",
      "others",
      "optional.",
      "first",
      "step",
      "need",
      "size",
      "according",
      "business",
      "needs.",
      "definitions",
      "see",
      "sizes.",
      "worker",
      "node",
      "nfs",
      "database",
      "configuration",
      "storage",
      "quantity",
      "small",
      "cpu",
      "32",
      "ram",
      "40",
      "140",
      "12",
      "681",
      "200",
      "medium",
      "16",
      "1263",
      "48",
      "96",
      "large",
      "2481",
      "64",
      "gb",
      "24",
      "128",
      "400",
      "table",
      "lists",
      "needed",
      "setting",
      "cloud.",
      "instance",
      "type"
    ],
    "language": "en",
    "word_count": 98,
    "importance_score": 6.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "sizing considerations",
    "contentLower": "for sizing guidelines for your kubernetes cluster, refer to the the kubernetes platform's official documentation. this section provides information about the minimum dedicated hardware resources required for the suite. determine the capability deployment sizes the suite installation may include the following capabilities: service management automation (sma) design and deploy (dnd) cloud management platform (cmp) finops operations orchestration (oo) containerized containerized ucmdb software asset management (sam) among them, the sma capability is mandatory and the others are optional. as the first step for sizing, you need to determine the capabilities that you need and their deployment size according to your business needs. for the deployment size definitions of each capability, see determine the capability deployment sizes. hardware requirements for sma (sma only) sma deployment size worker node nfs database configuration storage quantity configuration storage quantity configuration ",
    "keywordsLower": [
      "3.75",
      "sizing",
      "considerations",
      "determine",
      "capability",
      "deployment",
      "sizes",
      "hardware",
      "requirements",
      "sma",
      "bastion",
      "additional",
      "sam",
      "dnd",
      "cmp",
      "finops",
      "ucmdb",
      "classic",
      "containerized",
      "oo",
      "guidelines",
      "kubernetes",
      "cluster",
      "refer",
      "platform",
      "official",
      "documentation.",
      "section",
      "provides",
      "information",
      "about",
      "minimum",
      "dedicated",
      "resources",
      "required",
      "suite.",
      "suite",
      "installation",
      "include",
      "following",
      "capabilities",
      "service",
      "management",
      "automation",
      "design",
      "deploy",
      "cloud",
      "operations",
      "orchestration",
      "software",
      "asset",
      "among",
      "mandatory",
      "others",
      "optional.",
      "first",
      "step",
      "need",
      "size",
      "according",
      "business",
      "needs.",
      "definitions",
      "see",
      "sizes.",
      "worker",
      "node",
      "nfs",
      "database",
      "configuration",
      "storage",
      "quantity",
      "small",
      "cpu",
      "32",
      "ram",
      "40",
      "140",
      "12",
      "681",
      "200",
      "medium",
      "16",
      "1263",
      "48",
      "96",
      "large",
      "2481",
      "64",
      "gb",
      "24",
      "128",
      "400",
      "table",
      "lists",
      "needed",
      "setting",
      "cloud.",
      "instance",
      "type"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Remove public schema from external PostgreSQL",
    "content": "The suite uses a private schema for the database of each suite component (such as Service Management and Suite Administration). For best security, you can remove the public schema of both the Postgres database and the suite component databases. However, you need to make sure that each public schema doesn’t contain database objects that are in use before the removal. For detailed instructions on how to remove a public schema, see the PostgreSQL documentation.",
    "url": "removepublicschema",
    "filename": "removepublicschema",
    "headings": [],
    "keywords": [
      "remove",
      "public",
      "schema",
      "external",
      "postgresql",
      "suite",
      "uses",
      "private",
      "database",
      "component",
      "such",
      "service",
      "management",
      "administration",
      "best",
      "security",
      "both",
      "postgres",
      "databases.",
      "however",
      "need",
      "make",
      "sure",
      "doesn",
      "contain",
      "objects",
      "before",
      "removal.",
      "detailed",
      "instructions",
      "see",
      "documentation."
    ],
    "language": "en",
    "word_count": 49,
    "importance_score": 1.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "remove public schema from external postgresql",
    "contentLower": "the suite uses a private schema for the database of each suite component (such as service management and suite administration). for best security, you can remove the public schema of both the postgres database and the suite component databases. however, you need to make sure that each public schema doesn’t contain database objects that are in use before the removal. for detailed instructions on how to remove a public schema, see the postgresql documentation.",
    "keywordsLower": [
      "remove",
      "public",
      "schema",
      "external",
      "postgresql",
      "suite",
      "uses",
      "private",
      "database",
      "component",
      "such",
      "service",
      "management",
      "administration",
      "best",
      "security",
      "both",
      "postgres",
      "databases.",
      "however",
      "need",
      "make",
      "sure",
      "doesn",
      "contain",
      "objects",
      "before",
      "removal.",
      "detailed",
      "instructions",
      "see",
      "documentation."
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Scale up the DND pods",
    "content": "If you have Design and Deploy (DND) deployed and enabled, you can increase the throughput by scaling the pods as follows. Find the namespace by running the following command on a control plane node. kubectl get ns Grep for the deployment pod that you want to scale up. kubectl get deployments --all-namespaces|grep Example: kubectl get deployments --all-namespaces|grep dnd-controller Scale the pod by executing the following command: kubectl scale --current-replicas=1 --replicas=2 deployment/ -n Example: kubectl scale --current-replicas=1 --replicas=2 deployment/itom-dnd-controller-141127286 -n itsma-iz0px After scaling, the additional deployments and pods will be available. Before scaling: After scaling: Related topics Deploy DND",
    "url": "scalingdnd",
    "filename": "scalingdnd",
    "headings": [
      "Related topics"
    ],
    "keywords": [
      "scale",
      "dnd",
      "pods",
      "related",
      "topics",
      "design",
      "deploy",
      "deployed",
      "enabled",
      "increase",
      "throughput",
      "scaling",
      "follows.",
      "find",
      "namespace",
      "running",
      "following",
      "command",
      "control",
      "plane",
      "node.",
      "kubectl",
      "get",
      "ns",
      "grep",
      "deployment",
      "pod",
      "want",
      "up.",
      "deployments",
      "--all-namespaces",
      "example",
      "dnd-controller",
      "executing",
      "--current-replicas",
      "--replicas",
      "-n",
      "itom-dnd-controller-141127286",
      "itsma-iz0px",
      "after",
      "additional",
      "available.",
      "before"
    ],
    "language": "en",
    "word_count": 80,
    "importance_score": 2.5,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "scale up the dnd pods",
    "contentLower": "if you have design and deploy (dnd) deployed and enabled, you can increase the throughput by scaling the pods as follows. find the namespace by running the following command on a control plane node. kubectl get ns grep for the deployment pod that you want to scale up. kubectl get deployments --all-namespaces|grep example: kubectl get deployments --all-namespaces|grep dnd-controller scale the pod by executing the following command: kubectl scale --current-replicas=1 --replicas=2 deployment/ -n example: kubectl scale --current-replicas=1 --replicas=2 deployment/itom-dnd-controller-141127286 -n itsma-iz0px after scaling, the additional deployments and pods will be available. before scaling: after scaling: related topics deploy dnd",
    "keywordsLower": [
      "scale",
      "dnd",
      "pods",
      "related",
      "topics",
      "design",
      "deploy",
      "deployed",
      "enabled",
      "increase",
      "throughput",
      "scaling",
      "follows.",
      "find",
      "namespace",
      "running",
      "following",
      "command",
      "control",
      "plane",
      "node.",
      "kubectl",
      "get",
      "ns",
      "grep",
      "deployment",
      "pod",
      "want",
      "up.",
      "deployments",
      "--all-namespaces",
      "example",
      "dnd-controller",
      "executing",
      "--current-replicas",
      "--replicas",
      "-n",
      "itom-dnd-controller-141127286",
      "itsma-iz0px",
      "after",
      "additional",
      "available.",
      "before"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Sizing and system requirements",
    "content": "Sizing your cluster depends on several considerations. The Size your deployment topic offers you a lot of services and dependencies. It helps you decide on the number of resources required for your deployment. After you have completed the sizing, see the System requirements topic to understand the supported versions of the requirements to deploy the application. Get the required infrastructure The Size your deployment topic offers you a considerable number of resources you need for each of the applications you plan to deploy. The infrastructure differs based on the environment and the capabilities you choose to deploy. Make sure you obtained the required infrastructure and the required size in the following areas: Database server Storage servers Network resources Image repository server Kubernetes resources",
    "url": "sizingsystemrequirementsooc",
    "filename": "sizingsystemrequirementsooc",
    "headings": [
      "Get the required infrastructure"
    ],
    "keywords": [
      "sizing",
      "system",
      "requirements",
      "get",
      "required",
      "infrastructure",
      "cluster",
      "depends",
      "several",
      "considerations.",
      "size",
      "deployment",
      "topic",
      "offers",
      "lot",
      "services",
      "dependencies.",
      "helps",
      "decide",
      "number",
      "resources",
      "deployment.",
      "after",
      "completed",
      "see",
      "understand",
      "supported",
      "versions",
      "deploy",
      "application.",
      "considerable",
      "need",
      "applications",
      "plan",
      "deploy.",
      "differs",
      "based",
      "environment",
      "capabilities",
      "choose",
      "make",
      "sure",
      "obtained",
      "following",
      "areas",
      "database",
      "server",
      "storage",
      "servers",
      "network",
      "image",
      "repository",
      "kubernetes"
    ],
    "language": "en",
    "word_count": 75,
    "importance_score": 3.5,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "sizing and system requirements",
    "contentLower": "sizing your cluster depends on several considerations. the size your deployment topic offers you a lot of services and dependencies. it helps you decide on the number of resources required for your deployment. after you have completed the sizing, see the system requirements topic to understand the supported versions of the requirements to deploy the application. get the required infrastructure the size your deployment topic offers you a considerable number of resources you need for each of the applications you plan to deploy. the infrastructure differs based on the environment and the capabilities you choose to deploy. make sure you obtained the required infrastructure and the required size in the following areas: database server storage servers network resources image repository server kubernetes resources",
    "keywordsLower": [
      "sizing",
      "system",
      "requirements",
      "get",
      "required",
      "infrastructure",
      "cluster",
      "depends",
      "several",
      "considerations.",
      "size",
      "deployment",
      "topic",
      "offers",
      "lot",
      "services",
      "dependencies.",
      "helps",
      "decide",
      "number",
      "resources",
      "deployment.",
      "after",
      "completed",
      "see",
      "understand",
      "supported",
      "versions",
      "deploy",
      "application.",
      "considerable",
      "need",
      "applications",
      "plan",
      "deploy.",
      "differs",
      "based",
      "environment",
      "capabilities",
      "choose",
      "make",
      "sure",
      "obtained",
      "following",
      "areas",
      "database",
      "server",
      "storage",
      "servers",
      "network",
      "image",
      "repository",
      "kubernetes"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Size your deployment",
    "content": "OO Containerized is a containerized application meant to run inside a Kubernetes cluster. When installing OO Containerized, make sure that you have a Kubernetes cluster available and that the cluster has enough compute capacity (worker nodes) to accommodate the new deployment. In addition to the Kubernetes resources, OO Containerized requires also additional resources like databases and file storage. Find the use case for your deployment To understand the requirements decide the following deployment objectives: Deployment size Following are the deployment sizes: Deployment size Description Small Up to 5 tenants. Medium Up to 20 tenants. Deployment modes You can deploy using: Non HA mode: Intended for environments, where High Availability (HA) isn't required.HA mode: Intended for production environments, that required HA. An HA set up uses three master nodes and one of the master nodes has a virtual IP address. When that master node becomes unavailable, one of the remaining master nodes",
    "url": "sizedeploymentapphubooc",
    "filename": "sizedeploymentapphubooc",
    "headings": [
      "Find the use case for your deployment",
      "Deployment size",
      "Deployment modes",
      "Implications of deploying in Non HA mode"
    ],
    "keywords": [
      "OMT.It",
      "required.HA",
      "size",
      "deployment",
      "find",
      "case",
      "modes",
      "implications",
      "deploying",
      "non",
      "ha",
      "mode",
      "oo",
      "containerized",
      "application",
      "meant",
      "run",
      "inside",
      "kubernetes",
      "cluster.",
      "installing",
      "make",
      "sure",
      "cluster",
      "available",
      "enough",
      "compute",
      "capacity",
      "worker",
      "nodes",
      "accommodate",
      "new",
      "deployment.",
      "addition",
      "resources",
      "requires",
      "additional",
      "like",
      "databases",
      "file",
      "storage.",
      "understand",
      "requirements",
      "decide",
      "following",
      "objectives",
      "sizes",
      "description",
      "small",
      "tenants.",
      "medium",
      "20",
      "deploy",
      "intended",
      "environments",
      "high",
      "availability",
      "isn",
      "production",
      "required",
      "ha.",
      "set",
      "uses",
      "three",
      "master",
      "one",
      "virtual",
      "ip",
      "address.",
      "node",
      "becomes",
      "unavailable",
      "remaining",
      "gets",
      "accessing",
      "services",
      "through",
      "external",
      "hostname",
      "resolves",
      "address",
      "therefore",
      "still",
      "reachable",
      "after",
      "longer",
      "available.",
      "several",
      "restrictions",
      "limitations",
      "know",
      "before",
      "choose",
      "mode.",
      "there",
      "load",
      "balancing",
      "configurable",
      "resiliency",
      "postgresql"
    ],
    "language": "en",
    "word_count": 103,
    "importance_score": 5.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "size your deployment",
    "contentLower": "oo containerized is a containerized application meant to run inside a kubernetes cluster. when installing oo containerized, make sure that you have a kubernetes cluster available and that the cluster has enough compute capacity (worker nodes) to accommodate the new deployment. in addition to the kubernetes resources, oo containerized requires also additional resources like databases and file storage. find the use case for your deployment to understand the requirements decide the following deployment objectives: deployment size following are the deployment sizes: deployment size description small up to 5 tenants. medium up to 20 tenants. deployment modes you can deploy using: non ha mode: intended for environments, where high availability (ha) isn't required.ha mode: intended for production environments, that required ha. an ha set up uses three master nodes and one of the master nodes has a virtual ip address. when that master node becomes unavailable, one of the remaining master nodes",
    "keywordsLower": [
      "omt.it",
      "required.ha",
      "size",
      "deployment",
      "find",
      "case",
      "modes",
      "implications",
      "deploying",
      "non",
      "ha",
      "mode",
      "oo",
      "containerized",
      "application",
      "meant",
      "run",
      "inside",
      "kubernetes",
      "cluster.",
      "installing",
      "make",
      "sure",
      "cluster",
      "available",
      "enough",
      "compute",
      "capacity",
      "worker",
      "nodes",
      "accommodate",
      "new",
      "deployment.",
      "addition",
      "resources",
      "requires",
      "additional",
      "like",
      "databases",
      "file",
      "storage.",
      "understand",
      "requirements",
      "decide",
      "following",
      "objectives",
      "sizes",
      "description",
      "small",
      "tenants.",
      "medium",
      "20",
      "deploy",
      "intended",
      "environments",
      "high",
      "availability",
      "isn",
      "production",
      "required",
      "ha.",
      "set",
      "uses",
      "three",
      "master",
      "one",
      "virtual",
      "ip",
      "address.",
      "node",
      "becomes",
      "unavailable",
      "remaining",
      "gets",
      "accessing",
      "services",
      "through",
      "external",
      "hostname",
      "resolves",
      "address",
      "therefore",
      "still",
      "reachable",
      "after",
      "longer",
      "available.",
      "several",
      "restrictions",
      "limitations",
      "know",
      "before",
      "choose",
      "mode.",
      "there",
      "load",
      "balancing",
      "configurable",
      "resiliency",
      "postgresql"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "System requirements - AppHub",
    "content": "This section gives information about the required infrastructure and software with their supported versions. Kubernetes distributions The following Kubernetes distributions are supported in this release: Embedded Kubernetes packaged with OPTIC Management Toolkit (OMT).Amazon Elastic Kubernetes v 1.23, 1.24, 1.25. See Amazon Elastic Kubernetes Service (EKS) documentation.Azure Kubernetes Service (AKS) v 1.23, 1.24, 1.25. See Azure Kubernetes Service (AKS) documentation.Red Hat OpenShift Container Platform v 4.10, 4.11, 4.12. See Red Hat OpenShift documentation. OpenShift Container Platform deployment on managed cloud platforms isn't supported. Container image registry Kubernetes cluster needs access to a registry where the container images are located. You can set up any image registry that's Docker Registry HTTP API V2 compliant. For example, Elastic Container Registry for AWS. The images are published on Docker Hub. Make sure you have the required access to upload the OO Containerized",
    "url": "systemreqapphubooc",
    "filename": "systemreqapphubooc",
    "headings": [
      "Kubernetes distributions",
      "Container image registry",
      "Databases",
      "Relational database",
      "Storage",
      "Embedded Kubernetes",
      "AWS",
      "Red Hat OpenShift",
      "UID and GID",
      "Software requirements",
      "Operating systems",
      "Embedded Kubernetes",
      "External Kubernetes",
      "Browsers",
      "Screen resolution",
      "Languages",
      "Network requirements",
      "Network identification",
      "Communication connection on cloud",
      "Required port"
    ],
    "keywords": [
      "postgresql.conf",
      "16.1",
      "4.10",
      "1.24",
      "4.12",
      "documentation.Red",
      "1.25",
      "4.11",
      "1.23",
      "system",
      "requirements",
      "apphub",
      "kubernetes",
      "distributions",
      "container",
      "image",
      "registry",
      "databases",
      "relational",
      "database",
      "storage",
      "embedded",
      "aws",
      "red",
      "hat",
      "openshift",
      "uid",
      "gid",
      "software",
      "operating",
      "systems",
      "external",
      "browsers",
      "screen",
      "resolution",
      "languages",
      "network",
      "identification",
      "communication",
      "connection",
      "cloud",
      "required",
      "port",
      "section",
      "gives",
      "information",
      "about",
      "infrastructure",
      "supported",
      "versions.",
      "following",
      "release",
      "packaged",
      "optic",
      "management",
      "toolkit",
      "omt",
      ".amazon",
      "elastic",
      "1.25.",
      "see",
      "amazon",
      "service",
      "eks",
      "documentation.azure",
      "aks",
      "azure",
      "platform",
      "4.12.",
      "documentation.",
      "deployment",
      "managed",
      "platforms",
      "isn",
      "supported.",
      "cluster",
      "needs",
      "access",
      "images",
      "located.",
      "set",
      "any",
      "docker",
      "http",
      "api",
      "v2",
      "compliant.",
      "example",
      "aws.",
      "published",
      "hub.",
      "make",
      "sure",
      "upload",
      "oo",
      "containerized",
      "images.",
      "require",
      "urlimage",
      "pull"
    ],
    "language": "en",
    "word_count": 114,
    "importance_score": 6.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "system requirements - apphub",
    "contentLower": "this section gives information about the required infrastructure and software with their supported versions. kubernetes distributions the following kubernetes distributions are supported in this release: embedded kubernetes packaged with optic management toolkit (omt).amazon elastic kubernetes v 1.23, 1.24, 1.25. see amazon elastic kubernetes service (eks) documentation.azure kubernetes service (aks) v 1.23, 1.24, 1.25. see azure kubernetes service (aks) documentation.red hat openshift container platform v 4.10, 4.11, 4.12. see red hat openshift documentation. openshift container platform deployment on managed cloud platforms isn't supported. container image registry kubernetes cluster needs access to a registry where the container images are located. you can set up any image registry that's docker registry http api v2 compliant. for example, elastic container registry for aws. the images are published on docker hub. make sure you have the required access to upload the oo containerized",
    "keywordsLower": [
      "postgresql.conf",
      "16.1",
      "4.10",
      "1.24",
      "4.12",
      "documentation.red",
      "1.25",
      "4.11",
      "1.23",
      "system",
      "requirements",
      "apphub",
      "kubernetes",
      "distributions",
      "container",
      "image",
      "registry",
      "databases",
      "relational",
      "database",
      "storage",
      "embedded",
      "aws",
      "red",
      "hat",
      "openshift",
      "uid",
      "gid",
      "software",
      "operating",
      "systems",
      "external",
      "browsers",
      "screen",
      "resolution",
      "languages",
      "network",
      "identification",
      "communication",
      "connection",
      "cloud",
      "required",
      "port",
      "section",
      "gives",
      "information",
      "about",
      "infrastructure",
      "supported",
      "versions.",
      "following",
      "release",
      "packaged",
      "optic",
      "management",
      "toolkit",
      "omt",
      ".amazon",
      "elastic",
      "1.25.",
      "see",
      "amazon",
      "service",
      "eks",
      "documentation.azure",
      "aks",
      "azure",
      "platform",
      "4.12.",
      "documentation.",
      "deployment",
      "managed",
      "platforms",
      "isn",
      "supported.",
      "cluster",
      "needs",
      "access",
      "images",
      "located.",
      "set",
      "any",
      "docker",
      "http",
      "api",
      "v2",
      "compliant.",
      "example",
      "aws.",
      "published",
      "hub.",
      "make",
      "sure",
      "upload",
      "oo",
      "containerized",
      "images.",
      "require",
      "urlimage",
      "pull"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Set up prerequisites",
    "content": "This topic lists the tasks you must complete before deploying Operations Orchestration (OO) Containerized. Review each task and complete the ones that apply to your scenario. Integration admin user in Service Management Task Role Where to perform Environment Create OO integration admin user in the Service Management IdM (on-premises) Suite administrator Service Management IdM On-premises Create OO integration admin user in the Service Management IdM (EKS) Suite administrator Service Management IdM Amazon AWS Create OO integration admin user in the Service Management IdM (AKS) Suite administrator Service Management IdM Azure AKS Create OO integration admin user in the Service Management IdM (OpenShift) Suite administrator Service Management IdM Red Hat OpenShift Databases Create databases and respective users for OO Central, OO Scheduler, OO Controller, OO Session Manager, and AutoPass License Server. You can skip this step if you plan to deploy on-premises and use the option to create ",
    "url": "setupprerequisitesooc",
    "filename": "setupprerequisitesooc",
    "headings": [
      "Integration admin user in Service Management",
      "Databases",
      "Setup NFS/Elastic File System",
      "Create persistent volumes"
    ],
    "keywords": [
      "setupNFS.sh",
      "myserver.net",
      "volumes.yaml",
      "configureOONFS.sh",
      "set",
      "prerequisites",
      "integration",
      "admin",
      "user",
      "service",
      "management",
      "databases",
      "setup",
      "nfs",
      "elastic",
      "file",
      "system",
      "create",
      "persistent",
      "volumes",
      "topic",
      "lists",
      "tasks",
      "complete",
      "before",
      "deploying",
      "operations",
      "orchestration",
      "oo",
      "containerized.",
      "review",
      "task",
      "ones",
      "apply",
      "scenario.",
      "role",
      "perform",
      "environment",
      "idm",
      "on-premises",
      "suite",
      "administrator",
      "eks",
      "amazon",
      "aws",
      "aks",
      "azure",
      "openshift",
      "red",
      "hat",
      "respective",
      "users",
      "central",
      "scheduler",
      "controller",
      "session",
      "manager",
      "autopass",
      "license",
      "server.",
      "skip",
      "step",
      "plan",
      "deploy",
      "option",
      "database",
      "automatically",
      "apphub.",
      "configure",
      "external",
      "postgresql",
      "rds",
      "oo.",
      "premium",
      "files",
      "following",
      "steps",
      "copy",
      "save",
      "script",
      "bin",
      "bash",
      "path",
      "omt",
      "installation",
      "folder",
      "pth",
      "var",
      "vols",
      "itom",
      "echo",
      "rw",
      "sync",
      "anonuid",
      "anongid",
      "etc",
      "exports",
      "mkdir",
      "-p",
      "chmod"
    ],
    "language": "en",
    "word_count": 115,
    "importance_score": 5.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "set up prerequisites",
    "contentLower": "this topic lists the tasks you must complete before deploying operations orchestration (oo) containerized. review each task and complete the ones that apply to your scenario. integration admin user in service management task role where to perform environment create oo integration admin user in the service management idm (on-premises) suite administrator service management idm on-premises create oo integration admin user in the service management idm (eks) suite administrator service management idm amazon aws create oo integration admin user in the service management idm (aks) suite administrator service management idm azure aks create oo integration admin user in the service management idm (openshift) suite administrator service management idm red hat openshift databases create databases and respective users for oo central, oo scheduler, oo controller, oo session manager, and autopass license server. you can skip this step if you plan to deploy on-premises and use the option to create ",
    "keywordsLower": [
      "setupnfs.sh",
      "myserver.net",
      "volumes.yaml",
      "configureoonfs.sh",
      "set",
      "prerequisites",
      "integration",
      "admin",
      "user",
      "service",
      "management",
      "databases",
      "setup",
      "nfs",
      "elastic",
      "file",
      "system",
      "create",
      "persistent",
      "volumes",
      "topic",
      "lists",
      "tasks",
      "complete",
      "before",
      "deploying",
      "operations",
      "orchestration",
      "oo",
      "containerized.",
      "review",
      "task",
      "ones",
      "apply",
      "scenario.",
      "role",
      "perform",
      "environment",
      "idm",
      "on-premises",
      "suite",
      "administrator",
      "eks",
      "amazon",
      "aws",
      "aks",
      "azure",
      "openshift",
      "red",
      "hat",
      "respective",
      "users",
      "central",
      "scheduler",
      "controller",
      "session",
      "manager",
      "autopass",
      "license",
      "server.",
      "skip",
      "step",
      "plan",
      "deploy",
      "option",
      "database",
      "automatically",
      "apphub.",
      "configure",
      "external",
      "postgresql",
      "rds",
      "oo.",
      "premium",
      "files",
      "following",
      "steps",
      "copy",
      "save",
      "script",
      "bin",
      "bash",
      "path",
      "omt",
      "installation",
      "folder",
      "pth",
      "var",
      "vols",
      "itom",
      "echo",
      "rw",
      "sync",
      "anonuid",
      "anongid",
      "etc",
      "exports",
      "mkdir",
      "-p",
      "chmod"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "System requirements for OO RAS",
    "content": "This section provides information about the hardware and software requirements for the Operations Orchestration (OO) Remote Action Service (RAS) component. Software requirements Operating systems Operating system Architecture type Versions Microsoft Windows Server x86_x64 2022, 2025 SUSE Enterprise Linux x86_x64 15.x Red Hat Enterprise Linux x86_x64 8.3, 8.4, 8.6, 9.0, 10.0 Oracle Linux x86_x64 9.2 Rocky Linux x86_x64 9.3, 10.0 Other software Software framework Version .NET (Dot Net) Framework Full installation of Microsoft .NET Framework 4.5 or later. bzip2 To install OO RAS on Red Hat systems, you need this open-source compression program. If it doesn't already exist on your Linux system, you can download it from bzip2 website. Hardware requirements The hardware requirements described here are the minimal supported configuration. Component Description Processor Minimum: 2 GHz for single, or multiprocessor systems Minimum: 1 CPU core / 2 Threads Recommended: 4 CPU cores / 4–8 Threads ",
    "url": "supportmatrixooras",
    "filename": "supportmatrixooras",
    "headings": [
      "Software requirements",
      "Operating systems",
      "Other software",
      "Hardware requirements"
    ],
    "keywords": [
      "8.3",
      "10.0",
      "9.2",
      "4.5",
      "9.0",
      "8.4",
      "9.3",
      "8.6",
      "system",
      "requirements",
      "oo",
      "ras",
      "software",
      "operating",
      "systems",
      "hardware",
      "section",
      "provides",
      "information",
      "about",
      "operations",
      "orchestration",
      "remote",
      "action",
      "service",
      "component.",
      "architecture",
      "type",
      "versions",
      "microsoft",
      "windows",
      "server",
      "2022",
      "2025",
      "suse",
      "enterprise",
      "linux",
      "15.x",
      "red",
      "hat",
      "oracle",
      "rocky",
      "framework",
      "version",
      ".net",
      "dot",
      "net",
      "full",
      "installation",
      "later.",
      "bzip2",
      "install",
      "need",
      "open-source",
      "compression",
      "program.",
      "doesn",
      "already",
      "exist",
      "download",
      "website.",
      "described",
      "here",
      "minimal",
      "supported",
      "configuration.",
      "component",
      "description",
      "processor",
      "minimum",
      "ghz",
      "single",
      "multiprocessor",
      "cpu",
      "core",
      "threads",
      "recommended",
      "cores",
      "ram",
      "gb",
      "hard",
      "drive",
      "space",
      "gb¹",
      "takes",
      "less",
      "space.",
      "however",
      "flows",
      "run",
      "take",
      "depending",
      "complexity",
      "data",
      "processed",
      "respective",
      "flows."
    ],
    "language": "en",
    "word_count": 124,
    "importance_score": 5.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "system requirements for oo ras",
    "contentLower": "this section provides information about the hardware and software requirements for the operations orchestration (oo) remote action service (ras) component. software requirements operating systems operating system architecture type versions microsoft windows server x86_x64 2022, 2025 suse enterprise linux x86_x64 15.x red hat enterprise linux x86_x64 8.3, 8.4, 8.6, 9.0, 10.0 oracle linux x86_x64 9.2 rocky linux x86_x64 9.3, 10.0 other software software framework version .net (dot net) framework full installation of microsoft .net framework 4.5 or later. bzip2 to install oo ras on red hat systems, you need this open-source compression program. if it doesn't already exist on your linux system, you can download it from bzip2 website. hardware requirements the hardware requirements described here are the minimal supported configuration. component description processor minimum: 2 ghz for single, or multiprocessor systems minimum: 1 cpu core / 2 threads recommended: 4 cpu cores / 4–8 threads ",
    "keywordsLower": [
      "8.3",
      "10.0",
      "9.2",
      "4.5",
      "9.0",
      "8.4",
      "9.3",
      "8.6",
      "system",
      "requirements",
      "oo",
      "ras",
      "software",
      "operating",
      "systems",
      "hardware",
      "section",
      "provides",
      "information",
      "about",
      "operations",
      "orchestration",
      "remote",
      "action",
      "service",
      "component.",
      "architecture",
      "type",
      "versions",
      "microsoft",
      "windows",
      "server",
      "2022",
      "2025",
      "suse",
      "enterprise",
      "linux",
      "15.x",
      "red",
      "hat",
      "oracle",
      "rocky",
      "framework",
      "version",
      ".net",
      "dot",
      "net",
      "full",
      "installation",
      "later.",
      "bzip2",
      "install",
      "need",
      "open-source",
      "compression",
      "program.",
      "doesn",
      "already",
      "exist",
      "download",
      "website.",
      "described",
      "here",
      "minimal",
      "supported",
      "configuration.",
      "component",
      "description",
      "processor",
      "minimum",
      "ghz",
      "single",
      "multiprocessor",
      "cpu",
      "core",
      "threads",
      "recommended",
      "cores",
      "ram",
      "gb",
      "hard",
      "drive",
      "space",
      "gb¹",
      "takes",
      "less",
      "space.",
      "however",
      "flows",
      "run",
      "take",
      "depending",
      "complexity",
      "data",
      "processed",
      "respective",
      "flows."
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "System requirements for OO Workflow Designer",
    "content": "This section provides the system requirements information and instructions to install Operations Orchestration (OO) Workflow Designer. You can install the software using the installer or silent installation properties file. Software requirements Operating systems The following operating systems are supported: Operating system Architecture type Versions Microsoft Windows Server x86_x64 2022, 2025 SUSE Enterprise Linux x86_x64 15.x Red Hat Enterprise Linux x86_x64 8.3, 8.4, 8.6, 9.0, 10.0 Oracle Linux x86_x64 9.2 Rocky Linux x86_x64 9.3, 10.0 Other software bzip2: To install OO Workflow Designer, you need this open-source compression program. If it doesn't already exist on your Linux system, you can download it from bzip2 website. Databases Database Versions Oracle 19c PostgreSQL 14.x, 15.x, 16.x, 17.x Microsoft SQL Server 2016, 2017, 2019, 2022 Hardware requirements OO Workflow Designer The hardware requirements described here are the minimum supported configuration. These requirements ",
    "url": "supportmatrixoowfd",
    "filename": "supportmatrixoowfd",
    "headings": [
      "Software requirements",
      "Operating systems",
      "Other software",
      "Databases",
      "Hardware requirements",
      "OO Workflow Designer"
    ],
    "keywords": [
      "8.3",
      "10.0",
      "9.2",
      "9.0",
      "8.4",
      "9.3",
      "8.6",
      "system",
      "requirements",
      "oo",
      "workflow",
      "designer",
      "software",
      "operating",
      "systems",
      "databases",
      "hardware",
      "section",
      "provides",
      "information",
      "instructions",
      "install",
      "operations",
      "orchestration",
      "designer.",
      "installer",
      "silent",
      "installation",
      "properties",
      "file.",
      "following",
      "supported",
      "architecture",
      "type",
      "versions",
      "microsoft",
      "windows",
      "server",
      "2022",
      "2025",
      "suse",
      "enterprise",
      "linux",
      "15.x",
      "red",
      "hat",
      "oracle",
      "rocky",
      "bzip2",
      "need",
      "open-source",
      "compression",
      "program.",
      "doesn",
      "already",
      "exist",
      "download",
      "website.",
      "database",
      "19c",
      "postgresql",
      "14.x",
      "16.x",
      "17.x",
      "sql",
      "2016",
      "2017",
      "2019",
      "described",
      "here",
      "minimum",
      "configuration.",
      "on-premises",
      "installations",
      "key",
      "components",
      "installed",
      "customer",
      "site.",
      "component",
      "requirement",
      "per",
      "cpu",
      "gigahertz",
      "ghz",
      "single",
      "processor",
      "multiprocessor",
      "systems.",
      "according",
      "vendor",
      "recommendations",
      "less",
      "cores",
      "core",
      "recommended",
      "memory",
      "ram",
      "specified",
      "gb"
    ],
    "language": "en",
    "word_count": 116,
    "importance_score": 5.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "system requirements for oo workflow designer",
    "contentLower": "this section provides the system requirements information and instructions to install operations orchestration (oo) workflow designer. you can install the software using the installer or silent installation properties file. software requirements operating systems the following operating systems are supported: operating system architecture type versions microsoft windows server x86_x64 2022, 2025 suse enterprise linux x86_x64 15.x red hat enterprise linux x86_x64 8.3, 8.4, 8.6, 9.0, 10.0 oracle linux x86_x64 9.2 rocky linux x86_x64 9.3, 10.0 other software bzip2: to install oo workflow designer, you need this open-source compression program. if it doesn't already exist on your linux system, you can download it from bzip2 website. databases database versions oracle 19c postgresql 14.x, 15.x, 16.x, 17.x microsoft sql server 2016, 2017, 2019, 2022 hardware requirements oo workflow designer the hardware requirements described here are the minimum supported configuration. these requirements ",
    "keywordsLower": [
      "8.3",
      "10.0",
      "9.2",
      "9.0",
      "8.4",
      "9.3",
      "8.6",
      "system",
      "requirements",
      "oo",
      "workflow",
      "designer",
      "software",
      "operating",
      "systems",
      "databases",
      "hardware",
      "section",
      "provides",
      "information",
      "instructions",
      "install",
      "operations",
      "orchestration",
      "designer.",
      "installer",
      "silent",
      "installation",
      "properties",
      "file.",
      "following",
      "supported",
      "architecture",
      "type",
      "versions",
      "microsoft",
      "windows",
      "server",
      "2022",
      "2025",
      "suse",
      "enterprise",
      "linux",
      "15.x",
      "red",
      "hat",
      "oracle",
      "rocky",
      "bzip2",
      "need",
      "open-source",
      "compression",
      "program.",
      "doesn",
      "already",
      "exist",
      "download",
      "website.",
      "database",
      "19c",
      "postgresql",
      "14.x",
      "16.x",
      "17.x",
      "sql",
      "2016",
      "2017",
      "2019",
      "described",
      "here",
      "minimum",
      "configuration.",
      "on-premises",
      "installations",
      "key",
      "components",
      "installed",
      "customer",
      "site.",
      "component",
      "requirement",
      "per",
      "cpu",
      "gigahertz",
      "ghz",
      "single",
      "processor",
      "multiprocessor",
      "systems.",
      "according",
      "vendor",
      "recommendations",
      "less",
      "cores",
      "core",
      "recommended",
      "memory",
      "ram",
      "specified",
      "gb"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Set up database environment for OO Workflow Designer",
    "content": "This topic provides the database administrator required information to configure various types of databases with the OO Workflow Designer. Overview The meaning of the term “database” depends on the database vendor/technology used. In Oracle, the term “database” relates to a collection of files containing data and metadata. A single Oracle database may contain one or more schemas (and users). A Microsoft SQL Server “database” is closer in definition to Oracle’s \"schema\" than to Oracle’s \"database\". To avoid confusion, this topic will use the following terms: Instance/server–the software and memory structures providing Relational Database Management System (RDBMS) services Database–the entity containing tables, views, indexes, and more Review the following points related to the database usage: OO Workflow Designer requires a single database. This database may coexist with other databases contained in a database server. OO Workflow Designer database connectivity relies on Java JDBC. If yo",
    "url": "setupdatabaseoowfd",
    "filename": "setupdatabaseoowfd",
    "headings": [
      "Overview",
      "Language Support",
      "Use database clusters",
      "Database security",
      "Database specific adaptations",
      "Database sizing",
      "Hardware requirements"
    ],
    "keywords": [
      "postgresql.conf",
      "set",
      "database",
      "environment",
      "oo",
      "workflow",
      "designer",
      "overview",
      "language",
      "support",
      "clusters",
      "security",
      "specific",
      "adaptations",
      "sizing",
      "hardware",
      "requirements",
      "topic",
      "provides",
      "administrator",
      "required",
      "information",
      "configure",
      "various",
      "types",
      "databases",
      "designer.",
      "meaning",
      "term",
      "depends",
      "vendor",
      "technology",
      "used.",
      "oracle",
      "relates",
      "collection",
      "files",
      "containing",
      "data",
      "metadata.",
      "single",
      "contain",
      "one",
      "schemas",
      "users",
      "microsoft",
      "sql",
      "server",
      "closer",
      "definition",
      "schema",
      "avoid",
      "confusion",
      "following",
      "terms",
      "instance",
      "software",
      "memory",
      "structures",
      "providing",
      "relational",
      "management",
      "system",
      "rdbms",
      "services",
      "entity",
      "tables",
      "views",
      "indexes",
      "review",
      "points",
      "related",
      "usage",
      "requires",
      "database.",
      "coexist",
      "contained",
      "server.",
      "connectivity",
      "relies",
      "java",
      "jdbc.",
      "measures",
      "see",
      "jdbc",
      "documentation",
      "learn",
      "connection",
      "url",
      "format.",
      "contains",
      "about",
      "describes",
      "settings.",
      "settings",
      "aren",
      "specified",
      "leave",
      "default",
      "values"
    ],
    "language": "en",
    "word_count": 106,
    "importance_score": 5.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "set up database environment for oo workflow designer",
    "contentLower": "this topic provides the database administrator required information to configure various types of databases with the oo workflow designer. overview the meaning of the term “database” depends on the database vendor/technology used. in oracle, the term “database” relates to a collection of files containing data and metadata. a single oracle database may contain one or more schemas (and users). a microsoft sql server “database” is closer in definition to oracle’s \"schema\" than to oracle’s \"database\". to avoid confusion, this topic will use the following terms: instance/server–the software and memory structures providing relational database management system (rdbms) services database–the entity containing tables, views, indexes, and more review the following points related to the database usage: oo workflow designer requires a single database. this database may coexist with other databases contained in a database server. oo workflow designer database connectivity relies on java jdbc. if yo",
    "keywordsLower": [
      "postgresql.conf",
      "set",
      "database",
      "environment",
      "oo",
      "workflow",
      "designer",
      "overview",
      "language",
      "support",
      "clusters",
      "security",
      "specific",
      "adaptations",
      "sizing",
      "hardware",
      "requirements",
      "topic",
      "provides",
      "administrator",
      "required",
      "information",
      "configure",
      "various",
      "types",
      "databases",
      "designer.",
      "meaning",
      "term",
      "depends",
      "vendor",
      "technology",
      "used.",
      "oracle",
      "relates",
      "collection",
      "files",
      "containing",
      "data",
      "metadata.",
      "single",
      "contain",
      "one",
      "schemas",
      "users",
      "microsoft",
      "sql",
      "server",
      "closer",
      "definition",
      "schema",
      "avoid",
      "confusion",
      "following",
      "terms",
      "instance",
      "software",
      "memory",
      "structures",
      "providing",
      "relational",
      "management",
      "system",
      "rdbms",
      "services",
      "entity",
      "tables",
      "views",
      "indexes",
      "review",
      "points",
      "related",
      "usage",
      "requires",
      "database.",
      "coexist",
      "contained",
      "server.",
      "connectivity",
      "relies",
      "java",
      "jdbc.",
      "measures",
      "see",
      "jdbc",
      "documentation",
      "learn",
      "connection",
      "url",
      "format.",
      "contains",
      "about",
      "describes",
      "settings.",
      "settings",
      "aren",
      "specified",
      "leave",
      "default",
      "values"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Silent installation of OO Workflow Designer",
    "content": "This section describes how to perform a silent installation of an OO Workflow Designer. To install an OO Workflow Designer in a silent mode: From the extracted installation zip file, using a text editor, open the text file sample-oo-designer-silent.properties that has the required installation and configuration settings. Save a copy of the text file as silent.properties. Remove the comment sign (#) from the properties that you need, and add the value for each of these properties. From a command line, type the following example code: installer-oo-designer-win-<version>.exe -gm2 -s c:\\\\temp\\my-silent.properties To disable the extracting installation files progress bar, add to the command line -gm2 before -s. You can use the -n option if you don't want to start OO Workflow Designer after the installation has completed. The gm2 isn't supported with Linux. The -s property accepts either a full or a relative path depending on the operating system: Windows: Relative to the location of the .ex",
    "url": "deployoowfdsilent",
    "filename": "deployoowfdsilent",
    "headings": [
      "Linux guided install option"
    ],
    "keywords": [
      "oo_workflow_designer_guided_install.sh",
      "installer.exe",
      "silent",
      "installation",
      "oo",
      "workflow",
      "designer",
      "linux",
      "guided",
      "install",
      "option",
      "section",
      "describes",
      "perform",
      "designer.",
      "mode",
      "extracted",
      "zip",
      "file",
      "text",
      "editor",
      "open",
      "sample-oo-designer-silent.properties",
      "required",
      "configuration",
      "settings.",
      "save",
      "copy",
      "silent.properties.",
      "remove",
      "comment",
      "sign",
      "properties",
      "need",
      "add",
      "value",
      "properties.",
      "command",
      "line",
      "type",
      "following",
      "example",
      "code",
      "installer-oo-designer-win-.exe",
      "-gm2",
      "-s",
      "temp",
      "my-silent.properties",
      "disable",
      "extracting",
      "files",
      "progress",
      "bar",
      "before",
      "-s.",
      "-n",
      "don",
      "want",
      "start",
      "after",
      "completed.",
      "gm2",
      "isn",
      "supported",
      "linux.",
      "property",
      "accepts",
      "either",
      "full",
      "relative",
      "path",
      "depending",
      "operating",
      "system",
      "windows",
      "location",
      ".exe",
      "file.",
      "dira",
      "current",
      "directory",
      "dirb",
      "located",
      "under",
      "contains",
      "installer",
      "silent.properties",
      "prompt",
      "window",
      "enter",
      "two",
      "backslashes",
      "one",
      "backslash",
      "make",
      "sure",
      "folder",
      "download",
      "doesn",
      "contain"
    ],
    "language": "en",
    "word_count": 102,
    "importance_score": 2.5,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "silent installation of oo workflow designer",
    "contentLower": "this section describes how to perform a silent installation of an oo workflow designer. to install an oo workflow designer in a silent mode: from the extracted installation zip file, using a text editor, open the text file sample-oo-designer-silent.properties that has the required installation and configuration settings. save a copy of the text file as silent.properties. remove the comment sign (#) from the properties that you need, and add the value for each of these properties. from a command line, type the following example code: installer-oo-designer-win-<version>.exe -gm2 -s c:\\\\temp\\my-silent.properties to disable the extracting installation files progress bar, add to the command line -gm2 before -s. you can use the -n option if you don't want to start oo workflow designer after the installation has completed. the gm2 isn't supported with linux. the -s property accepts either a full or a relative path depending on the operating system: windows: relative to the location of the .ex",
    "keywordsLower": [
      "oo_workflow_designer_guided_install.sh",
      "installer.exe",
      "silent",
      "installation",
      "oo",
      "workflow",
      "designer",
      "linux",
      "guided",
      "install",
      "option",
      "section",
      "describes",
      "perform",
      "designer.",
      "mode",
      "extracted",
      "zip",
      "file",
      "text",
      "editor",
      "open",
      "sample-oo-designer-silent.properties",
      "required",
      "configuration",
      "settings.",
      "save",
      "copy",
      "silent.properties.",
      "remove",
      "comment",
      "sign",
      "properties",
      "need",
      "add",
      "value",
      "properties.",
      "command",
      "line",
      "type",
      "following",
      "example",
      "code",
      "installer-oo-designer-win-.exe",
      "-gm2",
      "-s",
      "temp",
      "my-silent.properties",
      "disable",
      "extracting",
      "files",
      "progress",
      "bar",
      "before",
      "-s.",
      "-n",
      "don",
      "want",
      "start",
      "after",
      "completed.",
      "gm2",
      "isn",
      "supported",
      "linux.",
      "property",
      "accepts",
      "either",
      "full",
      "relative",
      "path",
      "depending",
      "operating",
      "system",
      "windows",
      "location",
      ".exe",
      "file.",
      "dira",
      "current",
      "directory",
      "dirb",
      "located",
      "under",
      "contains",
      "installer",
      "silent.properties",
      "prompt",
      "window",
      "enter",
      "two",
      "backslashes",
      "one",
      "backslash",
      "make",
      "sure",
      "folder",
      "download",
      "doesn",
      "contain"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "System requirements for OO Studio",
    "content": "This section provides information about the software requirements for Operations Orchestration (OO) Studio. Operating systems The following operating systems are supported: Operating system Architecture type Versions Microsoft Windows Server x86_x64 2012, 2012 R2, 2016, 2019, 2022 Microsoft Windows x86_x64 10, 11 Additional requirements Requirement Version Service packs Download and install Microsoft Visual C++ 2010 (x86) and 2013 (x86 or x64) Redistributable Packages, regardless of your Windows version, and then restart to apply the updates. Git client It's recommended to install the 64-bit Git client 2.47.0 version for Windows Setup to use the Studio Git integration feature. .Net (Dot Net) Framework Microsoft .NET Framework 3.5.1 SP1 to start the PowerShell Wizard.",
    "url": "supportmatrixoostudio",
    "filename": "supportmatrixoostudio",
    "headings": [
      "Operating systems",
      "Additional requirements"
    ],
    "keywords": [
      "2.47",
      "2.47.0",
      "3.5.1",
      "system",
      "requirements",
      "oo",
      "studio",
      "operating",
      "systems",
      "additional",
      "section",
      "provides",
      "information",
      "about",
      "software",
      "operations",
      "orchestration",
      "studio.",
      "following",
      "supported",
      "architecture",
      "type",
      "versions",
      "microsoft",
      "windows",
      "server",
      "2012",
      "r2",
      "2016",
      "2019",
      "2022",
      "10",
      "11",
      "requirement",
      "version",
      "service",
      "packs",
      "download",
      "install",
      "visual",
      "2010",
      "x86",
      "2013",
      "x64",
      "redistributable",
      "packages",
      "regardless",
      "restart",
      "apply",
      "updates.",
      "git",
      "client",
      "recommended",
      "64-bit",
      "setup",
      "integration",
      "feature.",
      ".net",
      "dot",
      "net",
      "framework",
      "sp1",
      "start",
      "powershell",
      "wizard."
    ],
    "language": "en",
    "word_count": 92,
    "importance_score": 4.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "system requirements for oo studio",
    "contentLower": "this section provides information about the software requirements for operations orchestration (oo) studio. operating systems the following operating systems are supported: operating system architecture type versions microsoft windows server x86_x64 2012, 2012 r2, 2016, 2019, 2022 microsoft windows x86_x64 10, 11 additional requirements requirement version service packs download and install microsoft visual c++ 2010 (x86) and 2013 (x86 or x64) redistributable packages, regardless of your windows version, and then restart to apply the updates. git client it's recommended to install the 64-bit git client 2.47.0 version for windows setup to use the studio git integration feature. .net (dot net) framework microsoft .net framework 3.5.1 sp1 to start the powershell wizard.",
    "keywordsLower": [
      "2.47",
      "2.47.0",
      "3.5.1",
      "system",
      "requirements",
      "oo",
      "studio",
      "operating",
      "systems",
      "additional",
      "section",
      "provides",
      "information",
      "about",
      "software",
      "operations",
      "orchestration",
      "studio.",
      "following",
      "supported",
      "architecture",
      "type",
      "versions",
      "microsoft",
      "windows",
      "server",
      "2012",
      "r2",
      "2016",
      "2019",
      "2022",
      "10",
      "11",
      "requirement",
      "version",
      "service",
      "packs",
      "download",
      "install",
      "visual",
      "2010",
      "x86",
      "2013",
      "x64",
      "redistributable",
      "packages",
      "regardless",
      "restart",
      "apply",
      "updates.",
      "git",
      "client",
      "recommended",
      "64-bit",
      "setup",
      "integration",
      "feature.",
      ".net",
      "dot",
      "net",
      "framework",
      "sp1",
      "start",
      "powershell",
      "wizard."
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Storage related infrastructure",
    "content": "This topic provides you the required specifications to configure the storage server requirements. Skip this section if you have already set up the required storage infrastructure, either by using the ITOM Cloud Deployment Toolkit or by following the system requirements topic. If a container stops or restarts, all changes made inside the container are lost. To save information such as configuration files and databases, the information must be stored external to the container in an entity called Persistent Volume (PV) within the cluster. To decide the size for each of the disks, refer to the sizing calculator. The cluster components (say a Pod) access a storage volume in the following flow: Pod -> PVC -> PV-> Storage ( for example, NFS) A PV is a storage object in a cluster that maps to a physical storage for example, an NFS server volume. When you create a PV, the mapped physical storage volume becomes available in the Kubernetes cluster. The cluster components use this storage for pers",
    "url": "402-storagereqs",
    "filename": "402-storagereqs",
    "headings": [
      "Static provisioning without storage provisioner",
      "Dynamic provisioning with storage provisioner",
      "Storage configuration guidelines",
      "AWS",
      "Azure",
      "Google Kubernetes Engine",
      "Red Hat OpenShift",
      "High availability for storage"
    ],
    "keywords": [
      "https://kubernetes.io/docs/reference/labels-annotations-taints/#topologykubernetesiozone",
      "2.5",
      "kubernetes.io",
      "volumes.data",
      "63.9",
      "storage",
      "related",
      "infrastructure",
      "static",
      "provisioning",
      "provisioner",
      "dynamic",
      "configuration",
      "guidelines",
      "aws",
      "azure",
      "google",
      "kubernetes",
      "engine",
      "red",
      "hat",
      "openshift",
      "high",
      "availability",
      "topic",
      "provides",
      "required",
      "specifications",
      "configure",
      "server",
      "requirements.",
      "skip",
      "section",
      "already",
      "set",
      "either",
      "itom",
      "cloud",
      "deployment",
      "toolkit",
      "following",
      "system",
      "requirements",
      "topic.",
      "container",
      "stops",
      "restarts",
      "all",
      "changes",
      "made",
      "inside",
      "lost.",
      "save",
      "information",
      "such",
      "files",
      "databases",
      "stored",
      "external",
      "entity",
      "called",
      "persistent",
      "volume",
      "pv",
      "cluster.",
      "decide",
      "size",
      "disks",
      "refer",
      "sizing",
      "calculator.",
      "cluster",
      "components",
      "say",
      "pod",
      "access",
      "flow",
      "pvc",
      "pv-",
      "example",
      "nfs",
      "object",
      "maps",
      "physical",
      "volume.",
      "create",
      "mapped",
      "becomes",
      "available",
      "data",
      "storage.",
      "however",
      "don",
      "directly.",
      "turn",
      "claim",
      "intermediary",
      "between",
      "operations",
      "platform"
    ],
    "language": "en",
    "word_count": 98,
    "importance_score": 6.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "storage related infrastructure",
    "contentLower": "this topic provides you the required specifications to configure the storage server requirements. skip this section if you have already set up the required storage infrastructure, either by using the itom cloud deployment toolkit or by following the system requirements topic. if a container stops or restarts, all changes made inside the container are lost. to save information such as configuration files and databases, the information must be stored external to the container in an entity called persistent volume (pv) within the cluster. to decide the size for each of the disks, refer to the sizing calculator. the cluster components (say a pod) access a storage volume in the following flow: pod -> pvc -> pv-> storage ( for example, nfs) a pv is a storage object in a cluster that maps to a physical storage for example, an nfs server volume. when you create a pv, the mapped physical storage volume becomes available in the kubernetes cluster. the cluster components use this storage for pers",
    "keywordsLower": [
      "https://kubernetes.io/docs/reference/labels-annotations-taints/#topologykubernetesiozone",
      "2.5",
      "kubernetes.io",
      "volumes.data",
      "63.9",
      "storage",
      "related",
      "infrastructure",
      "static",
      "provisioning",
      "provisioner",
      "dynamic",
      "configuration",
      "guidelines",
      "aws",
      "azure",
      "google",
      "kubernetes",
      "engine",
      "red",
      "hat",
      "openshift",
      "high",
      "availability",
      "topic",
      "provides",
      "required",
      "specifications",
      "configure",
      "server",
      "requirements.",
      "skip",
      "section",
      "already",
      "set",
      "either",
      "itom",
      "cloud",
      "deployment",
      "toolkit",
      "following",
      "system",
      "requirements",
      "topic.",
      "container",
      "stops",
      "restarts",
      "all",
      "changes",
      "made",
      "inside",
      "lost.",
      "save",
      "information",
      "such",
      "files",
      "databases",
      "stored",
      "external",
      "entity",
      "called",
      "persistent",
      "volume",
      "pv",
      "cluster.",
      "decide",
      "size",
      "disks",
      "refer",
      "sizing",
      "calculator.",
      "cluster",
      "components",
      "say",
      "pod",
      "access",
      "flow",
      "pvc",
      "pv-",
      "example",
      "nfs",
      "object",
      "maps",
      "physical",
      "volume.",
      "create",
      "mapped",
      "becomes",
      "available",
      "data",
      "storage.",
      "however",
      "don",
      "directly.",
      "turn",
      "claim",
      "intermediary",
      "between",
      "operations",
      "platform"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Set up prerequisites",
    "content": "After creating Operations Platform namespace, complete the following tasks before deploying Operations Platform based on your requirements: Create Operations Platform relational database using a script Enable TLS on PostgreSQL Enable TLS in Oracle Install Vertica Create storage class manually for AWS Create persistent volumes Create local persistent volumes on worker nodes Install storage provisioner chart Install AWS load balancer and configure service",
    "url": "402-opsplatformprereqs",
    "filename": "402-opsplatformprereqs",
    "headings": [],
    "keywords": [
      "set",
      "prerequisites",
      "after",
      "creating",
      "operations",
      "platform",
      "namespace",
      "complete",
      "following",
      "tasks",
      "before",
      "deploying",
      "based",
      "requirements",
      "create",
      "relational",
      "database",
      "script",
      "enable",
      "tls",
      "postgresql",
      "oracle",
      "install",
      "vertica",
      "storage",
      "class",
      "manually",
      "aws",
      "persistent",
      "volumes",
      "local",
      "worker",
      "nodes",
      "provisioner",
      "chart",
      "load",
      "balancer",
      "configure",
      "service"
    ],
    "language": "en",
    "word_count": 54,
    "importance_score": 2.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "set up prerequisites",
    "contentLower": "after creating operations platform namespace, complete the following tasks before deploying operations platform based on your requirements: create operations platform relational database using a script enable tls on postgresql enable tls in oracle install vertica create storage class manually for aws create persistent volumes create local persistent volumes on worker nodes install storage provisioner chart install aws load balancer and configure service",
    "keywordsLower": [
      "set",
      "prerequisites",
      "after",
      "creating",
      "operations",
      "platform",
      "namespace",
      "complete",
      "following",
      "tasks",
      "before",
      "deploying",
      "based",
      "requirements",
      "create",
      "relational",
      "database",
      "script",
      "enable",
      "tls",
      "postgresql",
      "oracle",
      "install",
      "vertica",
      "storage",
      "class",
      "manually",
      "aws",
      "persistent",
      "volumes",
      "local",
      "worker",
      "nodes",
      "provisioner",
      "chart",
      "load",
      "balancer",
      "configure",
      "service"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Register application namespace in Operations Platform",
    "content": "The application services need to access Operations Platform to ensure that communication from the application services running within the same Kubernetes cluster and cross namespace is allowed. For application services to access Operations Platform, register the respective application namespaces in Operations Platform. Only the registered namespaces have authorized access. To ensure that only the registered namespaces can request certificates, use op-tms-cli to register your application namespace. When you register your application's namespace in Operations Platform, it automatically handles the RE CA certificate exchange. Register an application namespace The Tenant Management Service CLI, op-tms-cli manages the tenant lifecycle and supports application namespace registration. You can find the op-tms-cli-<version>.tar.gz file in the directory where you have unzipped the op-chart-<version>.zip file, under the subdirectory structure, op-chart\\tools\\op-tms-cli\\. To unzip the file, you ca",
    "url": "402-opvaultregisterappnamespace",
    "filename": "402-opvaultregisterappnamespace",
    "headings": [
      "Register an application namespace"
    ],
    "keywords": [
      "xx.tar",
      "tar.gz",
      "register",
      "application",
      "namespace",
      "operations",
      "platform",
      "services",
      "need",
      "access",
      "ensure",
      "communication",
      "running",
      "same",
      "kubernetes",
      "cluster",
      "cross",
      "allowed.",
      "respective",
      "namespaces",
      "platform.",
      "registered",
      "authorized",
      "access.",
      "request",
      "certificates",
      "op-tms-cli",
      "namespace.",
      "automatically",
      "handles",
      "re",
      "ca",
      "certificate",
      "exchange.",
      "tenant",
      "management",
      "service",
      "cli",
      "manages",
      "lifecycle",
      "supports",
      "registration.",
      "find",
      "op-tms-cli-.tar.gz",
      "file",
      "directory",
      "unzipped",
      "op-chart-.zip",
      "under",
      "subdirectory",
      "structure",
      "op-chart",
      "tools",
      "unzip",
      "copy",
      "choice",
      "parent",
      "op-tms-cli.",
      "run",
      "following",
      "command",
      "tar",
      "-xvf",
      "op-tms-cli-xx.x.x-xx.tar.gz",
      "bastion",
      "node",
      "installed",
      "navigate",
      "--appnamespace",
      "--opnamespace",
      "created.",
      "example",
      "opsb",
      "nom.",
      "created",
      "installation.",
      "ai",
      "op",
      "network",
      "nom",
      "here",
      "response",
      "shown",
      "see",
      "similar",
      "starting",
      "op-tms-cli-tool",
      "note",
      "tool",
      "executed",
      "host",
      "managed",
      "k8s",
      "control",
      "plane",
      "embedded",
      "registering",
      "name",
      "provider",
      "successfully"
    ],
    "language": "en",
    "word_count": 91,
    "importance_score": 2.5,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "register application namespace in operations platform",
    "contentLower": "the application services need to access operations platform to ensure that communication from the application services running within the same kubernetes cluster and cross namespace is allowed. for application services to access operations platform, register the respective application namespaces in operations platform. only the registered namespaces have authorized access. to ensure that only the registered namespaces can request certificates, use op-tms-cli to register your application namespace. when you register your application's namespace in operations platform, it automatically handles the re ca certificate exchange. register an application namespace the tenant management service cli, op-tms-cli manages the tenant lifecycle and supports application namespace registration. you can find the op-tms-cli-<version>.tar.gz file in the directory where you have unzipped the op-chart-<version>.zip file, under the subdirectory structure, op-chart\\tools\\op-tms-cli\\. to unzip the file, you ca",
    "keywordsLower": [
      "xx.tar",
      "tar.gz",
      "register",
      "application",
      "namespace",
      "operations",
      "platform",
      "services",
      "need",
      "access",
      "ensure",
      "communication",
      "running",
      "same",
      "kubernetes",
      "cluster",
      "cross",
      "allowed.",
      "respective",
      "namespaces",
      "platform.",
      "registered",
      "authorized",
      "access.",
      "request",
      "certificates",
      "op-tms-cli",
      "namespace.",
      "automatically",
      "handles",
      "re",
      "ca",
      "certificate",
      "exchange.",
      "tenant",
      "management",
      "service",
      "cli",
      "manages",
      "lifecycle",
      "supports",
      "registration.",
      "find",
      "op-tms-cli-.tar.gz",
      "file",
      "directory",
      "unzipped",
      "op-chart-.zip",
      "under",
      "subdirectory",
      "structure",
      "op-chart",
      "tools",
      "unzip",
      "copy",
      "choice",
      "parent",
      "op-tms-cli.",
      "run",
      "following",
      "command",
      "tar",
      "-xvf",
      "op-tms-cli-xx.x.x-xx.tar.gz",
      "bastion",
      "node",
      "installed",
      "navigate",
      "--appnamespace",
      "--opnamespace",
      "created.",
      "example",
      "opsb",
      "nom.",
      "created",
      "installation.",
      "ai",
      "op",
      "network",
      "nom",
      "here",
      "response",
      "shown",
      "see",
      "similar",
      "starting",
      "op-tms-cli-tool",
      "note",
      "tool",
      "executed",
      "host",
      "managed",
      "k8s",
      "control",
      "plane",
      "embedded",
      "registering",
      "name",
      "provider",
      "successfully"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Set up a secure connection between SMA and UCMDB Gateway",
    "content": "To set up a secure connection between Service Management and the UCMDB Gateway, you need to import the root CA certificate of both parties into each other. If the CA certificates are changed on either side, you need to import the new CA certificate chains to the other side again. Get the root CA certificate of UCMDB Gateway (classic UD/UCMDB) Get the cmsrootca.crt file from the ssl folder in the unzipped installer package of UCMDB Gateway for classic UD/UCMDB. Get the root CA certificate of UCMDB Gateway (containerized UD/UCMDB) Use one of the following methods to get the root CA certificate. From the browser: Log in to UCMDB Gateway (https://<UCMDB_HOSTNAME>:<UCMDB_PORT>/cms) from the browser. As an example, the following are steps for Chrome. Click the lock icon before the URL on the address bar. Click Connection is secure Click Certificate is valid. On the Certification Viewer, click Details. In the Certificate Hierarchy, select the site root certificate (the topmost one), and then ",
    "url": "nativesacmsslconnection",
    "filename": "nativesacmsslconnection",
    "headings": [
      "Get the root CA certificate of UCMDB Gateway (classic UD/UCMDB)",
      "Get the root CA certificate of UCMDB Gateway (containerized UD/UCMDB)",
      "Set the permission for the certificate file",
      "Import the UCMDB Gateway root CA certificate to the Suite",
      "Classic deployment",
      "Helm deployment",
      "Import the Service Management root CA certificate to UCMDB Gateway (classic UD/UCMDB)",
      "Import the Service Management root CA certificate to UCMDB Gateway (containerized UD/UCMDB)"
    ],
    "keywords": [
      "UCMDB_Gateway_CA_Certificate.crt",
      "https://<UCMDB_HOSTNAME>:<UCMDB_PORT>/cms",
      "esmlab.net",
      "Base-64",
      "trustedCAs.crt",
      "x.tgz",
      "smax.crt",
      "1.xx",
      "cmsrootca.crt",
      "values.yaml",
      "set",
      "secure",
      "connection",
      "between",
      "sma",
      "ucmdb",
      "gateway",
      "get",
      "root",
      "ca",
      "certificate",
      "classic",
      "ud",
      "containerized",
      "permission",
      "file",
      "import",
      "suite",
      "deployment",
      "helm",
      "service",
      "management",
      "need",
      "both",
      "parties",
      "other.",
      "certificates",
      "changed",
      "either",
      "side",
      "new",
      "chains",
      "again.",
      "ssl",
      "folder",
      "unzipped",
      "installer",
      "package",
      "ucmdb.",
      "one",
      "following",
      "methods",
      "certificate.",
      "browser",
      "log",
      "https",
      "cms",
      "browser.",
      "example",
      "steps",
      "chrome.",
      "click",
      "lock",
      "icon",
      "before",
      "url",
      "address",
      "bar.",
      "valid.",
      "certification",
      "viewer",
      "details.",
      "hierarchy",
      "select",
      "site",
      "topmost",
      "export.",
      "encoded",
      "ascii",
      "single",
      "format",
      "name",
      "save.",
      "command",
      "line",
      "run",
      "commands",
      "details",
      "openssl",
      "-connect",
      "cmsdemo01.esmlab.net",
      "9443",
      "-showcerts",
      "output",
      "display",
      "certificates.",
      "look",
      "same",
      "cn",
      "values."
    ],
    "language": "en",
    "word_count": 110,
    "importance_score": 5.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "set up a secure connection between sma and ucmdb gateway",
    "contentLower": "to set up a secure connection between service management and the ucmdb gateway, you need to import the root ca certificate of both parties into each other. if the ca certificates are changed on either side, you need to import the new ca certificate chains to the other side again. get the root ca certificate of ucmdb gateway (classic ud/ucmdb) get the cmsrootca.crt file from the ssl folder in the unzipped installer package of ucmdb gateway for classic ud/ucmdb. get the root ca certificate of ucmdb gateway (containerized ud/ucmdb) use one of the following methods to get the root ca certificate. from the browser: log in to ucmdb gateway (https://<ucmdb_hostname>:<ucmdb_port>/cms) from the browser. as an example, the following are steps for chrome. click the lock icon before the url on the address bar. click connection is secure click certificate is valid. on the certification viewer, click details. in the certificate hierarchy, select the site root certificate (the topmost one), and then ",
    "keywordsLower": [
      "ucmdb_gateway_ca_certificate.crt",
      "https://<ucmdb_hostname>:<ucmdb_port>/cms",
      "esmlab.net",
      "base-64",
      "trustedcas.crt",
      "x.tgz",
      "smax.crt",
      "1.xx",
      "cmsrootca.crt",
      "values.yaml",
      "set",
      "secure",
      "connection",
      "between",
      "sma",
      "ucmdb",
      "gateway",
      "get",
      "root",
      "ca",
      "certificate",
      "classic",
      "ud",
      "containerized",
      "permission",
      "file",
      "import",
      "suite",
      "deployment",
      "helm",
      "service",
      "management",
      "need",
      "both",
      "parties",
      "other.",
      "certificates",
      "changed",
      "either",
      "side",
      "new",
      "chains",
      "again.",
      "ssl",
      "folder",
      "unzipped",
      "installer",
      "package",
      "ucmdb.",
      "one",
      "following",
      "methods",
      "certificate.",
      "browser",
      "log",
      "https",
      "cms",
      "browser.",
      "example",
      "steps",
      "chrome.",
      "click",
      "lock",
      "icon",
      "before",
      "url",
      "address",
      "bar.",
      "valid.",
      "certification",
      "viewer",
      "details.",
      "hierarchy",
      "select",
      "site",
      "topmost",
      "export.",
      "encoded",
      "ascii",
      "single",
      "format",
      "name",
      "save.",
      "command",
      "line",
      "run",
      "commands",
      "details",
      "openssl",
      "-connect",
      "cmsdemo01.esmlab.net",
      "9443",
      "-showcerts",
      "output",
      "display",
      "certificates.",
      "look",
      "same",
      "cn",
      "values."
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Single Sign-On with UCMDB",
    "content": "Single Sign-On can be achieved by connecting UCMDB and suite IdM, it also works when there are multiple SMAX tenants and multiple UCMDB customers. If you have connected UCMDB and suite IdM as described in Associate Service Management tenants with UCMDB customers, you can enable Single Sign-On between SMAX and UCMDB by following these steps: To permit users to navigate to an external UD/UCMDB through UCMDB browser, add the UCMDB host domain as an authorized domain. To do this, navigate to Administration > Configuration > Application Settings and add the UCMDB host domain to the Authorized domains for navigation field. Examples: If the hostname is myhost.example.com, add \"example.com\" as an authorized domain. If the hostname is myhost.subdomain.example.com, add \"subdomain.example.com\" as an authorized domain. See Authorized domains for navigation for details. Go to the SACM homepage, click SACM configuration. Check the Enable UCMDB browser check box. Enter the UCMDB Browser URL of the co",
    "url": "ssoucmdb",
    "filename": "ssoucmdb",
    "headings": [],
    "keywords": [
      "https://<UCMDB_Server_Host>:<UCMDB_Server_Port>/ucmdb-browser",
      "example.com",
      "https://<UCMDB_Server_Host>:<UCMDB_Server_Port>/ucmdb-browser?customerID=xxxxxxxxx",
      "single",
      "sign-on",
      "ucmdb",
      "achieved",
      "connecting",
      "suite",
      "idm",
      "works",
      "there",
      "multiple",
      "smax",
      "tenants",
      "customers.",
      "connected",
      "described",
      "associate",
      "service",
      "management",
      "customers",
      "enable",
      "between",
      "following",
      "steps",
      "permit",
      "users",
      "navigate",
      "external",
      "ud",
      "through",
      "browser",
      "add",
      "host",
      "domain",
      "authorized",
      "domain.",
      "administration",
      "configuration",
      "application",
      "settings",
      "domains",
      "navigation",
      "field.",
      "examples",
      "hostname",
      "myhost.example.com",
      "myhost.subdomain.example.com",
      "subdomain.example.com",
      "see",
      "details.",
      "go",
      "sacm",
      "homepage",
      "click",
      "configuration.",
      "check",
      "box.",
      "enter",
      "url",
      "corresponding",
      "customer.",
      "resembles",
      "https",
      "ucmdb-browser.",
      "don",
      "need",
      "specify",
      "customer",
      "id",
      "user",
      "tries",
      "open",
      "automatically",
      "appended",
      "url.",
      "note",
      "try",
      "entering",
      "web",
      "manually",
      "append",
      "multi-customer",
      "enabled.",
      "example",
      "ucmdb-browser",
      "customerid",
      "xxxxxxxxx.",
      "save.",
      "gives",
      "idea",
      "sso",
      "ucmdb.",
      "tenant",
      "tenant2",
      "customer2",
      "tenant2.",
      "log",
      "module."
    ],
    "language": "en",
    "word_count": 100,
    "importance_score": 3.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "single sign-on with ucmdb",
    "contentLower": "single sign-on can be achieved by connecting ucmdb and suite idm, it also works when there are multiple smax tenants and multiple ucmdb customers. if you have connected ucmdb and suite idm as described in associate service management tenants with ucmdb customers, you can enable single sign-on between smax and ucmdb by following these steps: to permit users to navigate to an external ud/ucmdb through ucmdb browser, add the ucmdb host domain as an authorized domain. to do this, navigate to administration > configuration > application settings and add the ucmdb host domain to the authorized domains for navigation field. examples: if the hostname is myhost.example.com, add \"example.com\" as an authorized domain. if the hostname is myhost.subdomain.example.com, add \"subdomain.example.com\" as an authorized domain. see authorized domains for navigation for details. go to the sacm homepage, click sacm configuration. check the enable ucmdb browser check box. enter the ucmdb browser url of the co",
    "keywordsLower": [
      "https://<ucmdb_server_host>:<ucmdb_server_port>/ucmdb-browser",
      "example.com",
      "https://<ucmdb_server_host>:<ucmdb_server_port>/ucmdb-browser?customerid=xxxxxxxxx",
      "single",
      "sign-on",
      "ucmdb",
      "achieved",
      "connecting",
      "suite",
      "idm",
      "works",
      "there",
      "multiple",
      "smax",
      "tenants",
      "customers.",
      "connected",
      "described",
      "associate",
      "service",
      "management",
      "customers",
      "enable",
      "between",
      "following",
      "steps",
      "permit",
      "users",
      "navigate",
      "external",
      "ud",
      "through",
      "browser",
      "add",
      "host",
      "domain",
      "authorized",
      "domain.",
      "administration",
      "configuration",
      "application",
      "settings",
      "domains",
      "navigation",
      "field.",
      "examples",
      "hostname",
      "myhost.example.com",
      "myhost.subdomain.example.com",
      "subdomain.example.com",
      "see",
      "details.",
      "go",
      "sacm",
      "homepage",
      "click",
      "configuration.",
      "check",
      "box.",
      "enter",
      "url",
      "corresponding",
      "customer.",
      "resembles",
      "https",
      "ucmdb-browser.",
      "don",
      "need",
      "specify",
      "customer",
      "id",
      "user",
      "tries",
      "open",
      "automatically",
      "appended",
      "url.",
      "note",
      "try",
      "entering",
      "web",
      "manually",
      "append",
      "multi-customer",
      "enabled.",
      "example",
      "ucmdb-browser",
      "customerid",
      "xxxxxxxxx.",
      "save.",
      "gives",
      "idea",
      "sso",
      "ucmdb.",
      "tenant",
      "tenant2",
      "customer2",
      "tenant2.",
      "log",
      "module."
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Restore OMT when upgrade fails",
    "content": "If the OPTIC Management Toolkit (OMT) upgrade fails, you need to restore OMT. There are two ways to restore OMT depending on how you backed up OMT. Note The method of using VM snapshots is for on-premises deployments only. Restore OMT from VM snapshots If you took VM snapshots before the OMT upgrade, follow these steps to restore OMT: Revert the VMs to the snapshots that you have taken. For details, see your specific virtualization software documentation. Restore the OMT database from the database backup. For details, see your specific database documentation. Restore the OMT NFS core volume. For example: /var/vols/itom/itsma/core. Restore OMT manually If you performed a manual backup of OMT, restore OMT manually. For details, see Restore OMT manually.",
    "url": "upgraderestorecdf",
    "filename": "upgraderestorecdf",
    "headings": [
      "Restore OMT from VM snapshots",
      "Restore OMT manually"
    ],
    "keywords": [
      "restore",
      "omt",
      "upgrade",
      "fails",
      "vm",
      "snapshots",
      "manually",
      "optic",
      "management",
      "toolkit",
      "need",
      "omt.",
      "there",
      "two",
      "ways",
      "depending",
      "backed",
      "note",
      "method",
      "on-premises",
      "deployments",
      "only.",
      "took",
      "before",
      "follow",
      "steps",
      "revert",
      "vms",
      "taken.",
      "details",
      "see",
      "specific",
      "virtualization",
      "software",
      "documentation.",
      "database",
      "backup.",
      "nfs",
      "core",
      "volume.",
      "example",
      "var",
      "vols",
      "itom",
      "itsma",
      "core.",
      "performed",
      "manual",
      "backup",
      "manually."
    ],
    "language": "en",
    "word_count": 88,
    "importance_score": 4.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "restore omt when upgrade fails",
    "contentLower": "if the optic management toolkit (omt) upgrade fails, you need to restore omt. there are two ways to restore omt depending on how you backed up omt. note the method of using vm snapshots is for on-premises deployments only. restore omt from vm snapshots if you took vm snapshots before the omt upgrade, follow these steps to restore omt: revert the vms to the snapshots that you have taken. for details, see your specific virtualization software documentation. restore the omt database from the database backup. for details, see your specific database documentation. restore the omt nfs core volume. for example: /var/vols/itom/itsma/core. restore omt manually if you performed a manual backup of omt, restore omt manually. for details, see restore omt manually.",
    "keywordsLower": [
      "restore",
      "omt",
      "upgrade",
      "fails",
      "vm",
      "snapshots",
      "manually",
      "optic",
      "management",
      "toolkit",
      "need",
      "omt.",
      "there",
      "two",
      "ways",
      "depending",
      "backed",
      "note",
      "method",
      "on-premises",
      "deployments",
      "only.",
      "took",
      "before",
      "follow",
      "steps",
      "revert",
      "vms",
      "taken.",
      "details",
      "see",
      "specific",
      "virtualization",
      "software",
      "documentation.",
      "database",
      "backup.",
      "nfs",
      "core",
      "volume.",
      "example",
      "var",
      "vols",
      "itom",
      "itsma",
      "core.",
      "performed",
      "manual",
      "backup",
      "manually."
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Restore OMT manually",
    "content": "Restore the OMT installation depending on the scenarios. Restore files which are deleted accidentally When some files are deleted accidentally, you can restore them by copying them back. For the files in the directory bin, or the scripts, the tools, or the images in $CDF_HOME, restore them from the OMT installation package. For example: If the file $CDF_HOME/scripts/uploadimages.sh is deleted by accident, you can restore it from the OMT installation package. For other files, restore them from the backup directory. For example: If the file $CDF_HOME/ssl/ca.crt is deleted by accident, you can restore it from the cdf_backup/node/cdf_home.tar.gz backup file. Note: The restored files must have the same owner and permission with the deleted files. Restore the external databases If you used external databases (PostgreSQL or Oracle) to install OMT, you need to restore them. Refer to the related database manual for the detailed restore steps. Restore the embedded PostgreSQL databases (cdfapiser",
    "url": "restorecdfmanually",
    "filename": "restorecdfmanually",
    "headings": [
      "Restore files which are deleted accidentally",
      "Restore the external databases",
      "Restore the embedded PostgreSQL databases (cdfapiserver-db and cdfidm-db)",
      "Restore etcd data",
      "In a single-control plane node deployment",
      "In a multiple-control plane node deployment",
      "Troubleshooting",
      "Restore NFS server",
      "Restore NFS server to the original NFS server and path",
      "Restore old NFS to a new NFS server",
      "Restore the vault-params-key Vault keys",
      "Related topics"
    ],
    "keywords": [
      "ca.crt",
      "etcd.yaml",
      "boostport.com",
      "https://${ITOM_VAULT_IP}:8200",
      "example.net",
      "restart.sh",
      "https://${Control_Plane_Node2}:2380",
      "https://${Control_Plane_Node1}:2380,${Control_Plane_Node2}=https://${Control_Plane_Node2}:2380,${Control_Plane_Node3}=https://${Control_Plane_Node3}:2380",
      "YYYYMMDDHHMMSS.tar",
      "uploadimages.sh",
      "https://${THIS_NODE}:2380",
      "https://${Control_Plane_Node1}:2380",
      "cdf.sh",
      "cdf_home.tar",
      "snapshot.db",
      "https://${Control_Plane_Node3}:2380",
      "backup_recover.sh",
      "basic_config.env",
      "restore",
      "omt",
      "manually",
      "files",
      "deleted",
      "accidentally",
      "external",
      "databases",
      "embedded",
      "postgresql",
      "cdfapiserver-db",
      "cdfidm-db",
      "etcd",
      "data",
      "single-control",
      "plane",
      "node",
      "deployment",
      "multiple-control",
      "troubleshooting",
      "nfs",
      "server",
      "original",
      "path",
      "old",
      "new",
      "vault-params-key",
      "vault",
      "keys",
      "related",
      "topics",
      "installation",
      "depending",
      "scenarios.",
      "copying",
      "back.",
      "directory",
      "bin",
      "scripts",
      "tools",
      "images",
      "package.",
      "example",
      "file",
      "accident",
      "backup",
      "directory.",
      "ssl",
      "file.",
      "note",
      "restored",
      "same",
      "owner",
      "permission",
      "files.",
      "oracle",
      "install",
      "need",
      "them.",
      "refer",
      "database",
      "manual",
      "detailed",
      "steps.",
      "backed",
      "command",
      "running",
      "following",
      "cd",
      "-m",
      "dbrestore",
      "-f",
      "dir",
      "cdf-br-",
      "ipv4",
      "fqdn",
      "-yyyymmddhhmmss.tar.gz",
      "terminal",
      "resembles",
      "root",
      "control1",
      "opt"
    ],
    "language": "en",
    "word_count": 89,
    "importance_score": 6.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "restore omt manually",
    "contentLower": "restore the omt installation depending on the scenarios. restore files which are deleted accidentally when some files are deleted accidentally, you can restore them by copying them back. for the files in the directory bin, or the scripts, the tools, or the images in $cdf_home, restore them from the omt installation package. for example: if the file $cdf_home/scripts/uploadimages.sh is deleted by accident, you can restore it from the omt installation package. for other files, restore them from the backup directory. for example: if the file $cdf_home/ssl/ca.crt is deleted by accident, you can restore it from the cdf_backup/node/cdf_home.tar.gz backup file. note: the restored files must have the same owner and permission with the deleted files. restore the external databases if you used external databases (postgresql or oracle) to install omt, you need to restore them. refer to the related database manual for the detailed restore steps. restore the embedded postgresql databases (cdfapiser",
    "keywordsLower": [
      "ca.crt",
      "etcd.yaml",
      "boostport.com",
      "https://${itom_vault_ip}:8200",
      "example.net",
      "restart.sh",
      "https://${control_plane_node2}:2380",
      "https://${control_plane_node1}:2380,${control_plane_node2}=https://${control_plane_node2}:2380,${control_plane_node3}=https://${control_plane_node3}:2380",
      "yyyymmddhhmmss.tar",
      "uploadimages.sh",
      "https://${this_node}:2380",
      "https://${control_plane_node1}:2380",
      "cdf.sh",
      "cdf_home.tar",
      "snapshot.db",
      "https://${control_plane_node3}:2380",
      "backup_recover.sh",
      "basic_config.env",
      "restore",
      "omt",
      "manually",
      "files",
      "deleted",
      "accidentally",
      "external",
      "databases",
      "embedded",
      "postgresql",
      "cdfapiserver-db",
      "cdfidm-db",
      "etcd",
      "data",
      "single-control",
      "plane",
      "node",
      "deployment",
      "multiple-control",
      "troubleshooting",
      "nfs",
      "server",
      "original",
      "path",
      "old",
      "new",
      "vault-params-key",
      "vault",
      "keys",
      "related",
      "topics",
      "installation",
      "depending",
      "scenarios.",
      "copying",
      "back.",
      "directory",
      "bin",
      "scripts",
      "tools",
      "images",
      "package.",
      "example",
      "file",
      "accident",
      "backup",
      "directory.",
      "ssl",
      "file.",
      "note",
      "restored",
      "same",
      "owner",
      "permission",
      "files.",
      "oracle",
      "install",
      "need",
      "them.",
      "refer",
      "database",
      "manual",
      "detailed",
      "steps.",
      "backed",
      "command",
      "running",
      "following",
      "cd",
      "-m",
      "dbrestore",
      "-f",
      "dir",
      "cdf-br-",
      "ipv4",
      "fqdn",
      "-yyyymmddhhmmss.tar.gz",
      "terminal",
      "resembles",
      "root",
      "control1",
      "opt"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Revoke authority to upgrade OMT",
    "content": "This is an optional step. For security reasons, you may revoke the authority that you granted to the regular user after you've upgraded OMT. To revoke the authority after upgrade, remove the file /etc/sudoers.d/OMT_cmnd_alias_upgrade on all nodes.",
    "url": "revokesudoupg",
    "filename": "revokesudoupg",
    "headings": [],
    "keywords": [
      "revoke",
      "authority",
      "upgrade",
      "omt",
      "optional",
      "step.",
      "security",
      "reasons",
      "granted",
      "regular",
      "user",
      "after",
      "ve",
      "upgraded",
      "omt.",
      "remove",
      "file",
      "etc",
      "sudoers.d",
      "all",
      "nodes."
    ],
    "language": "en",
    "word_count": 28,
    "importance_score": 2.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "revoke authority to upgrade omt",
    "contentLower": "this is an optional step. for security reasons, you may revoke the authority that you granted to the regular user after you've upgraded omt. to revoke the authority after upgrade, remove the file /etc/sudoers.d/omt_cmnd_alias_upgrade on all nodes.",
    "keywordsLower": [
      "revoke",
      "authority",
      "upgrade",
      "omt",
      "optional",
      "step.",
      "security",
      "reasons",
      "granted",
      "regular",
      "user",
      "after",
      "ve",
      "upgraded",
      "omt.",
      "remove",
      "file",
      "etc",
      "sudoers.d",
      "all",
      "nodes."
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Restore the suite when upgrade fails",
    "content": "If the suite version update fails, you need to restore the suite. Restore the suite by using one of the following methods depending on how you backed up the suite data. Note You can use the method of using VM snapshots in on-premises environments only. Restore the suite from VM snapshots If you backed up the suite environment by taking snapshots of the control plane nodes and worker nodes, restore the suite as follows: Revert the control plane node and worker node VMs to the snapshots that you have taken. For details, see your specific virtualization software documentation. Restore the suite databases to the database backups. For details, see the specific database documentation. Restore the suite global and Smart Analytics NFS volumes. For details, see the \"Scenario 2: Persistent storage data has been corrupted\" topic for version 2023.05. Restore the suite using the SMA disaster recovery solution If you backed up the suite by using the SMA Disaster Recovery (DR) solution, follow the in",
    "url": "restoresuitedata",
    "filename": "restoresuitedata",
    "headings": [
      "Restore the suite from VM snapshots",
      "Restore the suite using the SMA disaster recovery solution",
      "Related topics"
    ],
    "keywords": [
      "2023.05",
      "restore",
      "suite",
      "upgrade",
      "fails",
      "vm",
      "snapshots",
      "sma",
      "disaster",
      "recovery",
      "solution",
      "related",
      "topics",
      "version",
      "update",
      "need",
      "suite.",
      "one",
      "following",
      "methods",
      "depending",
      "backed",
      "data.",
      "note",
      "method",
      "on-premises",
      "environments",
      "only.",
      "environment",
      "taking",
      "control",
      "plane",
      "nodes",
      "worker",
      "follows",
      "revert",
      "node",
      "vms",
      "taken.",
      "details",
      "see",
      "specific",
      "virtualization",
      "software",
      "documentation.",
      "databases",
      "database",
      "backups.",
      "global",
      "smart",
      "analytics",
      "nfs",
      "volumes.",
      "scenario",
      "persistent",
      "storage",
      "data",
      "corrupted",
      "topic",
      "2023.05.",
      "dr",
      "follow",
      "instructions",
      "described",
      "kubernetes",
      "cluster",
      "crashed",
      "back"
    ],
    "language": "en",
    "word_count": 101,
    "importance_score": 3.5,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "restore the suite when upgrade fails",
    "contentLower": "if the suite version update fails, you need to restore the suite. restore the suite by using one of the following methods depending on how you backed up the suite data. note you can use the method of using vm snapshots in on-premises environments only. restore the suite from vm snapshots if you backed up the suite environment by taking snapshots of the control plane nodes and worker nodes, restore the suite as follows: revert the control plane node and worker node vms to the snapshots that you have taken. for details, see your specific virtualization software documentation. restore the suite databases to the database backups. for details, see the specific database documentation. restore the suite global and smart analytics nfs volumes. for details, see the \"scenario 2: persistent storage data has been corrupted\" topic for version 2023.05. restore the suite using the sma disaster recovery solution if you backed up the suite by using the sma disaster recovery (dr) solution, follow the in",
    "keywordsLower": [
      "2023.05",
      "restore",
      "suite",
      "upgrade",
      "fails",
      "vm",
      "snapshots",
      "sma",
      "disaster",
      "recovery",
      "solution",
      "related",
      "topics",
      "version",
      "update",
      "need",
      "suite.",
      "one",
      "following",
      "methods",
      "depending",
      "backed",
      "data.",
      "note",
      "method",
      "on-premises",
      "environments",
      "only.",
      "environment",
      "taking",
      "control",
      "plane",
      "nodes",
      "worker",
      "follows",
      "revert",
      "node",
      "vms",
      "taken.",
      "details",
      "see",
      "specific",
      "virtualization",
      "software",
      "documentation.",
      "databases",
      "database",
      "backups.",
      "global",
      "smart",
      "analytics",
      "nfs",
      "volumes.",
      "scenario",
      "persistent",
      "storage",
      "data",
      "corrupted",
      "topic",
      "2023.05.",
      "dr",
      "follow",
      "instructions",
      "described",
      "kubernetes",
      "cluster",
      "crashed",
      "back"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Restore OO Containerized on-premises",
    "content": "This topic describes how to restore OO Containerized on-premises. When OO deployment is functioning but data is missing or corrupted The following steps restore OO Containerized on-premises when a deployment is still functioning, but data is missing or corrupted: Stop the OO deployment. On the control plane node, run the following command: $CDF_HOME/scripts/cdfctl.sh runlevel set -l DOWN -n <namespace-of-oo-deployment> Wait for a few minutes until the OO deployment has stopped fully. Restore OO databases: OO Central, UI, Controller, Scheduler, and Autopass. Restore the following data in NFS volumes: oo-config-volume storing OO Containerized configuration files. Example path: /var/vols/itom/oo/oo_config_volume. oo-data-export-volume storing OO tenants exported data. Example path: /var/vols/itom/oo/oo_data_export_volume. oo-data-volume storing storing OO-generated data. Example path: /var/vols/itom/oo/oo_data_volume Restart the OO deployment. On the control plane node, run the following ",
    "url": "restoreoocontainerizedembeddedk8s",
    "filename": "restoreoocontainerizedembeddedk8s",
    "headings": [
      "When OO deployment is functioning but data is missing or corrupted",
      "When OO deployment is failing or corrupted",
      "Restore Remote Action Server pods"
    ],
    "keywords": [
      "pv.yaml",
      "oo.tgz",
      "pvc.yaml",
      "cdfctl.sh",
      "dd.yaml",
      "values.yaml",
      "restore",
      "oo",
      "containerized",
      "on-premises",
      "deployment",
      "functioning",
      "data",
      "missing",
      "corrupted",
      "failing",
      "remote",
      "action",
      "server",
      "pods",
      "topic",
      "describes",
      "on-premises.",
      "following",
      "steps",
      "still",
      "stop",
      "deployment.",
      "control",
      "plane",
      "node",
      "run",
      "command",
      "scripts",
      "runlevel",
      "set",
      "-l",
      "-n",
      "wait",
      "few",
      "minutes",
      "until",
      "stopped",
      "fully.",
      "databases",
      "central",
      "ui",
      "controller",
      "scheduler",
      "autopass.",
      "nfs",
      "volumes",
      "oo-config-volume",
      "storing",
      "configuration",
      "files.",
      "example",
      "path",
      "var",
      "vols",
      "itom",
      "oo-data-export-volume",
      "tenants",
      "exported",
      "data.",
      "oo-data-volume",
      "oo-generated",
      "restart",
      "make",
      "sure",
      "always",
      "perform",
      "troubleshooting",
      "troubleshoot",
      "section",
      "documentation.",
      "resolve",
      "issue",
      "follow",
      "instructions",
      "below",
      "uninstall",
      "don",
      "clean",
      "databases.",
      "details",
      "see",
      "oo.",
      "create",
      "new",
      "information",
      "creating",
      "secret.",
      "secret",
      "backup",
      ".yaml",
      "file",
      "kubectl",
      "apply",
      "-f"
    ],
    "language": "en",
    "word_count": 112,
    "importance_score": 4.5,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "restore oo containerized on-premises",
    "contentLower": "this topic describes how to restore oo containerized on-premises. when oo deployment is functioning but data is missing or corrupted the following steps restore oo containerized on-premises when a deployment is still functioning, but data is missing or corrupted: stop the oo deployment. on the control plane node, run the following command: $cdf_home/scripts/cdfctl.sh runlevel set -l down -n <namespace-of-oo-deployment> wait for a few minutes until the oo deployment has stopped fully. restore oo databases: oo central, ui, controller, scheduler, and autopass. restore the following data in nfs volumes: oo-config-volume storing oo containerized configuration files. example path: /var/vols/itom/oo/oo_config_volume. oo-data-export-volume storing oo tenants exported data. example path: /var/vols/itom/oo/oo_data_export_volume. oo-data-volume storing storing oo-generated data. example path: /var/vols/itom/oo/oo_data_volume restart the oo deployment. on the control plane node, run the following ",
    "keywordsLower": [
      "pv.yaml",
      "oo.tgz",
      "pvc.yaml",
      "cdfctl.sh",
      "dd.yaml",
      "values.yaml",
      "restore",
      "oo",
      "containerized",
      "on-premises",
      "deployment",
      "functioning",
      "data",
      "missing",
      "corrupted",
      "failing",
      "remote",
      "action",
      "server",
      "pods",
      "topic",
      "describes",
      "on-premises.",
      "following",
      "steps",
      "still",
      "stop",
      "deployment.",
      "control",
      "plane",
      "node",
      "run",
      "command",
      "scripts",
      "runlevel",
      "set",
      "-l",
      "-n",
      "wait",
      "few",
      "minutes",
      "until",
      "stopped",
      "fully.",
      "databases",
      "central",
      "ui",
      "controller",
      "scheduler",
      "autopass.",
      "nfs",
      "volumes",
      "oo-config-volume",
      "storing",
      "configuration",
      "files.",
      "example",
      "path",
      "var",
      "vols",
      "itom",
      "oo-data-export-volume",
      "tenants",
      "exported",
      "data.",
      "oo-data-volume",
      "oo-generated",
      "restart",
      "make",
      "sure",
      "always",
      "perform",
      "troubleshooting",
      "troubleshoot",
      "section",
      "documentation.",
      "resolve",
      "issue",
      "follow",
      "instructions",
      "below",
      "uninstall",
      "don",
      "clean",
      "databases.",
      "details",
      "see",
      "oo.",
      "create",
      "new",
      "information",
      "creating",
      "secret.",
      "secret",
      "backup",
      ".yaml",
      "file",
      "kubectl",
      "apply",
      "-f"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Restore the UD/UCMDB deployment when upgrade fails (containerized UD/UCMDB)",
    "content": "Scenario 1 - the containerized UD/UCMDB deployment is still functioning but data is missing or corrupted Stop the UD/UCMDB deployment On the control plane node, run the following command: /opt/kubernetes/scripts/cdfctl.sh runlevel set -l DOWN -n <namespace-of-CMS-deployment> Wait for a few minutes until the UD/UCMDB deployment has fully stopped. Restore UD/UCMDB databases, including the UCMDB database, IdM database, and Autopass database. Restore the following data in NFS volumes: Component NFS volume name Directory Description UCMDB Gateway ucmdb-data-volume <ucmdb-data-volume>/cms-gateway Data generated by the UCMDB Gateway Restart the UD/UCMDB deployment. On the control plane node, run the following command: /opt/kubernetes/scripts/cdfctl.sh runlevel set -l UP -n <namespace-of-CMS-deployment> Scenario 2 - the containerized UD/UCMDB deployment is corrupted or failing Make sure you always perform troubleshooting by following instructions in Troubleshoot UD/UCMDB. If this still can't r",
    "url": "cmsrestore",
    "filename": "cmsrestore",
    "headings": [
      "Scenario 1 - the containerized UD/UCMDB deployment is still functioning but data is missing or corrupted",
      "Scenario 2 - the containerized UD/UCMDB deployment is corrupted or failing"
    ],
    "keywords": [
      "uducmdb",
      "cdfctl.sh",
      "values.yaml",
      "pv.yaml",
      "dd.yaml",
      "restore",
      "ud",
      "ucmdb",
      "deployment",
      "upgrade",
      "fails",
      "containerized",
      "scenario",
      "still",
      "functioning",
      "data",
      "missing",
      "corrupted",
      "failing",
      "stop",
      "control",
      "plane",
      "node",
      "run",
      "following",
      "command",
      "opt",
      "kubernetes",
      "scripts",
      "runlevel",
      "set",
      "-l",
      "-n",
      "wait",
      "few",
      "minutes",
      "until",
      "fully",
      "stopped.",
      "databases",
      "including",
      "database",
      "idm",
      "autopass",
      "database.",
      "nfs",
      "volumes",
      "component",
      "volume",
      "name",
      "directory",
      "description",
      "gateway",
      "ucmdb-data-volume",
      "cms-gateway",
      "generated",
      "restart",
      "deployment.",
      "make",
      "sure",
      "always",
      "perform",
      "troubleshooting",
      "instructions",
      "troubleshoot",
      "ucmdb.",
      "resolve",
      "issue",
      "follow",
      "below",
      "uninstall",
      "delete",
      "remove",
      "persistent",
      "clean",
      "details",
      "see",
      "create",
      "new",
      "secret.",
      "secret",
      "backup",
      ".yaml",
      "file",
      "kubectl",
      "apply",
      "-f",
      "re-create",
      "server",
      "configure",
      "pvs",
      "same",
      "configuration",
      "ucmdb-pv.yaml",
      "re-install",
      "my-values.yaml",
      "helm",
      "chart.",
      "install",
      "omt."
    ],
    "language": "en",
    "word_count": 116,
    "importance_score": 3.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "restore the ud/ucmdb deployment when upgrade fails (containerized ud/ucmdb)",
    "contentLower": "scenario 1 - the containerized ud/ucmdb deployment is still functioning but data is missing or corrupted stop the ud/ucmdb deployment on the control plane node, run the following command: /opt/kubernetes/scripts/cdfctl.sh runlevel set -l down -n <namespace-of-cms-deployment> wait for a few minutes until the ud/ucmdb deployment has fully stopped. restore ud/ucmdb databases, including the ucmdb database, idm database, and autopass database. restore the following data in nfs volumes: component nfs volume name directory description ucmdb gateway ucmdb-data-volume <ucmdb-data-volume>/cms-gateway data generated by the ucmdb gateway restart the ud/ucmdb deployment. on the control plane node, run the following command: /opt/kubernetes/scripts/cdfctl.sh runlevel set -l up -n <namespace-of-cms-deployment> scenario 2 - the containerized ud/ucmdb deployment is corrupted or failing make sure you always perform troubleshooting by following instructions in troubleshoot ud/ucmdb. if this still can't r",
    "keywordsLower": [
      "uducmdb",
      "cdfctl.sh",
      "values.yaml",
      "pv.yaml",
      "dd.yaml",
      "restore",
      "ud",
      "ucmdb",
      "deployment",
      "upgrade",
      "fails",
      "containerized",
      "scenario",
      "still",
      "functioning",
      "data",
      "missing",
      "corrupted",
      "failing",
      "stop",
      "control",
      "plane",
      "node",
      "run",
      "following",
      "command",
      "opt",
      "kubernetes",
      "scripts",
      "runlevel",
      "set",
      "-l",
      "-n",
      "wait",
      "few",
      "minutes",
      "until",
      "fully",
      "stopped.",
      "databases",
      "including",
      "database",
      "idm",
      "autopass",
      "database.",
      "nfs",
      "volumes",
      "component",
      "volume",
      "name",
      "directory",
      "description",
      "gateway",
      "ucmdb-data-volume",
      "cms-gateway",
      "generated",
      "restart",
      "deployment.",
      "make",
      "sure",
      "always",
      "perform",
      "troubleshooting",
      "instructions",
      "troubleshoot",
      "ucmdb.",
      "resolve",
      "issue",
      "follow",
      "below",
      "uninstall",
      "delete",
      "remove",
      "persistent",
      "clean",
      "details",
      "see",
      "create",
      "new",
      "secret.",
      "secret",
      "backup",
      ".yaml",
      "file",
      "kubectl",
      "apply",
      "-f",
      "re-create",
      "server",
      "configure",
      "pvs",
      "same",
      "configuration",
      "ucmdb-pv.yaml",
      "re-install",
      "my-values.yaml",
      "helm",
      "chart.",
      "install",
      "omt."
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Restore UD/UCMDB when upgrade fails (managed Kubernetes)",
    "content": "Scenario 1 - the containerized UD/UCMDB deployment is still functioning but data is missing or corrupted Stop the UD/UCMDB deployment. On the bastion node, navigate to the OMT installation directory: cd OMT_External_K8s_2n.n-nnn/scripts/ Run the following command: ./cdfctl.sh runlevel set -l DOWN -n <namespace-of-CMS-deployment> Wait for a few minutes until the UD/UCMDB deployment has fully stopped. Restore UD/UCMDB databases, including the UCMDB database, IdM database, and Autopass database. Restore the following data in NFS volumes: Component NFS volume name Directory Description UCMDB Gateway ucmdb-data-volume <ucmdb-data-volume>/cms-gateway Data generated by the UCMDB Gateway Restart the UD/UCMDB deployment. On the bastion node, navigate to the OMT installation directory: cd OMT_External_K8s_2n.n-nnn/scripts/ Run the following command: ./cdfctl.sh runlevel set -l UP -n <namespace-of-CMS-deployment> Scenario 2 - the containerized UD/UCMDB deployment is corrupted or failing Make sure",
    "url": "cmsrestoremanagedk8s",
    "filename": "cmsrestoremanagedk8s",
    "headings": [
      "Scenario 1 - the containerized UD/UCMDB deployment is still functioning but data is missing or corrupted",
      "Scenario 2 - the containerized UD/UCMDB deployment is corrupted or failing"
    ],
    "keywords": [
      "uducmdb",
      "cdfctl.sh",
      "values.yaml",
      "pv.yaml",
      "dd.yaml",
      "restore",
      "ud",
      "ucmdb",
      "upgrade",
      "fails",
      "managed",
      "kubernetes",
      "scenario",
      "containerized",
      "deployment",
      "still",
      "functioning",
      "data",
      "missing",
      "corrupted",
      "failing",
      "stop",
      "deployment.",
      "bastion",
      "node",
      "navigate",
      "omt",
      "installation",
      "directory",
      "cd",
      "scripts",
      "run",
      "following",
      "command",
      "runlevel",
      "set",
      "-l",
      "-n",
      "wait",
      "few",
      "minutes",
      "until",
      "fully",
      "stopped.",
      "databases",
      "including",
      "database",
      "idm",
      "autopass",
      "database.",
      "nfs",
      "volumes",
      "component",
      "volume",
      "name",
      "description",
      "gateway",
      "ucmdb-data-volume",
      "cms-gateway",
      "generated",
      "restart",
      "make",
      "sure",
      "always",
      "perform",
      "troubleshooting",
      "instructions",
      "troubleshoot",
      "ucmdb.",
      "resolve",
      "issue",
      "follow",
      "below",
      "uninstall",
      "steps",
      "delete",
      "remove",
      "persistent",
      "clean",
      "details",
      "see",
      "aws.",
      "create",
      "new",
      "secret.",
      "secret",
      "backup",
      "yaml",
      "file",
      "kubectl",
      "apply",
      "-f",
      "recreate",
      "volumes.",
      "configure",
      "efs",
      "pvs",
      "same",
      "configuration",
      "ucmdb-pv.yaml"
    ],
    "language": "en",
    "word_count": 109,
    "importance_score": 3.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "restore ud/ucmdb when upgrade fails (managed kubernetes)",
    "contentLower": "scenario 1 - the containerized ud/ucmdb deployment is still functioning but data is missing or corrupted stop the ud/ucmdb deployment. on the bastion node, navigate to the omt installation directory: cd omt_external_k8s_2n.n-nnn/scripts/ run the following command: ./cdfctl.sh runlevel set -l down -n <namespace-of-cms-deployment> wait for a few minutes until the ud/ucmdb deployment has fully stopped. restore ud/ucmdb databases, including the ucmdb database, idm database, and autopass database. restore the following data in nfs volumes: component nfs volume name directory description ucmdb gateway ucmdb-data-volume <ucmdb-data-volume>/cms-gateway data generated by the ucmdb gateway restart the ud/ucmdb deployment. on the bastion node, navigate to the omt installation directory: cd omt_external_k8s_2n.n-nnn/scripts/ run the following command: ./cdfctl.sh runlevel set -l up -n <namespace-of-cms-deployment> scenario 2 - the containerized ud/ucmdb deployment is corrupted or failing make sure",
    "keywordsLower": [
      "uducmdb",
      "cdfctl.sh",
      "values.yaml",
      "pv.yaml",
      "dd.yaml",
      "restore",
      "ud",
      "ucmdb",
      "upgrade",
      "fails",
      "managed",
      "kubernetes",
      "scenario",
      "containerized",
      "deployment",
      "still",
      "functioning",
      "data",
      "missing",
      "corrupted",
      "failing",
      "stop",
      "deployment.",
      "bastion",
      "node",
      "navigate",
      "omt",
      "installation",
      "directory",
      "cd",
      "scripts",
      "run",
      "following",
      "command",
      "runlevel",
      "set",
      "-l",
      "-n",
      "wait",
      "few",
      "minutes",
      "until",
      "fully",
      "stopped.",
      "databases",
      "including",
      "database",
      "idm",
      "autopass",
      "database.",
      "nfs",
      "volumes",
      "component",
      "volume",
      "name",
      "description",
      "gateway",
      "ucmdb-data-volume",
      "cms-gateway",
      "generated",
      "restart",
      "make",
      "sure",
      "always",
      "perform",
      "troubleshooting",
      "instructions",
      "troubleshoot",
      "ucmdb.",
      "resolve",
      "issue",
      "follow",
      "below",
      "uninstall",
      "steps",
      "delete",
      "remove",
      "persistent",
      "clean",
      "details",
      "see",
      "aws.",
      "create",
      "new",
      "secret.",
      "secret",
      "backup",
      "yaml",
      "file",
      "kubectl",
      "apply",
      "-f",
      "recreate",
      "volumes.",
      "configure",
      "efs",
      "pvs",
      "same",
      "configuration",
      "ucmdb-pv.yaml"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Restore the suite when upgrade fails (managed Kubernetes)",
    "content": "If the suite version update fails, you need to restore the suite. For details, see the SMA Restore Procedures topic in the help center for the version you upgrade from.",
    "url": "restoremanagedk8ssuite",
    "filename": "restoremanagedk8ssuite",
    "headings": [],
    "keywords": [
      "restore",
      "suite",
      "upgrade",
      "fails",
      "managed",
      "kubernetes",
      "version",
      "update",
      "need",
      "suite.",
      "details",
      "see",
      "sma",
      "procedures",
      "topic",
      "help",
      "center",
      "from."
    ],
    "language": "en",
    "word_count": 24,
    "importance_score": 1.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "restore the suite when upgrade fails (managed kubernetes)",
    "contentLower": "if the suite version update fails, you need to restore the suite. for details, see the sma restore procedures topic in the help center for the version you upgrade from.",
    "keywordsLower": [
      "restore",
      "suite",
      "upgrade",
      "fails",
      "managed",
      "kubernetes",
      "version",
      "update",
      "need",
      "suite.",
      "details",
      "see",
      "sma",
      "procedures",
      "topic",
      "help",
      "center",
      "from."
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Roll back OO Workflow Designer",
    "content": "This topic provides instructions to roll back Operations Orchestration (OO) Workflow Designer after its upgrade. Overview of rollback You can roll back an upgraded OO Workflow Designer to the earlier version using the rollback script provided as part of the upgrade package. This restores OO Workflow Designer to the state it was before the upgrade without losing database data. The rollback also restores OO Workflow Designer to the previous version, including patches, but it can only restore to the latest version. Prerequisites Make sure that the previous version of OO Workflow Designer has started successfully at least once. Otherwise, you may not be able to roll back the upgrade or might result in faulty rollback if you decide to do so. Before starting the rollback process, ensure to close the files and logs of OO. Make sure to have the backup of the component under <installation>/upgrade/<new-version>/backup/<component> Make sure the installed version is the same as the upgrade script",
    "url": "rollbacworkflowdesigner",
    "filename": "rollbacworkflowdesigner",
    "headings": [
      "Overview of rollback",
      "Prerequisites",
      "Unsupported rollback scenarios",
      "Rollback precautions",
      "Rollback procedure",
      "Post rollback task",
      "Rollback when your company doesn't allow changing the database schema"
    ],
    "keywords": [
      "rollback.sql",
      "upgrade.log",
      "rollback.bat",
      "roll",
      "back",
      "oo",
      "workflow",
      "designer",
      "overview",
      "rollback",
      "prerequisites",
      "unsupported",
      "scenarios",
      "precautions",
      "procedure",
      "post",
      "task",
      "company",
      "doesn",
      "allow",
      "changing",
      "database",
      "schema",
      "topic",
      "provides",
      "instructions",
      "operations",
      "orchestration",
      "after",
      "upgrade.",
      "upgraded",
      "earlier",
      "version",
      "script",
      "provided",
      "part",
      "upgrade",
      "package.",
      "restores",
      "state",
      "before",
      "losing",
      "data.",
      "previous",
      "including",
      "patches",
      "restore",
      "latest",
      "version.",
      "make",
      "sure",
      "started",
      "successfully",
      "least",
      "once.",
      "otherwise",
      "able",
      "result",
      "faulty",
      "decide",
      "so.",
      "starting",
      "process",
      "ensure",
      "close",
      "files",
      "logs",
      "oo.",
      "backup",
      "component",
      "under",
      "installed",
      "same",
      "perform",
      "twice.",
      "last",
      "successfully.",
      "attempting",
      "twice",
      "system",
      "unusable.",
      "isn",
      "supported",
      "idm",
      "mode.",
      "current",
      "workaround",
      "manually",
      "rollback.",
      "rolls",
      "changes",
      "preserves",
      "data",
      "added",
      "however",
      "sometimes",
      "still",
      "lose",
      "due",
      "changes."
    ],
    "language": "en",
    "word_count": 100,
    "importance_score": 6.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "roll back oo workflow designer",
    "contentLower": "this topic provides instructions to roll back operations orchestration (oo) workflow designer after its upgrade. overview of rollback you can roll back an upgraded oo workflow designer to the earlier version using the rollback script provided as part of the upgrade package. this restores oo workflow designer to the state it was before the upgrade without losing database data. the rollback also restores oo workflow designer to the previous version, including patches, but it can only restore to the latest version. prerequisites make sure that the previous version of oo workflow designer has started successfully at least once. otherwise, you may not be able to roll back the upgrade or might result in faulty rollback if you decide to do so. before starting the rollback process, ensure to close the files and logs of oo. make sure to have the backup of the component under <installation>/upgrade/<new-version>/backup/<component> make sure the installed version is the same as the upgrade script",
    "keywordsLower": [
      "rollback.sql",
      "upgrade.log",
      "rollback.bat",
      "roll",
      "back",
      "oo",
      "workflow",
      "designer",
      "overview",
      "rollback",
      "prerequisites",
      "unsupported",
      "scenarios",
      "precautions",
      "procedure",
      "post",
      "task",
      "company",
      "doesn",
      "allow",
      "changing",
      "database",
      "schema",
      "topic",
      "provides",
      "instructions",
      "operations",
      "orchestration",
      "after",
      "upgrade.",
      "upgraded",
      "earlier",
      "version",
      "script",
      "provided",
      "part",
      "upgrade",
      "package.",
      "restores",
      "state",
      "before",
      "losing",
      "data.",
      "previous",
      "including",
      "patches",
      "restore",
      "latest",
      "version.",
      "make",
      "sure",
      "started",
      "successfully",
      "least",
      "once.",
      "otherwise",
      "able",
      "result",
      "faulty",
      "decide",
      "so.",
      "starting",
      "process",
      "ensure",
      "close",
      "files",
      "logs",
      "oo.",
      "backup",
      "component",
      "under",
      "installed",
      "same",
      "perform",
      "twice.",
      "last",
      "successfully.",
      "attempting",
      "twice",
      "system",
      "unusable.",
      "isn",
      "supported",
      "idm",
      "mode.",
      "current",
      "workaround",
      "manually",
      "rollback.",
      "rolls",
      "changes",
      "preserves",
      "data",
      "added",
      "however",
      "sometimes",
      "still",
      "lose",
      "due",
      "changes."
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Supported authentication types for Rest Executor 2.0 endpoints",
    "content": "Rest Executor 2.0 endpoints support the following types of authentication. The maximum length allowed for the top-level domain for base URLs is 20 characters. Service Management This type is dedicated to integration with another Service Management system. Configuring an endpoint with the Service Management authentication type Field Value Agent Select Agentless (if not using the OPB Agent) or the OPB agent created for the endpoint. Authentication type Select Service Management. Protocol Select https. Base URL Enter the base URL of the target Service Management system: https://<FQDN> Tenant ID Enter the tenant ID of the target Service Management system. Username (if not using the OPB Agent) Enter the username of the integration user for connecting to the target Service Management system. Password (if not using the OPB Agent) Enter the password of the integration user for connecting to the target Service Management system. Confirm password (if not using the OPB Agent) Re-enter the passwor",
    "url": "configendpoint4xie",
    "filename": "configendpoint4xie",
    "headings": [
      "Service Management",
      "Configuring an endpoint with the Service Management authentication type",
      "Basic Authentication",
      "Configuring an endpoint with the Basic Authentication authentication type",
      "Generic",
      "Configuring an endpoint with the Generic authentication type",
      "No Auth",
      "Configuring an endpoint with the No Auth authentication type",
      "OAuth 2.0",
      "What external systems can use the OAuth 2.0 endpoint",
      "Prerequisites",
      "Setting up the endpoint (Authorization Code grant type)",
      "Setting up the endpoint (Client Credentials grant type)",
      "Token management (Authorization Code grant type only)",
      "Token status",
      "Token refresh (automatic background process)",
      "Token regeneration",
      "SAP SuccessFactors OAuth 2.0",
      "Configuring an endpoint with the SAP SuccessFactors OAuth 2.0 authentication type",
      "AWS Signature"
    ],
    "keywords": [
      "https://auth.example.com/authorize",
      "X.509",
      "https://<External_access_host>/rest/<Service",
      "successfactors.com",
      "https://apiyy.successfactors.com",
      "https://<FQDN",
      "https://<api-server>/oauth/token",
      "https://auth.example.com/authorize?prompt=consent",
      "2.0",
      "example.com",
      "supported",
      "authentication",
      "types",
      "rest",
      "executor",
      "endpoints",
      "service",
      "management",
      "configuring",
      "endpoint",
      "type",
      "basic",
      "generic",
      "auth",
      "oauth",
      "what",
      "external",
      "systems",
      "prerequisites",
      "setting",
      "authorization",
      "code",
      "grant",
      "client",
      "credentials",
      "token",
      "status",
      "refresh",
      "automatic",
      "background",
      "process",
      "regeneration",
      "sap",
      "successfactors",
      "aws",
      "signature",
      "bearer",
      "related",
      "topics",
      "support",
      "following",
      "authentication.",
      "maximum",
      "length",
      "allowed",
      "top-level",
      "domain",
      "base",
      "urls",
      "20",
      "characters.",
      "dedicated",
      "integration",
      "another",
      "system.",
      "field",
      "value",
      "agent",
      "select",
      "agentless",
      "opb",
      "created",
      "endpoint.",
      "management.",
      "protocol",
      "https.",
      "url",
      "enter",
      "target",
      "system",
      "https",
      "tenant",
      "id",
      "username",
      "user",
      "connecting",
      "password",
      "confirm",
      "re-enter",
      "password.",
      "certificate",
      "x.509.",
      "format",
      "pem.",
      "server",
      "open",
      "root",
      "ca",
      "file",
      "text"
    ],
    "language": "en",
    "word_count": 107,
    "importance_score": 5.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "supported authentication types for rest executor 2.0 endpoints",
    "contentLower": "rest executor 2.0 endpoints support the following types of authentication. the maximum length allowed for the top-level domain for base urls is 20 characters. service management this type is dedicated to integration with another service management system. configuring an endpoint with the service management authentication type field value agent select agentless (if not using the opb agent) or the opb agent created for the endpoint. authentication type select service management. protocol select https. base url enter the base url of the target service management system: https://<fqdn> tenant id enter the tenant id of the target service management system. username (if not using the opb agent) enter the username of the integration user for connecting to the target service management system. password (if not using the opb agent) enter the password of the integration user for connecting to the target service management system. confirm password (if not using the opb agent) re-enter the passwor",
    "keywordsLower": [
      "https://auth.example.com/authorize",
      "x.509",
      "https://<external_access_host>/rest/<service",
      "successfactors.com",
      "https://apiyy.successfactors.com",
      "https://<fqdn",
      "https://<api-server>/oauth/token",
      "https://auth.example.com/authorize?prompt=consent",
      "2.0",
      "example.com",
      "supported",
      "authentication",
      "types",
      "rest",
      "executor",
      "endpoints",
      "service",
      "management",
      "configuring",
      "endpoint",
      "type",
      "basic",
      "generic",
      "auth",
      "oauth",
      "what",
      "external",
      "systems",
      "prerequisites",
      "setting",
      "authorization",
      "code",
      "grant",
      "client",
      "credentials",
      "token",
      "status",
      "refresh",
      "automatic",
      "background",
      "process",
      "regeneration",
      "sap",
      "successfactors",
      "aws",
      "signature",
      "bearer",
      "related",
      "topics",
      "support",
      "following",
      "authentication.",
      "maximum",
      "length",
      "allowed",
      "top-level",
      "domain",
      "base",
      "urls",
      "20",
      "characters.",
      "dedicated",
      "integration",
      "another",
      "system.",
      "field",
      "value",
      "agent",
      "select",
      "agentless",
      "opb",
      "created",
      "endpoint.",
      "management.",
      "protocol",
      "https.",
      "url",
      "enter",
      "target",
      "system",
      "https",
      "tenant",
      "id",
      "username",
      "user",
      "connecting",
      "password",
      "confirm",
      "re-enter",
      "password.",
      "certificate",
      "x.509.",
      "format",
      "pem.",
      "server",
      "open",
      "root",
      "ca",
      "file",
      "text"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Scenario templates",
    "content": "Templates provide pre-configured scenarios, which you can use as a jumpstart to integrate two systems. Some connectors are delivered with one or more templates that provide certain fully implemented use cases. Templates require only minimal adjustments to make them work in an out-of-the-box system. In a customized system, you can use templates as a jumpstart for building integrations. OpenText may update some templates from time to time to provide various enhancements. The existing scenarios that you created from the previous templates continue to work. The adoption of the modifications is optional. The Integration Studio provides the following scenario templates: Asana integration for SAMAtlassian Jira integrationAWS cloud account sync integrationAzure Active Directory integrationAzure cloud account sync integrationAzure DevOps integrationDatadog integrationGCP cloud account sync integrationLucid integration for SAMMeta WhatsApp integrationMicrosoft 365 email integrationMicrosoft 365 ",
    "url": "xietemplate",
    "filename": "xietemplate",
    "headings": [],
    "keywords": [
      "scenario",
      "templates",
      "provide",
      "pre-configured",
      "scenarios",
      "jumpstart",
      "integrate",
      "two",
      "systems.",
      "connectors",
      "delivered",
      "one",
      "certain",
      "fully",
      "implemented",
      "cases.",
      "require",
      "minimal",
      "adjustments",
      "make",
      "work",
      "out-of-the-box",
      "system.",
      "customized",
      "system",
      "building",
      "integrations.",
      "opentext",
      "update",
      "time",
      "various",
      "enhancements.",
      "existing",
      "created",
      "previous",
      "continue",
      "work.",
      "adoption",
      "modifications",
      "optional.",
      "integration",
      "studio",
      "provides",
      "following",
      "asana",
      "samatlassian",
      "jira",
      "integrationaws",
      "cloud",
      "account",
      "sync",
      "integrationazure",
      "active",
      "directory",
      "devops",
      "integrationdatadog",
      "integrationgcp",
      "integrationlucid",
      "sammeta",
      "whatsapp",
      "integrationmicrosoft",
      "365",
      "email",
      "sammicrosoft",
      "intune",
      "teams",
      "bot",
      "integrationopenai",
      "chatgpt",
      "integrationopentext",
      "alm",
      "octane",
      "arcsight",
      "soar",
      "asset",
      "manager",
      "core",
      "content",
      "quality",
      "center",
      "service",
      "management",
      "valueedge",
      "strategy",
      "zenworks",
      "integrationsalesforce",
      "samsalesforce",
      "slack",
      "integrationsap",
      "successfactors",
      "integrationsmartsheet",
      "samwebex",
      "sam"
    ],
    "language": "en",
    "word_count": 88,
    "importance_score": 3.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "scenario templates",
    "contentLower": "templates provide pre-configured scenarios, which you can use as a jumpstart to integrate two systems. some connectors are delivered with one or more templates that provide certain fully implemented use cases. templates require only minimal adjustments to make them work in an out-of-the-box system. in a customized system, you can use templates as a jumpstart for building integrations. opentext may update some templates from time to time to provide various enhancements. the existing scenarios that you created from the previous templates continue to work. the adoption of the modifications is optional. the integration studio provides the following scenario templates: asana integration for samatlassian jira integrationaws cloud account sync integrationazure active directory integrationazure cloud account sync integrationazure devops integrationdatadog integrationgcp cloud account sync integrationlucid integration for sammeta whatsapp integrationmicrosoft 365 email integrationmicrosoft 365 ",
    "keywordsLower": [
      "scenario",
      "templates",
      "provide",
      "pre-configured",
      "scenarios",
      "jumpstart",
      "integrate",
      "two",
      "systems.",
      "connectors",
      "delivered",
      "one",
      "certain",
      "fully",
      "implemented",
      "cases.",
      "require",
      "minimal",
      "adjustments",
      "make",
      "work",
      "out-of-the-box",
      "system.",
      "customized",
      "system",
      "building",
      "integrations.",
      "opentext",
      "update",
      "time",
      "various",
      "enhancements.",
      "existing",
      "created",
      "previous",
      "continue",
      "work.",
      "adoption",
      "modifications",
      "optional.",
      "integration",
      "studio",
      "provides",
      "following",
      "asana",
      "samatlassian",
      "jira",
      "integrationaws",
      "cloud",
      "account",
      "sync",
      "integrationazure",
      "active",
      "directory",
      "devops",
      "integrationdatadog",
      "integrationgcp",
      "integrationlucid",
      "sammeta",
      "whatsapp",
      "integrationmicrosoft",
      "365",
      "email",
      "sammicrosoft",
      "intune",
      "teams",
      "bot",
      "integrationopenai",
      "chatgpt",
      "integrationopentext",
      "alm",
      "octane",
      "arcsight",
      "soar",
      "asset",
      "manager",
      "core",
      "content",
      "quality",
      "center",
      "service",
      "management",
      "valueedge",
      "strategy",
      "zenworks",
      "integrationsalesforce",
      "samsalesforce",
      "slack",
      "integrationsap",
      "successfactors",
      "integrationsmartsheet",
      "samwebex",
      "sam"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Scheduler",
    "content": "You can use the scheduler to trigger integration scenarios based on a schedule. For example, trigger the Jira Get Status scenario at 10 PM every day. Create schedules Perform the following steps to create a schedule: Click Administration > Utilities > Integration > Integration Studio. Click the Scheduler tab. Click + Add on the toolbar. The New Schedule wizard appears. On the Scenario page, specify a name for the schedule, and select the integration and scenario that must be triggered according to the schedule. On the Planning page, select the timezone, and then specify the start/end time and the recurrence pattern for the schedule in the Recurrence section. You can specify only the date for the schedule's end time. The exact end time is 0:00 of that date. (Optional) In the Exclusions section of the Planning page, add a list of time slots that are excluded from the schedule. To add an exclusion time slot, select the start time and end time, and then click Add. You can add exclusion tim",
    "url": "xiescheduler",
    "filename": "xiescheduler",
    "headings": [
      "Create schedules",
      "Manage schedules",
      "Monitor scheduler-triggered scenarios",
      "Use schedule data in the scenario",
      "Use schedule Input data",
      "Use built-in data"
    ],
    "keywords": [
      "payload.data",
      "scheduler",
      "create",
      "schedules",
      "manage",
      "monitor",
      "scheduler-triggered",
      "scenarios",
      "schedule",
      "data",
      "scenario",
      "input",
      "built-in",
      "trigger",
      "integration",
      "based",
      "schedule.",
      "example",
      "jira",
      "get",
      "status",
      "10",
      "pm",
      "every",
      "day.",
      "perform",
      "following",
      "steps",
      "click",
      "administration",
      "utilities",
      "studio.",
      "tab.",
      "add",
      "toolbar.",
      "new",
      "wizard",
      "appears.",
      "page",
      "specify",
      "name",
      "select",
      "triggered",
      "according",
      "planning",
      "timezone",
      "start",
      "end",
      "time",
      "recurrence",
      "pattern",
      "section.",
      "date",
      "time.",
      "exact",
      "00",
      "date.",
      "optional",
      "exclusions",
      "section",
      "list",
      "slots",
      "excluded",
      "exclusion",
      "slot",
      "add.",
      "inputs",
      "key-value",
      "pairs",
      "rules.",
      "value",
      "field",
      "form",
      "differences",
      "fields",
      "configuration",
      "studio",
      "expression",
      "language",
      "supported",
      "form.",
      "enter",
      "always",
      "treated",
      "string.",
      "string",
      "don",
      "need",
      "enclose",
      "quotes.",
      "quotes",
      "passes",
      "scenarios.",
      "save.",
      "microsoft",
      "teams",
      "integration.",
      "actions",
      "toolbar",
      "edit"
    ],
    "language": "en",
    "word_count": 101,
    "importance_score": 6.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "scheduler",
    "contentLower": "you can use the scheduler to trigger integration scenarios based on a schedule. for example, trigger the jira get status scenario at 10 pm every day. create schedules perform the following steps to create a schedule: click administration > utilities > integration > integration studio. click the scheduler tab. click + add on the toolbar. the new schedule wizard appears. on the scenario page, specify a name for the schedule, and select the integration and scenario that must be triggered according to the schedule. on the planning page, select the timezone, and then specify the start/end time and the recurrence pattern for the schedule in the recurrence section. you can specify only the date for the schedule's end time. the exact end time is 0:00 of that date. (optional) in the exclusions section of the planning page, add a list of time slots that are excluded from the schedule. to add an exclusion time slot, select the start time and end time, and then click add. you can add exclusion tim",
    "keywordsLower": [
      "payload.data",
      "scheduler",
      "create",
      "schedules",
      "manage",
      "monitor",
      "scheduler-triggered",
      "scenarios",
      "schedule",
      "data",
      "scenario",
      "input",
      "built-in",
      "trigger",
      "integration",
      "based",
      "schedule.",
      "example",
      "jira",
      "get",
      "status",
      "10",
      "pm",
      "every",
      "day.",
      "perform",
      "following",
      "steps",
      "click",
      "administration",
      "utilities",
      "studio.",
      "tab.",
      "add",
      "toolbar.",
      "new",
      "wizard",
      "appears.",
      "page",
      "specify",
      "name",
      "select",
      "triggered",
      "according",
      "planning",
      "timezone",
      "start",
      "end",
      "time",
      "recurrence",
      "pattern",
      "section.",
      "date",
      "time.",
      "exact",
      "00",
      "date.",
      "optional",
      "exclusions",
      "section",
      "list",
      "slots",
      "excluded",
      "exclusion",
      "slot",
      "add.",
      "inputs",
      "key-value",
      "pairs",
      "rules.",
      "value",
      "field",
      "form",
      "differences",
      "fields",
      "configuration",
      "studio",
      "expression",
      "language",
      "supported",
      "form.",
      "enter",
      "always",
      "treated",
      "string.",
      "string",
      "don",
      "need",
      "enclose",
      "quotes.",
      "quotes",
      "passes",
      "scenarios.",
      "save.",
      "microsoft",
      "teams",
      "integration.",
      "actions",
      "toolbar",
      "edit"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Synchronization",
    "content": "You can synchronize data from UCMDB with Service Management. Synchronization process The following diagram shows a high-level view of how the synchronization works. Service Management uses the On-Premises Bridge (OPB) to communicate with UCMDB. UCMDB pushes the relevant data to a staging area inside UCMDB, either based on a scheduler defined for the UCMDB integration point or manually. The local agent pulls the data from the staging area into Service Management every one hour using the Identification Web service. Notes The staging area is a temporary place inside UCMDB to which UCMDB pushes data and from which the OPB agent pulls data, based on different schedulers. See also Step 5: Create an integration job for the integration point. For more information about how the push adapter works, see the Universal Discovery Content Pack online help. Synchronization mode The following modes of synchronization are supported: Automatic synchronization: You create an endpoint in Service Management",
    "url": "syncoverview",
    "filename": "syncoverview",
    "headings": [
      "Synchronization process",
      "Synchronization mode",
      "Related topics"
    ],
    "keywords": [
      "synchronization",
      "process",
      "mode",
      "related",
      "topics",
      "synchronize",
      "data",
      "ucmdb",
      "service",
      "management.",
      "following",
      "diagram",
      "shows",
      "high-level",
      "view",
      "works.",
      "management",
      "uses",
      "on-premises",
      "bridge",
      "opb",
      "communicate",
      "ucmdb.",
      "pushes",
      "relevant",
      "staging",
      "area",
      "inside",
      "either",
      "based",
      "scheduler",
      "defined",
      "integration",
      "point",
      "manually.",
      "local",
      "agent",
      "pulls",
      "every",
      "one",
      "hour",
      "identification",
      "web",
      "service.",
      "notes",
      "temporary",
      "place",
      "different",
      "schedulers.",
      "see",
      "step",
      "create",
      "job",
      "point.",
      "information",
      "about",
      "push",
      "adapter",
      "works",
      "universal",
      "discovery",
      "content",
      "pack",
      "online",
      "help.",
      "modes",
      "supported",
      "automatic",
      "endpoint",
      "click",
      "sync",
      "now",
      "button.",
      "automatically.",
      "little",
      "control",
      "schedule.",
      "picture",
      "illustrates",
      "workflow",
      "synchronization.",
      "completes",
      "all",
      "tasks",
      "custom",
      "download",
      "package",
      "upload",
      "set",
      "customize",
      "pull",
      "tqls",
      "mappings",
      "jobs",
      "needed.",
      "own",
      "schedules.",
      "marked",
      "orange",
      "taken"
    ],
    "language": "en",
    "word_count": 102,
    "importance_score": 4.5,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "synchronization",
    "contentLower": "you can synchronize data from ucmdb with service management. synchronization process the following diagram shows a high-level view of how the synchronization works. service management uses the on-premises bridge (opb) to communicate with ucmdb. ucmdb pushes the relevant data to a staging area inside ucmdb, either based on a scheduler defined for the ucmdb integration point or manually. the local agent pulls the data from the staging area into service management every one hour using the identification web service. notes the staging area is a temporary place inside ucmdb to which ucmdb pushes data and from which the opb agent pulls data, based on different schedulers. see also step 5: create an integration job for the integration point. for more information about how the push adapter works, see the universal discovery content pack online help. synchronization mode the following modes of synchronization are supported: automatic synchronization: you create an endpoint in service management",
    "keywordsLower": [
      "synchronization",
      "process",
      "mode",
      "related",
      "topics",
      "synchronize",
      "data",
      "ucmdb",
      "service",
      "management.",
      "following",
      "diagram",
      "shows",
      "high-level",
      "view",
      "works.",
      "management",
      "uses",
      "on-premises",
      "bridge",
      "opb",
      "communicate",
      "ucmdb.",
      "pushes",
      "relevant",
      "staging",
      "area",
      "inside",
      "either",
      "based",
      "scheduler",
      "defined",
      "integration",
      "point",
      "manually.",
      "local",
      "agent",
      "pulls",
      "every",
      "one",
      "hour",
      "identification",
      "web",
      "service.",
      "notes",
      "temporary",
      "place",
      "different",
      "schedulers.",
      "see",
      "step",
      "create",
      "job",
      "point.",
      "information",
      "about",
      "push",
      "adapter",
      "works",
      "universal",
      "discovery",
      "content",
      "pack",
      "online",
      "help.",
      "modes",
      "supported",
      "automatic",
      "endpoint",
      "click",
      "sync",
      "now",
      "button.",
      "automatically.",
      "little",
      "control",
      "schedule.",
      "picture",
      "illustrates",
      "workflow",
      "synchronization.",
      "completes",
      "all",
      "tasks",
      "custom",
      "download",
      "package",
      "upload",
      "set",
      "customize",
      "pull",
      "tqls",
      "mappings",
      "jobs",
      "needed.",
      "own",
      "schedules.",
      "marked",
      "orange",
      "taken"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Synchronized configuration items (CIs)",
    "content": "Native SACM When Native SACM is enabled, CIs are synchronized as described in CI type, attribute, and subtype federation. CMS integration through On-Premises Bridge (OPB) When using OPB to integrate SMA and UD/UCMDB, with UCMDB as the source of CIs, Service Management supports synchronization of the CIs detailed in the following table. Service Management CI Matching UCMDB CIs TQL Queries Device node SACM Node Push ActualService Service SACM Service Push ServiceComponent BusinessApplication SACM Service Component Push SystemElement ApplicationSystem, RunningSoftware and CICollection SACM CI Collection to System Element Push SACM System Element Push The following tables display the CI attribute mappings for the CIs returned by these TQL queries. For each CI type, Root represents the root CI type in the TQL query (Device, System Element, Service Component, or Actual Service). The CI attribute name appears in brackets. For example, Root[global_id], refers to the global ID attribute of the ",
    "url": "syncdcis",
    "filename": "syncdcis",
    "headings": [
      "Native SACM",
      "CMS integration through On-Premises Bridge (OPB)",
      "Device attribute mapping",
      "System Element attribute mapping",
      "Service Component attribute mapping",
      "Actual Service attribute mapping"
    ],
    "keywords": [
      "Root.Cpu",
      "synchronized",
      "configuration",
      "items",
      "cis",
      "native",
      "sacm",
      "cms",
      "integration",
      "through",
      "on-premises",
      "bridge",
      "opb",
      "device",
      "attribute",
      "mapping",
      "system",
      "element",
      "service",
      "component",
      "actual",
      "enabled",
      "described",
      "ci",
      "type",
      "subtype",
      "federation.",
      "integrate",
      "sma",
      "ud",
      "ucmdb",
      "source",
      "management",
      "supports",
      "synchronization",
      "detailed",
      "following",
      "table.",
      "matching",
      "tql",
      "queries",
      "node",
      "push",
      "actualservice",
      "servicecomponent",
      "businessapplication",
      "systemelement",
      "applicationsystem",
      "runningsoftware",
      "cicollection",
      "collection",
      "tables",
      "display",
      "mappings",
      "returned",
      "queries.",
      "root",
      "represents",
      "query",
      "name",
      "appears",
      "brackets.",
      "example",
      "refers",
      "global",
      "id",
      "ci.",
      "includes",
      "related",
      "types",
      "cpu",
      "ip",
      "address",
      "file",
      "disk",
      "network",
      "cards",
      "running",
      "software",
      "case",
      "first",
      "property",
      "hostname",
      "description",
      "globalid",
      "root.asset",
      "assettag",
      "serialnumber",
      "non-empty",
      "value",
      "fields",
      "model",
      "vendor",
      "field",
      "null",
      "both",
      "unknown",
      "ostype",
      "osname",
      "osdescription"
    ],
    "language": "en",
    "word_count": 115,
    "importance_score": 6.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "synchronized configuration items (cis)",
    "contentLower": "native sacm when native sacm is enabled, cis are synchronized as described in ci type, attribute, and subtype federation. cms integration through on-premises bridge (opb) when using opb to integrate sma and ud/ucmdb, with ucmdb as the source of cis, service management supports synchronization of the cis detailed in the following table. service management ci matching ucmdb cis tql queries device node sacm node push actualservice service sacm service push servicecomponent businessapplication sacm service component push systemelement applicationsystem, runningsoftware and cicollection sacm ci collection to system element push sacm system element push the following tables display the ci attribute mappings for the cis returned by these tql queries. for each ci type, root represents the root ci type in the tql query (device, system element, service component, or actual service). the ci attribute name appears in brackets. for example, root[global_id], refers to the global id attribute of the ",
    "keywordsLower": [
      "root.cpu",
      "synchronized",
      "configuration",
      "items",
      "cis",
      "native",
      "sacm",
      "cms",
      "integration",
      "through",
      "on-premises",
      "bridge",
      "opb",
      "device",
      "attribute",
      "mapping",
      "system",
      "element",
      "service",
      "component",
      "actual",
      "enabled",
      "described",
      "ci",
      "type",
      "subtype",
      "federation.",
      "integrate",
      "sma",
      "ud",
      "ucmdb",
      "source",
      "management",
      "supports",
      "synchronization",
      "detailed",
      "following",
      "table.",
      "matching",
      "tql",
      "queries",
      "node",
      "push",
      "actualservice",
      "servicecomponent",
      "businessapplication",
      "systemelement",
      "applicationsystem",
      "runningsoftware",
      "cicollection",
      "collection",
      "tables",
      "display",
      "mappings",
      "returned",
      "queries.",
      "root",
      "represents",
      "query",
      "name",
      "appears",
      "brackets.",
      "example",
      "refers",
      "global",
      "id",
      "ci.",
      "includes",
      "related",
      "types",
      "cpu",
      "ip",
      "address",
      "file",
      "disk",
      "network",
      "cards",
      "running",
      "software",
      "case",
      "first",
      "property",
      "hostname",
      "description",
      "globalid",
      "root.asset",
      "assettag",
      "serialnumber",
      "non-empty",
      "value",
      "fields",
      "model",
      "vendor",
      "field",
      "null",
      "both",
      "unknown",
      "ostype",
      "osname",
      "osdescription"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Supported topologies",
    "content": "Native SACM When Native SACM is enabled, CI topologies are described in CI topology. CMS integration through On-Premises Bridge (OPB) When using OPB to integrate SMA and UD/UCMDB, Service Management supports the discovery of topologies by replicating the relationships within Service Management. Synchronization supports discovery of the topologies in the following table. In each of the cases in the table, Service Management may create a SystemElement CI to match the requirements of the Service Management data model. Topology TQL Query Relationships between any of the Service Management CIs which have topologies consisting of dependencies SACM Relations Push RunningSoftware SACM System Element RS Relation Push SACM System Element RS Push Failover cluster SACM Failover Cluster Push SACM Failover Cluster Relations Push SACM Failover Cluster Resource Group Push SACM Failover Cluster Resource Group Relations Push Load balancer cluster SACM Load Balancer Cluster Push SACM Load Balancer Cluste",
    "url": "supportedtopologies",
    "filename": "supportedtopologies",
    "headings": [
      "Native SACM",
      "CMS integration through On-Premises Bridge (OPB)",
      "Data mapping between Service Management and UCMDB",
      "Related topics"
    ],
    "keywords": [
      "supported",
      "topologies",
      "native",
      "sacm",
      "cms",
      "integration",
      "through",
      "on-premises",
      "bridge",
      "opb",
      "data",
      "mapping",
      "between",
      "service",
      "management",
      "ucmdb",
      "related",
      "topics",
      "enabled",
      "ci",
      "described",
      "topology.",
      "integrate",
      "sma",
      "ud",
      "supports",
      "discovery",
      "replicating",
      "relationships",
      "management.",
      "synchronization",
      "following",
      "table.",
      "cases",
      "table",
      "create",
      "systemelement",
      "match",
      "requirements",
      "model.",
      "topology",
      "tql",
      "query",
      "any",
      "cis",
      "consisting",
      "dependencies",
      "relations",
      "push",
      "runningsoftware",
      "system",
      "element",
      "rs",
      "relation",
      "failover",
      "cluster",
      "resource",
      "group",
      "load",
      "balancer",
      "oracle",
      "rac",
      "balancerpush",
      "virtualization",
      "host",
      "server",
      "running",
      "vm",
      "lpar",
      "solaris",
      "describes",
      "bwteen",
      "two",
      "systems.",
      "actual",
      "business",
      "infrastructure",
      "component",
      "application",
      "elements",
      "software",
      "collection",
      "clusters",
      "device",
      "node",
      "flow",
      "synchronized",
      "configuration",
      "items"
    ],
    "language": "en",
    "word_count": 114,
    "importance_score": 5.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "supported topologies",
    "contentLower": "native sacm when native sacm is enabled, ci topologies are described in ci topology. cms integration through on-premises bridge (opb) when using opb to integrate sma and ud/ucmdb, service management supports the discovery of topologies by replicating the relationships within service management. synchronization supports discovery of the topologies in the following table. in each of the cases in the table, service management may create a systemelement ci to match the requirements of the service management data model. topology tql query relationships between any of the service management cis which have topologies consisting of dependencies sacm relations push runningsoftware sacm system element rs relation push sacm system element rs push failover cluster sacm failover cluster push sacm failover cluster relations push sacm failover cluster resource group push sacm failover cluster resource group relations push load balancer cluster sacm load balancer cluster push sacm load balancer cluste",
    "keywordsLower": [
      "supported",
      "topologies",
      "native",
      "sacm",
      "cms",
      "integration",
      "through",
      "on-premises",
      "bridge",
      "opb",
      "data",
      "mapping",
      "between",
      "service",
      "management",
      "ucmdb",
      "related",
      "topics",
      "enabled",
      "ci",
      "described",
      "topology.",
      "integrate",
      "sma",
      "ud",
      "supports",
      "discovery",
      "replicating",
      "relationships",
      "management.",
      "synchronization",
      "following",
      "table.",
      "cases",
      "table",
      "create",
      "systemelement",
      "match",
      "requirements",
      "model.",
      "topology",
      "tql",
      "query",
      "any",
      "cis",
      "consisting",
      "dependencies",
      "relations",
      "push",
      "runningsoftware",
      "system",
      "element",
      "rs",
      "relation",
      "failover",
      "cluster",
      "resource",
      "group",
      "load",
      "balancer",
      "oracle",
      "rac",
      "balancerpush",
      "virtualization",
      "host",
      "server",
      "running",
      "vm",
      "lpar",
      "solaris",
      "describes",
      "bwteen",
      "two",
      "systems.",
      "actual",
      "business",
      "infrastructure",
      "component",
      "application",
      "elements",
      "software",
      "collection",
      "clusters",
      "device",
      "node",
      "flow",
      "synchronized",
      "configuration",
      "items"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Set up encryption for an Operations Orchestration integration",
    "content": "When working with sensitive customer data such as passwords, Service Management protects the data using asymmetric encryption. The sensitive data is encrypted with a public key provided by the customer. The private key is stored by the On-Premises Bridge agent at the customer site. To enable the encryption, you should follow this process: Generate a pair of public and private keys, using the key generation script provided in the On-Premises Bridge agent installation. Copy the content of the public key and paste it into the Service Management user interface. Import the key pair in all On-Premises Bridge agents to enable the decryption, using the import script provided in the On-Premises Bridge agent installation. Service Management provides scripts to generate public and private encryption keys and import them to the agent machine. This implements encryption between Service Management and the On-Premises Bridge agent, and ensures the security of the fields that are defined as encrypted ",
    "url": "ooencrypt",
    "filename": "ooencrypt",
    "headings": [
      "Related topics"
    ],
    "keywords": [
      "import_rsa_keys.bat",
      "id_rsa.priv",
      "id_rsa.pub",
      "rsa_key_gen.bat",
      "set",
      "encryption",
      "operations",
      "orchestration",
      "integration",
      "related",
      "topics",
      "working",
      "sensitive",
      "customer",
      "data",
      "such",
      "passwords",
      "service",
      "management",
      "protects",
      "asymmetric",
      "encryption.",
      "encrypted",
      "public",
      "key",
      "provided",
      "customer.",
      "private",
      "stored",
      "on-premises",
      "bridge",
      "agent",
      "site.",
      "enable",
      "follow",
      "process",
      "generate",
      "pair",
      "keys",
      "generation",
      "script",
      "installation.",
      "copy",
      "content",
      "paste",
      "user",
      "interface.",
      "import",
      "all",
      "agents",
      "decryption",
      "provides",
      "scripts",
      "machine.",
      "implements",
      "between",
      "ensures",
      "security",
      "fields",
      "defined",
      "original",
      "flow.",
      "keys.",
      "programdata",
      "microfocus",
      "product",
      "util",
      "opb",
      "directory",
      "machine",
      "run",
      "following",
      "generates",
      "located",
      "same",
      "default.",
      "there",
      "option",
      "define",
      "source",
      "randomness",
      "generating",
      "adding",
      "seed",
      "parameter",
      "character",
      "string",
      "any",
      "length.",
      "example",
      "-seed",
      "vb2fk8jgptwefpomkrav",
      "o44jooycsyu0k3z",
      "note",
      "need",
      "once",
      "one",
      "even",
      "multiple",
      "agents."
    ],
    "language": "en",
    "word_count": 99,
    "importance_score": 2.5,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "set up encryption for an operations orchestration integration",
    "contentLower": "when working with sensitive customer data such as passwords, service management protects the data using asymmetric encryption. the sensitive data is encrypted with a public key provided by the customer. the private key is stored by the on-premises bridge agent at the customer site. to enable the encryption, you should follow this process: generate a pair of public and private keys, using the key generation script provided in the on-premises bridge agent installation. copy the content of the public key and paste it into the service management user interface. import the key pair in all on-premises bridge agents to enable the decryption, using the import script provided in the on-premises bridge agent installation. service management provides scripts to generate public and private encryption keys and import them to the agent machine. this implements encryption between service management and the on-premises bridge agent, and ensures the security of the fields that are defined as encrypted ",
    "keywordsLower": [
      "import_rsa_keys.bat",
      "id_rsa.priv",
      "id_rsa.pub",
      "rsa_key_gen.bat",
      "set",
      "encryption",
      "operations",
      "orchestration",
      "integration",
      "related",
      "topics",
      "working",
      "sensitive",
      "customer",
      "data",
      "such",
      "passwords",
      "service",
      "management",
      "protects",
      "asymmetric",
      "encryption.",
      "encrypted",
      "public",
      "key",
      "provided",
      "customer.",
      "private",
      "stored",
      "on-premises",
      "bridge",
      "agent",
      "site.",
      "enable",
      "follow",
      "process",
      "generate",
      "pair",
      "keys",
      "generation",
      "script",
      "installation.",
      "copy",
      "content",
      "paste",
      "user",
      "interface.",
      "import",
      "all",
      "agents",
      "decryption",
      "provides",
      "scripts",
      "machine.",
      "implements",
      "between",
      "ensures",
      "security",
      "fields",
      "defined",
      "original",
      "flow.",
      "keys.",
      "programdata",
      "microfocus",
      "product",
      "util",
      "opb",
      "directory",
      "machine",
      "run",
      "following",
      "generates",
      "located",
      "same",
      "default.",
      "there",
      "option",
      "define",
      "source",
      "randomness",
      "generating",
      "adding",
      "seed",
      "parameter",
      "character",
      "string",
      "any",
      "length.",
      "example",
      "-seed",
      "vb2fk8jgptwefpomkrav",
      "o44jooycsyu0k3z",
      "note",
      "need",
      "once",
      "one",
      "even",
      "multiple",
      "agents."
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Run OO flows from Service Management",
    "content": "The following procedure assumes that you have already an OO flow available and have set up an integration with OO. You can run an Execute Operations Orchestration (OO) flow rule to run an OO flow at two levels: Entity/Workflow level: At this level, the Execute Operations Orchestration (OO) flow rule template contains an additional parameter (\"expression\") that allows you to specify a condition for triggering the execution of the OO flow. Caution: Use caution when running OO flows with this rule, because doing so on a large number of records may downgrade the system performance. Additionally, a massive or improper OO business rule configuration will impact other integrations that are configured on the same OPB agent and may cause a delay of several minutes or even hours in integration tasks depending on the number of tasks and the server load. Record level To run OO flows from Service Management Set up a business rule to run OO flows. You can do so at the entity/entity workflow level or",
    "url": "runooflows",
    "filename": "runooflows",
    "headings": [
      "Run OO flows in OO RAS"
    ],
    "keywords": [
      "run",
      "oo",
      "flows",
      "service",
      "management",
      "ras",
      "following",
      "procedure",
      "assumes",
      "already",
      "flow",
      "available",
      "set",
      "integration",
      "oo.",
      "execute",
      "operations",
      "orchestration",
      "rule",
      "two",
      "levels",
      "entity",
      "workflow",
      "level",
      "template",
      "contains",
      "additional",
      "parameter",
      "expression",
      "allows",
      "specify",
      "condition",
      "triggering",
      "execution",
      "flow.",
      "caution",
      "running",
      "because",
      "doing",
      "large",
      "number",
      "records",
      "downgrade",
      "system",
      "performance.",
      "additionally",
      "massive",
      "improper",
      "business",
      "configuration",
      "impact",
      "integrations",
      "configured",
      "same",
      "opb",
      "agent",
      "cause",
      "delay",
      "several",
      "minutes",
      "even",
      "hours",
      "tasks",
      "depending",
      "server",
      "load.",
      "record",
      "flows.",
      "level.",
      "main",
      "menu",
      "click",
      "administration",
      "studio.",
      "open",
      "entity.",
      "out-of-the-box",
      "custom",
      "example",
      "request.",
      "select",
      "name",
      "phase",
      "under",
      "name.",
      "take",
      "request",
      "example.",
      "processes",
      "rules",
      "support",
      "fulfillment",
      "first",
      "line",
      "tab",
      "right-side",
      "pane.",
      "after",
      "applying",
      "changes"
    ],
    "language": "en",
    "word_count": 106,
    "importance_score": 2.5,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "run oo flows from service management",
    "contentLower": "the following procedure assumes that you have already an oo flow available and have set up an integration with oo. you can run an execute operations orchestration (oo) flow rule to run an oo flow at two levels: entity/workflow level: at this level, the execute operations orchestration (oo) flow rule template contains an additional parameter (\"expression\") that allows you to specify a condition for triggering the execution of the oo flow. caution: use caution when running oo flows with this rule, because doing so on a large number of records may downgrade the system performance. additionally, a massive or improper oo business rule configuration will impact other integrations that are configured on the same opb agent and may cause a delay of several minutes or even hours in integration tasks depending on the number of tasks and the server load. record level to run oo flows from service management set up a business rule to run oo flows. you can do so at the entity/entity workflow level or",
    "keywordsLower": [
      "run",
      "oo",
      "flows",
      "service",
      "management",
      "ras",
      "following",
      "procedure",
      "assumes",
      "already",
      "flow",
      "available",
      "set",
      "integration",
      "oo.",
      "execute",
      "operations",
      "orchestration",
      "rule",
      "two",
      "levels",
      "entity",
      "workflow",
      "level",
      "template",
      "contains",
      "additional",
      "parameter",
      "expression",
      "allows",
      "specify",
      "condition",
      "triggering",
      "execution",
      "flow.",
      "caution",
      "running",
      "because",
      "doing",
      "large",
      "number",
      "records",
      "downgrade",
      "system",
      "performance.",
      "additionally",
      "massive",
      "improper",
      "business",
      "configuration",
      "impact",
      "integrations",
      "configured",
      "same",
      "opb",
      "agent",
      "cause",
      "delay",
      "several",
      "minutes",
      "even",
      "hours",
      "tasks",
      "depending",
      "server",
      "load.",
      "record",
      "flows.",
      "level.",
      "main",
      "menu",
      "click",
      "administration",
      "studio.",
      "open",
      "entity.",
      "out-of-the-box",
      "custom",
      "example",
      "request.",
      "select",
      "name",
      "phase",
      "under",
      "name.",
      "take",
      "request",
      "example.",
      "processes",
      "rules",
      "support",
      "fulfillment",
      "first",
      "line",
      "tab",
      "right-side",
      "pane.",
      "after",
      "applying",
      "changes"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Synchronize with PPM",
    "content": "The following steps describe how to synchronize Service Management with PPM. Notes For the product versions supported by this integration, visit the OpenText integrations website. For more information about downloading, installing, and creating the On-Premises Bridge Agent, see How to use On-Premises Bridge agents on Windows or How to use On-Premises Bridge agents on Linux. Download and install the On-Premises Bridge Agent. Create an agent. Specify the credentials of endpoint type ProjectPortfolioManagement-1.0 (for Linux) or PPM Outbound Integration (for Windows). Create a PPM endpoint: From the main menu, select Administration >Utilities > Integration>Endpoints. Click Add. Enter the endpoint details. Field Description Endpoint type Select the relevant PPM version. Endpoint name Type a name for the endpoint. Use only Latin letters and spaces. Running on agent Select the agent (installed in step 1) from the drop-down list. Click Add. Configure the endpoint: Click Configure. The Endpoin",
    "url": "syncwithppm",
    "filename": "syncwithppm",
    "headings": [
      "Related topics"
    ],
    "keywords": [
      "30000.00",
      "entity.cost",
      "000.00",
      "1.0",
      "synchronize",
      "ppm",
      "related",
      "topics",
      "following",
      "steps",
      "describe",
      "service",
      "management",
      "ppm.",
      "notes",
      "product",
      "versions",
      "supported",
      "integration",
      "visit",
      "opentext",
      "integrations",
      "website.",
      "information",
      "about",
      "downloading",
      "installing",
      "creating",
      "on-premises",
      "bridge",
      "agent",
      "see",
      "agents",
      "windows",
      "linux.",
      "download",
      "install",
      "agent.",
      "create",
      "specify",
      "credentials",
      "endpoint",
      "type",
      "projectportfoliomanagement-1.0",
      "linux",
      "outbound",
      "main",
      "menu",
      "select",
      "administration",
      "utilities",
      "endpoints.",
      "click",
      "add.",
      "enter",
      "details.",
      "field",
      "description",
      "relevant",
      "version.",
      "name",
      "endpoint.",
      "latin",
      "letters",
      "spaces.",
      "running",
      "installed",
      "step",
      "drop-down",
      "list.",
      "configure",
      "configure.",
      "configuration",
      "dialog",
      "box",
      "opens.",
      "details",
      "under",
      "settings.",
      "end",
      "point",
      "read-only.",
      "location",
      "base",
      "url",
      "server",
      "synchronized",
      "management.",
      "authentication",
      "server.",
      "note",
      "text",
      "appears",
      "insert",
      "credential",
      "id",
      "manually.",
      "enable",
      "manual",
      "sync"
    ],
    "language": "en",
    "word_count": 99,
    "importance_score": 3.5,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "synchronize with ppm",
    "contentLower": "the following steps describe how to synchronize service management with ppm. notes for the product versions supported by this integration, visit the opentext integrations website. for more information about downloading, installing, and creating the on-premises bridge agent, see how to use on-premises bridge agents on windows or how to use on-premises bridge agents on linux. download and install the on-premises bridge agent. create an agent. specify the credentials of endpoint type projectportfoliomanagement-1.0 (for linux) or ppm outbound integration (for windows). create a ppm endpoint: from the main menu, select administration >utilities > integration>endpoints. click add. enter the endpoint details. field description endpoint type select the relevant ppm version. endpoint name type a name for the endpoint. use only latin letters and spaces. running on agent select the agent (installed in step 1) from the drop-down list. click add. configure the endpoint: click configure. the endpoin",
    "keywordsLower": [
      "30000.00",
      "entity.cost",
      "000.00",
      "1.0",
      "synchronize",
      "ppm",
      "related",
      "topics",
      "following",
      "steps",
      "describe",
      "service",
      "management",
      "ppm.",
      "notes",
      "product",
      "versions",
      "supported",
      "integration",
      "visit",
      "opentext",
      "integrations",
      "website.",
      "information",
      "about",
      "downloading",
      "installing",
      "creating",
      "on-premises",
      "bridge",
      "agent",
      "see",
      "agents",
      "windows",
      "linux.",
      "download",
      "install",
      "agent.",
      "create",
      "specify",
      "credentials",
      "endpoint",
      "type",
      "projectportfoliomanagement-1.0",
      "linux",
      "outbound",
      "main",
      "menu",
      "select",
      "administration",
      "utilities",
      "endpoints.",
      "click",
      "add.",
      "enter",
      "details.",
      "field",
      "description",
      "relevant",
      "version.",
      "name",
      "endpoint.",
      "latin",
      "letters",
      "spaces.",
      "running",
      "installed",
      "step",
      "drop-down",
      "list.",
      "configure",
      "configure.",
      "configuration",
      "dialog",
      "box",
      "opens.",
      "details",
      "under",
      "settings.",
      "end",
      "point",
      "read-only.",
      "location",
      "base",
      "url",
      "server",
      "synchronized",
      "management.",
      "authentication",
      "server.",
      "note",
      "text",
      "appears",
      "insert",
      "credential",
      "id",
      "manually.",
      "enable",
      "manual",
      "sync"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Synchronize CIs from UCMDB to RTSM",
    "content": "Configure CI synchronization Terminology UCMDB - UCMDB attached to Service Management RTSM - UCMDB attached to OBM/OpScope Please consider the following recommendations before syncing the data between Service Management and OBM/OpScope. If both Service Management and OBM/OpScope are new or Service Management is in place already, and OBM/OpScope is newly set up, then discovery is set up to UCMDB and CIs are imported to UCMDB. Perform your service modeling in Service Management.  Push the Services and related CIs from the UCMDB to RTSM. In case you set up additional discovery jobs in OBM, you can push CIs back to UCMDB. The UCMDB is the Global ID generator. You must push back the Global ID of the CIs to RTSM. If OBM/OpScope is already installed and Service Management is newly set up and configured, there is already RTSM that has CIs. We recommend the following: Keep discovery in OBM/OpScope. Keep in mind that the data model in RTSM is different from standard UCMDB, hence the out-of-the-b",
    "url": "syncisfromucmdbtortsm",
    "filename": "syncisfromucmdbtortsm",
    "headings": [
      "Configure CI synchronization",
      "Configure RTSM",
      "Disable the Global ID generator",
      "Configure UCMDB",
      "Enable Global ID generator in UCMDB",
      "Turn off the autocomplete capability",
      "Configure and run integration jobs to push CIs to RTSM",
      "Add a new integration point",
      "Create integration jobs",
      "Run integration jobs",
      "Push CIs from RTSM to UCMDB"
    ],
    "keywords": [
      "example.com",
      "synchronize",
      "cis",
      "ucmdb",
      "rtsm",
      "configure",
      "ci",
      "synchronization",
      "disable",
      "global",
      "id",
      "generator",
      "enable",
      "turn",
      "off",
      "autocomplete",
      "capability",
      "run",
      "integration",
      "jobs",
      "push",
      "add",
      "new",
      "point",
      "create",
      "terminology",
      "attached",
      "service",
      "management",
      "obm",
      "opscope",
      "please",
      "consider",
      "following",
      "recommendations",
      "before",
      "syncing",
      "data",
      "between",
      "opscope.",
      "both",
      "place",
      "already",
      "newly",
      "set",
      "discovery",
      "imported",
      "ucmdb.",
      "perform",
      "modeling",
      "management.",
      "services",
      "related",
      "rtsm.",
      "case",
      "additional",
      "back",
      "generator.",
      "installed",
      "configured",
      "there",
      "cis.",
      "recommend",
      "keep",
      "mind",
      "model",
      "different",
      "standard",
      "hence",
      "out-of-the-box",
      "tqls",
      "exclude",
      "layout",
      "elements",
      "specific",
      "pushing",
      "relations",
      "running",
      "independently",
      "means",
      "sync",
      "happening",
      "make",
      "master",
      "repository",
      "all",
      "discovered",
      "distributed",
      "act",
      "unique",
      "ids",
      "changing",
      "cause",
      "side",
      "effects",
      "native",
      "sacm",
      "whose",
      "change",
      "re-created"
    ],
    "language": "en",
    "word_count": 110,
    "importance_score": 5.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "synchronize cis from ucmdb to rtsm",
    "contentLower": "configure ci synchronization terminology ucmdb - ucmdb attached to service management rtsm - ucmdb attached to obm/opscope please consider the following recommendations before syncing the data between service management and obm/opscope. if both service management and obm/opscope are new or service management is in place already, and obm/opscope is newly set up, then discovery is set up to ucmdb and cis are imported to ucmdb. perform your service modeling in service management.  push the services and related cis from the ucmdb to rtsm. in case you set up additional discovery jobs in obm, you can push cis back to ucmdb. the ucmdb is the global id generator. you must push back the global id of the cis to rtsm. if obm/opscope is already installed and service management is newly set up and configured, there is already rtsm that has cis. we recommend the following: keep discovery in obm/opscope. keep in mind that the data model in rtsm is different from standard ucmdb, hence the out-of-the-b",
    "keywordsLower": [
      "example.com",
      "synchronize",
      "cis",
      "ucmdb",
      "rtsm",
      "configure",
      "ci",
      "synchronization",
      "disable",
      "global",
      "id",
      "generator",
      "enable",
      "turn",
      "off",
      "autocomplete",
      "capability",
      "run",
      "integration",
      "jobs",
      "push",
      "add",
      "new",
      "point",
      "create",
      "terminology",
      "attached",
      "service",
      "management",
      "obm",
      "opscope",
      "please",
      "consider",
      "following",
      "recommendations",
      "before",
      "syncing",
      "data",
      "between",
      "opscope.",
      "both",
      "place",
      "already",
      "newly",
      "set",
      "discovery",
      "imported",
      "ucmdb.",
      "perform",
      "modeling",
      "management.",
      "services",
      "related",
      "rtsm.",
      "case",
      "additional",
      "back",
      "generator.",
      "installed",
      "configured",
      "there",
      "cis.",
      "recommend",
      "keep",
      "mind",
      "model",
      "different",
      "standard",
      "hence",
      "out-of-the-box",
      "tqls",
      "exclude",
      "layout",
      "elements",
      "specific",
      "pushing",
      "relations",
      "running",
      "independently",
      "means",
      "sync",
      "happening",
      "make",
      "master",
      "repository",
      "all",
      "discovered",
      "distributed",
      "act",
      "unique",
      "ids",
      "changing",
      "cause",
      "side",
      "effects",
      "native",
      "sacm",
      "whose",
      "change",
      "re-created"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Set up embedded Event Browser",
    "content": "This document describes how to set up the integration that enables OpenText Service Management (Service Management, formerly known as SMAX) users to directly view OBM event data in the Service Management UI. This integration doesn't involve syncing event data between Service Management and OBM. The use case for forwarding OBM events to create incidents in Service Management is documented in Integrate with OBM for incident and event data synchronization. Overview Use case Incident analysts often struggle to find meaningful information to analyze incidents raised by end users. To help incident analysts find relevant information to troubleshoot incidents faster, we embedded the Configuration Item (CI) Topology and OBM Event Browser into the Service Management incident form. With real-time access to OBM event data, incident analysts can immediately see events for the service that the incident is created for. With this information, the analyst can identify potential root causes of an incide",
    "url": "integrateeventbrowser",
    "filename": "integrateeventbrowser",
    "headings": [
      "Overview",
      "Use case",
      "Architecture",
      "Connectivity",
      "Prerequisites",
      "Configure OBM",
      "Create integration user",
      "Load management pack",
      "Change Infrastructure Settings",
      "Configure SSO between Service Management and OBM",
      "Shared IDP using SAML Single Sign On (SSO)",
      "Single Sign On (SSO) using the IdM OIDC client",
      "Configure suite IdM",
      "Configure OBM IdM for SSO",
      "Configure automatic user permission assignment",
      "Enable widget display",
      "Configure Infrastructure Settings in OBM",
      "Enable the widget display in Service Management",
      "Enable the Event Browser widget",
      "Add OBM hostname to the Authorized domains list"
    ],
    "keywords": [
      "SMAX_Integration_23_4.zip",
      "installer.bat",
      "page.The",
      "24.2",
      "https://<OBM",
      "ancestors.Add",
      "23.4",
      "internalDomain.com",
      "settings.Add",
      "pane.In",
      "microsoft.com",
      "installer.sh",
      "src.Add",
      "https://<Service",
      "values.yaml",
      "credentials.In",
      "http://schemas.microsoft.com/identity/claims/tenantid",
      "http://proxy:8080>\"NO_PROXY=\"<your",
      "https://proxy:8080>\"HTTP_PROXY=\"<your",
      "set",
      "embedded",
      "event",
      "browser",
      "overview",
      "case",
      "architecture",
      "connectivity",
      "prerequisites",
      "configure",
      "obm",
      "create",
      "integration",
      "user",
      "load",
      "management",
      "pack",
      "change",
      "infrastructure",
      "settings",
      "sso",
      "between",
      "service",
      "shared",
      "idp",
      "saml",
      "single",
      "sign",
      "idm",
      "oidc",
      "client",
      "suite",
      "automatic",
      "permission",
      "assignment",
      "enable",
      "widget",
      "display",
      "add",
      "hostname",
      "authorized",
      "domains",
      "list",
      "allow",
      "document",
      "describes",
      "enables",
      "opentext",
      "formerly",
      "known",
      "smax",
      "users",
      "directly",
      "view",
      "data",
      "ui.",
      "doesn",
      "involve",
      "syncing",
      "obm.",
      "forwarding",
      "events",
      "incidents",
      "documented",
      "integrate",
      "incident",
      "synchronization.",
      "analysts",
      "often",
      "struggle",
      "find",
      "meaningful",
      "information",
      "analyze",
      "raised",
      "end",
      "users.",
      "help",
      "relevant",
      "troubleshoot",
      "faster"
    ],
    "language": "en",
    "word_count": 108,
    "importance_score": 6.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "set up embedded event browser",
    "contentLower": "this document describes how to set up the integration that enables opentext service management (service management, formerly known as smax) users to directly view obm event data in the service management ui. this integration doesn't involve syncing event data between service management and obm. the use case for forwarding obm events to create incidents in service management is documented in integrate with obm for incident and event data synchronization. overview use case incident analysts often struggle to find meaningful information to analyze incidents raised by end users. to help incident analysts find relevant information to troubleshoot incidents faster, we embedded the configuration item (ci) topology and obm event browser into the service management incident form. with real-time access to obm event data, incident analysts can immediately see events for the service that the incident is created for. with this information, the analyst can identify potential root causes of an incide",
    "keywordsLower": [
      "smax_integration_23_4.zip",
      "installer.bat",
      "page.the",
      "24.2",
      "https://<obm",
      "ancestors.add",
      "23.4",
      "internaldomain.com",
      "settings.add",
      "pane.in",
      "microsoft.com",
      "installer.sh",
      "src.add",
      "https://<service",
      "values.yaml",
      "credentials.in",
      "http://schemas.microsoft.com/identity/claims/tenantid",
      "http://proxy:8080>\"no_proxy=\"<your",
      "https://proxy:8080>\"http_proxy=\"<your",
      "set",
      "embedded",
      "event",
      "browser",
      "overview",
      "case",
      "architecture",
      "connectivity",
      "prerequisites",
      "configure",
      "obm",
      "create",
      "integration",
      "user",
      "load",
      "management",
      "pack",
      "change",
      "infrastructure",
      "settings",
      "sso",
      "between",
      "service",
      "shared",
      "idp",
      "saml",
      "single",
      "sign",
      "idm",
      "oidc",
      "client",
      "suite",
      "automatic",
      "permission",
      "assignment",
      "enable",
      "widget",
      "display",
      "add",
      "hostname",
      "authorized",
      "domains",
      "list",
      "allow",
      "document",
      "describes",
      "enables",
      "opentext",
      "formerly",
      "known",
      "smax",
      "users",
      "directly",
      "view",
      "data",
      "ui.",
      "doesn",
      "involve",
      "syncing",
      "obm.",
      "forwarding",
      "events",
      "incidents",
      "documented",
      "integrate",
      "incident",
      "synchronization.",
      "analysts",
      "often",
      "struggle",
      "find",
      "meaningful",
      "information",
      "analyze",
      "raised",
      "end",
      "users.",
      "help",
      "relevant",
      "troubleshoot",
      "faster"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Set up Closed Loop Incident Process (CLIP)",
    "content": "The Service Management integration with OBM is bi-directional. It enables you to forward OBM events to Service Management to create and update incidents and synchronize incident changes back to OBM events.The communication from OBM to Service Management occurs through direct REST calls using the Service Management Case Exchange REST API and External System. Service Management uses the Case Exchange framework to create and update incidents in Service Management based on events in OBM.The communication from Service Management to OBM leverages the Service Management Integration Studio to prepare the payloads required by OBM to update the events.This document applies to Operations Bridge Manager Classic, Operations Bridge Manager Containerized, and OpScope. For brevity, we use OBM to refer to all these flavors of Operations Bridge Manager in this document.Integration comparisonStarting from version 24.2, we changed the way to send Service Management incident updates to OBM to update the ev",
    "url": "intgomi",
    "filename": "intgomi",
    "headings": [
      "Integration comparison",
      "Use cases",
      "Set up the integration",
      "Step 1: Prerequisites",
      "1.1 Prepare an integration user",
      "1.2 Configure the external system record",
      "1.3 Prepare the Groovy Script",
      "Step 2: Configure OBM",
      "2.2 Configure Service Management as a connected server in OBM",
      "2.3 Configure event forwarding rules",
      "Step 3: Configure Service Management",
      "3.1 Configure an agent in Service Management (optional)",
      "3.2 Set up the On-Premises Bridge(OPB) agent on a local server",
      "3.3 Configure a Service Management endpoint",
      "3.4: Configure the Service Management Integration Studio integration",
      "3.5: Configure a business rule to send incident updates to OBM",
      "Step 4: Verify the integration",
      "4.1: Sync OBM events to Service Management incidents",
      "4.2: Sync Service Management incidents to OBM events",
      "How to customize attribute synchronization"
    ],
    "keywords": [
      "omi_cert.cer",
      "necessary.The",
      "4.1",
      "rule.To",
      "server.On",
      "resolution.From",
      "synchronized.The",
      "1.1",
      "sma_CA.cer",
      "appears.In",
      "configured.For",
      "upgrade.The",
      "adapter.log",
      "3.3",
      "3.2",
      "rules.In",
      "events.The",
      "documentation.To",
      "integration.Step",
      "details.In",
      "configuration.Run",
      "phases.The",
      "system.In",
      "Agent.If",
      "mgmt.sh",
      "filters.The",
      "2.0",
      "https://[FQDN_OMi]/omi.Go",
      "documentation.It",
      "OBM.The",
      "https.Base",
      "OBM.Edit",
      "import_ldap_certs.bat",
      "Studio.To",
      "entity.Id",
      "Studio.In",
      "1.3",
      "1.1.1.3",
      "list.See",
      "https://[FQDN]/opr-gateway",
      "CREATE.Back",
      "checkbox.The",
      "mode.In",
      "expected.To",
      "manager.Most",
      "https://host.domain.com/opr-gateway/.UsernameEnter",
      "file.For",
      "mapping.See",
      "opens.In",
      "workflow.In",
      "https://[FQDN]/omi.Download",
      "page.If",
      "Management.Set",
      "incident.You",
      "domain.com",
      "OBM.In",
      "system.Get",
      "mgmt.bat",
      "OBM.To",
      "3.In",
      "accordingly.You",
      "updated.From",
      "current_user.Upn",
      "3.1",
      "2.2",
      "3.5",
      "2.In",
      "java.net",
      "comments.Use",
      "script.Step",
      "New.Make",
      "4.2",
      "1.1.1",
      "instance.Keep",
      "file.Save",
      "CREATE.For",
      "payloads.Set",
      "OBM.From",
      "OBM.Pay",
      "http://localhost:2317/opr-gateway/EventReceiver",
      "3.4",
      "closed.How",
      "up.OBM",
      "menu.If",
      "HTTP.The",
      "System.In",
      "Management.Step",
      "Management.From",
      "specified.In",
      "Save.In",
      "results.Run",
      "controller.log",
      "endpoint.An",
      "24.2",
      "1.2",
      "section.Next",
      "Management.To",
      "script.Tips",
      "page.In",
      "connection.conf"
    ],
    "language": "en",
    "word_count": 105,
    "importance_score": 5.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "set up closed loop incident process (clip)",
    "contentLower": "the service management integration with obm is bi-directional. it enables you to forward obm events to service management to create and update incidents and synchronize incident changes back to obm events.the communication from obm to service management occurs through direct rest calls using the service management case exchange rest api and external system. service management uses the case exchange framework to create and update incidents in service management based on events in obm.the communication from service management to obm leverages the service management integration studio to prepare the payloads required by obm to update the events.this document applies to operations bridge manager classic, operations bridge manager containerized, and opscope. for brevity, we use obm to refer to all these flavors of operations bridge manager in this document.integration comparisonstarting from version 24.2, we changed the way to send service management incident updates to obm to update the ev",
    "keywordsLower": [
      "omi_cert.cer",
      "necessary.the",
      "4.1",
      "rule.to",
      "server.on",
      "resolution.from",
      "synchronized.the",
      "1.1",
      "sma_ca.cer",
      "appears.in",
      "configured.for",
      "upgrade.the",
      "adapter.log",
      "3.3",
      "3.2",
      "rules.in",
      "events.the",
      "documentation.to",
      "integration.step",
      "details.in",
      "configuration.run",
      "phases.the",
      "system.in",
      "agent.if",
      "mgmt.sh",
      "filters.the",
      "2.0",
      "https://[fqdn_omi]/omi.go",
      "documentation.it",
      "obm.the",
      "https.base",
      "obm.edit",
      "import_ldap_certs.bat",
      "studio.to",
      "entity.id",
      "studio.in",
      "1.3",
      "1.1.1.3",
      "list.see",
      "https://[fqdn]/opr-gateway",
      "create.back",
      "checkbox.the",
      "mode.in",
      "expected.to",
      "manager.most",
      "https://host.domain.com/opr-gateway/.usernameenter",
      "file.for",
      "mapping.see",
      "opens.in",
      "workflow.in",
      "https://[fqdn]/omi.download",
      "page.if",
      "management.set",
      "incident.you",
      "domain.com",
      "obm.in",
      "system.get",
      "mgmt.bat",
      "obm.to",
      "3.in",
      "accordingly.you",
      "updated.from",
      "current_user.upn",
      "3.1",
      "2.2",
      "3.5",
      "2.in",
      "java.net",
      "comments.use",
      "script.step",
      "new.make",
      "4.2",
      "1.1.1",
      "instance.keep",
      "file.save",
      "create.for",
      "payloads.set",
      "obm.from",
      "obm.pay",
      "http://localhost:2317/opr-gateway/eventreceiver",
      "3.4",
      "closed.how",
      "up.obm",
      "menu.if",
      "http.the",
      "system.in",
      "management.step",
      "management.from",
      "specified.in",
      "save.in",
      "results.run",
      "controller.log",
      "endpoint.an",
      "24.2",
      "1.2",
      "section.next",
      "management.to",
      "script.tips",
      "page.in",
      "connection.conf"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Schedule Downtime",
    "content": "Overview It is now possible to integrate with OBM by using the Integration Studio to scheduled downtimes. A change request is set up in Service Management with a scheduled downtime. This will trigger the integration scenario for creating downtimes in OBM for each CI attached to the change. The integration scenario will forward the downtime details for every CI to OBM. The integration scenario will update the change request with details about the status of the downtime creation. The integration use cases described in this document serve as examples to inspire and guide your integration efforts. However, they should not be considered as prescriptive or guaranteed solutions for your particular scenario. The examples may or may not be applicable to your license edition. Considerations and Prerequisites To ensure the integration runs smoothly, please review the following items. OBM accepts only downtime start dates which are at least 1 day in future. OBM minimum version must be 24.4. Maximu",
    "url": "scheduledowntime",
    "filename": "scheduledowntime",
    "headings": [
      "Overview",
      "Considerations and Prerequisites",
      "Set up the integration",
      "Prepare an integration user in Service Management",
      "Prepare an integration user in OBM",
      "Create an endpoint in Service Management",
      "Create an integration",
      "Add and configure the scenarios",
      "Schedule downtime"
    ],
    "keywords": [
      "2.0",
      "24.4",
      "https://<fqdn>/opr-web/rest",
      "https://<fqdn",
      "schedule",
      "downtime",
      "overview",
      "considerations",
      "prerequisites",
      "set",
      "integration",
      "prepare",
      "user",
      "service",
      "management",
      "obm",
      "create",
      "endpoint",
      "add",
      "configure",
      "scenarios",
      "now",
      "possible",
      "integrate",
      "studio",
      "scheduled",
      "downtimes.",
      "change",
      "request",
      "downtime.",
      "trigger",
      "scenario",
      "creating",
      "downtimes",
      "ci",
      "attached",
      "change.",
      "forward",
      "details",
      "every",
      "obm.",
      "update",
      "about",
      "status",
      "creation.",
      "cases",
      "described",
      "document",
      "serve",
      "examples",
      "inspire",
      "guide",
      "efforts.",
      "however",
      "considered",
      "prescriptive",
      "guaranteed",
      "solutions",
      "particular",
      "scenario.",
      "applicable",
      "license",
      "edition.",
      "ensure",
      "runs",
      "smoothly",
      "please",
      "review",
      "following",
      "items.",
      "accepts",
      "start",
      "dates",
      "least",
      "day",
      "future.",
      "minimum",
      "version",
      "24.4.",
      "maximum",
      "allows",
      "certain",
      "amount",
      "system.",
      "number",
      "reached",
      "cannot",
      "new",
      "therefore",
      "fail.",
      "cis",
      "per",
      "controls",
      "allowed",
      "direct",
      "impacted",
      "settings",
      "covers",
      "requirements.",
      "exceeded"
    ],
    "language": "en",
    "word_count": 90,
    "importance_score": 6.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "schedule downtime",
    "contentLower": "overview it is now possible to integrate with obm by using the integration studio to scheduled downtimes. a change request is set up in service management with a scheduled downtime. this will trigger the integration scenario for creating downtimes in obm for each ci attached to the change. the integration scenario will forward the downtime details for every ci to obm. the integration scenario will update the change request with details about the status of the downtime creation. the integration use cases described in this document serve as examples to inspire and guide your integration efforts. however, they should not be considered as prescriptive or guaranteed solutions for your particular scenario. the examples may or may not be applicable to your license edition. considerations and prerequisites to ensure the integration runs smoothly, please review the following items. obm accepts only downtime start dates which are at least 1 day in future. obm minimum version must be 24.4. maximu",
    "keywordsLower": [
      "2.0",
      "24.4",
      "https://<fqdn>/opr-web/rest",
      "https://<fqdn",
      "schedule",
      "downtime",
      "overview",
      "considerations",
      "prerequisites",
      "set",
      "integration",
      "prepare",
      "user",
      "service",
      "management",
      "obm",
      "create",
      "endpoint",
      "add",
      "configure",
      "scenarios",
      "now",
      "possible",
      "integrate",
      "studio",
      "scheduled",
      "downtimes.",
      "change",
      "request",
      "downtime.",
      "trigger",
      "scenario",
      "creating",
      "downtimes",
      "ci",
      "attached",
      "change.",
      "forward",
      "details",
      "every",
      "obm.",
      "update",
      "about",
      "status",
      "creation.",
      "cases",
      "described",
      "document",
      "serve",
      "examples",
      "inspire",
      "guide",
      "efforts.",
      "however",
      "considered",
      "prescriptive",
      "guaranteed",
      "solutions",
      "particular",
      "scenario.",
      "applicable",
      "license",
      "edition.",
      "ensure",
      "runs",
      "smoothly",
      "please",
      "review",
      "following",
      "items.",
      "accepts",
      "start",
      "dates",
      "least",
      "day",
      "future.",
      "minimum",
      "version",
      "24.4.",
      "maximum",
      "allows",
      "certain",
      "amount",
      "system.",
      "number",
      "reached",
      "cannot",
      "new",
      "therefore",
      "fail.",
      "cis",
      "per",
      "controls",
      "allowed",
      "direct",
      "impacted",
      "settings",
      "covers",
      "requirements.",
      "exceeded"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Teams bot integration",
    "content": "It is now possible to use the Integration Studio as the bot engine for Microsoft Teams (MS Teams), leveraging the Integration Studio with the provided listener function. Once the MS Teams app/bot is created and published in your organization, the Integration Studio acts as the bot endpoint and can be used to handle a variety of use cases. Use cases The MS Teams bot scenario templates that we provide can handle the following use cases. Interact with MS Teams Bot This template represents the bot backend and is the main template to handle all user messages in MS Teams (including questions, bot commands, user actions). MS Teams will push the messages to this template. Then the scenario analyzes and handles the messages accordingly. In this template, we implemented the use cases for handling the greeting message, raising a standard request, starting a Virtual Agent search, and opening service catalogue offerings. On SaaS, the bot supports answering user questions by using the Aviator. This ",
    "url": "integrateteamsbot",
    "filename": "integrateteamsbot",
    "headings": [
      "Use cases",
      "Interact with MS Teams Bot",
      "Publish hot news in MS Teams",
      "Send request notifications",
      "Technical overview",
      "Configure apps in MS Teams and Azure",
      "Create a bot in Microsoft Teams",
      "Add the app to MS Teams",
      "Approve the app",
      "Configure the MAX Virtual Agent app in Azure Portal",
      "Configure Service Management",
      "Prepare an integration user",
      "Create an endpoint to connect to the MS Graph API",
      "Create an endpoint to connect to the Azure Bot Framework API",
      "Create an integration",
      "Configure the scenario",
      "Use the scenarios",
      "Interact with MS Teams Bot",
      "Send news notification",
      "Send request notification"
    ],
    "keywords": [
      "https://api.botframework.com/.default",
      "Marketplace.Log",
      "https://graph.microsoft.com",
      "microsoftonline.com",
      "type.Add",
      "Add.Open",
      "page.In",
      "integration.In",
      "microsoft.com",
      "Teams.Copy",
      "https://smba.trafficmanager.net/teams",
      "ReadBasic.All",
      "https://login.microsoftonline.com/<Directory",
      "v2.0",
      "trafficmanager.net",
      "2.0",
      "ecosystem.MS",
      "AllUser.Read",
      "bot.Copy",
      "botframework.com",
      "teams",
      "bot",
      "integration",
      "cases",
      "interact",
      "ms",
      "publish",
      "hot",
      "news",
      "send",
      "request",
      "notifications",
      "technical",
      "overview",
      "configure",
      "apps",
      "azure",
      "create",
      "microsoft",
      "add",
      "app",
      "approve",
      "max",
      "virtual",
      "agent",
      "portal",
      "service",
      "management",
      "prepare",
      "user",
      "endpoint",
      "connect",
      "graph",
      "api",
      "framework",
      "scenario",
      "scenarios",
      "notification",
      "limitations",
      "now",
      "possible",
      "studio",
      "engine",
      "leveraging",
      "provided",
      "listener",
      "function.",
      "once",
      "created",
      "published",
      "organization",
      "acts",
      "handle",
      "variety",
      "cases.",
      "templates",
      "provide",
      "following",
      "template",
      "represents",
      "backend",
      "main",
      "all",
      "messages",
      "including",
      "questions",
      "commands",
      "actions",
      "push",
      "template.",
      "analyzes",
      "handles",
      "accordingly.",
      "implemented",
      "handling",
      "greeting",
      "message",
      "raising",
      "standard",
      "starting"
    ],
    "language": "en",
    "word_count": 101,
    "importance_score": 6.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "teams bot integration",
    "contentLower": "it is now possible to use the integration studio as the bot engine for microsoft teams (ms teams), leveraging the integration studio with the provided listener function. once the ms teams app/bot is created and published in your organization, the integration studio acts as the bot endpoint and can be used to handle a variety of use cases. use cases the ms teams bot scenario templates that we provide can handle the following use cases. interact with ms teams bot this template represents the bot backend and is the main template to handle all user messages in ms teams (including questions, bot commands, user actions). ms teams will push the messages to this template. then the scenario analyzes and handles the messages accordingly. in this template, we implemented the use cases for handling the greeting message, raising a standard request, starting a virtual agent search, and opening service catalogue offerings. on saas, the bot supports answering user questions by using the aviator. this ",
    "keywordsLower": [
      "https://api.botframework.com/.default",
      "marketplace.log",
      "https://graph.microsoft.com",
      "microsoftonline.com",
      "type.add",
      "add.open",
      "page.in",
      "integration.in",
      "microsoft.com",
      "teams.copy",
      "https://smba.trafficmanager.net/teams",
      "readbasic.all",
      "https://login.microsoftonline.com/<directory",
      "v2.0",
      "trafficmanager.net",
      "2.0",
      "ecosystem.ms",
      "alluser.read",
      "bot.copy",
      "botframework.com",
      "teams",
      "bot",
      "integration",
      "cases",
      "interact",
      "ms",
      "publish",
      "hot",
      "news",
      "send",
      "request",
      "notifications",
      "technical",
      "overview",
      "configure",
      "apps",
      "azure",
      "create",
      "microsoft",
      "add",
      "app",
      "approve",
      "max",
      "virtual",
      "agent",
      "portal",
      "service",
      "management",
      "prepare",
      "user",
      "endpoint",
      "connect",
      "graph",
      "api",
      "framework",
      "scenario",
      "scenarios",
      "notification",
      "limitations",
      "now",
      "possible",
      "studio",
      "engine",
      "leveraging",
      "provided",
      "listener",
      "function.",
      "once",
      "created",
      "published",
      "organization",
      "acts",
      "handle",
      "variety",
      "cases.",
      "templates",
      "provide",
      "following",
      "template",
      "represents",
      "backend",
      "main",
      "all",
      "messages",
      "including",
      "questions",
      "commands",
      "actions",
      "push",
      "template.",
      "analyzes",
      "handles",
      "accordingly.",
      "implemented",
      "handling",
      "greeting",
      "message",
      "raising",
      "standard",
      "starting"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Teams channel notification",
    "content": "You can integrate Service Management with Microsoft Teams (MS Teams) in two ways: Using the Built-in Solution introduced in version 1Using the Integration Studio capability introduced in version 2 Both options allow agent users to collaborate in MS Teams while adhering to your established governance processes. Sample use cases The following typical use cases show how this integration can benefit your organization. This list is not exhaustive - the integration supports several more scenarios. Major incident The Major incident use case enables agent users to work together on major incidents, helping resolve critical issues quickly. The integration provides the following capabilities: Incident notifications: Notifies key stakeholders in Microsoft Teams as soon as a major incident record is created, ensuring the right people are connected.Stakeholder collaboration: Stakeholders can view incident details, collaborate on resolution, and close the record directly in Teams.Discussion tracking:",
    "url": "teamschannelnotification",
    "filename": "teamschannelnotification",
    "headings": [
      "Sample use cases",
      "Major incident",
      "Virtual CAB",
      "Contract negotiations",
      "Comparison version 1 vs version 2",
      "Overview",
      "Prerequisites",
      "Create a user account for the integration",
      "Create teams and channels",
      "Create a dedicated integration user in Service Management",
      "Register an Service Management app on the Azure portal",
      "Register an application for the integration",
      "Configure a client secret for the application",
      "Configure authentication for the application",
      "Configure API permissions for the application"
    ],
    "keywords": [
      "option.Set",
      "ChannelMessage.Read",
      "pane.For",
      "https://www.microsoft.com/en-us/microsoft-teams",
      "https://<FQDN>/xie/public/v1/azure_callback",
      "microsoft.com",
      "https://<External",
      "channels.For",
      "User.Read",
      "https://<FQDN>/rest/<Tenant",
      "teams",
      "channel",
      "notification",
      "sample",
      "cases",
      "major",
      "incident",
      "virtual",
      "cab",
      "contract",
      "negotiations",
      "comparison",
      "version",
      "vs",
      "overview",
      "prerequisites",
      "create",
      "user",
      "account",
      "integration",
      "channels",
      "dedicated",
      "service",
      "management",
      "register",
      "app",
      "azure",
      "portal",
      "application",
      "configure",
      "client",
      "secret",
      "authentication",
      "api",
      "permissions",
      "integrate",
      "microsoft",
      "ms",
      "two",
      "ways",
      "built-in",
      "solution",
      "introduced",
      "1using",
      "studio",
      "capability",
      "both",
      "options",
      "allow",
      "agent",
      "users",
      "collaborate",
      "while",
      "adhering",
      "established",
      "governance",
      "processes.",
      "following",
      "typical",
      "show",
      "benefit",
      "organization.",
      "list",
      "exhaustive",
      "supports",
      "several",
      "scenarios.",
      "case",
      "enables",
      "work",
      "together",
      "incidents",
      "helping",
      "resolve",
      "critical",
      "issues",
      "quickly.",
      "provides",
      "capabilities",
      "notifications",
      "notifies",
      "key",
      "stakeholders",
      "soon",
      "record",
      "created",
      "ensuring",
      "right",
      "people",
      "connected.stakeholder"
    ],
    "language": "en",
    "word_count": 100,
    "importance_score": 6.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "teams channel notification",
    "contentLower": "you can integrate service management with microsoft teams (ms teams) in two ways: using the built-in solution introduced in version 1using the integration studio capability introduced in version 2 both options allow agent users to collaborate in ms teams while adhering to your established governance processes. sample use cases the following typical use cases show how this integration can benefit your organization. this list is not exhaustive - the integration supports several more scenarios. major incident the major incident use case enables agent users to work together on major incidents, helping resolve critical issues quickly. the integration provides the following capabilities: incident notifications: notifies key stakeholders in microsoft teams as soon as a major incident record is created, ensuring the right people are connected.stakeholder collaboration: stakeholders can view incident details, collaborate on resolution, and close the record directly in teams.discussion tracking:",
    "keywordsLower": [
      "option.set",
      "channelmessage.read",
      "pane.for",
      "https://www.microsoft.com/en-us/microsoft-teams",
      "https://<fqdn>/xie/public/v1/azure_callback",
      "microsoft.com",
      "https://<external",
      "channels.for",
      "user.read",
      "https://<fqdn>/rest/<tenant",
      "teams",
      "channel",
      "notification",
      "sample",
      "cases",
      "major",
      "incident",
      "virtual",
      "cab",
      "contract",
      "negotiations",
      "comparison",
      "version",
      "vs",
      "overview",
      "prerequisites",
      "create",
      "user",
      "account",
      "integration",
      "channels",
      "dedicated",
      "service",
      "management",
      "register",
      "app",
      "azure",
      "portal",
      "application",
      "configure",
      "client",
      "secret",
      "authentication",
      "api",
      "permissions",
      "integrate",
      "microsoft",
      "ms",
      "two",
      "ways",
      "built-in",
      "solution",
      "introduced",
      "1using",
      "studio",
      "capability",
      "both",
      "options",
      "allow",
      "agent",
      "users",
      "collaborate",
      "while",
      "adhering",
      "established",
      "governance",
      "processes.",
      "following",
      "typical",
      "show",
      "benefit",
      "organization.",
      "list",
      "exhaustive",
      "supports",
      "several",
      "scenarios.",
      "case",
      "enables",
      "work",
      "together",
      "incidents",
      "helping",
      "resolve",
      "critical",
      "issues",
      "quickly.",
      "provides",
      "capabilities",
      "notifications",
      "notifies",
      "key",
      "stakeholders",
      "soon",
      "record",
      "created",
      "ensuring",
      "right",
      "people",
      "connected.stakeholder"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Teams channel notification v1",
    "content": "This version uses the built-in integration framework with basic configuration and monitoring possibilities. Privacy notice If you enable this integration, the application will exchange information with Microsoft Teams. It remains at all times the Customer's sole responsibility to assess these specifications against the Customer's regulatory and business requirements. Set up the integration Connect Service Management with MS Teams Perform the following steps: Log in to the agent interface as the tenant admin.Navigate to Administration > Utilities > Integration, and then select Integration Studio from the dropdown list on the top of the screen.Click Microsoft Teams on the left pane. Read the privacy notice at the bottom of this screen before you continue. In the State section, click Active to activate the integration. Configure the following settings: Configure the Azure AD application settings, which you have noted down when registering the application: Application (client) IDDirectory ",
    "url": "integratemsteamsthroughintegrationhub",
    "filename": "integratemsteamsthroughintegrationhub",
    "headings": [
      "Set up the integration",
      "Connect Service Management with MS Teams",
      "Use the integration",
      "Step 1. Configure a scenario for the integration",
      "Step 2. Create a business rule",
      "Step 3. Verify the integration",
      "How-tos",
      "How to configure field mapping",
      "Variable expression",
      "String constant",
      "Supported functions",
      "Field lengths",
      "How to reactivate the integration",
      "How to set up the sample use cases",
      "How to trigger actions based on keywords in MS Teams replies",
      "How to set up custom actions",
      "Collaborate in MS Teams",
      "Chat with an End User in MS Teams",
      "Limitations",
      "Troubleshooting"
    ],
    "keywords": [
      "OwnedByGroup.Name",
      "type.On",
      "exported.The",
      "opens.In",
      "successfully.In",
      "Teams.In",
      "tab.In",
      "microsoft.com",
      "Administrator.Name",
      "production.When",
      "tab.Add",
      "field.This",
      "Accept.Wait",
      "https://teams.microsoft.com/l/chat/0/0?users=${entity.RequestedByPerson.Email",
      "record.Make",
      "teams",
      "channel",
      "notification",
      "v1",
      "set",
      "integration",
      "connect",
      "service",
      "management",
      "ms",
      "step",
      "1.",
      "configure",
      "scenario",
      "2.",
      "create",
      "business",
      "rule",
      "3.",
      "verify",
      "how-tos",
      "field",
      "mapping",
      "variable",
      "expression",
      "string",
      "constant",
      "supported",
      "functions",
      "lengths",
      "reactivate",
      "sample",
      "cases",
      "trigger",
      "actions",
      "based",
      "keywords",
      "replies",
      "custom",
      "collaborate",
      "chat",
      "end",
      "user",
      "limitations",
      "troubleshooting",
      "version",
      "uses",
      "built-in",
      "framework",
      "basic",
      "configuration",
      "monitoring",
      "possibilities.",
      "privacy",
      "notice",
      "enable",
      "application",
      "exchange",
      "information",
      "microsoft",
      "teams.",
      "remains",
      "all",
      "times",
      "customer",
      "sole",
      "responsibility",
      "assess",
      "specifications",
      "against",
      "regulatory",
      "requirements.",
      "perform",
      "following",
      "steps",
      "log",
      "agent",
      "interface",
      "tenant",
      "admin.navigate",
      "administration",
      "utilities",
      "select",
      "studio",
      "dropdown"
    ],
    "language": "en",
    "word_count": 93,
    "importance_score": 6.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "teams channel notification v1",
    "contentLower": "this version uses the built-in integration framework with basic configuration and monitoring possibilities. privacy notice if you enable this integration, the application will exchange information with microsoft teams. it remains at all times the customer's sole responsibility to assess these specifications against the customer's regulatory and business requirements. set up the integration connect service management with ms teams perform the following steps: log in to the agent interface as the tenant admin.navigate to administration > utilities > integration, and then select integration studio from the dropdown list on the top of the screen.click microsoft teams on the left pane. read the privacy notice at the bottom of this screen before you continue. in the state section, click active to activate the integration. configure the following settings: configure the azure ad application settings, which you have noted down when registering the application: application (client) iddirectory ",
    "keywordsLower": [
      "ownedbygroup.name",
      "type.on",
      "exported.the",
      "opens.in",
      "successfully.in",
      "teams.in",
      "tab.in",
      "microsoft.com",
      "administrator.name",
      "production.when",
      "tab.add",
      "field.this",
      "accept.wait",
      "https://teams.microsoft.com/l/chat/0/0?users=${entity.requestedbyperson.email",
      "record.make",
      "teams",
      "channel",
      "notification",
      "v1",
      "set",
      "integration",
      "connect",
      "service",
      "management",
      "ms",
      "step",
      "1.",
      "configure",
      "scenario",
      "2.",
      "create",
      "business",
      "rule",
      "3.",
      "verify",
      "how-tos",
      "field",
      "mapping",
      "variable",
      "expression",
      "string",
      "constant",
      "supported",
      "functions",
      "lengths",
      "reactivate",
      "sample",
      "cases",
      "trigger",
      "actions",
      "based",
      "keywords",
      "replies",
      "custom",
      "collaborate",
      "chat",
      "end",
      "user",
      "limitations",
      "troubleshooting",
      "version",
      "uses",
      "built-in",
      "framework",
      "basic",
      "configuration",
      "monitoring",
      "possibilities.",
      "privacy",
      "notice",
      "enable",
      "application",
      "exchange",
      "information",
      "microsoft",
      "teams.",
      "remains",
      "all",
      "times",
      "customer",
      "sole",
      "responsibility",
      "assess",
      "specifications",
      "against",
      "regulatory",
      "requirements.",
      "perform",
      "following",
      "steps",
      "log",
      "agent",
      "interface",
      "tenant",
      "admin.navigate",
      "administration",
      "utilities",
      "select",
      "studio",
      "dropdown"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Teams channel notification v2",
    "content": "Overview The Microsoft (MS) Teams integration version 2 takes advantage of all features of the Integration Studio framework and provides the following benefits: Greater flexibility in configuring the integration.Allows customers to define their own adaptive cards that are sent directly to the MS Teams channel. Privacy notice If you enable this integration, the application exchanges information with Microsoft Teams. It the customer’s responsibility to evaluate these specifications and ensure they meet the customer’s regulatory and business requirements. Flavors This version of the MS Teams channel notification solution offers the following flavors for enabling notifications. Flavor 1: Subscription modeFlavor 2: Outgoing webhook mode Subscription mode Microsoft allows customers to subscribe to specific resources, such as MS Teams channels. Once subscribed, Microsoft notifies the subscriber about changes to the resource. Using subscription mode ensures that when someone replies to a threa",
    "url": "integratemsteamsthroughintegrationhubv2",
    "filename": "integratemsteamsthroughintegrationhubv2",
    "headings": [
      "Overview",
      "Flavors",
      "Subscription mode",
      "Outgoing webhook mode",
      "Create an endpoint",
      "Create an integration",
      "Subscription mode",
      "Configure the scenarios",
      "Set up subscription",
      "Schedule subscription refresh",
      "Outgoing webhook mode",
      "Configure the scenarios",
      "Set up reply handling",
      "Configure the outgoing webhook.",
      "Run the scenarios",
      "How-tos",
      "Get the Team ID",
      "Get the Channel ID",
      "Modify the adaptive card",
      "Set up the sample use cases"
    ],
    "keywords": [
      "section.To",
      "card.json",
      "Management.All",
      "listener.In",
      "https://graph.microsoft.com",
      "microsoftonline.com",
      "Management.The",
      "https://graph.microsoft.com/.default",
      "page.In",
      "integration.In",
      "type.On",
      "adaptivecards.io",
      "https://teams.microsoft.com/l/channel/19%3AXXXXXXXXXXXXXXXX%40thread.tacv2/General?groupId=aaaaaaaa-bbbb-cccc-dddd-eeeeeeeeeeee&tenantId=ffffffff-gggg-hhhh-iiii-jjjjjjjjjjjj",
      "microsoft.com",
      "tab.In",
      "Teams.Go",
      "https://teams.microsoft.com/l/team/19%3AXXXXXXXXXXXXXXXX%40thread.tacv2/conversations?groupId=aaaaaaaa-bbbb-cccc-dddd-eeeeeeeeeeee&tenantId=ffffffff-gggg-hhhh-iiii-jjjjjjjjjjjj",
      "trigger.Save",
      "5.To",
      "v2.0",
      "https://login.microsoftonline.com/<Directory_Id>/oauth2/v2.0/authorize?prompt=login",
      "http://adaptivecards.io/schemas/adaptive-card.json\",\"version\":\"1.6",
      "Settings.Set",
      "1.6",
      "2.0",
      "team.Go",
      "webhook.Open",
      "tab.Go",
      "Active.In",
      "Save.In",
      "teams",
      "channel",
      "notification",
      "v2",
      "overview",
      "flavors",
      "subscription",
      "mode",
      "outgoing",
      "webhook",
      "create",
      "endpoint",
      "integration",
      "configure",
      "scenarios",
      "set",
      "schedule",
      "refresh",
      "reply",
      "handling",
      "webhook.",
      "run",
      "how-tos",
      "get",
      "team",
      "id",
      "modify",
      "adaptive",
      "card",
      "sample",
      "cases",
      "major",
      "incident",
      "virtual",
      "cab",
      "contract",
      "negotiations",
      "microsoft",
      "ms",
      "version",
      "takes",
      "advantage",
      "all",
      "features",
      "studio",
      "framework",
      "provides",
      "following",
      "benefits",
      "greater",
      "flexibility",
      "configuring",
      "integration.allows",
      "customers",
      "define",
      "own",
      "cards",
      "sent",
      "directly",
      "channel.",
      "privacy",
      "notice",
      "enable",
      "application",
      "exchanges",
      "information",
      "teams.",
      "customer",
      "responsibility",
      "evaluate"
    ],
    "language": "en",
    "word_count": 102,
    "importance_score": 6.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "teams channel notification v2",
    "contentLower": "overview the microsoft (ms) teams integration version 2 takes advantage of all features of the integration studio framework and provides the following benefits: greater flexibility in configuring the integration.allows customers to define their own adaptive cards that are sent directly to the ms teams channel. privacy notice if you enable this integration, the application exchanges information with microsoft teams. it the customer’s responsibility to evaluate these specifications and ensure they meet the customer’s regulatory and business requirements. flavors this version of the ms teams channel notification solution offers the following flavors for enabling notifications. flavor 1: subscription modeflavor 2: outgoing webhook mode subscription mode microsoft allows customers to subscribe to specific resources, such as ms teams channels. once subscribed, microsoft notifies the subscriber about changes to the resource. using subscription mode ensures that when someone replies to a threa",
    "keywordsLower": [
      "section.to",
      "card.json",
      "management.all",
      "listener.in",
      "https://graph.microsoft.com",
      "microsoftonline.com",
      "management.the",
      "https://graph.microsoft.com/.default",
      "page.in",
      "integration.in",
      "type.on",
      "adaptivecards.io",
      "https://teams.microsoft.com/l/channel/19%3axxxxxxxxxxxxxxxx%40thread.tacv2/general?groupid=aaaaaaaa-bbbb-cccc-dddd-eeeeeeeeeeee&tenantid=ffffffff-gggg-hhhh-iiii-jjjjjjjjjjjj",
      "microsoft.com",
      "tab.in",
      "teams.go",
      "https://teams.microsoft.com/l/team/19%3axxxxxxxxxxxxxxxx%40thread.tacv2/conversations?groupid=aaaaaaaa-bbbb-cccc-dddd-eeeeeeeeeeee&tenantid=ffffffff-gggg-hhhh-iiii-jjjjjjjjjjjj",
      "trigger.save",
      "5.to",
      "v2.0",
      "https://login.microsoftonline.com/<directory_id>/oauth2/v2.0/authorize?prompt=login",
      "http://adaptivecards.io/schemas/adaptive-card.json\",\"version\":\"1.6",
      "settings.set",
      "1.6",
      "2.0",
      "team.go",
      "webhook.open",
      "tab.go",
      "active.in",
      "save.in",
      "teams",
      "channel",
      "notification",
      "v2",
      "overview",
      "flavors",
      "subscription",
      "mode",
      "outgoing",
      "webhook",
      "create",
      "endpoint",
      "integration",
      "configure",
      "scenarios",
      "set",
      "schedule",
      "refresh",
      "reply",
      "handling",
      "webhook.",
      "run",
      "how-tos",
      "get",
      "team",
      "id",
      "modify",
      "adaptive",
      "card",
      "sample",
      "cases",
      "major",
      "incident",
      "virtual",
      "cab",
      "contract",
      "negotiations",
      "microsoft",
      "ms",
      "version",
      "takes",
      "advantage",
      "all",
      "features",
      "studio",
      "framework",
      "provides",
      "following",
      "benefits",
      "greater",
      "flexibility",
      "configuring",
      "integration.allows",
      "customers",
      "define",
      "own",
      "cards",
      "sent",
      "directly",
      "channel.",
      "privacy",
      "notice",
      "enable",
      "application",
      "exchanges",
      "information",
      "teams.",
      "customer",
      "responsibility",
      "evaluate"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Technical details about the OO flows",
    "content": "This section describes the OO flows in more detail. Since the Service Management side is documented in the previous sections, it's not mentioned again. The OO flows contain all the logic to receive data from Service Management and to transform the data and submit it to SAP Solution Manager. Flow 1 – Create incidents in SAP Step - Get an XSFR token This step connects with the SAP credentials configured in the System Properties to receive an XSFR token, which is required in the following steps when connecting to SAP. Step - Parse the HTTP header This step parses the header returned from the first step and extracts the XSFR token. If no token is available, an error occurs. Step - Create and manipulate the SAP Solution Manager payload This step takes the data received from Service Management and prepares the JSON payload for the SAP Request. This step also transforms the data to ensure the payload is acceptable to SAP. The scriptlet section of this step prepares the data. For example, it t",
    "url": "ooflowdetails",
    "filename": "ooflowdetails",
    "headings": [
      "Flow 1 – Create incidents in SAP",
      "Step - Get an XSFR token",
      "Step - Parse the HTTP header",
      "Step - Create and manipulate the SAP Solution Manager payload",
      "Step – Create Incident in SAP Solution Manager",
      "Extracting the JSON from the SAP response",
      "Parsing the HTTP code",
      "Step – Success/Error Prepare Service Management Payload",
      "Step – Connect to Service Management",
      "Step – Update Incident in Service Management",
      "Flow 2 – Update Incident in SAP",
      "Step – Create and manipulate the SAP Solution Manager payload",
      "Step – Update Incident in SAP Solution Manager",
      "Flow 3 – Update Incident in SAP"
    ],
    "keywords": [
      "technical",
      "details",
      "about",
      "oo",
      "flows",
      "flow",
      "create",
      "incidents",
      "sap",
      "step",
      "get",
      "xsfr",
      "token",
      "parse",
      "http",
      "header",
      "manipulate",
      "solution",
      "manager",
      "payload",
      "incident",
      "extracting",
      "json",
      "response",
      "parsing",
      "code",
      "success",
      "error",
      "prepare",
      "service",
      "management",
      "connect",
      "update",
      "section",
      "describes",
      "detail.",
      "since",
      "side",
      "documented",
      "previous",
      "sections",
      "mentioned",
      "again.",
      "contain",
      "all",
      "logic",
      "receive",
      "data",
      "transform",
      "submit",
      "manager.",
      "connects",
      "credentials",
      "configured",
      "system",
      "properties",
      "required",
      "following",
      "steps",
      "connecting",
      "sap.",
      "parses",
      "returned",
      "first",
      "extracts",
      "token.",
      "available",
      "occurs.",
      "takes",
      "received",
      "prepares",
      "request.",
      "transforms",
      "ensure",
      "acceptable",
      "scriptlet",
      "data.",
      "example",
      "priority",
      "values",
      "corresponding",
      "script",
      "creates",
      "variable",
      "payloadsap",
      "next",
      "input",
      "post",
      "request",
      "towards",
      "generated",
      "posts",
      "step.",
      "consists",
      "several",
      "parameters",
      "embedded.",
      "contains",
      "plus",
      "parameters."
    ],
    "language": "en",
    "word_count": 108,
    "importance_score": 5.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "technical details about the oo flows",
    "contentLower": "this section describes the oo flows in more detail. since the service management side is documented in the previous sections, it's not mentioned again. the oo flows contain all the logic to receive data from service management and to transform the data and submit it to sap solution manager. flow 1 – create incidents in sap step - get an xsfr token this step connects with the sap credentials configured in the system properties to receive an xsfr token, which is required in the following steps when connecting to sap. step - parse the http header this step parses the header returned from the first step and extracts the xsfr token. if no token is available, an error occurs. step - create and manipulate the sap solution manager payload this step takes the data received from service management and prepares the json payload for the sap request. this step also transforms the data to ensure the payload is acceptable to sap. the scriptlet section of this step prepares the data. for example, it t",
    "keywordsLower": [
      "technical",
      "details",
      "about",
      "oo",
      "flows",
      "flow",
      "create",
      "incidents",
      "sap",
      "step",
      "get",
      "xsfr",
      "token",
      "parse",
      "http",
      "header",
      "manipulate",
      "solution",
      "manager",
      "payload",
      "incident",
      "extracting",
      "json",
      "response",
      "parsing",
      "code",
      "success",
      "error",
      "prepare",
      "service",
      "management",
      "connect",
      "update",
      "section",
      "describes",
      "detail.",
      "since",
      "side",
      "documented",
      "previous",
      "sections",
      "mentioned",
      "again.",
      "contain",
      "all",
      "logic",
      "receive",
      "data",
      "transform",
      "submit",
      "manager.",
      "connects",
      "credentials",
      "configured",
      "system",
      "properties",
      "required",
      "following",
      "steps",
      "connecting",
      "sap.",
      "parses",
      "returned",
      "first",
      "extracts",
      "token.",
      "available",
      "occurs.",
      "takes",
      "received",
      "prepares",
      "request.",
      "transforms",
      "ensure",
      "acceptable",
      "scriptlet",
      "data.",
      "example",
      "priority",
      "values",
      "corresponding",
      "script",
      "creates",
      "variable",
      "payloadsap",
      "next",
      "input",
      "post",
      "request",
      "towards",
      "generated",
      "posts",
      "step.",
      "consists",
      "several",
      "parameters",
      "embedded.",
      "contains",
      "plus",
      "parameters."
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Supported email integrations",
    "content": "The following out‑of‑the‑box email integrations can automatically create Service Management requests from incoming user emails. Studio‑based email integrations are highly customizable and has no limits on the number of attachments. OPB‑based email integrations support standard email protocols such as IMAP and POP; however, they cannot be customized and have limits on the number of attachments allowed. Review each integration’s capabilities and choose the one that best fits your needs. Integration type Supported protocols OPB based Email integration IMAP, POP3 OPB based Gmail integration IMAP, POP3 OPB based Email integration using EWS Note: Microsoft will end support for Exchange Web Services EWS on October 1, 2026. EWS Integration Studio based Microsoft 365 email integration MS Graph API",
    "url": "emailintegrations",
    "filename": "emailintegrations",
    "headings": [],
    "keywords": [
      "supported",
      "email",
      "integrations",
      "following",
      "out",
      "box",
      "automatically",
      "create",
      "service",
      "management",
      "requests",
      "incoming",
      "user",
      "emails.",
      "studio",
      "based",
      "highly",
      "customizable",
      "limits",
      "number",
      "attachments.",
      "opb",
      "support",
      "standard",
      "protocols",
      "such",
      "imap",
      "pop",
      "however",
      "cannot",
      "customized",
      "attachments",
      "allowed.",
      "review",
      "integration",
      "capabilities",
      "choose",
      "one",
      "best",
      "fits",
      "needs.",
      "type",
      "pop3",
      "gmail",
      "ews",
      "note",
      "microsoft",
      "end",
      "exchange",
      "web",
      "services",
      "october",
      "2026.",
      "365",
      "ms",
      "graph",
      "api"
    ],
    "language": "en",
    "word_count": 95,
    "importance_score": 3.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "supported email integrations",
    "contentLower": "the following out‑of‑the‑box email integrations can automatically create service management requests from incoming user emails. studio‑based email integrations are highly customizable and has no limits on the number of attachments. opb‑based email integrations support standard email protocols such as imap and pop; however, they cannot be customized and have limits on the number of attachments allowed. review each integration’s capabilities and choose the one that best fits your needs. integration type supported protocols opb based email integration imap, pop3 opb based gmail integration imap, pop3 opb based email integration using ews note: microsoft will end support for exchange web services ews on october 1, 2026. ews integration studio based microsoft 365 email integration ms graph api",
    "keywordsLower": [
      "supported",
      "email",
      "integrations",
      "following",
      "out",
      "box",
      "automatically",
      "create",
      "service",
      "management",
      "requests",
      "incoming",
      "user",
      "emails.",
      "studio",
      "based",
      "highly",
      "customizable",
      "limits",
      "number",
      "attachments.",
      "opb",
      "support",
      "standard",
      "protocols",
      "such",
      "imap",
      "pop",
      "however",
      "cannot",
      "customized",
      "attachments",
      "allowed.",
      "review",
      "integration",
      "capabilities",
      "choose",
      "one",
      "best",
      "fits",
      "needs.",
      "type",
      "pop3",
      "gmail",
      "ews",
      "note",
      "microsoft",
      "end",
      "exchange",
      "web",
      "services",
      "october",
      "2026.",
      "365",
      "ms",
      "graph",
      "api"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Sizing guide for OData integration",
    "content": "Before starting to use the OData integration, read this page to determine if you need additional Datahub pods, read-only platform pods, and additional worker nodes accordingly. Configuration recommendations The configuration recommendations are as follows: We strongly recommend that you deploy OData pods (read-only platform and datahub) on dedicated worker nodes. If you choose to use shared worker nodes, make sure hardware resources are sufficient to avoid competition and overlapping with other pods for OData performance, which may cause a downgrade of the system performance. Suppose each worker node's hardware configuration is 8 CPU cores and 32 GiB RAM, deploy OData pods based on the following guidelines. The maximum deployment recommended on a worker node is 3 datahub pods, or 2 read-only platform pods, or 1 datahub pod plus 1 read-only platform pod. Datahub pods and read-only platform pods should be matched one-to-one. A read-only platform pod and a datahub pod can support up to 4 ",
    "url": "sizingforodata",
    "filename": "sizingforodata",
    "headings": [
      "Configuration recommendations",
      "Determine hardware requirements for the OData integration",
      "Plan additional hardware resources for the DB server",
      "A performance reference based on AWS testing results"
    ],
    "keywords": [
      "1.5",
      "0.4",
      "3.45",
      "1.1",
      "5.9",
      "22.5",
      "16.6",
      "0.75",
      "2.6",
      "0.8",
      "4.12",
      "0.01",
      "43.6",
      "0.05",
      "1.68",
      "6.5",
      "1.77",
      "4.6",
      "0.25",
      "2.55",
      "3.7",
      "11.5",
      "2.3",
      "0.3",
      "0.6",
      "3.6",
      "sizing",
      "guide",
      "odata",
      "integration",
      "configuration",
      "recommendations",
      "determine",
      "hardware",
      "requirements",
      "plan",
      "additional",
      "resources",
      "db",
      "server",
      "performance",
      "reference",
      "based",
      "aws",
      "testing",
      "results",
      "before",
      "starting",
      "read",
      "page",
      "need",
      "datahub",
      "pods",
      "read-only",
      "platform",
      "worker",
      "nodes",
      "accordingly.",
      "follows",
      "strongly",
      "recommend",
      "deploy",
      "dedicated",
      "nodes.",
      "choose",
      "shared",
      "make",
      "sure",
      "sufficient",
      "avoid",
      "competition",
      "overlapping",
      "cause",
      "downgrade",
      "system",
      "performance.",
      "suppose",
      "node",
      "cpu",
      "cores",
      "32",
      "gib",
      "ram",
      "following",
      "guidelines.",
      "maximum",
      "deployment",
      "recommended",
      "pod",
      "plus",
      "pod.",
      "matched",
      "one-to-one.",
      "support",
      "consecutive",
      "api",
      "calls",
      "throughput",
      "about",
      "160000"
    ],
    "language": "en",
    "word_count": 109,
    "importance_score": 5.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "sizing guide for odata integration",
    "contentLower": "before starting to use the odata integration, read this page to determine if you need additional datahub pods, read-only platform pods, and additional worker nodes accordingly. configuration recommendations the configuration recommendations are as follows: we strongly recommend that you deploy odata pods (read-only platform and datahub) on dedicated worker nodes. if you choose to use shared worker nodes, make sure hardware resources are sufficient to avoid competition and overlapping with other pods for odata performance, which may cause a downgrade of the system performance. suppose each worker node's hardware configuration is 8 cpu cores and 32 gib ram, deploy odata pods based on the following guidelines. the maximum deployment recommended on a worker node is 3 datahub pods, or 2 read-only platform pods, or 1 datahub pod plus 1 read-only platform pod. datahub pods and read-only platform pods should be matched one-to-one. a read-only platform pod and a datahub pod can support up to 4 ",
    "keywordsLower": [
      "1.5",
      "0.4",
      "3.45",
      "1.1",
      "5.9",
      "22.5",
      "16.6",
      "0.75",
      "2.6",
      "0.8",
      "4.12",
      "0.01",
      "43.6",
      "0.05",
      "1.68",
      "6.5",
      "1.77",
      "4.6",
      "0.25",
      "2.55",
      "3.7",
      "11.5",
      "2.3",
      "0.3",
      "0.6",
      "3.6",
      "sizing",
      "guide",
      "odata",
      "integration",
      "configuration",
      "recommendations",
      "determine",
      "hardware",
      "requirements",
      "plan",
      "additional",
      "resources",
      "db",
      "server",
      "performance",
      "reference",
      "based",
      "aws",
      "testing",
      "results",
      "before",
      "starting",
      "read",
      "page",
      "need",
      "datahub",
      "pods",
      "read-only",
      "platform",
      "worker",
      "nodes",
      "accordingly.",
      "follows",
      "strongly",
      "recommend",
      "deploy",
      "dedicated",
      "nodes.",
      "choose",
      "shared",
      "make",
      "sure",
      "sufficient",
      "avoid",
      "competition",
      "overlapping",
      "cause",
      "downgrade",
      "system",
      "performance.",
      "suppose",
      "node",
      "cpu",
      "cores",
      "32",
      "gib",
      "ram",
      "following",
      "guidelines.",
      "maximum",
      "deployment",
      "recommended",
      "pod",
      "plus",
      "pod.",
      "matched",
      "one-to-one.",
      "support",
      "consecutive",
      "api",
      "calls",
      "throughput",
      "about",
      "160000"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Set up a tenant",
    "content": "Set up a tenant Before setting up a tenant, make sure the lightweight SSO settings and email service are configured in Configurations, also prepare the following items: License filesLDAP, SAML, or OAuth configuration information including LDAP certificate The following persons are involved in the setup process: Suite administratorsTenant administrators Tasks for suite administrators This image outlines the tasks for suite administrators to perform in Suite Administration. Configure security related settings (such as Lightweight SSO, IdM signing key, and expiration period for access token) and email service settings.Upload license files in Licenses and add them to a license pool. For details, see How to create and edit a license and How to create and edit a license pool.Create a customer in Customers. For details, see How to create and edit a customer.Create an account for the customer in Accounts. For details, see How to create an account.Create a DB type user to serve as the tenant ad",
    "url": "deploytenantwflw",
    "filename": "deploytenantwflw",
    "headings": [
      "Set up a tenant",
      "Tasks for suite administrators",
      "Tasks for tenant administrators",
      "Enable Native SACM for a tenant",
      "Add Design and Deploy (DND) to an existing tenant",
      "Add Cloud Cost Reporting to a tenant",
      "Add Software Asset Management (SAM) to a tenant"
    ],
    "keywords": [
      "set",
      "tenant",
      "tasks",
      "suite",
      "administrators",
      "enable",
      "native",
      "sacm",
      "add",
      "design",
      "deploy",
      "dnd",
      "existing",
      "cloud",
      "cost",
      "reporting",
      "software",
      "asset",
      "management",
      "sam",
      "before",
      "setting",
      "make",
      "sure",
      "lightweight",
      "sso",
      "settings",
      "email",
      "service",
      "configured",
      "configurations",
      "prepare",
      "following",
      "items",
      "license",
      "filesldap",
      "saml",
      "oauth",
      "configuration",
      "information",
      "including",
      "ldap",
      "certificate",
      "persons",
      "involved",
      "setup",
      "process",
      "administratorstenant",
      "image",
      "outlines",
      "perform",
      "administration.",
      "configure",
      "security",
      "related",
      "such",
      "idm",
      "signing",
      "key",
      "expiration",
      "period",
      "access",
      "token",
      "settings.upload",
      "files",
      "licenses",
      "pool.",
      "details",
      "see",
      "create",
      "edit",
      "pool.create",
      "customer",
      "customers.",
      "customer.create",
      "account",
      "accounts.",
      "account.create",
      "db",
      "type",
      "user",
      "serve",
      "administrator.",
      "user.",
      "general",
      "name",
      "case",
      "future",
      "changes",
      "administrator",
      "role.",
      "tenants",
      "created",
      "assign",
      "just",
      "created.",
      "tenant.assign",
      "capacity",
      "tenant.deploy",
      "tenant."
    ],
    "language": "en",
    "word_count": 99,
    "importance_score": 6.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "set up a tenant",
    "contentLower": "set up a tenant before setting up a tenant, make sure the lightweight sso settings and email service are configured in configurations, also prepare the following items: license filesldap, saml, or oauth configuration information including ldap certificate the following persons are involved in the setup process: suite administratorstenant administrators tasks for suite administrators this image outlines the tasks for suite administrators to perform in suite administration. configure security related settings (such as lightweight sso, idm signing key, and expiration period for access token) and email service settings.upload license files in licenses and add them to a license pool. for details, see how to create and edit a license and how to create and edit a license pool.create a customer in customers. for details, see how to create and edit a customer.create an account for the customer in accounts. for details, see how to create an account.create a db type user to serve as the tenant ad",
    "keywordsLower": [
      "set",
      "tenant",
      "tasks",
      "suite",
      "administrators",
      "enable",
      "native",
      "sacm",
      "add",
      "design",
      "deploy",
      "dnd",
      "existing",
      "cloud",
      "cost",
      "reporting",
      "software",
      "asset",
      "management",
      "sam",
      "before",
      "setting",
      "make",
      "sure",
      "lightweight",
      "sso",
      "settings",
      "email",
      "service",
      "configured",
      "configurations",
      "prepare",
      "following",
      "items",
      "license",
      "filesldap",
      "saml",
      "oauth",
      "configuration",
      "information",
      "including",
      "ldap",
      "certificate",
      "persons",
      "involved",
      "setup",
      "process",
      "administratorstenant",
      "image",
      "outlines",
      "perform",
      "administration.",
      "configure",
      "security",
      "related",
      "such",
      "idm",
      "signing",
      "key",
      "expiration",
      "period",
      "access",
      "token",
      "settings.upload",
      "files",
      "licenses",
      "pool.",
      "details",
      "see",
      "create",
      "edit",
      "pool.create",
      "customer",
      "customers.",
      "customer.create",
      "account",
      "accounts.",
      "account.create",
      "db",
      "type",
      "user",
      "serve",
      "administrator.",
      "user.",
      "general",
      "name",
      "case",
      "future",
      "changes",
      "administrator",
      "role.",
      "tenants",
      "created",
      "assign",
      "just",
      "created.",
      "tenant.assign",
      "capacity",
      "tenant.deploy",
      "tenant."
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Scaling",
    "content": "Your suite system has scalability. As a suite admin, you can scale up your system as needed. Overview The following gives an overview of the scalability of your suite system. Types of scaling Your suite system supports the following types of scaling: Suite deployment scaling: Before a version upgrade, you have the option to increase the existing deployment size. Suite capabilities scaling: You can scale a particular suite capability by configuring the Kubernetes controllers scaling controls, or adding or removing cluster nodes, or both. Kubernetes controllers scaling: All Kubernetes controllers have ways to offer horizontal scaling. Cluster node scaling: Because of scaling a Suite capability and thus the Kubernetes controllers it may become necessary to add, reconfigure, or remove a node. For more information, see Elasticity. Scalable pods Your suite system supports manual pod scaling. For a list of scalable pods, see the Scaling section in Suite enterprise readiness. Suite deployment ",
    "url": "scaling",
    "filename": "scaling",
    "headings": [
      "Overview",
      "Types of scaling",
      "Scalable pods",
      "Suite deployment scaling",
      "UD/UCMDB deployment scaling",
      "OO deployment scaling",
      "Smart analytics scaling",
      "Smart search content group scaling",
      "Scale out the DAH server",
      "DND scaling"
    ],
    "keywords": [
      "global.oo",
      "scaling",
      "overview",
      "types",
      "scalable",
      "pods",
      "suite",
      "deployment",
      "ud",
      "ucmdb",
      "oo",
      "smart",
      "analytics",
      "search",
      "content",
      "group",
      "scale",
      "out",
      "dah",
      "server",
      "dnd",
      "system",
      "scalability.",
      "admin",
      "needed.",
      "following",
      "gives",
      "scalability",
      "system.",
      "supports",
      "before",
      "version",
      "upgrade",
      "option",
      "increase",
      "existing",
      "size.",
      "capabilities",
      "particular",
      "capability",
      "configuring",
      "kubernetes",
      "controllers",
      "controls",
      "adding",
      "removing",
      "cluster",
      "nodes",
      "both.",
      "all",
      "ways",
      "offer",
      "horizontal",
      "scaling.",
      "node",
      "because",
      "thus",
      "become",
      "necessary",
      "add",
      "reconfigure",
      "remove",
      "node.",
      "information",
      "see",
      "elasticity.",
      "manual",
      "pod",
      "list",
      "section",
      "enterprise",
      "readiness.",
      "change",
      "sizing",
      "profile",
      "update.",
      "feature",
      "helpful",
      "initially",
      "started",
      "small",
      "limited",
      "number",
      "users",
      "now",
      "need",
      "larger",
      "onboard",
      "users.",
      "details",
      "relevant",
      "embedded",
      "managed",
      "size",
      "containerized",
      "ucmdb.",
      "during",
      "installation",
      "operations",
      "orchestration"
    ],
    "language": "en",
    "word_count": 100,
    "importance_score": 6.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "scaling",
    "contentLower": "your suite system has scalability. as a suite admin, you can scale up your system as needed. overview the following gives an overview of the scalability of your suite system. types of scaling your suite system supports the following types of scaling: suite deployment scaling: before a version upgrade, you have the option to increase the existing deployment size. suite capabilities scaling: you can scale a particular suite capability by configuring the kubernetes controllers scaling controls, or adding or removing cluster nodes, or both. kubernetes controllers scaling: all kubernetes controllers have ways to offer horizontal scaling. cluster node scaling: because of scaling a suite capability and thus the kubernetes controllers it may become necessary to add, reconfigure, or remove a node. for more information, see elasticity. scalable pods your suite system supports manual pod scaling. for a list of scalable pods, see the scaling section in suite enterprise readiness. suite deployment ",
    "keywordsLower": [
      "global.oo",
      "scaling",
      "overview",
      "types",
      "scalable",
      "pods",
      "suite",
      "deployment",
      "ud",
      "ucmdb",
      "oo",
      "smart",
      "analytics",
      "search",
      "content",
      "group",
      "scale",
      "out",
      "dah",
      "server",
      "dnd",
      "system",
      "scalability.",
      "admin",
      "needed.",
      "following",
      "gives",
      "scalability",
      "system.",
      "supports",
      "before",
      "version",
      "upgrade",
      "option",
      "increase",
      "existing",
      "size.",
      "capabilities",
      "particular",
      "capability",
      "configuring",
      "kubernetes",
      "controllers",
      "controls",
      "adding",
      "removing",
      "cluster",
      "nodes",
      "both.",
      "all",
      "ways",
      "offer",
      "horizontal",
      "scaling.",
      "node",
      "because",
      "thus",
      "become",
      "necessary",
      "add",
      "reconfigure",
      "remove",
      "node.",
      "information",
      "see",
      "elasticity.",
      "manual",
      "pod",
      "list",
      "section",
      "enterprise",
      "readiness.",
      "change",
      "sizing",
      "profile",
      "update.",
      "feature",
      "helpful",
      "initially",
      "started",
      "small",
      "limited",
      "number",
      "users",
      "now",
      "need",
      "larger",
      "onboard",
      "users.",
      "details",
      "relevant",
      "embedded",
      "managed",
      "size",
      "containerized",
      "ucmdb.",
      "during",
      "installation",
      "operations",
      "orchestration"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Smart virtual agent stop words",
    "content": "Stop words are words that are filtered out before processing of natural language data, smart virtual agent ignores these words when searching. The smart virtual agent stop words list can be found in: <global NFS root folder>/itsma-itsma-global/va/stopwords/stopwords.txt The out-of-the-box list includes stop words in English, French, and German, the users with root or sudo permission on the suite NFS server can edit the list. To add stop words in other languages, specify the language in [], and then add the stop words after the language name. For example, to add un and una in Spanish to the list, add them as below: [spanish] un una",
    "url": "stopwords",
    "filename": "stopwords",
    "headings": [],
    "keywords": [
      "stopwords.txt",
      "smart",
      "virtual",
      "agent",
      "stop",
      "words",
      "filtered",
      "out",
      "before",
      "processing",
      "natural",
      "language",
      "data",
      "ignores",
      "searching.",
      "list",
      "found",
      "itsma-itsma-global",
      "va",
      "stopwords",
      "out-of-the-box",
      "includes",
      "english",
      "french",
      "german",
      "users",
      "root",
      "sudo",
      "permission",
      "suite",
      "nfs",
      "server",
      "edit",
      "list.",
      "add",
      "languages",
      "specify",
      "after",
      "name.",
      "example",
      "un",
      "una",
      "spanish",
      "below"
    ],
    "language": "en",
    "word_count": 72,
    "importance_score": 3.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "smart virtual agent stop words",
    "contentLower": "stop words are words that are filtered out before processing of natural language data, smart virtual agent ignores these words when searching. the smart virtual agent stop words list can be found in: <global nfs root folder>/itsma-itsma-global/va/stopwords/stopwords.txt the out-of-the-box list includes stop words in english, french, and german, the users with root or sudo permission on the suite nfs server can edit the list. to add stop words in other languages, specify the language in [], and then add the stop words after the language name. for example, to add un and una in spanish to the list, add them as below: [spanish] un una",
    "keywordsLower": [
      "stopwords.txt",
      "smart",
      "virtual",
      "agent",
      "stop",
      "words",
      "filtered",
      "out",
      "before",
      "processing",
      "natural",
      "language",
      "data",
      "ignores",
      "searching.",
      "list",
      "found",
      "itsma-itsma-global",
      "va",
      "stopwords",
      "out-of-the-box",
      "includes",
      "english",
      "french",
      "german",
      "users",
      "root",
      "sudo",
      "permission",
      "suite",
      "nfs",
      "server",
      "edit",
      "list.",
      "add",
      "languages",
      "specify",
      "after",
      "name.",
      "example",
      "un",
      "una",
      "spanish",
      "below"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Replace the certificate for Service Management Automation",
    "content": "In a production environment, you are recommended to replace the out-of-box Nginx certificate for OMT and the suite with your own certificate, which must be signed by your corporate CA or a third-party CA. Before you replace the certificate, you need to prepare the certificate depending on whether it's single-level or multi-level. Once the certificate preparation is completed, you can replace the certificate for OMT and the suite. Private keys that are protected by a passphrase aren't supported. If your private key has a passphrase, use the openssl rsa command to remove the passphrase. For example: # openssl rsa -in tls_with_pass.key -out tls.key. If using Chrome, the server certificate must define the FQDN of the external access host as one of its Subject Alternative Names. Prepare your certificate Your organization may use a single-level or multi-level certificate. Prepare a single-level certificate Prepare a certificate file (for example, tls.crt) and a private key file (for example,",
    "url": "replacecertforsma",
    "filename": "replacecertforsma",
    "headings": [
      "Prepare your certificate",
      "Prepare a single-level certificate",
      "Prepare a multi-level certificate",
      "Replace the certificate",
      "Classic deployment",
      "Upload the certificate files",
      "Helm deployment",
      "Activate the certificate",
      "Additional step for cloud-based deployment",
      "AWS",
      "Azure (AKS)",
      "Import custom server certificate to Design and Deploy (DND)",
      "Replace the suite certificate in the UD/UCMDB deployment",
      "Related topics"
    ],
    "keywords": [
      "ca.crt",
      "file://<ca.crt",
      "server.key",
      "ca.cer",
      "secondCA.crt",
      "file://<server.crt",
      "1.0.0",
      "202x.xx",
      "smax.crt",
      "values.yaml",
      "tls.crt",
      "20xxxx00.xx",
      "https://<EXTERNAL_ACCESS_HOST>:5443",
      "tls.key",
      "xxx.tgz",
      "certificate.pfx",
      "thirdCA.crt",
      "server.crt",
      "file://<server.key",
      "tls_with_pass.key",
      "replace",
      "certificate",
      "service",
      "management",
      "automation",
      "prepare",
      "single-level",
      "multi-level",
      "classic",
      "deployment",
      "upload",
      "files",
      "helm",
      "activate",
      "additional",
      "step",
      "cloud-based",
      "aws",
      "azure",
      "aks",
      "import",
      "custom",
      "server",
      "design",
      "deploy",
      "dnd",
      "suite",
      "ud",
      "ucmdb",
      "related",
      "topics",
      "production",
      "environment",
      "recommended",
      "out-of-box",
      "nginx",
      "omt",
      "own",
      "signed",
      "corporate",
      "ca",
      "third-party",
      "ca.",
      "before",
      "need",
      "depending",
      "whether",
      "multi-level.",
      "once",
      "preparation",
      "completed",
      "suite.",
      "private",
      "keys",
      "protected",
      "passphrase",
      "aren",
      "supported.",
      "key",
      "openssl",
      "rsa",
      "command",
      "remove",
      "passphrase.",
      "example",
      "-in",
      "-out",
      "tls.key.",
      "chrome",
      "define",
      "fqdn",
      "external",
      "access",
      "host",
      "one",
      "subject",
      "alternative",
      "names.",
      "organization",
      "certificate."
    ],
    "language": "en",
    "word_count": 92,
    "importance_score": 5.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "replace the certificate for service management automation",
    "contentLower": "in a production environment, you are recommended to replace the out-of-box nginx certificate for omt and the suite with your own certificate, which must be signed by your corporate ca or a third-party ca. before you replace the certificate, you need to prepare the certificate depending on whether it's single-level or multi-level. once the certificate preparation is completed, you can replace the certificate for omt and the suite. private keys that are protected by a passphrase aren't supported. if your private key has a passphrase, use the openssl rsa command to remove the passphrase. for example: # openssl rsa -in tls_with_pass.key -out tls.key. if using chrome, the server certificate must define the fqdn of the external access host as one of its subject alternative names. prepare your certificate your organization may use a single-level or multi-level certificate. prepare a single-level certificate prepare a certificate file (for example, tls.crt) and a private key file (for example,",
    "keywordsLower": [
      "ca.crt",
      "file://<ca.crt",
      "server.key",
      "ca.cer",
      "secondca.crt",
      "file://<server.crt",
      "1.0.0",
      "202x.xx",
      "smax.crt",
      "values.yaml",
      "tls.crt",
      "20xxxx00.xx",
      "https://<external_access_host>:5443",
      "tls.key",
      "xxx.tgz",
      "certificate.pfx",
      "thirdca.crt",
      "server.crt",
      "file://<server.key",
      "tls_with_pass.key",
      "replace",
      "certificate",
      "service",
      "management",
      "automation",
      "prepare",
      "single-level",
      "multi-level",
      "classic",
      "deployment",
      "upload",
      "files",
      "helm",
      "activate",
      "additional",
      "step",
      "cloud-based",
      "aws",
      "azure",
      "aks",
      "import",
      "custom",
      "server",
      "design",
      "deploy",
      "dnd",
      "suite",
      "ud",
      "ucmdb",
      "related",
      "topics",
      "production",
      "environment",
      "recommended",
      "out-of-box",
      "nginx",
      "omt",
      "own",
      "signed",
      "corporate",
      "ca",
      "third-party",
      "ca.",
      "before",
      "need",
      "depending",
      "whether",
      "multi-level.",
      "once",
      "preparation",
      "completed",
      "suite.",
      "private",
      "keys",
      "protected",
      "passphrase",
      "aren",
      "supported.",
      "key",
      "openssl",
      "rsa",
      "command",
      "remove",
      "passphrase.",
      "example",
      "-in",
      "-out",
      "tls.key.",
      "chrome",
      "define",
      "fqdn",
      "external",
      "access",
      "host",
      "one",
      "subject",
      "alternative",
      "names.",
      "organization",
      "certificate."
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Replace certificate for Audit Service",
    "content": "In a production environment, you are recommended to replace the out-of-box certificate for Audit Service with your own certificate, signed by your corporate CA or a third-party CA. To do this, you must prepare the certificate based on whether your setup uses a single-level or multi-level certificate chain. Once preparation is complete, you proceed to replace the certificate for the Audit Service. Private keys protected by a passphrase are not supported. If your private key includes a passphrase, use the openssl rsa command to remove it. For example: # openssl rsa -in tls_with_pass.key -out tls.key. If you are using Chrome, ensure that the server certificate defines the FQDN of the external access host in one of its Subject Alternative Names. Prepare your certificate Prepare a single-level or multi-level certificate based on your organization's requirements. Prepare single-level certificate Prepare a certificate file (for example, tls.crt) and a private key file (for example, tls.key) i",
    "url": "replacecertforauditservice",
    "filename": "replacecertforauditservice",
    "headings": [
      "Prepare your certificate",
      "Prepare single-level certificate",
      "Prepare multi-level certificate",
      "Replace the certificate",
      "Helm deployment",
      "Verify Audit service installation"
    ],
    "keywords": [
      "server.crt",
      "secondCA.crt",
      "tls.key",
      "tls_with_pass.key",
      "global.tls",
      "values.yaml",
      "tls.crt",
      "thirdCA.crt",
      "replace",
      "certificate",
      "audit",
      "service",
      "prepare",
      "single-level",
      "multi-level",
      "helm",
      "deployment",
      "verify",
      "installation",
      "production",
      "environment",
      "recommended",
      "out-of-box",
      "own",
      "signed",
      "corporate",
      "ca",
      "third-party",
      "ca.",
      "based",
      "whether",
      "setup",
      "uses",
      "chain.",
      "once",
      "preparation",
      "complete",
      "proceed",
      "service.",
      "private",
      "keys",
      "protected",
      "passphrase",
      "supported.",
      "key",
      "includes",
      "openssl",
      "rsa",
      "command",
      "remove",
      "it.",
      "example",
      "-in",
      "-out",
      "tls.key.",
      "chrome",
      "ensure",
      "server",
      "defines",
      "fqdn",
      "external",
      "access",
      "host",
      "one",
      "subject",
      "alternative",
      "names.",
      "organization",
      "requirements.",
      "file",
      "pem",
      "format.",
      "recommend",
      "root",
      "sign",
      "certificate.",
      "additionally",
      "cn",
      "value",
      "name",
      "suite.",
      "following",
      "figure",
      "shows",
      "content",
      "instructions",
      "three-level",
      "example.",
      "since",
      "keep",
      "chain",
      "shown",
      "figure.",
      "requires",
      "import",
      "certificates",
      "end",
      "user",
      "browser.",
      "trusted"
    ],
    "language": "en",
    "word_count": 94,
    "importance_score": 6.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "replace certificate for audit service",
    "contentLower": "in a production environment, you are recommended to replace the out-of-box certificate for audit service with your own certificate, signed by your corporate ca or a third-party ca. to do this, you must prepare the certificate based on whether your setup uses a single-level or multi-level certificate chain. once preparation is complete, you proceed to replace the certificate for the audit service. private keys protected by a passphrase are not supported. if your private key includes a passphrase, use the openssl rsa command to remove it. for example: # openssl rsa -in tls_with_pass.key -out tls.key. if you are using chrome, ensure that the server certificate defines the fqdn of the external access host in one of its subject alternative names. prepare your certificate prepare a single-level or multi-level certificate based on your organization's requirements. prepare single-level certificate prepare a certificate file (for example, tls.crt) and a private key file (for example, tls.key) i",
    "keywordsLower": [
      "server.crt",
      "secondca.crt",
      "tls.key",
      "tls_with_pass.key",
      "global.tls",
      "values.yaml",
      "tls.crt",
      "thirdca.crt",
      "replace",
      "certificate",
      "audit",
      "service",
      "prepare",
      "single-level",
      "multi-level",
      "helm",
      "deployment",
      "verify",
      "installation",
      "production",
      "environment",
      "recommended",
      "out-of-box",
      "own",
      "signed",
      "corporate",
      "ca",
      "third-party",
      "ca.",
      "based",
      "whether",
      "setup",
      "uses",
      "chain.",
      "once",
      "preparation",
      "complete",
      "proceed",
      "service.",
      "private",
      "keys",
      "protected",
      "passphrase",
      "supported.",
      "key",
      "includes",
      "openssl",
      "rsa",
      "command",
      "remove",
      "it.",
      "example",
      "-in",
      "-out",
      "tls.key.",
      "chrome",
      "ensure",
      "server",
      "defines",
      "fqdn",
      "external",
      "access",
      "host",
      "one",
      "subject",
      "alternative",
      "names.",
      "organization",
      "requirements.",
      "file",
      "pem",
      "format.",
      "recommend",
      "root",
      "sign",
      "certificate.",
      "additionally",
      "cn",
      "value",
      "name",
      "suite.",
      "following",
      "figure",
      "shows",
      "content",
      "instructions",
      "three-level",
      "example.",
      "since",
      "keep",
      "chain",
      "shown",
      "figure.",
      "requires",
      "import",
      "certificates",
      "end",
      "user",
      "browser.",
      "trusted"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Restart the suite",
    "content": "This procedure restarts the pods of the suite only. It doesn't restart OMT or restart the VM hosts. To restart the suite, perform the following steps: In a managed Kubernetes environment, replace $CDF_HOME with your OMT package path, for example, OMT_External_K8s_2x.x-xxx. Navigate to the $CDF_HOME/scripts directory, and run the following command to stop the suite pods in the suite namespace: ./cdfctl.sh runlevel set -l DOWN -n <namespace> Where: <namespace> is the suite namespace (for example: itsma-pxh5s), and the last character in runlevel set -l is a lowercase letter L. Wait for 10 to 15 minutes to allow the suite pods to be stopped. You can run the following command to watch the suite pod status: watch kubectl get pods -n <namespace> This command will refresh the display of the suite pod status every two seconds. All of the suite pods must be stopped except the following ones (which must keep running): itom-ingress-controller-xxxxx, and itom-throttling-controller-xxxxx. Navigate t",
    "url": "restartsmasuite",
    "filename": "restartsmasuite",
    "headings": [],
    "keywords": [
      "cdfctl.sh",
      "restart",
      "suite",
      "procedure",
      "restarts",
      "pods",
      "only.",
      "doesn",
      "omt",
      "vm",
      "hosts.",
      "perform",
      "following",
      "steps",
      "managed",
      "kubernetes",
      "environment",
      "replace",
      "package",
      "path",
      "example",
      "navigate",
      "scripts",
      "directory",
      "run",
      "command",
      "stop",
      "namespace",
      "runlevel",
      "set",
      "-l",
      "-n",
      "itsma-pxh5s",
      "last",
      "character",
      "lowercase",
      "letter",
      "l.",
      "wait",
      "10",
      "15",
      "minutes",
      "allow",
      "stopped.",
      "watch",
      "pod",
      "status",
      "kubectl",
      "get",
      "refresh",
      "display",
      "every",
      "two",
      "seconds.",
      "all",
      "stopped",
      "except",
      "ones",
      "keep",
      "running",
      "itom-ingress-controller-xxxxx",
      "itom-throttling-controller-xxxxx.",
      "start",
      "until",
      "restarted."
    ],
    "language": "en",
    "word_count": 100,
    "importance_score": 3.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "restart the suite",
    "contentLower": "this procedure restarts the pods of the suite only. it doesn't restart omt or restart the vm hosts. to restart the suite, perform the following steps: in a managed kubernetes environment, replace $cdf_home with your omt package path, for example, omt_external_k8s_2x.x-xxx. navigate to the $cdf_home/scripts directory, and run the following command to stop the suite pods in the suite namespace: ./cdfctl.sh runlevel set -l down -n <namespace> where: <namespace> is the suite namespace (for example: itsma-pxh5s), and the last character in runlevel set -l is a lowercase letter l. wait for 10 to 15 minutes to allow the suite pods to be stopped. you can run the following command to watch the suite pod status: watch kubectl get pods -n <namespace> this command will refresh the display of the suite pod status every two seconds. all of the suite pods must be stopped except the following ones (which must keep running): itom-ingress-controller-xxxxx, and itom-throttling-controller-xxxxx. navigate t",
    "keywordsLower": [
      "cdfctl.sh",
      "restart",
      "suite",
      "procedure",
      "restarts",
      "pods",
      "only.",
      "doesn",
      "omt",
      "vm",
      "hosts.",
      "perform",
      "following",
      "steps",
      "managed",
      "kubernetes",
      "environment",
      "replace",
      "package",
      "path",
      "example",
      "navigate",
      "scripts",
      "directory",
      "run",
      "command",
      "stop",
      "namespace",
      "runlevel",
      "set",
      "-l",
      "-n",
      "itsma-pxh5s",
      "last",
      "character",
      "lowercase",
      "letter",
      "l.",
      "wait",
      "10",
      "15",
      "minutes",
      "allow",
      "stopped.",
      "watch",
      "pod",
      "status",
      "kubectl",
      "get",
      "refresh",
      "display",
      "every",
      "two",
      "seconds.",
      "all",
      "stopped",
      "except",
      "ones",
      "keep",
      "running",
      "itom-ingress-controller-xxxxx",
      "itom-throttling-controller-xxxxx.",
      "start",
      "until",
      "restarted."
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Restart the cluster hosts",
    "content": "To restart the cluster hosts, perform the following steps: Note: replace <namespace> in the following steps with your suite namespace. Log in to one of the control plane nodes as root or a sudo user. Navigate to the $CDF_HOME/scripts directory, and then stop the suite pods in the suite namespace: cd $CDF_HOME/scripts ./cdfctl.sh runlevel set -l DOWN -n <namespace> Note: The last character in runlevel set -l is lowercase letter L. You can use the global option -f to show more logs during the stop process. Run the following commands on each worker node. When you have finished, run the same commands on each control plane node: cd $CDF_HOME/bin ./kube-stop.sh Reboot all of the control plane node and worker node VMs. Run the following commands on a control plane node to check the cluster status: cd $CDF_HOME/bin ./kube-status.sh If all of the cluster nodes are running, skip this step; otherwise, run the following commands on each control plane node. When you have finished, run the same comm",
    "url": "restartsmacluster",
    "filename": "restartsmacluster",
    "headings": [],
    "keywords": [
      "cdfctl.sh",
      "start.sh",
      "stop.sh",
      "status.sh",
      "restart",
      "cluster",
      "hosts",
      "perform",
      "following",
      "steps",
      "note",
      "replace",
      "suite",
      "namespace.",
      "log",
      "one",
      "control",
      "plane",
      "nodes",
      "root",
      "sudo",
      "user.",
      "navigate",
      "scripts",
      "directory",
      "stop",
      "pods",
      "namespace",
      "cd",
      "runlevel",
      "set",
      "-l",
      "-n",
      "last",
      "character",
      "lowercase",
      "letter",
      "l.",
      "global",
      "option",
      "-f",
      "show",
      "logs",
      "during",
      "process.",
      "run",
      "commands",
      "worker",
      "node.",
      "finished",
      "same",
      "node",
      "bin",
      "kube-stop.sh",
      "reboot",
      "all",
      "vms.",
      "check",
      "status",
      "kube-status.sh",
      "running",
      "skip",
      "step",
      "otherwise",
      "kube-start.sh",
      "command",
      "start",
      "restarted",
      "script",
      "itom-ingress-controller",
      "demo-daemonset",
      "itom-throttling-controller",
      "need",
      "manually",
      "follows",
      "obtain",
      "pod",
      "names",
      "kubectl",
      "get",
      "grep",
      "delete",
      "name",
      "obtained",
      "previous",
      "step.",
      "example",
      "demo-daemonset-b752l",
      "itsma1"
    ],
    "language": "en",
    "word_count": 111,
    "importance_score": 3.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "restart the cluster hosts",
    "contentLower": "to restart the cluster hosts, perform the following steps: note: replace <namespace> in the following steps with your suite namespace. log in to one of the control plane nodes as root or a sudo user. navigate to the $cdf_home/scripts directory, and then stop the suite pods in the suite namespace: cd $cdf_home/scripts ./cdfctl.sh runlevel set -l down -n <namespace> note: the last character in runlevel set -l is lowercase letter l. you can use the global option -f to show more logs during the stop process. run the following commands on each worker node. when you have finished, run the same commands on each control plane node: cd $cdf_home/bin ./kube-stop.sh reboot all of the control plane node and worker node vms. run the following commands on a control plane node to check the cluster status: cd $cdf_home/bin ./kube-status.sh if all of the cluster nodes are running, skip this step; otherwise, run the following commands on each control plane node. when you have finished, run the same comm",
    "keywordsLower": [
      "cdfctl.sh",
      "start.sh",
      "stop.sh",
      "status.sh",
      "restart",
      "cluster",
      "hosts",
      "perform",
      "following",
      "steps",
      "note",
      "replace",
      "suite",
      "namespace.",
      "log",
      "one",
      "control",
      "plane",
      "nodes",
      "root",
      "sudo",
      "user.",
      "navigate",
      "scripts",
      "directory",
      "stop",
      "pods",
      "namespace",
      "cd",
      "runlevel",
      "set",
      "-l",
      "-n",
      "last",
      "character",
      "lowercase",
      "letter",
      "l.",
      "global",
      "option",
      "-f",
      "show",
      "logs",
      "during",
      "process.",
      "run",
      "commands",
      "worker",
      "node.",
      "finished",
      "same",
      "node",
      "bin",
      "kube-stop.sh",
      "reboot",
      "all",
      "vms.",
      "check",
      "status",
      "kube-status.sh",
      "running",
      "skip",
      "step",
      "otherwise",
      "kube-start.sh",
      "command",
      "start",
      "restarted",
      "script",
      "itom-ingress-controller",
      "demo-daemonset",
      "itom-throttling-controller",
      "need",
      "manually",
      "follows",
      "obtain",
      "pod",
      "names",
      "kubectl",
      "get",
      "grep",
      "delete",
      "name",
      "obtained",
      "previous",
      "step.",
      "example",
      "demo-daemonset-b752l",
      "itsma1"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Shut down the suite environment",
    "content": "To shut down the suite environment, you must stop the suite pods and then the OPTIC Management Toolkit (OMT), and finally power off the cluster nodes. Log in to one of the control plane nodes as root or a sudo user. Navigate to the $CDF_HOME/scripts directory, and run the following command to stop the suite pods in the suite namespace: ./cdfctl.sh runlevel set -l DOWN -n <namespace> Note: The last character in runlevel set -l is lowercase letter L. You can use the global option -f to show more logs during the stop process. Run the following commands on each worker node. When you have finished, run the same commands on each control plane node: cd $CDF_HOME/bin ./kube-stop.sh Power off the cluster nodes. Caution: A graceful shutdown as described earlier is always strongly recommended. A hard shutdown may cause data integrity issues and hence the corresponding services (such as RabbitMQ) may not be able to start successfully when you try to restart the system. Related topics RabbitMQ isn'",
    "url": "shutdownsuitesystem",
    "filename": "shutdownsuitesystem",
    "headings": [
      "Related topics"
    ],
    "keywords": [
      "cdfctl.sh",
      "stop.sh",
      "shut",
      "suite",
      "environment",
      "related",
      "topics",
      "stop",
      "pods",
      "optic",
      "management",
      "toolkit",
      "omt",
      "finally",
      "power",
      "off",
      "cluster",
      "nodes.",
      "log",
      "one",
      "control",
      "plane",
      "nodes",
      "root",
      "sudo",
      "user.",
      "navigate",
      "scripts",
      "directory",
      "run",
      "following",
      "command",
      "namespace",
      "runlevel",
      "set",
      "-l",
      "-n",
      "note",
      "last",
      "character",
      "lowercase",
      "letter",
      "l.",
      "global",
      "option",
      "-f",
      "show",
      "logs",
      "during",
      "process.",
      "commands",
      "worker",
      "node.",
      "finished",
      "same",
      "node",
      "cd",
      "bin",
      "kube-stop.sh",
      "caution",
      "graceful",
      "shutdown",
      "described",
      "earlier",
      "always",
      "strongly",
      "recommended.",
      "hard",
      "cause",
      "data",
      "integrity",
      "issues",
      "hence",
      "corresponding",
      "services",
      "such",
      "rabbitmq",
      "able",
      "start",
      "successfully",
      "try",
      "restart",
      "system.",
      "isn",
      "ready"
    ],
    "language": "en",
    "word_count": 109,
    "importance_score": 3.5,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "shut down the suite environment",
    "contentLower": "to shut down the suite environment, you must stop the suite pods and then the optic management toolkit (omt), and finally power off the cluster nodes. log in to one of the control plane nodes as root or a sudo user. navigate to the $cdf_home/scripts directory, and run the following command to stop the suite pods in the suite namespace: ./cdfctl.sh runlevel set -l down -n <namespace> note: the last character in runlevel set -l is lowercase letter l. you can use the global option -f to show more logs during the stop process. run the following commands on each worker node. when you have finished, run the same commands on each control plane node: cd $cdf_home/bin ./kube-stop.sh power off the cluster nodes. caution: a graceful shutdown as described earlier is always strongly recommended. a hard shutdown may cause data integrity issues and hence the corresponding services (such as rabbitmq) may not be able to start successfully when you try to restart the system. related topics rabbitmq isn'",
    "keywordsLower": [
      "cdfctl.sh",
      "stop.sh",
      "shut",
      "suite",
      "environment",
      "related",
      "topics",
      "stop",
      "pods",
      "optic",
      "management",
      "toolkit",
      "omt",
      "finally",
      "power",
      "off",
      "cluster",
      "nodes.",
      "log",
      "one",
      "control",
      "plane",
      "nodes",
      "root",
      "sudo",
      "user.",
      "navigate",
      "scripts",
      "directory",
      "run",
      "following",
      "command",
      "namespace",
      "runlevel",
      "set",
      "-l",
      "-n",
      "note",
      "last",
      "character",
      "lowercase",
      "letter",
      "l.",
      "global",
      "option",
      "-f",
      "show",
      "logs",
      "during",
      "process.",
      "commands",
      "worker",
      "node.",
      "finished",
      "same",
      "node",
      "cd",
      "bin",
      "kube-stop.sh",
      "caution",
      "graceful",
      "shutdown",
      "described",
      "earlier",
      "always",
      "strongly",
      "recommended.",
      "hard",
      "cause",
      "data",
      "integrity",
      "issues",
      "hence",
      "corresponding",
      "services",
      "such",
      "rabbitmq",
      "able",
      "start",
      "successfully",
      "try",
      "restart",
      "system.",
      "isn",
      "ready"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Take a snapshot of the suite",
    "content": "As a system administrator, you may need to take a snapshot of the SMA suite before you perform some system level tasks such as suite backup or upgrade. To take a snapshot of your suite, follow these steps: Shut down the SMA suite by running the following commands on a control plane node: cd $CDF_HOME/scripts ./cdfctl.sh runlevel set -l DOWN -n <namespace> Where: <namespace> is the suite namespace, and the runlevel setting uses a lowercase letter L. Make a note of the suite namespace as you will need it when restarting the suite later. You can use the global option -f to show more logs during the stop process. Run the following script on worker nodes: cd $CDF_HOME/bin ./kube-stop.sh Run the following script on the control plane nodes: cd $CDF_HOME/bin ./kube-stop.sh Shut down the control plane and worker nodes. Take a snapshot for all control plane and worker nodes. Start the control plane and worker nodes. Run the following commands on all control plane nodes concurrently. When you hav",
    "url": "takesuitesnapshot",
    "filename": "takesuitesnapshot",
    "headings": [],
    "keywords": [
      "cdfctl.sh",
      "start.sh",
      "stop.sh",
      "take",
      "snapshot",
      "suite",
      "system",
      "administrator",
      "need",
      "sma",
      "before",
      "perform",
      "level",
      "tasks",
      "such",
      "backup",
      "upgrade.",
      "follow",
      "steps",
      "shut",
      "running",
      "following",
      "commands",
      "control",
      "plane",
      "node",
      "cd",
      "scripts",
      "runlevel",
      "set",
      "-l",
      "-n",
      "namespace",
      "setting",
      "uses",
      "lowercase",
      "letter",
      "l.",
      "make",
      "note",
      "restarting",
      "later.",
      "global",
      "option",
      "-f",
      "show",
      "logs",
      "during",
      "stop",
      "process.",
      "run",
      "script",
      "worker",
      "nodes",
      "bin",
      "kube-stop.sh",
      "nodes.",
      "all",
      "start",
      "concurrently.",
      "finished",
      "starting",
      "same",
      "concurrently",
      "kube-start.sh",
      "namespace."
    ],
    "language": "en",
    "word_count": 110,
    "importance_score": 2.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "take a snapshot of the suite",
    "contentLower": "as a system administrator, you may need to take a snapshot of the sma suite before you perform some system level tasks such as suite backup or upgrade. to take a snapshot of your suite, follow these steps: shut down the sma suite by running the following commands on a control plane node: cd $cdf_home/scripts ./cdfctl.sh runlevel set -l down -n <namespace> where: <namespace> is the suite namespace, and the runlevel setting uses a lowercase letter l. make a note of the suite namespace as you will need it when restarting the suite later. you can use the global option -f to show more logs during the stop process. run the following script on worker nodes: cd $cdf_home/bin ./kube-stop.sh run the following script on the control plane nodes: cd $cdf_home/bin ./kube-stop.sh shut down the control plane and worker nodes. take a snapshot for all control plane and worker nodes. start the control plane and worker nodes. run the following commands on all control plane nodes concurrently. when you hav",
    "keywordsLower": [
      "cdfctl.sh",
      "start.sh",
      "stop.sh",
      "take",
      "snapshot",
      "suite",
      "system",
      "administrator",
      "need",
      "sma",
      "before",
      "perform",
      "level",
      "tasks",
      "such",
      "backup",
      "upgrade.",
      "follow",
      "steps",
      "shut",
      "running",
      "following",
      "commands",
      "control",
      "plane",
      "node",
      "cd",
      "scripts",
      "runlevel",
      "set",
      "-l",
      "-n",
      "namespace",
      "setting",
      "uses",
      "lowercase",
      "letter",
      "l.",
      "make",
      "note",
      "restarting",
      "later.",
      "global",
      "option",
      "-f",
      "show",
      "logs",
      "during",
      "stop",
      "process.",
      "run",
      "script",
      "worker",
      "nodes",
      "bin",
      "kube-stop.sh",
      "nodes.",
      "all",
      "start",
      "concurrently.",
      "finished",
      "starting",
      "same",
      "concurrently",
      "kube-start.sh",
      "namespace."
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Set up Velero",
    "content": "You need to use Velero to back up and restore your Kubernetes configurations and cluster. Velero comes pre-installed with OMT, refer to the OMT support matrix to see which version of velero ships with your OMT. If your OMT doesn't include Velero, you will first need to set up Velero according to your deployment. This topic describes how to set up Velero for different deployments.Set up Velero for Managed KubernetesUse the steps to set up Velero for managed Kubernetes.PreparationRefer to the tasks according to your cloud platform.Preparation steps for AWSCreate S3 bucket to store the backup data. Make sure the bucket region is the same as that of your Kubernetes cluster. If you already have one, skip this step.Set permission for Velero and use Option 1: Set permission with an IAM user. Preparation steps for AzureRun the command on the bastion node: az loginCreate an Azure storage account and blob container to store the backup data. Make sure the subscription and location are the same as",
    "url": "installveleromanagedk8s",
    "filename": "installveleromanagedk8s",
    "headings": [
      "Set up Velero for Managed Kubernetes",
      "Preparation",
      "Preparation steps for AWS",
      "Preparation steps for Azure",
      "Preparation steps for GCP",
      "Preparation steps for OpenShift",
      "Enable Kubernetes backup capability",
      "Upload Velero image to the registry",
      "Enable the capability with installation",
      "Enable the capability manually after installation",
      "Set up Velero on Embedded Kubernetes",
      "Enable Kubernetes backup capability",
      "Disable Kubernetes backup capability",
      "Get MinIO backups after upgrade to CloudServer"
    ],
    "keywords": [
      "ca.crt",
      "step.Get",
      "step.Set",
      "v1.8",
      "ca.key",
      "deployments.Set",
      "downloadimages.sh",
      "1.7.0",
      "disks.Set",
      "deployment.tls",
      "cert.key",
      "capability.Run",
      "projects.get",
      "example.org",
      "securityContext.user",
      "https://github.com/vmware-tanzu/velero/blob/main/examples/minio/00-minio-deployment.yamlFor",
      "https://minio-svc.minio:9000.NoteIf",
      "set.json",
      "uploadimages.sh",
      "gcr.io",
      "bucket.For",
      "https://velero.io/docs/v1.8/contributions/minio/#set-up-server",
      "velero.io",
      "gserviceaccount.com",
      "https://github.com/minio/minio/tree/master/docs/tls/kubernetes.Enable",
      "kubernetes.io",
      "CloudServer.If",
      "cert.crt",
      "Velero.Make",
      "disks.get",
      "https://velero.io/docs/v1.8/supported-providers/#s3-compatible-object-store-providers",
      "zones.get",
      "github.com",
      "snapshots.get",
      "cdf.sh",
      "ca.srl",
      "set",
      "velero",
      "managed",
      "kubernetes",
      "preparation",
      "steps",
      "aws",
      "azure",
      "gcp",
      "openshift",
      "enable",
      "backup",
      "capability",
      "upload",
      "image",
      "registry",
      "installation",
      "manually",
      "after",
      "embedded",
      "disable",
      "get",
      "minio",
      "backups",
      "upgrade",
      "cloudserver",
      "need",
      "back",
      "restore",
      "configurations",
      "cluster.",
      "comes",
      "pre-installed",
      "omt",
      "refer",
      "support",
      "matrix",
      "see",
      "version",
      "ships",
      "omt.",
      "doesn",
      "include",
      "first",
      "according",
      "deployment.",
      "topic",
      "describes",
      "different",
      "kubernetesuse",
      "kubernetes.preparationrefer",
      "tasks",
      "cloud",
      "platform.preparation",
      "awscreate",
      "s3",
      "bucket",
      "store",
      "data.",
      "make",
      "sure",
      "region",
      "same",
      "already"
    ],
    "language": "en",
    "word_count": 98,
    "importance_score": 6.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "set up velero",
    "contentLower": "you need to use velero to back up and restore your kubernetes configurations and cluster. velero comes pre-installed with omt, refer to the omt support matrix to see which version of velero ships with your omt. if your omt doesn't include velero, you will first need to set up velero according to your deployment. this topic describes how to set up velero for different deployments.set up velero for managed kubernetesuse the steps to set up velero for managed kubernetes.preparationrefer to the tasks according to your cloud platform.preparation steps for awscreate s3 bucket to store the backup data. make sure the bucket region is the same as that of your kubernetes cluster. if you already have one, skip this step.set permission for velero and use option 1: set permission with an iam user. preparation steps for azurerun the command on the bastion node: az logincreate an azure storage account and blob container to store the backup data. make sure the subscription and location are the same as",
    "keywordsLower": [
      "ca.crt",
      "step.get",
      "step.set",
      "v1.8",
      "ca.key",
      "deployments.set",
      "downloadimages.sh",
      "1.7.0",
      "disks.set",
      "deployment.tls",
      "cert.key",
      "capability.run",
      "projects.get",
      "example.org",
      "securitycontext.user",
      "https://github.com/vmware-tanzu/velero/blob/main/examples/minio/00-minio-deployment.yamlfor",
      "https://minio-svc.minio:9000.noteif",
      "set.json",
      "uploadimages.sh",
      "gcr.io",
      "bucket.for",
      "https://velero.io/docs/v1.8/contributions/minio/#set-up-server",
      "velero.io",
      "gserviceaccount.com",
      "https://github.com/minio/minio/tree/master/docs/tls/kubernetes.enable",
      "kubernetes.io",
      "cloudserver.if",
      "cert.crt",
      "velero.make",
      "disks.get",
      "https://velero.io/docs/v1.8/supported-providers/#s3-compatible-object-store-providers",
      "zones.get",
      "github.com",
      "snapshots.get",
      "cdf.sh",
      "ca.srl",
      "set",
      "velero",
      "managed",
      "kubernetes",
      "preparation",
      "steps",
      "aws",
      "azure",
      "gcp",
      "openshift",
      "enable",
      "backup",
      "capability",
      "upload",
      "image",
      "registry",
      "installation",
      "manually",
      "after",
      "embedded",
      "disable",
      "get",
      "minio",
      "backups",
      "upgrade",
      "cloudserver",
      "need",
      "back",
      "restore",
      "configurations",
      "cluster.",
      "comes",
      "pre-installed",
      "omt",
      "refer",
      "support",
      "matrix",
      "see",
      "version",
      "ships",
      "omt.",
      "doesn",
      "include",
      "first",
      "according",
      "deployment.",
      "topic",
      "describes",
      "different",
      "kubernetesuse",
      "kubernetes.preparationrefer",
      "tasks",
      "cloud",
      "platform.preparation",
      "awscreate",
      "s3",
      "bucket",
      "store",
      "data.",
      "make",
      "sure",
      "region",
      "same",
      "already"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "SMA Backup Procedure",
    "content": "This topic describes how to back up the suite data.Verify the environment before making a backupTo ensure a healthy backup, verify the environment before making a backup:Log in to the control plane node or bastion node and run the following command to make sure all the suite pods are ready: kubectl get pod --all-namespaces|grep -v 1/1|grep -v 2/2|grep -v 3/3|grep -v 4/4|grep -v Completed This command returns a list of abnormal pods. When it returns no result, all the suite pods are ready. If any pods can't run, see Troubleshoot installation.Clear your browser cache.Verify that you can log in to the Suite Administration interface: https://<external_access_host>/bo as the suite-admin user.Verify that you can log in to the OMT Management Portal: https://<external_access_host>:5443 as the admin user.Next, choose the backup solution based on your deployment platforms.For optimal security, always keep your backup files in a secure location.Scheduled routine backupOMT uses Velero to automatic",
    "url": "smabackupprocedure",
    "filename": "smabackupprocedure",
    "headings": [
      "Verify the environment before making a backup",
      "Scheduled routine backup",
      "Update scheduled backup",
      "Back up the suite on AWS​​​​​",
      "Back up the Kubernetes configurations",
      "Back up EFS and RDS",
      "Back up the suite on Azure",
      "Back up the Kubernetes configurations",
      "Back up the storage",
      "Back up the database",
      "Back up the suite on GCP",
      "Back up the Kubernetes configurations",
      "Back up the storage",
      "Back up the database",
      "Back up the suite on OpenShift",
      "Back up the Kubernetes configurations",
      "Back up the storage",
      "Back up the databases",
      "Back up the suite on embedded kubernetes",
      "Back up Velero master key"
    ],
    "keywords": [
      "files.Run",
      "environment.The",
      "assignments.Take",
      "https://<external_access_host>/bo",
      "capability.The",
      "requirements.For",
      "later.Back",
      "needs.The",
      "https://<external_access_host>:5443",
      "reachable.helm",
      "plan.Back",
      "cloudserver.Back",
      "plan.You",
      "field.Back",
      "Velero.Use",
      "Velero.Back",
      "Backup.RDS",
      "rules.You",
      "OpenShift.Back",
      "disaster.Back",
      "velero.io",
      "requirements.Back",
      "documentation.Back",
      "CloudServer.If",
      "backups.Back",
      "key.Be",
      "backup.For",
      "Velero.EFS",
      "place.Back",
      "backup.all",
      "Server.Back",
      "solution.If",
      "user.Next",
      "bucket.Back",
      "role.Back",
      "platforms.For",
      "sma",
      "backup",
      "procedure",
      "verify",
      "environment",
      "before",
      "making",
      "scheduled",
      "routine",
      "update",
      "back",
      "suite",
      "aws",
      "kubernetes",
      "configurations",
      "efs",
      "rds",
      "azure",
      "storage",
      "database",
      "gcp",
      "openshift",
      "databases",
      "embedded",
      "velero",
      "master",
      "key",
      "nfs",
      "topic",
      "describes",
      "data.verify",
      "backupto",
      "ensure",
      "healthy",
      "log",
      "control",
      "plane",
      "node",
      "bastion",
      "run",
      "following",
      "command",
      "make",
      "sure",
      "all",
      "pods",
      "ready",
      "kubectl",
      "get",
      "pod",
      "--all-namespaces",
      "grep",
      "-v",
      "completed",
      "returns",
      "list",
      "abnormal",
      "pods.",
      "result",
      "ready.",
      "any",
      "see",
      "troubleshoot",
      "installation.clear"
    ],
    "language": "en",
    "word_count": 113,
    "importance_score": 6.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "sma backup procedure",
    "contentLower": "this topic describes how to back up the suite data.verify the environment before making a backupto ensure a healthy backup, verify the environment before making a backup:log in to the control plane node or bastion node and run the following command to make sure all the suite pods are ready: kubectl get pod --all-namespaces|grep -v 1/1|grep -v 2/2|grep -v 3/3|grep -v 4/4|grep -v completed this command returns a list of abnormal pods. when it returns no result, all the suite pods are ready. if any pods can't run, see troubleshoot installation.clear your browser cache.verify that you can log in to the suite administration interface: https://<external_access_host>/bo as the suite-admin user.verify that you can log in to the omt management portal: https://<external_access_host>:5443 as the admin user.next, choose the backup solution based on your deployment platforms.for optimal security, always keep your backup files in a secure location.scheduled routine backupomt uses velero to automatic",
    "keywordsLower": [
      "files.run",
      "environment.the",
      "assignments.take",
      "https://<external_access_host>/bo",
      "capability.the",
      "requirements.for",
      "later.back",
      "needs.the",
      "https://<external_access_host>:5443",
      "reachable.helm",
      "plan.back",
      "cloudserver.back",
      "plan.you",
      "field.back",
      "velero.use",
      "velero.back",
      "backup.rds",
      "rules.you",
      "openshift.back",
      "disaster.back",
      "velero.io",
      "requirements.back",
      "documentation.back",
      "cloudserver.if",
      "backups.back",
      "key.be",
      "backup.for",
      "velero.efs",
      "place.back",
      "backup.all",
      "server.back",
      "solution.if",
      "user.next",
      "bucket.back",
      "role.back",
      "platforms.for",
      "sma",
      "backup",
      "procedure",
      "verify",
      "environment",
      "before",
      "making",
      "scheduled",
      "routine",
      "update",
      "back",
      "suite",
      "aws",
      "kubernetes",
      "configurations",
      "efs",
      "rds",
      "azure",
      "storage",
      "database",
      "gcp",
      "openshift",
      "databases",
      "embedded",
      "velero",
      "master",
      "key",
      "nfs",
      "topic",
      "describes",
      "data.verify",
      "backupto",
      "ensure",
      "healthy",
      "log",
      "control",
      "plane",
      "node",
      "bastion",
      "run",
      "following",
      "command",
      "make",
      "sure",
      "all",
      "pods",
      "ready",
      "kubectl",
      "get",
      "pod",
      "--all-namespaces",
      "grep",
      "-v",
      "completed",
      "returns",
      "list",
      "abnormal",
      "pods.",
      "result",
      "ready.",
      "any",
      "see",
      "troubleshoot",
      "installation.clear"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Self-managed PostgreSQL backup and restore",
    "content": "This topic provides instructions on how to back up the data of a self-managed PostgreSQL instance, using base backups and continuous archives, which you can perform at runtime without service interruption. To keep data consistency among all databases of the suite, instance-level backup is recommended. If your databases are running on different PostgreSQL instances, consider creating backups of these instances simultaneously to avoid inconsistency. This topic doesn't discuss how to back up a single database using pg_dump. Note that although you can use pg_dump without stopping the PostgreSQL service, you need to stop the applications to keep data consistency when using pg_dump to back up the Service Management databases one by one. Important Practice guidance of any third-party products (for example, PostgreSQL) provided by OpenText is for reference purposes only with an intention to help customers. However, customers will remain responsible for ensuring that the end-to-end solution wor",
    "url": "selfmanagedpgbackuprestore",
    "filename": "selfmanagedpgbackuprestore",
    "headings": [
      "Prerequisites",
      "Prepare a PostgreSQL Client host",
      "Prepare a disk for backup storage",
      "Backup",
      "Create base backups",
      "Create a base backup for single-node PostgreSQL",
      "Create a base backup for a Partroni-based PogreSQL HA setup",
      "Set up a standby (read-only) database server without failover",
      "Enable continuous archiving",
      "Restore",
      "Restore from a base backup",
      "For a Patroni-based PostgreSQL HA cluster",
      "For a single-node PostgreSQL",
      "Perform Point-in-Time Recovery (PITR)",
      "For a single-node PostgreSQL",
      "For a Patroni-based PostgreSQL HA cluster"
    ],
    "keywords": [
      "postgresql.yml",
      "postgresql.conf",
      "here.Here",
      "pg_hba.conf",
      "data.tar",
      "postgresql.org",
      "https://download.postgresql.org/pub/repos/yum/reporpms/EL-8-x86_64/pgdg-redhat-repo-latest.noarch.rpm",
      "tar.gz",
      "noarch.rpm",
      "20.5.5",
      "self-managed",
      "postgresql",
      "backup",
      "restore",
      "prerequisites",
      "prepare",
      "client",
      "host",
      "disk",
      "storage",
      "create",
      "base",
      "backups",
      "single-node",
      "partroni-based",
      "pogresql",
      "ha",
      "setup",
      "set",
      "standby",
      "read-only",
      "database",
      "server",
      "failover",
      "enable",
      "continuous",
      "archiving",
      "patroni-based",
      "cluster",
      "perform",
      "point-in-time",
      "recovery",
      "pitr",
      "topic",
      "provides",
      "instructions",
      "back",
      "data",
      "instance",
      "archives",
      "runtime",
      "service",
      "interruption.",
      "keep",
      "consistency",
      "among",
      "all",
      "databases",
      "suite",
      "instance-level",
      "recommended.",
      "running",
      "different",
      "instances",
      "consider",
      "creating",
      "simultaneously",
      "avoid",
      "inconsistency.",
      "doesn",
      "discuss",
      "single",
      "note",
      "although",
      "stopping",
      "need",
      "stop",
      "applications",
      "management",
      "one",
      "one.",
      "important",
      "practice",
      "guidance",
      "any",
      "third-party",
      "products",
      "example",
      "provided",
      "opentext",
      "reference",
      "purposes",
      "intention",
      "help",
      "customers.",
      "however",
      "customers",
      "remain",
      "responsible",
      "ensuring"
    ],
    "language": "en",
    "word_count": 92,
    "importance_score": 6.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "self-managed postgresql backup and restore",
    "contentLower": "this topic provides instructions on how to back up the data of a self-managed postgresql instance, using base backups and continuous archives, which you can perform at runtime without service interruption. to keep data consistency among all databases of the suite, instance-level backup is recommended. if your databases are running on different postgresql instances, consider creating backups of these instances simultaneously to avoid inconsistency. this topic doesn't discuss how to back up a single database using pg_dump. note that although you can use pg_dump without stopping the postgresql service, you need to stop the applications to keep data consistency when using pg_dump to back up the service management databases one by one. important practice guidance of any third-party products (for example, postgresql) provided by opentext is for reference purposes only with an intention to help customers. however, customers will remain responsible for ensuring that the end-to-end solution wor",
    "keywordsLower": [
      "postgresql.yml",
      "postgresql.conf",
      "here.here",
      "pg_hba.conf",
      "data.tar",
      "postgresql.org",
      "https://download.postgresql.org/pub/repos/yum/reporpms/el-8-x86_64/pgdg-redhat-repo-latest.noarch.rpm",
      "tar.gz",
      "noarch.rpm",
      "20.5.5",
      "self-managed",
      "postgresql",
      "backup",
      "restore",
      "prerequisites",
      "prepare",
      "client",
      "host",
      "disk",
      "storage",
      "create",
      "base",
      "backups",
      "single-node",
      "partroni-based",
      "pogresql",
      "ha",
      "setup",
      "set",
      "standby",
      "read-only",
      "database",
      "server",
      "failover",
      "enable",
      "continuous",
      "archiving",
      "patroni-based",
      "cluster",
      "perform",
      "point-in-time",
      "recovery",
      "pitr",
      "topic",
      "provides",
      "instructions",
      "back",
      "data",
      "instance",
      "archives",
      "runtime",
      "service",
      "interruption.",
      "keep",
      "consistency",
      "among",
      "all",
      "databases",
      "suite",
      "instance-level",
      "recommended.",
      "running",
      "different",
      "instances",
      "consider",
      "creating",
      "simultaneously",
      "avoid",
      "inconsistency.",
      "doesn",
      "discuss",
      "single",
      "note",
      "although",
      "stopping",
      "need",
      "stop",
      "applications",
      "management",
      "one",
      "one.",
      "important",
      "practice",
      "guidance",
      "any",
      "third-party",
      "products",
      "example",
      "provided",
      "opentext",
      "reference",
      "purposes",
      "intention",
      "help",
      "customers.",
      "however",
      "customers",
      "remain",
      "responsible",
      "ensuring"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "SMA Restore Procedures",
    "content": "This section describes how to restore the suite data in all environments. Choose the restore solution based on your actual scenarios: Scenario 1: Kubernetes configurations have been corrupted Scenario 2: Persistent storage data has been corrupted Scenario 3: Databases data has been corrupted Scenario 4: Kubernetes cluster has crashed",
    "url": "smarestoreprocedures",
    "filename": "smarestoreprocedures",
    "headings": [],
    "keywords": [
      "sma",
      "restore",
      "procedures",
      "section",
      "describes",
      "suite",
      "data",
      "all",
      "environments.",
      "choose",
      "solution",
      "based",
      "actual",
      "scenarios",
      "scenario",
      "kubernetes",
      "configurations",
      "corrupted",
      "persistent",
      "storage",
      "databases",
      "cluster",
      "crashed"
    ],
    "language": "en",
    "word_count": 37,
    "importance_score": 2.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "sma restore procedures",
    "contentLower": "this section describes how to restore the suite data in all environments. choose the restore solution based on your actual scenarios: scenario 1: kubernetes configurations have been corrupted scenario 2: persistent storage data has been corrupted scenario 3: databases data has been corrupted scenario 4: kubernetes cluster has crashed",
    "keywordsLower": [
      "sma",
      "restore",
      "procedures",
      "section",
      "describes",
      "suite",
      "data",
      "all",
      "environments.",
      "choose",
      "solution",
      "based",
      "actual",
      "scenarios",
      "scenario",
      "kubernetes",
      "configurations",
      "corrupted",
      "persistent",
      "storage",
      "databases",
      "cluster",
      "crashed"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Scenario 1: Kubernetes configurations are corrupted",
    "content": "In this scenario, one or more Kubernetes configurations of the suite and OMT (for example, configmaps and deployments) were mistakenly changed. You need to restore them to the latest correct configuration. Choose the restore solution based on your managed Kubernetes deployment platforms. PrerequisitesBefore you start, make sure:You have backed up the Kubernetes configurations using Velero.The Kubernetes cluster is functioning.There is no data corruption in the storage and databases.Restore on Kubernetes configurations Managed KubernetesYou can only use the restore process when the PersistentVolumeReclaimPolicy is Retain. Otherwise, data might be lost during restoring.Restore OMT deploymentPerform the following steps to restore OMT deployment if you've removed the OMT namespace by accident.Run the following command to create the OMT namespace. In ns admin mode, ask the cluster administrator to create the OMT namespace. source $HOME/itom-cdf.sh kubectl create ns $CDF_NAMESPACERefer to En",
    "url": "restorekubernetesconfig",
    "filename": "restorekubernetesconfig",
    "headings": [
      "Prerequisites",
      "Restore on Kubernetes configurations Managed Kubernetes",
      "Restore OMT deployment",
      "Restore suite deployment",
      "Restore the Kubernetes configurations Embedded Kubernetes",
      "Restore OMT deployment",
      "Restore suite deployment"
    ],
    "keywords": [
      "Velero.The",
      "deployment.Run",
      "CDF_NAMESPACE.json",
      "data.tar",
      "server.Run",
      "accident.Run",
      "microfocus.com",
      "cdf.sh",
      "metadata.name",
      "step.For",
      "scenario",
      "kubernetes",
      "configurations",
      "corrupted",
      "prerequisites",
      "restore",
      "managed",
      "omt",
      "deployment",
      "suite",
      "embedded",
      "one",
      "example",
      "configmaps",
      "deployments",
      "mistakenly",
      "changed.",
      "need",
      "latest",
      "correct",
      "configuration.",
      "choose",
      "solution",
      "based",
      "platforms.",
      "prerequisitesbefore",
      "start",
      "make",
      "sure",
      "backed",
      "cluster",
      "functioning.there",
      "data",
      "corruption",
      "storage",
      "databases.restore",
      "kubernetesyou",
      "process",
      "persistentvolumereclaimpolicy",
      "retain.",
      "otherwise",
      "lost",
      "during",
      "restoring.restore",
      "deploymentperform",
      "following",
      "steps",
      "ve",
      "removed",
      "namespace",
      "command",
      "create",
      "namespace.",
      "ns",
      "admin",
      "mode",
      "ask",
      "administrator",
      "source",
      "home",
      "itom-cdf.sh",
      "kubectl",
      "enable",
      "capability",
      "manually",
      "after",
      "installation",
      "backup",
      "capability.",
      "skip",
      "preparation",
      "steps.",
      "provided",
      "bucket",
      "information",
      "including",
      "name",
      "region",
      "resource",
      "group",
      "account",
      "credential",
      "file",
      "secret",
      "same",
      "ones",
      "installing.",
      "get",
      "available",
      "data."
    ],
    "language": "en",
    "word_count": 91,
    "importance_score": 5.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "scenario 1: kubernetes configurations are corrupted",
    "contentLower": "in this scenario, one or more kubernetes configurations of the suite and omt (for example, configmaps and deployments) were mistakenly changed. you need to restore them to the latest correct configuration. choose the restore solution based on your managed kubernetes deployment platforms. prerequisitesbefore you start, make sure:you have backed up the kubernetes configurations using velero.the kubernetes cluster is functioning.there is no data corruption in the storage and databases.restore on kubernetes configurations managed kubernetesyou can only use the restore process when the persistentvolumereclaimpolicy is retain. otherwise, data might be lost during restoring.restore omt deploymentperform the following steps to restore omt deployment if you've removed the omt namespace by accident.run the following command to create the omt namespace. in ns admin mode, ask the cluster administrator to create the omt namespace. source $home/itom-cdf.sh kubectl create ns $cdf_namespacerefer to en",
    "keywordsLower": [
      "velero.the",
      "deployment.run",
      "cdf_namespace.json",
      "data.tar",
      "server.run",
      "accident.run",
      "microfocus.com",
      "cdf.sh",
      "metadata.name",
      "step.for",
      "scenario",
      "kubernetes",
      "configurations",
      "corrupted",
      "prerequisites",
      "restore",
      "managed",
      "omt",
      "deployment",
      "suite",
      "embedded",
      "one",
      "example",
      "configmaps",
      "deployments",
      "mistakenly",
      "changed.",
      "need",
      "latest",
      "correct",
      "configuration.",
      "choose",
      "solution",
      "based",
      "platforms.",
      "prerequisitesbefore",
      "start",
      "make",
      "sure",
      "backed",
      "cluster",
      "functioning.there",
      "data",
      "corruption",
      "storage",
      "databases.restore",
      "kubernetesyou",
      "process",
      "persistentvolumereclaimpolicy",
      "retain.",
      "otherwise",
      "lost",
      "during",
      "restoring.restore",
      "deploymentperform",
      "following",
      "steps",
      "ve",
      "removed",
      "namespace",
      "command",
      "create",
      "namespace.",
      "ns",
      "admin",
      "mode",
      "ask",
      "administrator",
      "source",
      "home",
      "itom-cdf.sh",
      "kubectl",
      "enable",
      "capability",
      "manually",
      "after",
      "installation",
      "backup",
      "capability.",
      "skip",
      "preparation",
      "steps.",
      "provided",
      "bucket",
      "information",
      "including",
      "name",
      "region",
      "resource",
      "group",
      "account",
      "credential",
      "file",
      "secret",
      "same",
      "ones",
      "installing.",
      "get",
      "available",
      "data."
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Restore Design and Deploy (DND)",
    "content": "After the suite is restored, perform the following steps to restore Design and Deploy (DND) if your source environment has DND deployed. Manually redeploy DND after restoring the suite After the suite is restored, for the tenants where DND was deployed previously, you need to manually redeploy DND with these steps: Note  If your suite instance has multiple tenants in which DND was deployed, repeat these steps for each of them. You need to redeploy DND for the tenants where DND is listed on the Capability settings tab (Suite Administration > TENANTS > select the target tenant > Capability settings) and the deployment Status is Done. Log in to a control plane node or worker node (embedded Kubernetes environment) or the bastion node (managed Kubernetes environment) and save the script below as redeploy.sh: #!/usr/bin/env sh ## # This script will trigger force DND redeploy, typically for disaster recovery(DR) use. ## ITSMA_NAMESPACE=$(kubectl get ns | grep -e \"^itsma-\" | tr -s \" \" | cut -d",
    "url": "dnddr",
    "filename": "dnddr",
    "headings": [
      "Manually redeploy DND after restoring the suite",
      "Update aggregation provider settings"
    ],
    "keywords": [
      "dummy.com",
      "53.327",
      "redeploy.sh",
      "http://${DND_DEPLOY_CONTROLLER_SVC}:8080/v1/deployments/status",
      "http://${ATS_SVC}:31027/tenants/${TENANT_ID}/capabilities/redeploy",
      "53.185",
      "restore",
      "design",
      "deploy",
      "dnd",
      "manually",
      "redeploy",
      "after",
      "restoring",
      "suite",
      "update",
      "aggregation",
      "provider",
      "settings",
      "restored",
      "perform",
      "following",
      "steps",
      "source",
      "environment",
      "deployed.",
      "tenants",
      "deployed",
      "previously",
      "need",
      "note",
      "instance",
      "multiple",
      "repeat",
      "them.",
      "listed",
      "capability",
      "tab",
      "administration",
      "select",
      "target",
      "tenant",
      "deployment",
      "status",
      "done.",
      "log",
      "control",
      "plane",
      "node",
      "worker",
      "embedded",
      "kubernetes",
      "bastion",
      "managed",
      "save",
      "script",
      "below",
      "usr",
      "bin",
      "env",
      "sh",
      "trigger",
      "force",
      "typically",
      "disaster",
      "recovery",
      "dr",
      "use.",
      "kubectl",
      "get",
      "ns",
      "grep",
      "-e",
      "itsma-",
      "tr",
      "-s",
      "cut",
      "-d",
      "-f1",
      "figure",
      "out",
      "internal",
      "ip",
      "itom-bo-ats-svc.",
      "svc",
      "itom-bo-ats-svc",
      "-n",
      "-o",
      "jsonpath",
      ".spec.clusterip",
      "curl",
      "-x",
      "put",
      "http",
      "31027",
      "capabilities",
      "-h",
      "content-type",
      "application",
      "json"
    ],
    "language": "en",
    "word_count": 109,
    "importance_score": 4.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "restore design and deploy (dnd)",
    "contentLower": "after the suite is restored, perform the following steps to restore design and deploy (dnd) if your source environment has dnd deployed. manually redeploy dnd after restoring the suite after the suite is restored, for the tenants where dnd was deployed previously, you need to manually redeploy dnd with these steps: note  if your suite instance has multiple tenants in which dnd was deployed, repeat these steps for each of them. you need to redeploy dnd for the tenants where dnd is listed on the capability settings tab (suite administration > tenants > select the target tenant > capability settings) and the deployment status is done. log in to a control plane node or worker node (embedded kubernetes environment) or the bastion node (managed kubernetes environment) and save the script below as redeploy.sh: #!/usr/bin/env sh ## # this script will trigger force dnd redeploy, typically for disaster recovery(dr) use. ## itsma_namespace=$(kubectl get ns | grep -e \"^itsma-\" | tr -s \" \" | cut -d",
    "keywordsLower": [
      "dummy.com",
      "53.327",
      "redeploy.sh",
      "http://${dnd_deploy_controller_svc}:8080/v1/deployments/status",
      "http://${ats_svc}:31027/tenants/${tenant_id}/capabilities/redeploy",
      "53.185",
      "restore",
      "design",
      "deploy",
      "dnd",
      "manually",
      "redeploy",
      "after",
      "restoring",
      "suite",
      "update",
      "aggregation",
      "provider",
      "settings",
      "restored",
      "perform",
      "following",
      "steps",
      "source",
      "environment",
      "deployed.",
      "tenants",
      "deployed",
      "previously",
      "need",
      "note",
      "instance",
      "multiple",
      "repeat",
      "them.",
      "listed",
      "capability",
      "tab",
      "administration",
      "select",
      "target",
      "tenant",
      "deployment",
      "status",
      "done.",
      "log",
      "control",
      "plane",
      "node",
      "worker",
      "embedded",
      "kubernetes",
      "bastion",
      "managed",
      "save",
      "script",
      "below",
      "usr",
      "bin",
      "env",
      "sh",
      "trigger",
      "force",
      "typically",
      "disaster",
      "recovery",
      "dr",
      "use.",
      "kubectl",
      "get",
      "ns",
      "grep",
      "-e",
      "itsma-",
      "tr",
      "-s",
      "cut",
      "-d",
      "-f1",
      "figure",
      "out",
      "internal",
      "ip",
      "itom-bo-ats-svc.",
      "svc",
      "itom-bo-ats-svc",
      "-n",
      "-o",
      "jsonpath",
      ".spec.clusterip",
      "curl",
      "-x",
      "put",
      "http",
      "31027",
      "capabilities",
      "-h",
      "content-type",
      "application",
      "json"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Scenario 2: Persistent storage data has been corrupted",
    "content": "In this scenario, some files on the persistent storage are corrupted or deleted by accident or mistakenly. You need to restore these files to the latest backup. Choose the restore solution according to your deployment platforms. Prerequisites Before you start, make sure: You have backed up the storage. The Kubernetes cluster is functioning. There's no data corruption in your databases. Restore EFS on AWS If your suite is deployed on AWS, follow these steps to restore EFS: Run this command on the bastion to stop the system: ./cdfctl.sh runlevel set -l DOWN -n core,itsma-xxxxx Restore EFS by navigating to the AWS Backup console at https://console.aws.amazon.com/backup and following the instructions at Restore a backup. If your EFS instance still exists, For Restore type, select Full restore. For Restore location, select Restore to directory in source file system. Leave the remaining settings as is. If your EFS instance doesn't exist, For Restore type, select Full restore. For Restore loc",
    "url": "storagedatacorrupted",
    "filename": "storagedatacorrupted",
    "headings": [
      "Prerequisites",
      "Restore EFS on AWS",
      "Restore storage on Azure",
      "Restore storage on GCP",
      "Restore storage for OpenShift deployments",
      "Restore storage for Embedded Kubernetes",
      "Use the original NFS server to restore the original data",
      "Use a new NFS server to restore the NFS data"
    ],
    "keywords": [
      "https://cloud.google.com/filestore/docs/backup-restore?authuser=1#restoring_to_an_existing_instance",
      "https://docs.microsoft.com/en-us/azure/storage/files/storage-files-enable-soft-delete?tabs=azure-portal#restore-soft-deleted-file-share",
      "4.1",
      "amazon.com",
      "pv.yaml",
      "google.com",
      "https://console.aws.amazon.com/backup",
      "cdfctl.sh",
      "i.bak",
      "amazonaws.com",
      "microsoft.com",
      "https://cloud.google.com/filestore/docs/backup-restore?authuser=1#restoring_a_file_share",
      "https://cloud.google.com/filestore/docs/backup-restore?authuser=1#restoring_to_a_new_instance",
      "https://docs.microsoft.com/en-gb/azure/azure-netapp-files",
      "console.aws",
      "https://docs.microsoft.com/en-us/azure/backup/restore-afs",
      "scenario",
      "persistent",
      "storage",
      "data",
      "corrupted",
      "prerequisites",
      "restore",
      "efs",
      "aws",
      "azure",
      "gcp",
      "openshift",
      "deployments",
      "embedded",
      "kubernetes",
      "original",
      "nfs",
      "server",
      "new",
      "files",
      "deleted",
      "accident",
      "mistakenly.",
      "need",
      "latest",
      "backup.",
      "choose",
      "solution",
      "according",
      "deployment",
      "platforms.",
      "before",
      "start",
      "make",
      "sure",
      "backed",
      "storage.",
      "cluster",
      "functioning.",
      "there",
      "corruption",
      "databases.",
      "suite",
      "deployed",
      "follow",
      "steps",
      "run",
      "command",
      "bastion",
      "stop",
      "system",
      "runlevel",
      "set",
      "-l",
      "-n",
      "core",
      "itsma-xxxxx",
      "navigating",
      "backup",
      "console",
      "https",
      "console.aws.amazon.com",
      "following",
      "instructions",
      "instance",
      "still",
      "exists",
      "type",
      "select",
      "full",
      "restore.",
      "location",
      "directory",
      "source",
      "file",
      "system.",
      "leave",
      "remaining",
      "settings",
      "is.",
      "doesn",
      "exist",
      "after",
      "restored"
    ],
    "language": "en",
    "word_count": 108,
    "importance_score": 5.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "scenario 2: persistent storage data has been corrupted",
    "contentLower": "in this scenario, some files on the persistent storage are corrupted or deleted by accident or mistakenly. you need to restore these files to the latest backup. choose the restore solution according to your deployment platforms. prerequisites before you start, make sure: you have backed up the storage. the kubernetes cluster is functioning. there's no data corruption in your databases. restore efs on aws if your suite is deployed on aws, follow these steps to restore efs: run this command on the bastion to stop the system: ./cdfctl.sh runlevel set -l down -n core,itsma-xxxxx restore efs by navigating to the aws backup console at https://console.aws.amazon.com/backup and following the instructions at restore a backup. if your efs instance still exists, for restore type, select full restore. for restore location, select restore to directory in source file system. leave the remaining settings as is. if your efs instance doesn't exist, for restore type, select full restore. for restore loc",
    "keywordsLower": [
      "https://cloud.google.com/filestore/docs/backup-restore?authuser=1#restoring_to_an_existing_instance",
      "https://docs.microsoft.com/en-us/azure/storage/files/storage-files-enable-soft-delete?tabs=azure-portal#restore-soft-deleted-file-share",
      "4.1",
      "amazon.com",
      "pv.yaml",
      "google.com",
      "https://console.aws.amazon.com/backup",
      "cdfctl.sh",
      "i.bak",
      "amazonaws.com",
      "microsoft.com",
      "https://cloud.google.com/filestore/docs/backup-restore?authuser=1#restoring_a_file_share",
      "https://cloud.google.com/filestore/docs/backup-restore?authuser=1#restoring_to_a_new_instance",
      "https://docs.microsoft.com/en-gb/azure/azure-netapp-files",
      "console.aws",
      "https://docs.microsoft.com/en-us/azure/backup/restore-afs",
      "scenario",
      "persistent",
      "storage",
      "data",
      "corrupted",
      "prerequisites",
      "restore",
      "efs",
      "aws",
      "azure",
      "gcp",
      "openshift",
      "deployments",
      "embedded",
      "kubernetes",
      "original",
      "nfs",
      "server",
      "new",
      "files",
      "deleted",
      "accident",
      "mistakenly.",
      "need",
      "latest",
      "backup.",
      "choose",
      "solution",
      "according",
      "deployment",
      "platforms.",
      "before",
      "start",
      "make",
      "sure",
      "backed",
      "storage.",
      "cluster",
      "functioning.",
      "there",
      "corruption",
      "databases.",
      "suite",
      "deployed",
      "follow",
      "steps",
      "run",
      "command",
      "bastion",
      "stop",
      "system",
      "runlevel",
      "set",
      "-l",
      "-n",
      "core",
      "itsma-xxxxx",
      "navigating",
      "backup",
      "console",
      "https",
      "console.aws.amazon.com",
      "following",
      "instructions",
      "instance",
      "still",
      "exists",
      "type",
      "select",
      "full",
      "restore.",
      "location",
      "directory",
      "source",
      "file",
      "system.",
      "leave",
      "remaining",
      "settings",
      "is.",
      "doesn",
      "exist",
      "after",
      "restored"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Scenario 3: Databases are corrupted",
    "content": "In this scenario, the database data is corrupted or deleted by accident or mistakenly. You need to restore the databases to the latest backup. Choose the restore procedure according to your deployment platforms. Prerequisites Before you start, make sure: You have backed up the databases. The Kubernetes cluster is functioning. There is no data corruption in the storage. Restore RDS on AWS If your suite is deployed on AWS, follow these steps to restore RDS: Run this command on the bastion to stop the system: ./cdfctl.sh runlevel set -l DOWN -n core,itsma-xxxxx If your RDS instance still exists, take note of the database's DB identifier and then delete this old RDS. You will need the DB identifier later. Restore RDS by navigating to the AWS Backup console and following the official Restore a backup instructions. Make sure you configure the same settings as the old RDS instance: Under Settings, select the same DB Instance Identifier as the old RDS. Under Network & Security, select the same",
    "url": "databasedatacorrupted",
    "filename": "databasedatacorrupted",
    "headings": [
      "Prerequisites",
      "Restore RDS on AWS",
      "Restore databases on Azure",
      "Restore databases on GCP",
      "Restore databases on OpenShift",
      "Restore databases on Embedded Kubernetes",
      "Using the original database server",
      "Using a new database server"
    ],
    "keywords": [
      "cdfctl.sh",
      "scenario",
      "databases",
      "corrupted",
      "prerequisites",
      "restore",
      "rds",
      "aws",
      "azure",
      "gcp",
      "openshift",
      "embedded",
      "kubernetes",
      "original",
      "database",
      "server",
      "new",
      "data",
      "deleted",
      "accident",
      "mistakenly.",
      "need",
      "latest",
      "backup.",
      "choose",
      "procedure",
      "according",
      "deployment",
      "platforms.",
      "before",
      "start",
      "make",
      "sure",
      "backed",
      "databases.",
      "cluster",
      "functioning.",
      "there",
      "corruption",
      "storage.",
      "suite",
      "deployed",
      "follow",
      "steps",
      "run",
      "command",
      "bastion",
      "stop",
      "system",
      "runlevel",
      "set",
      "-l",
      "-n",
      "core",
      "itsma-xxxxx",
      "instance",
      "still",
      "exists",
      "take",
      "note",
      "db",
      "identifier",
      "delete",
      "old",
      "rds.",
      "later.",
      "navigating",
      "backup",
      "console",
      "following",
      "official",
      "instructions.",
      "configure",
      "same",
      "settings",
      "under",
      "select",
      "network",
      "security",
      "vpc",
      "subnet",
      "leave",
      "remaining",
      "is.",
      "created",
      "last",
      "step",
      "click",
      "modify.",
      "update",
      "group",
      "after",
      "modified",
      "successfully",
      "restart",
      "verify",
      "restoration",
      "kubectl",
      "get",
      "pod"
    ],
    "language": "en",
    "word_count": 108,
    "importance_score": 6.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "scenario 3: databases are corrupted",
    "contentLower": "in this scenario, the database data is corrupted or deleted by accident or mistakenly. you need to restore the databases to the latest backup. choose the restore procedure according to your deployment platforms. prerequisites before you start, make sure: you have backed up the databases. the kubernetes cluster is functioning. there is no data corruption in the storage. restore rds on aws if your suite is deployed on aws, follow these steps to restore rds: run this command on the bastion to stop the system: ./cdfctl.sh runlevel set -l down -n core,itsma-xxxxx if your rds instance still exists, take note of the database's db identifier and then delete this old rds. you will need the db identifier later. restore rds by navigating to the aws backup console and following the official restore a backup instructions. make sure you configure the same settings as the old rds instance: under settings, select the same db instance identifier as the old rds. under network & security, select the same",
    "keywordsLower": [
      "cdfctl.sh",
      "scenario",
      "databases",
      "corrupted",
      "prerequisites",
      "restore",
      "rds",
      "aws",
      "azure",
      "gcp",
      "openshift",
      "embedded",
      "kubernetes",
      "original",
      "database",
      "server",
      "new",
      "data",
      "deleted",
      "accident",
      "mistakenly.",
      "need",
      "latest",
      "backup.",
      "choose",
      "procedure",
      "according",
      "deployment",
      "platforms.",
      "before",
      "start",
      "make",
      "sure",
      "backed",
      "databases.",
      "cluster",
      "functioning.",
      "there",
      "corruption",
      "storage.",
      "suite",
      "deployed",
      "follow",
      "steps",
      "run",
      "command",
      "bastion",
      "stop",
      "system",
      "runlevel",
      "set",
      "-l",
      "-n",
      "core",
      "itsma-xxxxx",
      "instance",
      "still",
      "exists",
      "take",
      "note",
      "db",
      "identifier",
      "delete",
      "old",
      "rds.",
      "later.",
      "navigating",
      "backup",
      "console",
      "following",
      "official",
      "instructions.",
      "configure",
      "same",
      "settings",
      "under",
      "select",
      "network",
      "security",
      "vpc",
      "subnet",
      "leave",
      "remaining",
      "is.",
      "created",
      "last",
      "step",
      "click",
      "modify.",
      "update",
      "group",
      "after",
      "modified",
      "successfully",
      "restart",
      "verify",
      "restoration",
      "kubectl",
      "get",
      "pod"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Restore Vertica database",
    "content": "Perform the following steps to restore the Vertica database: Create the Vertica database with the same parameter and credentials as the original database. adminTools -t create_db -d cgro -p dbadmin --hosts=<VerticaNode1> --policy=always Stop the Vertica database. admintools -t stop_db -d cgro -p <password> -F (You can find available backed up archives under <vertica_backup_location>/Snapshots/) or by running vbr.py: /opt/vertica/bin/vbr.py -t listbackup --list-all -c backup_restore_full_external.ini Enter vertica password: backup backup_type epoch objects include_patterns exclude_patterns nodes(hosts) version file_system_type backup_snapshot_20200805_172031 full 2898 v_cgro_node0001(10.0.0.6 ) v9.2.1-0 [Linux] If using remote backups, ensure that password-less SSH has been correctly configured (presumably done already in order to have created the backup). Restore the database from a given restore point: /opt/vertica/bin/vbr.py -t restore --archive 20200805_172031 --config-file backup_r",
    "url": "verticadatabasebackuprestore",
    "filename": "verticadatabasebackuprestore",
    "headings": [
      "Related topics"
    ],
    "keywords": [
      "backup_restore_full_external.ini",
      "10.0.0.6",
      "v9.2.1",
      "10.0.0",
      "vbr.py",
      "restore",
      "vertica",
      "database",
      "related",
      "topics",
      "perform",
      "following",
      "steps",
      "create",
      "same",
      "parameter",
      "credentials",
      "original",
      "database.",
      "admintools",
      "-t",
      "-d",
      "cgro",
      "-p",
      "dbadmin",
      "--hosts",
      "--policy",
      "always",
      "stop",
      "-f",
      "find",
      "available",
      "backed",
      "archives",
      "under",
      "snapshots",
      "running",
      "opt",
      "bin",
      "listbackup",
      "--list-all",
      "-c",
      "enter",
      "password",
      "backup",
      "epoch",
      "objects",
      "nodes",
      "hosts",
      "version",
      "full",
      "2898",
      "v9.2.1-0",
      "linux",
      "remote",
      "backups",
      "ensure",
      "password-less",
      "ssh",
      "correctly",
      "configured",
      "presumably",
      "done",
      "already",
      "order",
      "created",
      "given",
      "point",
      "--archive",
      "--config-file",
      "starting",
      "cgro.",
      "participating",
      "restoring",
      "determining",
      "what",
      "data",
      "backup.",
      "100",
      "approximate",
      "bytes",
      "copy",
      "362268160",
      "363420789",
      "total.",
      "syncing",
      "cluster",
      "nodes.",
      "catalog.",
      "complete",
      "start",
      "db",
      "verify",
      "got",
      "restored.",
      "instructions",
      "backing",
      "see",
      "back"
    ],
    "language": "en",
    "word_count": 102,
    "importance_score": 3.5,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "restore vertica database",
    "contentLower": "perform the following steps to restore the vertica database: create the vertica database with the same parameter and credentials as the original database. admintools -t create_db -d cgro -p dbadmin --hosts=<verticanode1> --policy=always stop the vertica database. admintools -t stop_db -d cgro -p <password> -f (you can find available backed up archives under <vertica_backup_location>/snapshots/) or by running vbr.py: /opt/vertica/bin/vbr.py -t listbackup --list-all -c backup_restore_full_external.ini enter vertica password: backup backup_type epoch objects include_patterns exclude_patterns nodes(hosts) version file_system_type backup_snapshot_20200805_172031 full 2898 v_cgro_node0001(10.0.0.6 ) v9.2.1-0 [linux] if using remote backups, ensure that password-less ssh has been correctly configured (presumably done already in order to have created the backup). restore the database from a given restore point: /opt/vertica/bin/vbr.py -t restore --archive 20200805_172031 --config-file backup_r",
    "keywordsLower": [
      "backup_restore_full_external.ini",
      "10.0.0.6",
      "v9.2.1",
      "10.0.0",
      "vbr.py",
      "restore",
      "vertica",
      "database",
      "related",
      "topics",
      "perform",
      "following",
      "steps",
      "create",
      "same",
      "parameter",
      "credentials",
      "original",
      "database.",
      "admintools",
      "-t",
      "-d",
      "cgro",
      "-p",
      "dbadmin",
      "--hosts",
      "--policy",
      "always",
      "stop",
      "-f",
      "find",
      "available",
      "backed",
      "archives",
      "under",
      "snapshots",
      "running",
      "opt",
      "bin",
      "listbackup",
      "--list-all",
      "-c",
      "enter",
      "password",
      "backup",
      "epoch",
      "objects",
      "nodes",
      "hosts",
      "version",
      "full",
      "2898",
      "v9.2.1-0",
      "linux",
      "remote",
      "backups",
      "ensure",
      "password-less",
      "ssh",
      "correctly",
      "configured",
      "presumably",
      "done",
      "already",
      "order",
      "created",
      "given",
      "point",
      "--archive",
      "--config-file",
      "starting",
      "cgro.",
      "participating",
      "restoring",
      "determining",
      "what",
      "data",
      "backup.",
      "100",
      "approximate",
      "bytes",
      "copy",
      "362268160",
      "363420789",
      "total.",
      "syncing",
      "cluster",
      "nodes.",
      "catalog.",
      "complete",
      "start",
      "db",
      "verify",
      "got",
      "restored.",
      "instructions",
      "backing",
      "see",
      "back"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Scenario 4: Kubernetes cluster has crashed",
    "content": "In this scenario, the current Kubernetes cluster has crashed, for example, the API server isn't available, or the worker node isn't ready. You need to rebuild a new cluster for the suite. Choose the restore solution according to your deployment platforms. Prerequisites Before you start, make sure: You have backed up the Kubernetes configurations. There's no data corruption on storage and in databases. Restore EKS cluster on AWS For AWS deployment, follow these steps to restore the EKS cluster. Delete the older EKS worker nodes and cluster Delete the old EKS worker nodes by navigating to the AWS Management Console and selecting CloudFormation > the stack used to create your worker nodes > Delete. Delete the old EKS cluster by navigating to the AWS Management Console and selecting CloudFormation > the stack used to create your EKS cluster > Delete. Create a new EKS cluster Create a new EKS cluster by following the steps at Build EKS cluster. Field Description EKS Cluster Version Select t",
    "url": "kubernetesclustercrashed",
    "filename": "kubernetesclustercrashed",
    "headings": [
      "Prerequisites",
      "Restore EKS cluster on AWS",
      "Restore AKS cluster on Azure",
      "Restore GKE cluster on GCP",
      "Restore K8s cluster on OpenShift",
      "Restore K8s cluster on embedded Kubernetes"
    ],
    "keywords": [
      "ca.crt",
      "node.type",
      "https://dl.fedoraproject.org/pub/epel/epel-release-latest-7.noarch.rpm",
      "https://itom-vault.core:8200",
      "34.8.32.28",
      "8.32",
      "vault.core",
      "159xxx727.us",
      "kubernetes.io",
      "https://kubernetes.default",
      "noarch.rpm",
      "example.com",
      "backup.all",
      "fedoraproject.org",
      "34.8.32",
      "amazonaws.com",
      "2.elb",
      "metadata.name",
      "aes-256",
      "scenario",
      "kubernetes",
      "cluster",
      "crashed",
      "prerequisites",
      "restore",
      "eks",
      "aws",
      "aks",
      "azure",
      "gke",
      "gcp",
      "k8s",
      "openshift",
      "embedded",
      "current",
      "example",
      "api",
      "server",
      "isn",
      "available",
      "worker",
      "node",
      "ready.",
      "need",
      "rebuild",
      "new",
      "suite.",
      "choose",
      "solution",
      "according",
      "deployment",
      "platforms.",
      "before",
      "start",
      "make",
      "sure",
      "backed",
      "configurations.",
      "there",
      "data",
      "corruption",
      "storage",
      "databases.",
      "follow",
      "steps",
      "cluster.",
      "delete",
      "older",
      "nodes",
      "old",
      "navigating",
      "management",
      "console",
      "selecting",
      "cloudformation",
      "stack",
      "create",
      "delete.",
      "following",
      "build",
      "field",
      "description",
      "version",
      "select",
      "same",
      "security",
      "group",
      "name",
      "configure",
      "check",
      "connectivity",
      "kubectl",
      "commands",
      "region",
      "selected",
      "created",
      "such",
      "us-east-2",
      "previous",
      "step."
    ],
    "language": "en",
    "word_count": 114,
    "importance_score": 5.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "scenario 4: kubernetes cluster has crashed",
    "contentLower": "in this scenario, the current kubernetes cluster has crashed, for example, the api server isn't available, or the worker node isn't ready. you need to rebuild a new cluster for the suite. choose the restore solution according to your deployment platforms. prerequisites before you start, make sure: you have backed up the kubernetes configurations. there's no data corruption on storage and in databases. restore eks cluster on aws for aws deployment, follow these steps to restore the eks cluster. delete the older eks worker nodes and cluster delete the old eks worker nodes by navigating to the aws management console and selecting cloudformation > the stack used to create your worker nodes > delete. delete the old eks cluster by navigating to the aws management console and selecting cloudformation > the stack used to create your eks cluster > delete. create a new eks cluster create a new eks cluster by following the steps at build eks cluster. field description eks cluster version select t",
    "keywordsLower": [
      "ca.crt",
      "node.type",
      "https://dl.fedoraproject.org/pub/epel/epel-release-latest-7.noarch.rpm",
      "https://itom-vault.core:8200",
      "34.8.32.28",
      "8.32",
      "vault.core",
      "159xxx727.us",
      "kubernetes.io",
      "https://kubernetes.default",
      "noarch.rpm",
      "example.com",
      "backup.all",
      "fedoraproject.org",
      "34.8.32",
      "amazonaws.com",
      "2.elb",
      "metadata.name",
      "aes-256",
      "scenario",
      "kubernetes",
      "cluster",
      "crashed",
      "prerequisites",
      "restore",
      "eks",
      "aws",
      "aks",
      "azure",
      "gke",
      "gcp",
      "k8s",
      "openshift",
      "embedded",
      "current",
      "example",
      "api",
      "server",
      "isn",
      "available",
      "worker",
      "node",
      "ready.",
      "need",
      "rebuild",
      "new",
      "suite.",
      "choose",
      "solution",
      "according",
      "deployment",
      "platforms.",
      "before",
      "start",
      "make",
      "sure",
      "backed",
      "configurations.",
      "there",
      "data",
      "corruption",
      "storage",
      "databases.",
      "follow",
      "steps",
      "cluster.",
      "delete",
      "older",
      "nodes",
      "old",
      "navigating",
      "management",
      "console",
      "selecting",
      "cloudformation",
      "stack",
      "create",
      "delete.",
      "following",
      "build",
      "field",
      "description",
      "version",
      "select",
      "same",
      "security",
      "group",
      "name",
      "configure",
      "check",
      "connectivity",
      "kubectl",
      "commands",
      "region",
      "selected",
      "created",
      "such",
      "us-east-2",
      "previous",
      "step."
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Restore containerized UD/UCMDB deployment",
    "content": "Scenario 1 - the containerized UD/UCMDB deployment is still functioning but data are missing or corrupted Stop the UD/UCMDB deployment. On the control plane node (or bastion node), run the following command: /opt/cdf/scripts/cdfctl.sh runlevel set -l DOWN -n <namespace-of-CMS-deployment> Wait for a few minutes until the UD/UCMDB deployment fully stopped. Restore UD/UCMDB databases, including UCMDB database, IdM database, and Autopass database. Restore the following data in NFS volumes: Component NFS volume name Directory Description UCMDB Gateway ucmdb-data-volume <ucmdb-data-volume>/cms-gateway Data generated by the UCMDB Gateway Start the UD/UCMDB deployment. On the control plane node (or bastion node), run the following command: /opt/cdf/scripts/cdfctl.sh runlevel set -l UP -n <namespace-of-CMS-deployment> Scenario 2 - the containerized UD/UCMDB deployment is corrupted or failing Make sure you always perform troubleshooting by following instructions in Troubleshoot UD/UCMDB. If this",
    "url": "recoverycms",
    "filename": "recoverycms",
    "headings": [
      "Scenario 1 - the containerized UD/UCMDB deployment is still functioning but data are missing or corrupted",
      "Scenario 2 - the containerized UD/UCMDB deployment is corrupted or failing",
      "Scenario 3 - OMT crash"
    ],
    "keywords": [
      "uducmdb",
      "cdfctl.sh",
      "values.yaml",
      "pv.yaml",
      "dd.yaml",
      "restore",
      "containerized",
      "ud",
      "ucmdb",
      "deployment",
      "scenario",
      "still",
      "functioning",
      "data",
      "missing",
      "corrupted",
      "failing",
      "omt",
      "crash",
      "stop",
      "deployment.",
      "control",
      "plane",
      "node",
      "bastion",
      "run",
      "following",
      "command",
      "opt",
      "cdf",
      "scripts",
      "runlevel",
      "set",
      "-l",
      "-n",
      "wait",
      "few",
      "minutes",
      "until",
      "fully",
      "stopped.",
      "databases",
      "including",
      "database",
      "idm",
      "autopass",
      "database.",
      "nfs",
      "volumes",
      "component",
      "volume",
      "name",
      "directory",
      "description",
      "gateway",
      "ucmdb-data-volume",
      "cms-gateway",
      "generated",
      "start",
      "make",
      "sure",
      "always",
      "perform",
      "troubleshooting",
      "instructions",
      "troubleshoot",
      "ucmdb.",
      "cannot",
      "resolve",
      "issue",
      "follow",
      "below",
      "uninstall",
      "delete",
      "remove",
      "persistent",
      "clean",
      "details",
      "see",
      "create",
      "new",
      "secret.",
      "cms-secret",
      "backup",
      "secret",
      "yaml",
      "file",
      "kubectl",
      "apply",
      "-f",
      "cms-probe-secret",
      "re-create",
      "server",
      "volumes.",
      "pvs",
      "same",
      "configuration",
      "ucmdb-pv.yaml",
      "re-install",
      "my-values.yaml"
    ],
    "language": "en",
    "word_count": 113,
    "importance_score": 4.5,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "restore containerized ud/ucmdb deployment",
    "contentLower": "scenario 1 - the containerized ud/ucmdb deployment is still functioning but data are missing or corrupted stop the ud/ucmdb deployment. on the control plane node (or bastion node), run the following command: /opt/cdf/scripts/cdfctl.sh runlevel set -l down -n <namespace-of-cms-deployment> wait for a few minutes until the ud/ucmdb deployment fully stopped. restore ud/ucmdb databases, including ucmdb database, idm database, and autopass database. restore the following data in nfs volumes: component nfs volume name directory description ucmdb gateway ucmdb-data-volume <ucmdb-data-volume>/cms-gateway data generated by the ucmdb gateway start the ud/ucmdb deployment. on the control plane node (or bastion node), run the following command: /opt/cdf/scripts/cdfctl.sh runlevel set -l up -n <namespace-of-cms-deployment> scenario 2 - the containerized ud/ucmdb deployment is corrupted or failing make sure you always perform troubleshooting by following instructions in troubleshoot ud/ucmdb. if this",
    "keywordsLower": [
      "uducmdb",
      "cdfctl.sh",
      "values.yaml",
      "pv.yaml",
      "dd.yaml",
      "restore",
      "containerized",
      "ud",
      "ucmdb",
      "deployment",
      "scenario",
      "still",
      "functioning",
      "data",
      "missing",
      "corrupted",
      "failing",
      "omt",
      "crash",
      "stop",
      "deployment.",
      "control",
      "plane",
      "node",
      "bastion",
      "run",
      "following",
      "command",
      "opt",
      "cdf",
      "scripts",
      "runlevel",
      "set",
      "-l",
      "-n",
      "wait",
      "few",
      "minutes",
      "until",
      "fully",
      "stopped.",
      "databases",
      "including",
      "database",
      "idm",
      "autopass",
      "database.",
      "nfs",
      "volumes",
      "component",
      "volume",
      "name",
      "directory",
      "description",
      "gateway",
      "ucmdb-data-volume",
      "cms-gateway",
      "generated",
      "start",
      "make",
      "sure",
      "always",
      "perform",
      "troubleshooting",
      "instructions",
      "troubleshoot",
      "ucmdb.",
      "cannot",
      "resolve",
      "issue",
      "follow",
      "below",
      "uninstall",
      "delete",
      "remove",
      "persistent",
      "clean",
      "details",
      "see",
      "create",
      "new",
      "secret.",
      "cms-secret",
      "backup",
      "secret",
      "yaml",
      "file",
      "kubectl",
      "apply",
      "-f",
      "cms-probe-secret",
      "re-create",
      "server",
      "volumes.",
      "pvs",
      "same",
      "configuration",
      "ucmdb-pv.yaml",
      "re-install",
      "my-values.yaml"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Set up disaster recovery of OO",
    "content": "This topic contains detailed instructions on how to recover Operations Orchestration Containerized (OO Containerized) in the event of a failure from the backup taken at an earlier point in time. Role Location Kubernetes Cluster Administrator AWS EKS cluster and OO Containerized Kubernetes objects Kubernetes Cluster Administrator Azure AKS Cluster and OO Containerized Kubernetes objects You can perform backup and disaster recovery of OO using Velero. Velero is an open source tool to backup and restore, perform disaster recovery, and migrate Kubernetes cluster resources and persistent volumes Restore OO Containerized using Velero This section contains instructions to restore OO Containerized using the Velero tool. Prerequisites To back up and restore the Kubernetes configurations and cluster, you must first set up Velero according to your cloud deployment platforms. Make sure the Velero version works for your current Kubernetes version. It's recommended that you use the same Velero that ",
    "url": "disasterrecoveryoo",
    "filename": "disasterrecoveryoo",
    "headings": [
      "Restore OO Containerized using Velero",
      "Prerequisites",
      "Restore OO Containerized"
    ],
    "keywords": [
      "values.yaml",
      "oo.tgz",
      "oo_deployment_values.yaml",
      "set",
      "disaster",
      "recovery",
      "oo",
      "restore",
      "containerized",
      "velero",
      "prerequisites",
      "topic",
      "contains",
      "detailed",
      "instructions",
      "recover",
      "operations",
      "orchestration",
      "event",
      "failure",
      "backup",
      "taken",
      "earlier",
      "point",
      "time.",
      "role",
      "location",
      "kubernetes",
      "cluster",
      "administrator",
      "aws",
      "eks",
      "objects",
      "azure",
      "aks",
      "perform",
      "velero.",
      "open",
      "source",
      "tool",
      "migrate",
      "resources",
      "persistent",
      "volumes",
      "section",
      "tool.",
      "back",
      "configurations",
      "first",
      "according",
      "cloud",
      "deployment",
      "platforms.",
      "make",
      "sure",
      "version",
      "works",
      "current",
      "version.",
      "recommended",
      "same",
      "configured",
      "suite.",
      "install",
      "configure",
      "see",
      "start",
      "pod",
      "namespace",
      "environment.",
      "configurations.",
      "instructions.",
      "rds",
      "efs",
      "afs",
      "automatically",
      "backed",
      "restored",
      "through",
      "services.",
      "kubectl",
      "installed",
      "locally.",
      "possible",
      "data",
      "service",
      "management",
      "database",
      "don",
      "coincide.",
      "means",
      "there",
      "inconsistencies",
      "between",
      "tenant",
      "status",
      "containerized.",
      "following",
      "timeline",
      "illustrates"
    ],
    "language": "en",
    "word_count": 101,
    "importance_score": 3.5,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "set up disaster recovery of oo",
    "contentLower": "this topic contains detailed instructions on how to recover operations orchestration containerized (oo containerized) in the event of a failure from the backup taken at an earlier point in time. role location kubernetes cluster administrator aws eks cluster and oo containerized kubernetes objects kubernetes cluster administrator azure aks cluster and oo containerized kubernetes objects you can perform backup and disaster recovery of oo using velero. velero is an open source tool to backup and restore, perform disaster recovery, and migrate kubernetes cluster resources and persistent volumes restore oo containerized using velero this section contains instructions to restore oo containerized using the velero tool. prerequisites to back up and restore the kubernetes configurations and cluster, you must first set up velero according to your cloud deployment platforms. make sure the velero version works for your current kubernetes version. it's recommended that you use the same velero that ",
    "keywordsLower": [
      "values.yaml",
      "oo.tgz",
      "oo_deployment_values.yaml",
      "set",
      "disaster",
      "recovery",
      "oo",
      "restore",
      "containerized",
      "velero",
      "prerequisites",
      "topic",
      "contains",
      "detailed",
      "instructions",
      "recover",
      "operations",
      "orchestration",
      "event",
      "failure",
      "backup",
      "taken",
      "earlier",
      "point",
      "time.",
      "role",
      "location",
      "kubernetes",
      "cluster",
      "administrator",
      "aws",
      "eks",
      "objects",
      "azure",
      "aks",
      "perform",
      "velero.",
      "open",
      "source",
      "tool",
      "migrate",
      "resources",
      "persistent",
      "volumes",
      "section",
      "tool.",
      "back",
      "configurations",
      "first",
      "according",
      "cloud",
      "deployment",
      "platforms.",
      "make",
      "sure",
      "version",
      "works",
      "current",
      "version.",
      "recommended",
      "same",
      "configured",
      "suite.",
      "install",
      "configure",
      "see",
      "start",
      "pod",
      "namespace",
      "environment.",
      "configurations.",
      "instructions.",
      "rds",
      "efs",
      "afs",
      "automatically",
      "backed",
      "restored",
      "through",
      "services.",
      "kubectl",
      "installed",
      "locally.",
      "possible",
      "data",
      "service",
      "management",
      "database",
      "don",
      "coincide.",
      "means",
      "there",
      "inconsistencies",
      "between",
      "tenant",
      "status",
      "containerized.",
      "following",
      "timeline",
      "illustrates"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Retrieve the suite truststore password",
    "content": "The SMA truststore (itsma-truststore.jks) is located in the following folder on the NFS server: <suite global NFS directory>/certificate/ca-trust/. For example: /var/vols/itom/itsma/config-volume/certificate/ca-trust/. When importing an external certificate to the suite truststore or vise versa, you need to know the password of the suite truststore. You may consult the Kubernetes cluster administrator of your deployment to obtain the password, or you can retrieve the password using the Kubernetes CLI (command line interface) as described below. Follow these steps to retrieve the password on a control plane node: Run the following commands to identify the pod member that you will need to log in to: # kubectl get pods -n itsma1 | grep 'certificate-deployment' Where: itsma1 represents the suite namespace; change it if your suite uses a different one. Run the following commands to log in to the appropriate server: # kubectl exec -it <identified pod member> -n itsma1 -c certificate bash Run",
    "url": "truststorepassword",
    "filename": "truststorepassword",
    "headings": [],
    "keywords": [
      "truststore.jks",
      "retrieve",
      "suite",
      "truststore",
      "password",
      "sma",
      "itsma-truststore.jks",
      "located",
      "following",
      "folder",
      "nfs",
      "server",
      "certificate",
      "ca-trust",
      "example",
      "var",
      "vols",
      "itom",
      "itsma",
      "config-volume",
      "importing",
      "external",
      "vise",
      "versa",
      "need",
      "know",
      "truststore.",
      "consult",
      "kubernetes",
      "cluster",
      "administrator",
      "deployment",
      "obtain",
      "cli",
      "command",
      "line",
      "interface",
      "described",
      "below.",
      "follow",
      "steps",
      "control",
      "plane",
      "node",
      "run",
      "commands",
      "identify",
      "pod",
      "member",
      "log",
      "kubectl",
      "get",
      "pods",
      "-n",
      "itsma1",
      "grep",
      "certificate-deployment",
      "represents",
      "namespace",
      "change",
      "uses",
      "different",
      "one.",
      "appropriate",
      "exec",
      "-it",
      "-c",
      "bash"
    ],
    "language": "en",
    "word_count": 96,
    "importance_score": 3.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "retrieve the suite truststore password",
    "contentLower": "the sma truststore (itsma-truststore.jks) is located in the following folder on the nfs server: <suite global nfs directory>/certificate/ca-trust/. for example: /var/vols/itom/itsma/config-volume/certificate/ca-trust/. when importing an external certificate to the suite truststore or vise versa, you need to know the password of the suite truststore. you may consult the kubernetes cluster administrator of your deployment to obtain the password, or you can retrieve the password using the kubernetes cli (command line interface) as described below. follow these steps to retrieve the password on a control plane node: run the following commands to identify the pod member that you will need to log in to: # kubectl get pods -n itsma1 | grep 'certificate-deployment' where: itsma1 represents the suite namespace; change it if your suite uses a different one. run the following commands to log in to the appropriate server: # kubectl exec -it <identified pod member> -n itsma1 -c certificate bash run",
    "keywordsLower": [
      "truststore.jks",
      "retrieve",
      "suite",
      "truststore",
      "password",
      "sma",
      "itsma-truststore.jks",
      "located",
      "following",
      "folder",
      "nfs",
      "server",
      "certificate",
      "ca-trust",
      "example",
      "var",
      "vols",
      "itom",
      "itsma",
      "config-volume",
      "importing",
      "external",
      "vise",
      "versa",
      "need",
      "know",
      "truststore.",
      "consult",
      "kubernetes",
      "cluster",
      "administrator",
      "deployment",
      "obtain",
      "cli",
      "command",
      "line",
      "interface",
      "described",
      "below.",
      "follow",
      "steps",
      "control",
      "plane",
      "node",
      "run",
      "commands",
      "identify",
      "pod",
      "member",
      "log",
      "kubectl",
      "get",
      "pods",
      "-n",
      "itsma1",
      "grep",
      "certificate-deployment",
      "represents",
      "namespace",
      "change",
      "uses",
      "different",
      "one.",
      "appropriate",
      "exec",
      "-it",
      "-c",
      "bash"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Retrieve or change the integration user password",
    "content": "Service Management uses a system-defined user account named bo-integration@dummy.com for integration purposes such as data synchronization between Suite Administration and tenants. The initial password for this integration user account is set at the time of suite installation. You may need to check or change the integration user account password from time to time. Especially if you forget the password or your organization's security policy requires regular updates. This topic shows you how to do both. Retrieve integration user password Complete the following steps to find the current password for the integration user account. Run the following command on a control plane or a bastion node to find the pod running the itom-bo-login-deployment service. The pod name resembles itom-bo-login-deployment-xxxxxxxx, where xxxxxxxx is a unique identifier. kubectl get pods -n <suite namespace> | grep itom-bo-login-deployment Run the following command to retrieve the integration user password. Use t",
    "url": "changeintegrationuserpswd",
    "filename": "changeintegrationuserpswd",
    "headings": [
      "Retrieve integration user password",
      "Change integration user password in IdM portal",
      "Prerequisites",
      "Enter the new password",
      "Restart the suite"
    ],
    "keywords": [
      "Portal.Make",
      "https://<External_Access_Host>/idm-admin",
      "dummy.com",
      "characters.Must",
      "organization.On",
      "cdfctl.sh",
      "character.Must",
      "letter.Must",
      "retrieve",
      "change",
      "integration",
      "user",
      "password",
      "idm",
      "portal",
      "prerequisites",
      "enter",
      "new",
      "restart",
      "suite",
      "service",
      "management",
      "uses",
      "system-defined",
      "account",
      "named",
      "bo-integration",
      "purposes",
      "such",
      "data",
      "synchronization",
      "between",
      "administration",
      "tenants.",
      "initial",
      "set",
      "time",
      "installation.",
      "need",
      "check",
      "time.",
      "especially",
      "forget",
      "organization",
      "security",
      "policy",
      "requires",
      "regular",
      "updates.",
      "topic",
      "shows",
      "both.",
      "complete",
      "following",
      "steps",
      "find",
      "current",
      "account.",
      "run",
      "command",
      "control",
      "plane",
      "bastion",
      "node",
      "pod",
      "running",
      "itom-bo-login-deployment",
      "service.",
      "name",
      "resembles",
      "itom-bo-login-deployment-xxxxxxxx",
      "xxxxxxxx",
      "unique",
      "identifier.",
      "kubectl",
      "get",
      "pods",
      "-n",
      "grep",
      "password.",
      "identified",
      "earlier",
      "step.",
      "exec",
      "-it",
      "-c",
      "itom-bo-login",
      "example",
      "make",
      "sure",
      "know",
      "suite-admin",
      "login",
      "admin",
      "requirements",
      "met",
      "length",
      "10",
      "16",
      "contain"
    ],
    "language": "en",
    "word_count": 100,
    "importance_score": 4.5,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "retrieve or change the integration user password",
    "contentLower": "service management uses a system-defined user account named bo-integration@dummy.com for integration purposes such as data synchronization between suite administration and tenants. the initial password for this integration user account is set at the time of suite installation. you may need to check or change the integration user account password from time to time. especially if you forget the password or your organization's security policy requires regular updates. this topic shows you how to do both. retrieve integration user password complete the following steps to find the current password for the integration user account. run the following command on a control plane or a bastion node to find the pod running the itom-bo-login-deployment service. the pod name resembles itom-bo-login-deployment-xxxxxxxx, where xxxxxxxx is a unique identifier. kubectl get pods -n <suite namespace> | grep itom-bo-login-deployment run the following command to retrieve the integration user password. use t",
    "keywordsLower": [
      "portal.make",
      "https://<external_access_host>/idm-admin",
      "dummy.com",
      "characters.must",
      "organization.on",
      "cdfctl.sh",
      "character.must",
      "letter.must",
      "retrieve",
      "change",
      "integration",
      "user",
      "password",
      "idm",
      "portal",
      "prerequisites",
      "enter",
      "new",
      "restart",
      "suite",
      "service",
      "management",
      "uses",
      "system-defined",
      "account",
      "named",
      "bo-integration",
      "purposes",
      "such",
      "data",
      "synchronization",
      "between",
      "administration",
      "tenants.",
      "initial",
      "set",
      "time",
      "installation.",
      "need",
      "check",
      "time.",
      "especially",
      "forget",
      "organization",
      "security",
      "policy",
      "requires",
      "regular",
      "updates.",
      "topic",
      "shows",
      "both.",
      "complete",
      "following",
      "steps",
      "find",
      "current",
      "account.",
      "run",
      "command",
      "control",
      "plane",
      "bastion",
      "node",
      "pod",
      "running",
      "itom-bo-login-deployment",
      "service.",
      "name",
      "resembles",
      "itom-bo-login-deployment-xxxxxxxx",
      "xxxxxxxx",
      "unique",
      "identifier.",
      "kubectl",
      "get",
      "pods",
      "-n",
      "grep",
      "password.",
      "identified",
      "earlier",
      "step.",
      "exec",
      "-it",
      "-c",
      "itom-bo-login",
      "example",
      "make",
      "sure",
      "know",
      "suite-admin",
      "login",
      "admin",
      "requirements",
      "met",
      "length",
      "10",
      "16",
      "contain"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Scale up UD/UCMDB deployment size",
    "content": "The containerized UD/UCMDB provides three options for deployment size: small, medium, and large. You can perform the following steps to scale up the deployment size for the containerized UD/UCMDB. Note You can't revert a deployment in a large size back to a smaller one. Scale up resources You need to extend the following resources to meet the new UD/UCMDB deployment size: Worker nodes NFS storage Database size For the required resources for the new deployment size on different platforms, see the corresponding sizing document: On-premises deployment sizing AWS deployment sizing AKS deployment sizing OpenShift deployment sizing Update my-values.yaml After extending the resources as required by the new UD/UCMDB deployment size, follow these steps to apply the size change: Edit your my-values.yaml using any editor, change the value of global.size. Run the following command to apply this change: helm upgrade <UD/UCMDB RELEASE NAME> <UD/UCMDB CHART FILE> --namespace <UD/UCMDB NAMESPACE> -f <",
    "url": "changecmsdeploymentsize",
    "filename": "changecmsdeploymentsize",
    "headings": [
      "Scale up resources",
      "Update my-values.yaml"
    ],
    "keywords": [
      "uducmdb",
      "global.size",
      "1.xx",
      "x.tgz",
      "values.yaml",
      "scale",
      "ud",
      "ucmdb",
      "deployment",
      "size",
      "resources",
      "update",
      "my-values.yaml",
      "containerized",
      "provides",
      "three",
      "options",
      "small",
      "medium",
      "large.",
      "perform",
      "following",
      "steps",
      "ucmdb.",
      "note",
      "revert",
      "large",
      "back",
      "smaller",
      "one.",
      "need",
      "extend",
      "meet",
      "new",
      "worker",
      "nodes",
      "nfs",
      "storage",
      "database",
      "required",
      "different",
      "platforms",
      "see",
      "corresponding",
      "sizing",
      "document",
      "on-premises",
      "aws",
      "aks",
      "openshift",
      "after",
      "extending",
      "follow",
      "apply",
      "change",
      "edit",
      "any",
      "editor",
      "value",
      "global.size.",
      "run",
      "command",
      "helm",
      "upgrade",
      "--namespace",
      "-f",
      "retrieved",
      "running",
      "list",
      "-n",
      "tar",
      "file",
      "containing",
      "installation",
      "charts.",
      "namespace.",
      "custom",
      "properties",
      "configured",
      "deployment.",
      "example",
      "ucmdb-prod",
      "ucmdb-helm-charts",
      "charts",
      "ucmdb-1.xx.x-xxx",
      "2x.x.x.tgz"
    ],
    "language": "en",
    "word_count": 107,
    "importance_score": 4.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "scale up ud/ucmdb deployment size",
    "contentLower": "the containerized ud/ucmdb provides three options for deployment size: small, medium, and large. you can perform the following steps to scale up the deployment size for the containerized ud/ucmdb. note you can't revert a deployment in a large size back to a smaller one. scale up resources you need to extend the following resources to meet the new ud/ucmdb deployment size: worker nodes nfs storage database size for the required resources for the new deployment size on different platforms, see the corresponding sizing document: on-premises deployment sizing aws deployment sizing aks deployment sizing openshift deployment sizing update my-values.yaml after extending the resources as required by the new ud/ucmdb deployment size, follow these steps to apply the size change: edit your my-values.yaml using any editor, change the value of global.size. run the following command to apply this change: helm upgrade <ud/ucmdb release name> <ud/ucmdb chart file> --namespace <ud/ucmdb namespace> -f <",
    "keywordsLower": [
      "uducmdb",
      "global.size",
      "1.xx",
      "x.tgz",
      "values.yaml",
      "scale",
      "ud",
      "ucmdb",
      "deployment",
      "size",
      "resources",
      "update",
      "my-values.yaml",
      "containerized",
      "provides",
      "three",
      "options",
      "small",
      "medium",
      "large.",
      "perform",
      "following",
      "steps",
      "ucmdb.",
      "note",
      "revert",
      "large",
      "back",
      "smaller",
      "one.",
      "need",
      "extend",
      "meet",
      "new",
      "worker",
      "nodes",
      "nfs",
      "storage",
      "database",
      "required",
      "different",
      "platforms",
      "see",
      "corresponding",
      "sizing",
      "document",
      "on-premises",
      "aws",
      "aks",
      "openshift",
      "after",
      "extending",
      "follow",
      "apply",
      "change",
      "edit",
      "any",
      "editor",
      "value",
      "global.size.",
      "run",
      "command",
      "helm",
      "upgrade",
      "--namespace",
      "-f",
      "retrieved",
      "running",
      "list",
      "-n",
      "tar",
      "file",
      "containing",
      "installation",
      "charts.",
      "namespace.",
      "custom",
      "properties",
      "configured",
      "deployment.",
      "example",
      "ucmdb-prod",
      "ucmdb-helm-charts",
      "charts",
      "ucmdb-1.xx.x-xxx",
      "2x.x.x.tgz"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Restart UD/UCMDB",
    "content": "This procedure restarts the pods of the UD/UCMDB deployment only. It doesn't restart OMT or restart the VM hosts. To restart the UD/UCMDB, perform the following steps: Navigate to the $CDF_HOME/scripts directory, and run the following command to stop the UD/UCMDB pods: ./cdfctl.sh runlevel set -l DOWN -n <namespace> Where: <namespace> is the UD/UCMDB namespace, and the last character in runlevel set -l is lowercase letter L. You can run the following command to watch the UD/UCMDB pod status: watch kubectl get pods -n <namespace> This command will refresh the display of the UD/UCMDB pod status every two seconds. Navigate to the $CDF_HOME/scripts directory, and run the following command to start the UD/UCMDB pods: ./cdfctl.sh runlevel set -l UP -n <namespace> Wait until the UD/UCMDB pods have restarted. You can run the following command to watch the UD/UCMDB pod status: watch kubectl get pods -n <namespace>",
    "url": "restartcms",
    "filename": "restartcms",
    "headings": [],
    "keywords": [
      "uducmdb",
      "cdfctl.sh",
      "restart",
      "ud",
      "ucmdb",
      "procedure",
      "restarts",
      "pods",
      "deployment",
      "only.",
      "doesn",
      "omt",
      "vm",
      "hosts.",
      "perform",
      "following",
      "steps",
      "navigate",
      "scripts",
      "directory",
      "run",
      "command",
      "stop",
      "runlevel",
      "set",
      "-l",
      "-n",
      "namespace",
      "last",
      "character",
      "lowercase",
      "letter",
      "l.",
      "watch",
      "pod",
      "status",
      "kubectl",
      "get",
      "refresh",
      "display",
      "every",
      "two",
      "seconds.",
      "start",
      "wait",
      "until",
      "restarted."
    ],
    "language": "en",
    "word_count": 108,
    "importance_score": 3.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "restart ud/ucmdb",
    "contentLower": "this procedure restarts the pods of the ud/ucmdb deployment only. it doesn't restart omt or restart the vm hosts. to restart the ud/ucmdb, perform the following steps: navigate to the $cdf_home/scripts directory, and run the following command to stop the ud/ucmdb pods: ./cdfctl.sh runlevel set -l down -n <namespace> where: <namespace> is the ud/ucmdb namespace, and the last character in runlevel set -l is lowercase letter l. you can run the following command to watch the ud/ucmdb pod status: watch kubectl get pods -n <namespace> this command will refresh the display of the ud/ucmdb pod status every two seconds. navigate to the $cdf_home/scripts directory, and run the following command to start the ud/ucmdb pods: ./cdfctl.sh runlevel set -l up -n <namespace> wait until the ud/ucmdb pods have restarted. you can run the following command to watch the ud/ucmdb pod status: watch kubectl get pods -n <namespace>",
    "keywordsLower": [
      "uducmdb",
      "cdfctl.sh",
      "restart",
      "ud",
      "ucmdb",
      "procedure",
      "restarts",
      "pods",
      "deployment",
      "only.",
      "doesn",
      "omt",
      "vm",
      "hosts.",
      "perform",
      "following",
      "steps",
      "navigate",
      "scripts",
      "directory",
      "run",
      "command",
      "stop",
      "runlevel",
      "set",
      "-l",
      "-n",
      "namespace",
      "last",
      "character",
      "lowercase",
      "letter",
      "l.",
      "watch",
      "pod",
      "status",
      "kubectl",
      "get",
      "refresh",
      "display",
      "every",
      "two",
      "seconds.",
      "start",
      "wait",
      "until",
      "restarted."
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Renew UD/UCMDB certificates",
    "content": "To renew UD/UCMDB certificates, follow these steps: Log in to any one of the control plane nodes as a root user or non-root user. Run the following command. You can specify the -V option with some other number of days as the validity period of the certificate. $CDF_HOME/scripts/renewCert --renew -t external -V 365 -n <ucmdb_namespace> Your terminal resembles the following: [root@sh scripts]# ./renewCert --renew -t external -V 365 -n cms Additional log: /opt/cdf/log/renewcert/renewcert.20220705155042.log The external certificates will expire in 7823 hour(s). This command will overwrite the external certificates with self-signed certificates. ? Are you sure to continue Yes Renewing external certificates locally ... Renewing external certificates in Pod ... Applying secret: nginx-default-secret in cms ... Finished! Finished! When you renew the certificate with a sudo user, run: sudo $CDF_HOME/scripts/renewCert –renew -t external -V 365 -n <ucmdb_namespace>",
    "url": "renewcmscert",
    "filename": "renewcmscert",
    "headings": [],
    "keywords": [
      "uducmdb",
      "20220705155042.log",
      "renew",
      "ud",
      "ucmdb",
      "certificates",
      "follow",
      "steps",
      "log",
      "any",
      "one",
      "control",
      "plane",
      "nodes",
      "root",
      "user",
      "non-root",
      "user.",
      "run",
      "following",
      "command.",
      "specify",
      "-v",
      "option",
      "number",
      "days",
      "validity",
      "period",
      "certificate.",
      "scripts",
      "renewcert",
      "--renew",
      "-t",
      "external",
      "365",
      "-n",
      "terminal",
      "resembles",
      "sh",
      "cms",
      "additional",
      "opt",
      "cdf",
      "renewcert.20220705155042.log",
      "expire",
      "7823",
      "hour",
      "command",
      "overwrite",
      "self-signed",
      "certificates.",
      "sure",
      "continue",
      "renewing",
      "locally",
      "pod",
      "applying",
      "secret",
      "nginx-default-secret",
      "finished",
      "certificate",
      "sudo"
    ],
    "language": "en",
    "word_count": 107,
    "importance_score": 3.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "renew ud/ucmdb certificates",
    "contentLower": "to renew ud/ucmdb certificates, follow these steps: log in to any one of the control plane nodes as a root user or non-root user. run the following command. you can specify the -v option with some other number of days as the validity period of the certificate. $cdf_home/scripts/renewcert --renew -t external -v 365 -n <ucmdb_namespace> your terminal resembles the following: [root@sh scripts]# ./renewcert --renew -t external -v 365 -n cms additional log: /opt/cdf/log/renewcert/renewcert.20220705155042.log the external certificates will expire in 7823 hour(s). this command will overwrite the external certificates with self-signed certificates. ? are you sure to continue yes renewing external certificates locally ... renewing external certificates in pod ... applying secret: nginx-default-secret in cms ... finished! finished! when you renew the certificate with a sudo user, run: sudo $cdf_home/scripts/renewcert –renew -t external -v 365 -n <ucmdb_namespace>",
    "keywordsLower": [
      "uducmdb",
      "20220705155042.log",
      "renew",
      "ud",
      "ucmdb",
      "certificates",
      "follow",
      "steps",
      "log",
      "any",
      "one",
      "control",
      "plane",
      "nodes",
      "root",
      "user",
      "non-root",
      "user.",
      "run",
      "following",
      "command.",
      "specify",
      "-v",
      "option",
      "number",
      "days",
      "validity",
      "period",
      "certificate.",
      "scripts",
      "renewcert",
      "--renew",
      "-t",
      "external",
      "365",
      "-n",
      "terminal",
      "resembles",
      "sh",
      "cms",
      "additional",
      "opt",
      "cdf",
      "renewcert.20220705155042.log",
      "expire",
      "7823",
      "hour",
      "command",
      "overwrite",
      "self-signed",
      "certificates.",
      "sure",
      "continue",
      "renewing",
      "locally",
      "pod",
      "applying",
      "secret",
      "nginx-default-secret",
      "finished",
      "certificate",
      "sudo"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Replace the database certificate for UD/UCMDB",
    "content": "If you want to replace the database certificate because it is about to expire or no longer valid, follow these steps: Prepare the new database certificate. For example, for Amazon RDS, you can get the certificate from the Amazon Relational Database Service website. Get the UD/UCMDB configuration file (my-values.yaml) from the current UD/UCMDB deployment. Run the following command to get the UD/UCMDB release name: helm list -n <UD/UCMDB NAMESPACE> Then, run the following command to create a copy of the configuration file: helm get values <UD/UCMDB RELEASE NAME> -n <UD/UCMDB NAMESPACE> > my-values.yaml Replace the content of caCertificates.database.crt in my-values.yaml with the content of the database certificate that you got from the previous step. Note that each line of certificate content starts with a four-space indentation in my-values.yaml. Update the UD/UCMDB deployment with the updated configuration file. helm upgrade <UD/UCMDB RELEASE NAME> <UD/UCMDB CHART FILE> -n <UD/UCMDB NA",
    "url": "replacerdscertificates",
    "filename": "replacerdscertificates",
    "headings": [],
    "keywords": [
      "uducmdb",
      "values.yaml",
      "database.crt",
      "replace",
      "database",
      "certificate",
      "ud",
      "ucmdb",
      "want",
      "because",
      "about",
      "expire",
      "longer",
      "valid",
      "follow",
      "steps",
      "prepare",
      "new",
      "certificate.",
      "example",
      "amazon",
      "rds",
      "get",
      "relational",
      "service",
      "website.",
      "configuration",
      "file",
      "my-values.yaml",
      "current",
      "deployment.",
      "run",
      "following",
      "command",
      "release",
      "name",
      "helm",
      "list",
      "-n",
      "create",
      "copy",
      "values",
      "content",
      "cacertificates.database.crt",
      "got",
      "previous",
      "step.",
      "note",
      "line",
      "starts",
      "four-space",
      "indentation",
      "my-values.yaml.",
      "update",
      "deployment",
      "updated",
      "file.",
      "upgrade",
      "-f",
      "restart",
      "ucmdb.",
      "see"
    ],
    "language": "en",
    "word_count": 94,
    "importance_score": 2.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "replace the database certificate for ud/ucmdb",
    "contentLower": "if you want to replace the database certificate because it is about to expire or no longer valid, follow these steps: prepare the new database certificate. for example, for amazon rds, you can get the certificate from the amazon relational database service website. get the ud/ucmdb configuration file (my-values.yaml) from the current ud/ucmdb deployment. run the following command to get the ud/ucmdb release name: helm list -n <ud/ucmdb namespace> then, run the following command to create a copy of the configuration file: helm get values <ud/ucmdb release name> -n <ud/ucmdb namespace> > my-values.yaml replace the content of cacertificates.database.crt in my-values.yaml with the content of the database certificate that you got from the previous step. note that each line of certificate content starts with a four-space indentation in my-values.yaml. update the ud/ucmdb deployment with the updated configuration file. helm upgrade <ud/ucmdb release name> <ud/ucmdb chart file> -n <ud/ucmdb na",
    "keywordsLower": [
      "uducmdb",
      "values.yaml",
      "database.crt",
      "replace",
      "database",
      "certificate",
      "ud",
      "ucmdb",
      "want",
      "because",
      "about",
      "expire",
      "longer",
      "valid",
      "follow",
      "steps",
      "prepare",
      "new",
      "certificate.",
      "example",
      "amazon",
      "rds",
      "get",
      "relational",
      "service",
      "website.",
      "configuration",
      "file",
      "my-values.yaml",
      "current",
      "deployment.",
      "run",
      "following",
      "command",
      "release",
      "name",
      "helm",
      "list",
      "-n",
      "create",
      "copy",
      "values",
      "content",
      "cacertificates.database.crt",
      "got",
      "previous",
      "step.",
      "note",
      "line",
      "starts",
      "four-space",
      "indentation",
      "my-values.yaml.",
      "update",
      "deployment",
      "updated",
      "file.",
      "upgrade",
      "-f",
      "restart",
      "ucmdb.",
      "see"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Reconfigure database",
    "content": "After the containerized UD/UCMDB is installed, if you need to change the external database host of your system, follow the instructions in this topic. Back up configuration files Back up cms-secret and cms-probe-secret (if available). Run the following command: kubectl get secret cms-secret -o yaml -n <UD/UCMDB NAMESPACE> > cms-secret_backup_yyyy-mm-dd.yaml kubectl get secret cms-probe-secret -o yaml -n <UD/UCMDB NAMESPACE> > cms-probe-secret_backup_yyyy-mm-dd.yaml For example, kubectl get secret cms-secret -o yaml -n ucmdb-prod > secret_backup.yaml kubectl get secret cms-probe1-secret -o yaml -n ucmdb-prod > probe1-secret_backup.yaml Make sure that the previous database is functioning before the switching is succeeded. Back up all the configuration files that you are using. For example, my-values.yaml file, my-values-probe.yaml, probe1-values.yaml, and probe2-values.yaml files. If you don't remember the path of your custom my-values.yaml file, run the following command to create a cop",
    "url": "reconfigdb",
    "filename": "reconfigdb",
    "headings": [
      "Back up configuration files",
      "Switch to an empty database",
      "Switch to a database with UCMDB data",
      "Roll back to use the previous database"
    ],
    "keywords": [
      "secret_backup.yaml",
      "database.port",
      "database.host",
      "database.user",
      "x.tgz",
      "dd.yaml",
      "probe.yaml",
      "1.xx",
      "values.yaml",
      "example.com",
      "reconfigure",
      "database",
      "back",
      "configuration",
      "files",
      "switch",
      "empty",
      "ucmdb",
      "data",
      "roll",
      "previous",
      "after",
      "containerized",
      "ud",
      "installed",
      "need",
      "change",
      "external",
      "host",
      "system",
      "follow",
      "instructions",
      "topic.",
      "cms-secret",
      "cms-probe-secret",
      "available",
      "run",
      "following",
      "command",
      "kubectl",
      "get",
      "secret",
      "-o",
      "yaml",
      "-n",
      "example",
      "ucmdb-prod",
      "cms-probe1-secret",
      "make",
      "sure",
      "functioning",
      "before",
      "switching",
      "succeeded.",
      "all",
      "using.",
      "my-values.yaml",
      "file",
      "my-values-probe.yaml",
      "probe1-values.yaml",
      "probe2-values.yaml",
      "files.",
      "don",
      "remember",
      "path",
      "custom",
      "create",
      "copy",
      "current",
      "directory",
      "helm",
      "values",
      "want",
      "new",
      "steps",
      "prepare",
      "database.",
      "databases",
      "initialize",
      "during",
      "installation.",
      "table",
      "shows",
      "information",
      "prepared",
      "components.",
      "service",
      "db",
      "user",
      "name",
      "schema",
      "server",
      "idm",
      "apls",
      "flow",
      "probe",
      "postgresql",
      "passwords",
      "same",
      "ones"
    ],
    "language": "en",
    "word_count": 93,
    "importance_score": 5.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "reconfigure database",
    "contentLower": "after the containerized ud/ucmdb is installed, if you need to change the external database host of your system, follow the instructions in this topic. back up configuration files back up cms-secret and cms-probe-secret (if available). run the following command: kubectl get secret cms-secret -o yaml -n <ud/ucmdb namespace> > cms-secret_backup_yyyy-mm-dd.yaml kubectl get secret cms-probe-secret -o yaml -n <ud/ucmdb namespace> > cms-probe-secret_backup_yyyy-mm-dd.yaml for example, kubectl get secret cms-secret -o yaml -n ucmdb-prod > secret_backup.yaml kubectl get secret cms-probe1-secret -o yaml -n ucmdb-prod > probe1-secret_backup.yaml make sure that the previous database is functioning before the switching is succeeded. back up all the configuration files that you are using. for example, my-values.yaml file, my-values-probe.yaml, probe1-values.yaml, and probe2-values.yaml files. if you don't remember the path of your custom my-values.yaml file, run the following command to create a cop",
    "keywordsLower": [
      "secret_backup.yaml",
      "database.port",
      "database.host",
      "database.user",
      "x.tgz",
      "dd.yaml",
      "probe.yaml",
      "1.xx",
      "values.yaml",
      "example.com",
      "reconfigure",
      "database",
      "back",
      "configuration",
      "files",
      "switch",
      "empty",
      "ucmdb",
      "data",
      "roll",
      "previous",
      "after",
      "containerized",
      "ud",
      "installed",
      "need",
      "change",
      "external",
      "host",
      "system",
      "follow",
      "instructions",
      "topic.",
      "cms-secret",
      "cms-probe-secret",
      "available",
      "run",
      "following",
      "command",
      "kubectl",
      "get",
      "secret",
      "-o",
      "yaml",
      "-n",
      "example",
      "ucmdb-prod",
      "cms-probe1-secret",
      "make",
      "sure",
      "functioning",
      "before",
      "switching",
      "succeeded.",
      "all",
      "using.",
      "my-values.yaml",
      "file",
      "my-values-probe.yaml",
      "probe1-values.yaml",
      "probe2-values.yaml",
      "files.",
      "don",
      "remember",
      "path",
      "custom",
      "create",
      "copy",
      "current",
      "directory",
      "helm",
      "values",
      "want",
      "new",
      "steps",
      "prepare",
      "database.",
      "databases",
      "initialize",
      "during",
      "installation.",
      "table",
      "shows",
      "information",
      "prepared",
      "components.",
      "service",
      "db",
      "user",
      "name",
      "schema",
      "server",
      "idm",
      "apls",
      "flow",
      "probe",
      "postgresql",
      "passwords",
      "same",
      "ones"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Restart a service",
    "content": "In some cases, you might need to restart a given service. For example, after making a configuration change, a service must be restarted for the change to take effect. Restart the ucmdb service To restart the ucmdb service, follow these steps: Run the following command on a control plane node (embedded Kubernetes) or the bastion node (managed Kubernetes): kubectl scale statefulset itom-ucmdb -n <namespace> --replicas=0 Run the following command on a control plane node (embedded Kubernetes) or the bastion node (managed Kubernetes): kubectl scale statefulset itom-ucmdb -n <namespace> --replicas=<default replica number> The value of<default replica number> depends on the UD/UCMDB deployment size: Large deployment: 3 Medium or small deployment: 2 Restart other UD/UCMDB services Starting from Kubernetes 1.15, a new command is introduced to support rolling restart a service. In the containerized UD/UCMDB deployment, if you need to restart a service as part of an operation, you can do the foll",
    "url": "rollingrestartservice",
    "filename": "rollingrestartservice",
    "headings": [
      "Restart the ucmdb service",
      "Restart other UD/UCMDB services",
      "Restart Data Flow Probe",
      "Restart UCMDB UI",
      "Restart UCMDB Gateway"
    ],
    "keywords": [
      "1.15",
      "restart",
      "service",
      "ucmdb",
      "ud",
      "services",
      "data",
      "flow",
      "probe",
      "ui",
      "gateway",
      "cases",
      "need",
      "given",
      "service.",
      "example",
      "after",
      "making",
      "configuration",
      "change",
      "restarted",
      "take",
      "effect.",
      "follow",
      "steps",
      "run",
      "following",
      "command",
      "control",
      "plane",
      "node",
      "embedded",
      "kubernetes",
      "bastion",
      "managed",
      "kubectl",
      "scale",
      "statefulset",
      "itom-ucmdb",
      "-n",
      "--replicas",
      "value",
      "depends",
      "deployment",
      "size",
      "large",
      "medium",
      "small",
      "starting",
      "new",
      "introduced",
      "support",
      "rolling",
      "containerized",
      "part",
      "operation",
      "following.",
      "rollout",
      "itom-ucmdb-probe",
      "itom-ucmdb-browser",
      "itom-ucmdb-gateway",
      "related",
      "topics"
    ],
    "language": "en",
    "word_count": 99,
    "importance_score": 5.5,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "restart a service",
    "contentLower": "in some cases, you might need to restart a given service. for example, after making a configuration change, a service must be restarted for the change to take effect. restart the ucmdb service to restart the ucmdb service, follow these steps: run the following command on a control plane node (embedded kubernetes) or the bastion node (managed kubernetes): kubectl scale statefulset itom-ucmdb -n <namespace> --replicas=0 run the following command on a control plane node (embedded kubernetes) or the bastion node (managed kubernetes): kubectl scale statefulset itom-ucmdb -n <namespace> --replicas=<default replica number> the value of<default replica number> depends on the ud/ucmdb deployment size: large deployment: 3 medium or small deployment: 2 restart other ud/ucmdb services starting from kubernetes 1.15, a new command is introduced to support rolling restart a service. in the containerized ud/ucmdb deployment, if you need to restart a service as part of an operation, you can do the foll",
    "keywordsLower": [
      "1.15",
      "restart",
      "service",
      "ucmdb",
      "ud",
      "services",
      "data",
      "flow",
      "probe",
      "ui",
      "gateway",
      "cases",
      "need",
      "given",
      "service.",
      "example",
      "after",
      "making",
      "configuration",
      "change",
      "restarted",
      "take",
      "effect.",
      "follow",
      "steps",
      "run",
      "following",
      "command",
      "control",
      "plane",
      "node",
      "embedded",
      "kubernetes",
      "bastion",
      "managed",
      "kubectl",
      "scale",
      "statefulset",
      "itom-ucmdb",
      "-n",
      "--replicas",
      "value",
      "depends",
      "deployment",
      "size",
      "large",
      "medium",
      "small",
      "starting",
      "new",
      "introduced",
      "support",
      "rolling",
      "containerized",
      "part",
      "operation",
      "following.",
      "rollout",
      "itom-ucmdb-probe",
      "itom-ucmdb-browser",
      "itom-ucmdb-gateway",
      "related",
      "topics"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Tenants",
    "content": "Tenant management enables you to create, edit, deploy, and manage the tenants. There are four types of tenant: Production DEV Internal Trial Related topics How to create and edit a tenant",
    "url": "tenantmgmt",
    "filename": "tenantmgmt",
    "headings": [
      "Related topics"
    ],
    "keywords": [
      "tenants",
      "related",
      "topics",
      "tenant",
      "management",
      "enables",
      "create",
      "edit",
      "deploy",
      "manage",
      "tenants.",
      "there",
      "four",
      "types",
      "production",
      "dev",
      "internal",
      "trial"
    ],
    "language": "en",
    "word_count": 22,
    "importance_score": 2.5,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "tenants",
    "contentLower": "tenant management enables you to create, edit, deploy, and manage the tenants. there are four types of tenant: production dev internal trial related topics how to create and edit a tenant",
    "keywordsLower": [
      "tenants",
      "related",
      "topics",
      "tenant",
      "management",
      "enables",
      "create",
      "edit",
      "deploy",
      "manage",
      "tenants.",
      "there",
      "four",
      "types",
      "production",
      "dev",
      "internal",
      "trial"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Tenant details",
    "content": "The tenant details form in Suite Administration contains the following tabs. General Field Description ID Tenant ID. Name Tenant name. URL The URL to access this tenant. Custom domain The custom fully qualified domain name for this tenant such as mytenant.example.com. By doing this, users no longer need to type the tenant ID in the URL to access the tenant. The custom domain must be at least a third level domain such as mytenant.example.com. In other words, example.com isn't supported. Note: You can identify a tenant by the custom domain, and therefore must be unique and different from the external access host name of the suite (<External_Access_Host>). For detailed procedures, see Configure custom domains for tenants. Type Tenant type. Environment Tenant environment: ProdTestStagingPocRNDUnknownDR Backend type The backend type of the tenant. Default login type Login type: DBLDAPSAMLOAUTH When you select a default login type, the system will use the specified login type for user authen",
    "url": "tenantdetails",
    "filename": "tenantdetails",
    "headings": [
      "General",
      "IdM settings",
      "Users",
      "Service Manager Settings",
      "Licenses",
      "Assign a license",
      "Revoke a license",
      "Shared service",
      "Capability settings",
      "Add the OO capability",
      "Add the DND capability",
      "Add the Cloud Cost Reporting capability",
      "Add the SAM capability",
      "Application settings",
      "File settings",
      "Configuration Management settings",
      "Tuning settings",
      "OData settings",
      "Group members sync settings",
      "Integration Studio settings"
    ],
    "keywords": [
      "mysmserver.com",
      "https://uis.coloryourdata.io:1234",
      "smpgroot.crt",
      "coloryourdata.io",
      "https://<External_Access_Host>/saw/ess?TENANTID=xxxxxxxxx&AUTH=SAML",
      "2020.05",
      "microfocus.net",
      "https://cmsdemo01.microfocus.net:3000/cms-gatewayUCMDB",
      "user.Run",
      "search.Run",
      "limit.The",
      "200.If",
      "myidolserver.com",
      "http://mysmserver.com:13080",
      "https://uis.coloryourdata.io",
      "example.com",
      "store.Key",
      "https://mysmserver.com:13443",
      "tenant",
      "details",
      "general",
      "idm",
      "settings",
      "users",
      "service",
      "manager",
      "licenses",
      "assign",
      "license",
      "revoke",
      "shared",
      "capability",
      "add",
      "oo",
      "dnd",
      "cloud",
      "cost",
      "reporting",
      "sam",
      "application",
      "file",
      "configuration",
      "management",
      "tuning",
      "odata",
      "group",
      "members",
      "sync",
      "integration",
      "studio",
      "optic",
      "switcher",
      "email",
      "operation",
      "history",
      "authorization",
      "migration",
      "form",
      "suite",
      "administration",
      "contains",
      "following",
      "tabs.",
      "field",
      "description",
      "id",
      "id.",
      "name",
      "name.",
      "url",
      "access",
      "tenant.",
      "custom",
      "domain",
      "fully",
      "qualified",
      "such",
      "mytenant.example.com.",
      "doing",
      "longer",
      "need",
      "type",
      "least",
      "third",
      "level",
      "words",
      "isn",
      "supported.",
      "note",
      "identify",
      "therefore",
      "unique",
      "different",
      "external",
      "host",
      "detailed",
      "procedures",
      "see",
      "configure",
      "domains"
    ],
    "language": "en",
    "word_count": 104,
    "importance_score": 6.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "tenant details",
    "contentLower": "the tenant details form in suite administration contains the following tabs. general field description id tenant id. name tenant name. url the url to access this tenant. custom domain the custom fully qualified domain name for this tenant such as mytenant.example.com. by doing this, users no longer need to type the tenant id in the url to access the tenant. the custom domain must be at least a third level domain such as mytenant.example.com. in other words, example.com isn't supported. note: you can identify a tenant by the custom domain, and therefore must be unique and different from the external access host name of the suite (<external_access_host>). for detailed procedures, see configure custom domains for tenants. type tenant type. environment tenant environment: prodteststagingpocrndunknowndr backend type the backend type of the tenant. default login type login type: dbldapsamloauth when you select a default login type, the system will use the specified login type for user authen",
    "keywordsLower": [
      "mysmserver.com",
      "https://uis.coloryourdata.io:1234",
      "smpgroot.crt",
      "coloryourdata.io",
      "https://<external_access_host>/saw/ess?tenantid=xxxxxxxxx&auth=saml",
      "2020.05",
      "microfocus.net",
      "https://cmsdemo01.microfocus.net:3000/cms-gatewayucmdb",
      "user.run",
      "search.run",
      "limit.the",
      "200.if",
      "myidolserver.com",
      "http://mysmserver.com:13080",
      "https://uis.coloryourdata.io",
      "example.com",
      "store.key",
      "https://mysmserver.com:13443",
      "tenant",
      "details",
      "general",
      "idm",
      "settings",
      "users",
      "service",
      "manager",
      "licenses",
      "assign",
      "license",
      "revoke",
      "shared",
      "capability",
      "add",
      "oo",
      "dnd",
      "cloud",
      "cost",
      "reporting",
      "sam",
      "application",
      "file",
      "configuration",
      "management",
      "tuning",
      "odata",
      "group",
      "members",
      "sync",
      "integration",
      "studio",
      "optic",
      "switcher",
      "email",
      "operation",
      "history",
      "authorization",
      "migration",
      "form",
      "suite",
      "administration",
      "contains",
      "following",
      "tabs.",
      "field",
      "description",
      "id",
      "id.",
      "name",
      "name.",
      "url",
      "access",
      "tenant.",
      "custom",
      "domain",
      "fully",
      "qualified",
      "such",
      "mytenant.example.com.",
      "doing",
      "longer",
      "need",
      "type",
      "least",
      "third",
      "level",
      "words",
      "isn",
      "supported.",
      "note",
      "identify",
      "therefore",
      "unique",
      "different",
      "external",
      "host",
      "detailed",
      "procedures",
      "see",
      "configure",
      "domains"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Self-service password reset for DB users",
    "content": "The self service password reset feature enables users of the DB authentication type to reset their passwords on their own, by clicking the Forgot your password? link on the login page. Note This feature works only for users that have their authentication type in Suite Administration set to \"DB\". This feature doesn't unlock or activate users. A locked or inactive user is still locked or inactive after a password reset. To reset your password: Open your Service Management login URL in the browser. Enter your user name, and then click the Forgot your password? link on the login page. Enter the email address configured for your user account in the system and then click Send Code. If you enter another email address, the system doesn't send a code to that email address. Check your mailbox for the password reset email. Since this is an automated mail, check your junk and spam folders if you don’t appear to receive the email. This is a single use code and is valid for a period as specified in ",
    "url": "selfservicepasswordreset4dbusers",
    "filename": "selfservicepasswordreset4dbusers",
    "headings": [],
    "keywords": [
      "self-service",
      "password",
      "reset",
      "db",
      "users",
      "self",
      "service",
      "feature",
      "enables",
      "authentication",
      "type",
      "passwords",
      "own",
      "clicking",
      "forgot",
      "link",
      "login",
      "page.",
      "note",
      "works",
      "suite",
      "administration",
      "set",
      "doesn",
      "unlock",
      "activate",
      "users.",
      "locked",
      "inactive",
      "user",
      "still",
      "after",
      "reset.",
      "open",
      "management",
      "url",
      "browser.",
      "enter",
      "name",
      "click",
      "email",
      "address",
      "configured",
      "account",
      "system",
      "send",
      "code.",
      "another",
      "code",
      "address.",
      "check",
      "mailbox",
      "email.",
      "since",
      "automated",
      "mail",
      "junk",
      "spam",
      "folders",
      "don",
      "appear",
      "receive",
      "single",
      "valid",
      "period",
      "specified",
      "ok.",
      "new",
      "confirm",
      "it.",
      "adhere",
      "policy",
      "administrator",
      "configured.",
      "see",
      "configure",
      "idm",
      "admin",
      "portal.",
      "entered",
      "screen",
      "looks",
      "like",
      "below.",
      "submit.",
      "now",
      "log",
      "password."
    ],
    "language": "en",
    "word_count": 109,
    "importance_score": 2.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "self-service password reset for db users",
    "contentLower": "the self service password reset feature enables users of the db authentication type to reset their passwords on their own, by clicking the forgot your password? link on the login page. note this feature works only for users that have their authentication type in suite administration set to \"db\". this feature doesn't unlock or activate users. a locked or inactive user is still locked or inactive after a password reset. to reset your password: open your service management login url in the browser. enter your user name, and then click the forgot your password? link on the login page. enter the email address configured for your user account in the system and then click send code. if you enter another email address, the system doesn't send a code to that email address. check your mailbox for the password reset email. since this is an automated mail, check your junk and spam folders if you don’t appear to receive the email. this is a single use code and is valid for a period as specified in ",
    "keywordsLower": [
      "self-service",
      "password",
      "reset",
      "db",
      "users",
      "self",
      "service",
      "feature",
      "enables",
      "authentication",
      "type",
      "passwords",
      "own",
      "clicking",
      "forgot",
      "link",
      "login",
      "page.",
      "note",
      "works",
      "suite",
      "administration",
      "set",
      "doesn",
      "unlock",
      "activate",
      "users.",
      "locked",
      "inactive",
      "user",
      "still",
      "after",
      "reset.",
      "open",
      "management",
      "url",
      "browser.",
      "enter",
      "name",
      "click",
      "email",
      "address",
      "configured",
      "account",
      "system",
      "send",
      "code.",
      "another",
      "code",
      "address.",
      "check",
      "mailbox",
      "email.",
      "since",
      "automated",
      "mail",
      "junk",
      "spam",
      "folders",
      "don",
      "appear",
      "receive",
      "single",
      "valid",
      "period",
      "specified",
      "ok.",
      "new",
      "confirm",
      "it.",
      "adhere",
      "policy",
      "administrator",
      "configured.",
      "see",
      "configure",
      "idm",
      "admin",
      "portal.",
      "entered",
      "screen",
      "looks",
      "like",
      "below.",
      "submit.",
      "now",
      "log",
      "password."
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Set maximum concurrent user sessions per DB user in IdM Admin Portal",
    "content": "In the suite IdM Admin Portal, DB users are either of the Regular type or System type, which are account users or integration users in Suite Administration, respectively. The suite IdM has a setting to control the maximum concurrent sessions per DB user of the Regular type. Note This setting doesn't take effect on DB users of the System type in IdM. In other words, this setting has no effect on integration users defined in Suite Administration and hence won't break integrations that use an integration user. Log in to Suite Administration as suite-admin: https://<External Access Host>/bo. Click Tenants and then open a tenant. Click the IdM Settings tab to open the IdM Admin Portal. Click Customization on the left side navigation pane, and then select the AUTHENTICATION tab. Set the Concurrent Session Maximum value. The default value is -1, which means there's no limit on the number of concurrent sessions per DB user. For best security, it's recommended to not allow multiple sessions for",
    "url": "setmaxconcurrentusersessionsperdbuser",
    "filename": "setmaxconcurrentusersessionsperdbuser",
    "headings": [],
    "keywords": [
      "https://<External",
      "set",
      "maximum",
      "concurrent",
      "user",
      "sessions",
      "per",
      "db",
      "idm",
      "admin",
      "portal",
      "suite",
      "users",
      "either",
      "regular",
      "type",
      "system",
      "account",
      "integration",
      "administration",
      "respectively.",
      "setting",
      "control",
      "type.",
      "note",
      "doesn",
      "take",
      "effect",
      "idm.",
      "words",
      "defined",
      "hence",
      "won",
      "break",
      "integrations",
      "user.",
      "log",
      "suite-admin",
      "https",
      "bo.",
      "click",
      "tenants",
      "open",
      "tenant.",
      "settings",
      "tab",
      "portal.",
      "customization",
      "left",
      "side",
      "navigation",
      "pane",
      "select",
      "authentication",
      "tab.",
      "session",
      "value.",
      "default",
      "value",
      "-1",
      "means",
      "there",
      "limit",
      "number",
      "best",
      "security",
      "recommended",
      "allow",
      "multiple",
      "single",
      "locations.",
      "1.",
      "save."
    ],
    "language": "en",
    "word_count": 119,
    "importance_score": 1.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "set maximum concurrent user sessions per db user in idm admin portal",
    "contentLower": "in the suite idm admin portal, db users are either of the regular type or system type, which are account users or integration users in suite administration, respectively. the suite idm has a setting to control the maximum concurrent sessions per db user of the regular type. note this setting doesn't take effect on db users of the system type in idm. in other words, this setting has no effect on integration users defined in suite administration and hence won't break integrations that use an integration user. log in to suite administration as suite-admin: https://<external access host>/bo. click tenants and then open a tenant. click the idm settings tab to open the idm admin portal. click customization on the left side navigation pane, and then select the authentication tab. set the concurrent session maximum value. the default value is -1, which means there's no limit on the number of concurrent sessions per db user. for best security, it's recommended to not allow multiple sessions for",
    "keywordsLower": [
      "https://<external",
      "set",
      "maximum",
      "concurrent",
      "user",
      "sessions",
      "per",
      "db",
      "idm",
      "admin",
      "portal",
      "suite",
      "users",
      "either",
      "regular",
      "type",
      "system",
      "account",
      "integration",
      "administration",
      "respectively.",
      "setting",
      "control",
      "type.",
      "note",
      "doesn",
      "take",
      "effect",
      "idm.",
      "words",
      "defined",
      "hence",
      "won",
      "break",
      "integrations",
      "user.",
      "log",
      "suite-admin",
      "https",
      "bo.",
      "click",
      "tenants",
      "open",
      "tenant.",
      "settings",
      "tab",
      "portal.",
      "customization",
      "left",
      "side",
      "navigation",
      "pane",
      "select",
      "authentication",
      "tab.",
      "session",
      "value.",
      "default",
      "value",
      "-1",
      "means",
      "there",
      "limit",
      "number",
      "best",
      "security",
      "recommended",
      "allow",
      "multiple",
      "single",
      "locations.",
      "1.",
      "save."
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Renew IdM SAML SSO certificate",
    "content": "The validity period of the IdM SAML certificate for SAML Identity Provider (IDP) is 1 year by default. You can check the validity of this certificate and renew the certificate to ensure the use of SAML authentication in the portal. Check the validity of the IdM SAML SSO certificate Download the IdM SAML metadata. To do this, visit the following URL: https://<external_access_host_FQDN>:<PORT>/idm-service/saml/metadata For example: https://exampleVM.company.net/idm-service/saml/metadata Open the downloaded file, and then copy the text between the <ds:X509Certificate> and </ds:X509Certificate> tags to a new, empty file. Save the file with a .crt suffix. For example, save the file as certCheck.crt. Open the file to view the validity dates of the certificate. Renew the IdM SAML SSO certificate Use one of the following methods. Method 1: Renew the certificate from IdM Admin Portal If you used method 2 previously, you need to remove or rename the <config-volume>/certificate/ca-trust/samlKeyst",
    "url": "renewsamlcertificate",
    "filename": "renewsamlcertificate",
    "headings": [
      "Check the validity of the IdM SAML SSO certificate",
      "Renew the IdM SAML SSO certificate",
      "Method 1: Renew the certificate from IdM Admin Portal",
      "Method 2: Renew the certificate from the backend"
    ],
    "keywords": [
      "certCheck.crt",
      "https://<EXTERNAL_ACCESS_HOST>/idm-service/saml/metadata",
      "https://<host>/idm-admin",
      "https://exampleVM.company.net/idm-service/saml/metadata",
      "https://<external_access_host_FQDN>/idm-service/saml/metadata",
      "idm_saml_metadata.xml",
      "samlKeystore.jks",
      "company.net",
      "spring_saml_metadata.xml",
      "https://<external_access_host_FQDN>:<PORT>/idm-service/saml/metadata",
      "renew",
      "idm",
      "saml",
      "sso",
      "certificate",
      "check",
      "validity",
      "method",
      "admin",
      "portal",
      "backend",
      "period",
      "identity",
      "provider",
      "idp",
      "year",
      "default.",
      "ensure",
      "authentication",
      "portal.",
      "download",
      "metadata.",
      "visit",
      "following",
      "url",
      "https",
      "idm-service",
      "metadata",
      "example",
      "examplevm.company.net",
      "open",
      "downloaded",
      "file",
      "copy",
      "text",
      "between",
      "tags",
      "new",
      "empty",
      "file.",
      "save",
      ".crt",
      "suffix.",
      "certcheck.crt.",
      "view",
      "dates",
      "certificate.",
      "one",
      "methods.",
      "previously",
      "need",
      "remove",
      "rename",
      "ca-trust",
      "first",
      "before",
      "1.",
      "perform",
      "steps",
      "log",
      "idm-admin",
      "suite",
      "admin.",
      "system",
      "settings",
      "click",
      "under",
      "update",
      "enter",
      "display",
      "name.",
      "set",
      "uploading.",
      "drag",
      "upload.",
      "choose",
      "save.",
      "privatekey",
      "private",
      "key.",
      "restart",
      "idm.",
      "run",
      "commands",
      "pods",
      "any",
      "control",
      "plane",
      "nodes.",
      "kubectl"
    ],
    "language": "en",
    "word_count": 97,
    "importance_score": 5.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "renew idm saml sso certificate",
    "contentLower": "the validity period of the idm saml certificate for saml identity provider (idp) is 1 year by default. you can check the validity of this certificate and renew the certificate to ensure the use of saml authentication in the portal. check the validity of the idm saml sso certificate download the idm saml metadata. to do this, visit the following url: https://<external_access_host_fqdn>:<port>/idm-service/saml/metadata for example: https://examplevm.company.net/idm-service/saml/metadata open the downloaded file, and then copy the text between the <ds:x509certificate> and </ds:x509certificate> tags to a new, empty file. save the file with a .crt suffix. for example, save the file as certcheck.crt. open the file to view the validity dates of the certificate. renew the idm saml sso certificate use one of the following methods. method 1: renew the certificate from idm admin portal if you used method 2 previously, you need to remove or rename the <config-volume>/certificate/ca-trust/samlkeyst",
    "keywordsLower": [
      "certcheck.crt",
      "https://<external_access_host>/idm-service/saml/metadata",
      "https://<host>/idm-admin",
      "https://examplevm.company.net/idm-service/saml/metadata",
      "https://<external_access_host_fqdn>/idm-service/saml/metadata",
      "idm_saml_metadata.xml",
      "samlkeystore.jks",
      "company.net",
      "spring_saml_metadata.xml",
      "https://<external_access_host_fqdn>:<port>/idm-service/saml/metadata",
      "renew",
      "idm",
      "saml",
      "sso",
      "certificate",
      "check",
      "validity",
      "method",
      "admin",
      "portal",
      "backend",
      "period",
      "identity",
      "provider",
      "idp",
      "year",
      "default.",
      "ensure",
      "authentication",
      "portal.",
      "download",
      "metadata.",
      "visit",
      "following",
      "url",
      "https",
      "idm-service",
      "metadata",
      "example",
      "examplevm.company.net",
      "open",
      "downloaded",
      "file",
      "copy",
      "text",
      "between",
      "tags",
      "new",
      "empty",
      "file.",
      "save",
      ".crt",
      "suffix.",
      "certcheck.crt.",
      "view",
      "dates",
      "certificate.",
      "one",
      "methods.",
      "previously",
      "need",
      "remove",
      "rename",
      "ca-trust",
      "first",
      "before",
      "1.",
      "perform",
      "steps",
      "log",
      "idm-admin",
      "suite",
      "admin.",
      "system",
      "settings",
      "click",
      "under",
      "update",
      "enter",
      "display",
      "name.",
      "set",
      "uploading.",
      "drag",
      "upload.",
      "choose",
      "save.",
      "privatekey",
      "private",
      "key.",
      "restart",
      "idm.",
      "run",
      "commands",
      "pods",
      "any",
      "control",
      "plane",
      "nodes.",
      "kubectl"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Suite Administration for shared service providers",
    "content": "Shared service providers can use Suite Administration to set up a multi-tenant (MT) environment to manage their business units' and clients' request and incident records in one user interface via an MT console. Each business unit and client can use its own tenant while the MT console displays all data together in one consolidated view. Set up MT environment To set up the MT environment, complete the following tasks as a suite admin user or a shared service admin user: Prepare provider tenants Prepare a provider tenant with these steps: Create an account of Shared service type being Provider. This account hosts the shared service admin users and agents. Add users to the provider account. Four roles are available for users, among which: Shared service admin users are assigned with MT Administrator role in Service Management automatically. Shared service agents are assigned with MT Agent role in Service Management automatically. Create a provider tenant under the created provider account,",
    "url": "sharedserviceprovider",
    "filename": "sharedserviceprovider",
    "headings": [
      "Set up MT environment",
      "Prepare provider tenants",
      "Prepare managed tenants",
      "Add managed tenants to provider tenants",
      "Roles and permissions for provider and managed tenants",
      "Limitations",
      "Related topics"
    ],
    "keywords": [
      "suite",
      "administration",
      "shared",
      "service",
      "providers",
      "set",
      "mt",
      "environment",
      "prepare",
      "provider",
      "tenants",
      "managed",
      "add",
      "roles",
      "permissions",
      "limitations",
      "related",
      "topics",
      "multi-tenant",
      "manage",
      "business",
      "units",
      "clients",
      "request",
      "incident",
      "records",
      "one",
      "user",
      "interface",
      "via",
      "console.",
      "unit",
      "client",
      "own",
      "tenant",
      "while",
      "console",
      "displays",
      "all",
      "data",
      "together",
      "consolidated",
      "view.",
      "complete",
      "following",
      "tasks",
      "admin",
      "steps",
      "create",
      "account",
      "type",
      "provider.",
      "hosts",
      "users",
      "agents.",
      "account.",
      "four",
      "available",
      "among",
      "assigned",
      "administrator",
      "role",
      "management",
      "automatically.",
      "agents",
      "agent",
      "under",
      "created",
      "assign",
      "license",
      "deploy",
      "tenant.",
      "managed.",
      "after",
      "deployed",
      "go",
      "back",
      "click",
      "tab",
      "note",
      "updates",
      "synchronized",
      "direction.",
      "panel",
      "remove",
      "selected",
      "right",
      "arrow",
      "remove.",
      "access",
      "need",
      "first",
      "control",
      "list",
      "acl",
      "grant",
      "before",
      "information",
      "see",
      "control."
    ],
    "language": "en",
    "word_count": 115,
    "importance_score": 5.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "suite administration for shared service providers",
    "contentLower": "shared service providers can use suite administration to set up a multi-tenant (mt) environment to manage their business units' and clients' request and incident records in one user interface via an mt console. each business unit and client can use its own tenant while the mt console displays all data together in one consolidated view. set up mt environment to set up the mt environment, complete the following tasks as a suite admin user or a shared service admin user: prepare provider tenants prepare a provider tenant with these steps: create an account of shared service type being provider. this account hosts the shared service admin users and agents. add users to the provider account. four roles are available for users, among which: shared service admin users are assigned with mt administrator role in service management automatically. shared service agents are assigned with mt agent role in service management automatically. create a provider tenant under the created provider account,",
    "keywordsLower": [
      "suite",
      "administration",
      "shared",
      "service",
      "providers",
      "set",
      "mt",
      "environment",
      "prepare",
      "provider",
      "tenants",
      "managed",
      "add",
      "roles",
      "permissions",
      "limitations",
      "related",
      "topics",
      "multi-tenant",
      "manage",
      "business",
      "units",
      "clients",
      "request",
      "incident",
      "records",
      "one",
      "user",
      "interface",
      "via",
      "console.",
      "unit",
      "client",
      "own",
      "tenant",
      "while",
      "console",
      "displays",
      "all",
      "data",
      "together",
      "consolidated",
      "view.",
      "complete",
      "following",
      "tasks",
      "admin",
      "steps",
      "create",
      "account",
      "type",
      "provider.",
      "hosts",
      "users",
      "agents.",
      "account.",
      "four",
      "available",
      "among",
      "assigned",
      "administrator",
      "role",
      "management",
      "automatically.",
      "agents",
      "agent",
      "under",
      "created",
      "assign",
      "license",
      "deploy",
      "tenant.",
      "managed.",
      "after",
      "deployed",
      "go",
      "back",
      "click",
      "tab",
      "note",
      "updates",
      "synchronized",
      "direction.",
      "panel",
      "remove",
      "selected",
      "right",
      "arrow",
      "remove.",
      "access",
      "need",
      "first",
      "control",
      "list",
      "acl",
      "grant",
      "before",
      "information",
      "see",
      "control."
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Service Management licenses",
    "content": "You can assign a trial license or a license key to the tenant. Follow the below steps to create a trial license or upload a license and assign the license to a tenant. You can't assign both a Service Management license (Express or Premium) and an Asset Management license to the same tenant. If you try to do this, an error occurs. Create a trial license You can create a trial license manually. From the main menu, click Licenses. Click New. Complete the form with the required information. See the License details section below. Click Save. Upload a license key You can upload a production, non-production, or evaluation license key to the suite for a newly installed or renewed license. From the main menu, select Licenses. Click Upload licenses on the toolbar. Select the license mode. Click Choose File to select your license file. Click Import. You can get a preview of license information and licensable features. Click OK. All suite license files can be uploaded here, supported formats inclu",
    "url": "createlicense",
    "filename": "createlicense",
    "headings": [
      "Create a trial license",
      "Upload a license key",
      "Edit a license",
      "License details",
      "General tab",
      "Allocation tab",
      "License status",
      "Add to license pool",
      "Synchronize license information from AutoPass",
      "Delete a license",
      "Assign and revoke a license for a tenant",
      "Related topics"
    ],
    "keywords": [
      "https://<External_Access_Host>/autopass",
      "service",
      "management",
      "licenses",
      "create",
      "trial",
      "license",
      "upload",
      "key",
      "edit",
      "details",
      "general",
      "tab",
      "allocation",
      "status",
      "add",
      "pool",
      "synchronize",
      "information",
      "autopass",
      "delete",
      "assign",
      "revoke",
      "tenant",
      "related",
      "topics",
      "tenant.",
      "follow",
      "below",
      "steps",
      "both",
      "express",
      "premium",
      "asset",
      "same",
      "try",
      "error",
      "occurs.",
      "manually.",
      "main",
      "menu",
      "click",
      "licenses.",
      "new.",
      "complete",
      "form",
      "required",
      "information.",
      "see",
      "section",
      "below.",
      "save.",
      "production",
      "non-production",
      "evaluation",
      "suite",
      "newly",
      "installed",
      "renewed",
      "license.",
      "select",
      "toolbar.",
      "mode.",
      "choose",
      "file",
      "file.",
      "import.",
      "get",
      "preview",
      "licensable",
      "features.",
      "ok.",
      "all",
      "files",
      "uploaded",
      "here",
      "supported",
      "formats",
      "include",
      "ov4key",
      "xml",
      "dat.",
      "currently",
      "cloud",
      "managed",
      "administration",
      "hence",
      "shown",
      "grid",
      "product",
      "component",
      "apls",
      "retrieve",
      "install",
      "features",
      "apls.",
      "looks",
      "like",
      "following",
      "screenshot."
    ],
    "language": "en",
    "word_count": 110,
    "importance_score": 6.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "service management licenses",
    "contentLower": "you can assign a trial license or a license key to the tenant. follow the below steps to create a trial license or upload a license and assign the license to a tenant. you can't assign both a service management license (express or premium) and an asset management license to the same tenant. if you try to do this, an error occurs. create a trial license you can create a trial license manually. from the main menu, click licenses. click new. complete the form with the required information. see the license details section below. click save. upload a license key you can upload a production, non-production, or evaluation license key to the suite for a newly installed or renewed license. from the main menu, select licenses. click upload licenses on the toolbar. select the license mode. click choose file to select your license file. click import. you can get a preview of license information and licensable features. click ok. all suite license files can be uploaded here, supported formats inclu",
    "keywordsLower": [
      "https://<external_access_host>/autopass",
      "service",
      "management",
      "licenses",
      "create",
      "trial",
      "license",
      "upload",
      "key",
      "edit",
      "details",
      "general",
      "tab",
      "allocation",
      "status",
      "add",
      "pool",
      "synchronize",
      "information",
      "autopass",
      "delete",
      "assign",
      "revoke",
      "tenant",
      "related",
      "topics",
      "tenant.",
      "follow",
      "below",
      "steps",
      "both",
      "express",
      "premium",
      "asset",
      "same",
      "try",
      "error",
      "occurs.",
      "manually.",
      "main",
      "menu",
      "click",
      "licenses.",
      "new.",
      "complete",
      "form",
      "required",
      "information.",
      "see",
      "section",
      "below.",
      "save.",
      "production",
      "non-production",
      "evaluation",
      "suite",
      "newly",
      "installed",
      "renewed",
      "license.",
      "select",
      "toolbar.",
      "mode.",
      "choose",
      "file",
      "file.",
      "import.",
      "get",
      "preview",
      "licensable",
      "features.",
      "ok.",
      "all",
      "files",
      "uploaded",
      "here",
      "supported",
      "formats",
      "include",
      "ov4key",
      "xml",
      "dat.",
      "currently",
      "cloud",
      "managed",
      "administration",
      "hence",
      "shown",
      "grid",
      "product",
      "component",
      "apls",
      "retrieve",
      "install",
      "features",
      "apls.",
      "looks",
      "like",
      "following",
      "screenshot."
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Session timeout configuration",
    "content": "When a user successfully logs in to the UI (such as the Suite Administration Portal, Service Portal, or Agent interface), the backend services produce two tokens, which are stored in the client browser's cookies. Any requests from the UI to backend services need to carry the two tokens. These two tokens are the LWSSO token and the SMAX_AUTH_TOKEN token. The system uses the LWSSO token when integrated with other OpenText products based on lightweight SSO, or when running in mixed mode (SMA-SM mode). If the LWSSO token becomes invalid after a certain amount of time, the integration part will not work. For example, the 3rd party data or page will not be retrieved or displayed successfully. In mixed mode, data will not be retrieved successfully from Service Manager if the LWSSO token has expired. If the SMAX_AUTH_TOKEN becomes invalid, users must log in again for new tokens to continue operating on the system. The amount of time the two tokens are valid before they expire is controlled by ",
    "url": "timeout",
    "filename": "timeout",
    "headings": [
      "LWSSO token",
      "SMAX AUTH TOKEN",
      "lwssoConfig.expirationPeriod(in minutes)",
      "How to change it in UI",
      "Data in ConfigMap",
      "idm.token.lifetime.minutes (in minutes)",
      "For end-users, if they have not operated for the period specified by this parameter, their session is timed out, and they have to log in again before they can continue operating on the system.",
      "How to change it in UI",
      "Data in ConfigMap",
      "Recommended configuration",
      "Example",
      "Tips and tricks"
    ],
    "keywords": [
      "0.65",
      "https://<EXTERNAL_ACCESS_HOST>/bo",
      "session",
      "timeout",
      "configuration",
      "lwsso",
      "token",
      "smax",
      "auth",
      "lwssoconfig.expirationperiod",
      "minutes",
      "change",
      "ui",
      "data",
      "configmap",
      "idm.token.lifetime.minutes",
      "end-users",
      "operated",
      "period",
      "specified",
      "parameter",
      "timed",
      "out",
      "log",
      "again",
      "before",
      "continue",
      "operating",
      "system.",
      "recommended",
      "example",
      "tips",
      "tricks",
      "user",
      "successfully",
      "logs",
      "such",
      "suite",
      "administration",
      "portal",
      "service",
      "agent",
      "interface",
      "backend",
      "services",
      "produce",
      "two",
      "tokens",
      "stored",
      "client",
      "browser",
      "cookies.",
      "any",
      "requests",
      "need",
      "carry",
      "tokens.",
      "token.",
      "system",
      "uses",
      "integrated",
      "opentext",
      "products",
      "based",
      "lightweight",
      "sso",
      "running",
      "mixed",
      "mode",
      "sma-sm",
      "becomes",
      "invalid",
      "after",
      "certain",
      "amount",
      "time",
      "integration",
      "part",
      "work.",
      "3rd",
      "party",
      "page",
      "retrieved",
      "displayed",
      "successfully.",
      "manager",
      "expired.",
      "users",
      "new",
      "valid",
      "expire",
      "controlled",
      "specific",
      "parameters.",
      "value",
      "parameters",
      "extend",
      "shorten",
      "lives.",
      "document"
    ],
    "language": "en",
    "word_count": 103,
    "importance_score": 6.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "session timeout configuration",
    "contentLower": "when a user successfully logs in to the ui (such as the suite administration portal, service portal, or agent interface), the backend services produce two tokens, which are stored in the client browser's cookies. any requests from the ui to backend services need to carry the two tokens. these two tokens are the lwsso token and the smax_auth_token token. the system uses the lwsso token when integrated with other opentext products based on lightweight sso, or when running in mixed mode (sma-sm mode). if the lwsso token becomes invalid after a certain amount of time, the integration part will not work. for example, the 3rd party data or page will not be retrieved or displayed successfully. in mixed mode, data will not be retrieved successfully from service manager if the lwsso token has expired. if the smax_auth_token becomes invalid, users must log in again for new tokens to continue operating on the system. the amount of time the two tokens are valid before they expire is controlled by ",
    "keywordsLower": [
      "0.65",
      "https://<external_access_host>/bo",
      "session",
      "timeout",
      "configuration",
      "lwsso",
      "token",
      "smax",
      "auth",
      "lwssoconfig.expirationperiod",
      "minutes",
      "change",
      "ui",
      "data",
      "configmap",
      "idm.token.lifetime.minutes",
      "end-users",
      "operated",
      "period",
      "specified",
      "parameter",
      "timed",
      "out",
      "log",
      "again",
      "before",
      "continue",
      "operating",
      "system.",
      "recommended",
      "example",
      "tips",
      "tricks",
      "user",
      "successfully",
      "logs",
      "such",
      "suite",
      "administration",
      "portal",
      "service",
      "agent",
      "interface",
      "backend",
      "services",
      "produce",
      "two",
      "tokens",
      "stored",
      "client",
      "browser",
      "cookies.",
      "any",
      "requests",
      "need",
      "carry",
      "tokens.",
      "token.",
      "system",
      "uses",
      "integrated",
      "opentext",
      "products",
      "based",
      "lightweight",
      "sso",
      "running",
      "mixed",
      "mode",
      "sma-sm",
      "becomes",
      "invalid",
      "after",
      "certain",
      "amount",
      "time",
      "integration",
      "part",
      "work.",
      "3rd",
      "party",
      "page",
      "retrieved",
      "displayed",
      "successfully.",
      "manager",
      "expired.",
      "users",
      "new",
      "valid",
      "expire",
      "controlled",
      "specific",
      "parameters.",
      "value",
      "parameters",
      "extend",
      "shorten",
      "lives.",
      "document"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Scale out DAH server",
    "content": "Manually scale out the DAH server: If the search performance is slow in the suite system If a response timeout issue occurs when you check the Smart Analytics configuration in Suite Administration to view the status For more information about how to scale out the DAH server smarta-saw-dah in a helm-based deployment, see How to update replicas.",
    "url": "scaleoutdahserver",
    "filename": "scaleoutdahserver",
    "headings": [],
    "keywords": [
      "scale",
      "out",
      "dah",
      "server",
      "manually",
      "search",
      "performance",
      "slow",
      "suite",
      "system",
      "response",
      "timeout",
      "issue",
      "occurs",
      "check",
      "smart",
      "analytics",
      "configuration",
      "administration",
      "view",
      "status",
      "information",
      "about",
      "smarta-saw-dah",
      "helm-based",
      "deployment",
      "see",
      "update",
      "replicas."
    ],
    "language": "en",
    "word_count": 38,
    "importance_score": 2.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "scale out dah server",
    "contentLower": "manually scale out the dah server: if the search performance is slow in the suite system if a response timeout issue occurs when you check the smart analytics configuration in suite administration to view the status for more information about how to scale out the dah server smarta-saw-dah in a helm-based deployment, see how to update replicas.",
    "keywordsLower": [
      "scale",
      "out",
      "dah",
      "server",
      "manually",
      "search",
      "performance",
      "slow",
      "suite",
      "system",
      "response",
      "timeout",
      "issue",
      "occurs",
      "check",
      "smart",
      "analytics",
      "configuration",
      "administration",
      "view",
      "status",
      "information",
      "about",
      "smarta-saw-dah",
      "helm-based",
      "deployment",
      "see",
      "update",
      "replicas."
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Schedule the IDOL index compaction",
    "content": "You can schedule an IDOL index compaction periodically to clean up and optimize IDOL indexing. Log in to the control plane node as root or a sudo user, run the following command to access the target folders: cd <NFS>/itsma/config-volume/idol/<content_group_name>/content/smarta-saw-con-<n>/content.cfg The value of content_group_name can be saw or sawarc. For example, cd /var/vols/itom/itsma/config-volume/idol/saw/content/smarta-saw-con-0/content.cfg Run the vim content.cfg command, and then add a schedule section: [Schedule] Compact= CompactTime= CompactInterval= Compact. Set to True to enable a compacting schedule. CompactTime. Specify the time (hh:mm) when you want the Compact operation to start. CompactInterval. Specify the number of hours that elapse between individual compaction operations. Set to 0 (zero) if you want the operation to take place daily. For example, if you want the compaction to occur daily at midnight, add the following section: [Schedule] Compact=True CompactTime=",
    "url": "scheduleindexcompact",
    "filename": "scheduleindexcompact",
    "headings": [],
    "keywords": [
      "content.cfg",
      "schedule",
      "idol",
      "index",
      "compaction",
      "periodically",
      "clean",
      "optimize",
      "indexing.",
      "log",
      "control",
      "plane",
      "node",
      "root",
      "sudo",
      "user",
      "run",
      "following",
      "command",
      "access",
      "target",
      "folders",
      "cd",
      "itsma",
      "config-volume",
      "content",
      "smarta-saw-con-",
      "value",
      "saw",
      "sawarc.",
      "example",
      "var",
      "vols",
      "itom",
      "smarta-saw-con-0",
      "vim",
      "add",
      "section",
      "compact",
      "compacttime",
      "compactinterval",
      "compact.",
      "set",
      "true",
      "enable",
      "compacting",
      "schedule.",
      "compacttime.",
      "specify",
      "time",
      "hh",
      "mm",
      "want",
      "operation",
      "start.",
      "compactinterval.",
      "number",
      "hours",
      "elapse",
      "between",
      "individual",
      "operations.",
      "zero",
      "take",
      "place",
      "daily.",
      "occur",
      "daily",
      "midnight",
      "00",
      "24",
      "press",
      "esc",
      "enter",
      "wq",
      "save",
      "changes.",
      "need",
      "edit",
      "configuration",
      "files",
      "all",
      "scaled",
      "out",
      "servers",
      "installed",
      "suite",
      "large",
      "profile.",
      "restart",
      "servers.",
      "kubectl",
      "delete",
      "pod",
      "-n"
    ],
    "language": "en",
    "word_count": 105,
    "importance_score": 3.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "schedule the idol index compaction",
    "contentLower": "you can schedule an idol index compaction periodically to clean up and optimize idol indexing. log in to the control plane node as root or a sudo user, run the following command to access the target folders: cd <nfs>/itsma/config-volume/idol/<content_group_name>/content/smarta-saw-con-<n>/content.cfg the value of content_group_name can be saw or sawarc. for example, cd /var/vols/itom/itsma/config-volume/idol/saw/content/smarta-saw-con-0/content.cfg run the vim content.cfg command, and then add a schedule section: [schedule] compact= compacttime= compactinterval= compact. set to true to enable a compacting schedule. compacttime. specify the time (hh:mm) when you want the compact operation to start. compactinterval. specify the number of hours that elapse between individual compaction operations. set to 0 (zero) if you want the operation to take place daily. for example, if you want the compaction to occur daily at midnight, add the following section: [schedule] compact=true compacttime=",
    "keywordsLower": [
      "content.cfg",
      "schedule",
      "idol",
      "index",
      "compaction",
      "periodically",
      "clean",
      "optimize",
      "indexing.",
      "log",
      "control",
      "plane",
      "node",
      "root",
      "sudo",
      "user",
      "run",
      "following",
      "command",
      "access",
      "target",
      "folders",
      "cd",
      "itsma",
      "config-volume",
      "content",
      "smarta-saw-con-",
      "value",
      "saw",
      "sawarc.",
      "example",
      "var",
      "vols",
      "itom",
      "smarta-saw-con-0",
      "vim",
      "add",
      "section",
      "compact",
      "compacttime",
      "compactinterval",
      "compact.",
      "set",
      "true",
      "enable",
      "compacting",
      "schedule.",
      "compacttime.",
      "specify",
      "time",
      "hh",
      "mm",
      "want",
      "operation",
      "start.",
      "compactinterval.",
      "number",
      "hours",
      "elapse",
      "between",
      "individual",
      "operations.",
      "zero",
      "take",
      "place",
      "daily.",
      "occur",
      "daily",
      "midnight",
      "00",
      "24",
      "press",
      "esc",
      "enter",
      "wq",
      "save",
      "changes.",
      "need",
      "edit",
      "configuration",
      "files",
      "all",
      "scaled",
      "out",
      "servers",
      "installed",
      "suite",
      "large",
      "profile.",
      "restart",
      "servers.",
      "kubectl",
      "delete",
      "pod",
      "-n"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Studio",
    "content": "Studio enables a tenant admin to manage workflows for record types. This includes creating custom record types, defining and editing a record type's fields, forms, business rules, processes and notifications, as well as importing data and defining custom actions for the record type. The following tabs are available: Fields. The fields of a record are derived from the metadata for the record type. Forms. There are out-of-the-box forms defined for each record type. The forms are used for different purposes. For example, the New Incident form is used to create an incident in Incident Management. Processes and Rules. A workflow service provides a consistent way for applications to define and run business logic for their records. A workflow for a record contains processes, which are broken down into metaphases, and further into phases. The passage from one phase into another is called a transition. The business logic of a record's workflow is established by business rules. Notifications. No",
    "url": "records",
    "filename": "records",
    "headings": [
      "Related topics"
    ],
    "keywords": [
      "studio",
      "related",
      "topics",
      "enables",
      "tenant",
      "admin",
      "manage",
      "workflows",
      "record",
      "types.",
      "includes",
      "creating",
      "custom",
      "types",
      "defining",
      "editing",
      "type",
      "fields",
      "forms",
      "business",
      "rules",
      "processes",
      "notifications",
      "well",
      "importing",
      "data",
      "actions",
      "type.",
      "following",
      "tabs",
      "available",
      "fields.",
      "derived",
      "metadata",
      "forms.",
      "there",
      "out-of-the-box",
      "defined",
      "different",
      "purposes.",
      "example",
      "new",
      "incident",
      "form",
      "create",
      "management.",
      "rules.",
      "workflow",
      "service",
      "provides",
      "consistent",
      "way",
      "applications",
      "define",
      "run",
      "logic",
      "records.",
      "contains",
      "broken",
      "metaphases",
      "further",
      "phases.",
      "passage",
      "one",
      "phase",
      "another",
      "called",
      "transition.",
      "established",
      "notifications.",
      "notification",
      "templates",
      "pre-formatted",
      "email",
      "messages",
      "edit.",
      "configure",
      "sent",
      "relevant",
      "recipients",
      "specific",
      "points",
      "workflow.",
      "approval",
      "definitions.",
      "implementing",
      "certain",
      "changes",
      "approvals",
      "granted",
      "phases",
      "before",
      "moving",
      "next",
      "phase.",
      "definitions",
      "tab",
      "article",
      "change",
      "idea"
    ],
    "language": "en",
    "word_count": 97,
    "importance_score": 3.5,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "studio",
    "contentLower": "studio enables a tenant admin to manage workflows for record types. this includes creating custom record types, defining and editing a record type's fields, forms, business rules, processes and notifications, as well as importing data and defining custom actions for the record type. the following tabs are available: fields. the fields of a record are derived from the metadata for the record type. forms. there are out-of-the-box forms defined for each record type. the forms are used for different purposes. for example, the new incident form is used to create an incident in incident management. processes and rules. a workflow service provides a consistent way for applications to define and run business logic for their records. a workflow for a record contains processes, which are broken down into metaphases, and further into phases. the passage from one phase into another is called a transition. the business logic of a record's workflow is established by business rules. notifications. no",
    "keywordsLower": [
      "studio",
      "related",
      "topics",
      "enables",
      "tenant",
      "admin",
      "manage",
      "workflows",
      "record",
      "types.",
      "includes",
      "creating",
      "custom",
      "types",
      "defining",
      "editing",
      "type",
      "fields",
      "forms",
      "business",
      "rules",
      "processes",
      "notifications",
      "well",
      "importing",
      "data",
      "actions",
      "type.",
      "following",
      "tabs",
      "available",
      "fields.",
      "derived",
      "metadata",
      "forms.",
      "there",
      "out-of-the-box",
      "defined",
      "different",
      "purposes.",
      "example",
      "new",
      "incident",
      "form",
      "create",
      "management.",
      "rules.",
      "workflow",
      "service",
      "provides",
      "consistent",
      "way",
      "applications",
      "define",
      "run",
      "logic",
      "records.",
      "contains",
      "broken",
      "metaphases",
      "further",
      "phases.",
      "passage",
      "one",
      "phase",
      "another",
      "called",
      "transition.",
      "established",
      "notifications.",
      "notification",
      "templates",
      "pre-formatted",
      "email",
      "messages",
      "edit.",
      "configure",
      "sent",
      "relevant",
      "recipients",
      "specific",
      "points",
      "workflow.",
      "approval",
      "definitions.",
      "implementing",
      "certain",
      "changes",
      "approvals",
      "granted",
      "phases",
      "before",
      "moving",
      "next",
      "phase.",
      "definitions",
      "tab",
      "article",
      "change",
      "idea"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Studio business rules",
    "content": "Business rules are the building blocks from which the business logic of a workflow is constructed. You can define business rules for records, processes, metaphases, phases, and transitions. The following categories of business rules are available: Action rules. Rules that initiate an action, such as modifying data or sending an email. Validation rules. Rules that validate the data in a field. Rendering rules. Rules that govern the appearance of the user interface. Field selection rules. Rules that control the permitted data in the user interface. For each rule defined, there is also an Include condition option, which enables you to define a condition that must be satisfied for the rule to be run. Some out-of-the-box business rules are provided in the existing workflows, which you can edit. You can also define new business rules. For more information about adding a business rule, see How to add a business rule. Defining business rules in a workflow Business rules can be defined at each ",
    "url": "embizrules",
    "filename": "embizrules",
    "headings": [
      "Defining business rules in a workflow",
      "Business rule properties",
      "Business rule syntax",
      "Process events",
      "Process events order",
      "Business rule execution order",
      "Special rules",
      "Related topics"
    ],
    "keywords": [
      "studio",
      "business",
      "rules",
      "defining",
      "workflow",
      "rule",
      "properties",
      "syntax",
      "process",
      "events",
      "order",
      "execution",
      "special",
      "related",
      "topics",
      "building",
      "blocks",
      "logic",
      "constructed.",
      "define",
      "records",
      "processes",
      "metaphases",
      "phases",
      "transitions.",
      "following",
      "categories",
      "available",
      "action",
      "rules.",
      "initiate",
      "such",
      "modifying",
      "data",
      "sending",
      "email.",
      "validation",
      "validate",
      "field.",
      "rendering",
      "govern",
      "appearance",
      "user",
      "interface.",
      "field",
      "selection",
      "control",
      "permitted",
      "defined",
      "there",
      "include",
      "condition",
      "option",
      "enables",
      "satisfied",
      "run.",
      "out-of-the-box",
      "provided",
      "existing",
      "workflows",
      "edit.",
      "new",
      "information",
      "about",
      "adding",
      "see",
      "add",
      "rule.",
      "level",
      "record",
      "type",
      "metaphase",
      "phase",
      "type.",
      "select",
      "drop-down",
      "box",
      "top",
      "screen",
      "tab.",
      "left",
      "pane",
      "name",
      "tree",
      "tab",
      "displays",
      "across",
      "all",
      "processes.",
      "types",
      "customized.",
      "process.",
      "second",
      "right",
      "selected",
      "metaphases.",
      "unique",
      "consumed",
      "application.",
      "metaphase."
    ],
    "language": "en",
    "word_count": 95,
    "importance_score": 6.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "studio business rules",
    "contentLower": "business rules are the building blocks from which the business logic of a workflow is constructed. you can define business rules for records, processes, metaphases, phases, and transitions. the following categories of business rules are available: action rules. rules that initiate an action, such as modifying data or sending an email. validation rules. rules that validate the data in a field. rendering rules. rules that govern the appearance of the user interface. field selection rules. rules that control the permitted data in the user interface. for each rule defined, there is also an include condition option, which enables you to define a condition that must be satisfied for the rule to be run. some out-of-the-box business rules are provided in the existing workflows, which you can edit. you can also define new business rules. for more information about adding a business rule, see how to add a business rule. defining business rules in a workflow business rules can be defined at each ",
    "keywordsLower": [
      "studio",
      "business",
      "rules",
      "defining",
      "workflow",
      "rule",
      "properties",
      "syntax",
      "process",
      "events",
      "order",
      "execution",
      "special",
      "related",
      "topics",
      "building",
      "blocks",
      "logic",
      "constructed.",
      "define",
      "records",
      "processes",
      "metaphases",
      "phases",
      "transitions.",
      "following",
      "categories",
      "available",
      "action",
      "rules.",
      "initiate",
      "such",
      "modifying",
      "data",
      "sending",
      "email.",
      "validation",
      "validate",
      "field.",
      "rendering",
      "govern",
      "appearance",
      "user",
      "interface.",
      "field",
      "selection",
      "control",
      "permitted",
      "defined",
      "there",
      "include",
      "condition",
      "option",
      "enables",
      "satisfied",
      "run.",
      "out-of-the-box",
      "provided",
      "existing",
      "workflows",
      "edit.",
      "new",
      "information",
      "about",
      "adding",
      "see",
      "add",
      "rule.",
      "level",
      "record",
      "type",
      "metaphase",
      "phase",
      "type.",
      "select",
      "drop-down",
      "box",
      "top",
      "screen",
      "tab.",
      "left",
      "pane",
      "name",
      "tree",
      "tab",
      "displays",
      "across",
      "all",
      "processes.",
      "types",
      "customized.",
      "process.",
      "second",
      "right",
      "selected",
      "metaphases.",
      "unique",
      "consumed",
      "application.",
      "metaphase."
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Rendering rule examples",
    "content": "The following examples demonstrate how to formulate rules for each of the rendering rule templates: Disable fields The only parameter in this rule template is fields. Click the link and select the required fields. When the rule runs, the selected fields become disabled in the user interface. Use this rule if you want to make fields read-only for UI users but not limit backend or API actions. Display list by alphabetical order The only parameter in this rule template is of the Enum or Enum Set type. Select the Enum/Enum Set field from the drop-down list. When the rule runs, the values in the selected field will be displayed in alphabetical order in the form. Expand section by default For the form parameter, select the required form from the drop-down list.For the sections parameter, select the required section from the drop-down list. The list displays the sections on the form selected.When the rule runs, it expands the selected section of the selected form by default. This rule templat",
    "url": "renderingrules",
    "filename": "renderingrules",
    "headings": [
      "Disable fields",
      "Display list by alphabetical order",
      "Expand section by default",
      "Hide actions",
      "Hide fields",
      "Hide sections",
      "Hide tabs",
      "Restrict/allow editing of fields",
      "Restrict/allow attachments",
      "Related topics"
    ],
    "keywords": [
      "list.For",
      "form.When",
      "All.For",
      "selected.When",
      "rules.This",
      "fields.If",
      "fields.When",
      "rendering",
      "rule",
      "examples",
      "disable",
      "fields",
      "display",
      "list",
      "alphabetical",
      "order",
      "expand",
      "section",
      "default",
      "hide",
      "actions",
      "sections",
      "tabs",
      "restrict",
      "allow",
      "editing",
      "attachments",
      "related",
      "topics",
      "following",
      "demonstrate",
      "formulate",
      "rules",
      "templates",
      "parameter",
      "template",
      "fields.",
      "click",
      "link",
      "select",
      "required",
      "runs",
      "selected",
      "become",
      "disabled",
      "user",
      "interface.",
      "want",
      "make",
      "read-only",
      "ui",
      "users",
      "limit",
      "backend",
      "api",
      "actions.",
      "enum",
      "set",
      "type.",
      "field",
      "drop-down",
      "list.",
      "values",
      "displayed",
      "form.",
      "form",
      "displays",
      "expands",
      "default.",
      "doesn",
      "take",
      "effect",
      "resolution",
      "service",
      "request",
      "incident",
      "record",
      "types.",
      "hide.",
      "disappear",
      "contains",
      "all",
      "custom",
      "number",
      "out-of-the-box",
      "considered",
      "essential",
      "hidden",
      "example",
      "refresh",
      "action",
      "relies",
      "simulation",
      "results",
      "see",
      "several",
      "seconds.",
      "selected.",
      "full",
      "forms"
    ],
    "language": "en",
    "word_count": 100,
    "importance_score": 6.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "rendering rule examples",
    "contentLower": "the following examples demonstrate how to formulate rules for each of the rendering rule templates: disable fields the only parameter in this rule template is fields. click the link and select the required fields. when the rule runs, the selected fields become disabled in the user interface. use this rule if you want to make fields read-only for ui users but not limit backend or api actions. display list by alphabetical order the only parameter in this rule template is of the enum or enum set type. select the enum/enum set field from the drop-down list. when the rule runs, the values in the selected field will be displayed in alphabetical order in the form. expand section by default for the form parameter, select the required form from the drop-down list.for the sections parameter, select the required section from the drop-down list. the list displays the sections on the form selected.when the rule runs, it expands the selected section of the selected form by default. this rule templat",
    "keywordsLower": [
      "list.for",
      "form.when",
      "all.for",
      "selected.when",
      "rules.this",
      "fields.if",
      "fields.when",
      "rendering",
      "rule",
      "examples",
      "disable",
      "fields",
      "display",
      "list",
      "alphabetical",
      "order",
      "expand",
      "section",
      "default",
      "hide",
      "actions",
      "sections",
      "tabs",
      "restrict",
      "allow",
      "editing",
      "attachments",
      "related",
      "topics",
      "following",
      "demonstrate",
      "formulate",
      "rules",
      "templates",
      "parameter",
      "template",
      "fields.",
      "click",
      "link",
      "select",
      "required",
      "runs",
      "selected",
      "become",
      "disabled",
      "user",
      "interface.",
      "want",
      "make",
      "read-only",
      "ui",
      "users",
      "limit",
      "backend",
      "api",
      "actions.",
      "enum",
      "set",
      "type.",
      "field",
      "drop-down",
      "list.",
      "values",
      "displayed",
      "form.",
      "form",
      "displays",
      "expands",
      "default.",
      "doesn",
      "take",
      "effect",
      "resolution",
      "service",
      "request",
      "incident",
      "record",
      "types.",
      "hide.",
      "disappear",
      "contains",
      "all",
      "custom",
      "number",
      "out-of-the-box",
      "considered",
      "essential",
      "hidden",
      "example",
      "refresh",
      "action",
      "relies",
      "simulation",
      "results",
      "see",
      "several",
      "seconds.",
      "selected.",
      "full",
      "forms"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Run agentless REST calls",
    "content": "You can use REST calls based an endpoint that doesn't require an On-Premises Bridge (OPB) agent. Create an agentless endpoint From the main menu, select Administration > Utilities > Integration. Click the Endpoints tab. Click Add. Enter the endpoint details. Field Description Endpoint type Select Agentless Rest Executor 1.0. Endpoint name Enter a name for the endpoint. Use only Latin letters and spaces. Click Add. Service Management creates the endpoint. Click Configure, and then provide the following details. Field Description Protocol Select http or https. Certificate Available only when the https protocol is selected. Copy the content of the SSL certificate of the remote server. The certificate must be in PEM format. When connecting to the remote server, Service Management uses this certificate to verify if the remote server can be trusted. Location Enter the URL of the remote server to which you want to direct the REST call, including the protocol, host, port, and root context, if ",
    "url": "excuterestwithoutopb",
    "filename": "excuterestwithoutopb",
    "headings": [
      "Create an agentless endpoint",
      "Configure an Execute Agentless REST business rule",
      "Verify the execution of the REST calls",
      "Example",
      "Export the endpoint certificate",
      "Create a tenant key chain",
      "Create an agentless endpoint",
      "Associate an OBM device with a Service Management device",
      "Create a business rule for requests",
      "Update a request to trigger the business rule"
    ],
    "keywords": [
      "X.509",
      "9.10",
      "OBM.cer",
      "1.0",
      "Base-64",
      "https://myobm.mycompany.mygroup.net",
      "mygroup.net",
      "run",
      "agentless",
      "rest",
      "calls",
      "create",
      "endpoint",
      "configure",
      "execute",
      "business",
      "rule",
      "verify",
      "execution",
      "example",
      "export",
      "certificate",
      "tenant",
      "key",
      "chain",
      "associate",
      "obm",
      "device",
      "service",
      "management",
      "requests",
      "update",
      "request",
      "trigger",
      "based",
      "doesn",
      "require",
      "on-premises",
      "bridge",
      "opb",
      "agent.",
      "main",
      "menu",
      "select",
      "administration",
      "utilities",
      "integration.",
      "click",
      "endpoints",
      "tab.",
      "add.",
      "enter",
      "details.",
      "field",
      "description",
      "type",
      "executor",
      "1.0.",
      "name",
      "endpoint.",
      "latin",
      "letters",
      "spaces.",
      "creates",
      "provide",
      "following",
      "protocol",
      "http",
      "https.",
      "available",
      "https",
      "selected.",
      "copy",
      "content",
      "ssl",
      "remote",
      "server.",
      "pem",
      "format.",
      "connecting",
      "server",
      "uses",
      "trusted.",
      "location",
      "url",
      "want",
      "direct",
      "call",
      "including",
      "host",
      "port",
      "root",
      "context",
      "any.",
      "note",
      "don",
      "encoded",
      "url.",
      "authentication",
      "method"
    ],
    "language": "en",
    "word_count": 106,
    "importance_score": 6.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "run agentless rest calls",
    "contentLower": "you can use rest calls based an endpoint that doesn't require an on-premises bridge (opb) agent. create an agentless endpoint from the main menu, select administration > utilities > integration. click the endpoints tab. click add. enter the endpoint details. field description endpoint type select agentless rest executor 1.0. endpoint name enter a name for the endpoint. use only latin letters and spaces. click add. service management creates the endpoint. click configure, and then provide the following details. field description protocol select http or https. certificate available only when the https protocol is selected. copy the content of the ssl certificate of the remote server. the certificate must be in pem format. when connecting to the remote server, service management uses this certificate to verify if the remote server can be trusted. location enter the url of the remote server to which you want to direct the rest call, including the protocol, host, port, and root context, if ",
    "keywordsLower": [
      "x.509",
      "9.10",
      "obm.cer",
      "1.0",
      "base-64",
      "https://myobm.mycompany.mygroup.net",
      "mygroup.net",
      "run",
      "agentless",
      "rest",
      "calls",
      "create",
      "endpoint",
      "configure",
      "execute",
      "business",
      "rule",
      "verify",
      "execution",
      "example",
      "export",
      "certificate",
      "tenant",
      "key",
      "chain",
      "associate",
      "obm",
      "device",
      "service",
      "management",
      "requests",
      "update",
      "request",
      "trigger",
      "based",
      "doesn",
      "require",
      "on-premises",
      "bridge",
      "opb",
      "agent.",
      "main",
      "menu",
      "select",
      "administration",
      "utilities",
      "integration.",
      "click",
      "endpoints",
      "tab.",
      "add.",
      "enter",
      "details.",
      "field",
      "description",
      "type",
      "executor",
      "1.0.",
      "name",
      "endpoint.",
      "latin",
      "letters",
      "spaces.",
      "creates",
      "provide",
      "following",
      "protocol",
      "http",
      "https.",
      "available",
      "https",
      "selected.",
      "copy",
      "content",
      "ssl",
      "remote",
      "server.",
      "pem",
      "format.",
      "connecting",
      "server",
      "uses",
      "trusted.",
      "location",
      "url",
      "want",
      "direct",
      "call",
      "including",
      "host",
      "port",
      "root",
      "context",
      "any.",
      "note",
      "don",
      "encoded",
      "url.",
      "authentication",
      "method"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Run REST calls through OPB",
    "content": "You can run REST calls to remote products via the On-Premises Bridge Agent by using the Execute REST business rule. You can use this business rule in a workflow, or in task and approval plans. The rule enables you to define tasks that run REST calls automatically to external servers, and return the results. The results are stored in the output field defined in the business rule. Note It's only possible to run REST calls to external servers that support Basic Authentication. On-Premises Bridge Agent pre-configuration To use the Execute REST Business Rule, the On-Premises Bridge Agent needs to be installed on a customer machine, and be configured to work. Perform the following prerequisites: Configure the On-Premises Bridge Agent with a default endpoint. For more information, see How to use On-Premises Bridge agents on Windows or How to use On-Premises Bridge agents on Linux. Configure credentials using the Credentials Manager of the On-Premises Bridge Agent. These credentials are used f",
    "url": "executerest",
    "filename": "executerest",
    "headings": [
      "On-Premises Bridge Agent pre-configuration",
      "Execute REST business rule configuration",
      "Output field types",
      "Task Prefix field",
      "Example of a business rule",
      "Related topics"
    ],
    "keywords": [
      "http://www.google.com/mail",
      "atlassian.com",
      "https://<demo>.atlassian.net",
      "1.0",
      "atlassian.net",
      "vm.name",
      "google.com",
      "http://www.google.com/search",
      "4.0.0",
      "https://www.atlassian.com/software/jira",
      "run",
      "rest",
      "calls",
      "through",
      "opb",
      "on-premises",
      "bridge",
      "agent",
      "pre-configuration",
      "execute",
      "business",
      "rule",
      "configuration",
      "output",
      "field",
      "types",
      "task",
      "prefix",
      "example",
      "related",
      "topics",
      "remote",
      "products",
      "via",
      "rule.",
      "workflow",
      "approval",
      "plans.",
      "enables",
      "define",
      "tasks",
      "automatically",
      "external",
      "servers",
      "return",
      "results.",
      "results",
      "stored",
      "defined",
      "note",
      "possible",
      "support",
      "basic",
      "authentication.",
      "needs",
      "installed",
      "customer",
      "machine",
      "configured",
      "work.",
      "perform",
      "following",
      "prerequisites",
      "configure",
      "default",
      "endpoint.",
      "information",
      "see",
      "agents",
      "windows",
      "linux.",
      "credentials",
      "manager",
      "agent.",
      "authentication",
      "server.",
      "endpoints.",
      "endpoint",
      "service",
      "location",
      "uses",
      "id",
      "previous",
      "step",
      "server",
      "after",
      "endpoints",
      "accepts",
      "parameters",
      "parameter",
      "value",
      "select",
      "drop-down",
      "list.",
      "there",
      "one",
      "network",
      "domain.",
      "every",
      "override"
    ],
    "language": "en",
    "word_count": 99,
    "importance_score": 6.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "run rest calls through opb",
    "contentLower": "you can run rest calls to remote products via the on-premises bridge agent by using the execute rest business rule. you can use this business rule in a workflow, or in task and approval plans. the rule enables you to define tasks that run rest calls automatically to external servers, and return the results. the results are stored in the output field defined in the business rule. note it's only possible to run rest calls to external servers that support basic authentication. on-premises bridge agent pre-configuration to use the execute rest business rule, the on-premises bridge agent needs to be installed on a customer machine, and be configured to work. perform the following prerequisites: configure the on-premises bridge agent with a default endpoint. for more information, see how to use on-premises bridge agents on windows or how to use on-premises bridge agents on linux. configure credentials using the credentials manager of the on-premises bridge agent. these credentials are used f",
    "keywordsLower": [
      "http://www.google.com/mail",
      "atlassian.com",
      "https://<demo>.atlassian.net",
      "1.0",
      "atlassian.net",
      "vm.name",
      "google.com",
      "http://www.google.com/search",
      "4.0.0",
      "https://www.atlassian.com/software/jira",
      "run",
      "rest",
      "calls",
      "through",
      "opb",
      "on-premises",
      "bridge",
      "agent",
      "pre-configuration",
      "execute",
      "business",
      "rule",
      "configuration",
      "output",
      "field",
      "types",
      "task",
      "prefix",
      "example",
      "related",
      "topics",
      "remote",
      "products",
      "via",
      "rule.",
      "workflow",
      "approval",
      "plans.",
      "enables",
      "define",
      "tasks",
      "automatically",
      "external",
      "servers",
      "return",
      "results.",
      "results",
      "stored",
      "defined",
      "note",
      "possible",
      "support",
      "basic",
      "authentication.",
      "needs",
      "installed",
      "customer",
      "machine",
      "configured",
      "work.",
      "perform",
      "following",
      "prerequisites",
      "configure",
      "default",
      "endpoint.",
      "information",
      "see",
      "agents",
      "windows",
      "linux.",
      "credentials",
      "manager",
      "agent.",
      "authentication",
      "server.",
      "endpoints.",
      "endpoint",
      "service",
      "location",
      "uses",
      "id",
      "previous",
      "step",
      "server",
      "after",
      "endpoints",
      "accepts",
      "parameters",
      "parameter",
      "value",
      "select",
      "drop-down",
      "list.",
      "there",
      "one",
      "network",
      "domain.",
      "every",
      "override"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Studio - use case",
    "content": "The following is a use case scenario for a workflow in Studio: Consider a simple workflow for a record of type defect, which includes the following fields: Description Submitter Owner Resolution The workflow contains the following phases: New. The submitter enters the description. Assignment. The team leader assigns the defect to an owner. Open. The owner works on the defect. Fixed. The defect is closed by the owner. The business logic is as follows: When the defect is created, the submitter is automatically set to the currently logged-in user. The submitter must enter a defect description before it can be moved to the Assignment phase. In the Assignment phase, a defect owner must be entered. The submitter also has the option to enter a defect owner during defect creation (in the New phase), and advance directly to the Open phase. In the Open phase, the developer fixes the defect and closes it, moving it to the Fixed phase. The resolution must be assigned a value of either code problem",
    "url": "wflwusecase",
    "filename": "wflwusecase",
    "headings": [
      "Related topics"
    ],
    "keywords": [
      "studio",
      "case",
      "related",
      "topics",
      "following",
      "scenario",
      "workflow",
      "consider",
      "simple",
      "record",
      "type",
      "defect",
      "includes",
      "fields",
      "description",
      "submitter",
      "owner",
      "resolution",
      "contains",
      "phases",
      "new.",
      "enters",
      "description.",
      "assignment.",
      "team",
      "leader",
      "assigns",
      "owner.",
      "open.",
      "works",
      "defect.",
      "fixed.",
      "closed",
      "business",
      "logic",
      "follows",
      "created",
      "automatically",
      "set",
      "currently",
      "logged-in",
      "user.",
      "enter",
      "before",
      "moved",
      "assignment",
      "phase.",
      "phase",
      "entered.",
      "option",
      "during",
      "creation",
      "new",
      "advance",
      "directly",
      "open",
      "developer",
      "fixes",
      "closes",
      "moving",
      "fixed",
      "assigned",
      "value",
      "either",
      "code",
      "problem",
      "design",
      "advancing",
      "implement",
      "define",
      "four",
      "add",
      "transitions",
      "rules",
      "defined",
      "action",
      "rule",
      "take",
      "effect",
      "after",
      "data",
      "updated",
      "sets",
      "field",
      "equal",
      "current",
      "validation",
      "leaving",
      "checks",
      "problem.",
      "addition",
      "automatic",
      "transition",
      "advances",
      "assigned.",
      "processes",
      "descriptions",
      "tags",
      "examples",
      "rendering"
    ],
    "language": "en",
    "word_count": 95,
    "importance_score": 3.5,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "studio - use case",
    "contentLower": "the following is a use case scenario for a workflow in studio: consider a simple workflow for a record of type defect, which includes the following fields: description submitter owner resolution the workflow contains the following phases: new. the submitter enters the description. assignment. the team leader assigns the defect to an owner. open. the owner works on the defect. fixed. the defect is closed by the owner. the business logic is as follows: when the defect is created, the submitter is automatically set to the currently logged-in user. the submitter must enter a defect description before it can be moved to the assignment phase. in the assignment phase, a defect owner must be entered. the submitter also has the option to enter a defect owner during defect creation (in the new phase), and advance directly to the open phase. in the open phase, the developer fixes the defect and closes it, moving it to the fixed phase. the resolution must be assigned a value of either code problem",
    "keywordsLower": [
      "studio",
      "case",
      "related",
      "topics",
      "following",
      "scenario",
      "workflow",
      "consider",
      "simple",
      "record",
      "type",
      "defect",
      "includes",
      "fields",
      "description",
      "submitter",
      "owner",
      "resolution",
      "contains",
      "phases",
      "new.",
      "enters",
      "description.",
      "assignment.",
      "team",
      "leader",
      "assigns",
      "owner.",
      "open.",
      "works",
      "defect.",
      "fixed.",
      "closed",
      "business",
      "logic",
      "follows",
      "created",
      "automatically",
      "set",
      "currently",
      "logged-in",
      "user.",
      "enter",
      "before",
      "moved",
      "assignment",
      "phase.",
      "phase",
      "entered.",
      "option",
      "during",
      "creation",
      "new",
      "advance",
      "directly",
      "open",
      "developer",
      "fixes",
      "closes",
      "moving",
      "fixed",
      "assigned",
      "value",
      "either",
      "code",
      "problem",
      "design",
      "advancing",
      "implement",
      "define",
      "four",
      "add",
      "transitions",
      "rules",
      "defined",
      "action",
      "rule",
      "take",
      "effect",
      "after",
      "data",
      "updated",
      "sets",
      "field",
      "equal",
      "current",
      "validation",
      "leaving",
      "checks",
      "problem.",
      "addition",
      "automatic",
      "transition",
      "advances",
      "assigned.",
      "processes",
      "descriptions",
      "tags",
      "examples",
      "rendering"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Remove a value from a list using a rendering rule",
    "content": "While setting up the completion codes that the IT agents use when closing requests the administrator decided that the value ‘Solved by Social’ was not required in the list of available completion codes. In order to filter this value out of a list, a new ‘Define suggested values by a list to list mapping’ rule needs to be added. Enter the name of the list for both the source and destination lists. Map the names of the values to themselves, if a value is not needed do not add a mapping and it will not appear after the rule is applied. If there is a security reason that the value is being removed, a validation rule needs to be added to make sure that it can’t be populated using a different method than the UI.",
    "url": "xcbreexample1",
    "filename": "xcbreexample1",
    "headings": [],
    "keywords": [
      "remove",
      "value",
      "list",
      "rendering",
      "rule",
      "while",
      "setting",
      "completion",
      "codes",
      "agents",
      "closing",
      "requests",
      "administrator",
      "decided",
      "solved",
      "social",
      "required",
      "available",
      "codes.",
      "order",
      "filter",
      "out",
      "new",
      "define",
      "suggested",
      "values",
      "mapping",
      "needs",
      "added.",
      "enter",
      "name",
      "both",
      "source",
      "destination",
      "lists.",
      "map",
      "names",
      "themselves",
      "needed",
      "add",
      "appear",
      "after",
      "applied.",
      "there",
      "security",
      "reason",
      "removed",
      "validation",
      "added",
      "make",
      "sure",
      "populated",
      "different",
      "method",
      "ui."
    ],
    "language": "en",
    "word_count": 72,
    "importance_score": 2.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "remove a value from a list using a rendering rule",
    "contentLower": "while setting up the completion codes that the it agents use when closing requests the administrator decided that the value ‘solved by social’ was not required in the list of available completion codes. in order to filter this value out of a list, a new ‘define suggested values by a list to list mapping’ rule needs to be added. enter the name of the list for both the source and destination lists. map the names of the values to themselves, if a value is not needed do not add a mapping and it will not appear after the rule is applied. if there is a security reason that the value is being removed, a validation rule needs to be added to make sure that it can’t be populated using a different method than the ui.",
    "keywordsLower": [
      "remove",
      "value",
      "list",
      "rendering",
      "rule",
      "while",
      "setting",
      "completion",
      "codes",
      "agents",
      "closing",
      "requests",
      "administrator",
      "decided",
      "solved",
      "social",
      "required",
      "available",
      "codes.",
      "order",
      "filter",
      "out",
      "new",
      "define",
      "suggested",
      "values",
      "mapping",
      "needs",
      "added.",
      "enter",
      "name",
      "both",
      "source",
      "destination",
      "lists.",
      "map",
      "names",
      "themselves",
      "needed",
      "add",
      "appear",
      "after",
      "applied.",
      "there",
      "security",
      "reason",
      "removed",
      "validation",
      "added",
      "make",
      "sure",
      "populated",
      "different",
      "method",
      "ui."
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Set a field to a group that will be moved when dev2prod runs",
    "content": "The administrator wants to set the service desk group on all requests created through the Service Portal to a group named ‘Initial Ticket Reviewers’. When the dev2prod process runs the rule needs to use the group with the same name on the production tenant. The administrator needs to create a set field rule using the group_id_by_upn() function. Click on the ‘fx’ button to use the function. In order to not update the field every time or overwrite a value that may be set later in the workflow an ‘if’ condition should be used. It’s also possible to put the rule in a location that will only run once, for example entering the ‘Log’ phase. In the example an If condition is added to make sure that the field is not already set, and if it’s not set and entering the ‘Log’ phase then the service desk group is set.",
    "url": "xcbreexample2",
    "filename": "xcbreexample2",
    "headings": [],
    "keywords": [
      "set",
      "field",
      "group",
      "moved",
      "dev2prod",
      "runs",
      "administrator",
      "wants",
      "service",
      "desk",
      "all",
      "requests",
      "created",
      "through",
      "portal",
      "named",
      "initial",
      "ticket",
      "reviewers",
      "process",
      "rule",
      "needs",
      "same",
      "name",
      "production",
      "tenant.",
      "create",
      "function.",
      "click",
      "fx",
      "button",
      "order",
      "update",
      "every",
      "time",
      "overwrite",
      "value",
      "later",
      "workflow",
      "condition",
      "used.",
      "possible",
      "put",
      "location",
      "run",
      "once",
      "example",
      "entering",
      "log",
      "phase.",
      "added",
      "make",
      "sure",
      "already",
      "phase",
      "set."
    ],
    "language": "en",
    "word_count": 85,
    "importance_score": 1.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "set a field to a group that will be moved when dev2prod runs",
    "contentLower": "the administrator wants to set the service desk group on all requests created through the service portal to a group named ‘initial ticket reviewers’. when the dev2prod process runs the rule needs to use the group with the same name on the production tenant. the administrator needs to create a set field rule using the group_id_by_upn() function. click on the ‘fx’ button to use the function. in order to not update the field every time or overwrite a value that may be set later in the workflow an ‘if’ condition should be used. it’s also possible to put the rule in a location that will only run once, for example entering the ‘log’ phase. in the example an if condition is added to make sure that the field is not already set, and if it’s not set and entering the ‘log’ phase then the service desk group is set.",
    "keywordsLower": [
      "set",
      "field",
      "group",
      "moved",
      "dev2prod",
      "runs",
      "administrator",
      "wants",
      "service",
      "desk",
      "all",
      "requests",
      "created",
      "through",
      "portal",
      "named",
      "initial",
      "ticket",
      "reviewers",
      "process",
      "rule",
      "needs",
      "same",
      "name",
      "production",
      "tenant.",
      "create",
      "function.",
      "click",
      "fx",
      "button",
      "order",
      "update",
      "every",
      "time",
      "overwrite",
      "value",
      "later",
      "workflow",
      "condition",
      "used.",
      "possible",
      "put",
      "location",
      "run",
      "once",
      "example",
      "entering",
      "log",
      "phase.",
      "added",
      "make",
      "sure",
      "already",
      "phase",
      "set."
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Suggest solutions for the Service desk group using the union function",
    "content": "A typical use case for selecting the assignment group on a request may be to use a rendering rule to only make available for selection the 1st, 2nd and 3rd level support groups assigned to the service. To accomplish this in a single rule the union function may be used. Add the suggested solutions filter in the rendering forms rule section. Then select the service desk group field, select the ‘Id’, and ‘in’ ${union(entity.RegisteredForActualService.SupportLevel1Group.Id,entity.RegisteredForActualService.SupportLevel2Group.Id,entity.RegisteredForActualService.SupportLevel3Group.Id)}",
    "url": "xcbreexample7",
    "filename": "xcbreexample7",
    "headings": [],
    "keywords": [
      "SupportLevel1Group.Id",
      "SupportLevel3Group.Id",
      "SupportLevel2Group.Id",
      "suggest",
      "solutions",
      "service",
      "desk",
      "group",
      "union",
      "function",
      "typical",
      "case",
      "selecting",
      "assignment",
      "request",
      "rendering",
      "rule",
      "make",
      "available",
      "selection",
      "1st",
      "2nd",
      "3rd",
      "level",
      "support",
      "groups",
      "assigned",
      "service.",
      "accomplish",
      "single",
      "used.",
      "add",
      "suggested",
      "filter",
      "forms",
      "section.",
      "select",
      "field",
      "id",
      "entity.registeredforactualservice.supportlevel1group.id",
      "entity.registeredforactualservice.supportlevel2group.id",
      "entity.registeredforactualservice.supportlevel3group.id"
    ],
    "language": "en",
    "word_count": 51,
    "importance_score": 0.1,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "suggest solutions for the service desk group using the union function",
    "contentLower": "a typical use case for selecting the assignment group on a request may be to use a rendering rule to only make available for selection the 1st, 2nd and 3rd level support groups assigned to the service. to accomplish this in a single rule the union function may be used. add the suggested solutions filter in the rendering forms rule section. then select the service desk group field, select the ‘id’, and ‘in’ ${union(entity.registeredforactualservice.supportlevel1group.id,entity.registeredforactualservice.supportlevel2group.id,entity.registeredforactualservice.supportlevel3group.id)}",
    "keywordsLower": [
      "supportlevel1group.id",
      "supportlevel3group.id",
      "supportlevel2group.id",
      "suggest",
      "solutions",
      "service",
      "desk",
      "group",
      "union",
      "function",
      "typical",
      "case",
      "selecting",
      "assignment",
      "request",
      "rendering",
      "rule",
      "make",
      "available",
      "selection",
      "1st",
      "2nd",
      "3rd",
      "level",
      "support",
      "groups",
      "assigned",
      "service.",
      "accomplish",
      "single",
      "used.",
      "add",
      "suggested",
      "filter",
      "forms",
      "section.",
      "select",
      "field",
      "id",
      "entity.registeredforactualservice.supportlevel1group.id",
      "entity.registeredforactualservice.supportlevel2group.id",
      "entity.registeredforactualservice.supportlevel3group.id"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Suggest solutions to set the Service desk group using the union and intersect functions",
    "content": "It is possible to create multiple lists of values and then only use results that exist in both lists to populate something. In this example, the service desk suggested solution field will only show a group if the requested for person’s organizational group is one of the 1st, 2nd or 3rd level support groups assigned to the service. The behavior is illustrated below: The resulting request would appear as:",
    "url": "xcbreexample8",
    "filename": "xcbreexample8",
    "headings": [],
    "keywords": [
      "suggest",
      "solutions",
      "set",
      "service",
      "desk",
      "group",
      "union",
      "intersect",
      "functions",
      "possible",
      "create",
      "multiple",
      "lists",
      "values",
      "results",
      "exist",
      "both",
      "populate",
      "something.",
      "example",
      "suggested",
      "solution",
      "field",
      "show",
      "requested",
      "person",
      "organizational",
      "one",
      "1st",
      "2nd",
      "3rd",
      "level",
      "support",
      "groups",
      "assigned",
      "service.",
      "behavior",
      "illustrated",
      "below",
      "resulting",
      "request",
      "appear"
    ],
    "language": "en",
    "word_count": 48,
    "importance_score": 0.1,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "suggest solutions to set the service desk group using the union and intersect functions",
    "contentLower": "it is possible to create multiple lists of values and then only use results that exist in both lists to populate something. in this example, the service desk suggested solution field will only show a group if the requested for person’s organizational group is one of the 1st, 2nd or 3rd level support groups assigned to the service. the behavior is illustrated below: the resulting request would appear as:",
    "keywordsLower": [
      "suggest",
      "solutions",
      "set",
      "service",
      "desk",
      "group",
      "union",
      "intersect",
      "functions",
      "possible",
      "create",
      "multiple",
      "lists",
      "values",
      "results",
      "exist",
      "both",
      "populate",
      "something.",
      "example",
      "suggested",
      "solution",
      "field",
      "show",
      "requested",
      "person",
      "organizational",
      "one",
      "1st",
      "2nd",
      "3rd",
      "level",
      "support",
      "groups",
      "assigned",
      "service.",
      "behavior",
      "illustrated",
      "below",
      "resulting",
      "request",
      "appear"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Send notification to groups",
    "content": "You can send the notification to the groups using the Send notification rule template. ​​​​Simple rule: When you select the recipients in the Send notification rule template, you can add the assignment group as the recipients from the drop-down list. Expression Language: Alternatively, you can use the Expression Language mode to send a notification to the assignment group of a record. Here is an example: Send emails to group PDLs for large groups If a group has a lot of members, you should do the following to make the system send emails to the group PDL instead of individual users: Specify an email for the group on the Group page. Select the use group email flag on the notification template. Note: If you don't use the group PDL method, the system sends notifications to email addresses of group members individually, and this method supports 1,000 group members at maximum. If you add a group that has more than 1,000 members, some members will not receive email notifications due to this l",
    "url": "xcbreexample12",
    "filename": "xcbreexample12",
    "headings": [
      "Send emails to group PDLs for large groups"
    ],
    "keywords": [
      "send",
      "notification",
      "groups",
      "emails",
      "group",
      "pdls",
      "large",
      "rule",
      "template.",
      "simple",
      "select",
      "recipients",
      "template",
      "add",
      "assignment",
      "drop-down",
      "list.",
      "expression",
      "language",
      "alternatively",
      "mode",
      "record.",
      "here",
      "example",
      "lot",
      "members",
      "following",
      "make",
      "system",
      "pdl",
      "instead",
      "individual",
      "users",
      "specify",
      "email",
      "page.",
      "flag",
      "note",
      "don",
      "method",
      "sends",
      "notifications",
      "addresses",
      "individually",
      "supports",
      "000",
      "maximum.",
      "receive",
      "due",
      "limit."
    ],
    "language": "en",
    "word_count": 99,
    "importance_score": 3.5,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "send notification to groups",
    "contentLower": "you can send the notification to the groups using the send notification rule template. ​​​​simple rule: when you select the recipients in the send notification rule template, you can add the assignment group as the recipients from the drop-down list. expression language: alternatively, you can use the expression language mode to send a notification to the assignment group of a record. here is an example: send emails to group pdls for large groups if a group has a lot of members, you should do the following to make the system send emails to the group pdl instead of individual users: specify an email for the group on the group page. select the use group email flag on the notification template. note: if you don't use the group pdl method, the system sends notifications to email addresses of group members individually, and this method supports 1,000 group members at maximum. if you add a group that has more than 1,000 members, some members will not receive email notifications due to this l",
    "keywordsLower": [
      "send",
      "notification",
      "groups",
      "emails",
      "group",
      "pdls",
      "large",
      "rule",
      "template.",
      "simple",
      "select",
      "recipients",
      "template",
      "add",
      "assignment",
      "drop-down",
      "list.",
      "expression",
      "language",
      "alternatively",
      "mode",
      "record.",
      "here",
      "example",
      "lot",
      "members",
      "following",
      "make",
      "system",
      "pdl",
      "instead",
      "individual",
      "users",
      "specify",
      "email",
      "page.",
      "flag",
      "note",
      "don",
      "method",
      "sends",
      "notifications",
      "addresses",
      "individually",
      "supports",
      "000",
      "maximum.",
      "receive",
      "due",
      "limit."
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Send notification to first non-empty recipient",
    "content": "One common use of the expression language is building a list of recipients. In the below example the email will be sent to the first non-empty value, either the manager of the reported by person or the reported by person themselves.",
    "url": "xcbreexample9",
    "filename": "xcbreexample9",
    "headings": [],
    "keywords": [
      "send",
      "notification",
      "first",
      "non-empty",
      "recipient",
      "one",
      "common",
      "expression",
      "language",
      "building",
      "list",
      "recipients.",
      "below",
      "example",
      "email",
      "sent",
      "value",
      "either",
      "manager",
      "reported",
      "person",
      "themselves."
    ],
    "language": "en",
    "word_count": 26,
    "importance_score": 1.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "send notification to first non-empty recipient",
    "contentLower": "one common use of the expression language is building a list of recipients. in the below example the email will be sent to the first non-empty value, either the manager of the reported by person or the reported by person themselves.",
    "keywordsLower": [
      "send",
      "notification",
      "first",
      "non-empty",
      "recipient",
      "one",
      "common",
      "expression",
      "language",
      "building",
      "list",
      "recipients.",
      "below",
      "example",
      "email",
      "sent",
      "value",
      "either",
      "manager",
      "reported",
      "person",
      "themselves."
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Sending Parent Entity information in Approval or Task emails",
    "content": "Email notifications sent when a task or approval is created often need to include information from the parent request or change. Since change and request share the same notification templates for tasks and approvals, the Service Management administrator may use a conditional rule to show relevant information for the relevant parent type. Conditional rules are only available in notification templates. In this example, the email notification template used to send email to the task assignee will be updated to include information about the parent request or change. The email notification template (named ‘Send task assigned to person notification’) is located in Records -> Task -> Notifications: If the parent of the task is a request, the notification should include the phase, name, service, service desk group, and creation date of the request. If the parent of the task is a change, the notification should include the phase, reason for change, risk, change type, change owner, change owning ",
    "url": "xcbreexample10",
    "filename": "xcbreexample10",
    "headings": [],
    "keywords": [
      "ExpertGroup.Name",
      "ServiceDeskGroup.Name",
      "OwnedByPerson.Name",
      "OwnedByGroup.Name",
      "sending",
      "parent",
      "entity",
      "information",
      "approval",
      "task",
      "emails",
      "email",
      "notifications",
      "sent",
      "created",
      "often",
      "need",
      "include",
      "request",
      "change.",
      "since",
      "change",
      "share",
      "same",
      "notification",
      "templates",
      "tasks",
      "approvals",
      "service",
      "management",
      "administrator",
      "conditional",
      "rule",
      "show",
      "relevant",
      "type.",
      "rules",
      "available",
      "templates.",
      "example",
      "template",
      "send",
      "assignee",
      "updated",
      "about",
      "named",
      "assigned",
      "person",
      "located",
      "records",
      "phase",
      "name",
      "desk",
      "group",
      "creation",
      "date",
      "request.",
      "reason",
      "risk",
      "type",
      "owner",
      "owning",
      "model",
      "scheduled",
      "start",
      "end",
      "there",
      "common",
      "field",
      "names",
      "both",
      "single",
      "entry",
      "needed",
      "template.",
      "syntax",
      "access",
      "entity.parententity.fieldname",
      "phaseid",
      "types",
      "added",
      "resulting",
      "look",
      "like",
      "another",
      "approach",
      "allow",
      "different",
      "text",
      "depending",
      "record",
      "uses",
      "below",
      "condition",
      "result",
      "true",
      "mean",
      "fulfill.",
      "return",
      "false"
    ],
    "language": "en",
    "word_count": 102,
    "importance_score": 2.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "sending parent entity information in approval or task emails",
    "contentLower": "email notifications sent when a task or approval is created often need to include information from the parent request or change. since change and request share the same notification templates for tasks and approvals, the service management administrator may use a conditional rule to show relevant information for the relevant parent type. conditional rules are only available in notification templates. in this example, the email notification template used to send email to the task assignee will be updated to include information about the parent request or change. the email notification template (named ‘send task assigned to person notification’) is located in records -> task -> notifications: if the parent of the task is a request, the notification should include the phase, name, service, service desk group, and creation date of the request. if the parent of the task is a change, the notification should include the phase, reason for change, risk, change type, change owner, change owning ",
    "keywordsLower": [
      "expertgroup.name",
      "servicedeskgroup.name",
      "ownedbyperson.name",
      "ownedbygroup.name",
      "sending",
      "parent",
      "entity",
      "information",
      "approval",
      "task",
      "emails",
      "email",
      "notifications",
      "sent",
      "created",
      "often",
      "need",
      "include",
      "request",
      "change.",
      "since",
      "change",
      "share",
      "same",
      "notification",
      "templates",
      "tasks",
      "approvals",
      "service",
      "management",
      "administrator",
      "conditional",
      "rule",
      "show",
      "relevant",
      "type.",
      "rules",
      "available",
      "templates.",
      "example",
      "template",
      "send",
      "assignee",
      "updated",
      "about",
      "named",
      "assigned",
      "person",
      "located",
      "records",
      "phase",
      "name",
      "desk",
      "group",
      "creation",
      "date",
      "request.",
      "reason",
      "risk",
      "type",
      "owner",
      "owning",
      "model",
      "scheduled",
      "start",
      "end",
      "there",
      "common",
      "field",
      "names",
      "both",
      "single",
      "entry",
      "needed",
      "template.",
      "syntax",
      "access",
      "entity.parententity.fieldname",
      "phaseid",
      "types",
      "added",
      "resulting",
      "look",
      "like",
      "another",
      "approach",
      "allow",
      "different",
      "text",
      "depending",
      "record",
      "uses",
      "below",
      "condition",
      "result",
      "true",
      "mean",
      "fulfill.",
      "return",
      "false"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Set up Governance Level Approval",
    "content": "For example, assume you want to set up Service Management so that approval by the Cost Center manager is required for requests where the cost is greater than $2,000.00. From the main menu, select Administration > Configuration > Studio. Select Request as the record type. Click the Approval definitions tab. Out-of-the-box, an empty approval definition called Governance Approval is displayed. Type a suitable description. For example: \"Check the total amount of the request against the threshold for the requester's cost center. If threshold exceeded, approval of Cost Center manager required.\" Note There may only ever be one approval definition for the record type. If you want to change the name of the definition, remove the existing definition and add a new one. Hover over Start in the right pane. Click . The following menu is displayed: Click Decision in the menu. The New decision dialog is displayed. Select Yes/No decision type. Type a suitable title and a value for the in case of field.",
    "url": "setupgovernlevelapproval",
    "filename": "setupgovernlevelapproval",
    "headings": [
      "Related topics"
    ],
    "keywords": [
      "entity.Cost",
      "000.00",
      "set",
      "governance",
      "level",
      "approval",
      "related",
      "topics",
      "example",
      "assume",
      "want",
      "service",
      "management",
      "cost",
      "center",
      "manager",
      "required",
      "requests",
      "greater",
      "000.00.",
      "main",
      "menu",
      "select",
      "administration",
      "configuration",
      "studio.",
      "request",
      "record",
      "type.",
      "click",
      "definitions",
      "tab.",
      "out-of-the-box",
      "empty",
      "definition",
      "called",
      "displayed.",
      "type",
      "suitable",
      "description.",
      "check",
      "total",
      "amount",
      "against",
      "threshold",
      "requester",
      "center.",
      "exceeded",
      "required.",
      "note",
      "there",
      "ever",
      "one",
      "change",
      "name",
      "remove",
      "existing",
      "add",
      "new",
      "one.",
      "hover",
      "over",
      "start",
      "right",
      "pane.",
      "following",
      "displayed",
      "decision",
      "menu.",
      "dialog",
      "title",
      "value",
      "case",
      "field.",
      "field",
      "exceeds",
      "2000",
      "ok.",
      "plan",
      "plan.",
      "display",
      "approval.",
      "box",
      "strategy.",
      "strategy",
      "approve",
      "approver",
      "user.",
      "user",
      "approver.",
      "manager.",
      "leave",
      "condition",
      "empty.",
      "box.",
      "join.",
      "join",
      "node",
      "added.",
      "no."
    ],
    "language": "en",
    "word_count": 106,
    "importance_score": 3.5,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "set up governance level approval",
    "contentLower": "for example, assume you want to set up service management so that approval by the cost center manager is required for requests where the cost is greater than $2,000.00. from the main menu, select administration > configuration > studio. select request as the record type. click the approval definitions tab. out-of-the-box, an empty approval definition called governance approval is displayed. type a suitable description. for example: \"check the total amount of the request against the threshold for the requester's cost center. if threshold exceeded, approval of cost center manager required.\" note there may only ever be one approval definition for the record type. if you want to change the name of the definition, remove the existing definition and add a new one. hover over start in the right pane. click . the following menu is displayed: click decision in the menu. the new decision dialog is displayed. select yes/no decision type. type a suitable title and a value for the in case of field.",
    "keywordsLower": [
      "entity.cost",
      "000.00",
      "set",
      "governance",
      "level",
      "approval",
      "related",
      "topics",
      "example",
      "assume",
      "want",
      "service",
      "management",
      "cost",
      "center",
      "manager",
      "required",
      "requests",
      "greater",
      "000.00.",
      "main",
      "menu",
      "select",
      "administration",
      "configuration",
      "studio.",
      "request",
      "record",
      "type.",
      "click",
      "definitions",
      "tab.",
      "out-of-the-box",
      "empty",
      "definition",
      "called",
      "displayed.",
      "type",
      "suitable",
      "description.",
      "check",
      "total",
      "amount",
      "against",
      "threshold",
      "requester",
      "center.",
      "exceeded",
      "required.",
      "note",
      "there",
      "ever",
      "one",
      "change",
      "name",
      "remove",
      "existing",
      "add",
      "new",
      "one.",
      "hover",
      "over",
      "start",
      "right",
      "pane.",
      "following",
      "displayed",
      "decision",
      "menu.",
      "dialog",
      "title",
      "value",
      "case",
      "field.",
      "field",
      "exceeds",
      "2000",
      "ok.",
      "plan",
      "plan.",
      "display",
      "approval.",
      "box",
      "strategy.",
      "strategy",
      "approve",
      "approver",
      "user.",
      "user",
      "approver.",
      "manager.",
      "leave",
      "condition",
      "empty.",
      "box.",
      "join.",
      "join",
      "node",
      "added.",
      "no."
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Set up approval plan for a custom record type",
    "content": "For custom record types created using Studio, you can create approval definitions and enable approval plans in a workflow. Create approval definitions From the main menu, select Administration > Configuration > Studio. Select a custom record type. Create an approval definition as described in How to build an approval definition. You can add more approval definitions to the custom record type. Notes: Approval definitions of a custom record type can't be removed after being created. This behavior is identical to the behavior of the Change or Idea record type. Approval definitions isn't covered by the dev2prod process. This behavior is identical to the behavior of the Change or Idea record type. How to enable/disable approval plan in a phase From the main menu, select Administration > Configuration > Studio. Select a custom record type. Click the Processes and Rules tab. Select a phase, click the Properties tab on the right panel. Select or deselect the Enable Approval Plan check box. Cli",
    "url": "approvalcustomrec",
    "filename": "approvalcustomrec",
    "headings": [
      "Create approval definitions",
      "How to enable/disable approval plan in a phase",
      "How to select/deselect approval definition in a phase",
      "How to use approval plan on a custom record instance",
      "How to make sure the process doesn't enter the next phase until all approvals are finished successfully",
      "How to show the requestor's name for custom record types in Service Portal",
      "More information"
    ],
    "keywords": [
      "set",
      "approval",
      "plan",
      "custom",
      "record",
      "type",
      "create",
      "definitions",
      "enable",
      "disable",
      "phase",
      "select",
      "deselect",
      "definition",
      "instance",
      "make",
      "sure",
      "process",
      "doesn",
      "enter",
      "next",
      "until",
      "all",
      "approvals",
      "finished",
      "successfully",
      "show",
      "requestor",
      "name",
      "types",
      "service",
      "portal",
      "information",
      "created",
      "studio",
      "plans",
      "workflow.",
      "main",
      "menu",
      "administration",
      "configuration",
      "studio.",
      "type.",
      "described",
      "build",
      "definition.",
      "add",
      "notes",
      "removed",
      "after",
      "created.",
      "behavior",
      "identical",
      "change",
      "idea",
      "isn",
      "covered",
      "dev2prod",
      "process.",
      "click",
      "processes",
      "rules",
      "tab.",
      "properties",
      "tab",
      "right",
      "panel.",
      "check",
      "box.",
      "save.",
      "fields",
      "box",
      "selected",
      "find",
      "field",
      "named",
      "enabled",
      "plan.",
      "example",
      "customphase2",
      "gjgfyu09z",
      "unique",
      "suffix",
      "generated",
      "system.",
      "deselected",
      "corresponding",
      "removed.",
      "dsl",
      "expressions",
      "workflow",
      "business",
      "rules.",
      "see",
      "information.",
      "moved",
      "another",
      "metaphase.",
      "move",
      "metaphase"
    ],
    "language": "en",
    "word_count": 109,
    "importance_score": 5.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "set up approval plan for a custom record type",
    "contentLower": "for custom record types created using studio, you can create approval definitions and enable approval plans in a workflow. create approval definitions from the main menu, select administration > configuration > studio. select a custom record type. create an approval definition as described in how to build an approval definition. you can add more approval definitions to the custom record type. notes: approval definitions of a custom record type can't be removed after being created. this behavior is identical to the behavior of the change or idea record type. approval definitions isn't covered by the dev2prod process. this behavior is identical to the behavior of the change or idea record type. how to enable/disable approval plan in a phase from the main menu, select administration > configuration > studio. select a custom record type. click the processes and rules tab. select a phase, click the properties tab on the right panel. select or deselect the enable approval plan check box. cli",
    "keywordsLower": [
      "set",
      "approval",
      "plan",
      "custom",
      "record",
      "type",
      "create",
      "definitions",
      "enable",
      "disable",
      "phase",
      "select",
      "deselect",
      "definition",
      "instance",
      "make",
      "sure",
      "process",
      "doesn",
      "enter",
      "next",
      "until",
      "all",
      "approvals",
      "finished",
      "successfully",
      "show",
      "requestor",
      "name",
      "types",
      "service",
      "portal",
      "information",
      "created",
      "studio",
      "plans",
      "workflow.",
      "main",
      "menu",
      "administration",
      "configuration",
      "studio.",
      "type.",
      "described",
      "build",
      "definition.",
      "add",
      "notes",
      "removed",
      "after",
      "created.",
      "behavior",
      "identical",
      "change",
      "idea",
      "isn",
      "covered",
      "dev2prod",
      "process.",
      "click",
      "processes",
      "rules",
      "tab.",
      "properties",
      "tab",
      "right",
      "panel.",
      "check",
      "box.",
      "save.",
      "fields",
      "box",
      "selected",
      "find",
      "field",
      "named",
      "enabled",
      "plan.",
      "example",
      "customphase2",
      "gjgfyu09z",
      "unique",
      "suffix",
      "generated",
      "system.",
      "deselected",
      "corresponding",
      "removed.",
      "dsl",
      "expressions",
      "workflow",
      "business",
      "rules.",
      "see",
      "information.",
      "moved",
      "another",
      "metaphase.",
      "move",
      "metaphase"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "SLT settings",
    "content": "For out-of-the-box record types, the SLT settings tab enables you to control the out-of-the-box email notifications that Service Management sends as a Service Level target approaches a breach threshold. The notifications are described in Notifications. For custom record types you have created in Studio, the SLT settings tab enables you to control the SLT calculation and configure the key fields that are involved in SLT. To access the SLT settings tab: From the main menu, select Administration > Configuration > Studio. From the drop-down at the top of the page, select Incident, Request, or a custom record type created in Studio. Click the SLT settings tab. After saving the changes made to an SLT setting, you need to click the Apply button to apply the changes. You can't apply the changes to an SLT setting if the former setting is applied for the records at present. In this case, an error message is displayed when you click the Apply button. Configure SLT settings for requests and incide",
    "url": "sltsettings",
    "filename": "sltsettings",
    "headings": [
      "Configure SLT settings for requests and incidents",
      "Enable and disable automatic notifications for incidents or requests",
      "Configure fields for SLT calculation",
      "Enable the SLT settings for custom record types created in Studio"
    ],
    "keywords": [
      "slt",
      "settings",
      "configure",
      "requests",
      "incidents",
      "enable",
      "disable",
      "automatic",
      "notifications",
      "fields",
      "calculation",
      "custom",
      "record",
      "types",
      "created",
      "studio",
      "out-of-the-box",
      "tab",
      "enables",
      "control",
      "email",
      "service",
      "management",
      "sends",
      "level",
      "target",
      "approaches",
      "breach",
      "threshold.",
      "described",
      "notifications.",
      "key",
      "involved",
      "slt.",
      "access",
      "main",
      "menu",
      "select",
      "administration",
      "configuration",
      "studio.",
      "drop-down",
      "top",
      "page",
      "incident",
      "request",
      "type",
      "click",
      "tab.",
      "after",
      "saving",
      "changes",
      "made",
      "setting",
      "need",
      "apply",
      "button",
      "changes.",
      "former",
      "applied",
      "records",
      "present.",
      "case",
      "error",
      "message",
      "displayed",
      "button.",
      "follows.",
      "off",
      "save.",
      "selected",
      "enabled",
      "disabled",
      "according",
      "selection",
      "all",
      "type.",
      "displays",
      "following.",
      "section",
      "targets",
      "support",
      "initial",
      "review",
      "resolution",
      "time",
      "group",
      "fulfillment",
      "hr",
      "manually",
      "add",
      "notification",
      "specific",
      "defining",
      "business",
      "rule.",
      "ensures",
      "sent",
      "even",
      "set"
    ],
    "language": "en",
    "word_count": 101,
    "importance_score": 5.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "slt settings",
    "contentLower": "for out-of-the-box record types, the slt settings tab enables you to control the out-of-the-box email notifications that service management sends as a service level target approaches a breach threshold. the notifications are described in notifications. for custom record types you have created in studio, the slt settings tab enables you to control the slt calculation and configure the key fields that are involved in slt. to access the slt settings tab: from the main menu, select administration > configuration > studio. from the drop-down at the top of the page, select incident, request, or a custom record type created in studio. click the slt settings tab. after saving the changes made to an slt setting, you need to click the apply button to apply the changes. you can't apply the changes to an slt setting if the former setting is applied for the records at present. in this case, an error message is displayed when you click the apply button. configure slt settings for requests and incide",
    "keywordsLower": [
      "slt",
      "settings",
      "configure",
      "requests",
      "incidents",
      "enable",
      "disable",
      "automatic",
      "notifications",
      "fields",
      "calculation",
      "custom",
      "record",
      "types",
      "created",
      "studio",
      "out-of-the-box",
      "tab",
      "enables",
      "control",
      "email",
      "service",
      "management",
      "sends",
      "level",
      "target",
      "approaches",
      "breach",
      "threshold.",
      "described",
      "notifications.",
      "key",
      "involved",
      "slt.",
      "access",
      "main",
      "menu",
      "select",
      "administration",
      "configuration",
      "studio.",
      "drop-down",
      "top",
      "page",
      "incident",
      "request",
      "type",
      "click",
      "tab.",
      "after",
      "saving",
      "changes",
      "made",
      "setting",
      "need",
      "apply",
      "button",
      "changes.",
      "former",
      "applied",
      "records",
      "present.",
      "case",
      "error",
      "message",
      "displayed",
      "button.",
      "follows.",
      "off",
      "save.",
      "selected",
      "enabled",
      "disabled",
      "according",
      "selection",
      "all",
      "type.",
      "displays",
      "following.",
      "section",
      "targets",
      "support",
      "initial",
      "review",
      "resolution",
      "time",
      "group",
      "fulfillment",
      "hr",
      "manually",
      "add",
      "notification",
      "specific",
      "defining",
      "business",
      "rule.",
      "ensures",
      "sent",
      "even",
      "set"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Record level access control",
    "content": "The Access control tab in Studio offers an Enable Record Level Access Control (RLAC) option that enables a tenant admin to implement record level access control for agent users. For example, the tenant admin can configure RLAC for Request to allow only the assignee and assignment group to access a request. Currently, this feature supports only View access control at the record level. For Create, Update, and Delete access control, you can use business rules. RLAC is designed mainly for agent users and has no impact on Service Portal users except in some customization use cases. For a comparison of RLAC and other data access control tools such as data domain segmentation and entitlement rules, see Service Management data access control tools. RLAC overview This section explains how RLAC works and describes its limitations. Supported record types The Access control tab in Studio is available for most out-of-the-box record types and all custom record types. Unsupported record types include",
    "url": "rlacsettings",
    "filename": "rlacsettings",
    "headings": [
      "RLAC overview",
      "Supported record types",
      "RLAC handling for main or parent records",
      "Main records",
      "Parent record preview",
      "Supported field types in the RLAC filter",
      "Using indexed fields for optimal performance",
      "RLAC limitations",
      "Configure record level access control",
      "Configure access control fields",
      "Configure users to bypass RLAC",
      "Related topics"
    ],
    "keywords": [
      "Studio.Open",
      "Aviator.When",
      "configuration.If",
      "record.M2M",
      "record",
      "level",
      "access",
      "control",
      "rlac",
      "overview",
      "supported",
      "types",
      "handling",
      "main",
      "parent",
      "records",
      "preview",
      "field",
      "filter",
      "indexed",
      "fields",
      "optimal",
      "performance",
      "limitations",
      "configure",
      "users",
      "bypass",
      "related",
      "topics",
      "tab",
      "studio",
      "offers",
      "enable",
      "option",
      "enables",
      "tenant",
      "admin",
      "implement",
      "agent",
      "users.",
      "example",
      "request",
      "allow",
      "assignee",
      "assignment",
      "group",
      "request.",
      "currently",
      "feature",
      "supports",
      "view",
      "level.",
      "create",
      "update",
      "delete",
      "business",
      "rules.",
      "designed",
      "mainly",
      "impact",
      "service",
      "portal",
      "except",
      "customization",
      "cases.",
      "comparison",
      "data",
      "tools",
      "such",
      "domain",
      "segmentation",
      "entitlement",
      "rules",
      "see",
      "management",
      "tools.",
      "section",
      "explains",
      "works",
      "describes",
      "limitations.",
      "available",
      "most",
      "out-of-the-box",
      "all",
      "custom",
      "types.",
      "unsupported",
      "include",
      "person",
      "rule",
      "notification",
      "history",
      "event",
      "aviator",
      "model",
      "cost",
      "allocation",
      "fulfillment",
      "plan"
    ],
    "language": "en",
    "word_count": 112,
    "importance_score": 6.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "record level access control",
    "contentLower": "the access control tab in studio offers an enable record level access control (rlac) option that enables a tenant admin to implement record level access control for agent users. for example, the tenant admin can configure rlac for request to allow only the assignee and assignment group to access a request. currently, this feature supports only view access control at the record level. for create, update, and delete access control, you can use business rules. rlac is designed mainly for agent users and has no impact on service portal users except in some customization use cases. for a comparison of rlac and other data access control tools such as data domain segmentation and entitlement rules, see service management data access control tools. rlac overview this section explains how rlac works and describes its limitations. supported record types the access control tab in studio is available for most out-of-the-box record types and all custom record types. unsupported record types include",
    "keywordsLower": [
      "studio.open",
      "aviator.when",
      "configuration.if",
      "record.m2m",
      "record",
      "level",
      "access",
      "control",
      "rlac",
      "overview",
      "supported",
      "types",
      "handling",
      "main",
      "parent",
      "records",
      "preview",
      "field",
      "filter",
      "indexed",
      "fields",
      "optimal",
      "performance",
      "limitations",
      "configure",
      "users",
      "bypass",
      "related",
      "topics",
      "tab",
      "studio",
      "offers",
      "enable",
      "option",
      "enables",
      "tenant",
      "admin",
      "implement",
      "agent",
      "users.",
      "example",
      "request",
      "allow",
      "assignee",
      "assignment",
      "group",
      "request.",
      "currently",
      "feature",
      "supports",
      "view",
      "level.",
      "create",
      "update",
      "delete",
      "business",
      "rules.",
      "designed",
      "mainly",
      "impact",
      "service",
      "portal",
      "except",
      "customization",
      "cases.",
      "comparison",
      "data",
      "tools",
      "such",
      "domain",
      "segmentation",
      "entitlement",
      "rules",
      "see",
      "management",
      "tools.",
      "section",
      "explains",
      "works",
      "describes",
      "limitations.",
      "available",
      "most",
      "out-of-the-box",
      "all",
      "custom",
      "types.",
      "unsupported",
      "include",
      "person",
      "rule",
      "notification",
      "history",
      "event",
      "aviator",
      "model",
      "cost",
      "allocation",
      "fulfillment",
      "plan"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Studio best practices",
    "content": "The Studio functionality in Service Management has been enhanced to allow the creation of custom record types and applications. These custom components may be exported and moved between Service Management systems. Therefore, when building custom applications, it is important to consider how they will interact with the out-of-the-box applications. Before you start Taking the time to plan and design your custom application is the most important step in the process. Mapping out your process before you begin may highlight issues or conflicts that you did not anticipate. Furthermore, some of the customizations available can not be removed from the system once they have been created. Take the time to design the application. Don't rush into the implementation until you can at least answer the following questions: What does the complete data model look like? What relationships will you need to define (especially 1-to-many and many-to-many links)? Are links to any existing applications or exist",
    "url": "studiobestpractice",
    "filename": "studiobestpractice",
    "headings": [
      "Before you start",
      "Naming conventions",
      "Creating your application",
      "Menu",
      "Primary key decision",
      "Attributes",
      "Form design",
      "Workflows",
      "Examples",
      "Rules",
      "Lists",
      "Cross module modifications",
      "Template for manual changes",
      "Entity Definition",
      "Forms",
      "Workflow",
      "Meta-Phases (steps)",
      "Phases",
      "Rules",
      "Notifications"
    ],
    "keywords": [
      "nextaction.com",
      "myaction.com",
      "entity.Name",
      "entity.Id",
      "entity.Type",
      "ParentLocation.Name",
      "studio",
      "best",
      "practices",
      "before",
      "start",
      "naming",
      "conventions",
      "creating",
      "application",
      "menu",
      "primary",
      "key",
      "decision",
      "attributes",
      "form",
      "design",
      "workflows",
      "examples",
      "rules",
      "lists",
      "cross",
      "module",
      "modifications",
      "template",
      "manual",
      "changes",
      "entity",
      "definition",
      "forms",
      "workflow",
      "meta-phases",
      "steps",
      "phases",
      "notifications",
      "approval",
      "definitions",
      "custom",
      "actions",
      "slt",
      "settings",
      "global",
      "search",
      "cross-record",
      "roles",
      "functionality",
      "service",
      "management",
      "enhanced",
      "allow",
      "creation",
      "record",
      "types",
      "applications.",
      "components",
      "exported",
      "moved",
      "between",
      "systems.",
      "therefore",
      "building",
      "applications",
      "important",
      "consider",
      "interact",
      "out-of-the-box",
      "taking",
      "time",
      "plan",
      "most",
      "step",
      "process.",
      "mapping",
      "out",
      "process",
      "begin",
      "highlight",
      "issues",
      "conflicts",
      "anticipate.",
      "furthermore",
      "customizations",
      "available",
      "removed",
      "system",
      "once",
      "created.",
      "take",
      "application.",
      "don",
      "rush",
      "implementation",
      "until",
      "least",
      "answer"
    ],
    "language": "en",
    "word_count": 91,
    "importance_score": 6.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "studio best practices",
    "contentLower": "the studio functionality in service management has been enhanced to allow the creation of custom record types and applications. these custom components may be exported and moved between service management systems. therefore, when building custom applications, it is important to consider how they will interact with the out-of-the-box applications. before you start taking the time to plan and design your custom application is the most important step in the process. mapping out your process before you begin may highlight issues or conflicts that you did not anticipate. furthermore, some of the customizations available can not be removed from the system once they have been created. take the time to design the application. don't rush into the implementation until you can at least answer the following questions: what does the complete data model look like? what relationships will you need to define (especially 1-to-many and many-to-many links)? are links to any existing applications or exist",
    "keywordsLower": [
      "nextaction.com",
      "myaction.com",
      "entity.name",
      "entity.id",
      "entity.type",
      "parentlocation.name",
      "studio",
      "best",
      "practices",
      "before",
      "start",
      "naming",
      "conventions",
      "creating",
      "application",
      "menu",
      "primary",
      "key",
      "decision",
      "attributes",
      "form",
      "design",
      "workflows",
      "examples",
      "rules",
      "lists",
      "cross",
      "module",
      "modifications",
      "template",
      "manual",
      "changes",
      "entity",
      "definition",
      "forms",
      "workflow",
      "meta-phases",
      "steps",
      "phases",
      "notifications",
      "approval",
      "definitions",
      "custom",
      "actions",
      "slt",
      "settings",
      "global",
      "search",
      "cross-record",
      "roles",
      "functionality",
      "service",
      "management",
      "enhanced",
      "allow",
      "creation",
      "record",
      "types",
      "applications.",
      "components",
      "exported",
      "moved",
      "between",
      "systems.",
      "therefore",
      "building",
      "applications",
      "important",
      "consider",
      "interact",
      "out-of-the-box",
      "taking",
      "time",
      "plan",
      "most",
      "step",
      "process.",
      "mapping",
      "out",
      "process",
      "begin",
      "highlight",
      "issues",
      "conflicts",
      "anticipate.",
      "furthermore",
      "customizations",
      "available",
      "removed",
      "system",
      "once",
      "created.",
      "take",
      "application.",
      "don",
      "rush",
      "implementation",
      "until",
      "least",
      "answer"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Studio tutorial (part 1)",
    "content": "Using the Studio functionality in Service Management, customers and partners can develop new applications inside the product. With the available tools, a variety of useful functionality may be created. In this tutorial, you will create a Training application that will allow instructors to define the available courses, schedule specific classes, and track the students in these classes (and even grade their performance). The tutorial itself will be split into multiple parts. In part one, you will design and implement the needed record types for the application and the roles needed to control them. The components built in this section will be new to the system and completely self-contained. Part two of the tutorial will expand our application to allow end users to sign up for specific classes using the Service Catalog. Designing the Training Application One of the most important steps in creating our application comes before you make the actual configuration changes. Designing the applica",
    "url": "studiotutorial1",
    "filename": "studiotutorial1",
    "headings": [
      "Designing the Training Application",
      "List high-level functionality",
      "Create an Entity Model Diagram",
      "Plan the Menu Structure",
      "Implementation",
      "Add the Training Application",
      "Create the New Record Types",
      "Create the Course record type",
      "Add Fields to the Course record type",
      "Create the Class Record Type",
      "Create the Grade List",
      "Create the Student Record Type",
      "Add Forms for the New Record Types",
      "Course Forms",
      "Class Forms",
      "Student Forms",
      "Creating Process and Rules (Workflow)",
      "Adding Course Workflow",
      "Adding Course Rules",
      "Adding Class Workflow"
    ],
    "keywords": [
      "Student_c.Name",
      "studio",
      "tutorial",
      "part",
      "designing",
      "training",
      "application",
      "list",
      "high-level",
      "functionality",
      "create",
      "entity",
      "model",
      "diagram",
      "plan",
      "menu",
      "structure",
      "implementation",
      "add",
      "new",
      "record",
      "types",
      "course",
      "type",
      "fields",
      "class",
      "grade",
      "student",
      "forms",
      "creating",
      "process",
      "rules",
      "workflow",
      "adding",
      "activating",
      "role",
      "setting",
      "display",
      "label",
      "field",
      "allow",
      "classes",
      "available",
      "courses",
      "next",
      "steps",
      "service",
      "management",
      "customers",
      "partners",
      "develop",
      "applications",
      "inside",
      "product.",
      "tools",
      "variety",
      "useful",
      "created.",
      "instructors",
      "define",
      "schedule",
      "specific",
      "track",
      "students",
      "even",
      "performance",
      "itself",
      "split",
      "multiple",
      "parts.",
      "one",
      "design",
      "implement",
      "needed",
      "roles",
      "control",
      "them.",
      "components",
      "built",
      "section",
      "system",
      "completely",
      "self-contained.",
      "two",
      "expand",
      "end",
      "users",
      "sign",
      "catalog.",
      "most",
      "important",
      "comes",
      "before",
      "make",
      "actual",
      "configuration",
      "changes.",
      "front",
      "allows",
      "verify"
    ],
    "language": "en",
    "word_count": 93,
    "importance_score": 6.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "studio tutorial (part 1)",
    "contentLower": "using the studio functionality in service management, customers and partners can develop new applications inside the product. with the available tools, a variety of useful functionality may be created. in this tutorial, you will create a training application that will allow instructors to define the available courses, schedule specific classes, and track the students in these classes (and even grade their performance). the tutorial itself will be split into multiple parts. in part one, you will design and implement the needed record types for the application and the roles needed to control them. the components built in this section will be new to the system and completely self-contained. part two of the tutorial will expand our application to allow end users to sign up for specific classes using the service catalog. designing the training application one of the most important steps in creating our application comes before you make the actual configuration changes. designing the applica",
    "keywordsLower": [
      "student_c.name",
      "studio",
      "tutorial",
      "part",
      "designing",
      "training",
      "application",
      "list",
      "high-level",
      "functionality",
      "create",
      "entity",
      "model",
      "diagram",
      "plan",
      "menu",
      "structure",
      "implementation",
      "add",
      "new",
      "record",
      "types",
      "course",
      "type",
      "fields",
      "class",
      "grade",
      "student",
      "forms",
      "creating",
      "process",
      "rules",
      "workflow",
      "adding",
      "activating",
      "role",
      "setting",
      "display",
      "label",
      "field",
      "allow",
      "classes",
      "available",
      "courses",
      "next",
      "steps",
      "service",
      "management",
      "customers",
      "partners",
      "develop",
      "applications",
      "inside",
      "product.",
      "tools",
      "variety",
      "useful",
      "created.",
      "instructors",
      "define",
      "schedule",
      "specific",
      "track",
      "students",
      "even",
      "performance",
      "itself",
      "split",
      "multiple",
      "parts.",
      "one",
      "design",
      "implement",
      "needed",
      "roles",
      "control",
      "them.",
      "components",
      "built",
      "section",
      "system",
      "completely",
      "self-contained.",
      "two",
      "expand",
      "end",
      "users",
      "sign",
      "catalog.",
      "most",
      "important",
      "comes",
      "before",
      "make",
      "actual",
      "configuration",
      "changes.",
      "front",
      "allows",
      "verify"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Studio tutorial (part 2)",
    "content": "The first section of this tutorial described how to build a simple Training application where an instructor could add courses, schedule classes, and add students to those classes. In part two of the tutorial, you will create the functionality that will allow the students themselves to sign up for classes. This involves automatically creating a Service Offering for a class once it becomes available. Adding Classes to the Service Catalog The easiest way to make the classes available to the end users is to make them available in the Service Catalog. This will allow the end users to sign up for a class through the End User Portal. You will create the necessary functionality to automatically create an Offering which will add the end user to a class as a student. Setting up the Service Catalog Category and Service Every Offering in the Service Catalog must be assigned to a Service in the Service Asset Configuration Management module (SACM). Additionally, the Service must be associated with a",
    "url": "studiotutorial2",
    "filename": "studiotutorial2",
    "headings": [
      "Adding Classes to the Service Catalog",
      "Setting up the Service Catalog Category and Service",
      "Create a new field in the Offering record",
      "Creating the Fulfillment Plan",
      "Creating the Service Offering with a Rule",
      "Creating the Service Offering",
      "Granting Access using a Custom ESS Role"
    ],
    "keywords": [
      "studio",
      "tutorial",
      "part",
      "adding",
      "classes",
      "service",
      "catalog",
      "setting",
      "category",
      "create",
      "new",
      "field",
      "offering",
      "record",
      "creating",
      "fulfillment",
      "plan",
      "rule",
      "granting",
      "access",
      "custom",
      "ess",
      "role",
      "first",
      "section",
      "described",
      "build",
      "simple",
      "training",
      "application",
      "instructor",
      "add",
      "courses",
      "schedule",
      "students",
      "classes.",
      "two",
      "functionality",
      "allow",
      "themselves",
      "sign",
      "involves",
      "automatically",
      "class",
      "once",
      "becomes",
      "available.",
      "easiest",
      "way",
      "make",
      "available",
      "end",
      "users",
      "catalog.",
      "through",
      "user",
      "portal.",
      "necessary",
      "student.",
      "every",
      "assigned",
      "asset",
      "configuration",
      "management",
      "module",
      "sacm",
      "additionally",
      "associated",
      "inside",
      "category.",
      "menu",
      "select",
      "button",
      "top",
      "list.",
      "minimum",
      "need",
      "give",
      "display",
      "label",
      "description.",
      "finally",
      "press",
      "save",
      "button.",
      "now",
      "list",
      "categories",
      "option",
      "empty",
      "fill",
      "something",
      "similar.",
      "set",
      "subtype",
      "business",
      "description",
      "displayed",
      "edit",
      "option."
    ],
    "language": "en",
    "word_count": 94,
    "importance_score": 6.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "studio tutorial (part 2)",
    "contentLower": "the first section of this tutorial described how to build a simple training application where an instructor could add courses, schedule classes, and add students to those classes. in part two of the tutorial, you will create the functionality that will allow the students themselves to sign up for classes. this involves automatically creating a service offering for a class once it becomes available. adding classes to the service catalog the easiest way to make the classes available to the end users is to make them available in the service catalog. this will allow the end users to sign up for a class through the end user portal. you will create the necessary functionality to automatically create an offering which will add the end user to a class as a student. setting up the service catalog category and service every offering in the service catalog must be assigned to a service in the service asset configuration management module (sacm). additionally, the service must be associated with a",
    "keywordsLower": [
      "studio",
      "tutorial",
      "part",
      "adding",
      "classes",
      "service",
      "catalog",
      "setting",
      "category",
      "create",
      "new",
      "field",
      "offering",
      "record",
      "creating",
      "fulfillment",
      "plan",
      "rule",
      "granting",
      "access",
      "custom",
      "ess",
      "role",
      "first",
      "section",
      "described",
      "build",
      "simple",
      "training",
      "application",
      "instructor",
      "add",
      "courses",
      "schedule",
      "students",
      "classes.",
      "two",
      "functionality",
      "allow",
      "themselves",
      "sign",
      "involves",
      "automatically",
      "class",
      "once",
      "becomes",
      "available.",
      "easiest",
      "way",
      "make",
      "available",
      "end",
      "users",
      "catalog.",
      "through",
      "user",
      "portal.",
      "necessary",
      "student.",
      "every",
      "assigned",
      "asset",
      "configuration",
      "management",
      "module",
      "sacm",
      "additionally",
      "associated",
      "inside",
      "category.",
      "menu",
      "select",
      "button",
      "top",
      "list.",
      "minimum",
      "need",
      "give",
      "display",
      "label",
      "description.",
      "finally",
      "press",
      "save",
      "button.",
      "now",
      "list",
      "categories",
      "option",
      "empty",
      "fill",
      "something",
      "similar.",
      "set",
      "subtype",
      "business",
      "description",
      "displayed",
      "edit",
      "option."
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Synchronize authentication type information from Suite Administration",
    "content": "If you upgraded from an earlier release, the Authentication type field on the General tab of a user record added before the upgrade will be empty. To display the authentication type values for your existing user records, you must run a script contained in the SMA Operation Toolkit. To do this: Back up the entities_<tenantID> file in your database. Download the SMA Operation Toolkit. Based on your deployment, run the following script in the SMAX_sync_authType folder of the package on the runtime platform. For a classic deployment, run the sync_auth_type.sh script. For a helm deployment, run the sync_auth_type_helm.sh script. The script retrieves the value from the user records in Suite Administration and populates the Authentication type field for existing user records in Service Management. For more information about how to run the script, see How to run scripts on the runtime platform.",
    "url": "getauthtypefield",
    "filename": "getauthtypefield",
    "headings": [],
    "keywords": [
      "sync_auth_type_helm.sh",
      "sync_auth_type.sh",
      "synchronize",
      "authentication",
      "type",
      "information",
      "suite",
      "administration",
      "upgraded",
      "earlier",
      "release",
      "field",
      "general",
      "tab",
      "user",
      "record",
      "added",
      "before",
      "upgrade",
      "empty.",
      "display",
      "values",
      "existing",
      "records",
      "run",
      "script",
      "contained",
      "sma",
      "operation",
      "toolkit.",
      "back",
      "file",
      "database.",
      "download",
      "based",
      "deployment",
      "following",
      "folder",
      "package",
      "runtime",
      "platform.",
      "classic",
      "script.",
      "helm",
      "retrieves",
      "value",
      "populates",
      "service",
      "management.",
      "about",
      "see",
      "scripts"
    ],
    "language": "en",
    "word_count": 86,
    "importance_score": 2.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "synchronize authentication type information from suite administration",
    "contentLower": "if you upgraded from an earlier release, the authentication type field on the general tab of a user record added before the upgrade will be empty. to display the authentication type values for your existing user records, you must run a script contained in the sma operation toolkit. to do this: back up the entities_<tenantid> file in your database. download the sma operation toolkit. based on your deployment, run the following script in the smax_sync_authtype folder of the package on the runtime platform. for a classic deployment, run the sync_auth_type.sh script. for a helm deployment, run the sync_auth_type_helm.sh script. the script retrieves the value from the user records in suite administration and populates the authentication type field for existing user records in service management. for more information about how to run the script, see how to run scripts on the runtime platform.",
    "keywordsLower": [
      "sync_auth_type_helm.sh",
      "sync_auth_type.sh",
      "synchronize",
      "authentication",
      "type",
      "information",
      "suite",
      "administration",
      "upgraded",
      "earlier",
      "release",
      "field",
      "general",
      "tab",
      "user",
      "record",
      "added",
      "before",
      "upgrade",
      "empty.",
      "display",
      "values",
      "existing",
      "records",
      "run",
      "script",
      "contained",
      "sma",
      "operation",
      "toolkit.",
      "back",
      "file",
      "database.",
      "download",
      "based",
      "deployment",
      "following",
      "folder",
      "package",
      "runtime",
      "platform.",
      "classic",
      "script.",
      "helm",
      "retrieves",
      "value",
      "populates",
      "service",
      "management.",
      "about",
      "see",
      "scripts"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Roles",
    "content": "Service Management has built-in roles according to industry best practice recommendations. Large companies might have several people assigned to the same role. Smaller organizations might have more than one role assigned to one person. Maintaining a role-based view of the organization ensures you adhere to the best practice model. You can adhere to the best practice model, no matter who you assign to the role or how you divide the responsibilities associated with the role. For example, if your company is large, you may have separate process designers and process owners assigned to each module. A smaller company might assign both roles to one person for each module. Permissions are controls within applications. When assigned, they enable you to complete certain Service Management tasks, such as adding updated information to a record. Permissions are an administrative strategy to control access to records and limit the number of people who can view, create, update, or delete records. Per",
    "url": "pplroles",
    "filename": "pplroles",
    "headings": [
      "Out of the box roles",
      "How to create a role",
      "How to edit role permissions",
      "General",
      "Reports & Views",
      "Security",
      "Record Type",
      "Resources",
      "Resource list",
      "Knowledge Management",
      "Questions & Answers",
      "Live Support",
      "Aviator",
      "On-Call Schedule",
      "Change Management",
      "Service Portal administration",
      "Approvals",
      "SACM",
      "On-Premise Bridge/Integration",
      "Analysis"
    ],
    "keywords": [
      "10.20",
      "role.If",
      "1.0",
      "tenants.For",
      "25.4",
      "role.Type",
      "type.To",
      "pane.Type",
      "2.0",
      "roles",
      "out",
      "box",
      "create",
      "role",
      "edit",
      "permissions",
      "general",
      "reports",
      "views",
      "security",
      "record",
      "type",
      "resources",
      "resource",
      "list",
      "knowledge",
      "management",
      "questions",
      "answers",
      "live",
      "support",
      "aviator",
      "on-call",
      "schedule",
      "change",
      "service",
      "portal",
      "administration",
      "approvals",
      "sacm",
      "on-premise",
      "bridge",
      "integration",
      "analysis",
      "tasks",
      "menu",
      "visibility",
      "assign",
      "user",
      "unassign",
      "group",
      "related",
      "topics",
      "built-in",
      "according",
      "industry",
      "best",
      "practice",
      "recommendations.",
      "large",
      "companies",
      "several",
      "people",
      "assigned",
      "same",
      "role.",
      "smaller",
      "organizations",
      "one",
      "person.",
      "maintaining",
      "role-based",
      "view",
      "organization",
      "ensures",
      "adhere",
      "model.",
      "model",
      "matter",
      "divide",
      "responsibilities",
      "associated",
      "example",
      "company",
      "separate",
      "process",
      "designers",
      "owners",
      "module.",
      "both",
      "person",
      "controls",
      "applications.",
      "enable",
      "complete",
      "certain",
      "such",
      "adding",
      "updated",
      "information"
    ],
    "language": "en",
    "word_count": 92,
    "importance_score": 6.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "roles",
    "contentLower": "service management has built-in roles according to industry best practice recommendations. large companies might have several people assigned to the same role. smaller organizations might have more than one role assigned to one person. maintaining a role-based view of the organization ensures you adhere to the best practice model. you can adhere to the best practice model, no matter who you assign to the role or how you divide the responsibilities associated with the role. for example, if your company is large, you may have separate process designers and process owners assigned to each module. a smaller company might assign both roles to one person for each module. permissions are controls within applications. when assigned, they enable you to complete certain service management tasks, such as adding updated information to a record. permissions are an administrative strategy to control access to records and limit the number of people who can view, create, update, or delete records. per",
    "keywordsLower": [
      "10.20",
      "role.if",
      "1.0",
      "tenants.for",
      "25.4",
      "role.type",
      "type.to",
      "pane.type",
      "2.0",
      "roles",
      "out",
      "box",
      "create",
      "role",
      "edit",
      "permissions",
      "general",
      "reports",
      "views",
      "security",
      "record",
      "type",
      "resources",
      "resource",
      "list",
      "knowledge",
      "management",
      "questions",
      "answers",
      "live",
      "support",
      "aviator",
      "on-call",
      "schedule",
      "change",
      "service",
      "portal",
      "administration",
      "approvals",
      "sacm",
      "on-premise",
      "bridge",
      "integration",
      "analysis",
      "tasks",
      "menu",
      "visibility",
      "assign",
      "user",
      "unassign",
      "group",
      "related",
      "topics",
      "built-in",
      "according",
      "industry",
      "best",
      "practice",
      "recommendations.",
      "large",
      "companies",
      "several",
      "people",
      "assigned",
      "same",
      "role.",
      "smaller",
      "organizations",
      "one",
      "person.",
      "maintaining",
      "role-based",
      "view",
      "organization",
      "ensures",
      "adhere",
      "model.",
      "model",
      "matter",
      "divide",
      "responsibilities",
      "associated",
      "example",
      "company",
      "separate",
      "process",
      "designers",
      "owners",
      "module.",
      "both",
      "person",
      "controls",
      "applications.",
      "enable",
      "complete",
      "certain",
      "such",
      "adding",
      "updated",
      "information"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Set up synchronization with LDAP",
    "content": "You can synchronize person and group records from an LDAP server to Service Management via the On-Premises Bridge. When you configure the endpoint for the integration, you can define field mappings between the LDAP fields and the record fields in Service Management. For details, see Related topics. Related topics Integrate with LDAP",
    "url": "ldap",
    "filename": "ldap",
    "headings": [
      "Related topics"
    ],
    "keywords": [
      "set",
      "synchronization",
      "ldap",
      "related",
      "topics",
      "synchronize",
      "person",
      "group",
      "records",
      "server",
      "service",
      "management",
      "via",
      "on-premises",
      "bridge.",
      "configure",
      "endpoint",
      "integration",
      "define",
      "field",
      "mappings",
      "between",
      "fields",
      "record",
      "management.",
      "details",
      "see",
      "topics.",
      "integrate"
    ],
    "language": "en",
    "word_count": 35,
    "importance_score": 2.5,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "set up synchronization with ldap",
    "contentLower": "you can synchronize person and group records from an ldap server to service management via the on-premises bridge. when you configure the endpoint for the integration, you can define field mappings between the ldap fields and the record fields in service management. for details, see related topics. related topics integrate with ldap",
    "keywordsLower": [
      "set",
      "synchronization",
      "ldap",
      "related",
      "topics",
      "synchronize",
      "person",
      "group",
      "records",
      "server",
      "service",
      "management",
      "via",
      "on-premises",
      "bridge.",
      "configure",
      "endpoint",
      "integration",
      "define",
      "field",
      "mappings",
      "between",
      "fields",
      "record",
      "management.",
      "details",
      "see",
      "topics.",
      "integrate"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Routing definitions",
    "content": "Service Management provides an automatic routing solution for routing records to the correct groups based on the information contained in the record. The Routing Definitions module enables you to create and edit a visual routing definition which is easy to read and maintain. The routing definition appears as a tree diagram with four rows, known as lanes. The top lane includes only the root node of the definition. In the lower lanes, you can add nodes defining a path to follow when routing records to a specific group. The routing definitions are designed to be used in connection with the Set field based on routing definition business rule. The rule enables you to assign a value to a group field for a record based on the path defined in the selected routing definition. Alternatively, you can use a routing definition in connection with the Define suggested values based on routing definition business rule. The rule enables you to specify the values that appear in the drop-down list for a s",
    "url": "routingdefovw",
    "filename": "routingdefovw",
    "headings": [
      "Create a routing definition",
      "Routing definition use case - setting a field value",
      "Routing definition use case - defining suggested values",
      "Related topics"
    ],
    "keywords": [
      "Location.Id",
      "routing",
      "definitions",
      "create",
      "definition",
      "case",
      "setting",
      "field",
      "value",
      "defining",
      "suggested",
      "values",
      "related",
      "topics",
      "service",
      "management",
      "provides",
      "automatic",
      "solution",
      "records",
      "correct",
      "groups",
      "based",
      "information",
      "contained",
      "record.",
      "module",
      "enables",
      "edit",
      "visual",
      "easy",
      "read",
      "maintain.",
      "appears",
      "tree",
      "diagram",
      "four",
      "rows",
      "known",
      "lanes.",
      "top",
      "lane",
      "includes",
      "root",
      "node",
      "definition.",
      "lower",
      "lanes",
      "add",
      "nodes",
      "path",
      "follow",
      "specific",
      "group.",
      "designed",
      "connection",
      "set",
      "business",
      "rule.",
      "rule",
      "assign",
      "group",
      "record",
      "defined",
      "selected",
      "alternatively",
      "define",
      "specify",
      "appear",
      "drop-down",
      "list",
      "rules",
      "see",
      "studio",
      "rules.",
      "aren",
      "supported",
      "dev2prod",
      "functionality.",
      "any",
      "development",
      "environment",
      "manually",
      "redefined",
      "production",
      "environment.",
      "main",
      "menu",
      "select",
      "administration",
      "configuration",
      "definitions.",
      "pane",
      "left",
      "click",
      "new.",
      "enter",
      "name",
      "description",
      "launch"
    ],
    "language": "en",
    "word_count": 98,
    "importance_score": 5.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "routing definitions",
    "contentLower": "service management provides an automatic routing solution for routing records to the correct groups based on the information contained in the record. the routing definitions module enables you to create and edit a visual routing definition which is easy to read and maintain. the routing definition appears as a tree diagram with four rows, known as lanes. the top lane includes only the root node of the definition. in the lower lanes, you can add nodes defining a path to follow when routing records to a specific group. the routing definitions are designed to be used in connection with the set field based on routing definition business rule. the rule enables you to assign a value to a group field for a record based on the path defined in the selected routing definition. alternatively, you can use a routing definition in connection with the define suggested values based on routing definition business rule. the rule enables you to specify the values that appear in the drop-down list for a s",
    "keywordsLower": [
      "location.id",
      "routing",
      "definitions",
      "create",
      "definition",
      "case",
      "setting",
      "field",
      "value",
      "defining",
      "suggested",
      "values",
      "related",
      "topics",
      "service",
      "management",
      "provides",
      "automatic",
      "solution",
      "records",
      "correct",
      "groups",
      "based",
      "information",
      "contained",
      "record.",
      "module",
      "enables",
      "edit",
      "visual",
      "easy",
      "read",
      "maintain.",
      "appears",
      "tree",
      "diagram",
      "four",
      "rows",
      "known",
      "lanes.",
      "top",
      "lane",
      "includes",
      "root",
      "node",
      "definition.",
      "lower",
      "lanes",
      "add",
      "nodes",
      "path",
      "follow",
      "specific",
      "group.",
      "designed",
      "connection",
      "set",
      "business",
      "rule.",
      "rule",
      "assign",
      "group",
      "record",
      "defined",
      "selected",
      "alternatively",
      "define",
      "specify",
      "appear",
      "drop-down",
      "list",
      "rules",
      "see",
      "studio",
      "rules.",
      "aren",
      "supported",
      "dev2prod",
      "functionality.",
      "any",
      "development",
      "environment",
      "manually",
      "redefined",
      "production",
      "environment.",
      "main",
      "menu",
      "select",
      "administration",
      "configuration",
      "definitions.",
      "pane",
      "left",
      "click",
      "new.",
      "enter",
      "name",
      "description",
      "launch"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Release transition rules",
    "content": "The following information identifies each supported transition in the Release Management workflow. The Action or Condition column in the tables for each phase, show fields that contain data either entered by the end user or automatically provided by Service Management. At the start of each phase, Service Management verifies that the user-defined values set in the last phase are unchanged. If there is a change, the record can return to a prior phase or repeat an action. All releases begin with the Log phase. Log phase Event Action or Condition After change If not set by the user, Service Management sets default values Requested by = Current user Urgency = Slight disruption Service Management transitions to the Evaluate phase if the following required fields contain data: Title Release type Description Requested by Reason for release Release model Justification Service All releases transition from Log to the Evaluate phase. Evaluate phase Event Action or Condition Entering Service Manage",
    "url": "releasetransitionrules",
    "filename": "releasetransitionrules",
    "headings": [
      "Log phase",
      "Evaluate phase",
      "Plan and design phase",
      "Build and test phase",
      "Approve deployment phase",
      "Deploy phase",
      "Remediate phase",
      "Early life support phase",
      "Review phase",
      "Close phase",
      "Abandon phase",
      "Related topics"
    ],
    "keywords": [
      "release",
      "transition",
      "rules",
      "log",
      "phase",
      "evaluate",
      "plan",
      "design",
      "build",
      "test",
      "approve",
      "deployment",
      "deploy",
      "remediate",
      "early",
      "life",
      "support",
      "review",
      "close",
      "abandon",
      "related",
      "topics",
      "following",
      "information",
      "identifies",
      "supported",
      "management",
      "workflow.",
      "action",
      "condition",
      "column",
      "tables",
      "show",
      "fields",
      "contain",
      "data",
      "either",
      "entered",
      "end",
      "user",
      "automatically",
      "provided",
      "service",
      "management.",
      "start",
      "verifies",
      "user-defined",
      "values",
      "set",
      "last",
      "unchanged.",
      "there",
      "change",
      "record",
      "return",
      "prior",
      "repeat",
      "action.",
      "all",
      "releases",
      "begin",
      "phase.",
      "event",
      "after",
      "sets",
      "default",
      "requested",
      "current",
      "urgency",
      "slight",
      "disruption",
      "transitions",
      "required",
      "title",
      "type",
      "description",
      "reason",
      "model",
      "justification",
      "entering",
      "send",
      "notification",
      "new",
      "created",
      "owner.",
      "monitor",
      "task",
      "execution",
      "plan.",
      "emergency",
      "severe",
      "one",
      "phases",
      "additional",
      "valid",
      "owning",
      "group",
      "category",
      "owner",
      "completion"
    ],
    "language": "en",
    "word_count": 107,
    "importance_score": 6.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "release transition rules",
    "contentLower": "the following information identifies each supported transition in the release management workflow. the action or condition column in the tables for each phase, show fields that contain data either entered by the end user or automatically provided by service management. at the start of each phase, service management verifies that the user-defined values set in the last phase are unchanged. if there is a change, the record can return to a prior phase or repeat an action. all releases begin with the log phase. log phase event action or condition after change if not set by the user, service management sets default values requested by = current user urgency = slight disruption service management transitions to the evaluate phase if the following required fields contain data: title release type description requested by reason for release release model justification service all releases transition from log to the evaluate phase. evaluate phase event action or condition entering service manage",
    "keywordsLower": [
      "release",
      "transition",
      "rules",
      "log",
      "phase",
      "evaluate",
      "plan",
      "design",
      "build",
      "test",
      "approve",
      "deployment",
      "deploy",
      "remediate",
      "early",
      "life",
      "support",
      "review",
      "close",
      "abandon",
      "related",
      "topics",
      "following",
      "information",
      "identifies",
      "supported",
      "management",
      "workflow.",
      "action",
      "condition",
      "column",
      "tables",
      "show",
      "fields",
      "contain",
      "data",
      "either",
      "entered",
      "end",
      "user",
      "automatically",
      "provided",
      "service",
      "management.",
      "start",
      "verifies",
      "user-defined",
      "values",
      "set",
      "last",
      "unchanged.",
      "there",
      "change",
      "record",
      "return",
      "prior",
      "repeat",
      "action.",
      "all",
      "releases",
      "begin",
      "phase.",
      "event",
      "after",
      "sets",
      "default",
      "requested",
      "current",
      "urgency",
      "slight",
      "disruption",
      "transitions",
      "required",
      "title",
      "type",
      "description",
      "reason",
      "model",
      "justification",
      "entering",
      "send",
      "notification",
      "new",
      "created",
      "owner.",
      "monitor",
      "task",
      "execution",
      "plan.",
      "emergency",
      "severe",
      "one",
      "phases",
      "additional",
      "valid",
      "owning",
      "group",
      "category",
      "owner",
      "completion"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Service definition process - Business rules",
    "content": "The service definition workflow relies on a simple business rule that applies to these phases: Plan Build Operate Decommission Retired Event Condition Service Management action Entering Set Catalog status to Inactive/Active Sets the Catalog status field to Inactive or Active, depending on the phase. Related topics Service Portfolio Management Service definitions Service definition workflow Processes and Rules",
    "url": "processservicedefn",
    "filename": "processservicedefn",
    "headings": [
      "Related topics"
    ],
    "keywords": [
      "service",
      "definition",
      "process",
      "business",
      "rules",
      "related",
      "topics",
      "workflow",
      "relies",
      "simple",
      "rule",
      "applies",
      "phases",
      "plan",
      "build",
      "operate",
      "decommission",
      "retired",
      "event",
      "condition",
      "management",
      "action",
      "entering",
      "set",
      "catalog",
      "status",
      "inactive",
      "active",
      "sets",
      "field",
      "depending",
      "phase.",
      "portfolio",
      "definitions",
      "processes"
    ],
    "language": "en",
    "word_count": 50,
    "importance_score": 1.5,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "service definition process - business rules",
    "contentLower": "the service definition workflow relies on a simple business rule that applies to these phases: plan build operate decommission retired event condition service management action entering set catalog status to inactive/active sets the catalog status field to inactive or active, depending on the phase. related topics service portfolio management service definitions service definition workflow processes and rules",
    "keywordsLower": [
      "service",
      "definition",
      "process",
      "business",
      "rules",
      "related",
      "topics",
      "workflow",
      "relies",
      "simple",
      "rule",
      "applies",
      "phases",
      "plan",
      "build",
      "operate",
      "decommission",
      "retired",
      "event",
      "condition",
      "management",
      "action",
      "entering",
      "set",
      "catalog",
      "status",
      "inactive",
      "active",
      "sets",
      "field",
      "depending",
      "phase.",
      "portfolio",
      "definitions",
      "processes"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "System element process - Business rules",
    "content": "The system element workflow relies on a simple business rule that applies to these phases: In Use Ended Event Condition Service Management action After change If Missing = true Add a comment to the record that the system element is missing. Send an email to the Owner that the system element is missing. Related topics System elements System element workflow",
    "url": "processsyselement",
    "filename": "processsyselement",
    "headings": [
      "Related topics"
    ],
    "keywords": [
      "system",
      "element",
      "process",
      "business",
      "rules",
      "related",
      "topics",
      "workflow",
      "relies",
      "simple",
      "rule",
      "applies",
      "phases",
      "ended",
      "event",
      "condition",
      "service",
      "management",
      "action",
      "after",
      "change",
      "missing",
      "true",
      "add",
      "comment",
      "record",
      "missing.",
      "send",
      "email",
      "owner",
      "elements"
    ],
    "language": "en",
    "word_count": 43,
    "importance_score": 1.5,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "system element process - business rules",
    "contentLower": "the system element workflow relies on a simple business rule that applies to these phases: in use ended event condition service management action after change if missing = true add a comment to the record that the system element is missing. send an email to the owner that the system element is missing. related topics system elements system element workflow",
    "keywordsLower": [
      "system",
      "element",
      "process",
      "business",
      "rules",
      "related",
      "topics",
      "workflow",
      "relies",
      "simple",
      "rule",
      "applies",
      "phases",
      "ended",
      "event",
      "condition",
      "service",
      "management",
      "action",
      "after",
      "change",
      "missing",
      "true",
      "add",
      "comment",
      "record",
      "missing.",
      "send",
      "email",
      "owner",
      "elements"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "SACM service component process - Business rules",
    "content": "The service component workflow relies on a simple business rule that applies to these phases: Plan Build Operate Decommission Retired Event Condition Service Management action After change If Missing = true Add a comment to the record that the service component is missing. Send an email to the Owner that the service component is missing. Related topics Service components Service component workflow Processes and Rules",
    "url": "processservcomp",
    "filename": "processservcomp",
    "headings": [
      "Related topics"
    ],
    "keywords": [
      "sacm",
      "service",
      "component",
      "process",
      "business",
      "rules",
      "related",
      "topics",
      "workflow",
      "relies",
      "simple",
      "rule",
      "applies",
      "phases",
      "plan",
      "build",
      "operate",
      "decommission",
      "retired",
      "event",
      "condition",
      "management",
      "action",
      "after",
      "change",
      "missing",
      "true",
      "add",
      "comment",
      "record",
      "missing.",
      "send",
      "email",
      "owner",
      "components",
      "processes"
    ],
    "language": "en",
    "word_count": 50,
    "importance_score": 1.5,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "sacm service component process - business rules",
    "contentLower": "the service component workflow relies on a simple business rule that applies to these phases: plan build operate decommission retired event condition service management action after change if missing = true add a comment to the record that the service component is missing. send an email to the owner that the service component is missing. related topics service components service component workflow processes and rules",
    "keywordsLower": [
      "sacm",
      "service",
      "component",
      "process",
      "business",
      "rules",
      "related",
      "topics",
      "workflow",
      "relies",
      "simple",
      "rule",
      "applies",
      "phases",
      "plan",
      "build",
      "operate",
      "decommission",
      "retired",
      "event",
      "condition",
      "management",
      "action",
      "after",
      "change",
      "missing",
      "true",
      "add",
      "comment",
      "record",
      "missing.",
      "send",
      "email",
      "owner",
      "components",
      "processes"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Subscription process - Business rules",
    "content": "The subscription process relies on a few simple business rules. Rules repeat from one phase to another when the end user can make a change to a field affected by a business rule during that phase. Subscription global rules In the out-of-the-box asset subscription workflow, the rules detailed for each of the following events apply to all processes. Event Condition Service Management actions Entering Subscription Type is empty Subscription Type = Normal After change None Start date = mandatory None Subscriber = mandatory Start date isn't empty, and End date isn't empty Validate: End date > Start date Currency isn't empty Validate: Initial cost and Recurring cost are both not empty. Display the subscription workflow error message in case of a failure. Recurring cost isn't empty Validate: Recurring period isn't empty. Display the subscription workflow error message in case of a failure. Recurring period isn't empty Validate: Recurring cost isn't empty. Display the subscription workflow err",
    "url": "processsubscription",
    "filename": "processsubscription",
    "headings": [],
    "keywords": [
      "subscription",
      "process",
      "business",
      "rules",
      "relies",
      "few",
      "simple",
      "rules.",
      "repeat",
      "one",
      "phase",
      "another",
      "end",
      "user",
      "make",
      "change",
      "field",
      "affected",
      "rule",
      "during",
      "phase.",
      "global",
      "out-of-the-box",
      "asset",
      "workflow",
      "detailed",
      "following",
      "events",
      "apply",
      "all",
      "processes.",
      "event",
      "condition",
      "service",
      "management",
      "actions",
      "entering",
      "type",
      "empty",
      "normal",
      "after",
      "none",
      "start",
      "date",
      "mandatory",
      "subscriber",
      "isn",
      "validate",
      "currency",
      "initial",
      "cost",
      "recurring",
      "both",
      "empty.",
      "display",
      "error",
      "message",
      "case",
      "failure.",
      "period",
      "subscribed",
      "device",
      "infrastructure",
      "peripheral",
      "subscriptions",
      "label",
      "first",
      "status",
      "earlier",
      "now",
      "active",
      "later",
      "pending",
      "based",
      "definition",
      "applying",
      "changes",
      "initiated",
      "request",
      "offering",
      "provider",
      "dnd",
      "current",
      "id",
      "note",
      "applicable",
      "cloud",
      "enable",
      "design",
      "deployment.",
      "rendering",
      "show",
      "list",
      "filter",
      "operate",
      "decommission",
      "actual",
      "ended",
      "canceled",
      "hidden"
    ],
    "language": "en",
    "word_count": 127,
    "importance_score": 3.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "subscription process - business rules",
    "contentLower": "the subscription process relies on a few simple business rules. rules repeat from one phase to another when the end user can make a change to a field affected by a business rule during that phase. subscription global rules in the out-of-the-box asset subscription workflow, the rules detailed for each of the following events apply to all processes. event condition service management actions entering subscription type is empty subscription type = normal after change none start date = mandatory none subscriber = mandatory start date isn't empty, and end date isn't empty validate: end date > start date currency isn't empty validate: initial cost and recurring cost are both not empty. display the subscription workflow error message in case of a failure. recurring cost isn't empty validate: recurring period isn't empty. display the subscription workflow error message in case of a failure. recurring period isn't empty validate: recurring cost isn't empty. display the subscription workflow err",
    "keywordsLower": [
      "subscription",
      "process",
      "business",
      "rules",
      "relies",
      "few",
      "simple",
      "rules.",
      "repeat",
      "one",
      "phase",
      "another",
      "end",
      "user",
      "make",
      "change",
      "field",
      "affected",
      "rule",
      "during",
      "phase.",
      "global",
      "out-of-the-box",
      "asset",
      "workflow",
      "detailed",
      "following",
      "events",
      "apply",
      "all",
      "processes.",
      "event",
      "condition",
      "service",
      "management",
      "actions",
      "entering",
      "type",
      "empty",
      "normal",
      "after",
      "none",
      "start",
      "date",
      "mandatory",
      "subscriber",
      "isn",
      "validate",
      "currency",
      "initial",
      "cost",
      "recurring",
      "both",
      "empty.",
      "display",
      "error",
      "message",
      "case",
      "failure.",
      "period",
      "subscribed",
      "device",
      "infrastructure",
      "peripheral",
      "subscriptions",
      "label",
      "first",
      "status",
      "earlier",
      "now",
      "active",
      "later",
      "pending",
      "based",
      "definition",
      "applying",
      "changes",
      "initiated",
      "request",
      "offering",
      "provider",
      "dnd",
      "current",
      "id",
      "note",
      "applicable",
      "cloud",
      "enable",
      "design",
      "deployment.",
      "rendering",
      "show",
      "list",
      "filter",
      "operate",
      "decommission",
      "actual",
      "ended",
      "canceled",
      "hidden"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Reservation process - Business rules",
    "content": "All processes In the out-of-the-box reservations workflow, the rules detailed for each of the following events apply to all processes. Before change Condition Service Management actions Phase is Close, and Reserved device isn't empty Device Phase = Prepare Phase is Close, and Reserved infrastructure & peripheral isn't empty Infrastructure & peripheral Phase = Prepare After change Condition Service Management actions Phase is Close, and Reserved device isn't empty Device Phase = In use Phase is Close, and Reserved infrastructure & peripheral isn't empty Infrastructure & peripheral Phase = In use Reserved for is empty Reserved for = the first (in the order listed) of the following that isn't empty: Requested for of Request Current user Phase is Close or Cancel, and Reserved device isn't empty Reserved device = false Phase is Close or Cancel, and Reserved infrastructure & peripheral isn't empty Reserved infrastructure & peripheral = false Display label is empty, and For Request isn't empt",
    "url": "processreservation",
    "filename": "processreservation",
    "headings": [
      "Before change",
      "After change",
      "Rendering",
      "After applying changes",
      "Active phase",
      "Ended phase",
      "Related topics"
    ],
    "keywords": [
      "reservation",
      "process",
      "business",
      "rules",
      "before",
      "change",
      "after",
      "rendering",
      "applying",
      "changes",
      "active",
      "phase",
      "ended",
      "related",
      "topics",
      "all",
      "processes",
      "out-of-the-box",
      "reservations",
      "workflow",
      "detailed",
      "following",
      "events",
      "apply",
      "processes.",
      "condition",
      "service",
      "management",
      "actions",
      "close",
      "reserved",
      "device",
      "isn",
      "empty",
      "prepare",
      "infrastructure",
      "peripheral",
      "first",
      "order",
      "listed",
      "requested",
      "request",
      "current",
      "user",
      "cancel",
      "false",
      "display",
      "label",
      "id",
      "another",
      "selected",
      "start",
      "date",
      "now",
      "end",
      "30",
      "days",
      "none",
      "validate",
      "either",
      "both",
      "true",
      "show",
      "list",
      "filters",
      "stock",
      "send",
      "notification",
      "canceled",
      "metaphases",
      "phases",
      "indicated",
      "metaphase",
      "phase.",
      "event",
      "action",
      "per",
      "schedule",
      "automatically",
      "reached",
      "create",
      "relationship",
      "between",
      "values",
      "fields"
    ],
    "language": "en",
    "word_count": 115,
    "importance_score": 6.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "reservation process - business rules",
    "contentLower": "all processes in the out-of-the-box reservations workflow, the rules detailed for each of the following events apply to all processes. before change condition service management actions phase is close, and reserved device isn't empty device phase = prepare phase is close, and reserved infrastructure & peripheral isn't empty infrastructure & peripheral phase = prepare after change condition service management actions phase is close, and reserved device isn't empty device phase = in use phase is close, and reserved infrastructure & peripheral isn't empty infrastructure & peripheral phase = in use reserved for is empty reserved for = the first (in the order listed) of the following that isn't empty: requested for of request current user phase is close or cancel, and reserved device isn't empty reserved device = false phase is close or cancel, and reserved infrastructure & peripheral isn't empty reserved infrastructure & peripheral = false display label is empty, and for request isn't empt",
    "keywordsLower": [
      "reservation",
      "process",
      "business",
      "rules",
      "before",
      "change",
      "after",
      "rendering",
      "applying",
      "changes",
      "active",
      "phase",
      "ended",
      "related",
      "topics",
      "all",
      "processes",
      "out-of-the-box",
      "reservations",
      "workflow",
      "detailed",
      "following",
      "events",
      "apply",
      "processes.",
      "condition",
      "service",
      "management",
      "actions",
      "close",
      "reserved",
      "device",
      "isn",
      "empty",
      "prepare",
      "infrastructure",
      "peripheral",
      "first",
      "order",
      "listed",
      "requested",
      "request",
      "current",
      "user",
      "cancel",
      "false",
      "display",
      "label",
      "id",
      "another",
      "selected",
      "start",
      "date",
      "now",
      "end",
      "30",
      "days",
      "none",
      "validate",
      "either",
      "both",
      "true",
      "show",
      "list",
      "filters",
      "stock",
      "send",
      "notification",
      "canceled",
      "metaphases",
      "phases",
      "indicated",
      "metaphase",
      "phase.",
      "event",
      "action",
      "per",
      "schedule",
      "automatically",
      "reached",
      "create",
      "relationship",
      "between",
      "values",
      "fields"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Setting a closed record to read-only",
    "content": "After a record has been closed, the user should not be able to update it. You can define a business rule to prevent further updates to the record. The following are several options for defining the rule: Option 1 From the main menu, select Administration > Configuration > Studio > Processes and Rules. Select the Request record type. Select the Done metaphase. In After change, click Add, then select Simple rule. In Validation rules, select Validate expression. Click OK. Click expression, and enter ${current_update.PhaseId.IsChanged}. Click error message, and enter The record is closed and cannot be edited. Click Save. In this case, the request cannot be updated after reaching the Done metaphase under any circumstances. Option 2 From the main menu, select Administration > Configuration > Studio > Processes and Rules. Select the Request record type. Select the Done metaphase. In After change, click Add, then select Simple rule. In Validation rules, select Validate expression. Click OK. Cl",
    "url": "setreadonly",
    "filename": "setreadonly",
    "headings": [
      "Option 1",
      "Option 2",
      "Option 3"
    ],
    "keywords": [
      "setting",
      "closed",
      "record",
      "read-only",
      "option",
      "after",
      "user",
      "able",
      "update",
      "it.",
      "define",
      "business",
      "rule",
      "prevent",
      "further",
      "updates",
      "record.",
      "following",
      "several",
      "options",
      "defining",
      "main",
      "menu",
      "select",
      "administration",
      "configuration",
      "studio",
      "processes",
      "rules.",
      "request",
      "type.",
      "done",
      "metaphase.",
      "change",
      "click",
      "add",
      "simple",
      "rule.",
      "validation",
      "rules",
      "validate",
      "expression.",
      "ok.",
      "expression",
      "enter",
      "error",
      "message",
      "cannot",
      "edited.",
      "save.",
      "case",
      "updated",
      "reaching",
      "metaphase",
      "under",
      "any",
      "circumstances.",
      "ems-admin-template",
      "entitytype",
      "unless",
      "current",
      "admin",
      "permission.",
      "now",
      "entity.closetime",
      "3600000",
      "permission",
      "last",
      "hour."
    ],
    "language": "en",
    "word_count": 111,
    "importance_score": 3.5,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "setting a closed record to read-only",
    "contentLower": "after a record has been closed, the user should not be able to update it. you can define a business rule to prevent further updates to the record. the following are several options for defining the rule: option 1 from the main menu, select administration > configuration > studio > processes and rules. select the request record type. select the done metaphase. in after change, click add, then select simple rule. in validation rules, select validate expression. click ok. click expression, and enter ${current_update.phaseid.ischanged}. click error message, and enter the record is closed and cannot be edited. click save. in this case, the request cannot be updated after reaching the done metaphase under any circumstances. option 2 from the main menu, select administration > configuration > studio > processes and rules. select the request record type. select the done metaphase. in after change, click add, then select simple rule. in validation rules, select validate expression. click ok. cl",
    "keywordsLower": [
      "setting",
      "closed",
      "record",
      "read-only",
      "option",
      "after",
      "user",
      "able",
      "update",
      "it.",
      "define",
      "business",
      "rule",
      "prevent",
      "further",
      "updates",
      "record.",
      "following",
      "several",
      "options",
      "defining",
      "main",
      "menu",
      "select",
      "administration",
      "configuration",
      "studio",
      "processes",
      "rules.",
      "request",
      "type.",
      "done",
      "metaphase.",
      "change",
      "click",
      "add",
      "simple",
      "rule.",
      "validation",
      "rules",
      "validate",
      "expression.",
      "ok.",
      "expression",
      "enter",
      "error",
      "message",
      "cannot",
      "edited.",
      "save.",
      "case",
      "updated",
      "reaching",
      "metaphase",
      "under",
      "any",
      "circumstances.",
      "ems-admin-template",
      "entitytype",
      "unless",
      "current",
      "admin",
      "permission.",
      "now",
      "entity.closetime",
      "3600000",
      "permission",
      "last",
      "hour."
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Service Portal administration",
    "content": "You can use the Service Portal Settings module to design the look and feel of Service Portal. For information on how to build rules to entitle different audiences to view areas of the portal, and different themes, see How to manage entitlement rules. Note To work in the Service Portal Settings module, you must have the Service Portal Administrator role. Related topics Service Portal Quick guide to customizing the Service Portal How to configure Service Portal display theme settings How to configure Service Portal feature settings How to authorize knowledge handling in the Service Portal How to manage entitlement rules Live Support and chat",
    "url": "serviceportaladm",
    "filename": "serviceportaladm",
    "headings": [
      "Related topics"
    ],
    "keywords": [
      "service",
      "portal",
      "administration",
      "related",
      "topics",
      "settings",
      "module",
      "design",
      "look",
      "feel",
      "portal.",
      "information",
      "build",
      "rules",
      "entitle",
      "different",
      "audiences",
      "view",
      "areas",
      "themes",
      "see",
      "manage",
      "entitlement",
      "rules.",
      "note",
      "work",
      "administrator",
      "role.",
      "quick",
      "guide",
      "customizing",
      "configure",
      "display",
      "theme",
      "feature",
      "authorize",
      "knowledge",
      "handling",
      "live",
      "support",
      "chat"
    ],
    "language": "en",
    "word_count": 68,
    "importance_score": 3.5,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "service portal administration",
    "contentLower": "you can use the service portal settings module to design the look and feel of service portal. for information on how to build rules to entitle different audiences to view areas of the portal, and different themes, see how to manage entitlement rules. note to work in the service portal settings module, you must have the service portal administrator role. related topics service portal quick guide to customizing the service portal how to configure service portal display theme settings how to configure service portal feature settings how to authorize knowledge handling in the service portal how to manage entitlement rules live support and chat",
    "keywordsLower": [
      "service",
      "portal",
      "administration",
      "related",
      "topics",
      "settings",
      "module",
      "design",
      "look",
      "feel",
      "portal.",
      "information",
      "build",
      "rules",
      "entitle",
      "different",
      "audiences",
      "view",
      "areas",
      "themes",
      "see",
      "manage",
      "entitlement",
      "rules.",
      "note",
      "work",
      "administrator",
      "role.",
      "quick",
      "guide",
      "customizing",
      "configure",
      "display",
      "theme",
      "feature",
      "authorize",
      "knowledge",
      "handling",
      "live",
      "support",
      "chat"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Quick guide to customize the Service Portal",
    "content": "Service Management provides a default display theme for the Service Portal. You can create a custom theme to suit your company's look and feel. For more detailed information about where each of the customizable settings affects the Service Portal display, see How to configure Service Portal display theme settings. Here is a quick guide to enable you to create a custom theme by adjusting the most basic settings and quickly go live with your own branded Service Portal. Go to Theme Settings On Service Portal main page, click and select Theme Settings. Note This is the location where you configure all the theme settings for the portal, except category settings. You configure category settings in Service Catalog Management. Create a custom theme On the Theme Settings page, by default, the out-of-the-box Standard (default) theme settings are displayed. To create a custom theme: Click “ + ” to create a theme. The Create New Theme dialog box is displayed. Type a suitable name for the theme. Se",
    "url": "quickguide",
    "filename": "quickguide",
    "headings": [
      "Go to Theme Settings",
      "Create a custom theme",
      "Design header",
      "Select a background image",
      "Design the category tiles",
      "Enable custom theme",
      "Sample portals",
      "Related topics"
    ],
    "keywords": [
      "quick",
      "guide",
      "customize",
      "service",
      "portal",
      "go",
      "theme",
      "settings",
      "create",
      "custom",
      "design",
      "header",
      "select",
      "background",
      "image",
      "category",
      "tiles",
      "enable",
      "sample",
      "portals",
      "related",
      "topics",
      "management",
      "provides",
      "default",
      "display",
      "portal.",
      "suit",
      "company",
      "look",
      "feel.",
      "detailed",
      "information",
      "about",
      "customizable",
      "affects",
      "see",
      "configure",
      "settings.",
      "here",
      "adjusting",
      "most",
      "basic",
      "quickly",
      "live",
      "own",
      "branded",
      "main",
      "page",
      "click",
      "note",
      "location",
      "all",
      "except",
      "catalog",
      "management.",
      "out-of-the-box",
      "standard",
      "displayed.",
      "theme.",
      "new",
      "dialog",
      "box",
      "type",
      "suitable",
      "name",
      "provide",
      "initial",
      "want",
      "customize.",
      "example",
      "assume",
      "previously",
      "created",
      "named",
      "alpha.",
      "now",
      "similar",
      "based",
      "alpha",
      "perhaps",
      "changes",
      "text",
      "color",
      "background.",
      "first",
      "give",
      "name.",
      "drop-down",
      "list.",
      "wanted",
      "create.",
      "tab",
      "section",
      "following",
      "field",
      "action",
      "part",
      "logo",
      "otherwise"
    ],
    "language": "en",
    "word_count": 112,
    "importance_score": 5.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "quick guide to customize the service portal",
    "contentLower": "service management provides a default display theme for the service portal. you can create a custom theme to suit your company's look and feel. for more detailed information about where each of the customizable settings affects the service portal display, see how to configure service portal display theme settings. here is a quick guide to enable you to create a custom theme by adjusting the most basic settings and quickly go live with your own branded service portal. go to theme settings on service portal main page, click and select theme settings. note this is the location where you configure all the theme settings for the portal, except category settings. you configure category settings in service catalog management. create a custom theme on the theme settings page, by default, the out-of-the-box standard (default) theme settings are displayed. to create a custom theme: click “ + ” to create a theme. the create new theme dialog box is displayed. type a suitable name for the theme. se",
    "keywordsLower": [
      "quick",
      "guide",
      "customize",
      "service",
      "portal",
      "go",
      "theme",
      "settings",
      "create",
      "custom",
      "design",
      "header",
      "select",
      "background",
      "image",
      "category",
      "tiles",
      "enable",
      "sample",
      "portals",
      "related",
      "topics",
      "management",
      "provides",
      "default",
      "display",
      "portal.",
      "suit",
      "company",
      "look",
      "feel.",
      "detailed",
      "information",
      "about",
      "customizable",
      "affects",
      "see",
      "configure",
      "settings.",
      "here",
      "adjusting",
      "most",
      "basic",
      "quickly",
      "live",
      "own",
      "branded",
      "main",
      "page",
      "click",
      "note",
      "location",
      "all",
      "except",
      "catalog",
      "management.",
      "out-of-the-box",
      "standard",
      "displayed.",
      "theme.",
      "new",
      "dialog",
      "box",
      "type",
      "suitable",
      "name",
      "provide",
      "initial",
      "want",
      "customize.",
      "example",
      "assume",
      "previously",
      "created",
      "named",
      "alpha.",
      "now",
      "similar",
      "based",
      "alpha",
      "perhaps",
      "changes",
      "text",
      "color",
      "background.",
      "first",
      "give",
      "name.",
      "drop-down",
      "list.",
      "wanted",
      "create.",
      "tab",
      "section",
      "following",
      "field",
      "action",
      "part",
      "logo",
      "otherwise"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Service Portal custom widgets",
    "content": "In addition to the standard options for Service Portal display theme settings, you can also use a custom widget to embed your own Web Components or static HTML contents to certain theme areas. Note that the custom widgets are all associated with the themes. That is to say, the configured custom widgets are only displayed to the users who are assigned with the associated theme. Also, you can only create the custom widgets for your custom display themes. The custom widget is not available for the out-of-the-box display themes. Custom widget configuration also supports live preview in Service Portal. After a configuration is saved, the widget will be display in the corresponding position for preview. Quick links to use cases Here is the list of usage examples provided in the online documents and OpenText Marketplace. Encapsulation type Use case Document link HTML (iframe) Useful Links as sidebar widget (HTML file) Display external links Power BI Report as full page widget (HTML file) Embe",
    "url": "createcustomwidget",
    "filename": "createcustomwidget",
    "headings": [
      "Quick links to use cases",
      "Supported content types",
      "HTML document",
      "Web Components",
      "Supported encapsulation types",
      "iframe",
      "Shadow DOM",
      "Supported browsers",
      "Security configurations for custom widgets",
      "Add authorized domains for accessing external resources",
      "Configure the Access-Control-Allow-Origin header",
      "Set the file allowlist for custom widget configurations",
      "Create custom widgets in Service Portal",
      "Set the name of the widget",
      "Set the position and the size of the widget",
      "A glance of all custom widget locations:",
      "Upload the source file",
      "Related topics"
    ],
    "keywords": [
      "https://serviceportal.example.com",
      "example.com",
      "service",
      "portal",
      "custom",
      "widgets",
      "quick",
      "links",
      "cases",
      "supported",
      "content",
      "types",
      "html",
      "document",
      "web",
      "components",
      "encapsulation",
      "iframe",
      "shadow",
      "dom",
      "browsers",
      "security",
      "configurations",
      "add",
      "authorized",
      "domains",
      "accessing",
      "external",
      "resources",
      "configure",
      "access-control-allow-origin",
      "header",
      "set",
      "file",
      "allowlist",
      "widget",
      "create",
      "name",
      "position",
      "size",
      "glance",
      "all",
      "locations",
      "upload",
      "source",
      "related",
      "topics",
      "addition",
      "standard",
      "options",
      "display",
      "theme",
      "settings",
      "embed",
      "own",
      "static",
      "contents",
      "certain",
      "areas.",
      "note",
      "associated",
      "themes.",
      "say",
      "configured",
      "displayed",
      "users",
      "assigned",
      "theme.",
      "available",
      "out-of-the-box",
      "configuration",
      "supports",
      "live",
      "preview",
      "portal.",
      "after",
      "saved",
      "corresponding",
      "preview.",
      "here",
      "list",
      "usage",
      "examples",
      "provided",
      "online",
      "documents",
      "opentext",
      "marketplace.",
      "type",
      "case",
      "link",
      "useful",
      "sidebar",
      "power",
      "bi",
      "report",
      "full",
      "page",
      "pages",
      "component"
    ],
    "language": "en",
    "word_count": 104,
    "importance_score": 6.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "service portal custom widgets",
    "contentLower": "in addition to the standard options for service portal display theme settings, you can also use a custom widget to embed your own web components or static html contents to certain theme areas. note that the custom widgets are all associated with the themes. that is to say, the configured custom widgets are only displayed to the users who are assigned with the associated theme. also, you can only create the custom widgets for your custom display themes. the custom widget is not available for the out-of-the-box display themes. custom widget configuration also supports live preview in service portal. after a configuration is saved, the widget will be display in the corresponding position for preview. quick links to use cases here is the list of usage examples provided in the online documents and opentext marketplace. encapsulation type use case document link html (iframe) useful links as sidebar widget (html file) display external links power bi report as full page widget (html file) embe",
    "keywordsLower": [
      "https://serviceportal.example.com",
      "example.com",
      "service",
      "portal",
      "custom",
      "widgets",
      "quick",
      "links",
      "cases",
      "supported",
      "content",
      "types",
      "html",
      "document",
      "web",
      "components",
      "encapsulation",
      "iframe",
      "shadow",
      "dom",
      "browsers",
      "security",
      "configurations",
      "add",
      "authorized",
      "domains",
      "accessing",
      "external",
      "resources",
      "configure",
      "access-control-allow-origin",
      "header",
      "set",
      "file",
      "allowlist",
      "widget",
      "create",
      "name",
      "position",
      "size",
      "glance",
      "all",
      "locations",
      "upload",
      "source",
      "related",
      "topics",
      "addition",
      "standard",
      "options",
      "display",
      "theme",
      "settings",
      "embed",
      "own",
      "static",
      "contents",
      "certain",
      "areas.",
      "note",
      "associated",
      "themes.",
      "say",
      "configured",
      "displayed",
      "users",
      "assigned",
      "theme.",
      "available",
      "out-of-the-box",
      "configuration",
      "supports",
      "live",
      "preview",
      "portal.",
      "after",
      "saved",
      "corresponding",
      "preview.",
      "here",
      "list",
      "usage",
      "examples",
      "provided",
      "online",
      "documents",
      "opentext",
      "marketplace.",
      "type",
      "case",
      "link",
      "useful",
      "sidebar",
      "power",
      "bi",
      "report",
      "full",
      "page",
      "pages",
      "component"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Smart virtual agent",
    "content": "End users can chat with the smart virtual agent in Service Portal in natural language. The smart virtual agent combines Rasa with IDOL to understand their intentions and find the most matched intent predefined to provide either related answers or catalog offerings as responses. Rasa natural language understanding (NLU) is an open source natural language processing (NLP) tool for intent classification and user option extraction. The smart virtual agent uses Rasa as a set of high level APIs for building your own language parser with existing NLP and machine learning libraries. However, the classification algorithm only manages limited data volume. When an end user's question isn't understood by Rasa, the virtual agent utilizes IDOL and leverages the bigger index data volume in IDOL to provide cognitive search against the end user's question. The following diagram illustrates the smart virtual agent workflow: When an end user enters an issue or a question, the smart virtual agent matches ",
    "url": "vasettings",
    "filename": "vasettings",
    "headings": [
      "Enable the smart virtual agent",
      "Helm deployment",
      "Cloud deployment",
      "Configure the smart virtual agent",
      "Manage user options",
      "Add a new user option",
      "Remove a user option",
      "Manage intents",
      "Add new intents automatically",
      "Add a new intent manually",
      "Disable an intent",
      "Remove an intent",
      "Train an intent",
      "Export and import",
      "Multi-language support in one tenant",
      "Smart virtual agent configuration use case",
      "Related topics"
    ],
    "keywords": [
      "values.yaml",
      "sys.any",
      "smart",
      "virtual",
      "agent",
      "enable",
      "helm",
      "deployment",
      "cloud",
      "configure",
      "manage",
      "user",
      "options",
      "add",
      "new",
      "option",
      "remove",
      "intents",
      "automatically",
      "intent",
      "manually",
      "disable",
      "train",
      "export",
      "import",
      "multi-language",
      "support",
      "one",
      "tenant",
      "configuration",
      "case",
      "related",
      "topics",
      "end",
      "users",
      "chat",
      "service",
      "portal",
      "natural",
      "language.",
      "combines",
      "rasa",
      "idol",
      "understand",
      "intentions",
      "find",
      "most",
      "matched",
      "predefined",
      "provide",
      "either",
      "answers",
      "catalog",
      "offerings",
      "responses.",
      "language",
      "understanding",
      "nlu",
      "open",
      "source",
      "processing",
      "nlp",
      "tool",
      "classification",
      "extraction.",
      "uses",
      "set",
      "high",
      "level",
      "apis",
      "building",
      "own",
      "parser",
      "existing",
      "machine",
      "learning",
      "libraries.",
      "however",
      "algorithm",
      "manages",
      "limited",
      "data",
      "volume.",
      "question",
      "isn",
      "understood",
      "utilizes",
      "leverages",
      "bigger",
      "index",
      "volume",
      "cognitive",
      "search",
      "against",
      "question.",
      "following",
      "diagram",
      "illustrates",
      "workflow",
      "enters"
    ],
    "language": "en",
    "word_count": 117,
    "importance_score": 6.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "smart virtual agent",
    "contentLower": "end users can chat with the smart virtual agent in service portal in natural language. the smart virtual agent combines rasa with idol to understand their intentions and find the most matched intent predefined to provide either related answers or catalog offerings as responses. rasa natural language understanding (nlu) is an open source natural language processing (nlp) tool for intent classification and user option extraction. the smart virtual agent uses rasa as a set of high level apis for building your own language parser with existing nlp and machine learning libraries. however, the classification algorithm only manages limited data volume. when an end user's question isn't understood by rasa, the virtual agent utilizes idol and leverages the bigger index data volume in idol to provide cognitive search against the end user's question. the following diagram illustrates the smart virtual agent workflow: when an end user enters an issue or a question, the smart virtual agent matches ",
    "keywordsLower": [
      "values.yaml",
      "sys.any",
      "smart",
      "virtual",
      "agent",
      "enable",
      "helm",
      "deployment",
      "cloud",
      "configure",
      "manage",
      "user",
      "options",
      "add",
      "new",
      "option",
      "remove",
      "intents",
      "automatically",
      "intent",
      "manually",
      "disable",
      "train",
      "export",
      "import",
      "multi-language",
      "support",
      "one",
      "tenant",
      "configuration",
      "case",
      "related",
      "topics",
      "end",
      "users",
      "chat",
      "service",
      "portal",
      "natural",
      "language.",
      "combines",
      "rasa",
      "idol",
      "understand",
      "intentions",
      "find",
      "most",
      "matched",
      "predefined",
      "provide",
      "either",
      "answers",
      "catalog",
      "offerings",
      "responses.",
      "language",
      "understanding",
      "nlu",
      "open",
      "source",
      "processing",
      "nlp",
      "tool",
      "classification",
      "extraction.",
      "uses",
      "set",
      "high",
      "level",
      "apis",
      "building",
      "own",
      "parser",
      "existing",
      "machine",
      "learning",
      "libraries.",
      "however",
      "algorithm",
      "manages",
      "limited",
      "data",
      "volume.",
      "question",
      "isn",
      "understood",
      "utilizes",
      "leverages",
      "bigger",
      "index",
      "volume",
      "cognitive",
      "search",
      "against",
      "question.",
      "following",
      "diagram",
      "illustrates",
      "workflow",
      "enters"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Smart ticket",
    "content": "Smart Analytics can intelligently populate fields defined in smart ticket tasks. To customize the smart ticket settings, log in to Agent Interface and navigate to Administration > Configuration > AI Studio > Smart Ticket. Create a smart ticket task To create a smart ticket task, follow these steps: Click New. In the dialog box that opens, specify the following fields: Field Description Module name Select Request from the drop-down list. Predicted field Select a predicted field from the drop-down list. The available values are Offering, Service, Category, and Assignment group. If you select Assignment group as the predicted field and want the system to automatically fill a value for the Assignment Group field in a smart ticket, you must tailor the corresponding form and business rules, see the Tailor form and business rules for Assignment Group prediction section. Training sample query (Optional) Specify a sample data query, through which you can decide what kind of data you want to use",
    "url": "smartticket",
    "filename": "smartticket",
    "headings": [
      "Create a smart ticket task",
      "Edit a smart ticket task",
      "Perform training and testing",
      "Remove a smart ticket task",
      "Tailor form and business rules for Assignment Group prediction",
      "Related topics"
    ],
    "keywords": [
      "42.86",
      "50.00",
      "57.14",
      "smart",
      "ticket",
      "create",
      "task",
      "edit",
      "perform",
      "training",
      "testing",
      "remove",
      "tailor",
      "form",
      "business",
      "rules",
      "assignment",
      "group",
      "prediction",
      "related",
      "topics",
      "analytics",
      "intelligently",
      "populate",
      "fields",
      "defined",
      "tasks.",
      "customize",
      "settings",
      "log",
      "agent",
      "interface",
      "navigate",
      "administration",
      "configuration",
      "ai",
      "studio",
      "ticket.",
      "follow",
      "steps",
      "click",
      "new.",
      "dialog",
      "box",
      "opens",
      "specify",
      "following",
      "field",
      "description",
      "module",
      "name",
      "select",
      "request",
      "drop-down",
      "list.",
      "predicted",
      "available",
      "values",
      "offering",
      "service",
      "category",
      "group.",
      "want",
      "system",
      "automatically",
      "fill",
      "value",
      "corresponding",
      "see",
      "section.",
      "sample",
      "query",
      "optional",
      "data",
      "through",
      "decide",
      "what",
      "kind",
      "teach",
      "build",
      "intelligence",
      "out",
      "large",
      "volume.",
      "default",
      "uses",
      "all",
      "hr",
      "support",
      "samples.",
      "example",
      "set",
      "match",
      "close",
      "phaseid",
      "closed",
      "requests",
      "data.",
      "idol",
      "one"
    ],
    "language": "en",
    "word_count": 108,
    "importance_score": 6.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "smart ticket",
    "contentLower": "smart analytics can intelligently populate fields defined in smart ticket tasks. to customize the smart ticket settings, log in to agent interface and navigate to administration > configuration > ai studio > smart ticket. create a smart ticket task to create a smart ticket task, follow these steps: click new. in the dialog box that opens, specify the following fields: field description module name select request from the drop-down list. predicted field select a predicted field from the drop-down list. the available values are offering, service, category, and assignment group. if you select assignment group as the predicted field and want the system to automatically fill a value for the assignment group field in a smart ticket, you must tailor the corresponding form and business rules, see the tailor form and business rules for assignment group prediction section. training sample query (optional) specify a sample data query, through which you can decide what kind of data you want to use",
    "keywordsLower": [
      "42.86",
      "50.00",
      "57.14",
      "smart",
      "ticket",
      "create",
      "task",
      "edit",
      "perform",
      "training",
      "testing",
      "remove",
      "tailor",
      "form",
      "business",
      "rules",
      "assignment",
      "group",
      "prediction",
      "related",
      "topics",
      "analytics",
      "intelligently",
      "populate",
      "fields",
      "defined",
      "tasks.",
      "customize",
      "settings",
      "log",
      "agent",
      "interface",
      "navigate",
      "administration",
      "configuration",
      "ai",
      "studio",
      "ticket.",
      "follow",
      "steps",
      "click",
      "new.",
      "dialog",
      "box",
      "opens",
      "specify",
      "following",
      "field",
      "description",
      "module",
      "name",
      "select",
      "request",
      "drop-down",
      "list.",
      "predicted",
      "available",
      "values",
      "offering",
      "service",
      "category",
      "group.",
      "want",
      "system",
      "automatically",
      "fill",
      "value",
      "corresponding",
      "see",
      "section.",
      "sample",
      "query",
      "optional",
      "data",
      "through",
      "decide",
      "what",
      "kind",
      "teach",
      "build",
      "intelligence",
      "out",
      "large",
      "volume.",
      "default",
      "uses",
      "all",
      "hr",
      "support",
      "samples.",
      "example",
      "set",
      "match",
      "close",
      "phaseid",
      "closed",
      "requests",
      "data.",
      "idol",
      "one"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Smart search",
    "content": "You can customize the following smart search settings to pre-define the possible actions based on your search conditions and results in Agent Interface (Administration > Configuration > AI Studio > Smart Search). Enable phrase queries This setting allows you to automatically add quotations to the search criteria. By default, this setting is disabled. An exact phrase search follows these rules: remove stop words from the query phrase is case-insensitive match the exact form of all the terms match the terms in the specified order For example: Searching for the phrase phones and laptops returns the same search results as these phrases: phones laptops because the stop word \"and\" is removed. Phones and Laptops because the search is case-insensitive. Searching for the phrase phones and laptops returns different search results from these phrases: phone and laptop because the search only matches the exact form, not the stem form of terms. laptops and phones because the search only matches the ",
    "url": "smartsearch",
    "filename": "smartsearch",
    "headings": [
      "Enable phrase queries",
      "Ignore certain special characters",
      "Minimum search result relevance threshold (0-100)",
      "Related topics"
    ],
    "keywords": [
      "smart",
      "search",
      "enable",
      "phrase",
      "queries",
      "ignore",
      "certain",
      "special",
      "characters",
      "minimum",
      "result",
      "relevance",
      "threshold",
      "0-100",
      "related",
      "topics",
      "customize",
      "following",
      "settings",
      "pre-define",
      "possible",
      "actions",
      "based",
      "conditions",
      "results",
      "agent",
      "interface",
      "administration",
      "configuration",
      "ai",
      "studio",
      "setting",
      "allows",
      "automatically",
      "add",
      "quotations",
      "criteria.",
      "default",
      "disabled.",
      "exact",
      "follows",
      "rules",
      "remove",
      "stop",
      "words",
      "query",
      "case-insensitive",
      "match",
      "form",
      "all",
      "terms",
      "specified",
      "order",
      "example",
      "searching",
      "phones",
      "laptops",
      "returns",
      "same",
      "phrases",
      "because",
      "word",
      "removed.",
      "case-insensitive.",
      "different",
      "phone",
      "laptop",
      "matches",
      "stem",
      "terms.",
      "specific",
      "specify.",
      "enabling",
      "interpret",
      "elements",
      "normal",
      "instead",
      "syntax.",
      "include",
      "asterisks",
      "question",
      "marks",
      "colons",
      "double",
      "quotation",
      "brackets",
      "boolean",
      "proximity",
      "operators",
      "such",
      "eor",
      "xor",
      "near",
      "dnear",
      "wnear",
      "before",
      "after.",
      "select",
      "check",
      "box"
    ],
    "language": "en",
    "word_count": 100,
    "importance_score": 5.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "smart search",
    "contentLower": "you can customize the following smart search settings to pre-define the possible actions based on your search conditions and results in agent interface (administration > configuration > ai studio > smart search). enable phrase queries this setting allows you to automatically add quotations to the search criteria. by default, this setting is disabled. an exact phrase search follows these rules: remove stop words from the query phrase is case-insensitive match the exact form of all the terms match the terms in the specified order for example: searching for the phrase phones and laptops returns the same search results as these phrases: phones laptops because the stop word \"and\" is removed. phones and laptops because the search is case-insensitive. searching for the phrase phones and laptops returns different search results from these phrases: phone and laptop because the search only matches the exact form, not the stem form of terms. laptops and phones because the search only matches the ",
    "keywordsLower": [
      "smart",
      "search",
      "enable",
      "phrase",
      "queries",
      "ignore",
      "certain",
      "special",
      "characters",
      "minimum",
      "result",
      "relevance",
      "threshold",
      "0-100",
      "related",
      "topics",
      "customize",
      "following",
      "settings",
      "pre-define",
      "possible",
      "actions",
      "based",
      "conditions",
      "results",
      "agent",
      "interface",
      "administration",
      "configuration",
      "ai",
      "studio",
      "setting",
      "allows",
      "automatically",
      "add",
      "quotations",
      "criteria.",
      "default",
      "disabled.",
      "exact",
      "follows",
      "rules",
      "remove",
      "stop",
      "words",
      "query",
      "case-insensitive",
      "match",
      "form",
      "all",
      "terms",
      "specified",
      "order",
      "example",
      "searching",
      "phones",
      "laptops",
      "returns",
      "same",
      "phrases",
      "because",
      "word",
      "removed.",
      "case-insensitive.",
      "different",
      "phone",
      "laptop",
      "matches",
      "stem",
      "terms.",
      "specific",
      "specify.",
      "enabling",
      "interpret",
      "elements",
      "normal",
      "instead",
      "syntax.",
      "include",
      "asterisks",
      "question",
      "marks",
      "colons",
      "double",
      "quotation",
      "brackets",
      "boolean",
      "proximity",
      "operators",
      "such",
      "eor",
      "xor",
      "near",
      "dnear",
      "wnear",
      "before",
      "after.",
      "select",
      "check",
      "box"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Sample data",
    "content": "Sample data can be imported into your instance of Service Management. The Sample Data menu option (under Administration > Utilities > Data Deployment) appears only if you have the Tenant Admin role. There are many types of sample data. The following are some examples: Sample users, groups, and locations A sample service catalog that contains categories, services, and offerings Sample knowledge articles Sample IT records such as user requests, incidents, changes, and problems Assets and configuration management records such as services, assets, and devices The data imported as sample data is indistinguishable from data entered into the system. Once the sample data is deployed, the button on the Sample Data page becomes disabled. The Tenant Admin receives a notification via email when a new tenant is created. This mail includes a link to the Sample Data page where the data can be deployed onto the new tenant. If you deploy the sample data, it can't be undeployed. You can delete individua",
    "url": "sampledata",
    "filename": "sampledata",
    "headings": [],
    "keywords": [
      "sample",
      "data",
      "imported",
      "instance",
      "service",
      "management.",
      "menu",
      "option",
      "under",
      "administration",
      "utilities",
      "deployment",
      "appears",
      "tenant",
      "admin",
      "role.",
      "there",
      "many",
      "types",
      "data.",
      "following",
      "examples",
      "users",
      "groups",
      "locations",
      "catalog",
      "contains",
      "categories",
      "services",
      "offerings",
      "knowledge",
      "articles",
      "records",
      "such",
      "user",
      "requests",
      "incidents",
      "changes",
      "problems",
      "assets",
      "configuration",
      "management",
      "devices",
      "indistinguishable",
      "entered",
      "system.",
      "once",
      "deployed",
      "button",
      "page",
      "becomes",
      "disabled.",
      "receives",
      "notification",
      "via",
      "email",
      "new",
      "created.",
      "mail",
      "includes",
      "link",
      "onto",
      "tenant.",
      "deploy",
      "undeployed.",
      "delete",
      "individual",
      "pieces",
      "reverse",
      "deployment.",
      "addition",
      "need",
      "take",
      "care",
      "future",
      "upgrades",
      "system",
      "won",
      "upgrade",
      "automatically.",
      "recommend",
      "all",
      "same",
      "time.",
      "any",
      "pods",
      "restart",
      "during",
      "relationships",
      "created",
      "manually."
    ],
    "language": "en",
    "word_count": 103,
    "importance_score": 3.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "sample data",
    "contentLower": "sample data can be imported into your instance of service management. the sample data menu option (under administration > utilities > data deployment) appears only if you have the tenant admin role. there are many types of sample data. the following are some examples: sample users, groups, and locations a sample service catalog that contains categories, services, and offerings sample knowledge articles sample it records such as user requests, incidents, changes, and problems assets and configuration management records such as services, assets, and devices the data imported as sample data is indistinguishable from data entered into the system. once the sample data is deployed, the button on the sample data page becomes disabled. the tenant admin receives a notification via email when a new tenant is created. this mail includes a link to the sample data page where the data can be deployed onto the new tenant. if you deploy the sample data, it can't be undeployed. you can delete individua",
    "keywordsLower": [
      "sample",
      "data",
      "imported",
      "instance",
      "service",
      "management.",
      "menu",
      "option",
      "under",
      "administration",
      "utilities",
      "deployment",
      "appears",
      "tenant",
      "admin",
      "role.",
      "there",
      "many",
      "types",
      "data.",
      "following",
      "examples",
      "users",
      "groups",
      "locations",
      "catalog",
      "contains",
      "categories",
      "services",
      "offerings",
      "knowledge",
      "articles",
      "records",
      "such",
      "user",
      "requests",
      "incidents",
      "changes",
      "problems",
      "assets",
      "configuration",
      "management",
      "devices",
      "indistinguishable",
      "entered",
      "system.",
      "once",
      "deployed",
      "button",
      "page",
      "becomes",
      "disabled.",
      "receives",
      "notification",
      "via",
      "email",
      "new",
      "created.",
      "mail",
      "includes",
      "link",
      "onto",
      "tenant.",
      "deploy",
      "undeployed.",
      "delete",
      "individual",
      "pieces",
      "reverse",
      "deployment.",
      "addition",
      "need",
      "take",
      "care",
      "future",
      "upgrades",
      "system",
      "won",
      "upgrade",
      "automatically.",
      "recommend",
      "all",
      "same",
      "time.",
      "any",
      "pods",
      "restart",
      "during",
      "relationships",
      "created",
      "manually."
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Resource offering",
    "content": "You can perform the following tasks in the Resource Offering tab View resource offerings associated with the selected provider - See the list of resource offerings. Select a resource offering - Click Select. In the dialog box, add or remove resource offerings to or from the resource provider.",
    "url": "resourceofferingstab",
    "filename": "resourceofferingstab",
    "headings": [],
    "keywords": [
      "resource",
      "offering",
      "perform",
      "following",
      "tasks",
      "tab",
      "view",
      "offerings",
      "associated",
      "selected",
      "provider",
      "see",
      "list",
      "offerings.",
      "select",
      "click",
      "select.",
      "dialog",
      "box",
      "add",
      "remove",
      "provider."
    ],
    "language": "en",
    "word_count": 31,
    "importance_score": 2.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "resource offering",
    "contentLower": "you can perform the following tasks in the resource offering tab view resource offerings associated with the selected provider - see the list of resource offerings. select a resource offering - click select. in the dialog box, add or remove resource offerings to or from the resource provider.",
    "keywordsLower": [
      "resource",
      "offering",
      "perform",
      "following",
      "tasks",
      "tab",
      "view",
      "offerings",
      "associated",
      "selected",
      "provider",
      "see",
      "list",
      "offerings.",
      "select",
      "click",
      "select.",
      "dialog",
      "box",
      "add",
      "remove",
      "provider."
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Resource pool tasks",
    "content": "You can perform the following tasks: Edit a resource pool - Click the gear icon and select Edit. See the table in the topic Provider resource Pools for the items you can edit. Delete a resource pool - Click the gear icon and select Delete A resource pool can't be deleted unless the Current Utilization for each resource configured on the pool is zero. Refresh a resource pool - Click the gear icon and select Refresh. Synchronize a resource pool - Click the gear icon and selectSynchronize. This action automatically updates the Resources tab information with the latest information. The Synchronize action is available only when a Resource Synchronization Action is configured. Resource synchronization doesn't occur automatically and is performed only on demand. The default timeout for a resource synchronization action to complete is one hour. The timeout isn't configurable. The Last Synchronized field in the Overview tab of the resource pool indicates the last time (local client time) a reso",
    "url": "resourcepooloverviewtab",
    "filename": "resourcepooloverviewtab",
    "headings": [],
    "keywords": [
      "resource",
      "pool",
      "tasks",
      "perform",
      "following",
      "edit",
      "click",
      "gear",
      "icon",
      "select",
      "edit.",
      "see",
      "table",
      "topic",
      "provider",
      "pools",
      "items",
      "delete",
      "deleted",
      "unless",
      "current",
      "utilization",
      "configured",
      "zero.",
      "refresh",
      "refresh.",
      "synchronize",
      "selectsynchronize.",
      "action",
      "automatically",
      "updates",
      "resources",
      "tab",
      "information",
      "latest",
      "information.",
      "available",
      "synchronization",
      "configured.",
      "doesn",
      "occur",
      "performed",
      "demand.",
      "default",
      "timeout",
      "complete",
      "one",
      "hour.",
      "isn",
      "configurable.",
      "last",
      "synchronized",
      "field",
      "overview",
      "indicates",
      "time",
      "local",
      "client",
      "completed",
      "successfully.",
      "content",
      "screen",
      "update.",
      "after",
      "completes."
    ],
    "language": "en",
    "word_count": 105,
    "importance_score": 3.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "resource pool tasks",
    "contentLower": "you can perform the following tasks: edit a resource pool - click the gear icon and select edit. see the table in the topic provider resource pools for the items you can edit. delete a resource pool - click the gear icon and select delete a resource pool can't be deleted unless the current utilization for each resource configured on the pool is zero. refresh a resource pool - click the gear icon and select refresh. synchronize a resource pool - click the gear icon and selectsynchronize. this action automatically updates the resources tab information with the latest information. the synchronize action is available only when a resource synchronization action is configured. resource synchronization doesn't occur automatically and is performed only on demand. the default timeout for a resource synchronization action to complete is one hour. the timeout isn't configurable. the last synchronized field in the overview tab of the resource pool indicates the last time (local client time) a reso",
    "keywordsLower": [
      "resource",
      "pool",
      "tasks",
      "perform",
      "following",
      "edit",
      "click",
      "gear",
      "icon",
      "select",
      "edit.",
      "see",
      "table",
      "topic",
      "provider",
      "pools",
      "items",
      "delete",
      "deleted",
      "unless",
      "current",
      "utilization",
      "configured",
      "zero.",
      "refresh",
      "refresh.",
      "synchronize",
      "selectsynchronize.",
      "action",
      "automatically",
      "updates",
      "resources",
      "tab",
      "information",
      "latest",
      "information.",
      "available",
      "synchronization",
      "configured.",
      "doesn",
      "occur",
      "performed",
      "demand.",
      "default",
      "timeout",
      "complete",
      "one",
      "hour.",
      "isn",
      "configurable.",
      "last",
      "synchronized",
      "field",
      "overview",
      "indicates",
      "time",
      "local",
      "client",
      "completed",
      "successfully.",
      "content",
      "screen",
      "update.",
      "after",
      "completes."
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Resources for a resource pool",
    "content": "You can associate the following types of resources with a resource pool. You can also set capacity for the resources listed in the following table: Resource Unit of Measurement CPU Number of CPUs IPv4 Address Number of IP version 4 addresses IPv6 Address Number of IP version 6 addresses License Number of license keys Memory Megabytes (MB) of memory Physical Server Number of physical servers Power Kilowatts (KW) of power Storage Gigabytes (GB) of disk storage Subnet Number of IPv4 or IPv6 subnets VLAN Number of virtual LAN identifiers Virtual Server Number of virtual servers Tasks View resources for a resource pool - See the list of resources, as well as availability and capacity. Add a resource to a resource pool - Click Add. Provide the information listed in the following table. Edit a resource - Click the gear icon and select Edit. See the following table for the items you can edit. Delete a resource from a resource pool - Click the gear icon for the resource and select Delete.You ca",
    "url": "resourcepoolresourcestab",
    "filename": "resourcepoolresourcestab",
    "headings": [
      "Tasks"
    ],
    "keywords": [
      "Delete.You",
      "resources",
      "resource",
      "pool",
      "tasks",
      "associate",
      "following",
      "types",
      "pool.",
      "set",
      "capacity",
      "listed",
      "table",
      "unit",
      "measurement",
      "cpu",
      "number",
      "cpus",
      "ipv4",
      "address",
      "ip",
      "version",
      "addresses",
      "ipv6",
      "license",
      "keys",
      "memory",
      "megabytes",
      "mb",
      "physical",
      "server",
      "servers",
      "power",
      "kilowatts",
      "kw",
      "storage",
      "gigabytes",
      "gb",
      "disk",
      "subnet",
      "subnets",
      "vlan",
      "virtual",
      "lan",
      "identifiers",
      "view",
      "see",
      "list",
      "well",
      "availability",
      "capacity.",
      "add",
      "click",
      "add.",
      "provide",
      "information",
      "table.",
      "edit",
      "gear",
      "icon",
      "select",
      "edit.",
      "items",
      "delete",
      "currently",
      "current",
      "utilization",
      "value",
      "zero",
      "item",
      "description",
      "type",
      "included",
      "added",
      "one",
      "time",
      "after",
      "longer",
      "appears",
      "drop-down",
      "list.",
      "note",
      "created.",
      "available",
      "selection",
      "during",
      "provisioning",
      "service.",
      "unavailable",
      "isn",
      "unlimited",
      "restrictions",
      "allocations",
      "resource.",
      "total",
      "whole",
      "indicate",
      "maximum",
      "provided",
      "provider."
    ],
    "language": "en",
    "word_count": 117,
    "importance_score": 3.5,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "resources for a resource pool",
    "contentLower": "you can associate the following types of resources with a resource pool. you can also set capacity for the resources listed in the following table: resource unit of measurement cpu number of cpus ipv4 address number of ip version 4 addresses ipv6 address number of ip version 6 addresses license number of license keys memory megabytes (mb) of memory physical server number of physical servers power kilowatts (kw) of power storage gigabytes (gb) of disk storage subnet number of ipv4 or ipv6 subnets vlan number of virtual lan identifiers virtual server number of virtual servers tasks view resources for a resource pool - see the list of resources, as well as availability and capacity. add a resource to a resource pool - click add. provide the information listed in the following table. edit a resource - click the gear icon and select edit. see the following table for the items you can edit. delete a resource from a resource pool - click the gear icon for the resource and select delete.you ca",
    "keywordsLower": [
      "delete.you",
      "resources",
      "resource",
      "pool",
      "tasks",
      "associate",
      "following",
      "types",
      "pool.",
      "set",
      "capacity",
      "listed",
      "table",
      "unit",
      "measurement",
      "cpu",
      "number",
      "cpus",
      "ipv4",
      "address",
      "ip",
      "version",
      "addresses",
      "ipv6",
      "license",
      "keys",
      "memory",
      "megabytes",
      "mb",
      "physical",
      "server",
      "servers",
      "power",
      "kilowatts",
      "kw",
      "storage",
      "gigabytes",
      "gb",
      "disk",
      "subnet",
      "subnets",
      "vlan",
      "virtual",
      "lan",
      "identifiers",
      "view",
      "see",
      "list",
      "well",
      "availability",
      "capacity.",
      "add",
      "click",
      "add.",
      "provide",
      "information",
      "table.",
      "edit",
      "gear",
      "icon",
      "select",
      "edit.",
      "items",
      "delete",
      "currently",
      "current",
      "utilization",
      "value",
      "zero",
      "item",
      "description",
      "type",
      "included",
      "added",
      "one",
      "time",
      "after",
      "longer",
      "appears",
      "drop-down",
      "list.",
      "note",
      "created.",
      "available",
      "selection",
      "during",
      "provisioning",
      "service.",
      "unavailable",
      "isn",
      "unlimited",
      "restrictions",
      "allocations",
      "resource.",
      "total",
      "whole",
      "indicate",
      "maximum",
      "provided",
      "provider."
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Reporting options",
    "content": "Reporting The ability to process and investigate the data gathered in a service management system is of utmost importance. The Service Management application provides several methods for reporting on this data, including handling both operational and analytical type reports. Service Management only supports direct access to the database for the PostgreSQL views. Unless directed by the Support as part of a case investigation or resolution, any other database access is not supported. Due to the differences in technology and functionality between Service Manager and Service Management, automatic migration of existing reports is not possible. Therefore, it is important to understand the reporting options that Service Management provides in order to decide where and how the existing reporting requirements should be met. Internal Reporting In-tool reports enable the view of the current and past status of the Service Management system. Data may be grouped or filtered to display specific infor",
    "url": "reportingoptions",
    "filename": "reportingoptions",
    "headings": [
      "Reporting",
      "Internal Reporting",
      "External Reporting",
      "PostgreSQL Views",
      "Business Intelligence Integration"
    ],
    "keywords": [
      "reporting",
      "options",
      "internal",
      "external",
      "postgresql",
      "views",
      "business",
      "intelligence",
      "integration",
      "ability",
      "process",
      "investigate",
      "data",
      "gathered",
      "service",
      "management",
      "system",
      "utmost",
      "importance.",
      "application",
      "provides",
      "several",
      "methods",
      "including",
      "handling",
      "both",
      "operational",
      "analytical",
      "type",
      "reports.",
      "supports",
      "direct",
      "access",
      "database",
      "views.",
      "unless",
      "directed",
      "support",
      "part",
      "case",
      "investigation",
      "resolution",
      "any",
      "supported.",
      "due",
      "differences",
      "technology",
      "functionality",
      "between",
      "manager",
      "automatic",
      "migration",
      "existing",
      "reports",
      "possible.",
      "therefore",
      "important",
      "understand",
      "order",
      "decide",
      "requirements",
      "met.",
      "in-tool",
      "enable",
      "view",
      "current",
      "past",
      "status",
      "system.",
      "grouped",
      "filtered",
      "display",
      "specific",
      "information",
      "relevant",
      "agent",
      "supervisor.",
      "saved",
      "publically",
      "made",
      "available",
      "agents",
      "appropriate",
      "permissions",
      "set",
      "private",
      "use.",
      "overview",
      "found",
      "here.",
      "built-in",
      "dashboards",
      "provide",
      "quick",
      "useful",
      "way",
      "define",
      "many",
      "simple",
      "analytic"
    ],
    "language": "en",
    "word_count": 93,
    "importance_score": 5.5,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "reporting options",
    "contentLower": "reporting the ability to process and investigate the data gathered in a service management system is of utmost importance. the service management application provides several methods for reporting on this data, including handling both operational and analytical type reports. service management only supports direct access to the database for the postgresql views. unless directed by the support as part of a case investigation or resolution, any other database access is not supported. due to the differences in technology and functionality between service manager and service management, automatic migration of existing reports is not possible. therefore, it is important to understand the reporting options that service management provides in order to decide where and how the existing reporting requirements should be met. internal reporting in-tool reports enable the view of the current and past status of the service management system. data may be grouped or filtered to display specific infor",
    "keywordsLower": [
      "reporting",
      "options",
      "internal",
      "external",
      "postgresql",
      "views",
      "business",
      "intelligence",
      "integration",
      "ability",
      "process",
      "investigate",
      "data",
      "gathered",
      "service",
      "management",
      "system",
      "utmost",
      "importance.",
      "application",
      "provides",
      "several",
      "methods",
      "including",
      "handling",
      "both",
      "operational",
      "analytical",
      "type",
      "reports.",
      "supports",
      "direct",
      "access",
      "database",
      "views.",
      "unless",
      "directed",
      "support",
      "part",
      "case",
      "investigation",
      "resolution",
      "any",
      "supported.",
      "due",
      "differences",
      "technology",
      "functionality",
      "between",
      "manager",
      "automatic",
      "migration",
      "existing",
      "reports",
      "possible.",
      "therefore",
      "important",
      "understand",
      "order",
      "decide",
      "requirements",
      "met.",
      "in-tool",
      "enable",
      "view",
      "current",
      "past",
      "status",
      "system.",
      "grouped",
      "filtered",
      "display",
      "specific",
      "information",
      "relevant",
      "agent",
      "supervisor.",
      "saved",
      "publically",
      "made",
      "available",
      "agents",
      "appropriate",
      "permissions",
      "set",
      "private",
      "use.",
      "overview",
      "found",
      "here.",
      "built-in",
      "dashboards",
      "provide",
      "quick",
      "useful",
      "way",
      "define",
      "many",
      "simple",
      "analytic"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Reconfigure OO Containerized deployment",
    "content": "This topic describes instructions to reconfigure an existing deployment of OO Containerized using Helm chart. Prerequisites The following prerequisites apply: Make sure that the database you wish to change is already created and running. Make sure you have access to the latest values.yaml file. Run the following command to get the latest values.yaml file: helm get values <HELM_RELEASE_NAME> -n <OO_NAMESPACE> > latestvalues.yaml Change database hostname Run the following command to change the database host of the existing deployment of OO Containerized: helm upgrade <HELM_RELEASE_NAME> -n <OO_NAMESPACE> -f latestvalues.yaml <OO_HELM_CHART> --set global.database.host=\"new_db_host_fqdn\" Change database credentials Complete the following steps to change the credentials for databases for all the OO Containerized components/pods: Change the database name and user of OO Containerized components using the following command: helm upgrade <HELM_RELEASE_NAME> -n <OO_NAMESPACE> -f latestvalues.yam",
    "url": "399-reconfigureooc",
    "filename": "399-reconfigureooc",
    "headings": [
      "Prerequisites",
      "Change database hostname",
      "Change database credentials",
      "Adjust sizing of OO deployment",
      "Resize using the sizing parameter",
      "Resize using the sizing attributes",
      "Renew certificate for OO",
      "Renew CA certificates",
      "Renew TLS certificates"
    ],
    "keywords": [
      "RE_ca.cert",
      "previous_deployment_values.yaml",
      "latestvalues.yaml",
      "global.oo",
      "database.user",
      "database.host",
      "cdfctl.sh",
      "RE_ca.crt",
      "x.tgz",
      "global.tls",
      "values.yaml",
      "idm_cert.crt",
      "reconfigure",
      "oo",
      "containerized",
      "deployment",
      "prerequisites",
      "change",
      "database",
      "hostname",
      "credentials",
      "adjust",
      "sizing",
      "resize",
      "parameter",
      "attributes",
      "renew",
      "certificate",
      "ca",
      "certificates",
      "tls",
      "topic",
      "describes",
      "instructions",
      "existing",
      "helm",
      "chart.",
      "following",
      "apply",
      "make",
      "sure",
      "wish",
      "already",
      "created",
      "running.",
      "access",
      "latest",
      "file.",
      "run",
      "command",
      "get",
      "file",
      "values",
      "-n",
      "host",
      "upgrade",
      "-f",
      "--set",
      "global.database.host",
      "complete",
      "steps",
      "databases",
      "all",
      "components",
      "pods",
      "name",
      "user",
      "global.database..dbname",
      "global.database..user",
      "either",
      "oocentral",
      "oocontroller",
      "ooui",
      "ooscheduler.",
      "autopass",
      "component",
      "autopass.deployment.database.dbname",
      "autopass.deployment.database.user",
      "password",
      "command.",
      "base64",
      "encoded",
      "password.",
      "kubectl",
      "edit",
      "secret",
      "oo-secret",
      "replace",
      "old",
      "new",
      "respective",
      "attribute",
      "save",
      "extra",
      "oovault-secrets.deployment.issyncvaultsecrets",
      "true",
      "methods",
      "specify",
      "tenants",
      "global.oo.size"
    ],
    "language": "en",
    "word_count": 93,
    "importance_score": 6.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "reconfigure oo containerized deployment",
    "contentLower": "this topic describes instructions to reconfigure an existing deployment of oo containerized using helm chart. prerequisites the following prerequisites apply: make sure that the database you wish to change is already created and running. make sure you have access to the latest values.yaml file. run the following command to get the latest values.yaml file: helm get values <helm_release_name> -n <oo_namespace> > latestvalues.yaml change database hostname run the following command to change the database host of the existing deployment of oo containerized: helm upgrade <helm_release_name> -n <oo_namespace> -f latestvalues.yaml <oo_helm_chart> --set global.database.host=\"new_db_host_fqdn\" change database credentials complete the following steps to change the credentials for databases for all the oo containerized components/pods: change the database name and user of oo containerized components using the following command: helm upgrade <helm_release_name> -n <oo_namespace> -f latestvalues.yam",
    "keywordsLower": [
      "re_ca.cert",
      "previous_deployment_values.yaml",
      "latestvalues.yaml",
      "global.oo",
      "database.user",
      "database.host",
      "cdfctl.sh",
      "re_ca.crt",
      "x.tgz",
      "global.tls",
      "values.yaml",
      "idm_cert.crt",
      "reconfigure",
      "oo",
      "containerized",
      "deployment",
      "prerequisites",
      "change",
      "database",
      "hostname",
      "credentials",
      "adjust",
      "sizing",
      "resize",
      "parameter",
      "attributes",
      "renew",
      "certificate",
      "ca",
      "certificates",
      "tls",
      "topic",
      "describes",
      "instructions",
      "existing",
      "helm",
      "chart.",
      "following",
      "apply",
      "make",
      "sure",
      "wish",
      "already",
      "created",
      "running.",
      "access",
      "latest",
      "file.",
      "run",
      "command",
      "get",
      "file",
      "values",
      "-n",
      "host",
      "upgrade",
      "-f",
      "--set",
      "global.database.host",
      "complete",
      "steps",
      "databases",
      "all",
      "components",
      "pods",
      "name",
      "user",
      "global.database..dbname",
      "global.database..user",
      "either",
      "oocentral",
      "oocontroller",
      "ooui",
      "ooscheduler.",
      "autopass",
      "component",
      "autopass.deployment.database.dbname",
      "autopass.deployment.database.user",
      "password",
      "command.",
      "base64",
      "encoded",
      "password.",
      "kubectl",
      "edit",
      "secret",
      "oo-secret",
      "replace",
      "old",
      "new",
      "respective",
      "attribute",
      "save",
      "extra",
      "oovault-secrets.deployment.issyncvaultsecrets",
      "true",
      "methods",
      "specify",
      "tenants",
      "global.oo.size"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Set up topology for workers and RASes",
    "content": "The network topology is the arrangement of the various elements (links, nodes, and more) in a network. Workers and RASes are part of the topology that you can configure under the TOPOLOGY tab. The Workers tab displays information about the following items: Internal RAS: an internal RAS is responsible for executing flows. The internal RAS obtains tasks (flow execution messages) to process from OO Central. You can assign the internal RAS to a worker group. This enables internal RAS to withstand a high action execution load and increases the availability of workers in a data center. External RAS: an external RAS is a remote action server, containing a remote protocol for connecting with OO Central tenant. An external RAS will begin the connection to OO Central. After installing an external RAS, it will appear in the grid in the Workers tab. The TOPOLOGY > Workers tab displays information about each worker/RAS not restricted to the following: their status (Running or Stopped), installation",
    "url": "setupooworkers",
    "filename": "setupooworkers",
    "headings": [
      "Execution Status",
      "Worker busyness",
      "Configuration settings for busyness feature",
      "Central configuration properties",
      "Central Worker\\RAS configuration properties",
      "Assign an internal RAS to groups",
      "User interface elements",
      "TOPOLOGY > Workers",
      "Topology > Workers > Internal RAS Fleet pop-up",
      "Topology > Workers > Assign to Group pop-up",
      "Assign an internal RAS/external RAS to an existing worker group",
      "Create a new worker group and assign an internal RAS/external RAS",
      "Remove an external RAS from a worker group",
      "Disable a worker/RAS",
      "For internal RAS",
      "For external RAS",
      "Enable a worker/RAS",
      "For internal RAS",
      "For external RAS",
      "Delete a RAS"
    ],
    "keywords": [
      "Keep.From",
      "wrapper.conf",
      "History.To",
      "set",
      "topology",
      "workers",
      "rases",
      "execution",
      "status",
      "worker",
      "busyness",
      "configuration",
      "settings",
      "feature",
      "central",
      "properties",
      "ras",
      "assign",
      "internal",
      "groups",
      "user",
      "interface",
      "elements",
      "fleet",
      "pop-up",
      "group",
      "external",
      "existing",
      "create",
      "new",
      "remove",
      "disable",
      "enable",
      "delete",
      "verify",
      "installation",
      "network",
      "arrangement",
      "various",
      "links",
      "nodes",
      "network.",
      "part",
      "configure",
      "under",
      "tab.",
      "tab",
      "displays",
      "information",
      "about",
      "following",
      "items",
      "responsible",
      "executing",
      "flows.",
      "obtains",
      "tasks",
      "flow",
      "messages",
      "process",
      "oo",
      "central.",
      "group.",
      "enables",
      "withstand",
      "high",
      "action",
      "load",
      "increases",
      "availability",
      "data",
      "center.",
      "remote",
      "server",
      "containing",
      "protocol",
      "connecting",
      "tenant.",
      "begin",
      "connection",
      "after",
      "installing",
      "appear",
      "grid",
      "restricted",
      "running",
      "stopped",
      "path",
      "details",
      "operating",
      "system",
      "id.",
      "take",
      "minute",
      "two",
      "update.",
      "stop",
      "service",
      "takes",
      "few"
    ],
    "language": "en",
    "word_count": 104,
    "importance_score": 5.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "set up topology for workers and rases",
    "contentLower": "the network topology is the arrangement of the various elements (links, nodes, and more) in a network. workers and rases are part of the topology that you can configure under the topology tab. the workers tab displays information about the following items: internal ras: an internal ras is responsible for executing flows. the internal ras obtains tasks (flow execution messages) to process from oo central. you can assign the internal ras to a worker group. this enables internal ras to withstand a high action execution load and increases the availability of workers in a data center. external ras: an external ras is a remote action server, containing a remote protocol for connecting with oo central tenant. an external ras will begin the connection to oo central. after installing an external ras, it will appear in the grid in the workers tab. the topology > workers tab displays information about each worker/ras not restricted to the following: their status (running or stopped), installation",
    "keywordsLower": [
      "keep.from",
      "wrapper.conf",
      "history.to",
      "set",
      "topology",
      "workers",
      "rases",
      "execution",
      "status",
      "worker",
      "busyness",
      "configuration",
      "settings",
      "feature",
      "central",
      "properties",
      "ras",
      "assign",
      "internal",
      "groups",
      "user",
      "interface",
      "elements",
      "fleet",
      "pop-up",
      "group",
      "external",
      "existing",
      "create",
      "new",
      "remove",
      "disable",
      "enable",
      "delete",
      "verify",
      "installation",
      "network",
      "arrangement",
      "various",
      "links",
      "nodes",
      "network.",
      "part",
      "configure",
      "under",
      "tab.",
      "tab",
      "displays",
      "information",
      "about",
      "following",
      "items",
      "responsible",
      "executing",
      "flows.",
      "obtains",
      "tasks",
      "flow",
      "messages",
      "process",
      "oo",
      "central.",
      "group.",
      "enables",
      "withstand",
      "high",
      "action",
      "load",
      "increases",
      "availability",
      "data",
      "center.",
      "remote",
      "server",
      "containing",
      "protocol",
      "connecting",
      "tenant.",
      "begin",
      "connection",
      "after",
      "installing",
      "appear",
      "grid",
      "restricted",
      "running",
      "stopped",
      "path",
      "details",
      "operating",
      "system",
      "id.",
      "take",
      "minute",
      "two",
      "update.",
      "stop",
      "service",
      "takes",
      "few"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Roles and permissions in OO Central",
    "content": "This topic provides details about Roles and Permissions available in Operations Orchestration (OO) Containerized. Overview of roles and permissions OO uses Role-based Access Control (RBAC) to manage user access to perform OO Central tasks. RBAC lets the Suite Administrator control the actions that the OO users are allowed to perform based on their role. A permission is a predefined ability to perform a task. OO Central has a set of permissions that you can assign to the roles. A role is a collection of permissions. You can assign roles to users. OO roles and groups OO Central contains many out of the box permissions that enable a refined definition of which parts of the web user interface (UI) each role can see. The suite administrator can formulate a dedicated UI experience for each group of users. This enables end users to use OO Central and see the information they need, limiting their ability to harm the system. By default, OO Central has the following roles set up in the IdM Conso",
    "url": "oorolespermissions",
    "filename": "oorolespermissions",
    "headings": [
      "Overview of roles and permissions",
      "OO roles and groups",
      "Access IdM Admin console"
    ],
    "keywords": [
      "roles",
      "permissions",
      "oo",
      "central",
      "overview",
      "groups",
      "access",
      "idm",
      "admin",
      "console",
      "topic",
      "provides",
      "details",
      "about",
      "available",
      "operations",
      "orchestration",
      "containerized.",
      "uses",
      "role-based",
      "control",
      "rbac",
      "manage",
      "user",
      "perform",
      "tasks.",
      "lets",
      "suite",
      "administrator",
      "actions",
      "users",
      "allowed",
      "based",
      "role.",
      "permission",
      "predefined",
      "ability",
      "task.",
      "set",
      "assign",
      "roles.",
      "role",
      "collection",
      "permissions.",
      "users.",
      "contains",
      "many",
      "out",
      "box",
      "enable",
      "refined",
      "definition",
      "parts",
      "web",
      "interface",
      "ui",
      "see.",
      "formulate",
      "dedicated",
      "experience",
      "group",
      "enables",
      "end",
      "see",
      "information",
      "need",
      "limiting",
      "harm",
      "system.",
      "default",
      "following",
      "containerized",
      "name",
      "display",
      "description",
      "application",
      "component.",
      "all",
      "none",
      "workflow",
      "operator",
      "remote",
      "debug",
      "schedule",
      "management",
      "content",
      "power",
      "topology",
      "interface.",
      "linked",
      "products",
      "url",
      "format",
      "idm-admin",
      "table",
      "lists",
      "tasks",
      "task",
      "parameter",
      "setting"
    ],
    "language": "en",
    "word_count": 108,
    "importance_score": 3.5,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "roles and permissions in oo central",
    "contentLower": "this topic provides details about roles and permissions available in operations orchestration (oo) containerized. overview of roles and permissions oo uses role-based access control (rbac) to manage user access to perform oo central tasks. rbac lets the suite administrator control the actions that the oo users are allowed to perform based on their role. a permission is a predefined ability to perform a task. oo central has a set of permissions that you can assign to the roles. a role is a collection of permissions. you can assign roles to users. oo roles and groups oo central contains many out of the box permissions that enable a refined definition of which parts of the web user interface (ui) each role can see. the suite administrator can formulate a dedicated ui experience for each group of users. this enables end users to use oo central and see the information they need, limiting their ability to harm the system. by default, oo central has the following roles set up in the idm conso",
    "keywordsLower": [
      "roles",
      "permissions",
      "oo",
      "central",
      "overview",
      "groups",
      "access",
      "idm",
      "admin",
      "console",
      "topic",
      "provides",
      "details",
      "about",
      "available",
      "operations",
      "orchestration",
      "containerized.",
      "uses",
      "role-based",
      "control",
      "rbac",
      "manage",
      "user",
      "perform",
      "tasks.",
      "lets",
      "suite",
      "administrator",
      "actions",
      "users",
      "allowed",
      "based",
      "role.",
      "permission",
      "predefined",
      "ability",
      "task.",
      "set",
      "assign",
      "roles.",
      "role",
      "collection",
      "permissions.",
      "users.",
      "contains",
      "many",
      "out",
      "box",
      "enable",
      "refined",
      "definition",
      "parts",
      "web",
      "interface",
      "ui",
      "see.",
      "formulate",
      "dedicated",
      "experience",
      "group",
      "enables",
      "end",
      "see",
      "information",
      "need",
      "limiting",
      "harm",
      "system.",
      "default",
      "following",
      "containerized",
      "name",
      "display",
      "description",
      "application",
      "component.",
      "all",
      "none",
      "workflow",
      "operator",
      "remote",
      "debug",
      "schedule",
      "management",
      "content",
      "power",
      "topology",
      "interface.",
      "linked",
      "products",
      "url",
      "format",
      "idm-admin",
      "table",
      "lists",
      "tasks",
      "task",
      "parameter",
      "setting"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Set the browser language",
    "content": "Setting the browser language Central language support is according to the browser language. If the language is not supported, Central is displayed in English. Set up your browser for foreign language support. Note Make sure that the added language is the first in the list. Change the language preferences on Internet Explorer Go to Tools > Internet Options > General (tab) > Languages > Language preference. Select the required language. Make sure the primary language is the first in the list. Change the language preferences on Firefox Go to Tools > Options, Content (tab) > Languages > Choose (button). Select the required language. Change the language preferences on Google Chrome Click the Customize and control Google Chrome button, and then select Settings > Show advanced settings. In the Languages section, click Language and input settings. Click Add, and select the required language. You can add languages to this from a predefined set, and Chrome will send all the languages you choose ",
    "url": "setbrowserlanguage",
    "filename": "setbrowserlanguage",
    "headings": [
      "Change the language preferences on Internet Explorer",
      "Change the language preferences on Firefox",
      "Change the language preferences on Google Chrome",
      "Change the language preferences on Safari"
    ],
    "keywords": [
      "wrapper.conf",
      "set",
      "browser",
      "language",
      "change",
      "preferences",
      "internet",
      "explorer",
      "firefox",
      "google",
      "chrome",
      "safari",
      "setting",
      "central",
      "support",
      "according",
      "language.",
      "supported",
      "displayed",
      "english.",
      "foreign",
      "support.",
      "note",
      "make",
      "sure",
      "added",
      "first",
      "list.",
      "go",
      "tools",
      "options",
      "general",
      "tab",
      "languages",
      "preference.",
      "select",
      "required",
      "primary",
      "content",
      "choose",
      "button",
      "click",
      "customize",
      "control",
      "settings",
      "show",
      "advanced",
      "settings.",
      "section",
      "input",
      "add",
      "predefined",
      "send",
      "all",
      "accept-language",
      "header",
      "order",
      "arrange",
      "them.",
      "windows",
      "sent",
      "safari.",
      "derived",
      "system",
      "possible",
      "ms",
      "sql",
      "collation",
      "central-wrapper.conf",
      "content."
    ],
    "language": "en",
    "word_count": 103,
    "importance_score": 5.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "set the browser language",
    "contentLower": "setting the browser language central language support is according to the browser language. if the language is not supported, central is displayed in english. set up your browser for foreign language support. note make sure that the added language is the first in the list. change the language preferences on internet explorer go to tools > internet options > general (tab) > languages > language preference. select the required language. make sure the primary language is the first in the list. change the language preferences on firefox go to tools > options, content (tab) > languages > choose (button). select the required language. change the language preferences on google chrome click the customize and control google chrome button, and then select settings > show advanced settings. in the languages section, click language and input settings. click add, and select the required language. you can add languages to this from a predefined set, and chrome will send all the languages you choose ",
    "keywordsLower": [
      "wrapper.conf",
      "set",
      "browser",
      "language",
      "change",
      "preferences",
      "internet",
      "explorer",
      "firefox",
      "google",
      "chrome",
      "safari",
      "setting",
      "central",
      "support",
      "according",
      "language.",
      "supported",
      "displayed",
      "english.",
      "foreign",
      "support.",
      "note",
      "make",
      "sure",
      "added",
      "first",
      "list.",
      "go",
      "tools",
      "options",
      "general",
      "tab",
      "languages",
      "preference.",
      "select",
      "required",
      "primary",
      "content",
      "choose",
      "button",
      "click",
      "customize",
      "control",
      "settings",
      "show",
      "advanced",
      "settings.",
      "section",
      "input",
      "add",
      "predefined",
      "send",
      "all",
      "accept-language",
      "header",
      "order",
      "arrange",
      "them.",
      "windows",
      "sent",
      "safari.",
      "derived",
      "system",
      "possible",
      "ms",
      "sql",
      "collation",
      "central-wrapper.conf",
      "content."
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Set up the language for OO Workflow Designer",
    "content": "During the installation of Operations Orchestration (OO) Workflow Designer, you have an option to select a supported language in addition to the default English. This language isn't just used as the MS SQL collation language, if relevant, but for OO content also. You might find this language support useful at some scenarios, such as, when you need to ping a server that's configured in Japanese. You can change the language by editing the <component>-wrapper.conf file located in each components installation folder <installation_folder>/<component>/conf. Change the language for localized OO Workflow Designer If you are using the localized copy of Operations Orchestration (OO) Workflow Designer, then you will need to set the properties to reflect the system locale in the designer-wrapper.conf file. OO Workflow Designer supports English, French, German, Japanese, Simplified Chinese, and Spanish languages. You must note that the following instructions are for the localized OO Workflow Design",
    "url": "changelanguageood",
    "filename": "changelanguageood",
    "headings": [
      "Change the language for localized OO Workflow Designer",
      "Related topic"
    ],
    "keywords": [
      "set.LANG",
      "wrapper.conf",
      "wrapper.java",
      "set",
      "language",
      "oo",
      "workflow",
      "designer",
      "change",
      "localized",
      "related",
      "topic",
      "during",
      "installation",
      "operations",
      "orchestration",
      "option",
      "select",
      "supported",
      "addition",
      "default",
      "english.",
      "isn",
      "just",
      "ms",
      "sql",
      "collation",
      "relevant",
      "content",
      "also.",
      "find",
      "support",
      "useful",
      "scenarios",
      "such",
      "need",
      "ping",
      "server",
      "configured",
      "japanese.",
      "editing",
      "-wrapper.conf",
      "file",
      "located",
      "components",
      "folder",
      "conf.",
      "copy",
      "properties",
      "reflect",
      "system",
      "locale",
      "designer-wrapper.conf",
      "file.",
      "supports",
      "english",
      "french",
      "german",
      "japanese",
      "simplified",
      "chinese",
      "spanish",
      "languages.",
      "note",
      "following",
      "instructions",
      "designer.",
      "navigate",
      "conf",
      "open",
      "text",
      "editor",
      "edit",
      "set.language",
      "wrapper.java.additional.",
      "-duser.language",
      "-duser.country",
      "example",
      "save",
      "browsers",
      "see",
      "browser"
    ],
    "language": "en",
    "word_count": 93,
    "importance_score": 3.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "set up the language for oo workflow designer",
    "contentLower": "during the installation of operations orchestration (oo) workflow designer, you have an option to select a supported language in addition to the default english. this language isn't just used as the ms sql collation language, if relevant, but for oo content also. you might find this language support useful at some scenarios, such as, when you need to ping a server that's configured in japanese. you can change the language by editing the <component>-wrapper.conf file located in each components installation folder <installation_folder>/<component>/conf. change the language for localized oo workflow designer if you are using the localized copy of operations orchestration (oo) workflow designer, then you will need to set the properties to reflect the system locale in the designer-wrapper.conf file. oo workflow designer supports english, french, german, japanese, simplified chinese, and spanish languages. you must note that the following instructions are for the localized oo workflow design",
    "keywordsLower": [
      "set.lang",
      "wrapper.conf",
      "wrapper.java",
      "set",
      "language",
      "oo",
      "workflow",
      "designer",
      "change",
      "localized",
      "related",
      "topic",
      "during",
      "installation",
      "operations",
      "orchestration",
      "option",
      "select",
      "supported",
      "addition",
      "default",
      "english.",
      "isn",
      "just",
      "ms",
      "sql",
      "collation",
      "relevant",
      "content",
      "also.",
      "find",
      "support",
      "useful",
      "scenarios",
      "such",
      "need",
      "ping",
      "server",
      "configured",
      "japanese.",
      "editing",
      "-wrapper.conf",
      "file",
      "located",
      "components",
      "folder",
      "conf.",
      "copy",
      "properties",
      "reflect",
      "system",
      "locale",
      "designer-wrapper.conf",
      "file.",
      "supports",
      "english",
      "french",
      "german",
      "japanese",
      "simplified",
      "chinese",
      "spanish",
      "languages.",
      "note",
      "following",
      "instructions",
      "designer.",
      "navigate",
      "conf",
      "open",
      "text",
      "editor",
      "edit",
      "set.language",
      "wrapper.java.additional.",
      "-duser.language",
      "-duser.country",
      "example",
      "save",
      "browsers",
      "see",
      "browser"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Set up the browser language for OO Workflow Designer",
    "content": "The Operations Orchestration (OO) Workflow Designer language support is according to the set browser language. If the specific language isn't supported, OO Workflow Designer appears in English. You must set up your browser for foreign language support and make sure that the added language is the first in the list. Change the language preferences on Internet Explorer Go to Tools > Internet Options > General (tab) > Languages > Language preference. Select the required language. Make sure the primary language is the first on the list. Change the language preferences on Firefox Go to Tools > Options, Content (tab) > Languages > Choose (button). Select the required language. Change the language preferences on Google Chrome Click the Customize and control Google Chrome button, and then select Settings > Show advanced settings. In the Languages section, click Language and input settings. Click Add, and select the required language. You can add languages to this from a predefined set, and Chro",
    "url": "setbrowserlanguageood",
    "filename": "setbrowserlanguageood",
    "headings": [
      "Change the language preferences on Internet Explorer",
      "Change the language preferences on Firefox",
      "Change the language preferences on Google Chrome",
      "Change the language preferences on Safari",
      "Related topics"
    ],
    "keywords": [
      "wrapper.conf",
      "set",
      "browser",
      "language",
      "oo",
      "workflow",
      "designer",
      "change",
      "preferences",
      "internet",
      "explorer",
      "firefox",
      "google",
      "chrome",
      "safari",
      "related",
      "topics",
      "operations",
      "orchestration",
      "support",
      "according",
      "language.",
      "specific",
      "isn",
      "supported",
      "appears",
      "english.",
      "foreign",
      "make",
      "sure",
      "added",
      "first",
      "list.",
      "go",
      "tools",
      "options",
      "general",
      "tab",
      "languages",
      "preference.",
      "select",
      "required",
      "primary",
      "content",
      "choose",
      "button",
      "click",
      "customize",
      "control",
      "settings",
      "show",
      "advanced",
      "settings.",
      "section",
      "input",
      "add",
      "predefined",
      "send",
      "all",
      "accept-language",
      "header",
      "order",
      "arrange",
      "them.",
      "windows",
      "sent",
      "safari.",
      "system",
      "possible",
      "microsoft",
      "sql",
      "collation",
      "central-wrapper.conf",
      "content.",
      "information",
      "see",
      "topic."
    ],
    "language": "en",
    "word_count": 108,
    "importance_score": 4.5,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "set up the browser language for oo workflow designer",
    "contentLower": "the operations orchestration (oo) workflow designer language support is according to the set browser language. if the specific language isn't supported, oo workflow designer appears in english. you must set up your browser for foreign language support and make sure that the added language is the first in the list. change the language preferences on internet explorer go to tools > internet options > general (tab) > languages > language preference. select the required language. make sure the primary language is the first on the list. change the language preferences on firefox go to tools > options, content (tab) > languages > choose (button). select the required language. change the language preferences on google chrome click the customize and control google chrome button, and then select settings > show advanced settings. in the languages section, click language and input settings. click add, and select the required language. you can add languages to this from a predefined set, and chro",
    "keywordsLower": [
      "wrapper.conf",
      "set",
      "browser",
      "language",
      "oo",
      "workflow",
      "designer",
      "change",
      "preferences",
      "internet",
      "explorer",
      "firefox",
      "google",
      "chrome",
      "safari",
      "related",
      "topics",
      "operations",
      "orchestration",
      "support",
      "according",
      "language.",
      "specific",
      "isn",
      "supported",
      "appears",
      "english.",
      "foreign",
      "make",
      "sure",
      "added",
      "first",
      "list.",
      "go",
      "tools",
      "options",
      "general",
      "tab",
      "languages",
      "preference.",
      "select",
      "required",
      "primary",
      "content",
      "choose",
      "button",
      "click",
      "customize",
      "control",
      "settings",
      "show",
      "advanced",
      "settings.",
      "section",
      "input",
      "add",
      "predefined",
      "send",
      "all",
      "accept-language",
      "header",
      "order",
      "arrange",
      "them.",
      "windows",
      "sent",
      "safari.",
      "system",
      "possible",
      "microsoft",
      "sql",
      "collation",
      "central-wrapper.conf",
      "content.",
      "information",
      "see",
      "topic."
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Recurring administration tasks for OO Workflow Designer",
    "content": "This section includes administration tasks that you may need to perform periodically or in response to a specific situation. This section covers the following topics: Create a Git repository Configure content pack import size",
    "url": "recurringdesignertasks",
    "filename": "recurringdesignertasks",
    "headings": [],
    "keywords": [
      "recurring",
      "administration",
      "tasks",
      "oo",
      "workflow",
      "designer",
      "section",
      "includes",
      "need",
      "perform",
      "periodically",
      "response",
      "specific",
      "situation.",
      "covers",
      "following",
      "topics",
      "create",
      "git",
      "repository",
      "configure",
      "content",
      "pack",
      "import",
      "size"
    ],
    "language": "en",
    "word_count": 28,
    "importance_score": 1.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "recurring administration tasks for oo workflow designer",
    "contentLower": "this section includes administration tasks that you may need to perform periodically or in response to a specific situation. this section covers the following topics: create a git repository configure content pack import size",
    "keywordsLower": [
      "recurring",
      "administration",
      "tasks",
      "oo",
      "workflow",
      "designer",
      "section",
      "includes",
      "need",
      "perform",
      "periodically",
      "response",
      "specific",
      "situation.",
      "covers",
      "following",
      "topics",
      "create",
      "git",
      "repository",
      "configure",
      "content",
      "pack",
      "import",
      "size"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Set the system localization",
    "content": "If your OO Workflow Designer system is localized, you will need to set the properties to reflect the system locale, in the designer-wrapper.conf file. Open the designer-wrapper.conf file in a text editor (located under <installation_folder>/designer/conf). Edit the following properties: set.LANG= set.LC_ALL= set.LANGUAGE= wrapper.java.additional.<x>=-Duser.language= wrapper.java.additional.<x>=-Duser.country= For example, for Japanese: set.LANG=ja_JP set.LC_ALL=ja_JP Save the designer-wrapper.conf file.",
    "url": "setsystemlocalization",
    "filename": "setsystemlocalization",
    "headings": [],
    "keywords": [
      "set.LANG",
      "wrapper.conf",
      "wrapper.java",
      "set",
      "system",
      "localization",
      "oo",
      "workflow",
      "designer",
      "localized",
      "need",
      "properties",
      "reflect",
      "locale",
      "designer-wrapper.conf",
      "file.",
      "open",
      "file",
      "text",
      "editor",
      "located",
      "under",
      "conf",
      "edit",
      "following",
      "set.language",
      "wrapper.java.additional.",
      "-duser.language",
      "-duser.country",
      "example",
      "japanese",
      "save"
    ],
    "language": "en",
    "word_count": 44,
    "importance_score": 2.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "set the system localization",
    "contentLower": "if your oo workflow designer system is localized, you will need to set the properties to reflect the system locale, in the designer-wrapper.conf file. open the designer-wrapper.conf file in a text editor (located under <installation_folder>/designer/conf). edit the following properties: set.lang= set.lc_all= set.language= wrapper.java.additional.<x>=-duser.language= wrapper.java.additional.<x>=-duser.country= for example, for japanese: set.lang=ja_jp set.lc_all=ja_jp save the designer-wrapper.conf file.",
    "keywordsLower": [
      "set.lang",
      "wrapper.conf",
      "wrapper.java",
      "set",
      "system",
      "localization",
      "oo",
      "workflow",
      "designer",
      "localized",
      "need",
      "properties",
      "reflect",
      "locale",
      "designer-wrapper.conf",
      "file.",
      "open",
      "file",
      "text",
      "editor",
      "located",
      "under",
      "conf",
      "edit",
      "following",
      "set.language",
      "wrapper.java.additional.",
      "-duser.language",
      "-duser.country",
      "example",
      "japanese",
      "save"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Set up disaster recovery",
    "content": "Plan for disaster recovery To enable disaster recovery, create a secondary datacenter by replicating the following: Database configuration Schema OO Workflow Designer configuration and security files: <installation_folder>\\designer\\var\\security and <installation_folder>\\designer\\conf The replication can be ongoing, using whatever means you choose, for example, disk replication or database replication. Perform disaster recovery OO Workflow Designer supports cold disaster recovery, which requires a manual process to switch over from the primary datacenter to the secondary datacenter. You require this in the case of a full or partial failure in the primary datacenter. Restore the OO Workflow Designer server(s) by reinstalling all nodes. Use the database configuration, schema, and OO Workflow Designer configuration and security files that you replicated for the secondary datacenter. You can configure the database by editing the database.properties file. Delete the old worker nodes in the d",
    "url": "disasterrecoverydesigner",
    "filename": "disasterrecoverydesigner",
    "headings": [
      "Plan for disaster recovery",
      "Perform disaster recovery",
      "Related topics"
    ],
    "keywords": [
      "set",
      "disaster",
      "recovery",
      "plan",
      "perform",
      "related",
      "topics",
      "enable",
      "create",
      "secondary",
      "datacenter",
      "replicating",
      "following",
      "database",
      "configuration",
      "schema",
      "oo",
      "workflow",
      "designer",
      "security",
      "files",
      "var",
      "conf",
      "replication",
      "ongoing",
      "whatever",
      "means",
      "choose",
      "example",
      "disk",
      "replication.",
      "supports",
      "cold",
      "requires",
      "manual",
      "process",
      "switch",
      "over",
      "primary",
      "datacenter.",
      "require",
      "case",
      "full",
      "partial",
      "failure",
      "restore",
      "server",
      "reinstalling",
      "all",
      "nodes.",
      "replicated",
      "configure",
      "editing",
      "database.properties",
      "file.",
      "delete",
      "old",
      "worker",
      "nodes",
      "longer",
      "exist.",
      "turn",
      "off",
      "environment"
    ],
    "language": "en",
    "word_count": 95,
    "importance_score": 4.5,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "set up disaster recovery",
    "contentLower": "plan for disaster recovery to enable disaster recovery, create a secondary datacenter by replicating the following: database configuration schema oo workflow designer configuration and security files: <installation_folder>\\designer\\var\\security and <installation_folder>\\designer\\conf the replication can be ongoing, using whatever means you choose, for example, disk replication or database replication. perform disaster recovery oo workflow designer supports cold disaster recovery, which requires a manual process to switch over from the primary datacenter to the secondary datacenter. you require this in the case of a full or partial failure in the primary datacenter. restore the oo workflow designer server(s) by reinstalling all nodes. use the database configuration, schema, and oo workflow designer configuration and security files that you replicated for the secondary datacenter. you can configure the database by editing the database.properties file. delete the old worker nodes in the d",
    "keywordsLower": [
      "set",
      "disaster",
      "recovery",
      "plan",
      "perform",
      "related",
      "topics",
      "enable",
      "create",
      "secondary",
      "datacenter",
      "replicating",
      "following",
      "database",
      "configuration",
      "schema",
      "oo",
      "workflow",
      "designer",
      "security",
      "files",
      "var",
      "conf",
      "replication",
      "ongoing",
      "whatever",
      "means",
      "choose",
      "example",
      "disk",
      "replication.",
      "supports",
      "cold",
      "requires",
      "manual",
      "process",
      "switch",
      "over",
      "primary",
      "datacenter.",
      "require",
      "case",
      "full",
      "partial",
      "failure",
      "restore",
      "server",
      "reinstalling",
      "all",
      "nodes.",
      "replicated",
      "configure",
      "editing",
      "database.properties",
      "file.",
      "delete",
      "old",
      "worker",
      "nodes",
      "longer",
      "exist.",
      "turn",
      "off",
      "environment"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "System tuning",
    "content": "You can configure one or more of the following parameters for each OO Workflow Designer node. Note Changing any of the parameters below requires a restart of the configured node. JVM heap size - You can increase the initial and maximum size of the OO Workflow Designer heap by configuring the designer-wrapper.conf files (located under <installation_folder>/designer/conf/). wrapper.java.initmemory=<value in MB> wrapper.java.maxmemory=<value in MB> We recommend configuring OO Workflow Designer to 4GB. Database connections - You can increase the number of database connections in the database.properties file (located under <installation_folder>/designer/conf/). Edit the db.pool.maxPoolSize property. We recommend changing it to 100 connections.",
    "url": "systemtuningdesigner",
    "filename": "systemtuningdesigner",
    "headings": [],
    "keywords": [
      "db.pool",
      "wrapper.conf",
      "wrapper.java",
      "system",
      "tuning",
      "configure",
      "one",
      "following",
      "parameters",
      "oo",
      "workflow",
      "designer",
      "node.",
      "note",
      "changing",
      "any",
      "below",
      "requires",
      "restart",
      "configured",
      "jvm",
      "heap",
      "size",
      "increase",
      "initial",
      "maximum",
      "configuring",
      "designer-wrapper.conf",
      "files",
      "located",
      "under",
      "conf",
      "wrapper.java.initmemory",
      "wrapper.java.maxmemory",
      "recommend",
      "4gb.",
      "database",
      "connections",
      "number",
      "database.properties",
      "file",
      "edit",
      "db.pool.maxpoolsize",
      "property.",
      "100",
      "connections."
    ],
    "language": "en",
    "word_count": 64,
    "importance_score": 2.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "system tuning",
    "contentLower": "you can configure one or more of the following parameters for each oo workflow designer node. note changing any of the parameters below requires a restart of the configured node. jvm heap size - you can increase the initial and maximum size of the oo workflow designer heap by configuring the designer-wrapper.conf files (located under <installation_folder>/designer/conf/). wrapper.java.initmemory=<value in mb> wrapper.java.maxmemory=<value in mb> we recommend configuring oo workflow designer to 4gb. database connections - you can increase the number of database connections in the database.properties file (located under <installation_folder>/designer/conf/). edit the db.pool.maxpoolsize property. we recommend changing it to 100 connections.",
    "keywordsLower": [
      "db.pool",
      "wrapper.conf",
      "wrapper.java",
      "system",
      "tuning",
      "configure",
      "one",
      "following",
      "parameters",
      "oo",
      "workflow",
      "designer",
      "node.",
      "note",
      "changing",
      "any",
      "below",
      "requires",
      "restart",
      "configured",
      "jvm",
      "heap",
      "size",
      "increase",
      "initial",
      "maximum",
      "configuring",
      "designer-wrapper.conf",
      "files",
      "located",
      "under",
      "conf",
      "wrapper.java.initmemory",
      "wrapper.java.maxmemory",
      "recommend",
      "4gb.",
      "database",
      "connections",
      "number",
      "database.properties",
      "file",
      "edit",
      "db.pool.maxpoolsize",
      "property.",
      "100",
      "connections."
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Set up database environment",
    "content": "This topic provides the database administrator required information to configure various types of databases with the Operations Orchestration (OO) Workflow Designer. Overview The meaning of the term “database” depends on the database vendor/technology used. In Oracle, the term “database” relates to a collection of files containing data and metadata. A single Oracle database may contain one or more schemas (and users). A Microsoft SQL Server “database” is closer in definition to Oracle’s \"schema\" than to Oracle’s \"database\". To avoid confusion, this topic will use the following terms: Instance/server–the software and memory structures providing Relational Database Management System (RDBMS) services Database–the entity containing tables, views, indexes, and more Review the following points related to the database usage: OO Workflow Designer requires a single database. This database may coexist with other databases such as IdM database contained in a database server. OO Workflow Designer ",
    "url": "setupoodatabase",
    "filename": "setupoodatabase",
    "headings": [
      "Overview",
      "IdM database configuration",
      "Language Support",
      "Use database clusters",
      "Database security",
      "Database specific adaptations",
      "Database sizing",
      "Hardware requirements",
      "Related topics"
    ],
    "keywords": [
      "postgresql.conf",
      "set",
      "database",
      "environment",
      "overview",
      "idm",
      "configuration",
      "language",
      "support",
      "clusters",
      "security",
      "specific",
      "adaptations",
      "sizing",
      "hardware",
      "requirements",
      "related",
      "topics",
      "topic",
      "provides",
      "administrator",
      "required",
      "information",
      "configure",
      "various",
      "types",
      "databases",
      "operations",
      "orchestration",
      "oo",
      "workflow",
      "designer.",
      "meaning",
      "term",
      "depends",
      "vendor",
      "technology",
      "used.",
      "oracle",
      "relates",
      "collection",
      "files",
      "containing",
      "data",
      "metadata.",
      "single",
      "contain",
      "one",
      "schemas",
      "users",
      "microsoft",
      "sql",
      "server",
      "closer",
      "definition",
      "schema",
      "avoid",
      "confusion",
      "following",
      "terms",
      "instance",
      "software",
      "memory",
      "structures",
      "providing",
      "relational",
      "management",
      "system",
      "rdbms",
      "services",
      "entity",
      "tables",
      "views",
      "indexes",
      "review",
      "points",
      "usage",
      "designer",
      "requires",
      "database.",
      "coexist",
      "such",
      "contained",
      "server.",
      "connectivity",
      "relies",
      "java",
      "jdbc.",
      "measures",
      "see",
      "jdbc",
      "documentation",
      "learn",
      "connection",
      "url",
      "format.",
      "contains",
      "about",
      "describes",
      "settings."
    ],
    "language": "en",
    "word_count": 102,
    "importance_score": 6.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "set up database environment",
    "contentLower": "this topic provides the database administrator required information to configure various types of databases with the operations orchestration (oo) workflow designer. overview the meaning of the term “database” depends on the database vendor/technology used. in oracle, the term “database” relates to a collection of files containing data and metadata. a single oracle database may contain one or more schemas (and users). a microsoft sql server “database” is closer in definition to oracle’s \"schema\" than to oracle’s \"database\". to avoid confusion, this topic will use the following terms: instance/server–the software and memory structures providing relational database management system (rdbms) services database–the entity containing tables, views, indexes, and more review the following points related to the database usage: oo workflow designer requires a single database. this database may coexist with other databases such as idm database contained in a database server. oo workflow designer ",
    "keywordsLower": [
      "postgresql.conf",
      "set",
      "database",
      "environment",
      "overview",
      "idm",
      "configuration",
      "language",
      "support",
      "clusters",
      "security",
      "specific",
      "adaptations",
      "sizing",
      "hardware",
      "requirements",
      "related",
      "topics",
      "topic",
      "provides",
      "administrator",
      "required",
      "information",
      "configure",
      "various",
      "types",
      "databases",
      "operations",
      "orchestration",
      "oo",
      "workflow",
      "designer.",
      "meaning",
      "term",
      "depends",
      "vendor",
      "technology",
      "used.",
      "oracle",
      "relates",
      "collection",
      "files",
      "containing",
      "data",
      "metadata.",
      "single",
      "contain",
      "one",
      "schemas",
      "users",
      "microsoft",
      "sql",
      "server",
      "closer",
      "definition",
      "schema",
      "avoid",
      "confusion",
      "following",
      "terms",
      "instance",
      "software",
      "memory",
      "structures",
      "providing",
      "relational",
      "management",
      "system",
      "rdbms",
      "services",
      "entity",
      "tables",
      "views",
      "indexes",
      "review",
      "points",
      "usage",
      "designer",
      "requires",
      "database.",
      "coexist",
      "such",
      "contained",
      "server.",
      "connectivity",
      "relies",
      "java",
      "jdbc.",
      "measures",
      "see",
      "jdbc",
      "documentation",
      "learn",
      "connection",
      "url",
      "format.",
      "contains",
      "about",
      "describes",
      "settings."
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Schedule OO flows",
    "content": "This topic contains the instructions to schedule OO flows. Overview OO Scheduler allows you to control when to run your flows. You can specify a schedule to run for a specific flow and also set up recurring schedules for a task. For example, to check for the number of servers that are online, define a flow to check the IP address and then create a schedule to run that flow. View Scheduler The Schedules are displayed in a table under the SCHEDULER tab. The display of schedules depends on the permissions assigned for your role. Contact your administrator for help with permissions. If you your role has the View Schedules permission granted, then you'll be able to view the OO schedules and their details. If you your role has the Manage Schedules permission granted, then you'll be able to view and edit schedules. Scheduler actions The schedules display in a table. Click on the column header in the table to sort the schedules by that column. The menu bar has the following actions: Action Des",
    "url": "scheduleflowruns",
    "filename": "scheduleflowruns",
    "headings": [
      "Overview",
      "View Scheduler",
      "Scheduler actions",
      "Create a schedule",
      "Edit a schedule"
    ],
    "keywords": [
      "schedule",
      "oo",
      "flows",
      "overview",
      "view",
      "scheduler",
      "actions",
      "create",
      "edit",
      "topic",
      "contains",
      "instructions",
      "flows.",
      "allows",
      "control",
      "run",
      "specify",
      "specific",
      "flow",
      "set",
      "recurring",
      "schedules",
      "task.",
      "example",
      "check",
      "number",
      "servers",
      "online",
      "define",
      "ip",
      "address",
      "flow.",
      "displayed",
      "table",
      "under",
      "tab.",
      "display",
      "depends",
      "permissions",
      "assigned",
      "role.",
      "contact",
      "administrator",
      "help",
      "permissions.",
      "role",
      "permission",
      "granted",
      "ll",
      "able",
      "details.",
      "manage",
      "schedules.",
      "table.",
      "click",
      "column",
      "header",
      "sort",
      "column.",
      "menu",
      "bar",
      "following",
      "action",
      "description",
      "add",
      "new",
      "schedule.",
      "select",
      "edit.",
      "delete",
      "one",
      "delete.",
      "enable",
      "disabled",
      "them.",
      "disable",
      "refresh",
      "search",
      "keywords.",
      "filter",
      "based",
      "state",
      "next",
      "previous",
      "run.",
      "filters",
      "added",
      "filter.",
      "columns",
      "deselect",
      "name",
      "identifier",
      "user.",
      "before",
      "make",
      "sure",
      "logged",
      "user",
      "account",
      "tab"
    ],
    "language": "en",
    "word_count": 96,
    "importance_score": 5.5,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "schedule oo flows",
    "contentLower": "this topic contains the instructions to schedule oo flows. overview oo scheduler allows you to control when to run your flows. you can specify a schedule to run for a specific flow and also set up recurring schedules for a task. for example, to check for the number of servers that are online, define a flow to check the ip address and then create a schedule to run that flow. view scheduler the schedules are displayed in a table under the scheduler tab. the display of schedules depends on the permissions assigned for your role. contact your administrator for help with permissions. if you your role has the view schedules permission granted, then you'll be able to view the oo schedules and their details. if you your role has the manage schedules permission granted, then you'll be able to view and edit schedules. scheduler actions the schedules display in a table. click on the column header in the table to sort the schedules by that column. the menu bar has the following actions: action des",
    "keywordsLower": [
      "schedule",
      "oo",
      "flows",
      "overview",
      "view",
      "scheduler",
      "actions",
      "create",
      "edit",
      "topic",
      "contains",
      "instructions",
      "flows.",
      "allows",
      "control",
      "run",
      "specify",
      "specific",
      "flow",
      "set",
      "recurring",
      "schedules",
      "task.",
      "example",
      "check",
      "number",
      "servers",
      "online",
      "define",
      "ip",
      "address",
      "flow.",
      "displayed",
      "table",
      "under",
      "tab.",
      "display",
      "depends",
      "permissions",
      "assigned",
      "role.",
      "contact",
      "administrator",
      "help",
      "permissions.",
      "role",
      "permission",
      "granted",
      "ll",
      "able",
      "details.",
      "manage",
      "schedules.",
      "table.",
      "click",
      "column",
      "header",
      "sort",
      "column.",
      "menu",
      "bar",
      "following",
      "action",
      "description",
      "add",
      "new",
      "schedule.",
      "select",
      "edit.",
      "delete",
      "one",
      "delete.",
      "enable",
      "disabled",
      "them.",
      "disable",
      "refresh",
      "search",
      "keywords.",
      "filter",
      "based",
      "state",
      "next",
      "previous",
      "run.",
      "filters",
      "added",
      "filter.",
      "columns",
      "deselect",
      "name",
      "identifier",
      "user.",
      "before",
      "make",
      "sure",
      "logged",
      "user",
      "account",
      "tab"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Security and hardening",
    "content": "This section provides information on security models and recommendations for a secure implementation of OO Workflow Designer. This includes subjects such as authentication, authorization, encryption, and more. Security concepts Secure implementation and deployment Secure installation guidelines Network and communication security User management and authentication Backup OO Workflow Designer data Encryption in OO Workflow Designer Security questions and answers Hardening OO Workflow Designer",
    "url": "securehardendesigner",
    "filename": "securehardendesigner",
    "headings": [],
    "keywords": [
      "security",
      "hardening",
      "section",
      "provides",
      "information",
      "models",
      "recommendations",
      "secure",
      "implementation",
      "oo",
      "workflow",
      "designer.",
      "includes",
      "subjects",
      "such",
      "authentication",
      "authorization",
      "encryption",
      "more.",
      "concepts",
      "deployment",
      "installation",
      "guidelines",
      "network",
      "communication",
      "user",
      "management",
      "backup",
      "designer",
      "data",
      "questions",
      "answers"
    ],
    "language": "en",
    "word_count": 50,
    "importance_score": 2.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "security and hardening",
    "contentLower": "this section provides information on security models and recommendations for a secure implementation of oo workflow designer. this includes subjects such as authentication, authorization, encryption, and more. security concepts secure implementation and deployment secure installation guidelines network and communication security user management and authentication backup oo workflow designer data encryption in oo workflow designer security questions and answers hardening oo workflow designer",
    "keywordsLower": [
      "security",
      "hardening",
      "section",
      "provides",
      "information",
      "models",
      "recommendations",
      "secure",
      "implementation",
      "oo",
      "workflow",
      "designer.",
      "includes",
      "subjects",
      "such",
      "authentication",
      "authorization",
      "encryption",
      "more.",
      "concepts",
      "deployment",
      "installation",
      "guidelines",
      "network",
      "communication",
      "user",
      "management",
      "backup",
      "designer",
      "data",
      "questions",
      "answers"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Security concepts",
    "content": "Before securing the OO Workflow Designer application, it is recommended to go through the following table to understand terminologies: Term Description User A user is an object associated with a person (or application identity) representing the person and defining their authorization. OO Workflow Designer users are authenticated via LW-SSO (Lightweight Single Sign On). This is a mechanism in which a single action of user authentication and authorization can permit a user to access all systems that support LW-SSO. For example, if users have logged onto another product web client that has LWSSO enabled, they can enter the OO Workflow Designer application directly, bypassing the OO Workflow Designer logon screen. System Security The processes and mechanisms by which computer-based equipment, information, and services are protected from unintended or unauthorized access, change, or damage. Authentication The process of identifying an individual, usually based on a user name and password, o",
    "url": "securityconceptsdesigner",
    "filename": "securityconceptsdesigner",
    "headings": [],
    "keywords": [
      "security",
      "concepts",
      "before",
      "securing",
      "oo",
      "workflow",
      "designer",
      "application",
      "recommended",
      "go",
      "through",
      "following",
      "table",
      "understand",
      "terminologies",
      "term",
      "description",
      "user",
      "object",
      "associated",
      "person",
      "identity",
      "representing",
      "defining",
      "authorization.",
      "users",
      "authenticated",
      "via",
      "lw-sso",
      "lightweight",
      "single",
      "sign",
      "mechanism",
      "action",
      "authentication",
      "authorization",
      "permit",
      "access",
      "all",
      "systems",
      "support",
      "lw-sso.",
      "example",
      "logged",
      "onto",
      "another",
      "product",
      "web",
      "client",
      "lwsso",
      "enabled",
      "enter",
      "directly",
      "bypassing",
      "logon",
      "screen.",
      "system",
      "processes",
      "mechanisms",
      "computer-based",
      "equipment",
      "information",
      "services",
      "protected",
      "unintended",
      "unauthorized",
      "change",
      "damage.",
      "process",
      "identifying",
      "individual",
      "usually",
      "based",
      "name",
      "password",
      "certificate.",
      "encryption",
      "way",
      "enhance",
      "message",
      "file",
      "scrambling",
      "contents",
      "read",
      "someone",
      "right",
      "key",
      "encode",
      "it.",
      "tls",
      "protocol",
      "encrypts",
      "communication",
      "data."
    ],
    "language": "en",
    "word_count": 97,
    "importance_score": 3.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "security concepts",
    "contentLower": "before securing the oo workflow designer application, it is recommended to go through the following table to understand terminologies: term description user a user is an object associated with a person (or application identity) representing the person and defining their authorization. oo workflow designer users are authenticated via lw-sso (lightweight single sign on). this is a mechanism in which a single action of user authentication and authorization can permit a user to access all systems that support lw-sso. for example, if users have logged onto another product web client that has lwsso enabled, they can enter the oo workflow designer application directly, bypassing the oo workflow designer logon screen. system security the processes and mechanisms by which computer-based equipment, information, and services are protected from unintended or unauthorized access, change, or damage. authentication the process of identifying an individual, usually based on a user name and password, o",
    "keywordsLower": [
      "security",
      "concepts",
      "before",
      "securing",
      "oo",
      "workflow",
      "designer",
      "application",
      "recommended",
      "go",
      "through",
      "following",
      "table",
      "understand",
      "terminologies",
      "term",
      "description",
      "user",
      "object",
      "associated",
      "person",
      "identity",
      "representing",
      "defining",
      "authorization.",
      "users",
      "authenticated",
      "via",
      "lw-sso",
      "lightweight",
      "single",
      "sign",
      "mechanism",
      "action",
      "authentication",
      "authorization",
      "permit",
      "access",
      "all",
      "systems",
      "support",
      "lw-sso.",
      "example",
      "logged",
      "onto",
      "another",
      "product",
      "web",
      "client",
      "lwsso",
      "enabled",
      "enter",
      "directly",
      "bypassing",
      "logon",
      "screen.",
      "system",
      "processes",
      "mechanisms",
      "computer-based",
      "equipment",
      "information",
      "services",
      "protected",
      "unintended",
      "unauthorized",
      "change",
      "damage.",
      "process",
      "identifying",
      "individual",
      "usually",
      "based",
      "name",
      "password",
      "certificate.",
      "encryption",
      "way",
      "enhance",
      "message",
      "file",
      "scrambling",
      "contents",
      "read",
      "someone",
      "right",
      "key",
      "encode",
      "it.",
      "tls",
      "protocol",
      "encrypts",
      "communication",
      "data."
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Secure implementation and deployment",
    "content": "Physical security It is recommended that the OO Workflow Designer is protected by physical security controls defined by your organization. The OO Workflow Designer server components are installed in a physically secured environment, according to best practice. For example, the server must be in a closed room with access control. Related topics Secure installation guidelines",
    "url": "securedepldesigner",
    "filename": "securedepldesigner",
    "headings": [
      "Physical security",
      "Related topics"
    ],
    "keywords": [
      "secure",
      "implementation",
      "deployment",
      "physical",
      "security",
      "related",
      "topics",
      "recommended",
      "oo",
      "workflow",
      "designer",
      "protected",
      "controls",
      "defined",
      "organization.",
      "server",
      "components",
      "installed",
      "physically",
      "secured",
      "environment",
      "according",
      "best",
      "practice.",
      "example",
      "closed",
      "room",
      "access",
      "control.",
      "installation",
      "guidelines"
    ],
    "language": "en",
    "word_count": 38,
    "importance_score": 3.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "secure implementation and deployment",
    "contentLower": "physical security it is recommended that the oo workflow designer is protected by physical security controls defined by your organization. the oo workflow designer server components are installed in a physically secured environment, according to best practice. for example, the server must be in a closed room with access control. related topics secure installation guidelines",
    "keywordsLower": [
      "secure",
      "implementation",
      "deployment",
      "physical",
      "security",
      "related",
      "topics",
      "recommended",
      "oo",
      "workflow",
      "designer",
      "protected",
      "controls",
      "defined",
      "organization.",
      "server",
      "components",
      "installed",
      "physically",
      "secured",
      "environment",
      "according",
      "best",
      "practice.",
      "example",
      "closed",
      "room",
      "access",
      "control.",
      "installation",
      "guidelines"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Secure installation guidelines",
    "content": "Supported operating systems For the types and versions of supported operating systems, see the \"System requirements\" section of OO Workflow Designer Install section. Operating system hardening recommendations Contact your operating system vendor for recommended best practices for hardening your operating system. For example: Patches should be installed Unnecessary services/software should be removed or disabled Minimal permissions should be assigned to users Auditing should be enabled Recommended: Put up a firewall to protect against DDoS. Tomcat hardening When you install OO Workflow Designer, Tomcat is partially hardened by default. If you want extra hardening, see the recommendations in the Hardening chapter. Installation permissions The following permissions are required to install and run OO Workflow Designer: Installing OO Workflow Designer Windows/Linux: Any standard user who is able to run a Java process, and who has permission to create folders and services Running OO Workflow",
    "url": "installationsecuritydesigner",
    "filename": "installationsecuritydesigner",
    "headings": [
      "Supported operating systems",
      "Operating system hardening recommendations",
      "Tomcat hardening",
      "Installation permissions",
      "Security protection in OO Workflow Designer",
      "CSRF protection",
      "XSS protection",
      "Clickjacking protection",
      "Related topics"
    ],
    "keywords": [
      "https://www.owasp.org/index.php/Cross-site_Scripting_(XSS",
      "https://www.owasp.org/index.php/Cross-Site_Request_Forgery_(CSRF",
      "owasp.org",
      "https://www.owasp.org/index.php/Clickjacking",
      "index.php",
      "secure",
      "installation",
      "guidelines",
      "supported",
      "operating",
      "systems",
      "system",
      "hardening",
      "recommendations",
      "tomcat",
      "permissions",
      "security",
      "protection",
      "oo",
      "workflow",
      "designer",
      "csrf",
      "xss",
      "clickjacking",
      "related",
      "topics",
      "types",
      "versions",
      "see",
      "requirements",
      "section",
      "install",
      "section.",
      "contact",
      "vendor",
      "recommended",
      "best",
      "practices",
      "system.",
      "example",
      "patches",
      "installed",
      "unnecessary",
      "services",
      "software",
      "removed",
      "disabled",
      "minimal",
      "assigned",
      "users",
      "auditing",
      "enabled",
      "put",
      "firewall",
      "protect",
      "against",
      "ddos.",
      "partially",
      "hardened",
      "default.",
      "want",
      "extra",
      "chapter.",
      "following",
      "required",
      "run",
      "installing",
      "windows",
      "linux",
      "any",
      "standard",
      "user",
      "able",
      "java",
      "process",
      "permission",
      "create",
      "folders",
      "running",
      "service",
      "runs",
      "specific",
      "access",
      "directory",
      "note",
      "cis",
      "apache",
      "documentation.",
      "features",
      "designed",
      "installation.",
      "protected",
      "cross-site",
      "request",
      "forgery",
      "attack",
      "malicious",
      "web",
      "site",
      "email"
    ],
    "language": "en",
    "word_count": 101,
    "importance_score": 6.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "secure installation guidelines",
    "contentLower": "supported operating systems for the types and versions of supported operating systems, see the \"system requirements\" section of oo workflow designer install section. operating system hardening recommendations contact your operating system vendor for recommended best practices for hardening your operating system. for example: patches should be installed unnecessary services/software should be removed or disabled minimal permissions should be assigned to users auditing should be enabled recommended: put up a firewall to protect against ddos. tomcat hardening when you install oo workflow designer, tomcat is partially hardened by default. if you want extra hardening, see the recommendations in the hardening chapter. installation permissions the following permissions are required to install and run oo workflow designer: installing oo workflow designer windows/linux: any standard user who is able to run a java process, and who has permission to create folders and services running oo workflow",
    "keywordsLower": [
      "https://www.owasp.org/index.php/cross-site_scripting_(xss",
      "https://www.owasp.org/index.php/cross-site_request_forgery_(csrf",
      "owasp.org",
      "https://www.owasp.org/index.php/clickjacking",
      "index.php",
      "secure",
      "installation",
      "guidelines",
      "supported",
      "operating",
      "systems",
      "system",
      "hardening",
      "recommendations",
      "tomcat",
      "permissions",
      "security",
      "protection",
      "oo",
      "workflow",
      "designer",
      "csrf",
      "xss",
      "clickjacking",
      "related",
      "topics",
      "types",
      "versions",
      "see",
      "requirements",
      "section",
      "install",
      "section.",
      "contact",
      "vendor",
      "recommended",
      "best",
      "practices",
      "system.",
      "example",
      "patches",
      "installed",
      "unnecessary",
      "services",
      "software",
      "removed",
      "disabled",
      "minimal",
      "assigned",
      "users",
      "auditing",
      "enabled",
      "put",
      "firewall",
      "protect",
      "against",
      "ddos.",
      "partially",
      "hardened",
      "default.",
      "want",
      "extra",
      "chapter.",
      "following",
      "required",
      "run",
      "installing",
      "windows",
      "linux",
      "any",
      "standard",
      "user",
      "able",
      "java",
      "process",
      "permission",
      "create",
      "folders",
      "running",
      "service",
      "runs",
      "specific",
      "access",
      "directory",
      "note",
      "cis",
      "apache",
      "documentation.",
      "features",
      "designed",
      "installation.",
      "protected",
      "cross-site",
      "request",
      "forgery",
      "attack",
      "malicious",
      "web",
      "site",
      "email"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Security questions and answers",
    "content": "How can I generate a certificate request that can be signed by an external CA? Export the certificate request and send it to the external CA for signing. Which TCP/UDP ports does OO Workflow Designer use? What is the direction, user, and encryption? When you install OO Workflow Designer, you need to configure at least one available port for the OO Workflow Designer Server in the HTTP/HTTPS fields. The default provided values are 8080 and 8443, but you can change these. For more information about secure channels between OO Workflow Designer and the other components, see \"Network and communication security\" topic. How do I configure self-signed SSL certificates for OO Workflow Designer? During the installation of OO Workflow Designer, if you do not provide a certificate, a self-signed certificate is created by default. However, for security reasons, it is not recommended to use self-signed certificates. It's recommended to work with a certificate from a custom-root CA or from a well-know",
    "url": "securityqadesigner",
    "filename": "securityqadesigner",
    "headings": [
      "Related topics"
    ],
    "keywords": [
      "security",
      "questions",
      "answers",
      "related",
      "topics",
      "generate",
      "certificate",
      "request",
      "signed",
      "external",
      "ca",
      "export",
      "send",
      "signing.",
      "tcp",
      "udp",
      "ports",
      "oo",
      "workflow",
      "designer",
      "what",
      "direction",
      "user",
      "encryption",
      "install",
      "need",
      "configure",
      "least",
      "one",
      "available",
      "port",
      "server",
      "http",
      "https",
      "fields.",
      "default",
      "provided",
      "values",
      "8080",
      "8443",
      "change",
      "these.",
      "information",
      "about",
      "secure",
      "channels",
      "between",
      "components",
      "see",
      "network",
      "communication",
      "topic.",
      "self-signed",
      "ssl",
      "certificates",
      "during",
      "installation",
      "provide",
      "created",
      "default.",
      "however",
      "reasons",
      "recommended",
      "certificates.",
      "work",
      "custom-root",
      "well-known",
      "ca.",
      "detailed",
      "logs",
      "amount",
      "logging",
      "set",
      "different",
      "levels",
      "granularity.",
      "level",
      "info",
      "adjust",
      "this.",
      "sensitive",
      "encrypted",
      "topic",
      "answers.",
      "authentication",
      "mechanism",
      "support",
      "supports",
      "idm",
      "authentication.",
      "limit",
      "ip",
      "address",
      "supported",
      "moment.",
      "log",
      "files",
      "management"
    ],
    "language": "en",
    "word_count": 95,
    "importance_score": 3.5,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "security questions and answers",
    "contentLower": "how can i generate a certificate request that can be signed by an external ca? export the certificate request and send it to the external ca for signing. which tcp/udp ports does oo workflow designer use? what is the direction, user, and encryption? when you install oo workflow designer, you need to configure at least one available port for the oo workflow designer server in the http/https fields. the default provided values are 8080 and 8443, but you can change these. for more information about secure channels between oo workflow designer and the other components, see \"network and communication security\" topic. how do i configure self-signed ssl certificates for oo workflow designer? during the installation of oo workflow designer, if you do not provide a certificate, a self-signed certificate is created by default. however, for security reasons, it is not recommended to use self-signed certificates. it's recommended to work with a certificate from a custom-root ca or from a well-know",
    "keywordsLower": [
      "security",
      "questions",
      "answers",
      "related",
      "topics",
      "generate",
      "certificate",
      "request",
      "signed",
      "external",
      "ca",
      "export",
      "send",
      "signing.",
      "tcp",
      "udp",
      "ports",
      "oo",
      "workflow",
      "designer",
      "what",
      "direction",
      "user",
      "encryption",
      "install",
      "need",
      "configure",
      "least",
      "one",
      "available",
      "port",
      "server",
      "http",
      "https",
      "fields.",
      "default",
      "provided",
      "values",
      "8080",
      "8443",
      "change",
      "these.",
      "information",
      "about",
      "secure",
      "channels",
      "between",
      "components",
      "see",
      "network",
      "communication",
      "topic.",
      "self-signed",
      "ssl",
      "certificates",
      "during",
      "installation",
      "provide",
      "created",
      "default.",
      "however",
      "reasons",
      "recommended",
      "certificates.",
      "work",
      "custom-root",
      "well-known",
      "ca.",
      "detailed",
      "logs",
      "amount",
      "logging",
      "set",
      "different",
      "levels",
      "granularity.",
      "level",
      "info",
      "adjust",
      "this.",
      "sensitive",
      "encrypted",
      "topic",
      "answers.",
      "authentication",
      "mechanism",
      "support",
      "supports",
      "idm",
      "authentication.",
      "limit",
      "ip",
      "address",
      "supported",
      "moment.",
      "log",
      "files",
      "management"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Security hardening recommendations",
    "content": "This topic provides the recommended steps for security hardening of OO Workflow Designer. Install OO Workflow Designer. (Optional) Configure OO Workflow Designer for FIPS 140-2 Compliance. Configure the OO Workflow Designer server certificate for TLS encryption and client certificate for strong authentication (mutual), which can be done during installation. Harden the OO Workflow Designer server by removing the HTTP port and replacing the passwords of the KeyStore and TrustStore with strong passwords. Remove the RC4 cipher from the SSL-supported ciphers. Harden/secure the operating system and database. In the Windows and SQL server environment, configure OO Workflow Designer to work with Windows authentication. Default security settings In many cases, it is recommended to modify the default security settings that are provided out-of-the-box. Authentication – OO Workflow Designer uses IDM service for authentication. TLS Encryption – By default, OO Workflow Designer supports TLS protocol",
    "url": "hardeningrecommendationsdesigner",
    "filename": "hardeningrecommendationsdesigner",
    "headings": [
      "Default security settings"
    ],
    "keywords": [
      "1.3",
      "security",
      "hardening",
      "recommendations",
      "default",
      "settings",
      "topic",
      "provides",
      "recommended",
      "steps",
      "oo",
      "workflow",
      "designer.",
      "install",
      "optional",
      "configure",
      "designer",
      "fips",
      "140-2",
      "compliance.",
      "server",
      "certificate",
      "tls",
      "encryption",
      "client",
      "strong",
      "authentication",
      "mutual",
      "done",
      "during",
      "installation.",
      "harden",
      "removing",
      "http",
      "port",
      "replacing",
      "passwords",
      "keystore",
      "truststore",
      "passwords.",
      "remove",
      "rc4",
      "cipher",
      "ssl-supported",
      "ciphers.",
      "secure",
      "operating",
      "system",
      "database.",
      "windows",
      "sql",
      "environment",
      "work",
      "authentication.",
      "many",
      "cases",
      "modify",
      "provided",
      "out-of-the-box.",
      "uses",
      "idm",
      "service",
      "supports",
      "protocol",
      "1.3.",
      "user",
      "asked",
      "provide",
      "ca",
      "installation",
      "server.",
      "java",
      "certificate.",
      "replace",
      "encrypted"
    ],
    "language": "en",
    "word_count": 104,
    "importance_score": 3.5,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "security hardening recommendations",
    "contentLower": "this topic provides the recommended steps for security hardening of oo workflow designer. install oo workflow designer. (optional) configure oo workflow designer for fips 140-2 compliance. configure the oo workflow designer server certificate for tls encryption and client certificate for strong authentication (mutual), which can be done during installation. harden the oo workflow designer server by removing the http port and replacing the passwords of the keystore and truststore with strong passwords. remove the rc4 cipher from the ssl-supported ciphers. harden/secure the operating system and database. in the windows and sql server environment, configure oo workflow designer to work with windows authentication. default security settings in many cases, it is recommended to modify the default security settings that are provided out-of-the-box. authentication – oo workflow designer uses idm service for authentication. tls encryption – by default, oo workflow designer supports tls protocol",
    "keywordsLower": [
      "1.3",
      "security",
      "hardening",
      "recommendations",
      "default",
      "settings",
      "topic",
      "provides",
      "recommended",
      "steps",
      "oo",
      "workflow",
      "designer.",
      "install",
      "optional",
      "configure",
      "designer",
      "fips",
      "140-2",
      "compliance.",
      "server",
      "certificate",
      "tls",
      "encryption",
      "client",
      "strong",
      "authentication",
      "mutual",
      "done",
      "during",
      "installation.",
      "harden",
      "removing",
      "http",
      "port",
      "replacing",
      "passwords",
      "keystore",
      "truststore",
      "passwords.",
      "remove",
      "rc4",
      "cipher",
      "ssl-supported",
      "ciphers.",
      "secure",
      "operating",
      "system",
      "database.",
      "windows",
      "sql",
      "environment",
      "work",
      "authentication.",
      "many",
      "cases",
      "modify",
      "provided",
      "out-of-the-box.",
      "uses",
      "idm",
      "service",
      "supports",
      "protocol",
      "1.3.",
      "user",
      "asked",
      "provide",
      "ca",
      "installation",
      "server.",
      "java",
      "certificate.",
      "replace",
      "encrypted"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "TLS support for OO Workflow Designer",
    "content": "OO Workflow Designer includes support for TLS 1.3 protocol. This support is automatically enabled for newly installed and upgraded OO Workflow Designer services. The following TLS configuration is available in the conf/designer-wrapper.conf file: wrapper.java.additional.46=-Djdk.tls.client.protocols=\"TLSv1.3,TLSv1.2\" wrapper.java.additional.47=-Dtls.client.ciphers=\"TLS_AES_256_GCM_SHA384,TLS_AES_128_GCM_SHA256,TLS_AES_128_CCM_8_SHA256,TLS_AES_128_CCM_SHA256,TLS_CHACHA20_POLY1305_SHA256,TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_DHE_RSA_WITH_AES_128_GCM_SHA256,TLS_DHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305_SHA256,TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305_SHA256\" The jdk.tls.client.protocols JVM argument is used to set which versions of the TLS protocol are enabled on the client side. The default version is TLS 1.3 with a fallback to TLS 1.2. Possibl",
    "url": "tlssupportdesigner",
    "filename": "tlssupportdesigner",
    "headings": [],
    "keywords": [
      "Djdk.tls",
      "jdk.tls",
      "1.3",
      "additional.47",
      "wrapper.conf",
      "1.2",
      "additional.46",
      "wrapper.java",
      "tls",
      "support",
      "oo",
      "workflow",
      "designer",
      "includes",
      "protocol.",
      "automatically",
      "enabled",
      "newly",
      "installed",
      "upgraded",
      "services.",
      "following",
      "configuration",
      "available",
      "conf",
      "designer-wrapper.conf",
      "file",
      "wrapper.java.additional.46",
      "-djdk.tls.client.protocols",
      "tlsv1.3",
      "tlsv1.2",
      "wrapper.java.additional.47",
      "-dtls.client.ciphers",
      "jdk.tls.client.protocols",
      "jvm",
      "argument",
      "set",
      "versions",
      "protocol",
      "client",
      "side.",
      "default",
      "version",
      "fallback",
      "1.2.",
      "possible",
      "values",
      "both",
      "tls.client.ciphers",
      "list",
      "cipher",
      "suites",
      "parameter",
      "defined",
      "comma",
      "separated",
      "ciphers.",
      "want",
      "change",
      "edit",
      "file.",
      "stop",
      "designer.",
      "navigate",
      "directory.",
      "operations",
      "orchestration",
      "modifying",
      "parameters.",
      "start"
    ],
    "language": "en",
    "word_count": 67,
    "importance_score": 1.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "tls support for oo workflow designer",
    "contentLower": "oo workflow designer includes support for tls 1.3 protocol. this support is automatically enabled for newly installed and upgraded oo workflow designer services. the following tls configuration is available in the conf/designer-wrapper.conf file: wrapper.java.additional.46=-djdk.tls.client.protocols=\"tlsv1.3,tlsv1.2\" wrapper.java.additional.47=-dtls.client.ciphers=\"tls_aes_256_gcm_sha384,tls_aes_128_gcm_sha256,tls_aes_128_ccm_8_sha256,tls_aes_128_ccm_sha256,tls_chacha20_poly1305_sha256,tls_ecdhe_ecdsa_with_aes_128_gcm_sha256,tls_ecdhe_ecdsa_with_aes_256_gcm_sha384,tls_ecdhe_rsa_with_aes_128_gcm_sha256,tls_ecdhe_rsa_with_aes_256_gcm_sha384,tls_dhe_rsa_with_aes_128_gcm_sha256,tls_dhe_rsa_with_aes_256_gcm_sha384,tls_ecdhe_ecdsa_with_chacha20_poly1305_sha256,tls_ecdhe_rsa_with_chacha20_poly1305_sha256\" the jdk.tls.client.protocols jvm argument is used to set which versions of the tls protocol are enabled on the client side. the default version is tls 1.3 with a fallback to tls 1.2. possibl",
    "keywordsLower": [
      "djdk.tls",
      "jdk.tls",
      "1.3",
      "additional.47",
      "wrapper.conf",
      "1.2",
      "additional.46",
      "wrapper.java",
      "tls",
      "support",
      "oo",
      "workflow",
      "designer",
      "includes",
      "protocol.",
      "automatically",
      "enabled",
      "newly",
      "installed",
      "upgraded",
      "services.",
      "following",
      "configuration",
      "available",
      "conf",
      "designer-wrapper.conf",
      "file",
      "wrapper.java.additional.46",
      "-djdk.tls.client.protocols",
      "tlsv1.3",
      "tlsv1.2",
      "wrapper.java.additional.47",
      "-dtls.client.ciphers",
      "jdk.tls.client.protocols",
      "jvm",
      "argument",
      "set",
      "versions",
      "protocol",
      "client",
      "side.",
      "default",
      "version",
      "fallback",
      "1.2.",
      "possible",
      "values",
      "both",
      "tls.client.ciphers",
      "list",
      "cipher",
      "suites",
      "parameter",
      "defined",
      "comma",
      "separated",
      "ciphers.",
      "want",
      "change",
      "edit",
      "file.",
      "stop",
      "designer.",
      "navigate",
      "directory.",
      "operations",
      "orchestration",
      "modifying",
      "parameters.",
      "start"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "TLS support for External RAS",
    "content": "External RAS includes support for TLS 1.3 protocol. This support is automatically enabled for newly installed and upgraded External RAS services. The following TLS configuration is available in the conf/ras-wrapper.conf file: wrapper.java.additional.48=-Djdk.tls.client.protocols=\"TLSv1.3,TLSv1.2\" wrapper.java.additional.49=-Dtls.client.ciphers=\"TLS_AES_256_GCM_SHA384,TLS_AES_128_GCM_SHA256,TLS_AES_128_CCM_8_SHA256,TLS_AES_128_CCM_SHA256,TLS_CHACHA20_POLY1305_SHA256,TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_DHE_RSA_WITH_AES_128_GCM_SHA256,TLS_DHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305_SHA256,TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305_SHA256\" The jdk.tls.client.protocols JVM argument is used to set which versions of the TLS protocol are enabled on the client side. The default version is TLS 1.3 with a fallback to TLS 1.2. Possible values: \"TLSv1.3,TL",
    "url": "tlssupport",
    "filename": "tlssupport",
    "headings": [],
    "keywords": [
      "additional.48",
      "Djdk.tls",
      "additional.49",
      "jdk.tls",
      "1.3",
      "wrapper.conf",
      "1.2",
      "wrapper.java",
      "tls",
      "support",
      "external",
      "ras",
      "includes",
      "protocol.",
      "automatically",
      "enabled",
      "newly",
      "installed",
      "upgraded",
      "services.",
      "following",
      "configuration",
      "available",
      "conf",
      "ras-wrapper.conf",
      "file",
      "wrapper.java.additional.48",
      "-djdk.tls.client.protocols",
      "tlsv1.3",
      "tlsv1.2",
      "wrapper.java.additional.49",
      "-dtls.client.ciphers",
      "jdk.tls.client.protocols",
      "jvm",
      "argument",
      "set",
      "versions",
      "protocol",
      "client",
      "side.",
      "default",
      "version",
      "fallback",
      "1.2.",
      "possible",
      "values",
      "both",
      "tls.client.ciphers",
      "list",
      "cipher",
      "suites",
      "parameter",
      "defined",
      "comma",
      "separated",
      "ciphers.",
      "want",
      "change",
      "edit",
      "file.",
      "stop",
      "service.",
      "navigate",
      "directory.",
      "operations",
      "orchestration.",
      "modifying",
      "parameters.",
      "start"
    ],
    "language": "en",
    "word_count": 67,
    "importance_score": 2.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "tls support for external ras",
    "contentLower": "external ras includes support for tls 1.3 protocol. this support is automatically enabled for newly installed and upgraded external ras services. the following tls configuration is available in the conf/ras-wrapper.conf file: wrapper.java.additional.48=-djdk.tls.client.protocols=\"tlsv1.3,tlsv1.2\" wrapper.java.additional.49=-dtls.client.ciphers=\"tls_aes_256_gcm_sha384,tls_aes_128_gcm_sha256,tls_aes_128_ccm_8_sha256,tls_aes_128_ccm_sha256,tls_chacha20_poly1305_sha256,tls_ecdhe_ecdsa_with_aes_128_gcm_sha256,tls_ecdhe_ecdsa_with_aes_256_gcm_sha384,tls_ecdhe_rsa_with_aes_128_gcm_sha256,tls_ecdhe_rsa_with_aes_256_gcm_sha384,tls_dhe_rsa_with_aes_128_gcm_sha256,tls_dhe_rsa_with_aes_256_gcm_sha384,tls_ecdhe_ecdsa_with_chacha20_poly1305_sha256,tls_ecdhe_rsa_with_chacha20_poly1305_sha256\" the jdk.tls.client.protocols jvm argument is used to set which versions of the tls protocol are enabled on the client side. the default version is tls 1.3 with a fallback to tls 1.2. possible values: \"tlsv1.3,tl",
    "keywordsLower": [
      "additional.48",
      "djdk.tls",
      "additional.49",
      "jdk.tls",
      "1.3",
      "wrapper.conf",
      "1.2",
      "wrapper.java",
      "tls",
      "support",
      "external",
      "ras",
      "includes",
      "protocol.",
      "automatically",
      "enabled",
      "newly",
      "installed",
      "upgraded",
      "services.",
      "following",
      "configuration",
      "available",
      "conf",
      "ras-wrapper.conf",
      "file",
      "wrapper.java.additional.48",
      "-djdk.tls.client.protocols",
      "tlsv1.3",
      "tlsv1.2",
      "wrapper.java.additional.49",
      "-dtls.client.ciphers",
      "jdk.tls.client.protocols",
      "jvm",
      "argument",
      "set",
      "versions",
      "protocol",
      "client",
      "side.",
      "default",
      "version",
      "fallback",
      "1.2.",
      "possible",
      "values",
      "both",
      "tls.client.ciphers",
      "list",
      "cipher",
      "suites",
      "parameter",
      "defined",
      "comma",
      "separated",
      "ciphers.",
      "want",
      "change",
      "edit",
      "file.",
      "stop",
      "service.",
      "navigate",
      "directory.",
      "operations",
      "orchestration.",
      "modifying",
      "parameters.",
      "start"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Review and configure Portal entity filters",
    "content": "Portal entity filters control which records self-service portal users can see in the portal UI for each entity type (record type). To understand how portal entity filters work and how they interact with view permissions and API access, see Portal entity filters. To access the Portal entity filters page, go to Administration > Configuration > Service Portal Settings > Configuration Settings > Portal entity filters. Only tenant admins can add, edit, or delete portal entity filters. The system provides out-of-the-box portal entity filters for the following entity types: Entitlement Product Instance Environment Review these filters and edit them if needed to match your use case. For details, see Out-of-the-box filters and Edit a portal entity filter. Configure additional filters If you want to control visibility for other entity types, such as Company, define portal entity filters for those entity types. For instructions, see Add a portal entity filter. If you want to review sample express",
    "url": "reviewandconfigportalentityfilter",
    "filename": "reviewandconfigportalentityfilter",
    "headings": [
      "Configure additional filters"
    ],
    "keywords": [
      "review",
      "configure",
      "portal",
      "entity",
      "filters",
      "additional",
      "control",
      "records",
      "self-service",
      "users",
      "see",
      "ui",
      "type",
      "record",
      "understand",
      "work",
      "interact",
      "view",
      "permissions",
      "api",
      "access",
      "filters.",
      "page",
      "go",
      "administration",
      "configuration",
      "service",
      "settings",
      "tenant",
      "admins",
      "add",
      "edit",
      "delete",
      "system",
      "provides",
      "out-of-the-box",
      "following",
      "types",
      "entitlement",
      "product",
      "instance",
      "environment",
      "needed",
      "match",
      "case.",
      "details",
      "filter.",
      "want",
      "visibility",
      "such",
      "company",
      "define",
      "types.",
      "instructions",
      "sample",
      "expressions",
      "before",
      "creating",
      "filter",
      "expression",
      "examples.",
      "person",
      "security."
    ],
    "language": "en",
    "word_count": 111,
    "importance_score": 2.5,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "review and configure portal entity filters",
    "contentLower": "portal entity filters control which records self-service portal users can see in the portal ui for each entity type (record type). to understand how portal entity filters work and how they interact with view permissions and api access, see portal entity filters. to access the portal entity filters page, go to administration > configuration > service portal settings > configuration settings > portal entity filters. only tenant admins can add, edit, or delete portal entity filters. the system provides out-of-the-box portal entity filters for the following entity types: entitlement product instance environment review these filters and edit them if needed to match your use case. for details, see out-of-the-box filters and edit a portal entity filter. configure additional filters if you want to control visibility for other entity types, such as company, define portal entity filters for those entity types. for instructions, see add a portal entity filter. if you want to review sample express",
    "keywordsLower": [
      "review",
      "configure",
      "portal",
      "entity",
      "filters",
      "additional",
      "control",
      "records",
      "self-service",
      "users",
      "see",
      "ui",
      "type",
      "record",
      "understand",
      "work",
      "interact",
      "view",
      "permissions",
      "api",
      "access",
      "filters.",
      "page",
      "go",
      "administration",
      "configuration",
      "service",
      "settings",
      "tenant",
      "admins",
      "add",
      "edit",
      "delete",
      "system",
      "provides",
      "out-of-the-box",
      "following",
      "types",
      "entitlement",
      "product",
      "instance",
      "environment",
      "needed",
      "match",
      "case.",
      "details",
      "filter.",
      "want",
      "visibility",
      "such",
      "company",
      "define",
      "types.",
      "instructions",
      "sample",
      "expressions",
      "before",
      "creating",
      "filter",
      "expression",
      "examples.",
      "person",
      "security."
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Service Portal",
    "content": "Service Portal provides one centralized location for all employee issues related to IT. Its easy-to-use interface enables users to independently request and track support and service requests, search for a knowledge article, and browse a service catalog. The portal's sophisticated search capabilities enable users to independently find relevant information. Search results are gathered from multiple sources and can include multimedia-rich articles, relevant services and forms, and targeted support – all displayed in one, user-friendly interface. Category tiles In Service Portal, when a user clicks a category tile, a page is displayed with the following tabbed sections: Featured (hidden by default) - displays news, recommended & popular offerings, and articlesOfferings - displays all offerings that belong to the categoryArticles - displays relevant articles that belong to the categoryNews - displays relevant news that belong to the category The category page also includes an enhanced sear",
    "url": "serviceportal",
    "filename": "serviceportal",
    "headings": [
      "Submit a service request",
      "Copy a request",
      "Submit a smart ticket",
      "Search for information",
      "Request on behalf",
      "Ask friends",
      "Help friends",
      "Suggest idea",
      "View services and assets",
      "Delegate approvals",
      "Chat with the virtual agent",
      "Preferences and Skills",
      "Activate mobile app",
      "Theme settings"
    ],
    "keywords": [
      "request.The",
      "completing.When",
      "Continue.If",
      "icon.If",
      "Assets.You",
      "profile.When",
      "service",
      "portal",
      "submit",
      "request",
      "copy",
      "smart",
      "ticket",
      "search",
      "information",
      "behalf",
      "ask",
      "friends",
      "help",
      "suggest",
      "idea",
      "view",
      "services",
      "assets",
      "delegate",
      "approvals",
      "chat",
      "virtual",
      "agent",
      "preferences",
      "skills",
      "activate",
      "mobile",
      "app",
      "theme",
      "settings",
      "provides",
      "one",
      "centralized",
      "location",
      "all",
      "employee",
      "issues",
      "related",
      "it.",
      "easy-to-use",
      "interface",
      "enables",
      "users",
      "independently",
      "track",
      "support",
      "requests",
      "knowledge",
      "article",
      "browse",
      "catalog.",
      "sophisticated",
      "capabilities",
      "enable",
      "find",
      "relevant",
      "information.",
      "results",
      "gathered",
      "multiple",
      "sources",
      "include",
      "multimedia-rich",
      "articles",
      "forms",
      "targeted",
      "displayed",
      "user-friendly",
      "interface.",
      "category",
      "tiles",
      "user",
      "clicks",
      "tile",
      "page",
      "following",
      "tabbed",
      "sections",
      "featured",
      "hidden",
      "default",
      "displays",
      "news",
      "recommended",
      "popular",
      "offerings",
      "articlesofferings",
      "belong",
      "categoryarticles",
      "categorynews",
      "includes",
      "enhanced",
      "drop-down",
      "option"
    ],
    "language": "en",
    "word_count": 100,
    "importance_score": 6.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "service portal",
    "contentLower": "service portal provides one centralized location for all employee issues related to it. its easy-to-use interface enables users to independently request and track support and service requests, search for a knowledge article, and browse a service catalog. the portal's sophisticated search capabilities enable users to independently find relevant information. search results are gathered from multiple sources and can include multimedia-rich articles, relevant services and forms, and targeted support – all displayed in one, user-friendly interface. category tiles in service portal, when a user clicks a category tile, a page is displayed with the following tabbed sections: featured (hidden by default) - displays news, recommended & popular offerings, and articlesofferings - displays all offerings that belong to the categoryarticles - displays relevant articles that belong to the categorynews - displays relevant news that belong to the category the category page also includes an enhanced sear",
    "keywordsLower": [
      "request.the",
      "completing.when",
      "continue.if",
      "icon.if",
      "assets.you",
      "profile.when",
      "service",
      "portal",
      "submit",
      "request",
      "copy",
      "smart",
      "ticket",
      "search",
      "information",
      "behalf",
      "ask",
      "friends",
      "help",
      "suggest",
      "idea",
      "view",
      "services",
      "assets",
      "delegate",
      "approvals",
      "chat",
      "virtual",
      "agent",
      "preferences",
      "skills",
      "activate",
      "mobile",
      "app",
      "theme",
      "settings",
      "provides",
      "one",
      "centralized",
      "location",
      "all",
      "employee",
      "issues",
      "related",
      "it.",
      "easy-to-use",
      "interface",
      "enables",
      "users",
      "independently",
      "track",
      "support",
      "requests",
      "knowledge",
      "article",
      "browse",
      "catalog.",
      "sophisticated",
      "capabilities",
      "enable",
      "find",
      "relevant",
      "information.",
      "results",
      "gathered",
      "multiple",
      "sources",
      "include",
      "multimedia-rich",
      "articles",
      "forms",
      "targeted",
      "displayed",
      "user-friendly",
      "interface.",
      "category",
      "tiles",
      "user",
      "clicks",
      "tile",
      "page",
      "following",
      "tabbed",
      "sections",
      "featured",
      "hidden",
      "default",
      "displays",
      "news",
      "recommended",
      "popular",
      "offerings",
      "articlesofferings",
      "belong",
      "categoryarticles",
      "categorynews",
      "includes",
      "enhanced",
      "drop-down",
      "option"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Search",
    "content": "You can search in Service Management. Searching lists To find a particular value in a list field, you can enter the beginning of any word in the value you are looking for. All values that have words beginning with the string that you enter are displayed. For example, when editing a service request, to find a particular user in the Requested by field, enter John in the field. All values where the first name, last name, or name values start with John are displayed. For example: David John Smith Smith, John Peters, John Johnson, Andrew For most lists, you can search only by the beginning of the string. For those lists, bel displays Bella, but not Isabella. However, for the following list fields, you can search for a string that begins any word in the list entry. Words can be separated by - (dash), _ (underscore), or / (slash): Person Group Location Category Offering For example, dav displays William David Smith. If the search string contains one of the following special characters, a pref",
    "url": "globalsearch",
    "filename": "globalsearch",
    "headings": [
      "Searching lists",
      "Global search",
      "Enhanced search suggestions",
      "Context based enhanced search suggestions",
      "History based enhanced search suggestions",
      "Enhanced search suggestions example",
      "Related topics"
    ],
    "keywords": [
      "search",
      "searching",
      "lists",
      "global",
      "enhanced",
      "suggestions",
      "context",
      "based",
      "history",
      "example",
      "related",
      "topics",
      "service",
      "management.",
      "find",
      "particular",
      "value",
      "list",
      "field",
      "enter",
      "beginning",
      "any",
      "word",
      "looking",
      "for.",
      "all",
      "values",
      "words",
      "string",
      "displayed.",
      "editing",
      "request",
      "user",
      "requested",
      "john",
      "field.",
      "first",
      "name",
      "last",
      "start",
      "david",
      "smith",
      "peters",
      "johnson",
      "andrew",
      "most",
      "string.",
      "bel",
      "displays",
      "bella",
      "isabella.",
      "however",
      "following",
      "fields",
      "begins",
      "entry.",
      "separated",
      "dash",
      "underscore",
      "slash",
      "person",
      "group",
      "location",
      "category",
      "offering",
      "dav",
      "william",
      "smith.",
      "contains",
      "one",
      "special",
      "characters",
      "prefix",
      "added",
      "return",
      "expected",
      "result.",
      "there",
      "available",
      "assistance",
      "sc1",
      "application",
      "entering",
      "show",
      "value.",
      "instead",
      "need",
      "receive",
      "management",
      "uses",
      "idol",
      "intelligent",
      "data",
      "operating",
      "layer",
      "search.",
      "indexes",
      "new",
      "information",
      "regular"
    ],
    "language": "en",
    "word_count": 103,
    "importance_score": 6.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "search",
    "contentLower": "you can search in service management. searching lists to find a particular value in a list field, you can enter the beginning of any word in the value you are looking for. all values that have words beginning with the string that you enter are displayed. for example, when editing a service request, to find a particular user in the requested by field, enter john in the field. all values where the first name, last name, or name values start with john are displayed. for example: david john smith smith, john peters, john johnson, andrew for most lists, you can search only by the beginning of the string. for those lists, bel displays bella, but not isabella. however, for the following list fields, you can search for a string that begins any word in the list entry. words can be separated by - (dash), _ (underscore), or / (slash): person group location category offering for example, dav displays william david smith. if the search string contains one of the following special characters, a pref",
    "keywordsLower": [
      "search",
      "searching",
      "lists",
      "global",
      "enhanced",
      "suggestions",
      "context",
      "based",
      "history",
      "example",
      "related",
      "topics",
      "service",
      "management.",
      "find",
      "particular",
      "value",
      "list",
      "field",
      "enter",
      "beginning",
      "any",
      "word",
      "looking",
      "for.",
      "all",
      "values",
      "words",
      "string",
      "displayed.",
      "editing",
      "request",
      "user",
      "requested",
      "john",
      "field.",
      "first",
      "name",
      "last",
      "start",
      "david",
      "smith",
      "peters",
      "johnson",
      "andrew",
      "most",
      "string.",
      "bel",
      "displays",
      "bella",
      "isabella.",
      "however",
      "following",
      "fields",
      "begins",
      "entry.",
      "separated",
      "dash",
      "underscore",
      "slash",
      "person",
      "group",
      "location",
      "category",
      "offering",
      "dav",
      "william",
      "smith.",
      "contains",
      "one",
      "special",
      "characters",
      "prefix",
      "added",
      "return",
      "expected",
      "result.",
      "there",
      "available",
      "assistance",
      "sc1",
      "application",
      "entering",
      "show",
      "value.",
      "instead",
      "need",
      "receive",
      "management",
      "uses",
      "idol",
      "intelligent",
      "data",
      "operating",
      "layer",
      "search.",
      "indexes",
      "new",
      "information",
      "regular"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Send records by email",
    "content": "Agent users can send a record to specified users by email. Send a record without attachments by email As an example, use the procedure below to send a request by email: In the agent interface, go to the Request module, select a request from the list, and click More > Send by email. Or, open a request record, and then click More > Send by email on the record detail page. In the To, Cc, and Bcc fields, select the desired recipients. In the Message field, enter your message. Note that for performance and security considerations, the default content type is plain text, not HTML. Even if you enter manual line breaks when entering your message, the email body doesn't contain line breaks. If you're using Outlook, which supports multiple email formats, including HTML and plain text. If the email is written in HTML format and contains the <br> or <p> tags, line breaks will be displayed in the email; however, if it is in plain text, no line breaks will be displayed. To display line breaks in the",
    "url": "sendrcordsbyemail",
    "filename": "sendrcordsbyemail",
    "headings": [
      "Send a record without attachments by email",
      "Send a record with attachments by email"
    ],
    "keywords": [
      "send",
      "records",
      "email",
      "record",
      "attachments",
      "agent",
      "users",
      "specified",
      "email.",
      "example",
      "procedure",
      "below",
      "request",
      "interface",
      "go",
      "module",
      "select",
      "list",
      "click",
      "open",
      "detail",
      "page.",
      "cc",
      "bcc",
      "fields",
      "desired",
      "recipients.",
      "message",
      "field",
      "enter",
      "message.",
      "note",
      "performance",
      "security",
      "considerations",
      "default",
      "content",
      "type",
      "plain",
      "text",
      "html.",
      "even",
      "manual",
      "line",
      "breaks",
      "entering",
      "body",
      "doesn",
      "contain",
      "breaks.",
      "re",
      "outlook",
      "supports",
      "multiple",
      "formats",
      "including",
      "html",
      "text.",
      "written",
      "format",
      "contains",
      "tags",
      "displayed",
      "however",
      "displayed.",
      "display",
      "manually",
      "add",
      "break",
      "follows",
      "aaaa",
      "bbbb",
      "cccc.",
      "effect",
      "there",
      "30kb",
      "limit",
      "size",
      "field.",
      "exceeds",
      "system",
      "won",
      "notification.",
      "optionally",
      "copy",
      "option.",
      "send.",
      "feature",
      "allows",
      "change",
      "purchase",
      "order",
      "incident",
      "together",
      "attachments.",
      "support",
      "sending",
      "through",
      "types.",
      "non-encrypted"
    ],
    "language": "en",
    "word_count": 103,
    "importance_score": 4.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "send records by email",
    "contentLower": "agent users can send a record to specified users by email. send a record without attachments by email as an example, use the procedure below to send a request by email: in the agent interface, go to the request module, select a request from the list, and click more > send by email. or, open a request record, and then click more > send by email on the record detail page. in the to, cc, and bcc fields, select the desired recipients. in the message field, enter your message. note that for performance and security considerations, the default content type is plain text, not html. even if you enter manual line breaks when entering your message, the email body doesn't contain line breaks. if you're using outlook, which supports multiple email formats, including html and plain text. if the email is written in html format and contains the <br> or <p> tags, line breaks will be displayed in the email; however, if it is in plain text, no line breaks will be displayed. to display line breaks in the",
    "keywordsLower": [
      "send",
      "records",
      "email",
      "record",
      "attachments",
      "agent",
      "users",
      "specified",
      "email.",
      "example",
      "procedure",
      "below",
      "request",
      "interface",
      "go",
      "module",
      "select",
      "list",
      "click",
      "open",
      "detail",
      "page.",
      "cc",
      "bcc",
      "fields",
      "desired",
      "recipients.",
      "message",
      "field",
      "enter",
      "message.",
      "note",
      "performance",
      "security",
      "considerations",
      "default",
      "content",
      "type",
      "plain",
      "text",
      "html.",
      "even",
      "manual",
      "line",
      "breaks",
      "entering",
      "body",
      "doesn",
      "contain",
      "breaks.",
      "re",
      "outlook",
      "supports",
      "multiple",
      "formats",
      "including",
      "html",
      "text.",
      "written",
      "format",
      "contains",
      "tags",
      "displayed",
      "however",
      "displayed.",
      "display",
      "manually",
      "add",
      "break",
      "follows",
      "aaaa",
      "bbbb",
      "cccc.",
      "effect",
      "there",
      "30kb",
      "limit",
      "size",
      "field.",
      "exceeds",
      "system",
      "won",
      "notification.",
      "optionally",
      "copy",
      "option.",
      "send.",
      "feature",
      "allows",
      "change",
      "purchase",
      "order",
      "incident",
      "together",
      "attachments.",
      "support",
      "sending",
      "through",
      "types.",
      "non-encrypted"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Tasks queue",
    "content": "The Tasks queue enables you to view and manage manual tasks that are assigned to you, assigned to your groups, as well as tasks that have been completed by you recently. You can access all manual tasks if you have the Ability to view all tasks permission. View your tasks On the main menu, select Tasks. Select a view to view the corresponding tasks. You can select one of the following OOB views, or you can select a custom view. MY TASKS: tasks directly assigned to you. MY GROUP TASKS: tasks assigned to your groups. MY RECENTLY COMPLETED TASKS: tasks assigned to you and completed in the past month. If you have the \"Ability to view all tasks\" permission, the following OOB views are also available: ALL MY TASKS: tasks assigned to you or your groups, and your recently completed tasks. ALL TASKS: all tasks. Note that the tasks displayed for custom views that were created based on the ALL TASKS view differ, depending on whether you have the \"Ability to view all tasks\" permission: If you have ",
    "url": "pltfmtasks",
    "filename": "pltfmtasks",
    "headings": [
      "View your tasks",
      "Manage your tasks",
      "Error handling for automated tasks",
      "Related topics"
    ],
    "keywords": [
      "tasks",
      "queue",
      "view",
      "manage",
      "error",
      "handling",
      "automated",
      "related",
      "topics",
      "enables",
      "manual",
      "assigned",
      "groups",
      "well",
      "completed",
      "recently.",
      "access",
      "all",
      "ability",
      "permission.",
      "main",
      "menu",
      "select",
      "tasks.",
      "corresponding",
      "one",
      "following",
      "oob",
      "views",
      "custom",
      "view.",
      "directly",
      "you.",
      "group",
      "groups.",
      "recently",
      "past",
      "month.",
      "permission",
      "available",
      "note",
      "displayed",
      "created",
      "based",
      "differ",
      "depending",
      "whether",
      "see",
      "match",
      "filter",
      "criteria",
      "associated",
      "don",
      "criteria.",
      "default",
      "grid",
      "displays",
      "information",
      "about",
      "task",
      "id",
      "title",
      "phase",
      "current",
      "priority",
      "requestor",
      "requester",
      "parent",
      "entity",
      "type",
      "record",
      "right",
      "pane",
      "details",
      "top",
      "below",
      "that.",
      "sort",
      "click",
      "heading",
      "column",
      "want",
      "grid.",
      "descending",
      "highest",
      "lowest",
      "priority.",
      "add",
      "button",
      "left.",
      "edit.",
      "list",
      "button.",
      "filters.",
      "identifier",
      "display",
      "selected",
      "record.",
      "edit",
      "general"
    ],
    "language": "en",
    "word_count": 101,
    "importance_score": 5.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "tasks queue",
    "contentLower": "the tasks queue enables you to view and manage manual tasks that are assigned to you, assigned to your groups, as well as tasks that have been completed by you recently. you can access all manual tasks if you have the ability to view all tasks permission. view your tasks on the main menu, select tasks. select a view to view the corresponding tasks. you can select one of the following oob views, or you can select a custom view. my tasks: tasks directly assigned to you. my group tasks: tasks assigned to your groups. my recently completed tasks: tasks assigned to you and completed in the past month. if you have the \"ability to view all tasks\" permission, the following oob views are also available: all my tasks: tasks assigned to you or your groups, and your recently completed tasks. all tasks: all tasks. note that the tasks displayed for custom views that were created based on the all tasks view differ, depending on whether you have the \"ability to view all tasks\" permission: if you have ",
    "keywordsLower": [
      "tasks",
      "queue",
      "view",
      "manage",
      "error",
      "handling",
      "automated",
      "related",
      "topics",
      "enables",
      "manual",
      "assigned",
      "groups",
      "well",
      "completed",
      "recently.",
      "access",
      "all",
      "ability",
      "permission.",
      "main",
      "menu",
      "select",
      "tasks.",
      "corresponding",
      "one",
      "following",
      "oob",
      "views",
      "custom",
      "view.",
      "directly",
      "you.",
      "group",
      "groups.",
      "recently",
      "past",
      "month.",
      "permission",
      "available",
      "note",
      "displayed",
      "created",
      "based",
      "differ",
      "depending",
      "whether",
      "see",
      "match",
      "filter",
      "criteria",
      "associated",
      "don",
      "criteria.",
      "default",
      "grid",
      "displays",
      "information",
      "about",
      "task",
      "id",
      "title",
      "phase",
      "current",
      "priority",
      "requestor",
      "requester",
      "parent",
      "entity",
      "type",
      "record",
      "right",
      "pane",
      "details",
      "top",
      "below",
      "that.",
      "sort",
      "click",
      "heading",
      "column",
      "want",
      "grid.",
      "descending",
      "highest",
      "lowest",
      "priority.",
      "add",
      "button",
      "left.",
      "edit.",
      "list",
      "button.",
      "filters.",
      "identifier",
      "display",
      "selected",
      "record.",
      "edit",
      "general"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Strong identity validation for approvals",
    "content": "Certain task approvals may require strong identity validation as an additional level of security. You will require a passcode, verification code, and authorization code to proceed with the approval for these records. The feature may be enabled by an administrator for all records or for specific records only. Approve a task using strong identity validation Go to the main menu > Approvals. In the Service Portal, open your To do list. Select a pending approval that matches the conditions defined for strong identity validation and click Approve or Deny and then Save. If you already have a passcode, the Strong identity validation dialog prompts you to enter it. If you don't have one, you are prompted to create one. Enter a passcode 10 to 20 characters long containing at least one upper case character, at least one lower case character, and at least one number. Retype the passcode and click Create passcode. The system retains your passcode for one hour while there is user activity. If you co",
    "url": "approvalreauth",
    "filename": "approvalreauth",
    "headings": [
      "Approve a task using strong identity validation",
      "Related topics"
    ],
    "keywords": [
      "strong",
      "identity",
      "validation",
      "approvals",
      "approve",
      "task",
      "related",
      "topics",
      "certain",
      "require",
      "additional",
      "level",
      "security.",
      "passcode",
      "verification",
      "code",
      "authorization",
      "proceed",
      "approval",
      "records.",
      "feature",
      "enabled",
      "administrator",
      "all",
      "records",
      "specific",
      "only.",
      "go",
      "main",
      "menu",
      "approvals.",
      "service",
      "portal",
      "open",
      "list.",
      "select",
      "pending",
      "matches",
      "conditions",
      "defined",
      "click",
      "deny",
      "save.",
      "already",
      "dialog",
      "prompts",
      "enter",
      "it.",
      "don",
      "one",
      "prompted",
      "create",
      "one.",
      "10",
      "20",
      "characters",
      "long",
      "containing",
      "least",
      "upper",
      "case",
      "character",
      "lower",
      "number.",
      "retype",
      "passcode.",
      "system",
      "retains",
      "hour",
      "while",
      "there",
      "user",
      "activity.",
      "continue",
      "working",
      "beyond",
      "period",
      "activity",
      "minutes",
      "re-enter",
      "note",
      "want",
      "change",
      "security",
      "settings",
      "link",
      "profile",
      "page",
      "link.",
      "incorrect",
      "times",
      "locked",
      "15",
      "minutes.",
      "after",
      "next",
      "attempt",
      "30",
      "on.",
      "first"
    ],
    "language": "en",
    "word_count": 107,
    "importance_score": 4.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "strong identity validation for approvals",
    "contentLower": "certain task approvals may require strong identity validation as an additional level of security. you will require a passcode, verification code, and authorization code to proceed with the approval for these records. the feature may be enabled by an administrator for all records or for specific records only. approve a task using strong identity validation go to the main menu > approvals. in the service portal, open your to do list. select a pending approval that matches the conditions defined for strong identity validation and click approve or deny and then save. if you already have a passcode, the strong identity validation dialog prompts you to enter it. if you don't have one, you are prompted to create one. enter a passcode 10 to 20 characters long containing at least one upper case character, at least one lower case character, and at least one number. retype the passcode and click create passcode. the system retains your passcode for one hour while there is user activity. if you co",
    "keywordsLower": [
      "strong",
      "identity",
      "validation",
      "approvals",
      "approve",
      "task",
      "related",
      "topics",
      "certain",
      "require",
      "additional",
      "level",
      "security.",
      "passcode",
      "verification",
      "code",
      "authorization",
      "proceed",
      "approval",
      "records.",
      "feature",
      "enabled",
      "administrator",
      "all",
      "records",
      "specific",
      "only.",
      "go",
      "main",
      "menu",
      "approvals.",
      "service",
      "portal",
      "open",
      "list.",
      "select",
      "pending",
      "matches",
      "conditions",
      "defined",
      "click",
      "deny",
      "save.",
      "already",
      "dialog",
      "prompts",
      "enter",
      "it.",
      "don",
      "one",
      "prompted",
      "create",
      "one.",
      "10",
      "20",
      "characters",
      "long",
      "containing",
      "least",
      "upper",
      "case",
      "character",
      "lower",
      "number.",
      "retype",
      "passcode.",
      "system",
      "retains",
      "hour",
      "while",
      "there",
      "user",
      "activity.",
      "continue",
      "working",
      "beyond",
      "period",
      "activity",
      "minutes",
      "re-enter",
      "note",
      "want",
      "change",
      "security",
      "settings",
      "link",
      "profile",
      "page",
      "link.",
      "incorrect",
      "times",
      "locked",
      "15",
      "minutes.",
      "after",
      "next",
      "attempt",
      "30",
      "on.",
      "first"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Reports",
    "content": "Reports enable you to view the current status of the system. You can view out-of-the-box reports or create your own reports based on record type. You can group or filter the data to display the specific information and data as relevant to your work. You can view the reports in the Reports module or in your Dashboard. Users can create reports with one of these access levels: Private, Group, and Public: A Private report is visible only to the creator. All users can create private reports without the need for any specific permission. A Group report is visible only to the members of specified user groups. Users need the Create group reports role permission to create group reports. A Public report is visible to all users in the current tenant. Users need the Create public reports role permission to create public reports. Notes: The access level of a report applies only to the report definition; the actual data that a report displays to a user still depends on the user's permission to record",
    "url": "report",
    "filename": "report",
    "headings": [
      "Related topics"
    ],
    "keywords": [
      "reports",
      "related",
      "topics",
      "enable",
      "view",
      "current",
      "status",
      "system.",
      "out-of-the-box",
      "create",
      "own",
      "based",
      "record",
      "type.",
      "group",
      "filter",
      "data",
      "display",
      "specific",
      "information",
      "relevant",
      "work.",
      "module",
      "dashboard.",
      "users",
      "one",
      "access",
      "levels",
      "private",
      "public",
      "report",
      "visible",
      "creator.",
      "all",
      "need",
      "any",
      "permission.",
      "members",
      "specified",
      "user",
      "groups.",
      "role",
      "permission",
      "reports.",
      "tenant.",
      "notes",
      "level",
      "applies",
      "definition",
      "actual",
      "displays",
      "still",
      "depends",
      "types",
      "well",
      "domains",
      "domain",
      "segmentation",
      "configured.",
      "words",
      "possible",
      "same",
      "different",
      "users.",
      "granted",
      "administer",
      "actually",
      "playing",
      "administrator",
      "besides",
      "creating",
      "update",
      "delete",
      "created",
      "others",
      "including",
      "ones",
      "maintain",
      "clean",
      "set",
      "tenant",
      "organized",
      "following",
      "categories.",
      "type",
      "description",
      "analytic",
      "reflect",
      "historical",
      "over",
      "time",
      "calculated",
      "according",
      "defined",
      "schedule",
      "limit",
      "grouped",
      "field",
      "properties",
      "supports"
    ],
    "language": "en",
    "word_count": 104,
    "importance_score": 3.5,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "reports",
    "contentLower": "reports enable you to view the current status of the system. you can view out-of-the-box reports or create your own reports based on record type. you can group or filter the data to display the specific information and data as relevant to your work. you can view the reports in the reports module or in your dashboard. users can create reports with one of these access levels: private, group, and public: a private report is visible only to the creator. all users can create private reports without the need for any specific permission. a group report is visible only to the members of specified user groups. users need the create group reports role permission to create group reports. a public report is visible to all users in the current tenant. users need the create public reports role permission to create public reports. notes: the access level of a report applies only to the report definition; the actual data that a report displays to a user still depends on the user's permission to record",
    "keywordsLower": [
      "reports",
      "related",
      "topics",
      "enable",
      "view",
      "current",
      "status",
      "system.",
      "out-of-the-box",
      "create",
      "own",
      "based",
      "record",
      "type.",
      "group",
      "filter",
      "data",
      "display",
      "specific",
      "information",
      "relevant",
      "work.",
      "module",
      "dashboard.",
      "users",
      "one",
      "access",
      "levels",
      "private",
      "public",
      "report",
      "visible",
      "creator.",
      "all",
      "need",
      "any",
      "permission.",
      "members",
      "specified",
      "user",
      "groups.",
      "role",
      "permission",
      "reports.",
      "tenant.",
      "notes",
      "level",
      "applies",
      "definition",
      "actual",
      "displays",
      "still",
      "depends",
      "types",
      "well",
      "domains",
      "domain",
      "segmentation",
      "configured.",
      "words",
      "possible",
      "same",
      "different",
      "users.",
      "granted",
      "administer",
      "actually",
      "playing",
      "administrator",
      "besides",
      "creating",
      "update",
      "delete",
      "created",
      "others",
      "including",
      "ones",
      "maintain",
      "clean",
      "set",
      "tenant",
      "organized",
      "following",
      "categories.",
      "type",
      "description",
      "analytic",
      "reflect",
      "historical",
      "over",
      "time",
      "calculated",
      "according",
      "defined",
      "schedule",
      "limit",
      "grouped",
      "field",
      "properties",
      "supports"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Reports list pane",
    "content": "The Reports list pane, located on the left, displays a list of all existing reports. Reports list user interface The following table describes the user interface elements of the pane: Element Description Report list Select a report in the list to display it in the center pane. The reports in the list are color coded by report record type. For private reports, an icon indicates who created the report: for private reports you created. for private reports created by other users. The list has two sections: Recently viewed. Displays the five most recently viewed reports. All Reports. Displays all existing reports. You can use the Sort by box to sort the list by the following criteria: Report name (alphabetically) Access (Private/Group/Public) State (Active/Inactive) Report type (Analytic/Operational) Note The sort functionality is case-sensitive. For information on view permission for reports, see the Report permissions section. Search window Enter the first few letters of a report name in ",
    "url": "reportslist",
    "filename": "reportslist",
    "headings": [
      "Reports list user interface",
      "Report permissions",
      "Reports and data domain segmentation",
      "Report quota management",
      "How report quota points are calculated",
      "Related topics"
    ],
    "keywords": [
      "reports",
      "list",
      "pane",
      "user",
      "interface",
      "report",
      "permissions",
      "data",
      "domain",
      "segmentation",
      "quota",
      "management",
      "points",
      "calculated",
      "related",
      "topics",
      "located",
      "left",
      "displays",
      "all",
      "existing",
      "reports.",
      "following",
      "table",
      "describes",
      "elements",
      "element",
      "description",
      "select",
      "display",
      "center",
      "pane.",
      "color",
      "coded",
      "record",
      "type.",
      "private",
      "icon",
      "indicates",
      "created",
      "created.",
      "users.",
      "two",
      "sections",
      "recently",
      "viewed.",
      "five",
      "most",
      "viewed",
      "sort",
      "box",
      "criteria",
      "name",
      "alphabetically",
      "access",
      "group",
      "public",
      "state",
      "active",
      "inactive",
      "type",
      "analytic",
      "operational",
      "note",
      "functionality",
      "case-sensitive.",
      "information",
      "view",
      "permission",
      "see",
      "section.",
      "search",
      "window",
      "enter",
      "first",
      "few",
      "letters",
      "report.",
      "matches",
      "beginning",
      "name.",
      "word",
      "new",
      "click",
      "create",
      "creating",
      "work",
      "delete",
      "selected",
      "include",
      "list.",
      "appear",
      "grey",
      "don",
      "selected.",
      "bar",
      "percent",
      "currently",
      "default",
      "there"
    ],
    "language": "en",
    "word_count": 111,
    "importance_score": 6.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "reports list pane",
    "contentLower": "the reports list pane, located on the left, displays a list of all existing reports. reports list user interface the following table describes the user interface elements of the pane: element description report list select a report in the list to display it in the center pane. the reports in the list are color coded by report record type. for private reports, an icon indicates who created the report: for private reports you created. for private reports created by other users. the list has two sections: recently viewed. displays the five most recently viewed reports. all reports. displays all existing reports. you can use the sort by box to sort the list by the following criteria: report name (alphabetically) access (private/group/public) state (active/inactive) report type (analytic/operational) note the sort functionality is case-sensitive. for information on view permission for reports, see the report permissions section. search window enter the first few letters of a report name in ",
    "keywordsLower": [
      "reports",
      "list",
      "pane",
      "user",
      "interface",
      "report",
      "permissions",
      "data",
      "domain",
      "segmentation",
      "quota",
      "management",
      "points",
      "calculated",
      "related",
      "topics",
      "located",
      "left",
      "displays",
      "all",
      "existing",
      "reports.",
      "following",
      "table",
      "describes",
      "elements",
      "element",
      "description",
      "select",
      "display",
      "center",
      "pane.",
      "color",
      "coded",
      "record",
      "type.",
      "private",
      "icon",
      "indicates",
      "created",
      "created.",
      "users.",
      "two",
      "sections",
      "recently",
      "viewed.",
      "five",
      "most",
      "viewed",
      "sort",
      "box",
      "criteria",
      "name",
      "alphabetically",
      "access",
      "group",
      "public",
      "state",
      "active",
      "inactive",
      "type",
      "analytic",
      "operational",
      "note",
      "functionality",
      "case-sensitive.",
      "information",
      "view",
      "permission",
      "see",
      "section.",
      "search",
      "window",
      "enter",
      "first",
      "few",
      "letters",
      "report.",
      "matches",
      "beginning",
      "name.",
      "word",
      "new",
      "click",
      "create",
      "creating",
      "work",
      "delete",
      "selected",
      "include",
      "list.",
      "appear",
      "grey",
      "don",
      "selected.",
      "bar",
      "percent",
      "currently",
      "default",
      "there"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Reports center pane",
    "content": "The Reports center pane displays the report selected in the Reports list. The following options are available. When exporting reports to a CSV or XLS file, the system exports certain fields at a minimum depending on the record type. For most record types, the system exports the ID and Display Label fields at a minimum, and some record types have more minimum fields other than these two. Element Description Duplicate Click Duplicate to create a new report based on an existing one. You can make changes to the new report in the New report dialog box. Both the original report and the new one are saved. When duplicating an analytic or survey report, the new report is defined as active by default, even if the original report is inactive. When duplicating a public report, the duplicated report is private. Export CSV Click Export to export the grid report to a CSV file. Export XLS Click Export to export the grid report to an XLSX file. Export PDF Click Export to export the report to a PDF file",
    "url": "reprtscenterpane",
    "filename": "reprtscenterpane",
    "headings": [
      "Related topics"
    ],
    "keywords": [
      "reports",
      "center",
      "pane",
      "related",
      "topics",
      "displays",
      "report",
      "selected",
      "list.",
      "following",
      "options",
      "available.",
      "exporting",
      "csv",
      "xls",
      "file",
      "system",
      "exports",
      "certain",
      "fields",
      "minimum",
      "depending",
      "record",
      "type.",
      "most",
      "types",
      "id",
      "display",
      "label",
      "two.",
      "element",
      "description",
      "duplicate",
      "click",
      "create",
      "new",
      "based",
      "existing",
      "one.",
      "make",
      "changes",
      "dialog",
      "box.",
      "both",
      "original",
      "one",
      "saved.",
      "duplicating",
      "analytic",
      "survey",
      "defined",
      "active",
      "default",
      "even",
      "inactive.",
      "public",
      "duplicated",
      "private.",
      "export",
      "grid",
      "file.",
      "xlsx",
      "pdf",
      "change",
      "type",
      "report.",
      "isn",
      "operational",
      "analytic.",
      "counted",
      "toward",
      "quota.",
      "operational.",
      "longer",
      "requested",
      "made",
      "due",
      "properties",
      "error",
      "message",
      "relevant",
      "properties.",
      "edit",
      "again.",
      "option",
      "raw",
      "data",
      "reports.",
      "activate",
      "deactivate",
      "deactivate.",
      "quota",
      "inactive",
      "aren",
      "counted.",
      "out-of-the-box",
      "edited",
      "activated",
      "deactivated.",
      "select"
    ],
    "language": "en",
    "word_count": 112,
    "importance_score": 3.5,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "reports center pane",
    "contentLower": "the reports center pane displays the report selected in the reports list. the following options are available. when exporting reports to a csv or xls file, the system exports certain fields at a minimum depending on the record type. for most record types, the system exports the id and display label fields at a minimum, and some record types have more minimum fields other than these two. element description duplicate click duplicate to create a new report based on an existing one. you can make changes to the new report in the new report dialog box. both the original report and the new one are saved. when duplicating an analytic or survey report, the new report is defined as active by default, even if the original report is inactive. when duplicating a public report, the duplicated report is private. export csv click export to export the grid report to a csv file. export xls click export to export the grid report to an xlsx file. export pdf click export to export the report to a pdf file",
    "keywordsLower": [
      "reports",
      "center",
      "pane",
      "related",
      "topics",
      "displays",
      "report",
      "selected",
      "list.",
      "following",
      "options",
      "available.",
      "exporting",
      "csv",
      "xls",
      "file",
      "system",
      "exports",
      "certain",
      "fields",
      "minimum",
      "depending",
      "record",
      "type.",
      "most",
      "types",
      "id",
      "display",
      "label",
      "two.",
      "element",
      "description",
      "duplicate",
      "click",
      "create",
      "new",
      "based",
      "existing",
      "one.",
      "make",
      "changes",
      "dialog",
      "box.",
      "both",
      "original",
      "one",
      "saved.",
      "duplicating",
      "analytic",
      "survey",
      "defined",
      "active",
      "default",
      "even",
      "inactive.",
      "public",
      "duplicated",
      "private.",
      "export",
      "grid",
      "file.",
      "xlsx",
      "pdf",
      "change",
      "type",
      "report.",
      "isn",
      "operational",
      "analytic.",
      "counted",
      "toward",
      "quota.",
      "operational.",
      "longer",
      "requested",
      "made",
      "due",
      "properties",
      "error",
      "message",
      "relevant",
      "properties.",
      "edit",
      "again.",
      "option",
      "raw",
      "data",
      "reports.",
      "activate",
      "deactivate",
      "deactivate.",
      "quota",
      "inactive",
      "aren",
      "counted.",
      "out-of-the-box",
      "edited",
      "activated",
      "deactivated.",
      "select"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Report properties",
    "content": "The Report properties pane, located on the right, defines the properties of the selected report. Data in reports can be filtered and grouped by the attributes of the record on which the report is based. The following tabs are available both for defining a new report in the New report dialog box and for editing an existing report in the Report properties pane. Locked reports (indicated by a lock icon in the Report properties pane) can't be edited. Out-of-the-box reports are locked, but analytic out-of-the-box reports can be activated or deactivated. General tab Field Description Report name Type a word or phrase that's a unique identifier for this report. It should be a value that makes it easy to understand the purpose of the report. Example: All employees by start date. Report name is the field used for matching a search value, not the Display label field. Display label Enter the report title as it will appear in the report. Record type Select a record type on which to base the data i",
    "url": "reportproperties",
    "filename": "reportproperties",
    "headings": [
      "General tab",
      "Chart tab",
      "Details tab",
      "Related topics"
    ],
    "keywords": [
      "report",
      "properties",
      "general",
      "tab",
      "chart",
      "details",
      "related",
      "topics",
      "pane",
      "located",
      "right",
      "defines",
      "selected",
      "report.",
      "data",
      "reports",
      "filtered",
      "grouped",
      "attributes",
      "record",
      "based.",
      "following",
      "tabs",
      "available",
      "both",
      "defining",
      "new",
      "dialog",
      "box",
      "editing",
      "existing",
      "pane.",
      "locked",
      "indicated",
      "lock",
      "icon",
      "edited.",
      "out-of-the-box",
      "analytic",
      "activated",
      "deactivated.",
      "field",
      "description",
      "name",
      "type",
      "word",
      "phrase",
      "unique",
      "identifier",
      "value",
      "makes",
      "easy",
      "understand",
      "purpose",
      "example",
      "all",
      "employees",
      "start",
      "date.",
      "matching",
      "search",
      "display",
      "label",
      "field.",
      "enter",
      "title",
      "appear",
      "select",
      "base",
      "filter",
      "group",
      "fields",
      "determined",
      "selected.",
      "create",
      "based",
      "any",
      "view",
      "permission",
      "data.",
      "records",
      "match",
      "assigned",
      "domains.",
      "survey",
      "called",
      "survey.",
      "drop-down",
      "list.",
      "type.",
      "every",
      "selection.",
      "property",
      "list",
      "filter.",
      "incidents",
      "location",
      "required",
      "locations",
      "one"
    ],
    "language": "en",
    "word_count": 101,
    "importance_score": 5.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "report properties",
    "contentLower": "the report properties pane, located on the right, defines the properties of the selected report. data in reports can be filtered and grouped by the attributes of the record on which the report is based. the following tabs are available both for defining a new report in the new report dialog box and for editing an existing report in the report properties pane. locked reports (indicated by a lock icon in the report properties pane) can't be edited. out-of-the-box reports are locked, but analytic out-of-the-box reports can be activated or deactivated. general tab field description report name type a word or phrase that's a unique identifier for this report. it should be a value that makes it easy to understand the purpose of the report. example: all employees by start date. report name is the field used for matching a search value, not the display label field. display label enter the report title as it will appear in the report. record type select a record type on which to base the data i",
    "keywordsLower": [
      "report",
      "properties",
      "general",
      "tab",
      "chart",
      "details",
      "related",
      "topics",
      "pane",
      "located",
      "right",
      "defines",
      "selected",
      "report.",
      "data",
      "reports",
      "filtered",
      "grouped",
      "attributes",
      "record",
      "based.",
      "following",
      "tabs",
      "available",
      "both",
      "defining",
      "new",
      "dialog",
      "box",
      "editing",
      "existing",
      "pane.",
      "locked",
      "indicated",
      "lock",
      "icon",
      "edited.",
      "out-of-the-box",
      "analytic",
      "activated",
      "deactivated.",
      "field",
      "description",
      "name",
      "type",
      "word",
      "phrase",
      "unique",
      "identifier",
      "value",
      "makes",
      "easy",
      "understand",
      "purpose",
      "example",
      "all",
      "employees",
      "start",
      "date.",
      "matching",
      "search",
      "display",
      "label",
      "field.",
      "enter",
      "title",
      "appear",
      "select",
      "base",
      "filter",
      "group",
      "fields",
      "determined",
      "selected.",
      "create",
      "based",
      "any",
      "view",
      "permission",
      "data.",
      "records",
      "match",
      "assigned",
      "domains.",
      "survey",
      "called",
      "survey.",
      "drop-down",
      "list.",
      "type.",
      "every",
      "selection.",
      "property",
      "list",
      "filter.",
      "incidents",
      "location",
      "required",
      "locations",
      "one"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Scheduled reports",
    "content": "With a preset schedule, SMAX can regularly generate certain reports and send them to a group of recipients through emails. To create/delete a report schedule, click the Schedules tab on the Reports page, and then click New or Delete. Note: To create scheduled reports, an IT agent needs the Define schedule tasks for email reports role permission. The creation or deletion of a schedule is straightforward, the following schedule properties are provided as an example of how a schedule is configured. Name: Daily schedule A Display name: OLA analysis and article ranking Description: It's a report schedule example. Reports: Analysis of Group load by OLA; Article ranking Report format: PDF and CSV Internal recipients: Test user A External recipients: Test user B Group recipients: Release Manager Group Send email every: 1 Day Send email at: 5:00 PM Effective from 06/01/2019 Until 06/10/2019 In this example, a report schedule named \"OLA analysis and article ranking\" is shown in the schedule list",
    "url": "reportschedule",
    "filename": "reportschedule",
    "headings": [
      "Notes and tips for using scheduled reports",
      "Maximum number of schedules and reports",
      "Recipients",
      "Time zone",
      "Last day of a month",
      "Tenant attachment settings",
      "Performance",
      "Related topics"
    ],
    "keywords": [
      "2.60",
      "scheduled",
      "reports",
      "notes",
      "tips",
      "maximum",
      "number",
      "schedules",
      "recipients",
      "time",
      "zone",
      "last",
      "day",
      "month",
      "tenant",
      "attachment",
      "settings",
      "performance",
      "related",
      "topics",
      "preset",
      "schedule",
      "smax",
      "regularly",
      "generate",
      "certain",
      "send",
      "group",
      "through",
      "emails.",
      "create",
      "delete",
      "report",
      "click",
      "tab",
      "page",
      "new",
      "delete.",
      "note",
      "agent",
      "needs",
      "define",
      "tasks",
      "email",
      "role",
      "permission.",
      "creation",
      "deletion",
      "straightforward",
      "following",
      "properties",
      "provided",
      "example",
      "configured.",
      "name",
      "daily",
      "display",
      "ola",
      "analysis",
      "article",
      "ranking",
      "description",
      "example.",
      "load",
      "format",
      "pdf",
      "csv",
      "internal",
      "test",
      "user",
      "external",
      "release",
      "manager",
      "every",
      "00",
      "pm",
      "effective",
      "06",
      "01",
      "2019",
      "until",
      "10",
      "named",
      "shown",
      "list.",
      "enabled",
      "generated",
      "p.m.",
      "june",
      "basis.",
      "meanwhile",
      "emailed",
      "formats.",
      "aware",
      "while",
      "reports.",
      "100",
      "schedules.",
      "add",
      "schedule."
    ],
    "language": "en",
    "word_count": 118,
    "importance_score": 6.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "scheduled reports",
    "contentLower": "with a preset schedule, smax can regularly generate certain reports and send them to a group of recipients through emails. to create/delete a report schedule, click the schedules tab on the reports page, and then click new or delete. note: to create scheduled reports, an it agent needs the define schedule tasks for email reports role permission. the creation or deletion of a schedule is straightforward, the following schedule properties are provided as an example of how a schedule is configured. name: daily schedule a display name: ola analysis and article ranking description: it's a report schedule example. reports: analysis of group load by ola; article ranking report format: pdf and csv internal recipients: test user a external recipients: test user b group recipients: release manager group send email every: 1 day send email at: 5:00 pm effective from 06/01/2019 until 06/10/2019 in this example, a report schedule named \"ola analysis and article ranking\" is shown in the schedule list",
    "keywordsLower": [
      "2.60",
      "scheduled",
      "reports",
      "notes",
      "tips",
      "maximum",
      "number",
      "schedules",
      "recipients",
      "time",
      "zone",
      "last",
      "day",
      "month",
      "tenant",
      "attachment",
      "settings",
      "performance",
      "related",
      "topics",
      "preset",
      "schedule",
      "smax",
      "regularly",
      "generate",
      "certain",
      "send",
      "group",
      "through",
      "emails.",
      "create",
      "delete",
      "report",
      "click",
      "tab",
      "page",
      "new",
      "delete.",
      "note",
      "agent",
      "needs",
      "define",
      "tasks",
      "email",
      "role",
      "permission.",
      "creation",
      "deletion",
      "straightforward",
      "following",
      "properties",
      "provided",
      "example",
      "configured.",
      "name",
      "daily",
      "display",
      "ola",
      "analysis",
      "article",
      "ranking",
      "description",
      "example.",
      "load",
      "format",
      "pdf",
      "csv",
      "internal",
      "test",
      "user",
      "external",
      "release",
      "manager",
      "every",
      "00",
      "pm",
      "effective",
      "06",
      "01",
      "2019",
      "until",
      "10",
      "named",
      "shown",
      "list.",
      "enabled",
      "generated",
      "p.m.",
      "june",
      "basis.",
      "meanwhile",
      "emailed",
      "formats.",
      "aware",
      "while",
      "reports.",
      "100",
      "schedules.",
      "add",
      "schedule."
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Roles and permissions",
    "content": "Service Management has built-in roles that are based on industry best practice recommendations. Large companies might have several people assigned to the same role. Smaller organizations might have multiple roles assigned to one person. Maintaining a role-based view of the organization makes sure that you adhere to the best practice model no matter who is assigned to the role or how you divide the responsibilities associated with the role. For example, if your company is large, you may have separate process designers and process owners assigned to each module. A smaller company might assign both roles to one person for each module. Roles have certain permissions that enable you to complete your daily work. Roles are assigned by application area. For example, an Incident Coordinator, Change Coordinator, and Problem Coordinator are similar roles with similar rights within the Incident, Change, and Problem Management applications. Permissions Permissions are controls within applications. ",
    "url": "rolespermissions",
    "filename": "rolespermissions",
    "headings": [
      "Permissions",
      "Related topics"
    ],
    "keywords": [
      "roles",
      "permissions",
      "related",
      "topics",
      "service",
      "management",
      "built-in",
      "based",
      "industry",
      "best",
      "practice",
      "recommendations.",
      "large",
      "companies",
      "several",
      "people",
      "assigned",
      "same",
      "role.",
      "smaller",
      "organizations",
      "multiple",
      "one",
      "person.",
      "maintaining",
      "role-based",
      "view",
      "organization",
      "makes",
      "sure",
      "adhere",
      "model",
      "matter",
      "role",
      "divide",
      "responsibilities",
      "associated",
      "example",
      "company",
      "separate",
      "process",
      "designers",
      "owners",
      "module.",
      "assign",
      "both",
      "person",
      "certain",
      "enable",
      "complete",
      "daily",
      "work.",
      "application",
      "area.",
      "incident",
      "coordinator",
      "change",
      "problem",
      "similar",
      "rights",
      "applications.",
      "controls",
      "tasks",
      "such",
      "adding",
      "update",
      "information",
      "record.",
      "administrative",
      "strategy",
      "control",
      "access",
      "records",
      "limit",
      "number",
      "create",
      "delete",
      "records.",
      "particular",
      "data",
      "domains",
      "ability",
      "tagged",
      "domains.",
      "see",
      "domain",
      "segmentation.",
      "aren",
      "familiar",
      "contact",
      "tenant",
      "administrator.",
      "note",
      "license",
      "required",
      "log",
      "management.",
      "licenses",
      "users.",
      "overview"
    ],
    "language": "en",
    "word_count": 91,
    "importance_score": 4.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "roles and permissions",
    "contentLower": "service management has built-in roles that are based on industry best practice recommendations. large companies might have several people assigned to the same role. smaller organizations might have multiple roles assigned to one person. maintaining a role-based view of the organization makes sure that you adhere to the best practice model no matter who is assigned to the role or how you divide the responsibilities associated with the role. for example, if your company is large, you may have separate process designers and process owners assigned to each module. a smaller company might assign both roles to one person for each module. roles have certain permissions that enable you to complete your daily work. roles are assigned by application area. for example, an incident coordinator, change coordinator, and problem coordinator are similar roles with similar rights within the incident, change, and problem management applications. permissions permissions are controls within applications. ",
    "keywordsLower": [
      "roles",
      "permissions",
      "related",
      "topics",
      "service",
      "management",
      "built-in",
      "based",
      "industry",
      "best",
      "practice",
      "recommendations.",
      "large",
      "companies",
      "several",
      "people",
      "assigned",
      "same",
      "role.",
      "smaller",
      "organizations",
      "multiple",
      "one",
      "person.",
      "maintaining",
      "role-based",
      "view",
      "organization",
      "makes",
      "sure",
      "adhere",
      "model",
      "matter",
      "role",
      "divide",
      "responsibilities",
      "associated",
      "example",
      "company",
      "separate",
      "process",
      "designers",
      "owners",
      "module.",
      "assign",
      "both",
      "person",
      "certain",
      "enable",
      "complete",
      "daily",
      "work.",
      "application",
      "area.",
      "incident",
      "coordinator",
      "change",
      "problem",
      "similar",
      "rights",
      "applications.",
      "controls",
      "tasks",
      "such",
      "adding",
      "update",
      "information",
      "record.",
      "administrative",
      "strategy",
      "control",
      "access",
      "records",
      "limit",
      "number",
      "create",
      "delete",
      "records.",
      "particular",
      "data",
      "domains",
      "ability",
      "tagged",
      "domains.",
      "see",
      "domain",
      "segmentation.",
      "aren",
      "familiar",
      "contact",
      "tenant",
      "administrator.",
      "note",
      "license",
      "required",
      "log",
      "management.",
      "licenses",
      "users.",
      "overview"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Task plans",
    "content": "A task plan is a set of tasks in a record's workflow that needs to be completed before moving from one phase of the workflow to the next. A task plan might include automated tasks, manual tasks, and decisions that need to be made by the system to determine which path of the task plan to follow. A task plan for an approval phase of a workflow is known as an approval plan. An approval plan might include approval tasks and decisions that need to be made by the system to determine which path of the approval plan to follow. You can build task/approval plans for the following record types: Changes and change models Ideas Proposals Incidents and incident models Offerings and fulfillment plans Articles and article models Problems Releases Requests Agreements You can add a task plan to specific phases in the workflow of a record. You can only add an approval plan to phases in the workflow that are defined as allowing approval definitions. A phase in a workflow can have either tasks or approvals",
    "url": "taskplans",
    "filename": "taskplans",
    "headings": [
      "How to build a task/approval plan",
      "Step 1",
      "Step 2",
      "Step 3",
      "Step 4",
      "Step 5",
      "Context record",
      "Task properties",
      "Parent record",
      "Scheduling",
      "External",
      "Business rules",
      "Approval",
      "Decision",
      "Step 6",
      "Step 7",
      "Step 8",
      "Step 9",
      "Approval task status",
      "Approval strategy and task node status"
    ],
    "keywords": [
      "task",
      "plans",
      "build",
      "approval",
      "plan",
      "step",
      "context",
      "record",
      "properties",
      "parent",
      "scheduling",
      "external",
      "business",
      "rules",
      "decision",
      "status",
      "strategy",
      "node",
      "one",
      "approve",
      "all",
      "immediate",
      "deny",
      "quorum",
      "nodes",
      "slt",
      "calculation",
      "manual",
      "tasks",
      "control",
      "access",
      "disable",
      "phases",
      "related",
      "topics",
      "set",
      "workflow",
      "needs",
      "completed",
      "before",
      "moving",
      "phase",
      "next.",
      "include",
      "automated",
      "decisions",
      "need",
      "made",
      "system",
      "determine",
      "path",
      "follow.",
      "known",
      "plan.",
      "following",
      "types",
      "changes",
      "change",
      "models",
      "ideas",
      "proposals",
      "incidents",
      "incident",
      "offerings",
      "fulfillment",
      "articles",
      "article",
      "problems",
      "releases",
      "requests",
      "agreements",
      "add",
      "specific",
      "record.",
      "defined",
      "allowing",
      "definitions.",
      "either",
      "approvals",
      "both.",
      "corresponding",
      "model",
      "type",
      "request",
      "best",
      "practice",
      "types.",
      "way",
      "records",
      "created",
      "based",
      "automatically",
      "consistent",
      "management",
      "efficient.",
      "default",
      "any",
      "agent",
      "user",
      "modify"
    ],
    "language": "en",
    "word_count": 101,
    "importance_score": 6.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "task plans",
    "contentLower": "a task plan is a set of tasks in a record's workflow that needs to be completed before moving from one phase of the workflow to the next. a task plan might include automated tasks, manual tasks, and decisions that need to be made by the system to determine which path of the task plan to follow. a task plan for an approval phase of a workflow is known as an approval plan. an approval plan might include approval tasks and decisions that need to be made by the system to determine which path of the approval plan to follow. you can build task/approval plans for the following record types: changes and change models ideas proposals incidents and incident models offerings and fulfillment plans articles and article models problems releases requests agreements you can add a task plan to specific phases in the workflow of a record. you can only add an approval plan to phases in the workflow that are defined as allowing approval definitions. a phase in a workflow can have either tasks or approvals",
    "keywordsLower": [
      "task",
      "plans",
      "build",
      "approval",
      "plan",
      "step",
      "context",
      "record",
      "properties",
      "parent",
      "scheduling",
      "external",
      "business",
      "rules",
      "decision",
      "status",
      "strategy",
      "node",
      "one",
      "approve",
      "all",
      "immediate",
      "deny",
      "quorum",
      "nodes",
      "slt",
      "calculation",
      "manual",
      "tasks",
      "control",
      "access",
      "disable",
      "phases",
      "related",
      "topics",
      "set",
      "workflow",
      "needs",
      "completed",
      "before",
      "moving",
      "phase",
      "next.",
      "include",
      "automated",
      "decisions",
      "need",
      "made",
      "system",
      "determine",
      "path",
      "follow.",
      "known",
      "plan.",
      "following",
      "types",
      "changes",
      "change",
      "models",
      "ideas",
      "proposals",
      "incidents",
      "incident",
      "offerings",
      "fulfillment",
      "articles",
      "article",
      "problems",
      "releases",
      "requests",
      "agreements",
      "add",
      "specific",
      "record.",
      "defined",
      "allowing",
      "definitions.",
      "either",
      "approvals",
      "both.",
      "corresponding",
      "model",
      "type",
      "request",
      "best",
      "practice",
      "types.",
      "way",
      "records",
      "created",
      "based",
      "automatically",
      "consistent",
      "management",
      "efficient.",
      "default",
      "any",
      "agent",
      "user",
      "modify"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Service Portfolio Management",
    "content": "Service Portfolio Management enables you to manage your service portfolio, including service definitions that offer value to the users and support their goals. Related topics Category Link Administer Fields Forms Roles Data domain segmentation Service definition process - Business rules Mapping records created from a service definition record Use Service definitions Create a service definition record Edit a service definition record Service definition workflow Develop Single record APIs Record bulk update and collection APIs",
    "url": "serviceportfoliomgmt",
    "filename": "serviceportfoliomgmt",
    "headings": [
      "Related topics"
    ],
    "keywords": [
      "service",
      "portfolio",
      "management",
      "related",
      "topics",
      "enables",
      "manage",
      "including",
      "definitions",
      "offer",
      "value",
      "users",
      "support",
      "goals.",
      "category",
      "link",
      "administer",
      "fields",
      "forms",
      "roles",
      "data",
      "domain",
      "segmentation",
      "definition",
      "process",
      "business",
      "rules",
      "mapping",
      "records",
      "created",
      "record",
      "create",
      "edit",
      "workflow",
      "develop",
      "single",
      "apis",
      "bulk",
      "update",
      "collection"
    ],
    "language": "en",
    "word_count": 62,
    "importance_score": 2.5,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "service portfolio management",
    "contentLower": "service portfolio management enables you to manage your service portfolio, including service definitions that offer value to the users and support their goals. related topics category link administer fields forms roles data domain segmentation service definition process - business rules mapping records created from a service definition record use service definitions create a service definition record edit a service definition record service definition workflow develop single record apis record bulk update and collection apis",
    "keywordsLower": [
      "service",
      "portfolio",
      "management",
      "related",
      "topics",
      "enables",
      "manage",
      "including",
      "definitions",
      "offer",
      "value",
      "users",
      "support",
      "goals.",
      "category",
      "link",
      "administer",
      "fields",
      "forms",
      "roles",
      "data",
      "domain",
      "segmentation",
      "definition",
      "process",
      "business",
      "rules",
      "mapping",
      "records",
      "created",
      "record",
      "create",
      "edit",
      "workflow",
      "develop",
      "single",
      "apis",
      "bulk",
      "update",
      "collection"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Service definitions",
    "content": "Each category contains one or more service definitions. A service provides value to end users and supports their goals. A service definition is a high level description of the provided service. The service definition also groups actual services that are part of the same domain. In this example, you can see how the category specified by a service request can decide the entry point of the SACM model. Book store and CD store are the service definitions that belong to the Store category . Related topics Service Portfolio Management How to create a service definition record How to edit a service definition record Service definition workflow",
    "url": "servicedefn",
    "filename": "servicedefn",
    "headings": [
      "Related topics"
    ],
    "keywords": [
      "service",
      "definitions",
      "related",
      "topics",
      "category",
      "contains",
      "one",
      "definitions.",
      "provides",
      "value",
      "end",
      "users",
      "supports",
      "goals.",
      "definition",
      "high",
      "level",
      "description",
      "provided",
      "service.",
      "groups",
      "actual",
      "services",
      "part",
      "same",
      "domain.",
      "example",
      "see",
      "specified",
      "request",
      "decide",
      "entry",
      "point",
      "sacm",
      "model.",
      "book",
      "store",
      "cd",
      "belong",
      "portfolio",
      "management",
      "create",
      "record",
      "edit",
      "workflow"
    ],
    "language": "en",
    "word_count": 65,
    "importance_score": 3.5,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "service definitions",
    "contentLower": "each category contains one or more service definitions. a service provides value to end users and supports their goals. a service definition is a high level description of the provided service. the service definition also groups actual services that are part of the same domain. in this example, you can see how the category specified by a service request can decide the entry point of the sacm model. book store and cd store are the service definitions that belong to the store category . related topics service portfolio management how to create a service definition record how to edit a service definition record service definition workflow",
    "keywordsLower": [
      "service",
      "definitions",
      "related",
      "topics",
      "category",
      "contains",
      "one",
      "definitions.",
      "provides",
      "value",
      "end",
      "users",
      "supports",
      "goals.",
      "definition",
      "high",
      "level",
      "description",
      "provided",
      "service.",
      "groups",
      "actual",
      "services",
      "part",
      "same",
      "domain.",
      "example",
      "see",
      "specified",
      "request",
      "decide",
      "entry",
      "point",
      "sacm",
      "model.",
      "book",
      "store",
      "cd",
      "belong",
      "portfolio",
      "management",
      "create",
      "record",
      "edit",
      "workflow"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Service definition workflow",
    "content": "This section describes the metaphases and subordinate phases in the life cycle of a service definition. The service definition workflow relies on business rules. Rules repeat from one phase to another when the end user can make a change to a field affected by a business rule during that phase. For more information about the out-of-the-box business rules defined for the service definition workflow, see Service definition process - Business rules. Metaphase: Planning Includes the planning phases of a service definition. Phase Transition Description Plan Manual This is the starting point for the basic service definition workflow. Your plan can contain any or all of the following: Description Required resources Next phase: Build Metaphase: Construction Includes the construction phases of the service definition. Phase Transition Description Build Manual The service definition is built in this phase. If the built service definition matches the design produced in the Plan phase, you can manua",
    "url": "servicedefnwflw",
    "filename": "servicedefnwflw",
    "headings": [
      "Metaphase: Planning",
      "Metaphase: Construction",
      "Metaphase: Operation",
      "Metaphase: Final (End)",
      "Related topics"
    ],
    "keywords": [
      "service",
      "definition",
      "workflow",
      "metaphase",
      "planning",
      "construction",
      "operation",
      "final",
      "end",
      "related",
      "topics",
      "section",
      "describes",
      "metaphases",
      "subordinate",
      "phases",
      "life",
      "cycle",
      "definition.",
      "relies",
      "business",
      "rules.",
      "rules",
      "repeat",
      "one",
      "phase",
      "another",
      "user",
      "make",
      "change",
      "field",
      "affected",
      "rule",
      "during",
      "phase.",
      "information",
      "about",
      "out-of-the-box",
      "defined",
      "see",
      "process",
      "includes",
      "transition",
      "description",
      "plan",
      "manual",
      "starting",
      "point",
      "basic",
      "workflow.",
      "contain",
      "any",
      "all",
      "following",
      "required",
      "resources",
      "next",
      "build",
      "built",
      "matches",
      "design",
      "produced",
      "manually",
      "operate",
      "making",
      "available",
      "end-user",
      "community.",
      "alternatively",
      "return",
      "adjust",
      "plan.",
      "operational",
      "there",
      "replacement",
      "decommission",
      "something",
      "needs",
      "changed",
      "back",
      "still",
      "active",
      "ready",
      "retired",
      "replaced.",
      "closing",
      "longer",
      "available.",
      "none",
      "start",
      "again",
      "while",
      "waiting",
      "portfolio",
      "management",
      "definitions",
      "create",
      "record",
      "edit"
    ],
    "language": "en",
    "word_count": 102,
    "importance_score": 5.5,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "service definition workflow",
    "contentLower": "this section describes the metaphases and subordinate phases in the life cycle of a service definition. the service definition workflow relies on business rules. rules repeat from one phase to another when the end user can make a change to a field affected by a business rule during that phase. for more information about the out-of-the-box business rules defined for the service definition workflow, see service definition process - business rules. metaphase: planning includes the planning phases of a service definition. phase transition description plan manual this is the starting point for the basic service definition workflow. your plan can contain any or all of the following: description required resources next phase: build metaphase: construction includes the construction phases of the service definition. phase transition description build manual the service definition is built in this phase. if the built service definition matches the design produced in the plan phase, you can manua",
    "keywordsLower": [
      "service",
      "definition",
      "workflow",
      "metaphase",
      "planning",
      "construction",
      "operation",
      "final",
      "end",
      "related",
      "topics",
      "section",
      "describes",
      "metaphases",
      "subordinate",
      "phases",
      "life",
      "cycle",
      "definition.",
      "relies",
      "business",
      "rules.",
      "rules",
      "repeat",
      "one",
      "phase",
      "another",
      "user",
      "make",
      "change",
      "field",
      "affected",
      "rule",
      "during",
      "phase.",
      "information",
      "about",
      "out-of-the-box",
      "defined",
      "see",
      "process",
      "includes",
      "transition",
      "description",
      "plan",
      "manual",
      "starting",
      "point",
      "basic",
      "workflow.",
      "contain",
      "any",
      "all",
      "following",
      "required",
      "resources",
      "next",
      "build",
      "built",
      "matches",
      "design",
      "produced",
      "manually",
      "operate",
      "making",
      "available",
      "end-user",
      "community.",
      "alternatively",
      "return",
      "adjust",
      "plan.",
      "operational",
      "there",
      "replacement",
      "decommission",
      "something",
      "needs",
      "changed",
      "back",
      "still",
      "active",
      "ready",
      "retired",
      "replaced.",
      "closing",
      "longer",
      "available.",
      "none",
      "start",
      "again",
      "while",
      "waiting",
      "portfolio",
      "management",
      "definitions",
      "create",
      "record",
      "edit"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Service Catalog Management",
    "content": "Service Catalog Management is where the Service Catalog is managed. The Service Catalog contains services arranged by category. The services are further divided into service offerings and support offerings. Important As a best practice, set up the Service Catalog in a development tenant and then import it into your production tenant by using the Dev2Prod process. See Dev2Prod - Synchronize Service Catalog content. This is because each time you update a workflow (for example, updating a business rule of an offering), the system saves a new version of the workflow in the database and the database performance may downgrade significantly over time if you have a large volume of offerings. To avoid this issue, develop your Service Catalog content in your development tenant, then export the Service Catalog content to a package by using the Package Management Utility and then import the package to your production tenant. The exported package contains only the latest version of each workflow an",
    "url": "servicecatalogmgmt",
    "filename": "servicecatalogmgmt",
    "headings": [
      "Related topics"
    ],
    "keywords": [
      "service",
      "catalog",
      "management",
      "related",
      "topics",
      "managed.",
      "contains",
      "services",
      "arranged",
      "category.",
      "further",
      "divided",
      "offerings",
      "support",
      "offerings.",
      "important",
      "best",
      "practice",
      "set",
      "development",
      "tenant",
      "import",
      "production",
      "dev2prod",
      "process.",
      "see",
      "synchronize",
      "content.",
      "because",
      "time",
      "update",
      "workflow",
      "example",
      "updating",
      "business",
      "rule",
      "offering",
      "system",
      "saves",
      "new",
      "version",
      "database",
      "performance",
      "downgrade",
      "significantly",
      "over",
      "large",
      "volume",
      "avoid",
      "issue",
      "develop",
      "content",
      "export",
      "package",
      "utility",
      "tenant.",
      "exported",
      "latest",
      "hence",
      "won",
      "cause",
      "significant",
      "displayed",
      "home",
      "page",
      "portal.",
      "request",
      "agents",
      "module.",
      "agent",
      "opens",
      "select",
      "channel",
      "directly",
      "correct",
      "team",
      "handling.",
      "note",
      "work",
      "data",
      "domains",
      "want",
      "manually",
      "change",
      "existing",
      "domain",
      "assignments",
      "first",
      "add",
      "field",
      "relevant",
      "forms.",
      "information",
      "adding",
      "fields",
      "forms",
      "edit",
      "form.",
      "segmentation.",
      "category"
    ],
    "language": "en",
    "word_count": 91,
    "importance_score": 3.5,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "service catalog management",
    "contentLower": "service catalog management is where the service catalog is managed. the service catalog contains services arranged by category. the services are further divided into service offerings and support offerings. important as a best practice, set up the service catalog in a development tenant and then import it into your production tenant by using the dev2prod process. see dev2prod - synchronize service catalog content. this is because each time you update a workflow (for example, updating a business rule of an offering), the system saves a new version of the workflow in the database and the database performance may downgrade significantly over time if you have a large volume of offerings. to avoid this issue, develop your service catalog content in your development tenant, then export the service catalog content to a package by using the package management utility and then import the package to your production tenant. the exported package contains only the latest version of each workflow an",
    "keywordsLower": [
      "service",
      "catalog",
      "management",
      "related",
      "topics",
      "managed.",
      "contains",
      "services",
      "arranged",
      "category.",
      "further",
      "divided",
      "offerings",
      "support",
      "offerings.",
      "important",
      "best",
      "practice",
      "set",
      "development",
      "tenant",
      "import",
      "production",
      "dev2prod",
      "process.",
      "see",
      "synchronize",
      "content.",
      "because",
      "time",
      "update",
      "workflow",
      "example",
      "updating",
      "business",
      "rule",
      "offering",
      "system",
      "saves",
      "new",
      "version",
      "database",
      "performance",
      "downgrade",
      "significantly",
      "over",
      "large",
      "volume",
      "avoid",
      "issue",
      "develop",
      "content",
      "export",
      "package",
      "utility",
      "tenant.",
      "exported",
      "latest",
      "hence",
      "won",
      "cause",
      "significant",
      "displayed",
      "home",
      "page",
      "portal.",
      "request",
      "agents",
      "module.",
      "agent",
      "opens",
      "select",
      "channel",
      "directly",
      "correct",
      "team",
      "handling.",
      "note",
      "work",
      "data",
      "domains",
      "want",
      "manually",
      "change",
      "existing",
      "domain",
      "assignments",
      "first",
      "add",
      "field",
      "relevant",
      "forms.",
      "information",
      "adding",
      "fields",
      "forms",
      "edit",
      "form.",
      "segmentation.",
      "category"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Time Period Management",
    "content": "Service Management's Time Period Management module enables users with the appropriate permissions to create, edit, and manage time periods for use in Change and Service Level Management. You can create maintenance, blackout, work schedule, holiday, event, personal work schedule, and on call shift time periods. Time management helps users plan implementation of changes, so as to minimize disruption, and maximize the efficient use of resources. Service Management uses work schedule time periods in Service Level Management calculations. Related topics Category Link Administer Fields Forms Roles Data domain segmentation Use case scenarios - customizing with business rules Use Time periods Create a time period record Edit a time period record Activate a time period record Retire a time period record Develop Single record APIs Record bulk update and collection APIs",
    "url": "timemgmt",
    "filename": "timemgmt",
    "headings": [
      "Related topics"
    ],
    "keywords": [
      "time",
      "period",
      "management",
      "related",
      "topics",
      "service",
      "module",
      "enables",
      "users",
      "appropriate",
      "permissions",
      "create",
      "edit",
      "manage",
      "periods",
      "change",
      "level",
      "management.",
      "maintenance",
      "blackout",
      "work",
      "schedule",
      "holiday",
      "event",
      "personal",
      "call",
      "shift",
      "periods.",
      "helps",
      "plan",
      "implementation",
      "changes",
      "minimize",
      "disruption",
      "maximize",
      "efficient",
      "resources.",
      "uses",
      "calculations.",
      "category",
      "link",
      "administer",
      "fields",
      "forms",
      "roles",
      "data",
      "domain",
      "segmentation",
      "case",
      "scenarios",
      "customizing",
      "business",
      "rules",
      "record",
      "activate",
      "retire",
      "develop",
      "single",
      "apis",
      "bulk",
      "update",
      "collection"
    ],
    "language": "en",
    "word_count": 103,
    "importance_score": 3.5,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "time period management",
    "contentLower": "service management's time period management module enables users with the appropriate permissions to create, edit, and manage time periods for use in change and service level management. you can create maintenance, blackout, work schedule, holiday, event, personal work schedule, and on call shift time periods. time management helps users plan implementation of changes, so as to minimize disruption, and maximize the efficient use of resources. service management uses work schedule time periods in service level management calculations. related topics category link administer fields forms roles data domain segmentation use case scenarios - customizing with business rules use time periods create a time period record edit a time period record activate a time period record retire a time period record develop single record apis record bulk update and collection apis",
    "keywordsLower": [
      "time",
      "period",
      "management",
      "related",
      "topics",
      "service",
      "module",
      "enables",
      "users",
      "appropriate",
      "permissions",
      "create",
      "edit",
      "manage",
      "periods",
      "change",
      "level",
      "management.",
      "maintenance",
      "blackout",
      "work",
      "schedule",
      "holiday",
      "event",
      "personal",
      "call",
      "shift",
      "periods.",
      "helps",
      "plan",
      "implementation",
      "changes",
      "minimize",
      "disruption",
      "maximize",
      "efficient",
      "resources.",
      "uses",
      "calculations.",
      "category",
      "link",
      "administer",
      "fields",
      "forms",
      "roles",
      "data",
      "domain",
      "segmentation",
      "case",
      "scenarios",
      "customizing",
      "business",
      "rules",
      "record",
      "activate",
      "retire",
      "develop",
      "single",
      "apis",
      "bulk",
      "update",
      "collection"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Time periods",
    "content": "There are the following types of time period in Service Management. Time period Description Maintenance A time period which users can schedule changes to take place in. Blackout A time period which users should not schedule changes to take place in. Work schedule Service Level Management uses this type of time period for calculation of service level breaches. It specifies the times within which service level performance may be measured. For example, 08.00 to 17.00, Monday to Friday, recurring every week. Holiday For the information of users. Event For the information of users. Personal work schedule A time period in which users can schedule personal work time. Usually created from On-call schedule management or the user profile. On call shift A time period in which users can schedule on-call time. Usually created from On-call schedule management. Related topics How to create a time period record How to edit a time period record How to activate a time period record How to retire a time ",
    "url": "timeperiods",
    "filename": "timeperiods",
    "headings": [
      "Related topics"
    ],
    "keywords": [
      "17.00",
      "08.00",
      "time",
      "periods",
      "related",
      "topics",
      "there",
      "following",
      "types",
      "period",
      "service",
      "management.",
      "description",
      "maintenance",
      "users",
      "schedule",
      "changes",
      "take",
      "place",
      "in.",
      "blackout",
      "work",
      "level",
      "management",
      "uses",
      "type",
      "calculation",
      "breaches.",
      "specifies",
      "times",
      "performance",
      "measured.",
      "example",
      "monday",
      "friday",
      "recurring",
      "every",
      "week.",
      "holiday",
      "information",
      "users.",
      "event",
      "personal",
      "time.",
      "usually",
      "created",
      "on-call",
      "user",
      "profile.",
      "call",
      "shift",
      "create",
      "record",
      "edit",
      "activate",
      "retire"
    ],
    "language": "en",
    "word_count": 109,
    "importance_score": 3.5,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "time periods",
    "contentLower": "there are the following types of time period in service management. time period description maintenance a time period which users can schedule changes to take place in. blackout a time period which users should not schedule changes to take place in. work schedule service level management uses this type of time period for calculation of service level breaches. it specifies the times within which service level performance may be measured. for example, 08.00 to 17.00, monday to friday, recurring every week. holiday for the information of users. event for the information of users. personal work schedule a time period in which users can schedule personal work time. usually created from on-call schedule management or the user profile. on call shift a time period in which users can schedule on-call time. usually created from on-call schedule management. related topics how to create a time period record how to edit a time period record how to activate a time period record how to retire a time ",
    "keywordsLower": [
      "17.00",
      "08.00",
      "time",
      "periods",
      "related",
      "topics",
      "there",
      "following",
      "types",
      "period",
      "service",
      "management.",
      "description",
      "maintenance",
      "users",
      "schedule",
      "changes",
      "take",
      "place",
      "in.",
      "blackout",
      "work",
      "level",
      "management",
      "uses",
      "type",
      "calculation",
      "breaches.",
      "specifies",
      "times",
      "performance",
      "measured.",
      "example",
      "monday",
      "friday",
      "recurring",
      "every",
      "week.",
      "holiday",
      "information",
      "users.",
      "event",
      "personal",
      "time.",
      "usually",
      "created",
      "on-call",
      "user",
      "profile.",
      "call",
      "shift",
      "create",
      "record",
      "edit",
      "activate",
      "retire"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Service Level Management",
    "content": "Service management best practices describe the goals for Service Level Management (SLM) as follows: The goal for SLM is to maintain and improve service quality, through a constant cycle of agreeing, monitoring and reporting upon service achievements and instigation of actions to eradicate poor service – in line with business or cost justification. Through these methods, a better relationship between IT and its Customers can be developed. Service Management supports these goals by providing a service management best practices compliant application framework with a built-in workflow that incorporates service management best practices. The primary Service Level Management goal is to ensure the delivery of services within agreed Service Level Targets (SLTs). You can measure the quality of service delivery by defining Service Level Agreements with your customers to deliver their required services within predefined objectives. Service Level Targets define those objectives using measurable cr",
    "url": "servicelevelmgmt",
    "filename": "servicelevelmgmt",
    "headings": [
      "Related topics"
    ],
    "keywords": [
      "service",
      "level",
      "management",
      "related",
      "topics",
      "best",
      "practices",
      "describe",
      "goals",
      "slm",
      "follows",
      "goal",
      "maintain",
      "improve",
      "quality",
      "through",
      "constant",
      "cycle",
      "agreeing",
      "monitoring",
      "reporting",
      "upon",
      "achievements",
      "instigation",
      "actions",
      "eradicate",
      "poor",
      "line",
      "business",
      "cost",
      "justification.",
      "methods",
      "better",
      "relationship",
      "between",
      "customers",
      "developed.",
      "supports",
      "providing",
      "compliant",
      "application",
      "framework",
      "built-in",
      "workflow",
      "incorporates",
      "practices.",
      "primary",
      "ensure",
      "delivery",
      "services",
      "agreed",
      "targets",
      "slts",
      "measure",
      "defining",
      "agreements",
      "deliver",
      "required",
      "predefined",
      "objectives.",
      "define",
      "objectives",
      "measurable",
      "criteria.",
      "metrics",
      "report",
      "achievement",
      "set",
      "all",
      "services.",
      "create",
      "customer",
      "fosters",
      "communication.",
      "understands",
      "provided.",
      "monitor",
      "delivered",
      "necessary.",
      "enables",
      "prioritize",
      "requests",
      "incidents",
      "changes",
      "tasks",
      "problems",
      "custom",
      "records",
      "service.",
      "highest",
      "priorities",
      "resolved",
      "first.",
      "track",
      "configuring",
      "various",
      "types",
      "tools",
      "uses",
      "accomplish"
    ],
    "language": "en",
    "word_count": 98,
    "importance_score": 3.5,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "service level management",
    "contentLower": "service management best practices describe the goals for service level management (slm) as follows: the goal for slm is to maintain and improve service quality, through a constant cycle of agreeing, monitoring and reporting upon service achievements and instigation of actions to eradicate poor service – in line with business or cost justification. through these methods, a better relationship between it and its customers can be developed. service management supports these goals by providing a service management best practices compliant application framework with a built-in workflow that incorporates service management best practices. the primary service level management goal is to ensure the delivery of services within agreed service level targets (slts). you can measure the quality of service delivery by defining service level agreements with your customers to deliver their required services within predefined objectives. service level targets define those objectives using measurable cr",
    "keywordsLower": [
      "service",
      "level",
      "management",
      "related",
      "topics",
      "best",
      "practices",
      "describe",
      "goals",
      "slm",
      "follows",
      "goal",
      "maintain",
      "improve",
      "quality",
      "through",
      "constant",
      "cycle",
      "agreeing",
      "monitoring",
      "reporting",
      "upon",
      "achievements",
      "instigation",
      "actions",
      "eradicate",
      "poor",
      "line",
      "business",
      "cost",
      "justification.",
      "methods",
      "better",
      "relationship",
      "between",
      "customers",
      "developed.",
      "supports",
      "providing",
      "compliant",
      "application",
      "framework",
      "built-in",
      "workflow",
      "incorporates",
      "practices.",
      "primary",
      "ensure",
      "delivery",
      "services",
      "agreed",
      "targets",
      "slts",
      "measure",
      "defining",
      "agreements",
      "deliver",
      "required",
      "predefined",
      "objectives.",
      "define",
      "objectives",
      "measurable",
      "criteria.",
      "metrics",
      "report",
      "achievement",
      "set",
      "all",
      "services.",
      "create",
      "customer",
      "fosters",
      "communication.",
      "understands",
      "provided.",
      "monitor",
      "delivered",
      "necessary.",
      "enables",
      "prioritize",
      "requests",
      "incidents",
      "changes",
      "tasks",
      "problems",
      "custom",
      "records",
      "service.",
      "highest",
      "priorities",
      "resolved",
      "first.",
      "track",
      "configuring",
      "various",
      "types",
      "tools",
      "uses",
      "accomplish"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Service Level Management elements",
    "content": "This chapter gives an overview about the different elements used in the SLM module to successfully create and maintain the various agreements. Agreements Agreements (Service, Support, and HR) come in two types. A Service Level Agreement (SLA) is an external document that describes the agreed level of service between service providers and customers. It defines service goals and responsibilities for Configuration Items (CIs). An Operational Level Agreement (OLA) is an internal document that describes the level of service among the departments within an organization. Service Level Target Set A Service Level Target is a measurable commitment to provide service. A Service Level Agreement or Operational Level Agreement describes the details of the commitment. A Service Level Target set is described by the type of target and associated Service Management module. The following table explains the available target types, which can be used within a Service Level Target. Target type Description De",
    "url": "slmelements",
    "filename": "slmelements",
    "headings": [
      "Agreements",
      "Service Level Target Set",
      "Service Level Target Definitions"
    ],
    "keywords": [
      "service",
      "level",
      "management",
      "elements",
      "agreements",
      "target",
      "set",
      "definitions",
      "chapter",
      "gives",
      "overview",
      "about",
      "different",
      "slm",
      "module",
      "successfully",
      "create",
      "maintain",
      "various",
      "agreements.",
      "support",
      "hr",
      "come",
      "two",
      "types.",
      "agreement",
      "sla",
      "external",
      "document",
      "describes",
      "agreed",
      "between",
      "providers",
      "customers.",
      "defines",
      "goals",
      "responsibilities",
      "configuration",
      "items",
      "cis",
      "operational",
      "ola",
      "internal",
      "among",
      "departments",
      "organization.",
      "measurable",
      "commitment",
      "provide",
      "service.",
      "details",
      "commitment.",
      "described",
      "type",
      "associated",
      "module.",
      "following",
      "table",
      "explains",
      "available",
      "types",
      "target.",
      "description",
      "designed",
      "record",
      "initial",
      "review",
      "much",
      "time",
      "elapse",
      "before",
      "desk",
      "categorizes",
      "assigns",
      "individual",
      "group.",
      "incidents",
      "requests",
      "case",
      "resolution",
      "long",
      "resolve",
      "record.",
      "problems",
      "chat",
      "request",
      "response",
      "initiated",
      "until",
      "agent",
      "responds",
      "request.",
      "relevant",
      "records",
      "only.",
      "approval",
      "takes",
      "approved.",
      "fulfillment",
      "fulfilled."
    ],
    "language": "en",
    "word_count": 102,
    "importance_score": 4.5,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "service level management elements",
    "contentLower": "this chapter gives an overview about the different elements used in the slm module to successfully create and maintain the various agreements. agreements agreements (service, support, and hr) come in two types. a service level agreement (sla) is an external document that describes the agreed level of service between service providers and customers. it defines service goals and responsibilities for configuration items (cis). an operational level agreement (ola) is an internal document that describes the level of service among the departments within an organization. service level target set a service level target is a measurable commitment to provide service. a service level agreement or operational level agreement describes the details of the commitment. a service level target set is described by the type of target and associated service management module. the following table explains the available target types, which can be used within a service level target. target type description de",
    "keywordsLower": [
      "service",
      "level",
      "management",
      "elements",
      "agreements",
      "target",
      "set",
      "definitions",
      "chapter",
      "gives",
      "overview",
      "about",
      "different",
      "slm",
      "module",
      "successfully",
      "create",
      "maintain",
      "various",
      "agreements.",
      "support",
      "hr",
      "come",
      "two",
      "types.",
      "agreement",
      "sla",
      "external",
      "document",
      "describes",
      "agreed",
      "between",
      "providers",
      "customers.",
      "defines",
      "goals",
      "responsibilities",
      "configuration",
      "items",
      "cis",
      "operational",
      "ola",
      "internal",
      "among",
      "departments",
      "organization.",
      "measurable",
      "commitment",
      "provide",
      "service.",
      "details",
      "commitment.",
      "described",
      "type",
      "associated",
      "module.",
      "following",
      "table",
      "explains",
      "available",
      "types",
      "target.",
      "description",
      "designed",
      "record",
      "initial",
      "review",
      "much",
      "time",
      "elapse",
      "before",
      "desk",
      "categorizes",
      "assigns",
      "individual",
      "group.",
      "incidents",
      "requests",
      "case",
      "resolution",
      "long",
      "resolve",
      "record.",
      "problems",
      "chat",
      "request",
      "response",
      "initiated",
      "until",
      "agent",
      "responds",
      "request.",
      "relevant",
      "records",
      "only.",
      "approval",
      "takes",
      "approved.",
      "fulfillment",
      "fulfilled."
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Service Level Management roles",
    "content": "Service Management supports only the Service Level Manager role. If this is your role, you might be responsible for these tasks: Identify stakeholders and customers. Build relationships with internal and external IT and other service groups and other ITIL process groups. Negotiate requirements for Service Level Agreements (SLAs) with customers. Create SLAs and work with Tenant Admin to manage Service Level Target (SLT) rules. Ensure that service level targets described by the SLA are met. Create service level reports about services. Plan service reviews. Service Management uses role based permissions to enable you to complete a task that's appropriate to your role. Tenant Administrators manage and assign these permissions. Review the individual permission assignments for the Service Level Manager role in Administration > Master Data > People > Roles. Related topic Service Level Management Roles",
    "url": "slmroles",
    "filename": "slmroles",
    "headings": [],
    "keywords": [
      "service",
      "level",
      "management",
      "roles",
      "supports",
      "manager",
      "role.",
      "role",
      "responsible",
      "tasks",
      "identify",
      "stakeholders",
      "customers.",
      "build",
      "relationships",
      "internal",
      "external",
      "groups",
      "itil",
      "process",
      "groups.",
      "negotiate",
      "requirements",
      "agreements",
      "slas",
      "create",
      "work",
      "tenant",
      "admin",
      "manage",
      "target",
      "slt",
      "rules.",
      "ensure",
      "targets",
      "described",
      "sla",
      "met.",
      "reports",
      "about",
      "services.",
      "plan",
      "reviews.",
      "uses",
      "based",
      "permissions",
      "enable",
      "complete",
      "task",
      "appropriate",
      "administrators",
      "assign",
      "permissions.",
      "review",
      "individual",
      "permission",
      "assignments",
      "administration",
      "master",
      "data",
      "people",
      "roles.",
      "related",
      "topic"
    ],
    "language": "en",
    "word_count": 96,
    "importance_score": 3.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "service level management roles",
    "contentLower": "service management supports only the service level manager role. if this is your role, you might be responsible for these tasks: identify stakeholders and customers. build relationships with internal and external it and other service groups and other itil process groups. negotiate requirements for service level agreements (slas) with customers. create slas and work with tenant admin to manage service level target (slt) rules. ensure that service level targets described by the sla are met. create service level reports about services. plan service reviews. service management uses role based permissions to enable you to complete a task that's appropriate to your role. tenant administrators manage and assign these permissions. review the individual permission assignments for the service level manager role in administration > master data > people > roles. related topic service level management roles",
    "keywordsLower": [
      "service",
      "level",
      "management",
      "roles",
      "supports",
      "manager",
      "role.",
      "role",
      "responsible",
      "tasks",
      "identify",
      "stakeholders",
      "customers.",
      "build",
      "relationships",
      "internal",
      "external",
      "groups",
      "itil",
      "process",
      "groups.",
      "negotiate",
      "requirements",
      "agreements",
      "slas",
      "create",
      "work",
      "tenant",
      "admin",
      "manage",
      "target",
      "slt",
      "rules.",
      "ensure",
      "targets",
      "described",
      "sla",
      "met.",
      "reports",
      "about",
      "services.",
      "plan",
      "reviews.",
      "uses",
      "based",
      "permissions",
      "enable",
      "complete",
      "task",
      "appropriate",
      "administrators",
      "assign",
      "permissions.",
      "review",
      "individual",
      "permission",
      "assignments",
      "administration",
      "master",
      "data",
      "people",
      "roles.",
      "related",
      "topic"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Service Level Agreement workflow",
    "content": "This section describes the metaphases and subordinate phases in the life cycle of a Service Level Agreement. The Service Level Agreement workflow relies on business rules. Rules repeat from one phase to another when the end user can make a change to a field affected by a business rule during that phase. The default Service Level Agreement workflow is shown as below. You may customize the Agreement workflow according to your business needs. Only the agreements in the Active phase are included in the SLT calculation. When you customize the process and rules for SLT calculation, also make sure that you use the OOTB \"Active\" phase when you enable an agreement. Metaphase: New Phase Transition Description New Manual The starting point for a Service Level Agreement. Use this phase to define Service Level Requirements. Next phase: Inactive or Approve Metaphase: Inactive Phase Transition Description Inactive Manual The Service Level Agreement is being edited but isn't yet active. Next phase: Ap",
    "url": "slawflw",
    "filename": "slawflw",
    "headings": [
      "Metaphase: New",
      "Metaphase: Inactive",
      "Metaphase: Active",
      "Metaphase: Retired (End)",
      "Related topics"
    ],
    "keywords": [
      "service",
      "level",
      "agreement",
      "workflow",
      "metaphase",
      "new",
      "inactive",
      "active",
      "retired",
      "end",
      "related",
      "topics",
      "section",
      "describes",
      "metaphases",
      "subordinate",
      "phases",
      "life",
      "cycle",
      "agreement.",
      "relies",
      "business",
      "rules.",
      "rules",
      "repeat",
      "one",
      "phase",
      "another",
      "user",
      "make",
      "change",
      "field",
      "affected",
      "rule",
      "during",
      "phase.",
      "default",
      "shown",
      "below.",
      "customize",
      "according",
      "needs.",
      "agreements",
      "included",
      "slt",
      "calculation.",
      "process",
      "calculation",
      "sure",
      "ootb",
      "enable",
      "transition",
      "description",
      "manual",
      "starting",
      "point",
      "define",
      "requirements.",
      "next",
      "approve",
      "edited",
      "isn",
      "yet",
      "active.",
      "automatic",
      "there",
      "approval",
      "task",
      "configured",
      "move",
      "approved",
      "denied",
      "inactive.",
      "fully",
      "operation.",
      "currently",
      "out",
      "operation",
      "available",
      "future",
      "later",
      "use.",
      "expired",
      "historic",
      "reference.",
      "longer",
      "available.",
      "none",
      "management",
      "procedures"
    ],
    "language": "en",
    "word_count": 106,
    "importance_score": 5.5,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "service level agreement workflow",
    "contentLower": "this section describes the metaphases and subordinate phases in the life cycle of a service level agreement. the service level agreement workflow relies on business rules. rules repeat from one phase to another when the end user can make a change to a field affected by a business rule during that phase. the default service level agreement workflow is shown as below. you may customize the agreement workflow according to your business needs. only the agreements in the active phase are included in the slt calculation. when you customize the process and rules for slt calculation, also make sure that you use the ootb \"active\" phase when you enable an agreement. metaphase: new phase transition description new manual the starting point for a service level agreement. use this phase to define service level requirements. next phase: inactive or approve metaphase: inactive phase transition description inactive manual the service level agreement is being edited but isn't yet active. next phase: ap",
    "keywordsLower": [
      "service",
      "level",
      "agreement",
      "workflow",
      "metaphase",
      "new",
      "inactive",
      "active",
      "retired",
      "end",
      "related",
      "topics",
      "section",
      "describes",
      "metaphases",
      "subordinate",
      "phases",
      "life",
      "cycle",
      "agreement.",
      "relies",
      "business",
      "rules.",
      "rules",
      "repeat",
      "one",
      "phase",
      "another",
      "user",
      "make",
      "change",
      "field",
      "affected",
      "rule",
      "during",
      "phase.",
      "default",
      "shown",
      "below.",
      "customize",
      "according",
      "needs.",
      "agreements",
      "included",
      "slt",
      "calculation.",
      "process",
      "calculation",
      "sure",
      "ootb",
      "enable",
      "transition",
      "description",
      "manual",
      "starting",
      "point",
      "define",
      "requirements.",
      "next",
      "approve",
      "edited",
      "isn",
      "yet",
      "active.",
      "automatic",
      "there",
      "approval",
      "task",
      "configured",
      "move",
      "approved",
      "denied",
      "inactive.",
      "fully",
      "operation.",
      "currently",
      "out",
      "operation",
      "available",
      "future",
      "later",
      "use.",
      "expired",
      "historic",
      "reference.",
      "longer",
      "available.",
      "none",
      "management",
      "procedures"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Service Level Management procedures",
    "content": "If you are responsible for creating and monitoring Service Level Targets, you also work with customers to define the Service Level Agreements that describe your service objectives. A Service Level Target set links to a Service Level Agreement. When you define a Service Level Agreement, you must specify the name of a Service Level Target set that links to the Service Level Agreement. To define a Service Level Agreement: Create a Service Level Target set. (Optional) Manage custom target types. Create Target Definition for each Target type. Manage operation rules for each target type in Studio or in Target Set. Create a Service Level Agreement that points to the Service Level Target set. Relating Service Level Agreements to records. Note If you have the Service Management sample data deployed in your environment, you can see fully working examples of Service Level Management configuration. Related topics How to create a Service Level Target set record How to edit a Service Level Target se",
    "url": "slmtasks",
    "filename": "slmtasks",
    "headings": [
      "Related topics"
    ],
    "keywords": [
      "service",
      "level",
      "management",
      "procedures",
      "related",
      "topics",
      "responsible",
      "creating",
      "monitoring",
      "targets",
      "work",
      "customers",
      "define",
      "agreements",
      "describe",
      "objectives.",
      "target",
      "set",
      "links",
      "agreement.",
      "agreement",
      "specify",
      "name",
      "create",
      "set.",
      "optional",
      "manage",
      "custom",
      "types.",
      "definition",
      "type.",
      "operation",
      "rules",
      "type",
      "studio",
      "points",
      "relating",
      "records.",
      "note",
      "sample",
      "data",
      "deployed",
      "environment",
      "see",
      "fully",
      "working",
      "examples",
      "configuration.",
      "record",
      "edit",
      "add"
    ],
    "language": "en",
    "word_count": 110,
    "importance_score": 3.5,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "service level management procedures",
    "contentLower": "if you are responsible for creating and monitoring service level targets, you also work with customers to define the service level agreements that describe your service objectives. a service level target set links to a service level agreement. when you define a service level agreement, you must specify the name of a service level target set that links to the service level agreement. to define a service level agreement: create a service level target set. (optional) manage custom target types. create target definition for each target type. manage operation rules for each target type in studio or in target set. create a service level agreement that points to the service level target set. relating service level agreements to records. note if you have the service management sample data deployed in your environment, you can see fully working examples of service level management configuration. related topics how to create a service level target set record how to edit a service level target se",
    "keywordsLower": [
      "service",
      "level",
      "management",
      "procedures",
      "related",
      "topics",
      "responsible",
      "creating",
      "monitoring",
      "targets",
      "work",
      "customers",
      "define",
      "agreements",
      "describe",
      "objectives.",
      "target",
      "set",
      "links",
      "agreement.",
      "agreement",
      "specify",
      "name",
      "create",
      "set.",
      "optional",
      "manage",
      "custom",
      "types.",
      "definition",
      "type.",
      "operation",
      "rules",
      "type",
      "studio",
      "points",
      "relating",
      "records.",
      "note",
      "sample",
      "data",
      "deployed",
      "environment",
      "see",
      "fully",
      "working",
      "examples",
      "configuration.",
      "record",
      "edit",
      "add"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Relating Service Level Agreements to records",
    "content": "The service level targets for a Request, Incident, Change, Task, Problem, and custom record are based on Service Level Agreements as follows: For Service Requests and HR Requests, generally, Service Level Targets are based on the agreement associated with the underlying offering. For Support Requests, Incidents, Changes, Tasks, Problems, and customized record types, generally, Service Level Targets are based on the Service associated with the record. If no specific agreement is defined for the service, the default agreement is used. For Case Requests, Service Level Targets are based on the agreement associated with the underlying offering. If no specific agreement is defined for the underlying offering, the Service Level Targets are based on the service associated with the request. If no specific agreement is defined for the service, the default agreement is used. The table below provides an overview of the available methods to relate a Service Level Agreement to a record: Service Leve",
    "url": "offeringsla",
    "filename": "offeringsla",
    "headings": [],
    "keywords": [
      "relating",
      "service",
      "level",
      "agreements",
      "records",
      "targets",
      "request",
      "incident",
      "change",
      "task",
      "problem",
      "custom",
      "record",
      "based",
      "follows",
      "requests",
      "hr",
      "generally",
      "agreement",
      "associated",
      "underlying",
      "offering.",
      "support",
      "incidents",
      "changes",
      "tasks",
      "problems",
      "customized",
      "types",
      "record.",
      "specific",
      "defined",
      "default",
      "used.",
      "case",
      "offering",
      "request.",
      "table",
      "below",
      "provides",
      "overview",
      "available",
      "methods",
      "relate",
      "applicable",
      "sla",
      "ola",
      "field",
      "set",
      "one",
      "following",
      "note",
      "there",
      "requests.",
      "business",
      "rule",
      "created",
      "system",
      "applies",
      "priorities",
      "applied",
      "empty.",
      "item",
      "above",
      "true",
      "same",
      "target",
      "type",
      "applied.",
      "neither",
      "nor",
      "none",
      "value",
      "specified",
      "values",
      "tab",
      "model.",
      "human",
      "resources",
      "different",
      "agreements.",
      "all",
      "possible",
      "define",
      "ways",
      "via",
      "sets",
      "uc",
      "required",
      "agreement.",
      "such",
      "studio",
      "module.",
      "information",
      "defining",
      "rules",
      "see",
      "add",
      "rule.",
      "rules."
    ],
    "language": "en",
    "word_count": 99,
    "importance_score": 2.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "relating service level agreements to records",
    "contentLower": "the service level targets for a request, incident, change, task, problem, and custom record are based on service level agreements as follows: for service requests and hr requests, generally, service level targets are based on the agreement associated with the underlying offering. for support requests, incidents, changes, tasks, problems, and customized record types, generally, service level targets are based on the service associated with the record. if no specific agreement is defined for the service, the default agreement is used. for case requests, service level targets are based on the agreement associated with the underlying offering. if no specific agreement is defined for the underlying offering, the service level targets are based on the service associated with the request. if no specific agreement is defined for the service, the default agreement is used. the table below provides an overview of the available methods to relate a service level agreement to a record: service leve",
    "keywordsLower": [
      "relating",
      "service",
      "level",
      "agreements",
      "records",
      "targets",
      "request",
      "incident",
      "change",
      "task",
      "problem",
      "custom",
      "record",
      "based",
      "follows",
      "requests",
      "hr",
      "generally",
      "agreement",
      "associated",
      "underlying",
      "offering.",
      "support",
      "incidents",
      "changes",
      "tasks",
      "problems",
      "customized",
      "types",
      "record.",
      "specific",
      "defined",
      "default",
      "used.",
      "case",
      "offering",
      "request.",
      "table",
      "below",
      "provides",
      "overview",
      "available",
      "methods",
      "relate",
      "applicable",
      "sla",
      "ola",
      "field",
      "set",
      "one",
      "following",
      "note",
      "there",
      "requests.",
      "business",
      "rule",
      "created",
      "system",
      "applies",
      "priorities",
      "applied",
      "empty.",
      "item",
      "above",
      "true",
      "same",
      "target",
      "type",
      "applied.",
      "neither",
      "nor",
      "none",
      "value",
      "specified",
      "values",
      "tab",
      "model.",
      "human",
      "resources",
      "different",
      "agreements.",
      "all",
      "possible",
      "define",
      "ways",
      "via",
      "sets",
      "uc",
      "required",
      "agreement.",
      "such",
      "studio",
      "module.",
      "information",
      "defining",
      "rules",
      "see",
      "add",
      "rule.",
      "rules."
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Retire an agreement model",
    "content": "To retire an agreement model means changing its status, as shown in the workflow snapshot at the top of the model, from Active to Inactive. You must have the appropriate permissions to be able to retire an agreement model. If you retire an agreement model, this has no effect on existing service level agreement records. From the main menu, select Plan > Service Level > Agreement Models. Click the record identifier in the Id column to display the selected model. Click Retired. Click Save on the toolbar. Related topics How to create an agreement model How to edit an agreement model",
    "url": "retireagreementmodel",
    "filename": "retireagreementmodel",
    "headings": [
      "Related topics"
    ],
    "keywords": [
      "retire",
      "agreement",
      "model",
      "related",
      "topics",
      "means",
      "changing",
      "status",
      "shown",
      "workflow",
      "snapshot",
      "top",
      "active",
      "inactive.",
      "appropriate",
      "permissions",
      "able",
      "model.",
      "effect",
      "existing",
      "service",
      "level",
      "records.",
      "main",
      "menu",
      "select",
      "plan",
      "models.",
      "click",
      "record",
      "identifier",
      "id",
      "column",
      "display",
      "selected",
      "retired.",
      "save",
      "toolbar.",
      "create",
      "edit"
    ],
    "language": "en",
    "word_count": 60,
    "importance_score": 3.5,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "retire an agreement model",
    "contentLower": "to retire an agreement model means changing its status, as shown in the workflow snapshot at the top of the model, from active to inactive. you must have the appropriate permissions to be able to retire an agreement model. if you retire an agreement model, this has no effect on existing service level agreement records. from the main menu, select plan > service level > agreement models. click the record identifier in the id column to display the selected model. click retired. click save on the toolbar. related topics how to create an agreement model how to edit an agreement model",
    "keywordsLower": [
      "retire",
      "agreement",
      "model",
      "related",
      "topics",
      "means",
      "changing",
      "status",
      "shown",
      "workflow",
      "snapshot",
      "top",
      "active",
      "inactive.",
      "appropriate",
      "permissions",
      "able",
      "model.",
      "effect",
      "existing",
      "service",
      "level",
      "records.",
      "main",
      "menu",
      "select",
      "plan",
      "models.",
      "click",
      "record",
      "identifier",
      "id",
      "column",
      "display",
      "selected",
      "retired.",
      "save",
      "toolbar.",
      "create",
      "edit"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Service Level Management ITIL process",
    "content": "The Service Management Service Level Management module helps the organization deliver the services that customers need. Service Level Management also helps the organization manage costs and risks along with services. Service Level Management is a component of the ITIL 3 Service Design process. The focus of Service Level Management are Service Level Agreements that your organization negotiates with internal and external customers. These Service Level Agreements have performance targets that measure the quality of service delivery. When you monitor how well the organization meets these Service Level Targets, you can produce reports that describe past performance and drive service improvements. When you use Service Level Management, you are able to apply consistent measurement and performance standards to your organization's services. Service Level Management best practices If you implement Service Level Management, you can achieve the following goals: Ensure that the services described i",
    "url": "slmitilprocess",
    "filename": "slmitilprocess",
    "headings": [
      "Service Level Management best practices",
      "Service Level Management input and output",
      "Service Level Management key performance indicators",
      "Related topics"
    ],
    "keywords": [
      "service",
      "level",
      "management",
      "itil",
      "process",
      "best",
      "practices",
      "input",
      "output",
      "key",
      "performance",
      "indicators",
      "related",
      "topics",
      "module",
      "helps",
      "organization",
      "deliver",
      "services",
      "customers",
      "need.",
      "manage",
      "costs",
      "risks",
      "along",
      "services.",
      "component",
      "design",
      "process.",
      "focus",
      "agreements",
      "negotiates",
      "internal",
      "external",
      "customers.",
      "targets",
      "measure",
      "quality",
      "delivery.",
      "monitor",
      "well",
      "meets",
      "produce",
      "reports",
      "describe",
      "past",
      "drive",
      "improvements.",
      "able",
      "apply",
      "consistent",
      "measurement",
      "standards",
      "implement",
      "achieve",
      "following",
      "goals",
      "ensure",
      "described",
      "agreement",
      "delivered",
      "promised.",
      "interface",
      "incident",
      "problem",
      "make",
      "sure",
      "required",
      "available",
      "reasonable",
      "levels",
      "quality.",
      "align",
      "delivery",
      "catalog",
      "items.",
      "supports",
      "embedded",
      "processes",
      "workflows.",
      "depends",
      "negotiated",
      "agreements.",
      "contain",
      "all",
      "information",
      "description",
      "response",
      "times",
      "customer",
      "responsibilities",
      "hours",
      "availability",
      "initial",
      "review",
      "resolution",
      "approval",
      "fulfillment",
      "operational",
      "time"
    ],
    "language": "en",
    "word_count": 99,
    "importance_score": 5.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "service level management itil process",
    "contentLower": "the service management service level management module helps the organization deliver the services that customers need. service level management also helps the organization manage costs and risks along with services. service level management is a component of the itil 3 service design process. the focus of service level management are service level agreements that your organization negotiates with internal and external customers. these service level agreements have performance targets that measure the quality of service delivery. when you monitor how well the organization meets these service level targets, you can produce reports that describe past performance and drive service improvements. when you use service level management, you are able to apply consistent measurement and performance standards to your organization's services. service level management best practices if you implement service level management, you can achieve the following goals: ensure that the services described i",
    "keywordsLower": [
      "service",
      "level",
      "management",
      "itil",
      "process",
      "best",
      "practices",
      "input",
      "output",
      "key",
      "performance",
      "indicators",
      "related",
      "topics",
      "module",
      "helps",
      "organization",
      "deliver",
      "services",
      "customers",
      "need.",
      "manage",
      "costs",
      "risks",
      "along",
      "services.",
      "component",
      "design",
      "process.",
      "focus",
      "agreements",
      "negotiates",
      "internal",
      "external",
      "customers.",
      "targets",
      "measure",
      "quality",
      "delivery.",
      "monitor",
      "well",
      "meets",
      "produce",
      "reports",
      "describe",
      "past",
      "drive",
      "improvements.",
      "able",
      "apply",
      "consistent",
      "measurement",
      "standards",
      "implement",
      "achieve",
      "following",
      "goals",
      "ensure",
      "described",
      "agreement",
      "delivered",
      "promised.",
      "interface",
      "incident",
      "problem",
      "make",
      "sure",
      "required",
      "available",
      "reasonable",
      "levels",
      "quality.",
      "align",
      "delivery",
      "catalog",
      "items.",
      "supports",
      "embedded",
      "processes",
      "workflows.",
      "depends",
      "negotiated",
      "agreements.",
      "contain",
      "all",
      "information",
      "description",
      "response",
      "times",
      "customer",
      "responsibilities",
      "hours",
      "availability",
      "initial",
      "review",
      "resolution",
      "approval",
      "fulfillment",
      "operational",
      "time"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Service Level Target calculations",
    "content": "Service Management offers a complete set of Service Level Target (SLT) definitions for incident, request, change, task, problem, and custom records. As a Service Management administrator, you can change the default behavior of these built-in target definitions by editing the Service Level Target definition records. Calculations Service Management runs a backend scheduler job to calculate the elapsed time for each Service Level Target. The calculation frequency varies—Service Management decides the next calculation time by considering two factors: an interval that varies according to the time left or overdue compared with the target time of a Service Level Target. The less time left or overdue, the smaller interval. The smallest interval is one minute, and the largest is one day. an interval that is equal to one percent (1%) of the duration of the SLT definition. Service Management calculates two next calculation time values according to the two intervals, and chooses whichever is soone",
    "url": "sltcalculations",
    "filename": "sltcalculations",
    "headings": [
      "Calculations",
      "SLT-related fields in a record",
      "Actual service or offering in a record",
      "Process type of a record",
      "Timezone and work schedule",
      "New chat request",
      "Notifications",
      "Related topics"
    ],
    "keywords": [
      "SLT.Next",
      "service",
      "level",
      "target",
      "calculations",
      "slt-related",
      "fields",
      "record",
      "actual",
      "offering",
      "process",
      "type",
      "timezone",
      "work",
      "schedule",
      "new",
      "chat",
      "request",
      "notifications",
      "related",
      "topics",
      "management",
      "offers",
      "complete",
      "set",
      "slt",
      "definitions",
      "incident",
      "change",
      "task",
      "problem",
      "custom",
      "records.",
      "administrator",
      "default",
      "behavior",
      "built-in",
      "editing",
      "definition",
      "runs",
      "backend",
      "scheduler",
      "job",
      "calculate",
      "elapsed",
      "time",
      "target.",
      "calculation",
      "frequency",
      "varies",
      "decides",
      "next",
      "considering",
      "two",
      "factors",
      "interval",
      "according",
      "left",
      "overdue",
      "compared",
      "less",
      "smaller",
      "interval.",
      "smallest",
      "one",
      "minute",
      "largest",
      "day.",
      "equal",
      "percent",
      "duration",
      "definition.",
      "calculates",
      "values",
      "intervals",
      "chooses",
      "whichever",
      "sooner.",
      "start",
      "rule",
      "runs.",
      "details",
      "about",
      "durations",
      "targets",
      "see",
      "details.",
      "pay",
      "attention",
      "affect",
      "described",
      "below.",
      "update",
      "any",
      "sla",
      "ola",
      "priority",
      "assignment",
      "group",
      "customer"
    ],
    "language": "en",
    "word_count": 108,
    "importance_score": 6.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "service level target calculations",
    "contentLower": "service management offers a complete set of service level target (slt) definitions for incident, request, change, task, problem, and custom records. as a service management administrator, you can change the default behavior of these built-in target definitions by editing the service level target definition records. calculations service management runs a backend scheduler job to calculate the elapsed time for each service level target. the calculation frequency varies—service management decides the next calculation time by considering two factors: an interval that varies according to the time left or overdue compared with the target time of a service level target. the less time left or overdue, the smaller interval. the smallest interval is one minute, and the largest is one day. an interval that is equal to one percent (1%) of the duration of the slt definition. service management calculates two next calculation time values according to the two intervals, and chooses whichever is soone",
    "keywordsLower": [
      "slt.next",
      "service",
      "level",
      "target",
      "calculations",
      "slt-related",
      "fields",
      "record",
      "actual",
      "offering",
      "process",
      "type",
      "timezone",
      "work",
      "schedule",
      "new",
      "chat",
      "request",
      "notifications",
      "related",
      "topics",
      "management",
      "offers",
      "complete",
      "set",
      "slt",
      "definitions",
      "incident",
      "change",
      "task",
      "problem",
      "custom",
      "records.",
      "administrator",
      "default",
      "behavior",
      "built-in",
      "editing",
      "definition",
      "runs",
      "backend",
      "scheduler",
      "job",
      "calculate",
      "elapsed",
      "time",
      "target.",
      "calculation",
      "frequency",
      "varies",
      "decides",
      "next",
      "considering",
      "two",
      "factors",
      "interval",
      "according",
      "left",
      "overdue",
      "compared",
      "less",
      "smaller",
      "interval.",
      "smallest",
      "one",
      "minute",
      "largest",
      "day.",
      "equal",
      "percent",
      "duration",
      "definition.",
      "calculates",
      "values",
      "intervals",
      "chooses",
      "whichever",
      "sooner.",
      "start",
      "rule",
      "runs.",
      "details",
      "about",
      "durations",
      "targets",
      "see",
      "details.",
      "pay",
      "attention",
      "affect",
      "described",
      "below.",
      "update",
      "any",
      "sla",
      "ola",
      "priority",
      "assignment",
      "group",
      "customer"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Service Level Target duration",
    "content": "When you define a Service Level Target, you must specify a duration value. The duration is the amount of time that the Service Desk has to meet the target objectives. For details on how Service Management calculates duration for Service Level Targets, see the Service Level Target duration calculation details section. For an Initial Review target, duration is the acceptable amount of time that the Service Desk has to complete all activities related to logging, categorizing, and assigning an incident to an analyst. Defining a reasonable amount of time to complete this work sets appropriate expectations between the Service Desk and the customer for an acceptable response. For a Resolution target, duration is the acceptable amount of time that the assignment group or individual has to completely resolve the issue to the customer's satisfaction. This includes the actual work, review, and closure of the incident. For a Chat request target in Request records, duration is the acceptable amount",
    "url": "sltduration",
    "filename": "sltduration",
    "headings": [
      "Service Level Target duration calculation details",
      "Related topics"
    ],
    "keywords": [
      "17.00",
      "09.00",
      "service",
      "level",
      "target",
      "duration",
      "calculation",
      "details",
      "related",
      "topics",
      "define",
      "specify",
      "value.",
      "amount",
      "time",
      "desk",
      "meet",
      "objectives.",
      "management",
      "calculates",
      "targets",
      "see",
      "section.",
      "initial",
      "review",
      "acceptable",
      "complete",
      "all",
      "activities",
      "logging",
      "categorizing",
      "assigning",
      "incident",
      "analyst.",
      "defining",
      "reasonable",
      "work",
      "sets",
      "appropriate",
      "expectations",
      "between",
      "customer",
      "response.",
      "resolution",
      "assignment",
      "group",
      "individual",
      "completely",
      "resolve",
      "issue",
      "satisfaction.",
      "includes",
      "actual",
      "closure",
      "incident.",
      "chat",
      "request",
      "records",
      "agent",
      "respond",
      "request.",
      "approval",
      "approver",
      "approve",
      "ticket.",
      "fulfillment",
      "fulfilled.",
      "ola",
      "permitted",
      "group.",
      "consistently",
      "meets",
      "defined",
      "satisfaction",
      "improves.",
      "find",
      "slt",
      "progress",
      "bar",
      "top-right",
      "corner",
      "page.",
      "visually",
      "shows",
      "much",
      "ve",
      "got",
      "left",
      "until",
      "next",
      "sla",
      "time.",
      "following",
      "table",
      "supporting",
      "notes",
      "show",
      "durations",
      "available",
      "data"
    ],
    "language": "en",
    "word_count": 97,
    "importance_score": 4.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "service level target duration",
    "contentLower": "when you define a service level target, you must specify a duration value. the duration is the amount of time that the service desk has to meet the target objectives. for details on how service management calculates duration for service level targets, see the service level target duration calculation details section. for an initial review target, duration is the acceptable amount of time that the service desk has to complete all activities related to logging, categorizing, and assigning an incident to an analyst. defining a reasonable amount of time to complete this work sets appropriate expectations between the service desk and the customer for an acceptable response. for a resolution target, duration is the acceptable amount of time that the assignment group or individual has to completely resolve the issue to the customer's satisfaction. this includes the actual work, review, and closure of the incident. for a chat request target in request records, duration is the acceptable amount",
    "keywordsLower": [
      "17.00",
      "09.00",
      "service",
      "level",
      "target",
      "duration",
      "calculation",
      "details",
      "related",
      "topics",
      "define",
      "specify",
      "value.",
      "amount",
      "time",
      "desk",
      "meet",
      "objectives.",
      "management",
      "calculates",
      "targets",
      "see",
      "section.",
      "initial",
      "review",
      "acceptable",
      "complete",
      "all",
      "activities",
      "logging",
      "categorizing",
      "assigning",
      "incident",
      "analyst.",
      "defining",
      "reasonable",
      "work",
      "sets",
      "appropriate",
      "expectations",
      "between",
      "customer",
      "response.",
      "resolution",
      "assignment",
      "group",
      "individual",
      "completely",
      "resolve",
      "issue",
      "satisfaction.",
      "includes",
      "actual",
      "closure",
      "incident.",
      "chat",
      "request",
      "records",
      "agent",
      "respond",
      "request.",
      "approval",
      "approver",
      "approve",
      "ticket.",
      "fulfillment",
      "fulfilled.",
      "ola",
      "permitted",
      "group.",
      "consistently",
      "meets",
      "defined",
      "satisfaction",
      "improves.",
      "find",
      "slt",
      "progress",
      "bar",
      "top-right",
      "corner",
      "page.",
      "visually",
      "shows",
      "much",
      "ve",
      "got",
      "left",
      "until",
      "next",
      "sla",
      "time.",
      "following",
      "table",
      "supporting",
      "notes",
      "show",
      "durations",
      "available",
      "data"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Service Level Target status and history",
    "content": "You can measure service availability with performance objectives, or targets. If you agree on availability standards, and the organization fails to meet them, the performance targets are breached. A breach occurs when a reasonable amount of time to complete the objective is defined, but the record has not moved to the next state when that amount of time has passed. Service Level Target status The Service Level Targets section of any record with a linked target shows a table of achievement and status data. Next target time. This field shows a value as long as there is a target with an Active status. Example: If a Service Level Target with Active status passes the target date, its status changes to Breached. The Next target time isn't updated. Example: If a Service Level Target with Active Status is suspended, the Next target time changes to one of the following values: The next target date that's active. Blank if there are no other targets. Field Description Name The related Service Lev",
    "url": "sltstatus",
    "filename": "sltstatus",
    "headings": [
      "Service Level Target status",
      "Related topics"
    ],
    "keywords": [
      "service",
      "level",
      "target",
      "status",
      "history",
      "related",
      "topics",
      "measure",
      "availability",
      "performance",
      "objectives",
      "targets.",
      "agree",
      "standards",
      "organization",
      "fails",
      "meet",
      "targets",
      "breached.",
      "breach",
      "occurs",
      "reasonable",
      "amount",
      "time",
      "complete",
      "objective",
      "defined",
      "record",
      "moved",
      "next",
      "state",
      "passed.",
      "section",
      "any",
      "linked",
      "shows",
      "table",
      "achievement",
      "data.",
      "time.",
      "field",
      "value",
      "long",
      "there",
      "active",
      "status.",
      "example",
      "passes",
      "date",
      "changes",
      "isn",
      "updated.",
      "suspended",
      "one",
      "following",
      "values",
      "active.",
      "blank",
      "description",
      "name",
      "definition",
      "current",
      "target.",
      "default",
      "agreement",
      "defined.",
      "started",
      "workflow",
      "triggered",
      "start",
      "rule",
      "yet.",
      "chat",
      "request",
      "user",
      "yet",
      "submitted",
      "request.",
      "allowable",
      "interval",
      "expired.",
      "incident",
      "categorized",
      "two",
      "hours",
      "remain",
      "before",
      "initial",
      "review",
      "desk",
      "agent",
      "suspends",
      "type",
      "stop",
      "calculation",
      "requests",
      "information",
      "customer.",
      "until",
      "receives"
    ],
    "language": "en",
    "word_count": 109,
    "importance_score": 3.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "service level target status and history",
    "contentLower": "you can measure service availability with performance objectives, or targets. if you agree on availability standards, and the organization fails to meet them, the performance targets are breached. a breach occurs when a reasonable amount of time to complete the objective is defined, but the record has not moved to the next state when that amount of time has passed. service level target status the service level targets section of any record with a linked target shows a table of achievement and status data. next target time. this field shows a value as long as there is a target with an active status. example: if a service level target with active status passes the target date, its status changes to breached. the next target time isn't updated. example: if a service level target with active status is suspended, the next target time changes to one of the following values: the next target date that's active. blank if there are no other targets. field description name the related service lev",
    "keywordsLower": [
      "service",
      "level",
      "target",
      "status",
      "history",
      "related",
      "topics",
      "measure",
      "availability",
      "performance",
      "objectives",
      "targets.",
      "agree",
      "standards",
      "organization",
      "fails",
      "meet",
      "targets",
      "breached.",
      "breach",
      "occurs",
      "reasonable",
      "amount",
      "time",
      "complete",
      "objective",
      "defined",
      "record",
      "moved",
      "next",
      "state",
      "passed.",
      "section",
      "any",
      "linked",
      "shows",
      "table",
      "achievement",
      "data.",
      "time.",
      "field",
      "value",
      "long",
      "there",
      "active",
      "status.",
      "example",
      "passes",
      "date",
      "changes",
      "isn",
      "updated.",
      "suspended",
      "one",
      "following",
      "values",
      "active.",
      "blank",
      "description",
      "name",
      "definition",
      "current",
      "target.",
      "default",
      "agreement",
      "defined.",
      "started",
      "workflow",
      "triggered",
      "start",
      "rule",
      "yet.",
      "chat",
      "request",
      "user",
      "yet",
      "submitted",
      "request.",
      "allowable",
      "interval",
      "expired.",
      "incident",
      "categorized",
      "two",
      "hours",
      "remain",
      "before",
      "initial",
      "review",
      "desk",
      "agent",
      "suspends",
      "type",
      "stop",
      "calculation",
      "requests",
      "information",
      "customer.",
      "until",
      "receives"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Service Level Management and reports",
    "content": "Service Management's reporting functionality allows you to see how your Service Level Management is performing, using out-of-the-box reports, or reports that you create. The available out-of-the-box reports include: Average elapsed duration for incidents and requests by priority, service, or group Chat request response achievement rate Initial review and resolution achievement rate for incidents and requests SLT achievement percentage for incidents SLT achievement percentage for incidents in initial review or resolution by owning group, priority, or service SLT achievement percentage for requests SLT achievement percentage for requests in chat request response by assignment group, priority, or service SLT achievement percentage for requests in initial review by assignment group, priority, or service SLT achievement percentage for requests in resolution by assignment group, priority, or service SLT overall report by record and target type Status of active Fulfillment SLTs Status of acti",
    "url": "slmreports",
    "filename": "slmreports",
    "headings": [
      "Related topics"
    ],
    "keywords": [
      "service",
      "level",
      "management",
      "reports",
      "related",
      "topics",
      "reporting",
      "functionality",
      "allows",
      "see",
      "performing",
      "out-of-the-box",
      "create.",
      "available",
      "include",
      "average",
      "elapsed",
      "duration",
      "incidents",
      "requests",
      "priority",
      "group",
      "chat",
      "request",
      "response",
      "achievement",
      "rate",
      "initial",
      "review",
      "resolution",
      "slt",
      "percentage",
      "owning",
      "assignment",
      "overall",
      "report",
      "record",
      "target",
      "type",
      "status",
      "active",
      "fulfillment",
      "slts",
      "time",
      "olts",
      "analysis",
      "load",
      "ola",
      "results",
      "team",
      "changes",
      "classification",
      "deployment",
      "planning",
      "validation",
      "tasks",
      "completion",
      "per",
      "problems",
      "find",
      "following",
      "widget",
      "change",
      "dashboard",
      "task",
      "overview",
      "critical",
      "due",
      "today",
      "problem",
      "category",
      "unassigned",
      "information",
      "create",
      "performance",
      "work",
      "reports.",
      "creating",
      "editing",
      "select",
      "field",
      "one",
      "grouping",
      "options",
      "report.",
      "represents",
      "percent",
      "already",
      "passed.",
      "properties.",
      "properties",
      "calculations",
      "history"
    ],
    "language": "en",
    "word_count": 104,
    "importance_score": 3.5,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "service level management and reports",
    "contentLower": "service management's reporting functionality allows you to see how your service level management is performing, using out-of-the-box reports, or reports that you create. the available out-of-the-box reports include: average elapsed duration for incidents and requests by priority, service, or group chat request response achievement rate initial review and resolution achievement rate for incidents and requests slt achievement percentage for incidents slt achievement percentage for incidents in initial review or resolution by owning group, priority, or service slt achievement percentage for requests slt achievement percentage for requests in chat request response by assignment group, priority, or service slt achievement percentage for requests in initial review by assignment group, priority, or service slt achievement percentage for requests in resolution by assignment group, priority, or service slt overall report by record and target type status of active fulfillment slts status of acti",
    "keywordsLower": [
      "service",
      "level",
      "management",
      "reports",
      "related",
      "topics",
      "reporting",
      "functionality",
      "allows",
      "see",
      "performing",
      "out-of-the-box",
      "create.",
      "available",
      "include",
      "average",
      "elapsed",
      "duration",
      "incidents",
      "requests",
      "priority",
      "group",
      "chat",
      "request",
      "response",
      "achievement",
      "rate",
      "initial",
      "review",
      "resolution",
      "slt",
      "percentage",
      "owning",
      "assignment",
      "overall",
      "report",
      "record",
      "target",
      "type",
      "status",
      "active",
      "fulfillment",
      "slts",
      "time",
      "olts",
      "analysis",
      "load",
      "ola",
      "results",
      "team",
      "changes",
      "classification",
      "deployment",
      "planning",
      "validation",
      "tasks",
      "completion",
      "per",
      "problems",
      "find",
      "following",
      "widget",
      "change",
      "dashboard",
      "task",
      "overview",
      "critical",
      "due",
      "today",
      "problem",
      "category",
      "unassigned",
      "information",
      "create",
      "performance",
      "work",
      "reports.",
      "creating",
      "editing",
      "select",
      "field",
      "one",
      "grouping",
      "options",
      "report.",
      "represents",
      "percent",
      "already",
      "passed.",
      "properties.",
      "properties",
      "calculations",
      "history"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Retire a brand record",
    "content": "You must have the appropriate permissions to be able to retire a brand. If you retire a brand, this has no effect on existing records. To retire a brand record means changing its status, as shown in the workflow snapshot at the top of the record, from Active to Inactive. For example, your company previously bought Dell PowerEdge Servers, and now it's time to retire them. You will replace them with HP PROLIANT servers. The brand “PowerEdge” is no longer in use, so you can retire it by moving its phase to Inactive. To retire a brand record: From the main menu, select Plan > Company > Brands. Select the brand record. To filter the record list, click the Add filter button. For more information, see Filters. Click the record identifier in the ID column to display the selected record. Click Inactive, then Save. Related topics Brands How to create a brand record How to edit a brand record",
    "url": "retirebrand",
    "filename": "retirebrand",
    "headings": [
      "Related topics"
    ],
    "keywords": [
      "retire",
      "brand",
      "record",
      "related",
      "topics",
      "appropriate",
      "permissions",
      "able",
      "brand.",
      "effect",
      "existing",
      "records.",
      "means",
      "changing",
      "status",
      "shown",
      "workflow",
      "snapshot",
      "top",
      "active",
      "inactive.",
      "example",
      "company",
      "previously",
      "bought",
      "dell",
      "poweredge",
      "servers",
      "now",
      "time",
      "them.",
      "replace",
      "hp",
      "proliant",
      "servers.",
      "longer",
      "moving",
      "phase",
      "main",
      "menu",
      "select",
      "plan",
      "brands.",
      "record.",
      "filter",
      "list",
      "click",
      "add",
      "button.",
      "information",
      "see",
      "filters.",
      "identifier",
      "id",
      "column",
      "display",
      "selected",
      "inactive",
      "save.",
      "brands",
      "create",
      "edit"
    ],
    "language": "en",
    "word_count": 91,
    "importance_score": 3.5,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "retire a brand record",
    "contentLower": "you must have the appropriate permissions to be able to retire a brand. if you retire a brand, this has no effect on existing records. to retire a brand record means changing its status, as shown in the workflow snapshot at the top of the record, from active to inactive. for example, your company previously bought dell poweredge servers, and now it's time to retire them. you will replace them with hp proliant servers. the brand “poweredge” is no longer in use, so you can retire it by moving its phase to inactive. to retire a brand record: from the main menu, select plan > company > brands. select the brand record. to filter the record list, click the add filter button. for more information, see filters. click the record identifier in the id column to display the selected record. click inactive, then save. related topics brands how to create a brand record how to edit a brand record",
    "keywordsLower": [
      "retire",
      "brand",
      "record",
      "related",
      "topics",
      "appropriate",
      "permissions",
      "able",
      "brand.",
      "effect",
      "existing",
      "records.",
      "means",
      "changing",
      "status",
      "shown",
      "workflow",
      "snapshot",
      "top",
      "active",
      "inactive.",
      "example",
      "company",
      "previously",
      "bought",
      "dell",
      "poweredge",
      "servers",
      "now",
      "time",
      "them.",
      "replace",
      "hp",
      "proliant",
      "servers.",
      "longer",
      "moving",
      "phase",
      "main",
      "menu",
      "select",
      "plan",
      "brands.",
      "record.",
      "filter",
      "list",
      "click",
      "add",
      "button.",
      "information",
      "see",
      "filters.",
      "identifier",
      "id",
      "column",
      "display",
      "selected",
      "inactive",
      "save.",
      "brands",
      "create",
      "edit"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Sold license workflow",
    "content": "This page explains the sold license workflow and the steps to perform the following tasks: View workflow and current phase of sold license Change phase of sold license Sold license workflow The sold license workflow describes the different metaphases and phases in the lifecycle of a sold license. Metaphases represent broad stages in the lifecycle, while phases are the specific steps within each stage. The workflow relies on business rules. Rules repeat from one phase to another when the end user can make a change to a field affected by a business rule during that phase. The following figure shows the sold license workflow. The following sections describe phases within each metaphase. Unavailable Phase Description Allowed transitions Transition type New After you create a license, it is in the New phase by default. New to Awaiting delivery, New to Delivered Manual Awaiting delivery The customer is awaiting delivery of the license from the publisher. Awaiting delivery to Delivered, Await",
    "url": "managelicenseworkflow",
    "filename": "managelicenseworkflow",
    "headings": [
      "Sold license workflow",
      "Unavailable",
      "Available",
      "Ended (End)",
      "View workflow and current phase of sold license",
      "Change phase of sold license"
    ],
    "keywords": [
      "sold",
      "license",
      "workflow",
      "unavailable",
      "available",
      "ended",
      "end",
      "view",
      "current",
      "phase",
      "change",
      "page",
      "explains",
      "steps",
      "perform",
      "following",
      "tasks",
      "describes",
      "different",
      "metaphases",
      "phases",
      "lifecycle",
      "license.",
      "represent",
      "broad",
      "stages",
      "while",
      "specific",
      "stage.",
      "relies",
      "business",
      "rules.",
      "rules",
      "repeat",
      "one",
      "another",
      "user",
      "make",
      "field",
      "affected",
      "rule",
      "during",
      "phase.",
      "figure",
      "shows",
      "workflow.",
      "sections",
      "describe",
      "metaphase.",
      "description",
      "allowed",
      "transitions",
      "transition",
      "type",
      "new",
      "after",
      "create",
      "default.",
      "awaiting",
      "delivery",
      "delivered",
      "manual",
      "customer",
      "publisher.",
      "canceled",
      "customer.",
      "expiring",
      "nearing",
      "date.",
      "inactive",
      "longer",
      "service.",
      "none",
      "software",
      "publisher",
      "fulfill",
      "order",
      "order.",
      "click",
      "plan",
      "company.",
      "companies",
      "dropdown",
      "licenses.",
      "id",
      "tab.",
      "displays",
      "highlighted",
      "blue.",
      "button",
      "upper-right",
      "side",
      "next",
      "select",
      "appropriate",
      "dropdown.",
      "save."
    ],
    "language": "en",
    "word_count": 106,
    "importance_score": 6.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "sold license workflow",
    "contentLower": "this page explains the sold license workflow and the steps to perform the following tasks: view workflow and current phase of sold license change phase of sold license sold license workflow the sold license workflow describes the different metaphases and phases in the lifecycle of a sold license. metaphases represent broad stages in the lifecycle, while phases are the specific steps within each stage. the workflow relies on business rules. rules repeat from one phase to another when the end user can make a change to a field affected by a business rule during that phase. the following figure shows the sold license workflow. the following sections describe phases within each metaphase. unavailable phase description allowed transitions transition type new after you create a license, it is in the new phase by default. new to awaiting delivery, new to delivered manual awaiting delivery the customer is awaiting delivery of the license from the publisher. awaiting delivery to delivered, await",
    "keywordsLower": [
      "sold",
      "license",
      "workflow",
      "unavailable",
      "available",
      "ended",
      "end",
      "view",
      "current",
      "phase",
      "change",
      "page",
      "explains",
      "steps",
      "perform",
      "following",
      "tasks",
      "describes",
      "different",
      "metaphases",
      "phases",
      "lifecycle",
      "license.",
      "represent",
      "broad",
      "stages",
      "while",
      "specific",
      "stage.",
      "relies",
      "business",
      "rules.",
      "rules",
      "repeat",
      "one",
      "another",
      "user",
      "make",
      "field",
      "affected",
      "rule",
      "during",
      "phase.",
      "figure",
      "shows",
      "workflow.",
      "sections",
      "describe",
      "metaphase.",
      "description",
      "allowed",
      "transitions",
      "transition",
      "type",
      "new",
      "after",
      "create",
      "default.",
      "awaiting",
      "delivery",
      "delivered",
      "manual",
      "customer",
      "publisher.",
      "canceled",
      "customer.",
      "expiring",
      "nearing",
      "date.",
      "inactive",
      "longer",
      "service.",
      "none",
      "software",
      "publisher",
      "fulfill",
      "order",
      "order.",
      "click",
      "plan",
      "company.",
      "companies",
      "dropdown",
      "licenses.",
      "id",
      "tab.",
      "displays",
      "highlighted",
      "blue.",
      "button",
      "upper-right",
      "side",
      "next",
      "select",
      "appropriate",
      "dropdown.",
      "save."
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Resource Types",
    "content": "Resource types are the resources that are available to an organization for planning capacity for portfolios, programs, and projects in Service Management. How to create a resource type Follow these steps to create a resource type in Service Management: Note To create and edit resource types, you must have the Resource Manager role, or other role that has Create and Update permissions on Resource type records. For more information about this role, see Default roles. From the main menu, select Plan > Idea & Proposal > Resource Type. Service Management displays a list of resource types. Click New. Service Management displays a New Resource Type dialog box to gather basic information. Service Management doesn't assign an ID until you save the resource type. Complete the following fields: Field Description Title Enter a title for the resource type. Description Enter a description that captures the details of the resource type. Click Save when you are finished.",
    "url": "resourcetypes",
    "filename": "resourcetypes",
    "headings": [
      "How to create a resource type"
    ],
    "keywords": [
      "resource",
      "types",
      "create",
      "type",
      "resources",
      "available",
      "organization",
      "planning",
      "capacity",
      "portfolios",
      "programs",
      "projects",
      "service",
      "management.",
      "follow",
      "steps",
      "management",
      "note",
      "edit",
      "manager",
      "role",
      "update",
      "permissions",
      "records.",
      "information",
      "about",
      "see",
      "default",
      "roles.",
      "main",
      "menu",
      "select",
      "plan",
      "idea",
      "proposal",
      "type.",
      "displays",
      "list",
      "types.",
      "click",
      "new.",
      "new",
      "dialog",
      "box",
      "gather",
      "basic",
      "information.",
      "doesn",
      "assign",
      "id",
      "until",
      "save",
      "complete",
      "following",
      "fields",
      "field",
      "description",
      "title",
      "enter",
      "captures",
      "details",
      "finished."
    ],
    "language": "en",
    "word_count": 102,
    "importance_score": 3.5,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "resource types",
    "contentLower": "resource types are the resources that are available to an organization for planning capacity for portfolios, programs, and projects in service management. how to create a resource type follow these steps to create a resource type in service management: note to create and edit resource types, you must have the resource manager role, or other role that has create and update permissions on resource type records. for more information about this role, see default roles. from the main menu, select plan > idea & proposal > resource type. service management displays a list of resource types. click new. service management displays a new resource type dialog box to gather basic information. service management doesn't assign an id until you save the resource type. complete the following fields: field description title enter a title for the resource type. description enter a description that captures the details of the resource type. click save when you are finished.",
    "keywordsLower": [
      "resource",
      "types",
      "create",
      "type",
      "resources",
      "available",
      "organization",
      "planning",
      "capacity",
      "portfolios",
      "programs",
      "projects",
      "service",
      "management.",
      "follow",
      "steps",
      "management",
      "note",
      "edit",
      "manager",
      "role",
      "update",
      "permissions",
      "records.",
      "information",
      "about",
      "see",
      "default",
      "roles.",
      "main",
      "menu",
      "select",
      "plan",
      "idea",
      "proposal",
      "type.",
      "displays",
      "list",
      "types.",
      "click",
      "new.",
      "new",
      "dialog",
      "box",
      "gather",
      "basic",
      "information.",
      "doesn",
      "assign",
      "id",
      "until",
      "save",
      "complete",
      "following",
      "fields",
      "field",
      "description",
      "title",
      "enter",
      "captures",
      "details",
      "finished."
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Timelines",
    "content": "A timeline is a graphic representation of lifecycle phases in a project or program, and the milestones contained in those phases. Timelines are used to monitor the progress of a program or project. A phase is defined by specifying a time range, with a start date and an end date. A milestone marks a specific point in time (on a date that you specify). To create a timeline In the Records section, click New. Service Management displays a New Timeline dialog box. Enter a title for the timeline and click Save. Note You can have multiple timelines, but only one can be active at a particular point in time. To activate a timeline Select a timeline in the list and click . To add phases to a timeline Click the title of a timeline in the list to display its details. Select the Phases tab. Click New phase to display the New phase dialog box. Enter a title for the phase, as well as its start and end dates. Note The dates of phases in a timeline can't overlap. Click Save. When you are finished addin",
    "url": "timelines",
    "filename": "timelines",
    "headings": [
      "To create a timeline",
      "To activate a timeline",
      "To add phases to a timeline",
      "To add milestones to a phase",
      "Related topics"
    ],
    "keywords": [
      "timelines",
      "create",
      "timeline",
      "activate",
      "add",
      "phases",
      "milestones",
      "phase",
      "related",
      "topics",
      "graphic",
      "representation",
      "lifecycle",
      "project",
      "program",
      "contained",
      "phases.",
      "monitor",
      "progress",
      "project.",
      "defined",
      "specifying",
      "time",
      "range",
      "start",
      "date",
      "end",
      "date.",
      "milestone",
      "marks",
      "specific",
      "point",
      "specify",
      "records",
      "section",
      "click",
      "new.",
      "service",
      "management",
      "displays",
      "new",
      "dialog",
      "box.",
      "enter",
      "title",
      "save.",
      "note",
      "multiple",
      "one",
      "active",
      "particular",
      "time.",
      "select",
      "list",
      "display",
      "details.",
      "tab.",
      "well",
      "dates.",
      "dates",
      "overlap.",
      "finished",
      "adding",
      "save",
      "main",
      "toolbar.",
      "after",
      "items",
      "automatically",
      "displayed.",
      "granularity",
      "chart",
      "selecting",
      "appropriate",
      "breakdown",
      "week",
      "month",
      "quarter",
      "year",
      "flag",
      "representing",
      "displayed",
      "along",
      "timeline.",
      "edit"
    ],
    "language": "en",
    "word_count": 101,
    "importance_score": 5.5,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "timelines",
    "contentLower": "a timeline is a graphic representation of lifecycle phases in a project or program, and the milestones contained in those phases. timelines are used to monitor the progress of a program or project. a phase is defined by specifying a time range, with a start date and an end date. a milestone marks a specific point in time (on a date that you specify). to create a timeline in the records section, click new. service management displays a new timeline dialog box. enter a title for the timeline and click save. note you can have multiple timelines, but only one can be active at a particular point in time. to activate a timeline select a timeline in the list and click . to add phases to a timeline click the title of a timeline in the list to display its details. select the phases tab. click new phase to display the new phase dialog box. enter a title for the phase, as well as its start and end dates. note the dates of phases in a timeline can't overlap. click save. when you are finished addin",
    "keywordsLower": [
      "timelines",
      "create",
      "timeline",
      "activate",
      "add",
      "phases",
      "milestones",
      "phase",
      "related",
      "topics",
      "graphic",
      "representation",
      "lifecycle",
      "project",
      "program",
      "contained",
      "phases.",
      "monitor",
      "progress",
      "project.",
      "defined",
      "specifying",
      "time",
      "range",
      "start",
      "date",
      "end",
      "date.",
      "milestone",
      "marks",
      "specific",
      "point",
      "specify",
      "records",
      "section",
      "click",
      "new.",
      "service",
      "management",
      "displays",
      "new",
      "dialog",
      "box.",
      "enter",
      "title",
      "save.",
      "note",
      "multiple",
      "one",
      "active",
      "particular",
      "time.",
      "select",
      "list",
      "display",
      "details.",
      "tab.",
      "well",
      "dates.",
      "dates",
      "overlap.",
      "finished",
      "adding",
      "save",
      "main",
      "toolbar.",
      "after",
      "items",
      "automatically",
      "displayed.",
      "granularity",
      "chart",
      "selecting",
      "appropriate",
      "breakdown",
      "week",
      "month",
      "quarter",
      "year",
      "flag",
      "representing",
      "displayed",
      "along",
      "timeline.",
      "edit"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Scenarios",
    "content": "Project portfolio scenarios are sets of selections of the proposals that are included in the project portfolios. Scenarios help you understand the business consequences of different selections. You can use manual or automatic optimization to find the best selection of proposals that meets the business goal, while not breaking any resource or budget constraints. Related topics Project Portfolios How to build and manually optimize a scenario How to optimize a scenario automatically using the embedded optimization engine How to compare scenarios Optimization use case",
    "url": "scenarios",
    "filename": "scenarios",
    "headings": [
      "Related topics"
    ],
    "keywords": [
      "scenarios",
      "related",
      "topics",
      "project",
      "portfolio",
      "sets",
      "selections",
      "proposals",
      "included",
      "portfolios.",
      "help",
      "understand",
      "business",
      "consequences",
      "different",
      "selections.",
      "manual",
      "automatic",
      "optimization",
      "find",
      "best",
      "selection",
      "meets",
      "goal",
      "while",
      "breaking",
      "any",
      "resource",
      "budget",
      "constraints.",
      "portfolios",
      "build",
      "manually",
      "optimize",
      "scenario",
      "automatically",
      "embedded",
      "engine",
      "compare",
      "case"
    ],
    "language": "en",
    "word_count": 51,
    "importance_score": 2.5,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "scenarios",
    "contentLower": "project portfolio scenarios are sets of selections of the proposals that are included in the project portfolios. scenarios help you understand the business consequences of different selections. you can use manual or automatic optimization to find the best selection of proposals that meets the business goal, while not breaking any resource or budget constraints. related topics project portfolios how to build and manually optimize a scenario how to optimize a scenario automatically using the embedded optimization engine how to compare scenarios optimization use case",
    "keywordsLower": [
      "scenarios",
      "related",
      "topics",
      "project",
      "portfolio",
      "sets",
      "selections",
      "proposals",
      "included",
      "portfolios.",
      "help",
      "understand",
      "business",
      "consequences",
      "different",
      "selections.",
      "manual",
      "automatic",
      "optimization",
      "find",
      "best",
      "selection",
      "meets",
      "goal",
      "while",
      "breaking",
      "any",
      "resource",
      "budget",
      "constraints.",
      "portfolios",
      "build",
      "manually",
      "optimize",
      "scenario",
      "automatically",
      "embedded",
      "engine",
      "compare",
      "case"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Task notification rules",
    "content": "Service Management sends an email notification to designated users when a business rule triggers a notification event. The following sections describe the out-of-the-box notifications for tasks. All task processes Comment added Template Recipients Content Notes New comment added Change owner Reported by person All commenters Record title ID Confirmation of new comment Approval task processes After a change Template Recipients Content Notes Notification template for pending approval task with email integration Assignee Active delegates Record title ID Email integration is enabled. Send person a notification that an approval task is pending Assignee Active delegates Record title ID Email integration is off. After a record is in the Pending phase for 24 hours Template Recipients Content Notes Notification template for pending approval task reminder with email integration reminder Assignee Active delegates Record title ID Email integration is enabled. Send person a reminder that an approva",
    "url": "cmtasknotifrules",
    "filename": "cmtasknotifrules",
    "headings": [
      "All task processes",
      "Comment added",
      "Approval task processes",
      "After a change",
      "After a record is in the Pending phase for 24 hours",
      "After a record is in the Pending phase for 72 hours",
      "Automatic task processes",
      "Review phase - after change",
      "Manual task processes",
      "After a change",
      "After a record is in a metaphase (other than Done) for 48 hours",
      "After a record is in a metaphase (other than Done) for one week"
    ],
    "keywords": [
      "task",
      "notification",
      "rules",
      "all",
      "processes",
      "comment",
      "added",
      "approval",
      "after",
      "change",
      "record",
      "pending",
      "phase",
      "24",
      "hours",
      "72",
      "automatic",
      "review",
      "manual",
      "metaphase",
      "done",
      "48",
      "one",
      "week",
      "service",
      "management",
      "sends",
      "email",
      "designated",
      "users",
      "business",
      "rule",
      "triggers",
      "event.",
      "following",
      "sections",
      "describe",
      "out-of-the-box",
      "notifications",
      "tasks.",
      "template",
      "recipients",
      "content",
      "notes",
      "new",
      "owner",
      "reported",
      "person",
      "commenters",
      "title",
      "id",
      "confirmation",
      "integration",
      "assignee",
      "active",
      "delegates",
      "enabled.",
      "send",
      "off.",
      "reminder",
      "manager",
      "assigned",
      "group",
      "time",
      "created",
      "employee",
      "name"
    ],
    "language": "en",
    "word_count": 117,
    "importance_score": 6.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "task notification rules",
    "contentLower": "service management sends an email notification to designated users when a business rule triggers a notification event. the following sections describe the out-of-the-box notifications for tasks. all task processes comment added template recipients content notes new comment added change owner reported by person all commenters record title id confirmation of new comment approval task processes after a change template recipients content notes notification template for pending approval task with email integration assignee active delegates record title id email integration is enabled. send person a notification that an approval task is pending assignee active delegates record title id email integration is off. after a record is in the pending phase for 24 hours template recipients content notes notification template for pending approval task reminder with email integration reminder assignee active delegates record title id email integration is enabled. send person a reminder that an approva",
    "keywordsLower": [
      "task",
      "notification",
      "rules",
      "all",
      "processes",
      "comment",
      "added",
      "approval",
      "after",
      "change",
      "record",
      "pending",
      "phase",
      "24",
      "hours",
      "72",
      "automatic",
      "review",
      "manual",
      "metaphase",
      "done",
      "48",
      "one",
      "week",
      "service",
      "management",
      "sends",
      "email",
      "designated",
      "users",
      "business",
      "rule",
      "triggers",
      "event.",
      "following",
      "sections",
      "describe",
      "out-of-the-box",
      "notifications",
      "tasks.",
      "template",
      "recipients",
      "content",
      "notes",
      "new",
      "owner",
      "reported",
      "person",
      "commenters",
      "title",
      "id",
      "confirmation",
      "integration",
      "assignee",
      "active",
      "delegates",
      "enabled.",
      "send",
      "off.",
      "reminder",
      "manager",
      "assigned",
      "group",
      "time",
      "created",
      "employee",
      "name"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Retroactive changes",
    "content": "In certain special cases, you may implement an urgent change without submitting a request for change first. We strongly recommend that you enforce the Change Management processes for standard, normal, and emergency changes, and avoid running into this situation as much as possible. However, in the event that such a change has already happened, the system allows you to create a retroactive change, which is also known as a potentially unauthorized change or unplanned change. Creating a retroactive change record allows you to not only keep a record of the change implementation details but also perform a post-implementation review. According to the review result, you may close the change, or create another change record for further remediation, or even for rolling back the implemented change. The Standard, Normal, and Emergency change forms have a Retroactive check box, which flags a retroactive change. If you turn on this flag for a change record, the following behavior applies: The Actua",
    "url": "retroactivechanges",
    "filename": "retroactivechanges",
    "headings": [
      "Create a retroactive change manually",
      "Create retroactive changes automatically",
      "Enable retroactive change detection",
      "Create a business rule",
      "Make a schedule to create retroactive changes",
      "Edit a retroactive change",
      "Retroactive change workflow",
      "Excluded from Change Analytics reports",
      "Out-of-the-box reports on retroactive changes"
    ],
    "keywords": [
      "retroactive",
      "changes",
      "create",
      "change",
      "manually",
      "automatically",
      "enable",
      "detection",
      "business",
      "rule",
      "make",
      "schedule",
      "edit",
      "workflow",
      "excluded",
      "analytics",
      "reports",
      "out-of-the-box",
      "certain",
      "special",
      "cases",
      "implement",
      "urgent",
      "submitting",
      "request",
      "first.",
      "strongly",
      "recommend",
      "enforce",
      "management",
      "processes",
      "standard",
      "normal",
      "emergency",
      "avoid",
      "running",
      "situation",
      "much",
      "possible.",
      "however",
      "event",
      "such",
      "already",
      "happened",
      "system",
      "allows",
      "known",
      "potentially",
      "unauthorized",
      "unplanned",
      "change.",
      "creating",
      "record",
      "keep",
      "implementation",
      "details",
      "perform",
      "post-implementation",
      "review.",
      "according",
      "review",
      "result",
      "close",
      "another",
      "further",
      "remediation",
      "even",
      "rolling",
      "back",
      "implemented",
      "forms",
      "check",
      "box",
      "flags",
      "turn",
      "flag",
      "following",
      "behavior",
      "applies",
      "actual",
      "start",
      "end",
      "fields",
      "mandatory",
      "justification",
      "field",
      "becomes",
      "available",
      "optional",
      "go",
      "through",
      "simplified",
      "consists",
      "phases",
      "log",
      "evaluate",
      "close.",
      "steps",
      "basically",
      "same"
    ],
    "language": "en",
    "word_count": 92,
    "importance_score": 6.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "retroactive changes",
    "contentLower": "in certain special cases, you may implement an urgent change without submitting a request for change first. we strongly recommend that you enforce the change management processes for standard, normal, and emergency changes, and avoid running into this situation as much as possible. however, in the event that such a change has already happened, the system allows you to create a retroactive change, which is also known as a potentially unauthorized change or unplanned change. creating a retroactive change record allows you to not only keep a record of the change implementation details but also perform a post-implementation review. according to the review result, you may close the change, or create another change record for further remediation, or even for rolling back the implemented change. the standard, normal, and emergency change forms have a retroactive check box, which flags a retroactive change. if you turn on this flag for a change record, the following behavior applies: the actua",
    "keywordsLower": [
      "retroactive",
      "changes",
      "create",
      "change",
      "manually",
      "automatically",
      "enable",
      "detection",
      "business",
      "rule",
      "make",
      "schedule",
      "edit",
      "workflow",
      "excluded",
      "analytics",
      "reports",
      "out-of-the-box",
      "certain",
      "special",
      "cases",
      "implement",
      "urgent",
      "submitting",
      "request",
      "first.",
      "strongly",
      "recommend",
      "enforce",
      "management",
      "processes",
      "standard",
      "normal",
      "emergency",
      "avoid",
      "running",
      "situation",
      "much",
      "possible.",
      "however",
      "event",
      "such",
      "already",
      "happened",
      "system",
      "allows",
      "known",
      "potentially",
      "unauthorized",
      "unplanned",
      "change.",
      "creating",
      "record",
      "keep",
      "implementation",
      "details",
      "perform",
      "post-implementation",
      "review.",
      "according",
      "review",
      "result",
      "close",
      "another",
      "further",
      "remediation",
      "even",
      "rolling",
      "back",
      "implemented",
      "forms",
      "check",
      "box",
      "flags",
      "turn",
      "flag",
      "following",
      "behavior",
      "applies",
      "actual",
      "start",
      "end",
      "fields",
      "mandatory",
      "justification",
      "field",
      "becomes",
      "available",
      "optional",
      "go",
      "through",
      "simplified",
      "consists",
      "phases",
      "log",
      "evaluate",
      "close.",
      "steps",
      "basically",
      "same"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Reschedule a change",
    "content": "You can reschedule a change in the Change Calendar (Build > Change > Calendar) in one of the following ways: Drag the change representation If you want to reschedule the change, without increasing or decreasing the duration: Click the change representation in the main pane, and drag it to the new time. Click Save. If you want to increase or decrease the duration of the change: Click the resize handle at the appropriate end of the change representation, and drag it to its new time. Click Save. Note As you drag the change representation, a tooltip is displayed with: The scheduled start and end times. The downtime start and end times, if relevant. For each scale view (Day, Week, and Month) there is a minimum display size for the change representation. If the change representation is at the minimum, you can reschedule the change by dragging it, but you can't resize it. You must, instead, use the scheduling dialog. Edit the scheduling dialog Click the change representation. Click the drop-d",
    "url": "reschedulechange",
    "filename": "reschedulechange",
    "headings": [
      "Drag the change representation",
      "Edit the scheduling dialog",
      "Related topics"
    ],
    "keywords": [
      "reschedule",
      "change",
      "drag",
      "representation",
      "edit",
      "scheduling",
      "dialog",
      "related",
      "topics",
      "calendar",
      "build",
      "one",
      "following",
      "ways",
      "want",
      "increasing",
      "decreasing",
      "duration",
      "click",
      "main",
      "pane",
      "new",
      "time.",
      "save.",
      "increase",
      "decrease",
      "resize",
      "handle",
      "appropriate",
      "end",
      "note",
      "tooltip",
      "displayed",
      "scheduled",
      "start",
      "times.",
      "downtime",
      "times",
      "relevant.",
      "scale",
      "view",
      "day",
      "week",
      "month",
      "there",
      "minimum",
      "display",
      "size",
      "representation.",
      "dragging",
      "it.",
      "instead",
      "dialog.",
      "drop-down",
      "arrow",
      "right",
      "schedule",
      "details",
      "box",
      "displayed.",
      "additional",
      "available",
      "windows.",
      "list",
      "windows",
      "select",
      "suitable",
      "window",
      "return",
      "box.",
      "deal",
      "unscheduled",
      "breaches",
      "standards"
    ],
    "language": "en",
    "word_count": 94,
    "importance_score": 4.5,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "reschedule a change",
    "contentLower": "you can reschedule a change in the change calendar (build > change > calendar) in one of the following ways: drag the change representation if you want to reschedule the change, without increasing or decreasing the duration: click the change representation in the main pane, and drag it to the new time. click save. if you want to increase or decrease the duration of the change: click the resize handle at the appropriate end of the change representation, and drag it to its new time. click save. note as you drag the change representation, a tooltip is displayed with: the scheduled start and end times. the downtime start and end times, if relevant. for each scale view (day, week, and month) there is a minimum display size for the change representation. if the change representation is at the minimum, you can reschedule the change by dragging it, but you can't resize it. you must, instead, use the scheduling dialog. edit the scheduling dialog click the change representation. click the drop-d",
    "keywordsLower": [
      "reschedule",
      "change",
      "drag",
      "representation",
      "edit",
      "scheduling",
      "dialog",
      "related",
      "topics",
      "calendar",
      "build",
      "one",
      "following",
      "ways",
      "want",
      "increasing",
      "decreasing",
      "duration",
      "click",
      "main",
      "pane",
      "new",
      "time.",
      "save.",
      "increase",
      "decrease",
      "resize",
      "handle",
      "appropriate",
      "end",
      "note",
      "tooltip",
      "displayed",
      "scheduled",
      "start",
      "times.",
      "downtime",
      "times",
      "relevant.",
      "scale",
      "view",
      "day",
      "week",
      "month",
      "there",
      "minimum",
      "display",
      "size",
      "representation.",
      "dragging",
      "it.",
      "instead",
      "dialog.",
      "drop-down",
      "arrow",
      "right",
      "schedule",
      "details",
      "box",
      "displayed.",
      "additional",
      "available",
      "windows.",
      "list",
      "windows",
      "select",
      "suitable",
      "window",
      "return",
      "box.",
      "deal",
      "unscheduled",
      "breaches",
      "standards"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Reschedule downtime for a change",
    "content": "You can reschedule downtime for a change in the Change Calendar (Build > Change > Calendar) in one of the following ways: Drag the representation If you want to reschedule the downtime, without increasing or decreasing the duration: Click the downtime icon (inside the change representation) in the main pane, and drag it to the new time. Click Save. If you want to increase or decrease the duration of the downtime: Point to the appropriate end of the downtime icon until the resize handle is displayed. Drag the downtime icon to its new time. Click Save. Note As you drag the downtime, a tooltip is displayed with (a) the scheduled start and end times, and (b) the downtime start and end times. You can't drag the downtime beyond the scheduled start or end time of the change. For each scale view (Day, Week, and Month) there is a minimum display size for the change representation. If the change representation is at the minimum, you can reschedule the change by dragging it, but you can't resize ",
    "url": "rescheduledowntime",
    "filename": "rescheduledowntime",
    "headings": [
      "Drag the representation",
      "Edit the scheduling dialog",
      "Related topics"
    ],
    "keywords": [
      "reschedule",
      "downtime",
      "change",
      "drag",
      "representation",
      "edit",
      "scheduling",
      "dialog",
      "related",
      "topics",
      "calendar",
      "build",
      "one",
      "following",
      "ways",
      "want",
      "increasing",
      "decreasing",
      "duration",
      "click",
      "icon",
      "inside",
      "main",
      "pane",
      "new",
      "time.",
      "save.",
      "increase",
      "decrease",
      "point",
      "appropriate",
      "end",
      "until",
      "resize",
      "handle",
      "displayed.",
      "note",
      "tooltip",
      "displayed",
      "scheduled",
      "start",
      "times",
      "times.",
      "beyond",
      "time",
      "change.",
      "scale",
      "view",
      "day",
      "week",
      "month",
      "there",
      "minimum",
      "display",
      "size",
      "representation.",
      "dragging",
      "it.",
      "instead",
      "dialog.",
      "drop-down",
      "arrow",
      "right",
      "box",
      "dates",
      "appropriate.",
      "deal",
      "unscheduled",
      "breaches",
      "standards"
    ],
    "language": "en",
    "word_count": 98,
    "importance_score": 4.5,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "reschedule downtime for a change",
    "contentLower": "you can reschedule downtime for a change in the change calendar (build > change > calendar) in one of the following ways: drag the representation if you want to reschedule the downtime, without increasing or decreasing the duration: click the downtime icon (inside the change representation) in the main pane, and drag it to the new time. click save. if you want to increase or decrease the duration of the downtime: point to the appropriate end of the downtime icon until the resize handle is displayed. drag the downtime icon to its new time. click save. note as you drag the downtime, a tooltip is displayed with (a) the scheduled start and end times, and (b) the downtime start and end times. you can't drag the downtime beyond the scheduled start or end time of the change. for each scale view (day, week, and month) there is a minimum display size for the change representation. if the change representation is at the minimum, you can reschedule the change by dragging it, but you can't resize ",
    "keywordsLower": [
      "reschedule",
      "downtime",
      "change",
      "drag",
      "representation",
      "edit",
      "scheduling",
      "dialog",
      "related",
      "topics",
      "calendar",
      "build",
      "one",
      "following",
      "ways",
      "want",
      "increasing",
      "decreasing",
      "duration",
      "click",
      "icon",
      "inside",
      "main",
      "pane",
      "new",
      "time.",
      "save.",
      "increase",
      "decrease",
      "point",
      "appropriate",
      "end",
      "until",
      "resize",
      "handle",
      "displayed.",
      "note",
      "tooltip",
      "displayed",
      "scheduled",
      "start",
      "times",
      "times.",
      "beyond",
      "time",
      "change.",
      "scale",
      "view",
      "day",
      "week",
      "month",
      "there",
      "minimum",
      "display",
      "size",
      "representation.",
      "dragging",
      "it.",
      "instead",
      "dialog.",
      "drop-down",
      "arrow",
      "right",
      "box",
      "dates",
      "appropriate.",
      "deal",
      "unscheduled",
      "breaches",
      "standards"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Retire a change model",
    "content": "Note You must have the appropriate permissions to be able to retire a change model. If you retire a change model, this has no effect on existing change records. To retire a change model means changing its status, as shown in the workflow snapshot at the top of the model, from Active to Retired. From the main menu, select Build > Change > Models. Select the change model. Click the record identifier in the ID column to display the selected record. Click Retired, and then Save. Related topics How to create a change model How to edit a change model How to activate a change model Change model business rules",
    "url": "retirechangemodel",
    "filename": "retirechangemodel",
    "headings": [
      "Related topics"
    ],
    "keywords": [
      "retire",
      "change",
      "model",
      "related",
      "topics",
      "note",
      "appropriate",
      "permissions",
      "able",
      "model.",
      "effect",
      "existing",
      "records.",
      "means",
      "changing",
      "status",
      "shown",
      "workflow",
      "snapshot",
      "top",
      "active",
      "retired.",
      "main",
      "menu",
      "select",
      "build",
      "models.",
      "click",
      "record",
      "identifier",
      "id",
      "column",
      "display",
      "selected",
      "record.",
      "retired",
      "save.",
      "create",
      "edit",
      "activate",
      "business",
      "rules"
    ],
    "language": "en",
    "word_count": 65,
    "importance_score": 3.5,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "retire a change model",
    "contentLower": "note you must have the appropriate permissions to be able to retire a change model. if you retire a change model, this has no effect on existing change records. to retire a change model means changing its status, as shown in the workflow snapshot at the top of the model, from active to retired. from the main menu, select build > change > models. select the change model. click the record identifier in the id column to display the selected record. click retired, and then save. related topics how to create a change model how to edit a change model how to activate a change model change model business rules",
    "keywordsLower": [
      "retire",
      "change",
      "model",
      "related",
      "topics",
      "note",
      "appropriate",
      "permissions",
      "able",
      "model.",
      "effect",
      "existing",
      "records.",
      "means",
      "changing",
      "status",
      "shown",
      "workflow",
      "snapshot",
      "top",
      "active",
      "retired.",
      "main",
      "menu",
      "select",
      "build",
      "models.",
      "click",
      "record",
      "identifier",
      "id",
      "column",
      "display",
      "selected",
      "record.",
      "retired",
      "save.",
      "create",
      "edit",
      "activate",
      "business",
      "rules"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Scheduling changes",
    "content": "Service Management keeps details of the scheduling in each change record. You can view the details: In the change record. Click the Schedule tab. For more information, see How to edit a change record. In the Change Calendar. Point to the change in the left pane and click the Scroll to change button . For more information, see How to view the Change Calendar. Change scheduling standards Service Management monitors how each change complies with the following standards: The schedule for a change should be in a maintenance time period (or \"window.\") The schedule for a change should not be in a blackout time period (or \"window.\") Change scheduling breaches If a change breaches the change scheduling standards, Service Management displays the relevant information in the following parts of the UI: Change record Breach Change User interface Display Change isn't scheduled in a maintenance window. Not approved Top right of change record page Plan and execute tab, Change schedule section Breach st",
    "url": "changescheduling",
    "filename": "changescheduling",
    "headings": [
      "Change scheduling standards",
      "Change scheduling breaches",
      "Change record",
      "Change Calendar",
      "Related topics"
    ],
    "keywords": [
      "scheduling",
      "changes",
      "change",
      "standards",
      "breaches",
      "record",
      "calendar",
      "related",
      "topics",
      "service",
      "management",
      "keeps",
      "details",
      "record.",
      "view",
      "click",
      "schedule",
      "tab.",
      "information",
      "see",
      "edit",
      "calendar.",
      "point",
      "left",
      "pane",
      "scroll",
      "button",
      "monitors",
      "complies",
      "following",
      "maintenance",
      "time",
      "period",
      "window.",
      "blackout",
      "displays",
      "relevant",
      "parts",
      "ui",
      "breach",
      "user",
      "interface",
      "display",
      "isn",
      "scheduled",
      "approved",
      "top",
      "right",
      "page",
      "plan",
      "execute",
      "tab",
      "section",
      "status",
      "outside",
      "window",
      "breached",
      "inside",
      "note",
      "icon",
      "about",
      "link",
      "viewing",
      "records",
      "list",
      "appropriate",
      "message",
      "preview",
      "current",
      "creation",
      "there",
      "active",
      "disables",
      "icons.",
      "representation",
      "main",
      "windows",
      "periods"
    ],
    "language": "en",
    "word_count": 101,
    "importance_score": 5.5,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "scheduling changes",
    "contentLower": "service management keeps details of the scheduling in each change record. you can view the details: in the change record. click the schedule tab. for more information, see how to edit a change record. in the change calendar. point to the change in the left pane and click the scroll to change button . for more information, see how to view the change calendar. change scheduling standards service management monitors how each change complies with the following standards: the schedule for a change should be in a maintenance time period (or \"window.\") the schedule for a change should not be in a blackout time period (or \"window.\") change scheduling breaches if a change breaches the change scheduling standards, service management displays the relevant information in the following parts of the ui: change record breach change user interface display change isn't scheduled in a maintenance window. not approved top right of change record page plan and execute tab, change schedule section breach st",
    "keywordsLower": [
      "scheduling",
      "changes",
      "change",
      "standards",
      "breaches",
      "record",
      "calendar",
      "related",
      "topics",
      "service",
      "management",
      "keeps",
      "details",
      "record.",
      "view",
      "click",
      "schedule",
      "tab.",
      "information",
      "see",
      "edit",
      "calendar.",
      "point",
      "left",
      "pane",
      "scroll",
      "button",
      "monitors",
      "complies",
      "following",
      "maintenance",
      "time",
      "period",
      "window.",
      "blackout",
      "displays",
      "relevant",
      "parts",
      "ui",
      "breach",
      "user",
      "interface",
      "display",
      "isn",
      "scheduled",
      "approved",
      "top",
      "right",
      "page",
      "plan",
      "execute",
      "tab",
      "section",
      "status",
      "outside",
      "window",
      "breached",
      "inside",
      "note",
      "icon",
      "about",
      "link",
      "viewing",
      "records",
      "list",
      "appropriate",
      "message",
      "preview",
      "current",
      "creation",
      "there",
      "active",
      "disables",
      "icons.",
      "representation",
      "main",
      "windows",
      "periods"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Release Management",
    "content": "Release Management is the process that includes planning, designing, building, configuring and testing hardware and software releases, to create a defined set of release components - changes. Key activities include planning, preparation, scheduling, training, documentation, distribution, and installation of the release. In short, Release Management enables you to plan, schedule, and control multiple changes and additions to existing services. The Service Management Release Management module: Helps you create, manage, and deploy releases, and the changes in a release. Helps you schedule and track the status of included changes. Provides standard methods and procedures. Provides release level reporting, with actionable tiles that drill into changes in different release statuses. Related topics Category Links Get started Release management Release flows Administer Fields Forms Roles Data domain segmentation Release transition rules Use Release Management roles and permissions Release work",
    "url": "releasemgmt",
    "filename": "releasemgmt",
    "headings": [
      "Related topics"
    ],
    "keywords": [
      "release",
      "management",
      "related",
      "topics",
      "process",
      "includes",
      "planning",
      "designing",
      "building",
      "configuring",
      "testing",
      "hardware",
      "software",
      "releases",
      "create",
      "defined",
      "set",
      "components",
      "changes.",
      "key",
      "activities",
      "include",
      "preparation",
      "scheduling",
      "training",
      "documentation",
      "distribution",
      "installation",
      "release.",
      "short",
      "enables",
      "plan",
      "schedule",
      "control",
      "multiple",
      "changes",
      "additions",
      "existing",
      "services.",
      "service",
      "module",
      "helps",
      "manage",
      "deploy",
      "track",
      "status",
      "included",
      "provides",
      "standard",
      "methods",
      "procedures.",
      "level",
      "reporting",
      "actionable",
      "tiles",
      "drill",
      "different",
      "statuses.",
      "category",
      "links",
      "get",
      "started",
      "flows",
      "administer",
      "fields",
      "forms",
      "roles",
      "data",
      "domain",
      "segmentation",
      "transition",
      "rules",
      "permissions",
      "workflow",
      "notification",
      "procedures",
      "configure",
      "develop",
      "single",
      "record",
      "apis",
      "bulk",
      "update",
      "collection"
    ],
    "language": "en",
    "word_count": 102,
    "importance_score": 3.5,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "release management",
    "contentLower": "release management is the process that includes planning, designing, building, configuring and testing hardware and software releases, to create a defined set of release components - changes. key activities include planning, preparation, scheduling, training, documentation, distribution, and installation of the release. in short, release management enables you to plan, schedule, and control multiple changes and additions to existing services. the service management release management module: helps you create, manage, and deploy releases, and the changes in a release. helps you schedule and track the status of included changes. provides standard methods and procedures. provides release level reporting, with actionable tiles that drill into changes in different release statuses. related topics category links get started release management release flows administer fields forms roles data domain segmentation release transition rules use release management roles and permissions release work",
    "keywordsLower": [
      "release",
      "management",
      "related",
      "topics",
      "process",
      "includes",
      "planning",
      "designing",
      "building",
      "configuring",
      "testing",
      "hardware",
      "software",
      "releases",
      "create",
      "defined",
      "set",
      "components",
      "changes.",
      "key",
      "activities",
      "include",
      "preparation",
      "scheduling",
      "training",
      "documentation",
      "distribution",
      "installation",
      "release.",
      "short",
      "enables",
      "plan",
      "schedule",
      "control",
      "multiple",
      "changes",
      "additions",
      "existing",
      "services.",
      "service",
      "module",
      "helps",
      "manage",
      "deploy",
      "track",
      "status",
      "included",
      "provides",
      "standard",
      "methods",
      "procedures.",
      "level",
      "reporting",
      "actionable",
      "tiles",
      "drill",
      "different",
      "statuses.",
      "category",
      "links",
      "get",
      "started",
      "flows",
      "administer",
      "fields",
      "forms",
      "roles",
      "data",
      "domain",
      "segmentation",
      "transition",
      "rules",
      "permissions",
      "workflow",
      "notification",
      "procedures",
      "configure",
      "develop",
      "single",
      "record",
      "apis",
      "bulk",
      "update",
      "collection"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Release Management roles and permissions",
    "content": "There are specific roles associated with Release Management. Service Management uses role based permissions to enable you to complete a task that's appropriate to your role. System Administrators manage and assign these permissions. By default, the following roles are assigned to Release Management. These roles support release tracking and process ownership. Role Responsibilities Release Coordinator Creates release records and applies the correct release model. Schedules the release. Schedules changes in releases. Coordinates all releases throughout their lifecycle. Release Process Owner Accountable for all release related activities. Ensures that you perform the process according to the agreed and documented process and the process aims are met. Designs, documents, publicizes, and continuously improves the process. Defines the Key Performance Indicators (KPIs) to evaluate the effectiveness and efficiency of the process. Reviews KPIs and takes the required action following the analysis",
    "url": "rmroles",
    "filename": "rmroles",
    "headings": [
      "Related topics"
    ],
    "keywords": [
      "release",
      "management",
      "roles",
      "permissions",
      "related",
      "topics",
      "there",
      "specific",
      "associated",
      "management.",
      "service",
      "uses",
      "role",
      "based",
      "enable",
      "complete",
      "task",
      "appropriate",
      "role.",
      "system",
      "administrators",
      "manage",
      "assign",
      "permissions.",
      "default",
      "following",
      "assigned",
      "support",
      "tracking",
      "process",
      "ownership.",
      "responsibilities",
      "coordinator",
      "creates",
      "records",
      "applies",
      "correct",
      "model.",
      "schedules",
      "release.",
      "changes",
      "releases.",
      "coordinates",
      "all",
      "releases",
      "throughout",
      "lifecycle.",
      "owner",
      "accountable",
      "activities.",
      "ensures",
      "perform",
      "according",
      "agreed",
      "documented",
      "aims",
      "met.",
      "designs",
      "documents",
      "publicizes",
      "continuously",
      "improves",
      "process.",
      "defines",
      "key",
      "performance",
      "indicators",
      "kpis",
      "evaluate",
      "effectiveness",
      "efficiency",
      "reviews",
      "takes",
      "required",
      "action",
      "analysis.",
      "addresses",
      "any",
      "issues",
      "running",
      "review",
      "individual",
      "permission",
      "assignments",
      "administration",
      "master",
      "data",
      "people",
      "roles."
    ],
    "language": "en",
    "word_count": 100,
    "importance_score": 3.5,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "release management roles and permissions",
    "contentLower": "there are specific roles associated with release management. service management uses role based permissions to enable you to complete a task that's appropriate to your role. system administrators manage and assign these permissions. by default, the following roles are assigned to release management. these roles support release tracking and process ownership. role responsibilities release coordinator creates release records and applies the correct release model. schedules the release. schedules changes in releases. coordinates all releases throughout their lifecycle. release process owner accountable for all release related activities. ensures that you perform the process according to the agreed and documented process and the process aims are met. designs, documents, publicizes, and continuously improves the process. defines the key performance indicators (kpis) to evaluate the effectiveness and efficiency of the process. reviews kpis and takes the required action following the analysis",
    "keywordsLower": [
      "release",
      "management",
      "roles",
      "permissions",
      "related",
      "topics",
      "there",
      "specific",
      "associated",
      "management.",
      "service",
      "uses",
      "role",
      "based",
      "enable",
      "complete",
      "task",
      "appropriate",
      "role.",
      "system",
      "administrators",
      "manage",
      "assign",
      "permissions.",
      "default",
      "following",
      "assigned",
      "support",
      "tracking",
      "process",
      "ownership.",
      "responsibilities",
      "coordinator",
      "creates",
      "records",
      "applies",
      "correct",
      "model.",
      "schedules",
      "release.",
      "changes",
      "releases.",
      "coordinates",
      "all",
      "releases",
      "throughout",
      "lifecycle.",
      "owner",
      "accountable",
      "activities.",
      "ensures",
      "perform",
      "according",
      "agreed",
      "documented",
      "aims",
      "met.",
      "designs",
      "documents",
      "publicizes",
      "continuously",
      "improves",
      "process.",
      "defines",
      "key",
      "performance",
      "indicators",
      "kpis",
      "evaluate",
      "effectiveness",
      "efficiency",
      "reviews",
      "takes",
      "required",
      "action",
      "analysis.",
      "addresses",
      "any",
      "issues",
      "running",
      "review",
      "individual",
      "permission",
      "assignments",
      "administration",
      "master",
      "data",
      "people",
      "roles."
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Release workflow",
    "content": "This section describes the metaphases and subordinate phases in the life cycle of a release. The workflow relies on business rules. Rules repeat from one phase to another when the end user can make a change to a field affected by a business rule during that phase. For more information about the out-of-the-box business rules defined for the release workflow, see Release transition rules. Metaphase: Classification A Release Coordinator logs a release including selecting a model. Phase Transition Description Log Automatic The Release Coordinator (or another role entitled to create a new release, such as a Change Coordinator or Incident Analyst) logs a release. As soon as the release is logged it's automatically queued for evaluation by the Release Coordinator. Next phase: Evaluate Evaluate Manual The Release Coordinator checks the information provided - including the model - performs an initial analysis, identifies the necessary changes, and ensures they are part of the release by creatin",
    "url": "rmwflw",
    "filename": "rmwflw",
    "headings": [
      "Metaphase: Classification",
      "Metaphase: Planning",
      "Metaphase: Deployment",
      "Metaphase: Validation",
      "Metaphase: Done (End)",
      "Related topics"
    ],
    "keywords": [
      "release",
      "workflow",
      "metaphase",
      "classification",
      "planning",
      "deployment",
      "validation",
      "done",
      "end",
      "related",
      "topics",
      "section",
      "describes",
      "metaphases",
      "subordinate",
      "phases",
      "life",
      "cycle",
      "release.",
      "relies",
      "business",
      "rules.",
      "rules",
      "repeat",
      "one",
      "phase",
      "another",
      "user",
      "make",
      "change",
      "field",
      "affected",
      "rule",
      "during",
      "phase.",
      "information",
      "about",
      "out-of-the-box",
      "defined",
      "see",
      "transition",
      "coordinator",
      "logs",
      "including",
      "selecting",
      "model.",
      "description",
      "log",
      "automatic",
      "role",
      "entitled",
      "create",
      "new",
      "such",
      "incident",
      "analyst",
      "soon",
      "logged",
      "automatically",
      "queued",
      "evaluation",
      "coordinator.",
      "next",
      "evaluate",
      "manual",
      "checks",
      "provided",
      "model",
      "performs",
      "initial",
      "analysis",
      "identifies",
      "necessary",
      "changes",
      "ensures",
      "part",
      "creating",
      "linking",
      "them.",
      "decision",
      "move",
      "transitions",
      "manually",
      "plan",
      "design",
      "canceled",
      "abandon",
      "plans",
      "resources",
      "tasks",
      "required.",
      "example",
      "include",
      "training",
      "staff.",
      "reviews",
      "revises",
      "updates",
      "schedule",
      "necessary."
    ],
    "language": "en",
    "word_count": 101,
    "importance_score": 6.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "release workflow",
    "contentLower": "this section describes the metaphases and subordinate phases in the life cycle of a release. the workflow relies on business rules. rules repeat from one phase to another when the end user can make a change to a field affected by a business rule during that phase. for more information about the out-of-the-box business rules defined for the release workflow, see release transition rules. metaphase: classification a release coordinator logs a release including selecting a model. phase transition description log automatic the release coordinator (or another role entitled to create a new release, such as a change coordinator or incident analyst) logs a release. as soon as the release is logged it's automatically queued for evaluation by the release coordinator. next phase: evaluate evaluate manual the release coordinator checks the information provided - including the model - performs an initial analysis, identifies the necessary changes, and ensures they are part of the release by creatin",
    "keywordsLower": [
      "release",
      "workflow",
      "metaphase",
      "classification",
      "planning",
      "deployment",
      "validation",
      "done",
      "end",
      "related",
      "topics",
      "section",
      "describes",
      "metaphases",
      "subordinate",
      "phases",
      "life",
      "cycle",
      "release.",
      "relies",
      "business",
      "rules.",
      "rules",
      "repeat",
      "one",
      "phase",
      "another",
      "user",
      "make",
      "change",
      "field",
      "affected",
      "rule",
      "during",
      "phase.",
      "information",
      "about",
      "out-of-the-box",
      "defined",
      "see",
      "transition",
      "coordinator",
      "logs",
      "including",
      "selecting",
      "model.",
      "description",
      "log",
      "automatic",
      "role",
      "entitled",
      "create",
      "new",
      "such",
      "incident",
      "analyst",
      "soon",
      "logged",
      "automatically",
      "queued",
      "evaluation",
      "coordinator.",
      "next",
      "evaluate",
      "manual",
      "checks",
      "provided",
      "model",
      "performs",
      "initial",
      "analysis",
      "identifies",
      "necessary",
      "changes",
      "ensures",
      "part",
      "creating",
      "linking",
      "them.",
      "decision",
      "move",
      "transitions",
      "manually",
      "plan",
      "design",
      "canceled",
      "abandon",
      "plans",
      "resources",
      "tasks",
      "required.",
      "example",
      "include",
      "training",
      "staff.",
      "reviews",
      "revises",
      "updates",
      "schedule",
      "necessary."
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Release notification rules",
    "content": "Service Management sends an email notification to designated users when a business rule triggers a notification event. The following table describes the event trigger, identifies the email recipient, and identifies the information contained in the notification. The default business rules define the recipients according to the user or group identified in the release record (or the included changes), but an administrator must first do the following: Assign the appropriate Release Management roles to the named users. Populate groups with users who also have the appropriate roles to add, change, or update release records. Event Recipients Email contains this information Release has been opened Service Owner Release Owning Group Release ID and name, service, requested date, description, justification, release type, owner, priority Transition to Plan and design phase Service Owner Release Owning Group Release ID and name, service, requested date, scheduled start, scheduled end, description, ",
    "url": "rmnotifrules",
    "filename": "rmnotifrules",
    "headings": [
      "Related topics"
    ],
    "keywords": [
      "release",
      "notification",
      "rules",
      "related",
      "topics",
      "service",
      "management",
      "sends",
      "email",
      "designated",
      "users",
      "business",
      "rule",
      "triggers",
      "event.",
      "following",
      "table",
      "describes",
      "event",
      "trigger",
      "identifies",
      "recipient",
      "information",
      "contained",
      "notification.",
      "default",
      "define",
      "recipients",
      "according",
      "user",
      "group",
      "identified",
      "record",
      "included",
      "changes",
      "administrator",
      "first",
      "assign",
      "appropriate",
      "roles",
      "named",
      "users.",
      "populate",
      "groups",
      "add",
      "change",
      "update",
      "records.",
      "contains",
      "opened",
      "owner",
      "owning",
      "id",
      "name",
      "requested",
      "date",
      "description",
      "justification",
      "type",
      "priority",
      "transition",
      "plan",
      "design",
      "phase",
      "scheduled",
      "start",
      "end",
      "risk",
      "build",
      "test",
      "approve",
      "deployment",
      "pending",
      "owners",
      "all",
      "approved",
      "deployed",
      "deploy",
      "remediate",
      "early",
      "life",
      "support",
      "level",
      "completion",
      "code",
      "review",
      "abandon",
      "close",
      "comments",
      "about",
      "customizing",
      "templates",
      "see",
      "notifications.",
      "workflow"
    ],
    "language": "en",
    "word_count": 104,
    "importance_score": 3.5,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "release notification rules",
    "contentLower": "service management sends an email notification to designated users when a business rule triggers a notification event. the following table describes the event trigger, identifies the email recipient, and identifies the information contained in the notification. the default business rules define the recipients according to the user or group identified in the release record (or the included changes), but an administrator must first do the following: assign the appropriate release management roles to the named users. populate groups with users who also have the appropriate roles to add, change, or update release records. event recipients email contains this information release has been opened service owner release owning group release id and name, service, requested date, description, justification, release type, owner, priority transition to plan and design phase service owner release owning group release id and name, service, requested date, scheduled start, scheduled end, description, ",
    "keywordsLower": [
      "release",
      "notification",
      "rules",
      "related",
      "topics",
      "service",
      "management",
      "sends",
      "email",
      "designated",
      "users",
      "business",
      "rule",
      "triggers",
      "event.",
      "following",
      "table",
      "describes",
      "event",
      "trigger",
      "identifies",
      "recipient",
      "information",
      "contained",
      "notification.",
      "default",
      "define",
      "recipients",
      "according",
      "user",
      "group",
      "identified",
      "record",
      "included",
      "changes",
      "administrator",
      "first",
      "assign",
      "appropriate",
      "roles",
      "named",
      "users.",
      "populate",
      "groups",
      "add",
      "change",
      "update",
      "records.",
      "contains",
      "opened",
      "owner",
      "owning",
      "id",
      "name",
      "requested",
      "date",
      "description",
      "justification",
      "type",
      "priority",
      "transition",
      "plan",
      "design",
      "phase",
      "scheduled",
      "start",
      "end",
      "risk",
      "build",
      "test",
      "approve",
      "deployment",
      "pending",
      "owners",
      "all",
      "approved",
      "deployed",
      "deploy",
      "remediate",
      "early",
      "life",
      "support",
      "level",
      "completion",
      "code",
      "review",
      "abandon",
      "close",
      "comments",
      "about",
      "customizing",
      "templates",
      "see",
      "notifications.",
      "workflow"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Release Management procedures",
    "content": "Release Management procedures help you deal with the complete life cycle of release records. Related topics How to create a release record How to edit a release record Releases - how to add or remove changes Releases and the Change Calendar",
    "url": "rmtasks",
    "filename": "rmtasks",
    "headings": [
      "Related topics"
    ],
    "keywords": [
      "release",
      "management",
      "procedures",
      "related",
      "topics",
      "help",
      "deal",
      "complete",
      "life",
      "cycle",
      "records.",
      "create",
      "record",
      "edit",
      "releases",
      "add",
      "remove",
      "changes",
      "change",
      "calendar"
    ],
    "language": "en",
    "word_count": 28,
    "importance_score": 2.5,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "release management procedures",
    "contentLower": "release management procedures help you deal with the complete life cycle of release records. related topics how to create a release record how to edit a release record releases - how to add or remove changes releases and the change calendar",
    "keywordsLower": [
      "release",
      "management",
      "procedures",
      "related",
      "topics",
      "help",
      "deal",
      "complete",
      "life",
      "cycle",
      "records.",
      "create",
      "record",
      "edit",
      "releases",
      "add",
      "remove",
      "changes",
      "change",
      "calendar"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Releases and the Change Calendar",
    "content": "How to view a release in the Change Calendar You can view a release in the Change Calendar as follows: From Release Management: From the main menu, select Build > Release. Service Management displays the available releases. Select the release record you want to view. To filter the record list, click the Add filter button. For more information, see Filters. Click the record identifier in the ID column to display the selected record. Click . The Change Calendar displays in release mode. To view another release, click View other release, and select the release to view. From the Change Calendar: From the main menu, select Build > Change > Calendar. Click View release. Select the release you want to view. The Change Calendar displays in the release mode section. To view another release, click View other release, and select the release to view. Note On the left side of the Change Calendar footer, there is a Release option: You can select this to enable a drop-down list that shows releases in",
    "url": "rmviewchangecalendar",
    "filename": "rmviewchangecalendar",
    "headings": [
      "How to view a release in the Change Calendar",
      "Release mode",
      "Related topics"
    ],
    "keywords": [
      "releases",
      "change",
      "calendar",
      "view",
      "release",
      "mode",
      "related",
      "topics",
      "follows",
      "management",
      "main",
      "menu",
      "select",
      "build",
      "release.",
      "service",
      "displays",
      "available",
      "releases.",
      "record",
      "want",
      "view.",
      "filter",
      "list",
      "click",
      "add",
      "button.",
      "information",
      "see",
      "filters.",
      "identifier",
      "id",
      "column",
      "display",
      "selected",
      "record.",
      "mode.",
      "another",
      "calendar.",
      "section.",
      "note",
      "left",
      "side",
      "footer",
      "there",
      "option",
      "enable",
      "drop-down",
      "shows",
      "displayed",
      "time",
      "range",
      "all",
      "colored",
      "line",
      "header",
      "match",
      "schedule",
      "point",
      "about",
      "including",
      "link",
      "changes",
      "included",
      "highlighted",
      "whether",
      "after",
      "clicking",
      "different",
      "usual",
      "details",
      "top",
      "page",
      "type",
      "scheduled",
      "start",
      "end",
      "dates",
      "owner",
      "set",
      "button",
      "right",
      "page.",
      "go",
      "becomes",
      "options",
      "date",
      "specified",
      "bottom",
      "locked",
      "user",
      "appropriate",
      "permissions",
      "remove",
      "changes.",
      "end.",
      "create",
      "edit"
    ],
    "language": "en",
    "word_count": 107,
    "importance_score": 4.5,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "releases and the change calendar",
    "contentLower": "how to view a release in the change calendar you can view a release in the change calendar as follows: from release management: from the main menu, select build > release. service management displays the available releases. select the release record you want to view. to filter the record list, click the add filter button. for more information, see filters. click the record identifier in the id column to display the selected record. click . the change calendar displays in release mode. to view another release, click view other release, and select the release to view. from the change calendar: from the main menu, select build > change > calendar. click view release. select the release you want to view. the change calendar displays in the release mode section. to view another release, click view other release, and select the release to view. note on the left side of the change calendar footer, there is a release option: you can select this to enable a drop-down list that shows releases in",
    "keywordsLower": [
      "releases",
      "change",
      "calendar",
      "view",
      "release",
      "mode",
      "related",
      "topics",
      "follows",
      "management",
      "main",
      "menu",
      "select",
      "build",
      "release.",
      "service",
      "displays",
      "available",
      "releases.",
      "record",
      "want",
      "view.",
      "filter",
      "list",
      "click",
      "add",
      "button.",
      "information",
      "see",
      "filters.",
      "identifier",
      "id",
      "column",
      "display",
      "selected",
      "record.",
      "mode.",
      "another",
      "calendar.",
      "section.",
      "note",
      "left",
      "side",
      "footer",
      "there",
      "option",
      "enable",
      "drop-down",
      "shows",
      "displayed",
      "time",
      "range",
      "all",
      "colored",
      "line",
      "header",
      "match",
      "schedule",
      "point",
      "about",
      "including",
      "link",
      "changes",
      "included",
      "highlighted",
      "whether",
      "after",
      "clicking",
      "different",
      "usual",
      "details",
      "top",
      "page",
      "type",
      "scheduled",
      "start",
      "end",
      "dates",
      "owner",
      "set",
      "button",
      "right",
      "page.",
      "go",
      "becomes",
      "options",
      "date",
      "specified",
      "bottom",
      "locked",
      "user",
      "appropriate",
      "permissions",
      "remove",
      "changes.",
      "end.",
      "create",
      "edit"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Release models",
    "content": "Release models can help you standardize the end-to-end process of release management, and maximize efficiency. Related topics How to create a release model How to edit a release model How to activate a release model How to retire a release model",
    "url": "releasemodels",
    "filename": "releasemodels",
    "headings": [
      "Related topics"
    ],
    "keywords": [
      "release",
      "models",
      "related",
      "topics",
      "help",
      "standardize",
      "end-to-end",
      "process",
      "management",
      "maximize",
      "efficiency.",
      "create",
      "model",
      "edit",
      "activate",
      "retire"
    ],
    "language": "en",
    "word_count": 26,
    "importance_score": 2.5,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "release models",
    "contentLower": "release models can help you standardize the end-to-end process of release management, and maximize efficiency. related topics how to create a release model how to edit a release model how to activate a release model how to retire a release model",
    "keywordsLower": [
      "release",
      "models",
      "related",
      "topics",
      "help",
      "standardize",
      "end-to-end",
      "process",
      "management",
      "maximize",
      "efficiency.",
      "create",
      "model",
      "edit",
      "activate",
      "retire"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Retire a release model",
    "content": "Note You must have the appropriate permissions to be able to retire a release model. If you retire a release model, this has no effect on existing release records. To retire a release model means changing its status, as shown in the workflow snapshot at the top of the model, from Active to Retired. From the main menu, select Build > Release > Models. Select the release model. Click the record identifier in the ID column to display the selected record. Click Retired, then Save. Related topics How to create a release model How to edit a release model How to activate a release model Release model business rules",
    "url": "retirereleasemodel",
    "filename": "retirereleasemodel",
    "headings": [
      "Related topics"
    ],
    "keywords": [
      "retire",
      "release",
      "model",
      "related",
      "topics",
      "note",
      "appropriate",
      "permissions",
      "able",
      "model.",
      "effect",
      "existing",
      "records.",
      "means",
      "changing",
      "status",
      "shown",
      "workflow",
      "snapshot",
      "top",
      "active",
      "retired.",
      "main",
      "menu",
      "select",
      "build",
      "models.",
      "click",
      "record",
      "identifier",
      "id",
      "column",
      "display",
      "selected",
      "record.",
      "retired",
      "save.",
      "create",
      "edit",
      "activate",
      "business",
      "rules"
    ],
    "language": "en",
    "word_count": 65,
    "importance_score": 3.5,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "retire a release model",
    "contentLower": "note you must have the appropriate permissions to be able to retire a release model. if you retire a release model, this has no effect on existing release records. to retire a release model means changing its status, as shown in the workflow snapshot at the top of the model, from active to retired. from the main menu, select build > release > models. select the release model. click the record identifier in the id column to display the selected record. click retired, then save. related topics how to create a release model how to edit a release model how to activate a release model release model business rules",
    "keywordsLower": [
      "retire",
      "release",
      "model",
      "related",
      "topics",
      "note",
      "appropriate",
      "permissions",
      "able",
      "model.",
      "effect",
      "existing",
      "records.",
      "means",
      "changing",
      "status",
      "shown",
      "workflow",
      "snapshot",
      "top",
      "active",
      "retired.",
      "main",
      "menu",
      "select",
      "build",
      "models.",
      "click",
      "record",
      "identifier",
      "id",
      "column",
      "display",
      "selected",
      "record.",
      "retired",
      "save.",
      "create",
      "edit",
      "activate",
      "business",
      "rules"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Release model business rules",
    "content": "You can define business rules within a specific release model. The rules run in the release workflow for release records based on the selected model. These business rules can be used to make a user option mandatory, hidden, or to control values displayed in the user option fields and any fields in the release based on the model. You can define the rules to run in connection with one of the following process events: Process event Description Before change The rule is run before the data is updated. After change The rule is run after the data is updated. Rendering forms The rule is run when a form is opened. After applying changes The rule is run after the change is committed. In each process event, you can define the rule to run either before or after the general record business rules. To add an release model business rule: Select the required release model and select the Rules tab. Select the required process event and click one of the links to add a rule. Click the button next to Add ",
    "url": "releasemodelrules",
    "filename": "releasemodelrules",
    "headings": [
      "Related topics"
    ],
    "keywords": [
      "release",
      "model",
      "business",
      "rules",
      "related",
      "topics",
      "define",
      "specific",
      "model.",
      "run",
      "workflow",
      "records",
      "based",
      "selected",
      "make",
      "user",
      "option",
      "mandatory",
      "hidden",
      "control",
      "values",
      "displayed",
      "fields",
      "any",
      "connection",
      "one",
      "following",
      "process",
      "events",
      "event",
      "description",
      "before",
      "change",
      "rule",
      "data",
      "updated.",
      "after",
      "rendering",
      "forms",
      "form",
      "opened.",
      "applying",
      "changes",
      "committed.",
      "either",
      "general",
      "record",
      "rules.",
      "add",
      "select",
      "required",
      "tab.",
      "click",
      "links",
      "rule.",
      "button",
      "next",
      "event.",
      "template",
      "information",
      "see",
      "defined",
      "left",
      "margin",
      "display",
      "arrow",
      "buttons",
      "enable",
      "order",
      "move",
      "vice",
      "versa.",
      "alternatively",
      "drag",
      "drop",
      "desired",
      "location.",
      "save",
      "toolbar.",
      "note",
      "different",
      "basis",
      "new",
      "apply",
      "record.",
      "modify",
      "existing",
      "aren",
      "affected",
      "retain",
      "original",
      "create",
      "edit",
      "activate",
      "retire"
    ],
    "language": "en",
    "word_count": 113,
    "importance_score": 3.5,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "release model business rules",
    "contentLower": "you can define business rules within a specific release model. the rules run in the release workflow for release records based on the selected model. these business rules can be used to make a user option mandatory, hidden, or to control values displayed in the user option fields and any fields in the release based on the model. you can define the rules to run in connection with one of the following process events: process event description before change the rule is run before the data is updated. after change the rule is run after the data is updated. rendering forms the rule is run when a form is opened. after applying changes the rule is run after the change is committed. in each process event, you can define the rule to run either before or after the general record business rules. to add an release model business rule: select the required release model and select the rules tab. select the required process event and click one of the links to add a rule. click the button next to add ",
    "keywordsLower": [
      "release",
      "model",
      "business",
      "rules",
      "related",
      "topics",
      "define",
      "specific",
      "model.",
      "run",
      "workflow",
      "records",
      "based",
      "selected",
      "make",
      "user",
      "option",
      "mandatory",
      "hidden",
      "control",
      "values",
      "displayed",
      "fields",
      "any",
      "connection",
      "one",
      "following",
      "process",
      "events",
      "event",
      "description",
      "before",
      "change",
      "rule",
      "data",
      "updated.",
      "after",
      "rendering",
      "forms",
      "form",
      "opened.",
      "applying",
      "changes",
      "committed.",
      "either",
      "general",
      "record",
      "rules.",
      "add",
      "select",
      "required",
      "tab.",
      "click",
      "links",
      "rule.",
      "button",
      "next",
      "event.",
      "template",
      "information",
      "see",
      "defined",
      "left",
      "margin",
      "display",
      "arrow",
      "buttons",
      "enable",
      "order",
      "move",
      "vice",
      "versa.",
      "alternatively",
      "drag",
      "drop",
      "desired",
      "location.",
      "save",
      "toolbar.",
      "note",
      "different",
      "basis",
      "new",
      "apply",
      "record.",
      "modify",
      "existing",
      "aren",
      "affected",
      "retain",
      "original",
      "create",
      "edit",
      "activate",
      "retire"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Retire an article model",
    "content": "Note You must have the appropriate permissions to be able to retire an article model. If you retire an article model, this has no effect on existing article records. To retire an article model means changing its status, as shown in the workflow snapshot at the top of the model, from Active to Retired. From the main menu, select Build > Knowledge > Models. Select the article model. Click the record identifier in the ID column to display the selected record. Click Retired, then Save. Related topics How to create an article model How to edit an article model How to activate an article model",
    "url": "retirearticlemodel",
    "filename": "retirearticlemodel",
    "headings": [
      "Related topics"
    ],
    "keywords": [
      "retire",
      "article",
      "model",
      "related",
      "topics",
      "note",
      "appropriate",
      "permissions",
      "able",
      "model.",
      "effect",
      "existing",
      "records.",
      "means",
      "changing",
      "status",
      "shown",
      "workflow",
      "snapshot",
      "top",
      "active",
      "retired.",
      "main",
      "menu",
      "select",
      "build",
      "knowledge",
      "models.",
      "click",
      "record",
      "identifier",
      "id",
      "column",
      "display",
      "selected",
      "record.",
      "retired",
      "save.",
      "create",
      "edit",
      "activate"
    ],
    "language": "en",
    "word_count": 61,
    "importance_score": 3.5,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "retire an article model",
    "contentLower": "note you must have the appropriate permissions to be able to retire an article model. if you retire an article model, this has no effect on existing article records. to retire an article model means changing its status, as shown in the workflow snapshot at the top of the model, from active to retired. from the main menu, select build > knowledge > models. select the article model. click the record identifier in the id column to display the selected record. click retired, then save. related topics how to create an article model how to edit an article model how to activate an article model",
    "keywordsLower": [
      "retire",
      "article",
      "model",
      "related",
      "topics",
      "note",
      "appropriate",
      "permissions",
      "able",
      "model.",
      "effect",
      "existing",
      "records.",
      "means",
      "changing",
      "status",
      "shown",
      "workflow",
      "snapshot",
      "top",
      "active",
      "retired.",
      "main",
      "menu",
      "select",
      "build",
      "knowledge",
      "models.",
      "click",
      "record",
      "identifier",
      "id",
      "column",
      "display",
      "selected",
      "record.",
      "retired",
      "save.",
      "create",
      "edit",
      "activate"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Quickstart - How to package knowledge articles using the Knowledge Packaging Tool",
    "content": "This section provides a Quickstart set of instructions for packaging knowledge articles using the Knowledge Packaging tool. Note This procedure assumes that you have downloaded the Knowledge Packaging Tool ZIP file and that you have extracted its contents. If not, download the tool as described in How to download the Knowledge Packaging tool. This section describes how to use the tool to package knowledge articles. In this case, the articles must be in HTML format, or in a format that can be saved to HTML format. Advanced users: The Knowledge Packaging tool can also be used to package knowledge articles from other sources, and in various file formats. For example, knowledge articles retrieved from a custom knowledge base using an in-house article retriever plugin, or knowledge articles that have been retrieved and machine translated. For more information, see Implement an in-house article retriever plugin and Translate and package retrieved articles using an external translator impleme",
    "url": "pckgknowledgearticle",
    "filename": "pckgknowledgearticle",
    "headings": [
      "Related topics"
    ],
    "keywords": [
      "metadata.xml",
      "article.htm",
      "1.0",
      "info.log",
      "article.docx",
      "summary.log",
      "https://www.youtube.com/embed/FLIfIKOiC-o",
      "youtube.com",
      "error.log",
      "filename1.html",
      "articles.zip",
      "article_packager.bat",
      "quickstart",
      "package",
      "knowledge",
      "articles",
      "packaging",
      "tool",
      "related",
      "topics",
      "section",
      "provides",
      "set",
      "instructions",
      "tool.",
      "note",
      "procedure",
      "assumes",
      "downloaded",
      "zip",
      "file",
      "extracted",
      "contents.",
      "download",
      "described",
      "describes",
      "articles.",
      "case",
      "html",
      "format",
      "saved",
      "format.",
      "advanced",
      "users",
      "sources",
      "various",
      "formats.",
      "example",
      "retrieved",
      "custom",
      "base",
      "in-house",
      "article",
      "retriever",
      "plugin",
      "machine",
      "translated.",
      "information",
      "see",
      "implement",
      "translate",
      "external",
      "translator",
      "implementation.",
      "suite-admin",
      "add",
      "types",
      "attachment",
      "allowlist",
      "tenant",
      "suite",
      "administration",
      "otherwise",
      "import",
      "fail.",
      "application",
      "settings.",
      "local",
      "create",
      "folder",
      "myarticles.",
      "copy",
      "folder.",
      "saw-article-packaging-tool",
      "locate",
      "word",
      "document",
      "named",
      "sample-article.docx",
      "myarticles",
      "want",
      "isn",
      "already",
      "open",
      "relevant",
      "save",
      "microsoft",
      "sample-article",
      "filename",
      "optional"
    ],
    "language": "en",
    "word_count": 92,
    "importance_score": 1.5,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "quickstart - how to package knowledge articles using the knowledge packaging tool",
    "contentLower": "this section provides a quickstart set of instructions for packaging knowledge articles using the knowledge packaging tool. note this procedure assumes that you have downloaded the knowledge packaging tool zip file and that you have extracted its contents. if not, download the tool as described in how to download the knowledge packaging tool. this section describes how to use the tool to package knowledge articles. in this case, the articles must be in html format, or in a format that can be saved to html format. advanced users: the knowledge packaging tool can also be used to package knowledge articles from other sources, and in various file formats. for example, knowledge articles retrieved from a custom knowledge base using an in-house article retriever plugin, or knowledge articles that have been retrieved and machine translated. for more information, see implement an in-house article retriever plugin and translate and package retrieved articles using an external translator impleme",
    "keywordsLower": [
      "metadata.xml",
      "article.htm",
      "1.0",
      "info.log",
      "article.docx",
      "summary.log",
      "https://www.youtube.com/embed/flifikoic-o",
      "youtube.com",
      "error.log",
      "filename1.html",
      "articles.zip",
      "article_packager.bat",
      "quickstart",
      "package",
      "knowledge",
      "articles",
      "packaging",
      "tool",
      "related",
      "topics",
      "section",
      "provides",
      "set",
      "instructions",
      "tool.",
      "note",
      "procedure",
      "assumes",
      "downloaded",
      "zip",
      "file",
      "extracted",
      "contents.",
      "download",
      "described",
      "describes",
      "articles.",
      "case",
      "html",
      "format",
      "saved",
      "format.",
      "advanced",
      "users",
      "sources",
      "various",
      "formats.",
      "example",
      "retrieved",
      "custom",
      "base",
      "in-house",
      "article",
      "retriever",
      "plugin",
      "machine",
      "translated.",
      "information",
      "see",
      "implement",
      "translate",
      "external",
      "translator",
      "implementation.",
      "suite-admin",
      "add",
      "types",
      "attachment",
      "allowlist",
      "tenant",
      "suite",
      "administration",
      "otherwise",
      "import",
      "fail.",
      "application",
      "settings.",
      "local",
      "create",
      "folder",
      "myarticles.",
      "copy",
      "folder.",
      "saw-article-packaging-tool",
      "locate",
      "word",
      "document",
      "named",
      "sample-article.docx",
      "myarticles",
      "want",
      "isn",
      "already",
      "open",
      "relevant",
      "save",
      "microsoft",
      "sample-article",
      "filename",
      "optional"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Translate and package retrieved articles using an external translator implementation",
    "content": "You can use an external ArticleRetriever wrapper implementation to generate machine translations for articles that are extracted using any ArticleRetriever plugin implementation. Note The external translation wrapper implementation is not developed or supported by OpenText. To use the ArticleRetrieverTranslationWrapper implementation: Create a Microsoft Windows Azure account and log in: https://login.live.com/login.srf. Subscribe to the Microsoft Translator API: http://datamarket.azure.com/dataset/bing/microsofttranslator. Go to your Windows Azure account: https://datamarket.azure.com/account. Register a new application: https://datamarket.azure.com/developer/applications/register. In the client ID field, provide a unique name, for example, Article-Translator. You can also use this name in the name and description fields. In the redirect URL field, provide any working URL. For example, https://www.microsoft.com. Copy the Client-secret string, which looks something like this: l72isD4Efp",
    "url": "translatepackagearticlesusingexternaltranslator",
    "filename": "translatepackagearticlesusingexternaltranslator",
    "headings": [],
    "keywords": [
      "login.srf",
      "azure.com",
      "https://www.microsoft.com",
      "login.live",
      "https://datamarket.azure.com/developer/applications/register",
      "google.com",
      "http://datamarket.azure.com/dataset/bing/microsofttranslator",
      "microsoft.com",
      "0.6.2",
      "dependencies.jar",
      "https://datamarket.azure.com/account",
      "https://login.live.com/login.srf",
      "https://code.google.com/p/microsoft-translator-java-api/downloads/detail?name=microsofttranslator-java-api-0.6.2-jar-with-dependencies.jar",
      "translate",
      "package",
      "retrieved",
      "articles",
      "external",
      "translator",
      "implementation",
      "articleretriever",
      "wrapper",
      "generate",
      "machine",
      "translations",
      "extracted",
      "any",
      "plugin",
      "implementation.",
      "note",
      "translation",
      "developed",
      "supported",
      "opentext.",
      "articleretrievertranslationwrapper",
      "create",
      "microsoft",
      "windows",
      "azure",
      "account",
      "log",
      "https",
      "login.live.com",
      "login.srf.",
      "subscribe",
      "api",
      "http",
      "datamarket.azure.com",
      "dataset",
      "bing",
      "microsofttranslator.",
      "go",
      "account.",
      "register",
      "new",
      "application",
      "developer",
      "applications",
      "register.",
      "client",
      "id",
      "field",
      "provide",
      "unique",
      "name",
      "example",
      "article-translator.",
      "description",
      "fields.",
      "redirect",
      "url",
      "working",
      "url.",
      "www.microsoft.com.",
      "copy",
      "client-secret",
      "string",
      "looks",
      "something",
      "like",
      "l72isd4efpzvcipvorxplsq",
      "v5v1qsjqg5wdpid8g",
      "surround",
      "secret",
      "double",
      "quotes",
      "add",
      "article",
      "retriever",
      "command",
      "line",
      "click",
      "create.",
      "download",
      "microsoft-translator-java-api-0.6.2-jar-with-dependencies.jar",
      "file",
      "code.google.com",
      "microsoft-translator-java-api",
      "downloads",
      "detail"
    ],
    "language": "en",
    "word_count": 92,
    "importance_score": 2.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "translate and package retrieved articles using an external translator implementation",
    "contentLower": "you can use an external articleretriever wrapper implementation to generate machine translations for articles that are extracted using any articleretriever plugin implementation. note the external translation wrapper implementation is not developed or supported by opentext. to use the articleretrievertranslationwrapper implementation: create a microsoft windows azure account and log in: https://login.live.com/login.srf. subscribe to the microsoft translator api: http://datamarket.azure.com/dataset/bing/microsofttranslator. go to your windows azure account: https://datamarket.azure.com/account. register a new application: https://datamarket.azure.com/developer/applications/register. in the client id field, provide a unique name, for example, article-translator. you can also use this name in the name and description fields. in the redirect url field, provide any working url. for example, https://www.microsoft.com. copy the client-secret string, which looks something like this: l72isd4efp",
    "keywordsLower": [
      "login.srf",
      "azure.com",
      "https://www.microsoft.com",
      "login.live",
      "https://datamarket.azure.com/developer/applications/register",
      "google.com",
      "http://datamarket.azure.com/dataset/bing/microsofttranslator",
      "microsoft.com",
      "0.6.2",
      "dependencies.jar",
      "https://datamarket.azure.com/account",
      "https://login.live.com/login.srf",
      "https://code.google.com/p/microsoft-translator-java-api/downloads/detail?name=microsofttranslator-java-api-0.6.2-jar-with-dependencies.jar",
      "translate",
      "package",
      "retrieved",
      "articles",
      "external",
      "translator",
      "implementation",
      "articleretriever",
      "wrapper",
      "generate",
      "machine",
      "translations",
      "extracted",
      "any",
      "plugin",
      "implementation.",
      "note",
      "translation",
      "developed",
      "supported",
      "opentext.",
      "articleretrievertranslationwrapper",
      "create",
      "microsoft",
      "windows",
      "azure",
      "account",
      "log",
      "https",
      "login.live.com",
      "login.srf.",
      "subscribe",
      "api",
      "http",
      "datamarket.azure.com",
      "dataset",
      "bing",
      "microsofttranslator.",
      "go",
      "account.",
      "register",
      "new",
      "application",
      "developer",
      "applications",
      "register.",
      "client",
      "id",
      "field",
      "provide",
      "unique",
      "name",
      "example",
      "article-translator.",
      "description",
      "fields.",
      "redirect",
      "url",
      "working",
      "url.",
      "www.microsoft.com.",
      "copy",
      "client-secret",
      "string",
      "looks",
      "something",
      "like",
      "l72isd4efpzvcipvorxplsq",
      "v5v1qsjqg5wdpid8g",
      "surround",
      "secret",
      "double",
      "quotes",
      "add",
      "article",
      "retriever",
      "command",
      "line",
      "click",
      "create.",
      "download",
      "microsoft-translator-java-api-0.6.2-jar-with-dependencies.jar",
      "file",
      "code.google.com",
      "microsoft-translator-java-api",
      "downloads",
      "detail"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Service Asset and Configuration Management",
    "content": "Service management administrators and other personnel need current information about business services and devices to close defects, fulfill change requests, and solve problems. Most business services depend on hardware and software to run efficiently. When there is an outage, the interruption can affect the entire organization, a special group, or just a few individuals. Service Asset and Configuration Management (SACM) is the process that's responsible for both Configuration Management and Asset Management. SACM helps you organize and track the individual assets that support your business services. Related topics Category Links Get started Getting started with SACM SACM Overview SACM Details Native SACM Administer Fields Forms Roles Data domain segmentation Integrate Integrate with UCMDB Use Devices System elements Service components Actual services Stock Management Reservations Asset models Infrastructure & peripheral assets Subscriptions Enterprise assets Enterprise asset subtypes ",
    "url": "sacm",
    "filename": "sacm",
    "headings": [
      "Related topics"
    ],
    "keywords": [
      "service",
      "asset",
      "configuration",
      "management",
      "related",
      "topics",
      "administrators",
      "personnel",
      "need",
      "current",
      "information",
      "about",
      "business",
      "services",
      "devices",
      "close",
      "defects",
      "fulfill",
      "change",
      "requests",
      "solve",
      "problems.",
      "most",
      "depend",
      "hardware",
      "software",
      "run",
      "efficiently.",
      "there",
      "outage",
      "interruption",
      "affect",
      "entire",
      "organization",
      "special",
      "group",
      "just",
      "few",
      "individuals.",
      "sacm",
      "process",
      "responsible",
      "both",
      "management.",
      "helps",
      "organize",
      "track",
      "individual",
      "assets",
      "support",
      "services.",
      "category",
      "links",
      "get",
      "started",
      "getting",
      "overview",
      "details",
      "native",
      "administer",
      "fields",
      "forms",
      "roles",
      "data",
      "domain",
      "segmentation",
      "integrate",
      "ucmdb",
      "system",
      "elements",
      "components",
      "actual",
      "stock",
      "reservations",
      "models",
      "infrastructure",
      "peripheral",
      "subscriptions",
      "enterprise",
      "subtypes",
      "identification",
      "synchronization",
      "develop",
      "single",
      "record",
      "apis",
      "bulk",
      "update",
      "collection"
    ],
    "language": "en",
    "word_count": 109,
    "importance_score": 3.5,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "service asset and configuration management",
    "contentLower": "service management administrators and other personnel need current information about business services and devices to close defects, fulfill change requests, and solve problems. most business services depend on hardware and software to run efficiently. when there is an outage, the interruption can affect the entire organization, a special group, or just a few individuals. service asset and configuration management (sacm) is the process that's responsible for both configuration management and asset management. sacm helps you organize and track the individual assets that support your business services. related topics category links get started getting started with sacm sacm overview sacm details native sacm administer fields forms roles data domain segmentation integrate integrate with ucmdb use devices system elements service components actual services stock management reservations asset models infrastructure & peripheral assets subscriptions enterprise assets enterprise asset subtypes ",
    "keywordsLower": [
      "service",
      "asset",
      "configuration",
      "management",
      "related",
      "topics",
      "administrators",
      "personnel",
      "need",
      "current",
      "information",
      "about",
      "business",
      "services",
      "devices",
      "close",
      "defects",
      "fulfill",
      "change",
      "requests",
      "solve",
      "problems.",
      "most",
      "depend",
      "hardware",
      "software",
      "run",
      "efficiently.",
      "there",
      "outage",
      "interruption",
      "affect",
      "entire",
      "organization",
      "special",
      "group",
      "just",
      "few",
      "individuals.",
      "sacm",
      "process",
      "responsible",
      "both",
      "management.",
      "helps",
      "organize",
      "track",
      "individual",
      "assets",
      "support",
      "services.",
      "category",
      "links",
      "get",
      "started",
      "getting",
      "overview",
      "details",
      "native",
      "administer",
      "fields",
      "forms",
      "roles",
      "data",
      "domain",
      "segmentation",
      "integrate",
      "ucmdb",
      "system",
      "elements",
      "components",
      "actual",
      "stock",
      "reservations",
      "models",
      "infrastructure",
      "peripheral",
      "subscriptions",
      "enterprise",
      "subtypes",
      "identification",
      "synchronization",
      "develop",
      "single",
      "record",
      "apis",
      "bulk",
      "update",
      "collection"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "SACM user interface",
    "content": "The Service Asset and Configuration Management user interface has similarities with other Service Management modules, but it also has some unique features. Depending on the type of device or service, the form has unique sections to display more (or less) information than other device types. SACM is a management strategy for tracking components that support your organizational business services. Because these components are grouped by levels in the SACM model hierarchy, you can also review device or service information according to its position in that hierarchy. SACM home The Service Asset and Configuration Management home page includes: SACM submenus SACM configuration link Search SACM summary view SACM submenus Submenus appear on the Service Asset and Configuration Management top menu, and simplify navigation within the Service Asset and Configuration Management database. Devices System Elements Service Components Actual Services Stock Management Reservations Asset Models Infrastruct",
    "url": "sacmuserinterface",
    "filename": "sacmuserinterface",
    "headings": [
      "SACM home",
      "SACM submenus",
      "SACM summary view"
    ],
    "keywords": [
      "sacm",
      "user",
      "interface",
      "home",
      "submenus",
      "summary",
      "view",
      "service",
      "asset",
      "configuration",
      "management",
      "similarities",
      "modules",
      "unique",
      "features.",
      "depending",
      "type",
      "device",
      "form",
      "sections",
      "display",
      "less",
      "information",
      "types.",
      "strategy",
      "tracking",
      "components",
      "support",
      "organizational",
      "business",
      "services.",
      "because",
      "grouped",
      "levels",
      "model",
      "hierarchy",
      "review",
      "according",
      "position",
      "hierarchy.",
      "page",
      "includes",
      "link",
      "search",
      "appear",
      "top",
      "menu",
      "simplify",
      "navigation",
      "database.",
      "devices",
      "system",
      "elements",
      "actual",
      "services",
      "stock",
      "reservations",
      "models",
      "infrastructure",
      "peripherals",
      "subscriptions",
      "enterprise",
      "assets",
      "subtype",
      "visual",
      "dashboard",
      "shows",
      "aggregated",
      "about",
      "under",
      "management.",
      "clickable",
      "tiles",
      "represent",
      "filtered",
      "search.",
      "tile",
      "displays",
      "following",
      "label.",
      "one",
      "hierarchical",
      "element",
      "component",
      "definition",
      "peripheral",
      "number.",
      "total",
      "number",
      "records",
      "results",
      "bottom",
      "tile.",
      "all",
      "part",
      "belong",
      "same",
      "level.",
      "example",
      "servers"
    ],
    "language": "en",
    "word_count": 98,
    "importance_score": 4.5,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "sacm user interface",
    "contentLower": "the service asset and configuration management user interface has similarities with other service management modules, but it also has some unique features. depending on the type of device or service, the form has unique sections to display more (or less) information than other device types. sacm is a management strategy for tracking components that support your organizational business services. because these components are grouped by levels in the sacm model hierarchy, you can also review device or service information according to its position in that hierarchy. sacm home the service asset and configuration management home page includes: sacm submenus sacm configuration link search sacm summary view sacm submenus submenus appear on the service asset and configuration management top menu, and simplify navigation within the service asset and configuration management database. devices system elements service components actual services stock management reservations asset models infrastruct",
    "keywordsLower": [
      "sacm",
      "user",
      "interface",
      "home",
      "submenus",
      "summary",
      "view",
      "service",
      "asset",
      "configuration",
      "management",
      "similarities",
      "modules",
      "unique",
      "features.",
      "depending",
      "type",
      "device",
      "form",
      "sections",
      "display",
      "less",
      "information",
      "types.",
      "strategy",
      "tracking",
      "components",
      "support",
      "organizational",
      "business",
      "services.",
      "because",
      "grouped",
      "levels",
      "model",
      "hierarchy",
      "review",
      "according",
      "position",
      "hierarchy.",
      "page",
      "includes",
      "link",
      "search",
      "appear",
      "top",
      "menu",
      "simplify",
      "navigation",
      "database.",
      "devices",
      "system",
      "elements",
      "actual",
      "services",
      "stock",
      "reservations",
      "models",
      "infrastructure",
      "peripherals",
      "subscriptions",
      "enterprise",
      "assets",
      "subtype",
      "visual",
      "dashboard",
      "shows",
      "aggregated",
      "about",
      "under",
      "management.",
      "clickable",
      "tiles",
      "represent",
      "filtered",
      "search.",
      "tile",
      "displays",
      "following",
      "label.",
      "one",
      "hierarchical",
      "element",
      "component",
      "definition",
      "peripheral",
      "number.",
      "total",
      "number",
      "records",
      "results",
      "bottom",
      "tile.",
      "all",
      "part",
      "belong",
      "same",
      "level.",
      "example",
      "servers"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Service Asset and Configuration Management model",
    "content": "The Service Management model is a framework to define, manage, and track all individual components that support your organizational business services. Each hierarchical level in the model is a container for one or more components. The Service Catalog provides a list of supported business services that end users can request. The list of available services are organized into categories, such as application services or communications services. The Service Asset and Configuration Management model uses the category information provided in a service request. The category determines which path to follow through the Service Asset and Configuration Management model to access an individual device that supports a business service in that category. The following diagram shows the complete Service Asset and Configuration Management model that depends on the category specified in the service request. Related topics Actual service Service component System element Device Service Portfolio Management M",
    "url": "sacmmodel",
    "filename": "sacmmodel",
    "headings": [
      "Related topics"
    ],
    "keywords": [
      "service",
      "asset",
      "configuration",
      "management",
      "model",
      "related",
      "topics",
      "framework",
      "define",
      "manage",
      "track",
      "all",
      "individual",
      "components",
      "support",
      "organizational",
      "business",
      "services.",
      "hierarchical",
      "level",
      "container",
      "one",
      "components.",
      "catalog",
      "provides",
      "list",
      "supported",
      "services",
      "end",
      "users",
      "request.",
      "available",
      "organized",
      "categories",
      "such",
      "application",
      "communications",
      "uses",
      "category",
      "information",
      "provided",
      "determines",
      "path",
      "follow",
      "through",
      "access",
      "device",
      "supports",
      "category.",
      "following",
      "diagram",
      "shows",
      "complete",
      "depends",
      "specified",
      "actual",
      "component",
      "system",
      "element",
      "portfolio",
      "examples"
    ],
    "language": "en",
    "word_count": 100,
    "importance_score": 2.5,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "service asset and configuration management model",
    "contentLower": "the service management model is a framework to define, manage, and track all individual components that support your organizational business services. each hierarchical level in the model is a container for one or more components. the service catalog provides a list of supported business services that end users can request. the list of available services are organized into categories, such as application services or communications services. the service asset and configuration management model uses the category information provided in a service request. the category determines which path to follow through the service asset and configuration management model to access an individual device that supports a business service in that category. the following diagram shows the complete service asset and configuration management model that depends on the category specified in the service request. related topics actual service service component system element device service portfolio management m",
    "keywordsLower": [
      "service",
      "asset",
      "configuration",
      "management",
      "model",
      "related",
      "topics",
      "framework",
      "define",
      "manage",
      "track",
      "all",
      "individual",
      "components",
      "support",
      "organizational",
      "business",
      "services.",
      "hierarchical",
      "level",
      "container",
      "one",
      "components.",
      "catalog",
      "provides",
      "list",
      "supported",
      "services",
      "end",
      "users",
      "request.",
      "available",
      "organized",
      "categories",
      "such",
      "application",
      "communications",
      "uses",
      "category",
      "information",
      "provided",
      "determines",
      "path",
      "follow",
      "through",
      "access",
      "device",
      "supports",
      "category.",
      "following",
      "diagram",
      "shows",
      "complete",
      "depends",
      "specified",
      "actual",
      "component",
      "system",
      "element",
      "portfolio",
      "examples"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "SACM service component",
    "content": "Each actual service contains one or more service components. Each service component can support one or more actual services. The service component and the actual service represent the business service logic of the organization in the Service Asset and Configuration Management data model. Example: Store (category) Book Store (service definition) Buy new book (actual service) Orders application (service component) Catalog application (service component) Shipment application (service component) Buy used book (actual service) Orders application (service component) Catalog application (service component) Shipment application (service component) CD Store (service definition) ... In this example, the actual services each contain three service components. These service components are the Orders, Catalog and Shipment application. Each component supports the actual service. A service component can also depend on another actual service. For example, the Catalog application uses Database services.",
    "url": "modelservicecomponent",
    "filename": "modelservicecomponent",
    "headings": [
      "Related topics"
    ],
    "keywords": [
      "sacm",
      "service",
      "component",
      "related",
      "topics",
      "actual",
      "contains",
      "one",
      "components.",
      "support",
      "services.",
      "represent",
      "business",
      "logic",
      "organization",
      "asset",
      "configuration",
      "management",
      "data",
      "model.",
      "example",
      "store",
      "category",
      "book",
      "definition",
      "buy",
      "new",
      "orders",
      "application",
      "catalog",
      "shipment",
      "cd",
      "services",
      "contain",
      "three",
      "components",
      "application.",
      "supports",
      "service.",
      "depend",
      "another",
      "uses",
      "database",
      "model",
      "device",
      "system",
      "element",
      "definitions"
    ],
    "language": "en",
    "word_count": 104,
    "importance_score": 3.5,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "sacm service component",
    "contentLower": "each actual service contains one or more service components. each service component can support one or more actual services. the service component and the actual service represent the business service logic of the organization in the service asset and configuration management data model. example: store (category) book store (service definition) buy new book (actual service) orders application (service component) catalog application (service component) shipment application (service component) buy used book (actual service) orders application (service component) catalog application (service component) shipment application (service component) cd store (service definition) ... in this example, the actual services each contain three service components. these service components are the orders, catalog and shipment application. each component supports the actual service. a service component can also depend on another actual service. for example, the catalog application uses database services.",
    "keywordsLower": [
      "sacm",
      "service",
      "component",
      "related",
      "topics",
      "actual",
      "contains",
      "one",
      "components.",
      "support",
      "services.",
      "represent",
      "business",
      "logic",
      "organization",
      "asset",
      "configuration",
      "management",
      "data",
      "model.",
      "example",
      "store",
      "category",
      "book",
      "definition",
      "buy",
      "new",
      "orders",
      "application",
      "catalog",
      "shipment",
      "cd",
      "services",
      "contain",
      "three",
      "components",
      "application.",
      "supports",
      "service.",
      "depend",
      "another",
      "uses",
      "database",
      "model",
      "device",
      "system",
      "element",
      "definitions"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "System element",
    "content": "A system element is the functionality supported by a device. For example, a server is a device. When this server runs a specific set of applications, it becomes a web server. The web server is the system element. The parent service component is a complete application system that depends on the web server (a system element) to make the actual service available to an end user. Each service component contains zero or more system elements. Each system element contains zero or more devices. Each system element can support zero or more service components. For example, an application server and web server are necessary to support an online book ordering system. A database is also essential to store customer and order information captured in the online book ordering system. Example: Store (category) Book Store (service definition) Buy new book (actual service) ... Buy used book (actual service) Orders application (service component) ... Catalog application (service component) JBoss application",
    "url": "modelsyselement",
    "filename": "modelsyselement",
    "headings": [
      "Related topics"
    ],
    "keywords": [
      "system",
      "element",
      "related",
      "topics",
      "functionality",
      "supported",
      "device.",
      "example",
      "server",
      "runs",
      "specific",
      "set",
      "applications",
      "becomes",
      "web",
      "server.",
      "element.",
      "parent",
      "service",
      "component",
      "complete",
      "application",
      "depends",
      "make",
      "actual",
      "available",
      "end",
      "user.",
      "contains",
      "zero",
      "elements.",
      "devices.",
      "support",
      "components.",
      "necessary",
      "online",
      "book",
      "ordering",
      "system.",
      "database",
      "essential",
      "store",
      "customer",
      "order",
      "information",
      "captured",
      "category",
      "definition",
      "buy",
      "new",
      "orders",
      "catalog",
      "jboss",
      "iis",
      "shipment",
      "cd",
      "there",
      "two",
      "elements",
      "contained",
      "application.",
      "defined",
      "record",
      "subordinate",
      "device",
      "records.",
      "note",
      "shows",
      "depend",
      "services",
      "own",
      "oracle",
      "instances",
      "asset",
      "configuration",
      "management",
      "model",
      "definitions"
    ],
    "language": "en",
    "word_count": 106,
    "importance_score": 3.5,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "system element",
    "contentLower": "a system element is the functionality supported by a device. for example, a server is a device. when this server runs a specific set of applications, it becomes a web server. the web server is the system element. the parent service component is a complete application system that depends on the web server (a system element) to make the actual service available to an end user. each service component contains zero or more system elements. each system element contains zero or more devices. each system element can support zero or more service components. for example, an application server and web server are necessary to support an online book ordering system. a database is also essential to store customer and order information captured in the online book ordering system. example: store (category) book store (service definition) buy new book (actual service) ... buy used book (actual service) orders application (service component) ... catalog application (service component) jboss application",
    "keywordsLower": [
      "system",
      "element",
      "related",
      "topics",
      "functionality",
      "supported",
      "device.",
      "example",
      "server",
      "runs",
      "specific",
      "set",
      "applications",
      "becomes",
      "web",
      "server.",
      "element.",
      "parent",
      "service",
      "component",
      "complete",
      "application",
      "depends",
      "make",
      "actual",
      "available",
      "end",
      "user.",
      "contains",
      "zero",
      "elements.",
      "devices.",
      "support",
      "components.",
      "necessary",
      "online",
      "book",
      "ordering",
      "system.",
      "database",
      "essential",
      "store",
      "customer",
      "order",
      "information",
      "captured",
      "category",
      "definition",
      "buy",
      "new",
      "orders",
      "catalog",
      "jboss",
      "iis",
      "shipment",
      "cd",
      "there",
      "two",
      "elements",
      "contained",
      "application.",
      "defined",
      "record",
      "subordinate",
      "device",
      "records.",
      "note",
      "shows",
      "depend",
      "services",
      "own",
      "oracle",
      "instances",
      "asset",
      "configuration",
      "management",
      "model",
      "definitions"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "SACM modeling use case",
    "content": "This use case provides a practical step-by-step modeling guide for the online book store service example. The modeling approach used in this example is top-down modeling; we start from the top logical record types of the service and the relationships between them and proceed to describe the lower infrastructure elements of the tree and their relationships with the upper logical elements. A service-model is a topological graph structure composed of records which are connected via relationships. The most important design consideration behind the Service Management service model is simplifying the complexity of service model graph structures. This ensures that any person with any role in the enterprise can easily consume and understand the service model. Service Management enforces a strict service structure - all services follow the same graphical pattern to facilitate easy interpretation of the model at a single glance. All service models created in Service Management are tree models; g",
    "url": "modelingusecase",
    "filename": "modelingusecase",
    "headings": [
      "Top logical record types and relationships",
      "Actual-service and Service-component",
      "Containment relationship type",
      "Usage relationship type",
      "Containment vs. usage relationship",
      "Service scope demarcation",
      "Distinguishing between infrastructure and business services",
      "Record types representing infrastructure elements",
      "Modeling the service components of the online book store service",
      "Shipment management service component",
      "Order management service component",
      "Book catalog browsing service component",
      "Related topics"
    ],
    "keywords": [
      "sacm",
      "modeling",
      "case",
      "top",
      "logical",
      "record",
      "types",
      "relationships",
      "actual-service",
      "service-component",
      "containment",
      "relationship",
      "type",
      "usage",
      "vs.",
      "service",
      "scope",
      "demarcation",
      "distinguishing",
      "between",
      "infrastructure",
      "business",
      "services",
      "representing",
      "elements",
      "components",
      "online",
      "book",
      "store",
      "shipment",
      "management",
      "component",
      "order",
      "catalog",
      "browsing",
      "related",
      "topics",
      "provides",
      "practical",
      "step-by-step",
      "guide",
      "example.",
      "approach",
      "example",
      "top-down",
      "start",
      "proceed",
      "describe",
      "lower",
      "tree",
      "upper",
      "elements.",
      "service-model",
      "topological",
      "graph",
      "structure",
      "composed",
      "records",
      "connected",
      "via",
      "relationships.",
      "most",
      "important",
      "design",
      "consideration",
      "behind",
      "model",
      "simplifying",
      "complexity",
      "structures.",
      "ensures",
      "any",
      "person",
      "role",
      "enterprise",
      "easily",
      "consume",
      "understand",
      "model.",
      "enforces",
      "strict",
      "all",
      "follow",
      "same",
      "graphical",
      "pattern",
      "facilitate",
      "easy",
      "interpretation",
      "single",
      "glance.",
      "models",
      "created",
      "general",
      "complex",
      "graphs",
      "structures",
      "aren",
      "supported.",
      "represents"
    ],
    "language": "en",
    "word_count": 99,
    "importance_score": 6.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "sacm modeling use case",
    "contentLower": "this use case provides a practical step-by-step modeling guide for the online book store service example. the modeling approach used in this example is top-down modeling; we start from the top logical record types of the service and the relationships between them and proceed to describe the lower infrastructure elements of the tree and their relationships with the upper logical elements. a service-model is a topological graph structure composed of records which are connected via relationships. the most important design consideration behind the service management service model is simplifying the complexity of service model graph structures. this ensures that any person with any role in the enterprise can easily consume and understand the service model. service management enforces a strict service structure - all services follow the same graphical pattern to facilitate easy interpretation of the model at a single glance. all service models created in service management are tree models; g",
    "keywordsLower": [
      "sacm",
      "modeling",
      "case",
      "top",
      "logical",
      "record",
      "types",
      "relationships",
      "actual-service",
      "service-component",
      "containment",
      "relationship",
      "type",
      "usage",
      "vs.",
      "service",
      "scope",
      "demarcation",
      "distinguishing",
      "between",
      "infrastructure",
      "business",
      "services",
      "representing",
      "elements",
      "components",
      "online",
      "book",
      "store",
      "shipment",
      "management",
      "component",
      "order",
      "catalog",
      "browsing",
      "related",
      "topics",
      "provides",
      "practical",
      "step-by-step",
      "guide",
      "example.",
      "approach",
      "example",
      "top-down",
      "start",
      "proceed",
      "describe",
      "lower",
      "tree",
      "upper",
      "elements.",
      "service-model",
      "topological",
      "graph",
      "structure",
      "composed",
      "records",
      "connected",
      "via",
      "relationships.",
      "most",
      "important",
      "design",
      "consideration",
      "behind",
      "model",
      "simplifying",
      "complexity",
      "structures.",
      "ensures",
      "any",
      "person",
      "role",
      "enterprise",
      "easily",
      "consume",
      "understand",
      "model.",
      "enforces",
      "strict",
      "all",
      "follow",
      "same",
      "graphical",
      "pattern",
      "facilitate",
      "easy",
      "interpretation",
      "single",
      "glance.",
      "models",
      "created",
      "general",
      "complex",
      "graphs",
      "structures",
      "aren",
      "supported.",
      "represents"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "SACM and ITIL",
    "content": "The goal of Service Asset and Configuration Management (SACM) is to support ITIL processes with accurate information about service assets and configuration items. The following activities contribute to this support process for service assets and configuration items. Identification Control Studio Reports Audits Verification Depending on your role, you may be assigned tasks that relate to these activities. SACM scope Service asset management inventories assets across the complete service life cycle. The inventory information includes a detailed description of the asset and who is the responsible owner. The scope of asset management includes: Maintenance of accurate asset inventory records from initial acquisition through to end-of-life. Controlled changes to service assets and configuration items. Managed releases of new service assets and configuration items. Identification and governance over shared assets that affect different business services. SACM principles Service Asset and Confi",
    "url": "sacmanditil",
    "filename": "sacmanditil",
    "headings": [
      "SACM scope",
      "SACM principles",
      "Service Asset and Configuration Management roles and permissions"
    ],
    "keywords": [
      "sacm",
      "itil",
      "scope",
      "principles",
      "service",
      "asset",
      "configuration",
      "management",
      "roles",
      "permissions",
      "goal",
      "support",
      "processes",
      "accurate",
      "information",
      "about",
      "assets",
      "items.",
      "following",
      "activities",
      "contribute",
      "process",
      "identification",
      "control",
      "studio",
      "reports",
      "audits",
      "verification",
      "depending",
      "role",
      "assigned",
      "tasks",
      "relate",
      "activities.",
      "inventories",
      "across",
      "complete",
      "life",
      "cycle.",
      "inventory",
      "includes",
      "detailed",
      "description",
      "responsible",
      "owner.",
      "maintenance",
      "records",
      "initial",
      "acquisition",
      "through",
      "end-of-life.",
      "controlled",
      "changes",
      "managed",
      "releases",
      "new",
      "governance",
      "over",
      "shared",
      "affect",
      "different",
      "business",
      "services.",
      "provides",
      "framework",
      "develop",
      "maintain",
      "item",
      "information.",
      "best",
      "practices",
      "ensure",
      "organization",
      "controls",
      "costs",
      "resources.",
      "meets",
      "corporate",
      "requirements",
      "such",
      "software",
      "management.",
      "requirement",
      "available",
      "reliable",
      "cost",
      "effective",
      "evolves",
      "find",
      "fix",
      "reactive",
      "model",
      "proactive",
      "predicts",
      "prevents",
      "outages.",
      "facilitates",
      "traceability",
      "regular",
      "audits."
    ],
    "language": "en",
    "word_count": 99,
    "importance_score": 4.5,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "sacm and itil",
    "contentLower": "the goal of service asset and configuration management (sacm) is to support itil processes with accurate information about service assets and configuration items. the following activities contribute to this support process for service assets and configuration items. identification control studio reports audits verification depending on your role, you may be assigned tasks that relate to these activities. sacm scope service asset management inventories assets across the complete service life cycle. the inventory information includes a detailed description of the asset and who is the responsible owner. the scope of asset management includes: maintenance of accurate asset inventory records from initial acquisition through to end-of-life. controlled changes to service assets and configuration items. managed releases of new service assets and configuration items. identification and governance over shared assets that affect different business services. sacm principles service asset and confi",
    "keywordsLower": [
      "sacm",
      "itil",
      "scope",
      "principles",
      "service",
      "asset",
      "configuration",
      "management",
      "roles",
      "permissions",
      "goal",
      "support",
      "processes",
      "accurate",
      "information",
      "about",
      "assets",
      "items.",
      "following",
      "activities",
      "contribute",
      "process",
      "identification",
      "control",
      "studio",
      "reports",
      "audits",
      "verification",
      "depending",
      "role",
      "assigned",
      "tasks",
      "relate",
      "activities.",
      "inventories",
      "across",
      "complete",
      "life",
      "cycle.",
      "inventory",
      "includes",
      "detailed",
      "description",
      "responsible",
      "owner.",
      "maintenance",
      "records",
      "initial",
      "acquisition",
      "through",
      "end-of-life.",
      "controlled",
      "changes",
      "managed",
      "releases",
      "new",
      "governance",
      "over",
      "shared",
      "affect",
      "different",
      "business",
      "services.",
      "provides",
      "framework",
      "develop",
      "maintain",
      "item",
      "information.",
      "best",
      "practices",
      "ensure",
      "organization",
      "controls",
      "costs",
      "resources.",
      "meets",
      "corporate",
      "requirements",
      "such",
      "software",
      "management.",
      "requirement",
      "available",
      "reliable",
      "cost",
      "effective",
      "evolves",
      "find",
      "fix",
      "reactive",
      "model",
      "proactive",
      "predicts",
      "prevents",
      "outages.",
      "facilitates",
      "traceability",
      "regular",
      "audits."
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Service modeling in Native SACM",
    "content": "The Service Asset and Configuration Management (SACM) model is a framework to define, manage, and track all the individual components that support your organizational business services. Each hierarchical level in the model is a container for one or more components. The hierarchy includes Actual Service, Service Component, Device, and System Element. SACM model hierarchy Actual Service The Actual Service record type in Native SACM is mapped to the Service CI type in UCMDB. An Actual Service is an instance of a service that benefits end users. It might be a business service or an infrastructure service. Typical examples of an Actual Service are the Payroll and Employee services, which manage the payroll and employee systems in HR management. The Actual Service record type can represent either a business service or an infrastructure service. This is determined by setting the appropriate value (business-service or infrastructure-service) in the Actual Service’s subtype attribute. Business ",
    "url": "nsacmservicemodeling",
    "filename": "nsacmservicemodeling",
    "headings": [
      "SACM model hierarchy",
      "CI relationships",
      "How to build the model: top-down and UCMDB auto-discovery",
      "Related topics"
    ],
    "keywords": [
      "service",
      "modeling",
      "native",
      "sacm",
      "model",
      "hierarchy",
      "ci",
      "relationships",
      "build",
      "top-down",
      "ucmdb",
      "auto-discovery",
      "related",
      "topics",
      "asset",
      "configuration",
      "management",
      "framework",
      "define",
      "manage",
      "track",
      "all",
      "individual",
      "components",
      "support",
      "organizational",
      "business",
      "services.",
      "hierarchical",
      "level",
      "container",
      "one",
      "components.",
      "includes",
      "actual",
      "component",
      "device",
      "system",
      "element.",
      "record",
      "type",
      "mapped",
      "ucmdb.",
      "instance",
      "benefits",
      "end",
      "users.",
      "infrastructure",
      "service.",
      "typical",
      "examples",
      "payroll",
      "employee",
      "services",
      "systems",
      "hr",
      "management.",
      "represent",
      "either",
      "determined",
      "setting",
      "appropriate",
      "value",
      "business-service",
      "infrastructure-service",
      "subtype",
      "attribute.",
      "directly",
      "customers",
      "while",
      "usually",
      "t.",
      "instead",
      "backend",
      "example",
      "database",
      "application",
      "represents",
      "second-level",
      "logic",
      "subsystem",
      "high-level",
      "web",
      "server",
      "defined",
      "node",
      "physical",
      "virtual",
      "configurable",
      "items",
      "discovered",
      "created",
      "nodes",
      "smartphone",
      "laptop",
      "network",
      "storage",
      "device.",
      "enum",
      "field"
    ],
    "language": "en",
    "word_count": 98,
    "importance_score": 5.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "service modeling in native sacm",
    "contentLower": "the service asset and configuration management (sacm) model is a framework to define, manage, and track all the individual components that support your organizational business services. each hierarchical level in the model is a container for one or more components. the hierarchy includes actual service, service component, device, and system element. sacm model hierarchy actual service the actual service record type in native sacm is mapped to the service ci type in ucmdb. an actual service is an instance of a service that benefits end users. it might be a business service or an infrastructure service. typical examples of an actual service are the payroll and employee services, which manage the payroll and employee systems in hr management. the actual service record type can represent either a business service or an infrastructure service. this is determined by setting the appropriate value (business-service or infrastructure-service) in the actual service’s subtype attribute. business ",
    "keywordsLower": [
      "service",
      "modeling",
      "native",
      "sacm",
      "model",
      "hierarchy",
      "ci",
      "relationships",
      "build",
      "top-down",
      "ucmdb",
      "auto-discovery",
      "related",
      "topics",
      "asset",
      "configuration",
      "management",
      "framework",
      "define",
      "manage",
      "track",
      "all",
      "individual",
      "components",
      "support",
      "organizational",
      "business",
      "services.",
      "hierarchical",
      "level",
      "container",
      "one",
      "components.",
      "includes",
      "actual",
      "component",
      "device",
      "system",
      "element.",
      "record",
      "type",
      "mapped",
      "ucmdb.",
      "instance",
      "benefits",
      "end",
      "users.",
      "infrastructure",
      "service.",
      "typical",
      "examples",
      "payroll",
      "employee",
      "services",
      "systems",
      "hr",
      "management.",
      "represent",
      "either",
      "determined",
      "setting",
      "appropriate",
      "value",
      "business-service",
      "infrastructure-service",
      "subtype",
      "attribute.",
      "directly",
      "customers",
      "while",
      "usually",
      "t.",
      "instead",
      "backend",
      "example",
      "database",
      "application",
      "represents",
      "second-level",
      "logic",
      "subsystem",
      "high-level",
      "web",
      "server",
      "defined",
      "node",
      "physical",
      "virtual",
      "configurable",
      "items",
      "discovered",
      "created",
      "nodes",
      "smartphone",
      "laptop",
      "network",
      "storage",
      "device.",
      "enum",
      "field"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Tenant export and import",
    "content": "When you plan to move a tenant that has Native SACM enabled (either inside the same farm or across farms), you need to perform the following tasks to set up your new tenant successfully. Preparation Prepare a new active tenant that doesn't have Native SACM enabled. See Set up a tenant. Prepare a new UCMDB customer to which the new tenant will connect. We recommend that you use the tenant ID as the UCMDB customer ID. For more details about the Multi Customer mode in UCMDB, see UCMDB Multi-Customer overview. To create a new UCMDB customer, see Create a customer. Ensure all customizations from the source UCMDB customer are moved to the target UCMDB customer. We recommend that you use the Package Manager to transfer customizations. Customized Infrastructure Settings in the source UCMDB customer (marked in the Was modified column) should also be configured in the target UCMDB customer. Push data from the source UCMDB customer to the target one To migrate CIs from the source UCMDB customer t",
    "url": "tenantclone",
    "filename": "tenantclone",
    "headings": [
      "Preparation",
      "Push data from the source UCMDB customer to the target one",
      "Import the source tenant to the target tenant",
      "Reconfigure Native SACM in the target tenant",
      "Synchronize the BitmapId and BitPostion of each CI from UCMDB to Service Management",
      "Some background"
    ],
    "keywords": [
      "https://<service-management-host>:<service-management-port>/rest/<target-tenant-id>/cmsx/ci/model/action/migration",
      "installService.bat",
      "tenant",
      "export",
      "import",
      "preparation",
      "push",
      "data",
      "source",
      "ucmdb",
      "customer",
      "target",
      "one",
      "reconfigure",
      "native",
      "sacm",
      "synchronize",
      "bitmapid",
      "bitpostion",
      "ci",
      "service",
      "management",
      "background",
      "plan",
      "move",
      "enabled",
      "either",
      "inside",
      "same",
      "farm",
      "across",
      "farms",
      "need",
      "perform",
      "following",
      "tasks",
      "set",
      "new",
      "successfully.",
      "prepare",
      "active",
      "doesn",
      "enabled.",
      "see",
      "tenant.",
      "connect.",
      "recommend",
      "id",
      "id.",
      "details",
      "about",
      "multi",
      "mode",
      "multi-customer",
      "overview.",
      "create",
      "customer.",
      "ensure",
      "all",
      "customizations",
      "moved",
      "package",
      "manager",
      "transfer",
      "customizations.",
      "customized",
      "infrastructure",
      "settings",
      "marked",
      "modified",
      "column",
      "configured",
      "migrate",
      "cis",
      "log",
      "suite",
      "administration",
      "admin.",
      "information",
      "tenants",
      "once",
      "ready",
      "migration",
      "complete",
      "having",
      "again.",
      "values",
      "gateway",
      "url",
      "user",
      "name",
      "password",
      "run",
      "rest",
      "api",
      "regenerated",
      "bitposition",
      "any",
      "client",
      "this."
    ],
    "language": "en",
    "word_count": 107,
    "importance_score": 6.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "tenant export and import",
    "contentLower": "when you plan to move a tenant that has native sacm enabled (either inside the same farm or across farms), you need to perform the following tasks to set up your new tenant successfully. preparation prepare a new active tenant that doesn't have native sacm enabled. see set up a tenant. prepare a new ucmdb customer to which the new tenant will connect. we recommend that you use the tenant id as the ucmdb customer id. for more details about the multi customer mode in ucmdb, see ucmdb multi-customer overview. to create a new ucmdb customer, see create a customer. ensure all customizations from the source ucmdb customer are moved to the target ucmdb customer. we recommend that you use the package manager to transfer customizations. customized infrastructure settings in the source ucmdb customer (marked in the was modified column) should also be configured in the target ucmdb customer. push data from the source ucmdb customer to the target one to migrate cis from the source ucmdb customer t",
    "keywordsLower": [
      "https://<service-management-host>:<service-management-port>/rest/<target-tenant-id>/cmsx/ci/model/action/migration",
      "installservice.bat",
      "tenant",
      "export",
      "import",
      "preparation",
      "push",
      "data",
      "source",
      "ucmdb",
      "customer",
      "target",
      "one",
      "reconfigure",
      "native",
      "sacm",
      "synchronize",
      "bitmapid",
      "bitpostion",
      "ci",
      "service",
      "management",
      "background",
      "plan",
      "move",
      "enabled",
      "either",
      "inside",
      "same",
      "farm",
      "across",
      "farms",
      "need",
      "perform",
      "following",
      "tasks",
      "set",
      "new",
      "successfully.",
      "prepare",
      "active",
      "doesn",
      "enabled.",
      "see",
      "tenant.",
      "connect.",
      "recommend",
      "id",
      "id.",
      "details",
      "about",
      "multi",
      "mode",
      "multi-customer",
      "overview.",
      "create",
      "customer.",
      "ensure",
      "all",
      "customizations",
      "moved",
      "package",
      "manager",
      "transfer",
      "customizations.",
      "customized",
      "infrastructure",
      "settings",
      "marked",
      "modified",
      "column",
      "configured",
      "migrate",
      "cis",
      "log",
      "suite",
      "administration",
      "admin.",
      "information",
      "tenants",
      "once",
      "ready",
      "migration",
      "complete",
      "having",
      "again.",
      "values",
      "gateway",
      "url",
      "user",
      "name",
      "password",
      "run",
      "rest",
      "api",
      "regenerated",
      "bitposition",
      "any",
      "client",
      "this."
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "System elements",
    "content": "A system element is the functionality supported by a device. For example, a server is a device. When this server runs a specific set of applications, it becomes a web server. The web server is the system element. The parent service component is a complete application system that depends on the web server (a system element) to make the actual service available to an end user. Each service component contains zero or more system elements. Each system element contains zero or more devices. Each system element can support zero or more service components. Related topics How to create a system element record How to edit a system element record How to delete a system element record System element workflow",
    "url": "syselements",
    "filename": "syselements",
    "headings": [
      "Related topics"
    ],
    "keywords": [
      "system",
      "elements",
      "related",
      "topics",
      "element",
      "functionality",
      "supported",
      "device.",
      "example",
      "server",
      "runs",
      "specific",
      "set",
      "applications",
      "becomes",
      "web",
      "server.",
      "element.",
      "parent",
      "service",
      "component",
      "complete",
      "application",
      "depends",
      "make",
      "actual",
      "available",
      "end",
      "user.",
      "contains",
      "zero",
      "elements.",
      "devices.",
      "support",
      "components.",
      "create",
      "record",
      "edit",
      "delete",
      "workflow"
    ],
    "language": "en",
    "word_count": 73,
    "importance_score": 3.5,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "system elements",
    "contentLower": "a system element is the functionality supported by a device. for example, a server is a device. when this server runs a specific set of applications, it becomes a web server. the web server is the system element. the parent service component is a complete application system that depends on the web server (a system element) to make the actual service available to an end user. each service component contains zero or more system elements. each system element contains zero or more devices. each system element can support zero or more service components. related topics how to create a system element record how to edit a system element record how to delete a system element record system element workflow",
    "keywordsLower": [
      "system",
      "elements",
      "related",
      "topics",
      "element",
      "functionality",
      "supported",
      "device.",
      "example",
      "server",
      "runs",
      "specific",
      "set",
      "applications",
      "becomes",
      "web",
      "server.",
      "element.",
      "parent",
      "service",
      "component",
      "complete",
      "application",
      "depends",
      "make",
      "actual",
      "available",
      "end",
      "user.",
      "contains",
      "zero",
      "elements.",
      "devices.",
      "support",
      "components.",
      "create",
      "record",
      "edit",
      "delete",
      "workflow"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "System element workflow",
    "content": "This section describes the metaphases and subordinate phases in the life cycle of a system element. The system element workflow relies on business rules. Rules repeat from one phase to another when the end user can make a change to a field modified by a business rule during that phase. For more information about the out-of-the-box business rules defined for the system element workflow, see System element process - Business rules. Metaphase: In use The subordinate phase is In use. Phase Transition Description In use Manual An active system element is In use that supports a service component. Next phase: Ended Example: a database or a web server. Metaphase: End of life (End) The subordinate phase is Ended. Phase Transition Description Ended Manual The system element is no longer available. Next phase: None, or you can return to In use Example: you can return the system element to service by returning it to the In use phase. Related topics System elements How to create a system element re",
    "url": "syselementwflw",
    "filename": "syselementwflw",
    "headings": [
      "Metaphase: In use",
      "Metaphase: End of life (End)",
      "Related topics"
    ],
    "keywords": [
      "system",
      "element",
      "workflow",
      "metaphase",
      "end",
      "life",
      "related",
      "topics",
      "section",
      "describes",
      "metaphases",
      "subordinate",
      "phases",
      "cycle",
      "element.",
      "relies",
      "business",
      "rules.",
      "rules",
      "repeat",
      "one",
      "phase",
      "another",
      "user",
      "make",
      "change",
      "field",
      "modified",
      "rule",
      "during",
      "phase.",
      "information",
      "about",
      "out-of-the-box",
      "defined",
      "see",
      "process",
      "use.",
      "transition",
      "description",
      "manual",
      "active",
      "supports",
      "service",
      "component.",
      "next",
      "ended",
      "example",
      "database",
      "web",
      "server.",
      "ended.",
      "longer",
      "available.",
      "none",
      "return",
      "returning",
      "elements",
      "create",
      "record",
      "edit",
      "delete",
      "view",
      "impact",
      "map"
    ],
    "language": "en",
    "word_count": 104,
    "importance_score": 4.5,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "system element workflow",
    "contentLower": "this section describes the metaphases and subordinate phases in the life cycle of a system element. the system element workflow relies on business rules. rules repeat from one phase to another when the end user can make a change to a field modified by a business rule during that phase. for more information about the out-of-the-box business rules defined for the system element workflow, see system element process - business rules. metaphase: in use the subordinate phase is in use. phase transition description in use manual an active system element is in use that supports a service component. next phase: ended example: a database or a web server. metaphase: end of life (end) the subordinate phase is ended. phase transition description ended manual the system element is no longer available. next phase: none, or you can return to in use example: you can return the system element to service by returning it to the in use phase. related topics system elements how to create a system element re",
    "keywordsLower": [
      "system",
      "element",
      "workflow",
      "metaphase",
      "end",
      "life",
      "related",
      "topics",
      "section",
      "describes",
      "metaphases",
      "subordinate",
      "phases",
      "cycle",
      "element.",
      "relies",
      "business",
      "rules.",
      "rules",
      "repeat",
      "one",
      "phase",
      "another",
      "user",
      "make",
      "change",
      "field",
      "modified",
      "rule",
      "during",
      "phase.",
      "information",
      "about",
      "out-of-the-box",
      "defined",
      "see",
      "process",
      "use.",
      "transition",
      "description",
      "manual",
      "active",
      "supports",
      "service",
      "component.",
      "next",
      "ended",
      "example",
      "database",
      "web",
      "server.",
      "ended.",
      "longer",
      "available.",
      "none",
      "return",
      "returning",
      "elements",
      "create",
      "record",
      "edit",
      "delete",
      "view",
      "impact",
      "map"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "SACM service components",
    "content": "Each actual service contains one or more service components. Each service component can support one or more actual services. The service component and the actual service represent the business service logic of the organization in the Service Asset and Configuration Management data model. Related topics How to create a service component record How to edit a service component record How to delete a service component record Service component workflow",
    "url": "servicecomponents",
    "filename": "servicecomponents",
    "headings": [
      "Related topics"
    ],
    "keywords": [
      "sacm",
      "service",
      "components",
      "related",
      "topics",
      "actual",
      "contains",
      "one",
      "components.",
      "component",
      "support",
      "services.",
      "represent",
      "business",
      "logic",
      "organization",
      "asset",
      "configuration",
      "management",
      "data",
      "model.",
      "create",
      "record",
      "edit",
      "delete",
      "workflow"
    ],
    "language": "en",
    "word_count": 47,
    "importance_score": 2.5,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "sacm service components",
    "contentLower": "each actual service contains one or more service components. each service component can support one or more actual services. the service component and the actual service represent the business service logic of the organization in the service asset and configuration management data model. related topics how to create a service component record how to edit a service component record how to delete a service component record service component workflow",
    "keywordsLower": [
      "sacm",
      "service",
      "components",
      "related",
      "topics",
      "actual",
      "contains",
      "one",
      "components.",
      "component",
      "support",
      "services.",
      "represent",
      "business",
      "logic",
      "organization",
      "asset",
      "configuration",
      "management",
      "data",
      "model.",
      "create",
      "record",
      "edit",
      "delete",
      "workflow"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "SACM service component workflow",
    "content": "This section describes the metaphases and subordinate phases in the life cycle of a service component. The service component workflow relies on business rules. Rules repeat from one phase to another when the end user can make a change to a field affected by a business rule during that phase. For more information about the out-of-the-box business rules defined for the service component workflow, see Service component process - Business rules. Metaphase: Planning The service component is in the planning stages. Phase Transition Description Plan Manual This is the starting point for the basic service component workflow. The plan can contain any or all of the following: Scope Description Availability Required resources Dependencies Processes and templates Service Level Agreements Key Performance Indicators Risks Approvals Next phase: Build Example: a new version (v2.0) of the enterprise email system is available. The organization needs to plan the implementation, decide which features to e",
    "url": "servicecomponentwflw",
    "filename": "servicecomponentwflw",
    "headings": [
      "Metaphase: Planning",
      "Metaphase: Construction",
      "Metaphase: Operation",
      "Metaphase: Final (End)",
      "Related topics"
    ],
    "keywords": [
      "v3.0",
      "v2.0",
      "sacm",
      "service",
      "component",
      "workflow",
      "metaphase",
      "planning",
      "construction",
      "operation",
      "final",
      "end",
      "related",
      "topics",
      "section",
      "describes",
      "metaphases",
      "subordinate",
      "phases",
      "life",
      "cycle",
      "component.",
      "relies",
      "business",
      "rules.",
      "rules",
      "repeat",
      "one",
      "phase",
      "another",
      "user",
      "make",
      "change",
      "field",
      "affected",
      "rule",
      "during",
      "phase.",
      "information",
      "about",
      "out-of-the-box",
      "defined",
      "see",
      "process",
      "stages.",
      "transition",
      "description",
      "plan",
      "manual",
      "starting",
      "point",
      "basic",
      "workflow.",
      "contain",
      "any",
      "all",
      "following",
      "scope",
      "availability",
      "required",
      "resources",
      "dependencies",
      "processes",
      "templates",
      "level",
      "agreements",
      "key",
      "performance",
      "indicators",
      "risks",
      "approvals",
      "next",
      "build",
      "example",
      "new",
      "version",
      "enterprise",
      "email",
      "system",
      "available.",
      "organization",
      "needs",
      "implementation",
      "decide",
      "features",
      "enable",
      "assess",
      "security",
      "impact",
      "changes",
      "existing",
      "protocols.",
      "enters",
      "building",
      "design",
      "built",
      "matches",
      "produced",
      "manually",
      "operate"
    ],
    "language": "en",
    "word_count": 105,
    "importance_score": 5.5,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "sacm service component workflow",
    "contentLower": "this section describes the metaphases and subordinate phases in the life cycle of a service component. the service component workflow relies on business rules. rules repeat from one phase to another when the end user can make a change to a field affected by a business rule during that phase. for more information about the out-of-the-box business rules defined for the service component workflow, see service component process - business rules. metaphase: planning the service component is in the planning stages. phase transition description plan manual this is the starting point for the basic service component workflow. the plan can contain any or all of the following: scope description availability required resources dependencies processes and templates service level agreements key performance indicators risks approvals next phase: build example: a new version (v2.0) of the enterprise email system is available. the organization needs to plan the implementation, decide which features to e",
    "keywordsLower": [
      "v3.0",
      "v2.0",
      "sacm",
      "service",
      "component",
      "workflow",
      "metaphase",
      "planning",
      "construction",
      "operation",
      "final",
      "end",
      "related",
      "topics",
      "section",
      "describes",
      "metaphases",
      "subordinate",
      "phases",
      "life",
      "cycle",
      "component.",
      "relies",
      "business",
      "rules.",
      "rules",
      "repeat",
      "one",
      "phase",
      "another",
      "user",
      "make",
      "change",
      "field",
      "affected",
      "rule",
      "during",
      "phase.",
      "information",
      "about",
      "out-of-the-box",
      "defined",
      "see",
      "process",
      "stages.",
      "transition",
      "description",
      "plan",
      "manual",
      "starting",
      "point",
      "basic",
      "workflow.",
      "contain",
      "any",
      "all",
      "following",
      "scope",
      "availability",
      "required",
      "resources",
      "dependencies",
      "processes",
      "templates",
      "level",
      "agreements",
      "key",
      "performance",
      "indicators",
      "risks",
      "approvals",
      "next",
      "build",
      "example",
      "new",
      "version",
      "enterprise",
      "email",
      "system",
      "available.",
      "organization",
      "needs",
      "implementation",
      "decide",
      "features",
      "enable",
      "assess",
      "security",
      "impact",
      "changes",
      "existing",
      "protocols.",
      "enters",
      "building",
      "design",
      "built",
      "matches",
      "produced",
      "manually",
      "operate"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Stock Management",
    "content": "Stockrooms are physical locations where stocks and assets are stored. You manage your stockrooms and the content of your stockrooms from the Stock Management area of the SACM module. Related topics How to create and edit a stockroom record",
    "url": "stockmgmt",
    "filename": "stockmgmt",
    "headings": [
      "Related topics"
    ],
    "keywords": [
      "stock",
      "management",
      "related",
      "topics",
      "stockrooms",
      "physical",
      "locations",
      "stocks",
      "assets",
      "stored.",
      "manage",
      "content",
      "area",
      "sacm",
      "module.",
      "create",
      "edit",
      "stockroom",
      "record"
    ],
    "language": "en",
    "word_count": 23,
    "importance_score": 2.5,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "stock management",
    "contentLower": "stockrooms are physical locations where stocks and assets are stored. you manage your stockrooms and the content of your stockrooms from the stock management area of the sacm module. related topics how to create and edit a stockroom record",
    "keywordsLower": [
      "stock",
      "management",
      "related",
      "topics",
      "stockrooms",
      "physical",
      "locations",
      "stocks",
      "assets",
      "stored.",
      "manage",
      "content",
      "area",
      "sacm",
      "module.",
      "create",
      "edit",
      "stockroom",
      "record"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Stockroom workflow",
    "content": "The stockroom has the following workflow: Metaphase: Operational The subordinate phase is Operational. Phase Transition Description Operational Manual The stockroom is operational and you can manage the stocks in the stockroom. Next phase: Closed Metaphase: Closed (End) The subordinate phase is Closed. Phase Transition Description Closed Manual The stockroom is unavailable for storage. Next phase: Operational Related topics Stock Management How to create and edit a stockroom record",
    "url": "stockroomwflw",
    "filename": "stockroomwflw",
    "headings": [
      "Metaphase: Operational",
      "Metaphase: Closed (End)",
      "Related topics"
    ],
    "keywords": [
      "stockroom",
      "workflow",
      "metaphase",
      "operational",
      "closed",
      "end",
      "related",
      "topics",
      "following",
      "subordinate",
      "phase",
      "operational.",
      "transition",
      "description",
      "manual",
      "manage",
      "stocks",
      "stockroom.",
      "next",
      "closed.",
      "unavailable",
      "storage.",
      "stock",
      "management",
      "create",
      "edit",
      "record"
    ],
    "language": "en",
    "word_count": 48,
    "importance_score": 3.5,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "stockroom workflow",
    "contentLower": "the stockroom has the following workflow: metaphase: operational the subordinate phase is operational. phase transition description operational manual the stockroom is operational and you can manage the stocks in the stockroom. next phase: closed metaphase: closed (end) the subordinate phase is closed. phase transition description closed manual the stockroom is unavailable for storage. next phase: operational related topics stock management how to create and edit a stockroom record",
    "keywordsLower": [
      "stockroom",
      "workflow",
      "metaphase",
      "operational",
      "closed",
      "end",
      "related",
      "topics",
      "following",
      "subordinate",
      "phase",
      "operational.",
      "transition",
      "description",
      "manual",
      "manage",
      "stocks",
      "stockroom.",
      "next",
      "closed.",
      "unavailable",
      "storage.",
      "stock",
      "management",
      "create",
      "edit",
      "record"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Shipment file format",
    "content": "When adding assets records to SACM by the advance ship notice method, the data must be in CSV format and match the structure displayed in the template. The CSV format must use UTF-8 encoding to retain special characters such as language accents. For more information, see How to create a CSV file with UTF-8 encoding from an Excel file. To obtain the advance ship notice template: From the main menu, select Build > Service Asset & Configuration. Click the Receive assets link in the upper right corner. The Receive assets dialog box is displayed. In the Method field, select Advance ship notice. Click the Download sample file link that's displayed. File format: The advance ship notice file must include the following fields, in order, as the header: AssetTagPrefix AssetType SubType AssetModel WarrantyEndDate UnitPrice Currency ExternalPONumber Quantity Serial number There must not be any blanks for the following fields: AssetType SubType Quantity You may not select any additional fields to in",
    "url": "addassetsfile",
    "filename": "addassetsfile",
    "headings": [
      "Related topics"
    ],
    "keywords": [
      "shipment",
      "file",
      "format",
      "related",
      "topics",
      "adding",
      "assets",
      "records",
      "sacm",
      "advance",
      "ship",
      "notice",
      "method",
      "data",
      "csv",
      "match",
      "structure",
      "displayed",
      "template.",
      "utf-8",
      "encoding",
      "retain",
      "special",
      "characters",
      "such",
      "language",
      "accents.",
      "information",
      "see",
      "create",
      "excel",
      "file.",
      "obtain",
      "template",
      "main",
      "menu",
      "select",
      "build",
      "service",
      "asset",
      "configuration.",
      "click",
      "receive",
      "link",
      "upper",
      "right",
      "corner.",
      "dialog",
      "box",
      "displayed.",
      "field",
      "notice.",
      "download",
      "sample",
      "include",
      "following",
      "fields",
      "order",
      "header",
      "assettagprefix",
      "assettype",
      "subtype",
      "assetmodel",
      "warrantyenddate",
      "unitprice",
      "currency",
      "externalponumber",
      "quantity",
      "serial",
      "number",
      "there",
      "any",
      "blanks",
      "additional",
      "configuration",
      "management"
    ],
    "language": "en",
    "word_count": 108,
    "importance_score": 3.5,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "shipment file format",
    "contentLower": "when adding assets records to sacm by the advance ship notice method, the data must be in csv format and match the structure displayed in the template. the csv format must use utf-8 encoding to retain special characters such as language accents. for more information, see how to create a csv file with utf-8 encoding from an excel file. to obtain the advance ship notice template: from the main menu, select build > service asset & configuration. click the receive assets link in the upper right corner. the receive assets dialog box is displayed. in the method field, select advance ship notice. click the download sample file link that's displayed. file format: the advance ship notice file must include the following fields, in order, as the header: assettagprefix assettype subtype assetmodel warrantyenddate unitprice currency externalponumber quantity serial number there must not be any blanks for the following fields: assettype subtype quantity you may not select any additional fields to in",
    "keywordsLower": [
      "shipment",
      "file",
      "format",
      "related",
      "topics",
      "adding",
      "assets",
      "records",
      "sacm",
      "advance",
      "ship",
      "notice",
      "method",
      "data",
      "csv",
      "match",
      "structure",
      "displayed",
      "template.",
      "utf-8",
      "encoding",
      "retain",
      "special",
      "characters",
      "such",
      "language",
      "accents.",
      "information",
      "see",
      "create",
      "excel",
      "file.",
      "obtain",
      "template",
      "main",
      "menu",
      "select",
      "build",
      "service",
      "asset",
      "configuration.",
      "click",
      "receive",
      "link",
      "upper",
      "right",
      "corner.",
      "dialog",
      "box",
      "displayed.",
      "field",
      "notice.",
      "download",
      "sample",
      "include",
      "following",
      "fields",
      "order",
      "header",
      "assettagprefix",
      "assettype",
      "subtype",
      "assetmodel",
      "warrantyenddate",
      "unitprice",
      "currency",
      "externalponumber",
      "quantity",
      "serial",
      "number",
      "there",
      "any",
      "blanks",
      "additional",
      "configuration",
      "management"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Reservations",
    "content": "In Service Management, reservations help you efficiently identify and pre-allocate appropriate assets to match requests in your organization. Essentially there are multiple parts to the reservations feature. One is the reservations record attached to an asset (for example, a device or an infrastructure & peripheral asset or an enterprise asset) which displays basic information about a reservation. Another is the capability to configure Service Management so that, where appropriate, requests are automatically fulfilled by matching, identifying, and reserving suitable assets. This capability is enabled by knitting together with Reservations several other features of Service Management, such as: In SACM: Stockroom Management and Asset Models In Service Catalog Management: Offerings and the Task Plan In Service Request Management: Requests Reservations business rules A user with the appropriate permissions, such as a Stockroom Admin or Asset & Configuration Administrator, can have an overv",
    "url": "reservations",
    "filename": "reservations",
    "headings": [
      "Related topics"
    ],
    "keywords": [
      "reservations",
      "related",
      "topics",
      "service",
      "management",
      "help",
      "efficiently",
      "identify",
      "pre-allocate",
      "appropriate",
      "assets",
      "match",
      "requests",
      "organization.",
      "essentially",
      "there",
      "multiple",
      "parts",
      "feature.",
      "one",
      "record",
      "attached",
      "asset",
      "example",
      "device",
      "infrastructure",
      "peripheral",
      "enterprise",
      "displays",
      "basic",
      "information",
      "about",
      "reservation.",
      "another",
      "capability",
      "configure",
      "automatically",
      "fulfilled",
      "matching",
      "identifying",
      "reserving",
      "suitable",
      "assets.",
      "enabled",
      "knitting",
      "together",
      "several",
      "features",
      "such",
      "sacm",
      "stockroom",
      "models",
      "catalog",
      "offerings",
      "task",
      "plan",
      "request",
      "business",
      "rules",
      "user",
      "permissions",
      "admin",
      "configuration",
      "administrator",
      "overview",
      "through",
      "list",
      "view.",
      "view",
      "main",
      "menu",
      "select",
      "build",
      "home",
      "reservations.",
      "set",
      "automatic",
      "reservation",
      "test",
      "create",
      "manual",
      "cancel",
      "close",
      "workflow"
    ],
    "language": "en",
    "word_count": 88,
    "importance_score": 3.5,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "reservations",
    "contentLower": "in service management, reservations help you efficiently identify and pre-allocate appropriate assets to match requests in your organization. essentially there are multiple parts to the reservations feature. one is the reservations record attached to an asset (for example, a device or an infrastructure & peripheral asset or an enterprise asset) which displays basic information about a reservation. another is the capability to configure service management so that, where appropriate, requests are automatically fulfilled by matching, identifying, and reserving suitable assets. this capability is enabled by knitting together with reservations several other features of service management, such as: in sacm: stockroom management and asset models in service catalog management: offerings and the task plan in service request management: requests reservations business rules a user with the appropriate permissions, such as a stockroom admin or asset & configuration administrator, can have an overv",
    "keywordsLower": [
      "reservations",
      "related",
      "topics",
      "service",
      "management",
      "help",
      "efficiently",
      "identify",
      "pre-allocate",
      "appropriate",
      "assets",
      "match",
      "requests",
      "organization.",
      "essentially",
      "there",
      "multiple",
      "parts",
      "feature.",
      "one",
      "record",
      "attached",
      "asset",
      "example",
      "device",
      "infrastructure",
      "peripheral",
      "enterprise",
      "displays",
      "basic",
      "information",
      "about",
      "reservation.",
      "another",
      "capability",
      "configure",
      "automatically",
      "fulfilled",
      "matching",
      "identifying",
      "reserving",
      "suitable",
      "assets.",
      "enabled",
      "knitting",
      "together",
      "several",
      "features",
      "such",
      "sacm",
      "stockroom",
      "models",
      "catalog",
      "offerings",
      "task",
      "plan",
      "request",
      "business",
      "rules",
      "user",
      "permissions",
      "admin",
      "configuration",
      "administrator",
      "overview",
      "through",
      "list",
      "view.",
      "view",
      "main",
      "menu",
      "select",
      "build",
      "home",
      "reservations.",
      "set",
      "automatic",
      "reservation",
      "test",
      "create",
      "manual",
      "cancel",
      "close",
      "workflow"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Set up an automatic reservation",
    "content": "The following steps are an example of how, in outline, you can set up a reservation for your organization to deal with a request for a new PC. By using the example as a framework, you can set up reservations to deal with devices, infrastructure & peripheral assets, and enterprise assets managed within Service Management. The following content uses examples in the Service Management sample data. For more information about the sample data, see Sample data. The reservation business rule currently doesn't handle quantity. When reserving a consumable asset with a quantity greater than one, all enterprise assets will be reserved. To set up an automatic reservation: From the main menu, select Plan > Service Catalog > Offerings. Filter the records to display only Service offerings with the Service definition of PC Lifecycle. Select the (DEMO) Request a new PC offering record. Click Details on the toolbar. The record is displayed. Note the following in the Offering details section of the Genera",
    "url": "setreservations",
    "filename": "setreservations",
    "headings": [
      "Related topics"
    ],
    "keywords": [
      "set",
      "automatic",
      "reservation",
      "related",
      "topics",
      "following",
      "steps",
      "example",
      "outline",
      "organization",
      "deal",
      "request",
      "new",
      "pc.",
      "framework",
      "reservations",
      "devices",
      "infrastructure",
      "peripheral",
      "assets",
      "enterprise",
      "managed",
      "service",
      "management.",
      "content",
      "uses",
      "examples",
      "management",
      "sample",
      "data.",
      "information",
      "about",
      "data",
      "see",
      "business",
      "rule",
      "currently",
      "doesn",
      "handle",
      "quantity.",
      "reserving",
      "consumable",
      "asset",
      "quantity",
      "greater",
      "one",
      "all",
      "reserved.",
      "main",
      "menu",
      "select",
      "plan",
      "catalog",
      "offerings.",
      "filter",
      "records",
      "display",
      "offerings",
      "definition",
      "pc",
      "lifecycle.",
      "demo",
      "offering",
      "record.",
      "click",
      "details",
      "toolbar.",
      "record",
      "displayed.",
      "note",
      "section",
      "general",
      "tab",
      "label.",
      "text",
      "displays",
      "title",
      "suggests",
      "user",
      "portal.",
      "status.",
      "active",
      "work.",
      "offered",
      "model.",
      "model",
      "create",
      "offering.",
      "task",
      "tab.",
      "approve",
      "part",
      "there",
      "requiring",
      "managerial",
      "approval",
      "ordered",
      "high",
      "performance.",
      "isn"
    ],
    "language": "en",
    "word_count": 98,
    "importance_score": 3.5,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "set up an automatic reservation",
    "contentLower": "the following steps are an example of how, in outline, you can set up a reservation for your organization to deal with a request for a new pc. by using the example as a framework, you can set up reservations to deal with devices, infrastructure & peripheral assets, and enterprise assets managed within service management. the following content uses examples in the service management sample data. for more information about the sample data, see sample data. the reservation business rule currently doesn't handle quantity. when reserving a consumable asset with a quantity greater than one, all enterprise assets will be reserved. to set up an automatic reservation: from the main menu, select plan > service catalog > offerings. filter the records to display only service offerings with the service definition of pc lifecycle. select the (demo) request a new pc offering record. click details on the toolbar. the record is displayed. note the following in the offering details section of the genera",
    "keywordsLower": [
      "set",
      "automatic",
      "reservation",
      "related",
      "topics",
      "following",
      "steps",
      "example",
      "outline",
      "organization",
      "deal",
      "request",
      "new",
      "pc.",
      "framework",
      "reservations",
      "devices",
      "infrastructure",
      "peripheral",
      "assets",
      "enterprise",
      "managed",
      "service",
      "management.",
      "content",
      "uses",
      "examples",
      "management",
      "sample",
      "data.",
      "information",
      "about",
      "data",
      "see",
      "business",
      "rule",
      "currently",
      "doesn",
      "handle",
      "quantity.",
      "reserving",
      "consumable",
      "asset",
      "quantity",
      "greater",
      "one",
      "all",
      "reserved.",
      "main",
      "menu",
      "select",
      "plan",
      "catalog",
      "offerings.",
      "filter",
      "records",
      "display",
      "offerings",
      "definition",
      "pc",
      "lifecycle.",
      "demo",
      "offering",
      "record.",
      "click",
      "details",
      "toolbar.",
      "record",
      "displayed.",
      "note",
      "section",
      "general",
      "tab",
      "label.",
      "text",
      "displays",
      "title",
      "suggests",
      "user",
      "portal.",
      "status.",
      "active",
      "work.",
      "offered",
      "model.",
      "model",
      "create",
      "offering.",
      "task",
      "tab.",
      "approve",
      "part",
      "there",
      "requiring",
      "managerial",
      "approval",
      "ordered",
      "high",
      "performance.",
      "isn"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Test the automatic reservation",
    "content": "To test the automatic reservation configuration, do each of the following: Create the request From the main menu, select Service Portal. In Search topics, type \"Request new PC.\" Search results are displayed. Click the offering \"(DEMO) Request a new PC.\" The request form opens. In Business justification, type \"I need a new PC for testing.\" Click Submit. A request receipt is displayed. Review the request From the main menu, select Run > Service Request > Requests. Select the newly created request and click Details. The request is displayed. Click the Reservation tab. If the automatic reservation has completed: The Reserved flag for the reserved device is set to true; and The reservation details are displayed here. Click the Task Plan tab. In the Fulfill section, if the automatic reservation has completed, the Reserve PC part of the task plan is highlighted and marked \"Completed.\" In addition, Service Management automatically sends a notification email to the person entered in the Reserve",
    "url": "testreservations",
    "filename": "testreservations",
    "headings": [
      "Create the request",
      "Review the request",
      "Complete the remaining manual tasks",
      "Review the device details",
      "Review the resolution",
      "Validate the request completion",
      "If the reservation task completes without a reservation",
      "Related topics"
    ],
    "keywords": [
      "test",
      "automatic",
      "reservation",
      "create",
      "request",
      "review",
      "complete",
      "remaining",
      "manual",
      "tasks",
      "device",
      "details",
      "resolution",
      "validate",
      "completion",
      "task",
      "completes",
      "related",
      "topics",
      "configuration",
      "following",
      "main",
      "menu",
      "select",
      "service",
      "portal.",
      "search",
      "type",
      "new",
      "pc.",
      "results",
      "displayed.",
      "click",
      "offering",
      "demo",
      "form",
      "opens.",
      "business",
      "justification",
      "need",
      "pc",
      "testing.",
      "submit.",
      "receipt",
      "run",
      "requests.",
      "newly",
      "created",
      "details.",
      "tab.",
      "completed",
      "reserved",
      "flag",
      "set",
      "true",
      "displayed",
      "here.",
      "plan",
      "fulfill",
      "section",
      "reserve",
      "part",
      "highlighted",
      "marked",
      "completed.",
      "addition",
      "management",
      "automatically",
      "sends",
      "notification",
      "email",
      "person",
      "entered",
      "field.",
      "next",
      "stage",
      "prepare",
      "note",
      "out-of-the-box",
      "assigned",
      "hardware",
      "services",
      "group.",
      "group",
      "view",
      "task.",
      "filter.",
      "save.",
      "close",
      "reservation.",
      "completes.",
      "deliver",
      "request.",
      "tab",
      "id",
      "link",
      "under",
      "asset.",
      "record",
      "point"
    ],
    "language": "en",
    "word_count": 105,
    "importance_score": 6.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "test the automatic reservation",
    "contentLower": "to test the automatic reservation configuration, do each of the following: create the request from the main menu, select service portal. in search topics, type \"request new pc.\" search results are displayed. click the offering \"(demo) request a new pc.\" the request form opens. in business justification, type \"i need a new pc for testing.\" click submit. a request receipt is displayed. review the request from the main menu, select run > service request > requests. select the newly created request and click details. the request is displayed. click the reservation tab. if the automatic reservation has completed: the reserved flag for the reserved device is set to true; and the reservation details are displayed here. click the task plan tab. in the fulfill section, if the automatic reservation has completed, the reserve pc part of the task plan is highlighted and marked \"completed.\" in addition, service management automatically sends a notification email to the person entered in the reserve",
    "keywordsLower": [
      "test",
      "automatic",
      "reservation",
      "create",
      "request",
      "review",
      "complete",
      "remaining",
      "manual",
      "tasks",
      "device",
      "details",
      "resolution",
      "validate",
      "completion",
      "task",
      "completes",
      "related",
      "topics",
      "configuration",
      "following",
      "main",
      "menu",
      "select",
      "service",
      "portal.",
      "search",
      "type",
      "new",
      "pc.",
      "results",
      "displayed.",
      "click",
      "offering",
      "demo",
      "form",
      "opens.",
      "business",
      "justification",
      "need",
      "pc",
      "testing.",
      "submit.",
      "receipt",
      "run",
      "requests.",
      "newly",
      "created",
      "details.",
      "tab.",
      "completed",
      "reserved",
      "flag",
      "set",
      "true",
      "displayed",
      "here.",
      "plan",
      "fulfill",
      "section",
      "reserve",
      "part",
      "highlighted",
      "marked",
      "completed.",
      "addition",
      "management",
      "automatically",
      "sends",
      "notification",
      "email",
      "person",
      "entered",
      "field.",
      "next",
      "stage",
      "prepare",
      "note",
      "out-of-the-box",
      "assigned",
      "hardware",
      "services",
      "group.",
      "group",
      "view",
      "task.",
      "filter.",
      "save.",
      "close",
      "reservation.",
      "completes.",
      "deliver",
      "request.",
      "tab",
      "id",
      "link",
      "under",
      "asset.",
      "record",
      "point"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Reservations workflow",
    "content": "This section describes the metaphases and subordinate phases in the life cycle of a reservation. The reservation workflow relies on business rules. Rules repeat from one phase to another when the end user can make a change to a field affected by a business rule during that phase. For more information about the out-of-the-box business rules defined for the reservation workflow, see Reservation process - Business rules. Metaphase: Active Phase Transition Description Active Manual The reservation is active. When the reservation period ends, you can manually transition it to the Ended phase. If the reservation is canceled, you can manually transition it to the Canceled phase. Next phase: Ended or Canceled Metaphase: Inactive (End) Phase Transition Description Ended None The reservation period has ended. For example, the reserved asset has been checked out of the stockroom and is in use. Next phase: None Canceled None The reservation has been canceled. For example, the reserved asset has no",
    "url": "reservationswflw",
    "filename": "reservationswflw",
    "headings": [
      "Metaphase: Active",
      "Metaphase: Inactive (End)",
      "Related topics"
    ],
    "keywords": [
      "reservations",
      "workflow",
      "metaphase",
      "active",
      "inactive",
      "end",
      "related",
      "topics",
      "section",
      "describes",
      "metaphases",
      "subordinate",
      "phases",
      "life",
      "cycle",
      "reservation.",
      "reservation",
      "relies",
      "business",
      "rules.",
      "rules",
      "repeat",
      "one",
      "phase",
      "another",
      "user",
      "make",
      "change",
      "field",
      "affected",
      "rule",
      "during",
      "phase.",
      "information",
      "about",
      "out-of-the-box",
      "defined",
      "see",
      "process",
      "transition",
      "description",
      "manual",
      "active.",
      "period",
      "ends",
      "manually",
      "ended",
      "canceled",
      "next",
      "none",
      "ended.",
      "example",
      "reserved",
      "asset",
      "checked",
      "out",
      "stockroom",
      "use.",
      "canceled.",
      "period.",
      "set",
      "automatic",
      "test",
      "create",
      "cancel",
      "close"
    ],
    "language": "en",
    "word_count": 97,
    "importance_score": 4.5,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "reservations workflow",
    "contentLower": "this section describes the metaphases and subordinate phases in the life cycle of a reservation. the reservation workflow relies on business rules. rules repeat from one phase to another when the end user can make a change to a field affected by a business rule during that phase. for more information about the out-of-the-box business rules defined for the reservation workflow, see reservation process - business rules. metaphase: active phase transition description active manual the reservation is active. when the reservation period ends, you can manually transition it to the ended phase. if the reservation is canceled, you can manually transition it to the canceled phase. next phase: ended or canceled metaphase: inactive (end) phase transition description ended none the reservation period has ended. for example, the reserved asset has been checked out of the stockroom and is in use. next phase: none canceled none the reservation has been canceled. for example, the reserved asset has no",
    "keywordsLower": [
      "reservations",
      "workflow",
      "metaphase",
      "active",
      "inactive",
      "end",
      "related",
      "topics",
      "section",
      "describes",
      "metaphases",
      "subordinate",
      "phases",
      "life",
      "cycle",
      "reservation.",
      "reservation",
      "relies",
      "business",
      "rules.",
      "rules",
      "repeat",
      "one",
      "phase",
      "another",
      "user",
      "make",
      "change",
      "field",
      "affected",
      "rule",
      "during",
      "phase.",
      "information",
      "about",
      "out-of-the-box",
      "defined",
      "see",
      "process",
      "transition",
      "description",
      "manual",
      "active.",
      "period",
      "ends",
      "manually",
      "ended",
      "canceled",
      "next",
      "none",
      "ended.",
      "example",
      "reserved",
      "asset",
      "checked",
      "out",
      "stockroom",
      "use.",
      "canceled.",
      "period.",
      "set",
      "automatic",
      "test",
      "create",
      "cancel",
      "close"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Retire an asset model record",
    "content": "You must have the appropriate permissions to be able to retire an asset model. If you retire an asset model, this has no effect on existing asset records. To retire an asset model means changing its status, as shown in the workflow snapshot at the top of the model, from Active to Inactive. From the main menu, select Build > Service Asset and Configuration. From SACM Home, select Asset Models. There are two ways to view the SACM asset model records: tree view and table view. In the tree view: Select the asset model. Click , then Edit to display the selected record. In the table view: Select the asset model. Click the record identifier in the Id column to display the selected record. Click Inactive. Click Save on the toolbar. Related topics Asset models How to create an asset model record How to edit an asset model record",
    "url": "retireassetmodel",
    "filename": "retireassetmodel",
    "headings": [
      "Related topics"
    ],
    "keywords": [
      "retire",
      "asset",
      "model",
      "record",
      "related",
      "topics",
      "appropriate",
      "permissions",
      "able",
      "model.",
      "effect",
      "existing",
      "records.",
      "means",
      "changing",
      "status",
      "shown",
      "workflow",
      "snapshot",
      "top",
      "active",
      "inactive.",
      "main",
      "menu",
      "select",
      "build",
      "service",
      "configuration.",
      "sacm",
      "home",
      "models.",
      "there",
      "two",
      "ways",
      "view",
      "records",
      "tree",
      "table",
      "view.",
      "click",
      "edit",
      "display",
      "selected",
      "record.",
      "identifier",
      "id",
      "column",
      "save",
      "toolbar.",
      "models",
      "create"
    ],
    "language": "en",
    "word_count": 94,
    "importance_score": 3.5,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "retire an asset model record",
    "contentLower": "you must have the appropriate permissions to be able to retire an asset model. if you retire an asset model, this has no effect on existing asset records. to retire an asset model means changing its status, as shown in the workflow snapshot at the top of the model, from active to inactive. from the main menu, select build > service asset and configuration. from sacm home, select asset models. there are two ways to view the sacm asset model records: tree view and table view. in the tree view: select the asset model. click , then edit to display the selected record. in the table view: select the asset model. click the record identifier in the id column to display the selected record. click inactive. click save on the toolbar. related topics asset models how to create an asset model record how to edit an asset model record",
    "keywordsLower": [
      "retire",
      "asset",
      "model",
      "record",
      "related",
      "topics",
      "appropriate",
      "permissions",
      "able",
      "model.",
      "effect",
      "existing",
      "records.",
      "means",
      "changing",
      "status",
      "shown",
      "workflow",
      "snapshot",
      "top",
      "active",
      "inactive.",
      "main",
      "menu",
      "select",
      "build",
      "service",
      "configuration.",
      "sacm",
      "home",
      "models.",
      "there",
      "two",
      "ways",
      "view",
      "records",
      "tree",
      "table",
      "view.",
      "click",
      "edit",
      "display",
      "selected",
      "record.",
      "identifier",
      "id",
      "column",
      "save",
      "toolbar.",
      "models",
      "create"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Subscriptions",
    "content": "In Service Management, in addition to managing ownership and use, you can also use the subscription feature to manage access to a service or asset. Typically, the subscriber (or the appropriate cost center) will incur a charge for the subscription. A subscription can have a set start date, end date, an initial cost, recurring cost, and status. The status displays the current state of the subscription, reflecting whether the subscriber can access the service or asset. View subscription records From the main menu, select Build > Service Asset & Configuration. From SACM Home, select Subscriptions. Note The Subscribers tab of actual service records also displays details of subscriptions for the selected actual service. Related topics How to create a subscription record How to edit a subscription record How to configure Service Management for subscriptions Subscription workflow",
    "url": "subscriptions",
    "filename": "subscriptions",
    "headings": [
      "View subscription records",
      "Related topics"
    ],
    "keywords": [
      "subscriptions",
      "view",
      "subscription",
      "records",
      "related",
      "topics",
      "service",
      "management",
      "addition",
      "managing",
      "ownership",
      "feature",
      "manage",
      "access",
      "asset.",
      "typically",
      "subscriber",
      "appropriate",
      "cost",
      "center",
      "incur",
      "charge",
      "subscription.",
      "set",
      "start",
      "date",
      "end",
      "initial",
      "recurring",
      "status.",
      "status",
      "displays",
      "current",
      "state",
      "reflecting",
      "whether",
      "main",
      "menu",
      "select",
      "build",
      "asset",
      "configuration.",
      "sacm",
      "home",
      "subscriptions.",
      "note",
      "subscribers",
      "tab",
      "actual",
      "details",
      "selected",
      "service.",
      "create",
      "record",
      "edit",
      "configure",
      "workflow"
    ],
    "language": "en",
    "word_count": 82,
    "importance_score": 4.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "subscriptions",
    "contentLower": "in service management, in addition to managing ownership and use, you can also use the subscription feature to manage access to a service or asset. typically, the subscriber (or the appropriate cost center) will incur a charge for the subscription. a subscription can have a set start date, end date, an initial cost, recurring cost, and status. the status displays the current state of the subscription, reflecting whether the subscriber can access the service or asset. view subscription records from the main menu, select build > service asset & configuration. from sacm home, select subscriptions. note the subscribers tab of actual service records also displays details of subscriptions for the selected actual service. related topics how to create a subscription record how to edit a subscription record how to configure service management for subscriptions subscription workflow",
    "keywordsLower": [
      "subscriptions",
      "view",
      "subscription",
      "records",
      "related",
      "topics",
      "service",
      "management",
      "addition",
      "managing",
      "ownership",
      "feature",
      "manage",
      "access",
      "asset.",
      "typically",
      "subscriber",
      "appropriate",
      "cost",
      "center",
      "incur",
      "charge",
      "subscription.",
      "set",
      "start",
      "date",
      "end",
      "initial",
      "recurring",
      "status.",
      "status",
      "displays",
      "current",
      "state",
      "reflecting",
      "whether",
      "main",
      "menu",
      "select",
      "build",
      "asset",
      "configuration.",
      "sacm",
      "home",
      "subscriptions.",
      "note",
      "subscribers",
      "tab",
      "actual",
      "details",
      "selected",
      "service.",
      "create",
      "record",
      "edit",
      "configure",
      "workflow"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Subscription workflow",
    "content": "This section describes the metaphases and subordinate phases in the life cycle of subscription. The workflow relies on business rules. Rules repeat from one phase to another when the end user can make a change to a field affected by a business rule during that phase. For more information about the out-of-the-box business rules defined for the subscription workflow, see Subscription process - Business rules. Normal The Normal subscription workflow is used for normal subscriptions. Metaphase: Operation Phase Transition Description Active Manual The subscription is available for selection. To make the subscription inactive, manually transition it to the Inactive phase. Next phase: Inactive Metaphase: Final (End) Phase Transition Description Inactive Manual The subscription isn't available for selection. To make the subscription active again, manually transition it to the Active phase. Next phase: None, or return to Active Subscription Lifecycle The Subscription Lifecycle subscription work",
    "url": "subscriptionswflw",
    "filename": "subscriptionswflw",
    "headings": [
      "Normal",
      "Metaphase: Operation",
      "Metaphase: Final (End)",
      "Subscription Lifecycle",
      "Related topics"
    ],
    "keywords": [
      "subscription",
      "workflow",
      "normal",
      "metaphase",
      "operation",
      "final",
      "end",
      "lifecycle",
      "related",
      "topics",
      "section",
      "describes",
      "metaphases",
      "subordinate",
      "phases",
      "life",
      "cycle",
      "subscription.",
      "relies",
      "business",
      "rules.",
      "rules",
      "repeat",
      "one",
      "phase",
      "another",
      "user",
      "make",
      "change",
      "field",
      "affected",
      "rule",
      "during",
      "phase.",
      "information",
      "about",
      "out-of-the-box",
      "defined",
      "see",
      "process",
      "subscriptions.",
      "transition",
      "description",
      "active",
      "manual",
      "available",
      "selection.",
      "inactive",
      "manually",
      "next",
      "isn",
      "again",
      "none",
      "return",
      "cloud",
      "services.",
      "request",
      "automatic",
      "initiated.",
      "provision",
      "system",
      "starts",
      "fulfillment.",
      "cancel",
      "cancels",
      "future",
      "service",
      "portal.",
      "actual",
      "created",
      "plan.",
      "provisioning",
      "service.",
      "fulfillment",
      "successful.",
      "failed",
      "build.",
      "active.",
      "expire",
      "reaches",
      "date.",
      "modify",
      "modifies",
      "operate.",
      "updating",
      "completes",
      "modification.",
      "cancelling",
      "deprovision",
      "cancellation",
      "operate",
      "plan",
      "build",
      "after",
      "moves",
      "decommission.",
      "release",
      "component",
      "cis",
      "remain"
    ],
    "language": "en",
    "word_count": 100,
    "importance_score": 5.5,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "subscription workflow",
    "contentLower": "this section describes the metaphases and subordinate phases in the life cycle of subscription. the workflow relies on business rules. rules repeat from one phase to another when the end user can make a change to a field affected by a business rule during that phase. for more information about the out-of-the-box business rules defined for the subscription workflow, see subscription process - business rules. normal the normal subscription workflow is used for normal subscriptions. metaphase: operation phase transition description active manual the subscription is available for selection. to make the subscription inactive, manually transition it to the inactive phase. next phase: inactive metaphase: final (end) phase transition description inactive manual the subscription isn't available for selection. to make the subscription active again, manually transition it to the active phase. next phase: none, or return to active subscription lifecycle the subscription lifecycle subscription work",
    "keywordsLower": [
      "subscription",
      "workflow",
      "normal",
      "metaphase",
      "operation",
      "final",
      "end",
      "lifecycle",
      "related",
      "topics",
      "section",
      "describes",
      "metaphases",
      "subordinate",
      "phases",
      "life",
      "cycle",
      "subscription.",
      "relies",
      "business",
      "rules.",
      "rules",
      "repeat",
      "one",
      "phase",
      "another",
      "user",
      "make",
      "change",
      "field",
      "affected",
      "rule",
      "during",
      "phase.",
      "information",
      "about",
      "out-of-the-box",
      "defined",
      "see",
      "process",
      "subscriptions.",
      "transition",
      "description",
      "active",
      "manual",
      "available",
      "selection.",
      "inactive",
      "manually",
      "next",
      "isn",
      "again",
      "none",
      "return",
      "cloud",
      "services.",
      "request",
      "automatic",
      "initiated.",
      "provision",
      "system",
      "starts",
      "fulfillment.",
      "cancel",
      "cancels",
      "future",
      "service",
      "portal.",
      "actual",
      "created",
      "plan.",
      "provisioning",
      "service.",
      "fulfillment",
      "successful.",
      "failed",
      "build.",
      "active.",
      "expire",
      "reaches",
      "date.",
      "modify",
      "modifies",
      "operate.",
      "updating",
      "completes",
      "modification.",
      "cancelling",
      "deprovision",
      "cancellation",
      "operate",
      "plan",
      "build",
      "after",
      "moves",
      "decommission.",
      "release",
      "component",
      "cis",
      "remain"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Subscription notification rules",
    "content": "Service Management sends an email notification to designated users when a business rule triggers a notification event. The following sections describe the notifications for cloud subscriptions. The subscription date is calculated using the time zone defined in the email recipient. If no time zone is defined in the email recipient, the Time zone definition field in Application Settings will be used. If the Time zone definition field in Application Settings is also empty, the time zone of Service Management server will be used. Subscription expiration Template Recipients Content Notes Subscription email template for subscription about to expire Subscriber The members of the groups which can access the subscription Subscription ID Subscription title Subscription start date Subscription end date Subscription initial cost Subscription recurring cost \"View subscription\" link The notification is triggered when the subscription is about to expire (15 days before subscription expiration). Subsc",
    "url": "subscriptionnotificationrule",
    "filename": "subscriptionnotificationrule",
    "headings": [
      "Subscription expiration",
      "Service deployment",
      "Service cancellation",
      "Service modification",
      "Service transfer"
    ],
    "keywords": [
      "subscription",
      "notification",
      "rules",
      "expiration",
      "service",
      "deployment",
      "cancellation",
      "modification",
      "transfer",
      "management",
      "sends",
      "email",
      "designated",
      "users",
      "business",
      "rule",
      "triggers",
      "event.",
      "following",
      "sections",
      "describe",
      "notifications",
      "cloud",
      "subscriptions.",
      "date",
      "calculated",
      "time",
      "zone",
      "defined",
      "recipient.",
      "recipient",
      "definition",
      "field",
      "application",
      "settings",
      "used.",
      "empty",
      "server",
      "template",
      "recipients",
      "content",
      "notes",
      "about",
      "expire",
      "subscriber",
      "members",
      "groups",
      "access",
      "id",
      "title",
      "start",
      "end",
      "initial",
      "cost",
      "recurring",
      "view",
      "link",
      "triggered",
      "15",
      "days",
      "before",
      "expired",
      "related",
      "canceled",
      "successful",
      "instance",
      "details",
      "successfully",
      "deployed.",
      "failed",
      "error",
      "message",
      "failed.",
      "requested",
      "canceled.",
      "successful.",
      "new",
      "original"
    ],
    "language": "en",
    "word_count": 101,
    "importance_score": 5.5,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "subscription notification rules",
    "contentLower": "service management sends an email notification to designated users when a business rule triggers a notification event. the following sections describe the notifications for cloud subscriptions. the subscription date is calculated using the time zone defined in the email recipient. if no time zone is defined in the email recipient, the time zone definition field in application settings will be used. if the time zone definition field in application settings is also empty, the time zone of service management server will be used. subscription expiration template recipients content notes subscription email template for subscription about to expire subscriber the members of the groups which can access the subscription subscription id subscription title subscription start date subscription end date subscription initial cost subscription recurring cost \"view subscription\" link the notification is triggered when the subscription is about to expire (15 days before subscription expiration). subsc",
    "keywordsLower": [
      "subscription",
      "notification",
      "rules",
      "expiration",
      "service",
      "deployment",
      "cancellation",
      "modification",
      "transfer",
      "management",
      "sends",
      "email",
      "designated",
      "users",
      "business",
      "rule",
      "triggers",
      "event.",
      "following",
      "sections",
      "describe",
      "notifications",
      "cloud",
      "subscriptions.",
      "date",
      "calculated",
      "time",
      "zone",
      "defined",
      "recipient.",
      "recipient",
      "definition",
      "field",
      "application",
      "settings",
      "used.",
      "empty",
      "server",
      "template",
      "recipients",
      "content",
      "notes",
      "about",
      "expire",
      "subscriber",
      "members",
      "groups",
      "access",
      "id",
      "title",
      "start",
      "end",
      "initial",
      "cost",
      "recurring",
      "view",
      "link",
      "triggered",
      "15",
      "days",
      "before",
      "expired",
      "related",
      "canceled",
      "successful",
      "instance",
      "details",
      "successfully",
      "deployed.",
      "failed",
      "error",
      "message",
      "failed.",
      "requested",
      "canceled.",
      "successful.",
      "new",
      "original"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Transfer subscriptions",
    "content": "You can transfer cloud subscriptions from one subscriber to another subscriber, with the following restrictions: Only the subscriptions in Active status/phase can be transferred. All existing requests for the subscription will be transferred together with the subscription. The current subscriber and the target subscriber must be in the same tenant. Cloud subscriptions without group access can be: Transferred by: - The current subscriber - The manager of the current subscriber Transferred to: - Any user in the same tenant Note: - Contacts can't be the target subscriber, because contacts can't log in to Service Portal. - If data segmentation is enabled, only the users belong to the same data domain can be the target subscriber Cloud subscriptions with group access can be: Transferred by: - The current subscriber - The manager of the current subscriber - Any member in “Full access” groups of this subscription - The managers of those members in “Full access” groups of this subscription Tra",
    "url": "transfersubscriptions",
    "filename": "transfersubscriptions",
    "headings": [
      "Transfer subscriptions"
    ],
    "keywords": [
      "transfer",
      "subscriptions",
      "cloud",
      "one",
      "subscriber",
      "another",
      "following",
      "restrictions",
      "active",
      "status",
      "phase",
      "transferred.",
      "all",
      "existing",
      "requests",
      "subscription",
      "transferred",
      "together",
      "subscription.",
      "current",
      "target",
      "same",
      "tenant.",
      "group",
      "access",
      "manager",
      "any",
      "user",
      "tenant",
      "note",
      "contacts",
      "because",
      "log",
      "service",
      "portal.",
      "data",
      "segmentation",
      "enabled",
      "users",
      "belong",
      "domain",
      "member",
      "full",
      "groups",
      "managers",
      "members",
      "there",
      "defined",
      "selects",
      "matches",
      "found",
      "message",
      "displayed",
      "list.",
      "himself",
      "herself",
      "follow",
      "steps",
      "portal",
      "click",
      "menu",
      "top",
      "left",
      "page.",
      "select",
      "services",
      "assets",
      "tab.",
      "want",
      "transfer.",
      "actions",
      "drop-down",
      "whom",
      "once",
      "process",
      "fulfilled",
      "selected",
      "step",
      "become",
      "request",
      "generated",
      "track",
      "action.",
      "find",
      "history",
      "section"
    ],
    "language": "en",
    "word_count": 88,
    "importance_score": 3.5,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "transfer subscriptions",
    "contentLower": "you can transfer cloud subscriptions from one subscriber to another subscriber, with the following restrictions: only the subscriptions in active status/phase can be transferred. all existing requests for the subscription will be transferred together with the subscription. the current subscriber and the target subscriber must be in the same tenant. cloud subscriptions without group access can be: transferred by: - the current subscriber - the manager of the current subscriber transferred to: - any user in the same tenant note: - contacts can't be the target subscriber, because contacts can't log in to service portal. - if data segmentation is enabled, only the users belong to the same data domain can be the target subscriber cloud subscriptions with group access can be: transferred by: - the current subscriber - the manager of the current subscriber - any member in “full access” groups of this subscription - the managers of those members in “full access” groups of this subscription tra",
    "keywordsLower": [
      "transfer",
      "subscriptions",
      "cloud",
      "one",
      "subscriber",
      "another",
      "following",
      "restrictions",
      "active",
      "status",
      "phase",
      "transferred.",
      "all",
      "existing",
      "requests",
      "subscription",
      "transferred",
      "together",
      "subscription.",
      "current",
      "target",
      "same",
      "tenant.",
      "group",
      "access",
      "manager",
      "any",
      "user",
      "tenant",
      "note",
      "contacts",
      "because",
      "log",
      "service",
      "portal.",
      "data",
      "segmentation",
      "enabled",
      "users",
      "belong",
      "domain",
      "member",
      "full",
      "groups",
      "managers",
      "members",
      "there",
      "defined",
      "selects",
      "matches",
      "found",
      "message",
      "displayed",
      "list.",
      "himself",
      "herself",
      "follow",
      "steps",
      "portal",
      "click",
      "menu",
      "top",
      "left",
      "page.",
      "select",
      "services",
      "assets",
      "tab.",
      "want",
      "transfer.",
      "actions",
      "drop-down",
      "whom",
      "once",
      "process",
      "fulfilled",
      "selected",
      "step",
      "become",
      "request",
      "generated",
      "track",
      "action.",
      "find",
      "history",
      "section"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Survey Management",
    "content": "Survey management enables you to create surveys, send them to end users, and to consume the data collected by the surveys. Related topics Category Links Get started Surveys Administer Fields Forms Roles Use Survey Management workflow Hot Topic Analytics for surveys Develop Single record APIs Record bulk update and collection APIs",
    "url": "surveysoverview",
    "filename": "surveysoverview",
    "headings": [
      "Related topics"
    ],
    "keywords": [
      "survey",
      "management",
      "related",
      "topics",
      "enables",
      "create",
      "surveys",
      "send",
      "end",
      "users",
      "consume",
      "data",
      "collected",
      "surveys.",
      "category",
      "links",
      "get",
      "started",
      "administer",
      "fields",
      "forms",
      "roles",
      "workflow",
      "hot",
      "topic",
      "analytics",
      "develop",
      "single",
      "record",
      "apis",
      "bulk",
      "update",
      "collection"
    ],
    "language": "en",
    "word_count": 41,
    "importance_score": 2.5,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "survey management",
    "contentLower": "survey management enables you to create surveys, send them to end users, and to consume the data collected by the surveys. related topics category links get started surveys administer fields forms roles use survey management workflow hot topic analytics for surveys develop single record apis record bulk update and collection apis",
    "keywordsLower": [
      "survey",
      "management",
      "related",
      "topics",
      "enables",
      "create",
      "surveys",
      "send",
      "end",
      "users",
      "consume",
      "data",
      "collected",
      "surveys.",
      "category",
      "links",
      "get",
      "started",
      "administer",
      "fields",
      "forms",
      "roles",
      "workflow",
      "hot",
      "topic",
      "analytics",
      "develop",
      "single",
      "record",
      "apis",
      "bulk",
      "update",
      "collection"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Survey Management workflow",
    "content": "This section describes the metaphases and subordinate phases in the life cycle of a survey. Metaphase: Creation The survey is created. Phase Transition Description Create Manual The Survey Editor creates a survey and adds sections, structure, and questions to it, as well as selecting the fields that will appear in the survey reports. Note The survey can't advance to Prepare phase until at least one question has been added to a survey. It's possible to return a survey to Create phase from a later phase. You can add new questions, inactivate existing questions (thereby removing them from the survey sent to users), or add report fields. This has the following implications: An existing survey that already has results is being edited. Changing existing questions might change their meanings in the results. However, in order to maintain data integrity, you can't: Change the type of existing questions. Add or remove questions from existing Rating group questions. Change the record type of the ",
    "url": "surveyswflw",
    "filename": "surveyswflw",
    "headings": [
      "Metaphase: Creation",
      "Metaphase: Publication",
      "Metaphase: Consumption",
      "Metaphase: Retirement (End)",
      "Related topics"
    ],
    "keywords": [
      "survey",
      "management",
      "workflow",
      "metaphase",
      "creation",
      "publication",
      "consumption",
      "retirement",
      "end",
      "related",
      "topics",
      "section",
      "describes",
      "metaphases",
      "subordinate",
      "phases",
      "life",
      "cycle",
      "survey.",
      "created.",
      "phase",
      "transition",
      "description",
      "create",
      "manual",
      "editor",
      "creates",
      "adds",
      "sections",
      "structure",
      "questions",
      "well",
      "selecting",
      "fields",
      "appear",
      "reports.",
      "note",
      "advance",
      "prepare",
      "until",
      "least",
      "one",
      "question",
      "added",
      "possible",
      "return",
      "later",
      "phase.",
      "add",
      "new",
      "inactivate",
      "existing",
      "thereby",
      "removing",
      "sent",
      "users",
      "report",
      "fields.",
      "following",
      "implications",
      "already",
      "results",
      "edited.",
      "changing",
      "change",
      "meanings",
      "results.",
      "however",
      "order",
      "maintain",
      "data",
      "integrity",
      "type",
      "questions.",
      "remove",
      "rating",
      "group",
      "record",
      "either",
      "user.",
      "time",
      "move",
      "completed",
      "back",
      "version",
      "incremented.",
      "enables",
      "filtering",
      "reports",
      "responses",
      "answered",
      "specific",
      "versions",
      "next",
      "prepared",
      "execution.",
      "automatic",
      "define",
      "execution",
      "dates"
    ],
    "language": "en",
    "word_count": 101,
    "importance_score": 5.5,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "survey management workflow",
    "contentLower": "this section describes the metaphases and subordinate phases in the life cycle of a survey. metaphase: creation the survey is created. phase transition description create manual the survey editor creates a survey and adds sections, structure, and questions to it, as well as selecting the fields that will appear in the survey reports. note the survey can't advance to prepare phase until at least one question has been added to a survey. it's possible to return a survey to create phase from a later phase. you can add new questions, inactivate existing questions (thereby removing them from the survey sent to users), or add report fields. this has the following implications: an existing survey that already has results is being edited. changing existing questions might change their meanings in the results. however, in order to maintain data integrity, you can't: change the type of existing questions. add or remove questions from existing rating group questions. change the record type of the ",
    "keywordsLower": [
      "survey",
      "management",
      "workflow",
      "metaphase",
      "creation",
      "publication",
      "consumption",
      "retirement",
      "end",
      "related",
      "topics",
      "section",
      "describes",
      "metaphases",
      "subordinate",
      "phases",
      "life",
      "cycle",
      "survey.",
      "created.",
      "phase",
      "transition",
      "description",
      "create",
      "manual",
      "editor",
      "creates",
      "adds",
      "sections",
      "structure",
      "questions",
      "well",
      "selecting",
      "fields",
      "appear",
      "reports.",
      "note",
      "advance",
      "prepare",
      "until",
      "least",
      "one",
      "question",
      "added",
      "possible",
      "return",
      "later",
      "phase.",
      "add",
      "new",
      "inactivate",
      "existing",
      "thereby",
      "removing",
      "sent",
      "users",
      "report",
      "fields.",
      "following",
      "implications",
      "already",
      "results",
      "edited.",
      "changing",
      "change",
      "meanings",
      "results.",
      "however",
      "order",
      "maintain",
      "data",
      "integrity",
      "type",
      "questions.",
      "remove",
      "rating",
      "group",
      "record",
      "either",
      "user.",
      "time",
      "move",
      "completed",
      "back",
      "version",
      "incremented.",
      "enables",
      "filtering",
      "reports",
      "responses",
      "answered",
      "specific",
      "versions",
      "next",
      "prepared",
      "execution.",
      "automatic",
      "define",
      "execution",
      "dates"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Survey Management procedures",
    "content": "In Survey Management, you can create and manage surveys, and create reports containing results of the surveys. Related topics How to set up a survey How to add questions to a survey How to prepare a survey for execution How to conduct a survey Export data from a survey Retrieve survey responses manually",
    "url": "surveysbasictasks",
    "filename": "surveysbasictasks",
    "headings": [
      "Related topics"
    ],
    "keywords": [
      "survey",
      "management",
      "procedures",
      "related",
      "topics",
      "create",
      "manage",
      "surveys",
      "reports",
      "containing",
      "results",
      "surveys.",
      "set",
      "add",
      "questions",
      "prepare",
      "execution",
      "conduct",
      "export",
      "data",
      "retrieve",
      "responses",
      "manually"
    ],
    "language": "en",
    "word_count": 32,
    "importance_score": 2.5,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "survey management procedures",
    "contentLower": "in survey management, you can create and manage surveys, and create reports containing results of the surveys. related topics how to set up a survey how to add questions to a survey how to prepare a survey for execution how to conduct a survey export data from a survey retrieve survey responses manually",
    "keywordsLower": [
      "survey",
      "management",
      "procedures",
      "related",
      "topics",
      "create",
      "manage",
      "surveys",
      "reports",
      "containing",
      "results",
      "surveys.",
      "set",
      "add",
      "questions",
      "prepare",
      "execution",
      "conduct",
      "export",
      "data",
      "retrieve",
      "responses",
      "manually"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Set up a survey",
    "content": "The Survey Management page displays all of your active and inactive surveys. You manage your surveys from this page. You must add questions to a survey before you can run it. For more information, see How to add questions to a survey. Note To create and edit surveys, you must have the Survey Editor role. For more information about this role, see Default roles. Create a survey From the main menu, select Build > Survey. Service Management displays the Survey Management page. Click New. Enter the following information: Field Description Title The title of the survey, displayed in the Service Portal. User instructions Instructions for a person responding to the survey. Internal name A unique name for the survey. This is the name used when creating the relevant business rule. Description Internal information for the survey manager. Click Save. To view changes or updates made to the record, click the History tab. For more information, see History. To open, join, or view a discussion or to vi",
    "url": "createsurvey",
    "filename": "createsurvey",
    "headings": [
      "Create a survey",
      "Duplicate a survey",
      "Add questions to the survey",
      "Select fields for reports",
      "Prepare the survey for conduction",
      "Related topics"
    ],
    "keywords": [
      "set",
      "survey",
      "create",
      "duplicate",
      "add",
      "questions",
      "select",
      "fields",
      "reports",
      "prepare",
      "conduction",
      "related",
      "topics",
      "management",
      "page",
      "displays",
      "all",
      "active",
      "inactive",
      "surveys.",
      "manage",
      "surveys",
      "page.",
      "before",
      "run",
      "it.",
      "information",
      "see",
      "survey.",
      "note",
      "edit",
      "editor",
      "role.",
      "about",
      "role",
      "default",
      "roles.",
      "main",
      "menu",
      "build",
      "service",
      "click",
      "new.",
      "enter",
      "following",
      "field",
      "description",
      "title",
      "displayed",
      "portal.",
      "user",
      "instructions",
      "person",
      "responding",
      "internal",
      "name",
      "unique",
      "creating",
      "relevant",
      "business",
      "rule.",
      "manager.",
      "save.",
      "view",
      "changes",
      "updates",
      "made",
      "record",
      "history",
      "tab.",
      "history.",
      "open",
      "join",
      "discussion",
      "post",
      "comments",
      "discussions",
      "discussions.",
      "most",
      "interesting",
      "areas",
      "analysis",
      "hot",
      "topic",
      "analytics",
      "save",
      "changes.",
      "any",
      "existing",
      "modify",
      "required",
      "independent",
      "original",
      "want",
      "duplicate.",
      "name.",
      "ok.",
      "identifier",
      "id",
      "column"
    ],
    "language": "en",
    "word_count": 102,
    "importance_score": 6.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "set up a survey",
    "contentLower": "the survey management page displays all of your active and inactive surveys. you manage your surveys from this page. you must add questions to a survey before you can run it. for more information, see how to add questions to a survey. note to create and edit surveys, you must have the survey editor role. for more information about this role, see default roles. create a survey from the main menu, select build > survey. service management displays the survey management page. click new. enter the following information: field description title the title of the survey, displayed in the service portal. user instructions instructions for a person responding to the survey. internal name a unique name for the survey. this is the name used when creating the relevant business rule. description internal information for the survey manager. click save. to view changes or updates made to the record, click the history tab. for more information, see history. to open, join, or view a discussion or to vi",
    "keywordsLower": [
      "set",
      "survey",
      "create",
      "duplicate",
      "add",
      "questions",
      "select",
      "fields",
      "reports",
      "prepare",
      "conduction",
      "related",
      "topics",
      "management",
      "page",
      "displays",
      "all",
      "active",
      "inactive",
      "surveys.",
      "manage",
      "surveys",
      "page.",
      "before",
      "run",
      "it.",
      "information",
      "see",
      "survey.",
      "note",
      "edit",
      "editor",
      "role.",
      "about",
      "role",
      "default",
      "roles.",
      "main",
      "menu",
      "build",
      "service",
      "click",
      "new.",
      "enter",
      "following",
      "field",
      "description",
      "title",
      "displayed",
      "portal.",
      "user",
      "instructions",
      "person",
      "responding",
      "internal",
      "name",
      "unique",
      "creating",
      "relevant",
      "business",
      "rule.",
      "manager.",
      "save.",
      "view",
      "changes",
      "updates",
      "made",
      "record",
      "history",
      "tab.",
      "history.",
      "open",
      "join",
      "discussion",
      "post",
      "comments",
      "discussions",
      "discussions.",
      "most",
      "interesting",
      "areas",
      "analysis",
      "hot",
      "topic",
      "analytics",
      "save",
      "changes.",
      "any",
      "existing",
      "modify",
      "required",
      "independent",
      "original",
      "want",
      "duplicate.",
      "name.",
      "ok.",
      "identifier",
      "id",
      "column"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Survey notification templates",
    "content": "Service Management sends surveys to users based on a notification template. When you send a survey manually by using the Send survey now button from a survey record or when you create a business rule for the system to automatically send a survey, you need to specify a survey notification template. Define survey notification templates Service Management has pre-defined survey notification templates. To access these templates: Log in to the agent interface as the tenant admin. Navigate to Administration > Studio, and open the Survey record type. Click the Notifications tab. Out of the box, this tab displays a list of pre-defined survey templates. If you like, you can customize these templates or create your own templates. For details, see Work with notification templates. Specify a survey notification template When you sending a manual survey or create a \"Survey notification\" business rule, you need to specify a survey notification template. You can select Survey default template or a cu",
    "url": "surveynotificationtemplates",
    "filename": "surveynotificationtemplates",
    "headings": [
      "Define survey notification templates",
      "Specify a survey notification template",
      "Survey default template",
      "Custom template"
    ],
    "keywords": [
      "survey",
      "notification",
      "templates",
      "define",
      "specify",
      "template",
      "default",
      "custom",
      "service",
      "management",
      "sends",
      "surveys",
      "users",
      "based",
      "template.",
      "send",
      "manually",
      "now",
      "button",
      "record",
      "create",
      "business",
      "rule",
      "system",
      "automatically",
      "need",
      "pre-defined",
      "templates.",
      "access",
      "log",
      "agent",
      "interface",
      "tenant",
      "admin.",
      "navigate",
      "administration",
      "studio",
      "open",
      "type.",
      "click",
      "notifications",
      "tab.",
      "out",
      "box",
      "tab",
      "displays",
      "list",
      "like",
      "customize",
      "own",
      "details",
      "see",
      "work",
      "sending",
      "manual",
      "select",
      "available.",
      "creating",
      "uses",
      "one",
      "out-of-the-box",
      "according",
      "content",
      "specified",
      "survey.",
      "two",
      "attributes",
      "determine",
      "whether",
      "question",
      "primary",
      "rating",
      "answer",
      "type",
      "defined",
      "report",
      "fields",
      "section",
      "following",
      "table",
      "explains",
      "applicable",
      "meet",
      "all",
      "conditions",
      "example",
      "ve",
      "request",
      "created",
      "meets",
      "condition",
      "rule."
    ],
    "language": "en",
    "word_count": 100,
    "importance_score": 5.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "survey notification templates",
    "contentLower": "service management sends surveys to users based on a notification template. when you send a survey manually by using the send survey now button from a survey record or when you create a business rule for the system to automatically send a survey, you need to specify a survey notification template. define survey notification templates service management has pre-defined survey notification templates. to access these templates: log in to the agent interface as the tenant admin. navigate to administration > studio, and open the survey record type. click the notifications tab. out of the box, this tab displays a list of pre-defined survey templates. if you like, you can customize these templates or create your own templates. for details, see work with notification templates. specify a survey notification template when you sending a manual survey or create a \"survey notification\" business rule, you need to specify a survey notification template. you can select survey default template or a cu",
    "keywordsLower": [
      "survey",
      "notification",
      "templates",
      "define",
      "specify",
      "template",
      "default",
      "custom",
      "service",
      "management",
      "sends",
      "surveys",
      "users",
      "based",
      "template.",
      "send",
      "manually",
      "now",
      "button",
      "record",
      "create",
      "business",
      "rule",
      "system",
      "automatically",
      "need",
      "pre-defined",
      "templates.",
      "access",
      "log",
      "agent",
      "interface",
      "tenant",
      "admin.",
      "navigate",
      "administration",
      "studio",
      "open",
      "type.",
      "click",
      "notifications",
      "tab.",
      "out",
      "box",
      "tab",
      "displays",
      "list",
      "like",
      "customize",
      "own",
      "details",
      "see",
      "work",
      "sending",
      "manual",
      "select",
      "available.",
      "creating",
      "uses",
      "one",
      "out-of-the-box",
      "according",
      "content",
      "specified",
      "survey.",
      "two",
      "attributes",
      "determine",
      "whether",
      "question",
      "primary",
      "rating",
      "answer",
      "type",
      "defined",
      "report",
      "fields",
      "section",
      "following",
      "table",
      "explains",
      "applicable",
      "meet",
      "all",
      "conditions",
      "example",
      "ve",
      "request",
      "created",
      "meets",
      "condition",
      "rule."
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Retrieve survey responses manually",
    "content": "By default, the system retrieves survey responses for the previous day and reflects the results in survey reports and Hot Topic Analytics for surveys. It takes up to two days for the system to show survey response data in report charts. One day to add user response data to the report calculation data list, and another day to generate analytical reports. To reduce this duration, a Retrieve survey responses button is available so that you can immediately retrieve and add user response data to the report calculation data list. Note After you manually retrieve user response data, you still need to wait another day to see newly retrieved user responses in report charts. To manually retrieve survey responses, follow these steps: From the main menu, select Build > Survey. Service Management displays the available surveys. Click the record identifier in the ID column to display the selected record. On the main toolbar, click Retrieve survey responses. Select the start date and the end date, an",
    "url": "retrievesurveyresponses",
    "filename": "retrievesurveyresponses",
    "headings": [
      "Related topics"
    ],
    "keywords": [
      "retrieve",
      "survey",
      "responses",
      "manually",
      "related",
      "topics",
      "default",
      "system",
      "retrieves",
      "previous",
      "day",
      "reflects",
      "results",
      "reports",
      "hot",
      "topic",
      "analytics",
      "surveys.",
      "takes",
      "two",
      "days",
      "show",
      "response",
      "data",
      "report",
      "charts.",
      "one",
      "add",
      "user",
      "calculation",
      "list",
      "another",
      "generate",
      "analytical",
      "reports.",
      "reduce",
      "duration",
      "button",
      "available",
      "immediately",
      "list.",
      "note",
      "after",
      "still",
      "need",
      "wait",
      "see",
      "newly",
      "retrieved",
      "follow",
      "steps",
      "main",
      "menu",
      "select",
      "build",
      "survey.",
      "service",
      "management",
      "displays",
      "click",
      "record",
      "identifier",
      "id",
      "column",
      "display",
      "selected",
      "record.",
      "toolbar",
      "responses.",
      "start",
      "date",
      "end",
      "retrieve.",
      "queue",
      "calculation.",
      "scheduler",
      "runs",
      "daily",
      "basis",
      "regenerate",
      "based",
      "queue.",
      "means",
      "most",
      "refresh",
      "map",
      "reflect",
      "updated",
      "conduct"
    ],
    "language": "en",
    "word_count": 115,
    "importance_score": 3.5,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "retrieve survey responses manually",
    "contentLower": "by default, the system retrieves survey responses for the previous day and reflects the results in survey reports and hot topic analytics for surveys. it takes up to two days for the system to show survey response data in report charts. one day to add user response data to the report calculation data list, and another day to generate analytical reports. to reduce this duration, a retrieve survey responses button is available so that you can immediately retrieve and add user response data to the report calculation data list. note after you manually retrieve user response data, you still need to wait another day to see newly retrieved user responses in report charts. to manually retrieve survey responses, follow these steps: from the main menu, select build > survey. service management displays the available surveys. click the record identifier in the id column to display the selected record. on the main toolbar, click retrieve survey responses. select the start date and the end date, an",
    "keywordsLower": [
      "retrieve",
      "survey",
      "responses",
      "manually",
      "related",
      "topics",
      "default",
      "system",
      "retrieves",
      "previous",
      "day",
      "reflects",
      "results",
      "reports",
      "hot",
      "topic",
      "analytics",
      "surveys.",
      "takes",
      "two",
      "days",
      "show",
      "response",
      "data",
      "report",
      "charts.",
      "one",
      "add",
      "user",
      "calculation",
      "list",
      "another",
      "generate",
      "analytical",
      "reports.",
      "reduce",
      "duration",
      "button",
      "available",
      "immediately",
      "list.",
      "note",
      "after",
      "still",
      "need",
      "wait",
      "see",
      "newly",
      "retrieved",
      "follow",
      "steps",
      "main",
      "menu",
      "select",
      "build",
      "survey.",
      "service",
      "management",
      "displays",
      "click",
      "record",
      "identifier",
      "id",
      "column",
      "display",
      "selected",
      "record.",
      "toolbar",
      "responses.",
      "start",
      "date",
      "end",
      "retrieve.",
      "queue",
      "calculation.",
      "scheduler",
      "runs",
      "daily",
      "basis",
      "regenerate",
      "based",
      "queue.",
      "means",
      "most",
      "refresh",
      "map",
      "reflect",
      "updated",
      "conduct"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Receiving assets",
    "content": "This section includes the following: Create and manage receiving slips Create and manage receiving lines",
    "url": "receivinghead",
    "filename": "receivinghead",
    "headings": [],
    "keywords": [
      "receiving",
      "assets",
      "section",
      "includes",
      "following",
      "create",
      "manage",
      "slips",
      "lines"
    ],
    "language": "en",
    "word_count": 13,
    "importance_score": 2.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "receiving assets",
    "contentLower": "this section includes the following: create and manage receiving slips create and manage receiving lines",
    "keywordsLower": [
      "receiving",
      "assets",
      "section",
      "includes",
      "following",
      "create",
      "manage",
      "slips",
      "lines"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Run",
    "content": "This part of the Help Center includes the following: Service Request ManagementIncident ManagementProblem ManagementSoftware Asset ManagementFinancial Management",
    "url": "run",
    "filename": "run",
    "headings": [],
    "keywords": [
      "run",
      "part",
      "help",
      "center",
      "includes",
      "following",
      "service",
      "request",
      "managementincident",
      "managementproblem",
      "managementsoftware",
      "asset",
      "managementfinancial",
      "management"
    ],
    "language": "en",
    "word_count": 14,
    "importance_score": 2.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "run",
    "contentLower": "this part of the help center includes the following: service request managementincident managementproblem managementsoftware asset managementfinancial management",
    "keywordsLower": [
      "run",
      "part",
      "help",
      "center",
      "includes",
      "following",
      "service",
      "request",
      "managementincident",
      "managementproblem",
      "managementsoftware",
      "asset",
      "managementfinancial",
      "management"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Service Request Management",
    "content": "Service Request Management enables you to create, escalate, fulfill, and monitor service requests. Service requests can be one of the following types: Service Request Support Request HR Support Request Case Request Cart Request (a cart request comes from the Service Portal when a user submits a shopping cart) If you work with data domains and you want to manually change existing domain assignments, you must first add the Data domains field to the relevant forms. For more information on adding fields to forms, see How to edit a form. For more information on data domains, see Data domain segmentation. Related topics Category Link Get started Solution planning using Service Management Request Management Request Flows Request vs. Incident Working with forms Dev2Prod Integrate Configure email integration Case Exchange integration operations for requests Configure Live Support with CTI Administer How to edit a form Action rule examples Use case scenarios - customizing with business rules Dat",
    "url": "servicerequestmgmt",
    "filename": "servicerequestmgmt",
    "headings": [
      "Related topics"
    ],
    "keywords": [
      "service",
      "request",
      "management",
      "related",
      "topics",
      "enables",
      "create",
      "escalate",
      "fulfill",
      "monitor",
      "requests.",
      "requests",
      "one",
      "following",
      "types",
      "support",
      "hr",
      "case",
      "cart",
      "comes",
      "portal",
      "user",
      "submits",
      "shopping",
      "work",
      "data",
      "domains",
      "want",
      "manually",
      "change",
      "existing",
      "domain",
      "assignments",
      "first",
      "add",
      "field",
      "relevant",
      "forms.",
      "information",
      "adding",
      "fields",
      "forms",
      "see",
      "edit",
      "form.",
      "segmentation.",
      "category",
      "link",
      "get",
      "started",
      "solution",
      "planning",
      "flows",
      "vs.",
      "incident",
      "working",
      "dev2prod",
      "integrate",
      "configure",
      "email",
      "integration",
      "exchange",
      "operations",
      "live",
      "cti",
      "administer",
      "form",
      "action",
      "rule",
      "examples",
      "scenarios",
      "customizing",
      "business",
      "rules",
      "segmentation",
      "chat",
      "location-based",
      "roles",
      "permissions",
      "procedures",
      "workflow",
      "troubleshoot",
      "develop",
      "rest",
      "api",
      "single",
      "record",
      "apis",
      "bulk",
      "update",
      "collection",
      "comments"
    ],
    "language": "en",
    "word_count": 113,
    "importance_score": 3.5,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "service request management",
    "contentLower": "service request management enables you to create, escalate, fulfill, and monitor service requests. service requests can be one of the following types: service request support request hr support request case request cart request (a cart request comes from the service portal when a user submits a shopping cart) if you work with data domains and you want to manually change existing domain assignments, you must first add the data domains field to the relevant forms. for more information on adding fields to forms, see how to edit a form. for more information on data domains, see data domain segmentation. related topics category link get started solution planning using service management request management request flows request vs. incident working with forms dev2prod integrate configure email integration case exchange integration operations for requests configure live support with cti administer how to edit a form action rule examples use case scenarios - customizing with business rules dat",
    "keywordsLower": [
      "service",
      "request",
      "management",
      "related",
      "topics",
      "enables",
      "create",
      "escalate",
      "fulfill",
      "monitor",
      "requests.",
      "requests",
      "one",
      "following",
      "types",
      "support",
      "hr",
      "case",
      "cart",
      "comes",
      "portal",
      "user",
      "submits",
      "shopping",
      "work",
      "data",
      "domains",
      "want",
      "manually",
      "change",
      "existing",
      "domain",
      "assignments",
      "first",
      "add",
      "field",
      "relevant",
      "forms.",
      "information",
      "adding",
      "fields",
      "forms",
      "see",
      "edit",
      "form.",
      "segmentation.",
      "category",
      "link",
      "get",
      "started",
      "solution",
      "planning",
      "flows",
      "vs.",
      "incident",
      "working",
      "dev2prod",
      "integrate",
      "configure",
      "email",
      "integration",
      "exchange",
      "operations",
      "live",
      "cti",
      "administer",
      "form",
      "action",
      "rule",
      "examples",
      "scenarios",
      "customizing",
      "business",
      "rules",
      "segmentation",
      "chat",
      "location-based",
      "roles",
      "permissions",
      "procedures",
      "workflow",
      "troubleshoot",
      "develop",
      "rest",
      "api",
      "single",
      "record",
      "apis",
      "bulk",
      "update",
      "collection",
      "comments"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Service Request Management roles and permissions",
    "content": "There are specific roles associated with Service Request Management. Service Management uses role-based permissions to enable you to complete a task that's appropriate to your role. The tenant administrator manages and assigns these permissions. By default, the following roles are assigned to Service Request Management. These roles support request tracking and process ownership. Role Responsibilities Service Request Agent Provide first-level support through taking calls. Handle service requests using the request fulfillment processes. Classify, fulfill, and close the service requests. Service Request Coordinator Act as an escalation point agent when difficult or controversial calls are received. Assist analysts in providing first-line support when workloads are high, or where additional experience is required. Review and acknowledge service requests to help desk group. Service Request Manager Manage the overall help desk activities. Take overall responsibility for service request handl",
    "url": "srmroles",
    "filename": "srmroles",
    "headings": [
      "Related topics"
    ],
    "keywords": [
      "service",
      "request",
      "management",
      "roles",
      "permissions",
      "related",
      "topics",
      "there",
      "specific",
      "associated",
      "management.",
      "uses",
      "role-based",
      "enable",
      "complete",
      "task",
      "appropriate",
      "role.",
      "tenant",
      "administrator",
      "manages",
      "assigns",
      "permissions.",
      "default",
      "following",
      "assigned",
      "support",
      "tracking",
      "process",
      "ownership.",
      "role",
      "responsibilities",
      "agent",
      "provide",
      "first-level",
      "through",
      "taking",
      "calls.",
      "handle",
      "requests",
      "fulfillment",
      "processes.",
      "classify",
      "fulfill",
      "close",
      "requests.",
      "coordinator",
      "act",
      "escalation",
      "point",
      "difficult",
      "controversial",
      "calls",
      "received.",
      "assist",
      "analysts",
      "providing",
      "first-line",
      "workloads",
      "high",
      "additional",
      "experience",
      "required.",
      "review",
      "acknowledge",
      "help",
      "desk",
      "group.",
      "manager",
      "manage",
      "overall",
      "activities.",
      "take",
      "responsibility",
      "handling",
      "desk.",
      "further",
      "coordinators.",
      "report",
      "senior",
      "managers",
      "any",
      "issue",
      "significantly",
      "impact",
      "business.",
      "ensure",
      "staffing",
      "skill",
      "levels",
      "maintained",
      "throughout",
      "operational",
      "hours",
      "managing",
      "shift",
      "schedules",
      "on.",
      "owner",
      "responsible"
    ],
    "language": "en",
    "word_count": 105,
    "importance_score": 2.5,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "service request management roles and permissions",
    "contentLower": "there are specific roles associated with service request management. service management uses role-based permissions to enable you to complete a task that's appropriate to your role. the tenant administrator manages and assigns these permissions. by default, the following roles are assigned to service request management. these roles support request tracking and process ownership. role responsibilities service request agent provide first-level support through taking calls. handle service requests using the request fulfillment processes. classify, fulfill, and close the service requests. service request coordinator act as an escalation point agent when difficult or controversial calls are received. assist analysts in providing first-line support when workloads are high, or where additional experience is required. review and acknowledge service requests to help desk group. service request manager manage the overall help desk activities. take overall responsibility for service request handl",
    "keywordsLower": [
      "service",
      "request",
      "management",
      "roles",
      "permissions",
      "related",
      "topics",
      "there",
      "specific",
      "associated",
      "management.",
      "uses",
      "role-based",
      "enable",
      "complete",
      "task",
      "appropriate",
      "role.",
      "tenant",
      "administrator",
      "manages",
      "assigns",
      "permissions.",
      "default",
      "following",
      "assigned",
      "support",
      "tracking",
      "process",
      "ownership.",
      "role",
      "responsibilities",
      "agent",
      "provide",
      "first-level",
      "through",
      "taking",
      "calls.",
      "handle",
      "requests",
      "fulfillment",
      "processes.",
      "classify",
      "fulfill",
      "close",
      "requests.",
      "coordinator",
      "act",
      "escalation",
      "point",
      "difficult",
      "controversial",
      "calls",
      "received.",
      "assist",
      "analysts",
      "providing",
      "first-line",
      "workloads",
      "high",
      "additional",
      "experience",
      "required.",
      "review",
      "acknowledge",
      "help",
      "desk",
      "group.",
      "manager",
      "manage",
      "overall",
      "activities.",
      "take",
      "responsibility",
      "handling",
      "desk.",
      "further",
      "coordinators.",
      "report",
      "senior",
      "managers",
      "any",
      "issue",
      "significantly",
      "impact",
      "business.",
      "ensure",
      "staffing",
      "skill",
      "levels",
      "maintained",
      "throughout",
      "operational",
      "hours",
      "managing",
      "shift",
      "schedules",
      "on.",
      "owner",
      "responsible"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Service Request Management procedures",
    "content": "Service Request Management is the primary point of contact for users when: There is a service disruption request for support, or There is a need to request an offering item. It's also a communication point for users and a coordination point for multiple IT groups and processes. In this module, service request personnel create, classify, analyze, escalate, monitor, and fulfill service requests. Related topics How to create a request record How to edit a request record How to create a record from a request How to deal with a Live Support call How to use the chat capability",
    "url": "srmtasks",
    "filename": "srmtasks",
    "headings": [
      "Related topics"
    ],
    "keywords": [
      "service",
      "request",
      "management",
      "procedures",
      "related",
      "topics",
      "primary",
      "point",
      "contact",
      "users",
      "there",
      "disruption",
      "support",
      "need",
      "offering",
      "item.",
      "communication",
      "coordination",
      "multiple",
      "groups",
      "processes.",
      "module",
      "personnel",
      "create",
      "classify",
      "analyze",
      "escalate",
      "monitor",
      "fulfill",
      "requests.",
      "record",
      "edit",
      "deal",
      "live",
      "call",
      "chat",
      "capability"
    ],
    "language": "en",
    "word_count": 59,
    "importance_score": 2.5,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "service request management procedures",
    "contentLower": "service request management is the primary point of contact for users when: there is a service disruption request for support, or there is a need to request an offering item. it's also a communication point for users and a coordination point for multiple it groups and processes. in this module, service request personnel create, classify, analyze, escalate, monitor, and fulfill service requests. related topics how to create a request record how to edit a request record how to create a record from a request how to deal with a live support call how to use the chat capability",
    "keywordsLower": [
      "service",
      "request",
      "management",
      "procedures",
      "related",
      "topics",
      "primary",
      "point",
      "contact",
      "users",
      "there",
      "disruption",
      "support",
      "need",
      "offering",
      "item.",
      "communication",
      "coordination",
      "multiple",
      "groups",
      "processes.",
      "module",
      "personnel",
      "create",
      "classify",
      "analyze",
      "escalate",
      "monitor",
      "fulfill",
      "requests.",
      "record",
      "edit",
      "deal",
      "live",
      "call",
      "chat",
      "capability"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Request on behalf",
    "content": "With the appropriate configuration, Service Management allows users in the Service Portal to create a request on behalf of another person. The feature is designed for two types of people: managers, and assistants. There are the following types of request on behalf situations: On behalf of an individual On behalf of a member of a group: any one of the members of a specified group By a manager, on behalf of someone who reports to the manager This feature isn't available if you use a tablet, tablet PC, or a mobile phone to access Service Management. How to set up request on behalf On behalf of an individual For user A to be able to create a request for user B: From the main menu, select Administration > Master Data > People > People. Select user A. Click the Request on behalf tab. In the Users section, click Add. Add user B. Click Save. For more information, see Users and contacts and Request on behalf tab. On behalf of a group member For user A to be able to create a request for members ",
    "url": "requestonbehalf",
    "filename": "requestonbehalf",
    "headings": [
      "How to set up request on behalf",
      "On behalf of an individual",
      "On behalf of a group member",
      "By a manager, on behalf of someone who reports to the manager",
      "Universal request on behalf",
      "Related topics"
    ],
    "keywords": [
      "request",
      "behalf",
      "set",
      "individual",
      "group",
      "member",
      "manager",
      "someone",
      "reports",
      "universal",
      "related",
      "topics",
      "appropriate",
      "configuration",
      "service",
      "management",
      "allows",
      "users",
      "portal",
      "create",
      "another",
      "person.",
      "feature",
      "designed",
      "two",
      "types",
      "people",
      "managers",
      "assistants.",
      "there",
      "following",
      "situations",
      "any",
      "one",
      "members",
      "specified",
      "isn",
      "available",
      "tablet",
      "pc",
      "mobile",
      "phone",
      "access",
      "management.",
      "user",
      "able",
      "main",
      "menu",
      "select",
      "administration",
      "master",
      "data",
      "people.",
      "a.",
      "click",
      "tab.",
      "section",
      "add.",
      "add",
      "b.",
      "save.",
      "information",
      "see",
      "contacts",
      "g.",
      "functionality",
      "automatically",
      "enabled",
      "record",
      "employee",
      "specify",
      "manager.",
      "example",
      "setting",
      "u.",
      "general",
      "tab",
      "organizational",
      "drop-down.",
      "list",
      "managers.",
      "configure",
      "allow",
      "user.",
      "segmentation",
      "after",
      "enable",
      "end",
      "all",
      "system.",
      "studio.",
      "drop-down",
      "top",
      "page",
      "request.",
      "processes",
      "rules",
      "close",
      "workflow",
      "map."
    ],
    "language": "en",
    "word_count": 105,
    "importance_score": 6.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "request on behalf",
    "contentLower": "with the appropriate configuration, service management allows users in the service portal to create a request on behalf of another person. the feature is designed for two types of people: managers, and assistants. there are the following types of request on behalf situations: on behalf of an individual on behalf of a member of a group: any one of the members of a specified group by a manager, on behalf of someone who reports to the manager this feature isn't available if you use a tablet, tablet pc, or a mobile phone to access service management. how to set up request on behalf on behalf of an individual for user a to be able to create a request for user b: from the main menu, select administration > master data > people > people. select user a. click the request on behalf tab. in the users section, click add. add user b. click save. for more information, see users and contacts and request on behalf tab. on behalf of a group member for user a to be able to create a request for members ",
    "keywordsLower": [
      "request",
      "behalf",
      "set",
      "individual",
      "group",
      "member",
      "manager",
      "someone",
      "reports",
      "universal",
      "related",
      "topics",
      "appropriate",
      "configuration",
      "service",
      "management",
      "allows",
      "users",
      "portal",
      "create",
      "another",
      "person.",
      "feature",
      "designed",
      "two",
      "types",
      "people",
      "managers",
      "assistants.",
      "there",
      "following",
      "situations",
      "any",
      "one",
      "members",
      "specified",
      "isn",
      "available",
      "tablet",
      "pc",
      "mobile",
      "phone",
      "access",
      "management.",
      "user",
      "able",
      "main",
      "menu",
      "select",
      "administration",
      "master",
      "data",
      "people.",
      "a.",
      "click",
      "tab.",
      "section",
      "add.",
      "add",
      "b.",
      "save.",
      "information",
      "see",
      "contacts",
      "g.",
      "functionality",
      "automatically",
      "enabled",
      "record",
      "employee",
      "specify",
      "manager.",
      "example",
      "setting",
      "u.",
      "general",
      "tab",
      "organizational",
      "drop-down.",
      "list",
      "managers.",
      "configure",
      "allow",
      "user.",
      "segmentation",
      "after",
      "enable",
      "end",
      "all",
      "system.",
      "studio.",
      "drop-down",
      "top",
      "page",
      "request.",
      "processes",
      "rules",
      "close",
      "workflow",
      "map."
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Service Portal users and request on behalf",
    "content": "Service Portal users can create a request on behalf of another person. Note This feature isn't available if you use a mobile phone to access Service Management. How to use request on behalf in the Service Portal To make a request on behalf of another person: In the Service Portal, click the portal menu button at the top right of the page. Click Request on behalf. Select from the drop-down. Note When you search for a person in the RoB list, you can use any of these keywords: First Name, Last Name, Employee ID, Email Address (only the part before the @ sign can be searched out). How does request on behalf affect users in the Service Portal? When a user in the Service Portal makes a request on behalf of another person, this has the following effects: Questions and answers don't display Ideas don't display News displays according to the identity of the other person Requests that display are those of the user Search uses the identity of the other person Categories display according to the e",
    "url": "spusersrequestonbehalf",
    "filename": "spusersrequestonbehalf",
    "headings": [
      "How to use request on behalf in the Service Portal",
      "How does request on behalf affect users in the Service Portal?",
      "Related topics"
    ],
    "keywords": [
      "service",
      "portal",
      "users",
      "request",
      "behalf",
      "affect",
      "related",
      "topics",
      "create",
      "another",
      "person.",
      "note",
      "feature",
      "isn",
      "available",
      "mobile",
      "phone",
      "access",
      "management.",
      "make",
      "person",
      "click",
      "menu",
      "button",
      "top",
      "right",
      "page.",
      "behalf.",
      "select",
      "drop-down.",
      "search",
      "rob",
      "list",
      "any",
      "keywords",
      "first",
      "name",
      "last",
      "employee",
      "id",
      "email",
      "address",
      "part",
      "before",
      "sign",
      "searched",
      "out",
      "user",
      "makes",
      "following",
      "effects",
      "questions",
      "answers",
      "don",
      "display",
      "ideas",
      "news",
      "displays",
      "according",
      "identity",
      "requests",
      "uses",
      "categories",
      "entitlement",
      "rules",
      "applicable",
      "offering",
      "availability",
      "prices",
      "carts",
      "submitted",
      "information",
      "see",
      "selections",
      "portal.",
      "shopping",
      "cart"
    ],
    "language": "en",
    "word_count": 107,
    "importance_score": 3.5,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "service portal users and request on behalf",
    "contentLower": "service portal users can create a request on behalf of another person. note this feature isn't available if you use a mobile phone to access service management. how to use request on behalf in the service portal to make a request on behalf of another person: in the service portal, click the portal menu button at the top right of the page. click request on behalf. select from the drop-down. note when you search for a person in the rob list, you can use any of these keywords: first name, last name, employee id, email address (only the part before the @ sign can be searched out). how does request on behalf affect users in the service portal? when a user in the service portal makes a request on behalf of another person, this has the following effects: questions and answers don't display ideas don't display news displays according to the identity of the other person requests that display are those of the user search uses the identity of the other person categories display according to the e",
    "keywordsLower": [
      "service",
      "portal",
      "users",
      "request",
      "behalf",
      "affect",
      "related",
      "topics",
      "create",
      "another",
      "person.",
      "note",
      "feature",
      "isn",
      "available",
      "mobile",
      "phone",
      "access",
      "management.",
      "make",
      "person",
      "click",
      "menu",
      "button",
      "top",
      "right",
      "page.",
      "behalf.",
      "select",
      "drop-down.",
      "search",
      "rob",
      "list",
      "any",
      "keywords",
      "first",
      "name",
      "last",
      "employee",
      "id",
      "email",
      "address",
      "part",
      "before",
      "sign",
      "searched",
      "out",
      "user",
      "makes",
      "following",
      "effects",
      "questions",
      "answers",
      "don",
      "display",
      "ideas",
      "news",
      "displays",
      "according",
      "identity",
      "requests",
      "uses",
      "categories",
      "entitlement",
      "rules",
      "applicable",
      "offering",
      "availability",
      "prices",
      "carts",
      "submitted",
      "information",
      "see",
      "selections",
      "portal.",
      "shopping",
      "cart"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Service Portal shopping cart",
    "content": "Service Management provides a shopping cart system for users in the Service Portal to collect and submit requests for multiple goods and services. As each item is added to or removed from the cart, the total number of items is updated and displayed beside the cart image. The user can click the cart image to edit, duplicate, or remove items, and to submit them. Adding to cart is not supported for case requests. Cart and child requests The shopping cart uses cart and child requests as follows: Cart requests Created each time the user submits a cart. Contain the individual requests in each cart as child requests. Use a workflow that must be completed before the child requests advance from the log phase. For more information, see Shopping cart workflow. Child requests Are displayed in the Related records tab of the parent cart request. Are not treated as active until their parent cart request completes its workflow. View cart requests in Service Request Management You can filter the list v",
    "url": "shoppingcart",
    "filename": "shoppingcart",
    "headings": [
      "Cart and child requests",
      "View cart requests in Service Request Management",
      "Related topics"
    ],
    "keywords": [
      "service",
      "portal",
      "shopping",
      "cart",
      "child",
      "requests",
      "view",
      "request",
      "management",
      "related",
      "topics",
      "provides",
      "system",
      "users",
      "collect",
      "submit",
      "multiple",
      "goods",
      "services.",
      "item",
      "added",
      "removed",
      "total",
      "number",
      "items",
      "updated",
      "displayed",
      "beside",
      "image.",
      "user",
      "click",
      "image",
      "edit",
      "duplicate",
      "remove",
      "them.",
      "adding",
      "supported",
      "case",
      "requests.",
      "uses",
      "follows",
      "created",
      "time",
      "submits",
      "cart.",
      "contain",
      "individual",
      "workflow",
      "completed",
      "before",
      "advance",
      "log",
      "phase.",
      "information",
      "see",
      "workflow.",
      "records",
      "tab",
      "parent",
      "request.",
      "treated",
      "active",
      "until",
      "completes",
      "filter",
      "list",
      "display",
      "main",
      "menu",
      "select",
      "run",
      "displays",
      "add",
      "button.",
      "field",
      "type.",
      "ok.",
      "behalf"
    ],
    "language": "en",
    "word_count": 108,
    "importance_score": 4.5,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "service portal shopping cart",
    "contentLower": "service management provides a shopping cart system for users in the service portal to collect and submit requests for multiple goods and services. as each item is added to or removed from the cart, the total number of items is updated and displayed beside the cart image. the user can click the cart image to edit, duplicate, or remove items, and to submit them. adding to cart is not supported for case requests. cart and child requests the shopping cart uses cart and child requests as follows: cart requests created each time the user submits a cart. contain the individual requests in each cart as child requests. use a workflow that must be completed before the child requests advance from the log phase. for more information, see shopping cart workflow. child requests are displayed in the related records tab of the parent cart request. are not treated as active until their parent cart request completes its workflow. view cart requests in service request management you can filter the list v",
    "keywordsLower": [
      "service",
      "portal",
      "shopping",
      "cart",
      "child",
      "requests",
      "view",
      "request",
      "management",
      "related",
      "topics",
      "provides",
      "system",
      "users",
      "collect",
      "submit",
      "multiple",
      "goods",
      "services.",
      "item",
      "added",
      "removed",
      "total",
      "number",
      "items",
      "updated",
      "displayed",
      "beside",
      "image.",
      "user",
      "click",
      "image",
      "edit",
      "duplicate",
      "remove",
      "them.",
      "adding",
      "supported",
      "case",
      "requests.",
      "uses",
      "follows",
      "created",
      "time",
      "submits",
      "cart.",
      "contain",
      "individual",
      "workflow",
      "completed",
      "before",
      "advance",
      "log",
      "phase.",
      "information",
      "see",
      "workflow.",
      "records",
      "tab",
      "parent",
      "request.",
      "treated",
      "active",
      "until",
      "completes",
      "filter",
      "list",
      "display",
      "main",
      "menu",
      "select",
      "run",
      "displays",
      "add",
      "button.",
      "field",
      "type.",
      "ok.",
      "behalf"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Service Request Management workflow",
    "content": "A workflow is an end-to-end process from the service request creation to the service request closure. The building blocks of the workflow are metaphases, phases and transitions. Service Management displays a graphic view of the workflow where you can see the current phase and the transitions that connect the current phase to all other phases. The Service Request Management process workflow includes all necessary steps to create and implement service requests, including any necessary escalations or reassignments. If an incident is created from the request on the request entity page, the request is automatically transitioned from the First line support phase to the Escalate phase. Service Request Management workflows contain metaphases and phases that lead to closure. When you update a record, the record can transition from one phase to the next automatically, if certain conditions are met. In certain phases, you can also advance manually to the next phase in the workflow snapshot. Examp",
    "url": "srmwflw",
    "filename": "srmwflw",
    "headings": [
      "Related topics"
    ],
    "keywords": [
      "service",
      "request",
      "management",
      "workflow",
      "related",
      "topics",
      "end-to-end",
      "process",
      "creation",
      "closure.",
      "building",
      "blocks",
      "metaphases",
      "phases",
      "transitions.",
      "displays",
      "graphic",
      "view",
      "see",
      "current",
      "phase",
      "transitions",
      "connect",
      "all",
      "phases.",
      "includes",
      "necessary",
      "steps",
      "create",
      "implement",
      "requests",
      "including",
      "any",
      "escalations",
      "reassignments.",
      "incident",
      "created",
      "entity",
      "page",
      "automatically",
      "transitioned",
      "first",
      "line",
      "support",
      "escalate",
      "phase.",
      "workflows",
      "contain",
      "lead",
      "update",
      "record",
      "transition",
      "one",
      "next",
      "certain",
      "conditions",
      "met.",
      "advance",
      "manually",
      "snapshot.",
      "example",
      "depend",
      "value",
      "field",
      "record.",
      "fulfillment",
      "metaphase",
      "validation",
      "occurs",
      "solution",
      "completion",
      "code",
      "provided",
      "together",
      "request.",
      "reflects",
      "itilv3",
      "recommendations.",
      "kpis",
      "notification",
      "rules"
    ],
    "language": "en",
    "word_count": 96,
    "importance_score": 3.5,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "service request management workflow",
    "contentLower": "a workflow is an end-to-end process from the service request creation to the service request closure. the building blocks of the workflow are metaphases, phases and transitions. service management displays a graphic view of the workflow where you can see the current phase and the transitions that connect the current phase to all other phases. the service request management process workflow includes all necessary steps to create and implement service requests, including any necessary escalations or reassignments. if an incident is created from the request on the request entity page, the request is automatically transitioned from the first line support phase to the escalate phase. service request management workflows contain metaphases and phases that lead to closure. when you update a record, the record can transition from one phase to the next automatically, if certain conditions are met. in certain phases, you can also advance manually to the next phase in the workflow snapshot. examp",
    "keywordsLower": [
      "service",
      "request",
      "management",
      "workflow",
      "related",
      "topics",
      "end-to-end",
      "process",
      "creation",
      "closure.",
      "building",
      "blocks",
      "metaphases",
      "phases",
      "transitions.",
      "displays",
      "graphic",
      "view",
      "see",
      "current",
      "phase",
      "transitions",
      "connect",
      "all",
      "phases.",
      "includes",
      "necessary",
      "steps",
      "create",
      "implement",
      "requests",
      "including",
      "any",
      "escalations",
      "reassignments.",
      "incident",
      "created",
      "entity",
      "page",
      "automatically",
      "transitioned",
      "first",
      "line",
      "support",
      "escalate",
      "phase.",
      "workflows",
      "contain",
      "lead",
      "update",
      "record",
      "transition",
      "one",
      "next",
      "certain",
      "conditions",
      "met.",
      "advance",
      "manually",
      "snapshot.",
      "example",
      "depend",
      "value",
      "field",
      "record.",
      "fulfillment",
      "metaphase",
      "validation",
      "occurs",
      "solution",
      "completion",
      "code",
      "provided",
      "together",
      "request.",
      "reflects",
      "itilv3",
      "recommendations.",
      "kpis",
      "notification",
      "rules"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Service Request workflow",
    "content": "This section describes the metaphases and subordinate phases in the life cycle of a Service Request. The workflow relies on business rules. Rules repeat from one phase to another when the end user can make a change to a field affected by a business rule during that phase. Metaphase: Classification Example: a request is submitted for the \"Request a new SharePoint site\" offering item, which requires manager approval. The request is automatically moved to Approve phase. Phase Transition Description Log Automatic Log is the starting point for requests. The result of the phase is the successful creation of a request. The phase automatically transitions to Approve when a task plan is specified for the Approve phase of the request. The phase automatically transitions to Fulfill when no task plan is specified for the Approve phase but the request is assigned to a person. The phase automatically transitions to Close when its parent cart request is denied. Next phase: Approve, Fulfill, or Close ",
    "url": "servicewflw",
    "filename": "servicewflw",
    "headings": [
      "Metaphase: Classification",
      "Metaphase: Approval",
      "Metaphase: Fulfillment",
      "Metaphase: Validation",
      "Metaphase: Done (End)",
      "Related topics"
    ],
    "keywords": [
      "approval.The",
      "service",
      "request",
      "workflow",
      "metaphase",
      "classification",
      "approval",
      "fulfillment",
      "validation",
      "done",
      "end",
      "related",
      "topics",
      "section",
      "describes",
      "metaphases",
      "subordinate",
      "phases",
      "life",
      "cycle",
      "request.",
      "relies",
      "business",
      "rules.",
      "rules",
      "repeat",
      "one",
      "phase",
      "another",
      "user",
      "make",
      "change",
      "field",
      "affected",
      "rule",
      "during",
      "phase.",
      "example",
      "submitted",
      "new",
      "sharepoint",
      "site",
      "offering",
      "item",
      "requires",
      "manager",
      "approval.",
      "automatically",
      "moved",
      "approve",
      "transition",
      "description",
      "log",
      "automatic",
      "starting",
      "point",
      "requests.",
      "result",
      "successful",
      "creation",
      "transitions",
      "task",
      "plan",
      "specified",
      "fulfill",
      "assigned",
      "person.",
      "close",
      "parent",
      "cart",
      "denied.",
      "next",
      "manual",
      "agent",
      "manually",
      "abandon",
      "longer",
      "valid",
      "relevant.",
      "once",
      "approved",
      "dispatched",
      "owner",
      "handle.",
      "person",
      "approved.",
      "case",
      "completion",
      "code",
      "set",
      "created",
      "requestor",
      "either",
      "rest",
      "api.",
      "fills",
      "solution",
      "information.",
      "accept",
      "waits"
    ],
    "language": "en",
    "word_count": 99,
    "importance_score": 6.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "service request workflow",
    "contentLower": "this section describes the metaphases and subordinate phases in the life cycle of a service request. the workflow relies on business rules. rules repeat from one phase to another when the end user can make a change to a field affected by a business rule during that phase. metaphase: classification example: a request is submitted for the \"request a new sharepoint site\" offering item, which requires manager approval. the request is automatically moved to approve phase. phase transition description log automatic log is the starting point for requests. the result of the phase is the successful creation of a request. the phase automatically transitions to approve when a task plan is specified for the approve phase of the request. the phase automatically transitions to fulfill when no task plan is specified for the approve phase but the request is assigned to a person. the phase automatically transitions to close when its parent cart request is denied. next phase: approve, fulfill, or close ",
    "keywordsLower": [
      "approval.the",
      "service",
      "request",
      "workflow",
      "metaphase",
      "classification",
      "approval",
      "fulfillment",
      "validation",
      "done",
      "end",
      "related",
      "topics",
      "section",
      "describes",
      "metaphases",
      "subordinate",
      "phases",
      "life",
      "cycle",
      "request.",
      "relies",
      "business",
      "rules.",
      "rules",
      "repeat",
      "one",
      "phase",
      "another",
      "user",
      "make",
      "change",
      "field",
      "affected",
      "rule",
      "during",
      "phase.",
      "example",
      "submitted",
      "new",
      "sharepoint",
      "site",
      "offering",
      "item",
      "requires",
      "manager",
      "approval.",
      "automatically",
      "moved",
      "approve",
      "transition",
      "description",
      "log",
      "automatic",
      "starting",
      "point",
      "requests.",
      "result",
      "successful",
      "creation",
      "transitions",
      "task",
      "plan",
      "specified",
      "fulfill",
      "assigned",
      "person.",
      "close",
      "parent",
      "cart",
      "denied.",
      "next",
      "manual",
      "agent",
      "manually",
      "abandon",
      "longer",
      "valid",
      "relevant.",
      "once",
      "approved",
      "dispatched",
      "owner",
      "handle.",
      "person",
      "approved.",
      "case",
      "completion",
      "code",
      "set",
      "created",
      "requestor",
      "either",
      "rest",
      "api.",
      "fills",
      "solution",
      "information.",
      "accept",
      "waits"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Support Request workflow",
    "content": "This section describes the metaphases and subordinate phases in the life cycle of a Support Request. The request workflow relies on business rules. Rules repeat from one phase to another when the end user can make a change to a field affected by a business rule during that phase. Metaphase: Classification Example: a request is submitted to apply the latest security patch on a particular database server. The Service Request Coordinator classifies the request, assigns the request to an owner, and manually transitions the phase to First line support. Phase Transition Description Log Automatic Log is the starting point for requests. The result of the phase is the successful creation of a request. The phase automatically transitions to Classify when it has no parent cart request, or it's not dependent on the approval of its cart request. The phase automatically transitions to Close when its parent cart request is denied. Next phase: Classify or Close Classify Automatic or Manual The phase a",
    "url": "supportwflw",
    "filename": "supportwflw",
    "headings": [
      "Metaphase: Classification",
      "Metaphase: Fulfillment",
      "Metaphase: Validation",
      "Metaphase: Done (End)",
      "Related topics"
    ],
    "keywords": [
      "support",
      "request",
      "workflow",
      "metaphase",
      "classification",
      "fulfillment",
      "validation",
      "done",
      "end",
      "related",
      "topics",
      "section",
      "describes",
      "metaphases",
      "subordinate",
      "phases",
      "life",
      "cycle",
      "request.",
      "relies",
      "business",
      "rules.",
      "rules",
      "repeat",
      "one",
      "phase",
      "another",
      "user",
      "make",
      "change",
      "field",
      "affected",
      "rule",
      "during",
      "phase.",
      "example",
      "submitted",
      "apply",
      "latest",
      "security",
      "patch",
      "particular",
      "database",
      "server.",
      "service",
      "coordinator",
      "classifies",
      "assigns",
      "owner",
      "manually",
      "transitions",
      "first",
      "line",
      "support.",
      "transition",
      "description",
      "log",
      "automatic",
      "starting",
      "point",
      "requests.",
      "result",
      "successful",
      "creation",
      "automatically",
      "classify",
      "parent",
      "cart",
      "dependent",
      "approval",
      "close",
      "denied.",
      "next",
      "manual",
      "assigned",
      "person",
      "group.",
      "abandon",
      "requestor",
      "marks",
      "solved",
      "tracking",
      "page",
      "portal.",
      "case",
      "completion",
      "code",
      "set",
      "abandoned",
      "user.",
      "fulfilled",
      "social",
      "comments.",
      "agent",
      "longer",
      "valid",
      "relevant.",
      "after",
      "task",
      "assignees"
    ],
    "language": "en",
    "word_count": 100,
    "importance_score": 5.5,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "support request workflow",
    "contentLower": "this section describes the metaphases and subordinate phases in the life cycle of a support request. the request workflow relies on business rules. rules repeat from one phase to another when the end user can make a change to a field affected by a business rule during that phase. metaphase: classification example: a request is submitted to apply the latest security patch on a particular database server. the service request coordinator classifies the request, assigns the request to an owner, and manually transitions the phase to first line support. phase transition description log automatic log is the starting point for requests. the result of the phase is the successful creation of a request. the phase automatically transitions to classify when it has no parent cart request, or it's not dependent on the approval of its cart request. the phase automatically transitions to close when its parent cart request is denied. next phase: classify or close classify automatic or manual the phase a",
    "keywordsLower": [
      "support",
      "request",
      "workflow",
      "metaphase",
      "classification",
      "fulfillment",
      "validation",
      "done",
      "end",
      "related",
      "topics",
      "section",
      "describes",
      "metaphases",
      "subordinate",
      "phases",
      "life",
      "cycle",
      "request.",
      "relies",
      "business",
      "rules.",
      "rules",
      "repeat",
      "one",
      "phase",
      "another",
      "user",
      "make",
      "change",
      "field",
      "affected",
      "rule",
      "during",
      "phase.",
      "example",
      "submitted",
      "apply",
      "latest",
      "security",
      "patch",
      "particular",
      "database",
      "server.",
      "service",
      "coordinator",
      "classifies",
      "assigns",
      "owner",
      "manually",
      "transitions",
      "first",
      "line",
      "support.",
      "transition",
      "description",
      "log",
      "automatic",
      "starting",
      "point",
      "requests.",
      "result",
      "successful",
      "creation",
      "automatically",
      "classify",
      "parent",
      "cart",
      "dependent",
      "approval",
      "close",
      "denied.",
      "next",
      "manual",
      "assigned",
      "person",
      "group.",
      "abandon",
      "requestor",
      "marks",
      "solved",
      "tracking",
      "page",
      "portal.",
      "case",
      "completion",
      "code",
      "set",
      "abandoned",
      "user.",
      "fulfilled",
      "social",
      "comments.",
      "agent",
      "longer",
      "valid",
      "relevant.",
      "after",
      "task",
      "assignees"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Shopping cart workflow",
    "content": "This section describes the metaphases and subordinate phases in the life cycle of a cart request. Metaphase: Classification Example: a cart request is submitted with three child requests. The cart request is automatically moved to Approve phase. Phase Transition Description Log Automatic Log is the starting point for requests. The result of the phase is the successful creation of a request. The phase automatically transitions to Approve when there is an approval plan for the Approve phase. The phase automatically transitions to Close when there is no approval plan for the Approve phase. Next phase: Approve or Close Metaphase: Approval Example: a cart request is submitted with three child requests. Governance Level Approval is required. Once approved, the cart request is done, and the child requests individually proceed. Phase Transition Description Approve Automatic The phase automatically transitions to Close when the cart approval decision is made. Next phase: Close. Metaphase: Done ",
    "url": "cartwflw",
    "filename": "cartwflw",
    "headings": [
      "Metaphase: Classification",
      "Metaphase: Approval",
      "Metaphase: Done (End)",
      "Related topics"
    ],
    "keywords": [
      "shopping",
      "cart",
      "workflow",
      "metaphase",
      "classification",
      "approval",
      "done",
      "end",
      "related",
      "topics",
      "section",
      "describes",
      "metaphases",
      "subordinate",
      "phases",
      "life",
      "cycle",
      "request.",
      "example",
      "request",
      "submitted",
      "three",
      "child",
      "requests.",
      "automatically",
      "moved",
      "approve",
      "phase.",
      "phase",
      "transition",
      "description",
      "log",
      "automatic",
      "starting",
      "point",
      "result",
      "successful",
      "creation",
      "transitions",
      "there",
      "plan",
      "close",
      "next",
      "governance",
      "level",
      "required.",
      "once",
      "approved",
      "requests",
      "individually",
      "proceed.",
      "decision",
      "made.",
      "close.",
      "none",
      "completed.",
      "now",
      "none.",
      "note",
      "until",
      "reaches",
      "remain",
      "service",
      "management",
      "kpis",
      "notification",
      "rules",
      "portal",
      "support"
    ],
    "language": "en",
    "word_count": 103,
    "importance_score": 5.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "shopping cart workflow",
    "contentLower": "this section describes the metaphases and subordinate phases in the life cycle of a cart request. metaphase: classification example: a cart request is submitted with three child requests. the cart request is automatically moved to approve phase. phase transition description log automatic log is the starting point for requests. the result of the phase is the successful creation of a request. the phase automatically transitions to approve when there is an approval plan for the approve phase. the phase automatically transitions to close when there is no approval plan for the approve phase. next phase: approve or close metaphase: approval example: a cart request is submitted with three child requests. governance level approval is required. once approved, the cart request is done, and the child requests individually proceed. phase transition description approve automatic the phase automatically transitions to close when the cart approval decision is made. next phase: close. metaphase: done ",
    "keywordsLower": [
      "shopping",
      "cart",
      "workflow",
      "metaphase",
      "classification",
      "approval",
      "done",
      "end",
      "related",
      "topics",
      "section",
      "describes",
      "metaphases",
      "subordinate",
      "phases",
      "life",
      "cycle",
      "request.",
      "example",
      "request",
      "submitted",
      "three",
      "child",
      "requests.",
      "automatically",
      "moved",
      "approve",
      "phase.",
      "phase",
      "transition",
      "description",
      "log",
      "automatic",
      "starting",
      "point",
      "result",
      "successful",
      "creation",
      "transitions",
      "there",
      "plan",
      "close",
      "next",
      "governance",
      "level",
      "required.",
      "once",
      "approved",
      "requests",
      "individually",
      "proceed.",
      "decision",
      "made.",
      "close.",
      "none",
      "completed.",
      "now",
      "none.",
      "note",
      "until",
      "reaches",
      "remain",
      "service",
      "management",
      "kpis",
      "notification",
      "rules",
      "portal",
      "support"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Service request notification rules",
    "content": "Service Management sends an email notification to designated users when a business rule triggers a notification event. The following sections describe the notifications. The default business rules define the recipients according to the user or group identified in the service request record, but an administrator must first do the following: Assign the appropriate Service Request Management roles to the named users Populate groups with users who also have the appropriate roles to add, change, or update service requests. For the cloud service notifications, the subscription date is calculated using the time zone defined in the email recipient. If no time zone is defined in the email recipient, the Time zone definition field in Application Settings will be used. If the Time zone definition field in Application Settings is also empty, the time zone of Service Management server will be used. New request Template Recipients Content Notes Template definition for create request Requested for pe",
    "url": "srmnotifications",
    "filename": "srmnotifications",
    "headings": [
      "New request",
      "User abandons a chat",
      "Request assigned",
      "Request approved",
      "Request denied",
      "Solution provided",
      "Cloud Service deployment failed",
      "Cloud Service modification failed",
      "Cloud Service cancellation failed",
      "Cloud Service transfer failed",
      "SLT breach: initial review",
      "SLT breach: resolution",
      "SLT breach: OLA",
      "SLT breach: fulfillment",
      "Comment added",
      "Notification rules and confidential requests",
      "Cart requests and notification rules",
      "Related topics"
    ],
    "keywords": [
      "entity.Id",
      "service",
      "request",
      "notification",
      "rules",
      "new",
      "user",
      "abandons",
      "chat",
      "assigned",
      "approved",
      "denied",
      "solution",
      "provided",
      "cloud",
      "deployment",
      "failed",
      "modification",
      "cancellation",
      "transfer",
      "slt",
      "breach",
      "initial",
      "review",
      "resolution",
      "ola",
      "fulfillment",
      "comment",
      "added",
      "confidential",
      "requests",
      "cart",
      "related",
      "topics",
      "management",
      "sends",
      "email",
      "designated",
      "users",
      "business",
      "rule",
      "triggers",
      "event.",
      "following",
      "sections",
      "describe",
      "notifications.",
      "default",
      "define",
      "recipients",
      "according",
      "group",
      "identified",
      "record",
      "administrator",
      "first",
      "assign",
      "appropriate",
      "roles",
      "named",
      "populate",
      "groups",
      "add",
      "change",
      "update",
      "requests.",
      "notifications",
      "subscription",
      "date",
      "calculated",
      "time",
      "zone",
      "defined",
      "recipient.",
      "recipient",
      "definition",
      "field",
      "application",
      "settings",
      "used.",
      "empty",
      "server",
      "template",
      "content",
      "notes",
      "create",
      "requested",
      "person",
      "title",
      "id",
      "parent",
      "integration",
      "off.",
      "creation",
      "knowledge",
      "displaylabel",
      "mailto",
      "link",
      "private",
      "there"
    ],
    "language": "en",
    "word_count": 101,
    "importance_score": 6.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "service request notification rules",
    "contentLower": "service management sends an email notification to designated users when a business rule triggers a notification event. the following sections describe the notifications. the default business rules define the recipients according to the user or group identified in the service request record, but an administrator must first do the following: assign the appropriate service request management roles to the named users populate groups with users who also have the appropriate roles to add, change, or update service requests. for the cloud service notifications, the subscription date is calculated using the time zone defined in the email recipient. if no time zone is defined in the email recipient, the time zone definition field in application settings will be used. if the time zone definition field in application settings is also empty, the time zone of service management server will be used. new request template recipients content notes template definition for create request requested for pe",
    "keywordsLower": [
      "entity.id",
      "service",
      "request",
      "notification",
      "rules",
      "new",
      "user",
      "abandons",
      "chat",
      "assigned",
      "approved",
      "denied",
      "solution",
      "provided",
      "cloud",
      "deployment",
      "failed",
      "modification",
      "cancellation",
      "transfer",
      "slt",
      "breach",
      "initial",
      "review",
      "resolution",
      "ola",
      "fulfillment",
      "comment",
      "added",
      "confidential",
      "requests",
      "cart",
      "related",
      "topics",
      "management",
      "sends",
      "email",
      "designated",
      "users",
      "business",
      "rule",
      "triggers",
      "event.",
      "following",
      "sections",
      "describe",
      "notifications.",
      "default",
      "define",
      "recipients",
      "according",
      "group",
      "identified",
      "record",
      "administrator",
      "first",
      "assign",
      "appropriate",
      "roles",
      "named",
      "populate",
      "groups",
      "add",
      "change",
      "update",
      "requests.",
      "notifications",
      "subscription",
      "date",
      "calculated",
      "time",
      "zone",
      "defined",
      "recipient.",
      "recipient",
      "definition",
      "field",
      "application",
      "settings",
      "used.",
      "empty",
      "server",
      "template",
      "content",
      "notes",
      "create",
      "requested",
      "person",
      "title",
      "id",
      "parent",
      "integration",
      "off.",
      "creation",
      "knowledge",
      "displaylabel",
      "mailto",
      "link",
      "private",
      "there"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Service Request Management KPIs",
    "content": "Key Performance Indicators (KPIs) are useful for evaluating your Service Request Management processes. To visualize trend information, it's useful to graph KPI data periodically. In addition to the data provided by Service Management, you may need additional tools to report on all of your KPI requirements. Metric Description Percentage of requests closed within Service Level Target time The number of requests that are closed within the Service Level Target time, relative to the number of all requests closed, in a given time period. Percentage of rejected requests The number of resolved requests that were rejected by the user as not solved Backlog of requests The number of requests that aren't yet closed, in a given time period. Total number of requests Total number of new requests, in a given time period. These are common metrics, however, each standards organization has their own recommendations. ITIL V3 KPIs Total number of requests (as a control measure). Breakdown of requests at ea",
    "url": "srmkpis",
    "filename": "srmkpis",
    "headings": [
      "ITIL V3 KPIs",
      "Useful request fields",
      "Related topics"
    ],
    "keywords": [
      "4.1",
      "service",
      "request",
      "management",
      "kpis",
      "itil",
      "v3",
      "useful",
      "fields",
      "related",
      "topics",
      "key",
      "performance",
      "indicators",
      "evaluating",
      "processes.",
      "visualize",
      "trend",
      "information",
      "graph",
      "kpi",
      "data",
      "periodically.",
      "addition",
      "provided",
      "need",
      "additional",
      "tools",
      "report",
      "all",
      "requirements.",
      "metric",
      "description",
      "percentage",
      "requests",
      "closed",
      "level",
      "target",
      "time",
      "number",
      "relative",
      "given",
      "period.",
      "rejected",
      "resolved",
      "user",
      "solved",
      "backlog",
      "aren",
      "yet",
      "total",
      "new",
      "common",
      "metrics",
      "however",
      "standards",
      "organization",
      "own",
      "recommendations.",
      "control",
      "measure",
      "breakdown",
      "stage.",
      "example",
      "logged",
      "work",
      "progress",
      "closed.",
      "size",
      "current",
      "backlog.",
      "major",
      "requests.",
      "mean",
      "elapsed",
      "achieve",
      "resolution",
      "workaround",
      "impact.",
      "handled",
      "response",
      "time.",
      "specify",
      "response-time",
      "targets",
      "defined",
      "targets.",
      "average",
      "cost",
      "request.",
      "reopened",
      "total.",
      "incorrectly",
      "assigned.",
      "categorized.",
      "remotely",
      "on-site",
      "visit",
      "required.",
      "offering."
    ],
    "language": "en",
    "word_count": 107,
    "importance_score": 4.5,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "service request management kpis",
    "contentLower": "key performance indicators (kpis) are useful for evaluating your service request management processes. to visualize trend information, it's useful to graph kpi data periodically. in addition to the data provided by service management, you may need additional tools to report on all of your kpi requirements. metric description percentage of requests closed within service level target time the number of requests that are closed within the service level target time, relative to the number of all requests closed, in a given time period. percentage of rejected requests the number of resolved requests that were rejected by the user as not solved backlog of requests the number of requests that aren't yet closed, in a given time period. total number of requests total number of new requests, in a given time period. these are common metrics, however, each standards organization has their own recommendations. itil v3 kpis total number of requests (as a control measure). breakdown of requests at ea",
    "keywordsLower": [
      "4.1",
      "service",
      "request",
      "management",
      "kpis",
      "itil",
      "v3",
      "useful",
      "fields",
      "related",
      "topics",
      "key",
      "performance",
      "indicators",
      "evaluating",
      "processes.",
      "visualize",
      "trend",
      "information",
      "graph",
      "kpi",
      "data",
      "periodically.",
      "addition",
      "provided",
      "need",
      "additional",
      "tools",
      "report",
      "all",
      "requirements.",
      "metric",
      "description",
      "percentage",
      "requests",
      "closed",
      "level",
      "target",
      "time",
      "number",
      "relative",
      "given",
      "period.",
      "rejected",
      "resolved",
      "user",
      "solved",
      "backlog",
      "aren",
      "yet",
      "total",
      "new",
      "common",
      "metrics",
      "however",
      "standards",
      "organization",
      "own",
      "recommendations.",
      "control",
      "measure",
      "breakdown",
      "stage.",
      "example",
      "logged",
      "work",
      "progress",
      "closed.",
      "size",
      "current",
      "backlog.",
      "major",
      "requests.",
      "mean",
      "elapsed",
      "achieve",
      "resolution",
      "workaround",
      "impact.",
      "handled",
      "response",
      "time.",
      "specify",
      "response-time",
      "targets",
      "defined",
      "targets.",
      "average",
      "cost",
      "request.",
      "reopened",
      "total.",
      "incorrectly",
      "assigned.",
      "categorized.",
      "remotely",
      "on-site",
      "visit",
      "required.",
      "offering."
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Set up public requests",
    "content": "To set up public requests, edit each of the following as detailed: Offerings For each offering under which you want to allow requests to be public: Open the offering record. Go to the Public audience section in the General tab. Edit the Allow public and Public scope fields, as required. For example: An Allow public setting of Always means that requests created under this offering are always shared, according to the Public scope setting. A Public scope setting of Organization means that requests created under this offering are shared with people who are in the same organizational group as that of the person in the Requested for field of the request. For more information, see Public audience. Save your changes. Person To be able to see public requests, a user must be in the relevant public scope. Person and Location Where the public scope is Location, to see public requests, a user must be at the same or lower level of location as that of the person in the Requested for field of the requ",
    "url": "publicrequestssetup",
    "filename": "publicrequestssetup",
    "headings": [
      "Offerings",
      "Person",
      "Related topics"
    ],
    "keywords": [
      "set",
      "public",
      "requests",
      "offerings",
      "person",
      "related",
      "topics",
      "edit",
      "following",
      "detailed",
      "offering",
      "under",
      "want",
      "allow",
      "open",
      "record.",
      "go",
      "audience",
      "section",
      "general",
      "tab.",
      "scope",
      "fields",
      "required.",
      "example",
      "setting",
      "always",
      "means",
      "created",
      "shared",
      "according",
      "setting.",
      "organization",
      "people",
      "same",
      "organizational",
      "group",
      "requested",
      "field",
      "request.",
      "information",
      "see",
      "audience.",
      "save",
      "changes.",
      "able",
      "user",
      "relevant",
      "scope.",
      "location",
      "lower",
      "level",
      "request",
      "north",
      "america",
      "united",
      "states",
      "san",
      "diego",
      "office",
      "hierarchy",
      "city",
      "sharing",
      "country",
      "customize",
      "main",
      "menu",
      "select",
      "administration",
      "configuration",
      "service",
      "portal",
      "settings",
      "feature",
      "default",
      "sharing.",
      "enabled",
      "create",
      "interact",
      "management",
      "features",
      "view",
      "follow"
    ],
    "language": "en",
    "word_count": 98,
    "importance_score": 4.5,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "set up public requests",
    "contentLower": "to set up public requests, edit each of the following as detailed: offerings for each offering under which you want to allow requests to be public: open the offering record. go to the public audience section in the general tab. edit the allow public and public scope fields, as required. for example: an allow public setting of always means that requests created under this offering are always shared, according to the public scope setting. a public scope setting of organization means that requests created under this offering are shared with people who are in the same organizational group as that of the person in the requested for field of the request. for more information, see public audience. save your changes. person to be able to see public requests, a user must be in the relevant public scope. person and location where the public scope is location, to see public requests, a user must be at the same or lower level of location as that of the person in the requested for field of the requ",
    "keywordsLower": [
      "set",
      "public",
      "requests",
      "offerings",
      "person",
      "related",
      "topics",
      "edit",
      "following",
      "detailed",
      "offering",
      "under",
      "want",
      "allow",
      "open",
      "record.",
      "go",
      "audience",
      "section",
      "general",
      "tab.",
      "scope",
      "fields",
      "required.",
      "example",
      "setting",
      "always",
      "means",
      "created",
      "shared",
      "according",
      "setting.",
      "organization",
      "people",
      "same",
      "organizational",
      "group",
      "requested",
      "field",
      "request.",
      "information",
      "see",
      "audience.",
      "save",
      "changes.",
      "able",
      "user",
      "relevant",
      "scope.",
      "location",
      "lower",
      "level",
      "request",
      "north",
      "america",
      "united",
      "states",
      "san",
      "diego",
      "office",
      "hierarchy",
      "city",
      "sharing",
      "country",
      "customize",
      "main",
      "menu",
      "select",
      "administration",
      "configuration",
      "service",
      "portal",
      "settings",
      "feature",
      "default",
      "sharing.",
      "enabled",
      "create",
      "interact",
      "management",
      "features",
      "view",
      "follow"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Relate incident records",
    "content": "Service Management records are often linked to one another because you can't always resolve an issue without investigating its cause or putting changes in motion to avoid similar issues. Service Management lists related records in the Related records section of the incident form. Click the Related records tab to display a list of related records that depend on the current record the current record depends on In each section, the default sort order is first by record type, then by phase. You can click a column heading to reverse the sort order in any column. Field Description ID The identifier of the record. Click the ID value to link to the record. Title or Name A short description provided by the end user. Phase The current phase of the current record in the workflow. Priority The priority is a value based on urgency and business impact values. In the appropriate section, do one of the following: Click Add to create a relationship between the current record and another record. The Add",
    "url": "imrelaterec",
    "filename": "imrelaterec",
    "headings": [
      "Related topics"
    ],
    "keywords": [
      "relate",
      "incident",
      "records",
      "related",
      "topics",
      "service",
      "management",
      "often",
      "linked",
      "one",
      "another",
      "because",
      "always",
      "resolve",
      "issue",
      "investigating",
      "cause",
      "putting",
      "changes",
      "motion",
      "avoid",
      "similar",
      "issues.",
      "lists",
      "section",
      "form.",
      "click",
      "tab",
      "display",
      "list",
      "depend",
      "current",
      "record",
      "depends",
      "default",
      "sort",
      "order",
      "first",
      "type",
      "phase.",
      "column",
      "heading",
      "reverse",
      "any",
      "column.",
      "field",
      "description",
      "id",
      "identifier",
      "record.",
      "value",
      "link",
      "title",
      "name",
      "short",
      "provided",
      "end",
      "user.",
      "phase",
      "workflow.",
      "priority",
      "based",
      "urgency",
      "business",
      "impact",
      "values.",
      "appropriate",
      "following",
      "add",
      "create",
      "relationship",
      "between",
      "dialog",
      "box",
      "opens",
      "displaying",
      "potential",
      "records.",
      "select",
      "individual",
      "displays",
      "contents",
      "right",
      "pane.",
      "search",
      "top",
      "box.",
      "find",
      "want",
      "ok",
      "relationship.",
      "remove",
      "delete",
      "selected",
      "confirm",
      "action.",
      "note",
      "action",
      "removes",
      "two"
    ],
    "language": "en",
    "word_count": 108,
    "importance_score": 3.5,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "relate incident records",
    "contentLower": "service management records are often linked to one another because you can't always resolve an issue without investigating its cause or putting changes in motion to avoid similar issues. service management lists related records in the related records section of the incident form. click the related records tab to display a list of related records that depend on the current record the current record depends on in each section, the default sort order is first by record type, then by phase. you can click a column heading to reverse the sort order in any column. field description id the identifier of the record. click the id value to link to the record. title or name a short description provided by the end user. phase the current phase of the current record in the workflow. priority the priority is a value based on urgency and business impact values. in the appropriate section, do one of the following: click add to create a relationship between the current record and another record. the add",
    "keywordsLower": [
      "relate",
      "incident",
      "records",
      "related",
      "topics",
      "service",
      "management",
      "often",
      "linked",
      "one",
      "another",
      "because",
      "always",
      "resolve",
      "issue",
      "investigating",
      "cause",
      "putting",
      "changes",
      "motion",
      "avoid",
      "similar",
      "issues.",
      "lists",
      "section",
      "form.",
      "click",
      "tab",
      "display",
      "list",
      "depend",
      "current",
      "record",
      "depends",
      "default",
      "sort",
      "order",
      "first",
      "type",
      "phase.",
      "column",
      "heading",
      "reverse",
      "any",
      "column.",
      "field",
      "description",
      "id",
      "identifier",
      "record.",
      "value",
      "link",
      "title",
      "name",
      "short",
      "provided",
      "end",
      "user.",
      "phase",
      "workflow.",
      "priority",
      "based",
      "urgency",
      "business",
      "impact",
      "values.",
      "appropriate",
      "following",
      "add",
      "create",
      "relationship",
      "between",
      "dialog",
      "box",
      "opens",
      "displaying",
      "potential",
      "records.",
      "select",
      "individual",
      "displays",
      "contents",
      "right",
      "pane.",
      "search",
      "top",
      "box.",
      "find",
      "want",
      "ok",
      "relationship.",
      "remove",
      "delete",
      "selected",
      "confirm",
      "action.",
      "note",
      "action",
      "removes",
      "two"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Retire an incident model",
    "content": "Note You must have the appropriate permissions to retire an incident model. If you retire an incident model, this has no effect on existing incidents that used the model. When you retire a model, you change its status from active to retired. You can see the change in the workflow snapshot at the top of the page. From the main menu, select Run > Incident > Models. Service Management displays a list of existing incident model records. Select the incident model. Click the record identifier in the ID column to display the selected record. To the right of the workflow snapshot, click Retired, then Save. Related topics How to activate an incident model How to create an incident model How to edit an incident model Incident models Incident model business rules",
    "url": "retireincidentmodel",
    "filename": "retireincidentmodel",
    "headings": [
      "Related topics"
    ],
    "keywords": [
      "retire",
      "incident",
      "model",
      "related",
      "topics",
      "note",
      "appropriate",
      "permissions",
      "model.",
      "effect",
      "existing",
      "incidents",
      "change",
      "status",
      "active",
      "retired.",
      "see",
      "workflow",
      "snapshot",
      "top",
      "page.",
      "main",
      "menu",
      "select",
      "run",
      "models.",
      "service",
      "management",
      "displays",
      "list",
      "records.",
      "click",
      "record",
      "identifier",
      "id",
      "column",
      "display",
      "selected",
      "record.",
      "right",
      "retired",
      "save.",
      "activate",
      "create",
      "edit",
      "models",
      "business",
      "rules"
    ],
    "language": "en",
    "word_count": 76,
    "importance_score": 3.5,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "retire an incident model",
    "contentLower": "note you must have the appropriate permissions to retire an incident model. if you retire an incident model, this has no effect on existing incidents that used the model. when you retire a model, you change its status from active to retired. you can see the change in the workflow snapshot at the top of the page. from the main menu, select run > incident > models. service management displays a list of existing incident model records. select the incident model. click the record identifier in the id column to display the selected record. to the right of the workflow snapshot, click retired, then save. related topics how to activate an incident model how to create an incident model how to edit an incident model incident models incident model business rules",
    "keywordsLower": [
      "retire",
      "incident",
      "model",
      "related",
      "topics",
      "note",
      "appropriate",
      "permissions",
      "model.",
      "effect",
      "existing",
      "incidents",
      "change",
      "status",
      "active",
      "retired.",
      "see",
      "workflow",
      "snapshot",
      "top",
      "page.",
      "main",
      "menu",
      "select",
      "run",
      "models.",
      "service",
      "management",
      "displays",
      "list",
      "records.",
      "click",
      "record",
      "identifier",
      "id",
      "column",
      "display",
      "selected",
      "record.",
      "right",
      "retired",
      "save.",
      "activate",
      "create",
      "edit",
      "models",
      "business",
      "rules"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Solution matching",
    "content": "A quick method to resolve an incident is to search for a solution or workaround that applied to another incident with similar circumstances or field values. Service Management stores the information found in these incident record fields: Title Description Solution Location Service Configuration item When you create a new incident, you can search for other incidents that have matching information in one or more of these fields. The solution that resolved the earlier incident might also apply to the new incident. When you can find a satisfactory solution or workaround, you can decrease the amount of time to resolve the new incident. Related topics First touch solutions Incident Management ITIL process Learn more about Incident Management",
    "url": "solutionmatching",
    "filename": "solutionmatching",
    "headings": [
      "Related topics"
    ],
    "keywords": [
      "solution",
      "matching",
      "related",
      "topics",
      "quick",
      "method",
      "resolve",
      "incident",
      "search",
      "workaround",
      "applied",
      "another",
      "similar",
      "circumstances",
      "field",
      "values.",
      "service",
      "management",
      "stores",
      "information",
      "found",
      "record",
      "fields",
      "title",
      "description",
      "location",
      "configuration",
      "item",
      "create",
      "new",
      "incidents",
      "one",
      "fields.",
      "resolved",
      "earlier",
      "apply",
      "incident.",
      "find",
      "satisfactory",
      "decrease",
      "amount",
      "time",
      "first",
      "touch",
      "solutions",
      "itil",
      "process",
      "learn",
      "about"
    ],
    "language": "en",
    "word_count": 70,
    "importance_score": 3.5,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "solution matching",
    "contentLower": "a quick method to resolve an incident is to search for a solution or workaround that applied to another incident with similar circumstances or field values. service management stores the information found in these incident record fields: title description solution location service configuration item when you create a new incident, you can search for other incidents that have matching information in one or more of these fields. the solution that resolved the earlier incident might also apply to the new incident. when you can find a satisfactory solution or workaround, you can decrease the amount of time to resolve the new incident. related topics first touch solutions incident management itil process learn more about incident management",
    "keywordsLower": [
      "solution",
      "matching",
      "related",
      "topics",
      "quick",
      "method",
      "resolve",
      "incident",
      "search",
      "workaround",
      "applied",
      "another",
      "similar",
      "circumstances",
      "field",
      "values.",
      "service",
      "management",
      "stores",
      "information",
      "found",
      "record",
      "fields",
      "title",
      "description",
      "location",
      "configuration",
      "item",
      "create",
      "new",
      "incidents",
      "one",
      "fields.",
      "resolved",
      "earlier",
      "apply",
      "incident.",
      "find",
      "satisfactory",
      "decrease",
      "amount",
      "time",
      "first",
      "touch",
      "solutions",
      "itil",
      "process",
      "learn",
      "about"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Relate problem records",
    "content": "Service Management records are often linked to one another because you can't always complete a problem without investigating incidents or their causes, or putting changes in motion. Service Management lists related records in a separate tab on the change form. The Related records tab enables you to review, create, and delete relationships among Service Management records. The bracketed number in the tab label displays the number of related records for the current record. There are two types of related records: Causes of the record are other changes, incidents, or problems that triggered the current record. Example: An employee requests a certain change to an email account. The request triggered an incident because there is an email server outage. You can't complete the change until the incident status is closed. Effects of the record are other changes, incidents, or problems that are the result of the current record. Example: The incident to repair the email server outage generates a p",
    "url": "pmrelaterec",
    "filename": "pmrelaterec",
    "headings": [
      "To relate records",
      "Related topics"
    ],
    "keywords": [
      "relate",
      "problem",
      "records",
      "related",
      "topics",
      "service",
      "management",
      "often",
      "linked",
      "one",
      "another",
      "because",
      "always",
      "complete",
      "investigating",
      "incidents",
      "causes",
      "putting",
      "changes",
      "motion.",
      "lists",
      "separate",
      "tab",
      "change",
      "form.",
      "enables",
      "review",
      "create",
      "delete",
      "relationships",
      "among",
      "records.",
      "bracketed",
      "number",
      "label",
      "displays",
      "current",
      "record.",
      "there",
      "two",
      "types",
      "record",
      "problems",
      "triggered",
      "example",
      "employee",
      "requests",
      "certain",
      "email",
      "account.",
      "request",
      "incident",
      "server",
      "outage.",
      "until",
      "status",
      "closed.",
      "effects",
      "result",
      "repair",
      "outage",
      "generates",
      "recurring",
      "requires",
      "investigation.",
      "resolution",
      "finding",
      "root",
      "cause",
      "resolved",
      "resolved.",
      "resolving",
      "involve",
      "hardware",
      "software",
      "acquisition",
      "even",
      "require",
      "new",
      "available.",
      "link",
      "asset",
      "problems.",
      "click",
      "display",
      "list",
      "section",
      "default",
      "sort",
      "order",
      "first",
      "type",
      "phase.",
      "column",
      "heading",
      "reverse",
      "any",
      "column.",
      "field",
      "description"
    ],
    "language": "en",
    "word_count": 103,
    "importance_score": 4.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "relate problem records",
    "contentLower": "service management records are often linked to one another because you can't always complete a problem without investigating incidents or their causes, or putting changes in motion. service management lists related records in a separate tab on the change form. the related records tab enables you to review, create, and delete relationships among service management records. the bracketed number in the tab label displays the number of related records for the current record. there are two types of related records: causes of the record are other changes, incidents, or problems that triggered the current record. example: an employee requests a certain change to an email account. the request triggered an incident because there is an email server outage. you can't complete the change until the incident status is closed. effects of the record are other changes, incidents, or problems that are the result of the current record. example: the incident to repair the email server outage generates a p",
    "keywordsLower": [
      "relate",
      "problem",
      "records",
      "related",
      "topics",
      "service",
      "management",
      "often",
      "linked",
      "one",
      "another",
      "because",
      "always",
      "complete",
      "investigating",
      "incidents",
      "causes",
      "putting",
      "changes",
      "motion.",
      "lists",
      "separate",
      "tab",
      "change",
      "form.",
      "enables",
      "review",
      "create",
      "delete",
      "relationships",
      "among",
      "records.",
      "bracketed",
      "number",
      "label",
      "displays",
      "current",
      "record.",
      "there",
      "two",
      "types",
      "record",
      "problems",
      "triggered",
      "example",
      "employee",
      "requests",
      "certain",
      "email",
      "account.",
      "request",
      "incident",
      "server",
      "outage.",
      "until",
      "status",
      "closed.",
      "effects",
      "result",
      "repair",
      "outage",
      "generates",
      "recurring",
      "requires",
      "investigation.",
      "resolution",
      "finding",
      "root",
      "cause",
      "resolved",
      "resolved.",
      "resolving",
      "involve",
      "hardware",
      "software",
      "acquisition",
      "even",
      "require",
      "new",
      "available.",
      "link",
      "asset",
      "problems.",
      "click",
      "display",
      "list",
      "section",
      "default",
      "sort",
      "order",
      "first",
      "type",
      "phase.",
      "column",
      "heading",
      "reverse",
      "any",
      "column.",
      "field",
      "description"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Set up working hours",
    "content": "Every user can set their working hours: the times during which the user is at work. To set up your working hours: Log in to Service Management using your credentials. Click the avatar in the menu bar and then select User profile. The Profile & Preferences page is displayed. Click Schedule. Your personal schedule is displayed. Click Manage working hours. The Manage working hours dialog box is displayed. Select a Time zone from the drop-down. This should match the location where you are working. Select the Working days. Enter the Start time and End time. These values apply to each of the selected Working days. If you want different working hours for different days, click Split working hours, and enter the appropriate values for each group of days. For example, assume you want the following working hours: Monday 9.00 AM to 3.00 PM Tuesday 9.00 AM to 3.00 PM Wednesday 7.00 AM to 1.00 PM Thursday 9.00 AM to 3.00 PM Friday 7.00 AM to 11.00 AM In such a case, you could: Select Monday, Tuesday",
    "url": "workinghours",
    "filename": "workinghours",
    "headings": [
      "Related topics"
    ],
    "keywords": [
      "7.00",
      "1.00",
      "9.00",
      "11.00",
      "3.00",
      "set",
      "working",
      "hours",
      "related",
      "topics",
      "every",
      "user",
      "times",
      "during",
      "work.",
      "log",
      "service",
      "management",
      "credentials.",
      "click",
      "avatar",
      "menu",
      "bar",
      "select",
      "profile.",
      "profile",
      "preferences",
      "page",
      "displayed.",
      "schedule.",
      "personal",
      "schedule",
      "manage",
      "hours.",
      "dialog",
      "box",
      "time",
      "zone",
      "drop-down.",
      "match",
      "location",
      "working.",
      "days.",
      "enter",
      "start",
      "end",
      "time.",
      "values",
      "apply",
      "selected",
      "want",
      "different",
      "days",
      "split",
      "appropriate",
      "group",
      "example",
      "assume",
      "following",
      "monday",
      "am",
      "pm",
      "tuesday",
      "wednesday",
      "thursday",
      "friday",
      "such",
      "case",
      "pm.",
      "am.",
      "save.",
      "assignment",
      "strategy",
      "edit",
      "employee",
      "on-call",
      "shifts",
      "add",
      "vacation"
    ],
    "language": "en",
    "word_count": 116,
    "importance_score": 3.5,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "set up working hours",
    "contentLower": "every user can set their working hours: the times during which the user is at work. to set up your working hours: log in to service management using your credentials. click the avatar in the menu bar and then select user profile. the profile & preferences page is displayed. click schedule. your personal schedule is displayed. click manage working hours. the manage working hours dialog box is displayed. select a time zone from the drop-down. this should match the location where you are working. select the working days. enter the start time and end time. these values apply to each of the selected working days. if you want different working hours for different days, click split working hours, and enter the appropriate values for each group of days. for example, assume you want the following working hours: monday 9.00 am to 3.00 pm tuesday 9.00 am to 3.00 pm wednesday 7.00 am to 1.00 pm thursday 9.00 am to 3.00 pm friday 7.00 am to 11.00 am in such a case, you could: select monday, tuesday",
    "keywordsLower": [
      "7.00",
      "1.00",
      "9.00",
      "11.00",
      "3.00",
      "set",
      "working",
      "hours",
      "related",
      "topics",
      "every",
      "user",
      "times",
      "during",
      "work.",
      "log",
      "service",
      "management",
      "credentials.",
      "click",
      "avatar",
      "menu",
      "bar",
      "select",
      "profile.",
      "profile",
      "preferences",
      "page",
      "displayed.",
      "schedule.",
      "personal",
      "schedule",
      "manage",
      "hours.",
      "dialog",
      "box",
      "time",
      "zone",
      "drop-down.",
      "match",
      "location",
      "working.",
      "days.",
      "enter",
      "start",
      "end",
      "time.",
      "values",
      "apply",
      "selected",
      "want",
      "different",
      "days",
      "split",
      "appropriate",
      "group",
      "example",
      "assume",
      "following",
      "monday",
      "am",
      "pm",
      "tuesday",
      "wednesday",
      "thursday",
      "friday",
      "such",
      "case",
      "pm.",
      "am.",
      "save.",
      "assignment",
      "strategy",
      "edit",
      "employee",
      "on-call",
      "shifts",
      "add",
      "vacation"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Set up the working hours for your employees",
    "content": "If you are the manager of a person, you can set up or edit their working hours. To set up or edit the working hours for an employee: Log in to Service Management using your credentials. Click the avatar in the menu bar and then select User profile. The Profile & Preferences page is displayed. Click the calendar icon for the employee. The schedule for the employee is displayed. Click Manage working hours. The Manage working hours dialog box is displayed. To edit existing working hours, edit the dialog box as required. To set up new working hours: Select a Time zone from the drop-down. This should match the location where the employee is working. Select the Working days. Enter the Start time and End time. These values apply to each of the selected Working days. If you want different working hours for different days, click Split working hours, and enter the appropriate values for each group of days. Click Save. How to set up or edit a vacation for an employee If you are the manager of a p",
    "url": "managersetup",
    "filename": "managersetup",
    "headings": [
      "How to set up or edit a vacation for an employee",
      "Related topics"
    ],
    "keywords": [
      "displayed.To",
      "vacation.To",
      "set",
      "working",
      "hours",
      "employees",
      "edit",
      "vacation",
      "employee",
      "related",
      "topics",
      "manager",
      "person",
      "hours.",
      "log",
      "service",
      "management",
      "credentials.",
      "click",
      "avatar",
      "menu",
      "bar",
      "select",
      "user",
      "profile.",
      "profile",
      "preferences",
      "page",
      "displayed.",
      "calendar",
      "icon",
      "employee.",
      "schedule",
      "manage",
      "dialog",
      "box",
      "existing",
      "required.",
      "new",
      "time",
      "zone",
      "drop-down.",
      "match",
      "location",
      "working.",
      "days.",
      "enter",
      "start",
      "end",
      "time.",
      "values",
      "apply",
      "selected",
      "want",
      "different",
      "days",
      "split",
      "appropriate",
      "group",
      "save.",
      "vacations.",
      "on-call",
      "shifts",
      "automatically",
      "adjusted",
      "reflect",
      "still",
      "appear",
      "shift",
      "during",
      "period.",
      "managers",
      "manually",
      "update",
      "absence.",
      "credentials.click",
      "displayed.click",
      "navigate",
      "it.",
      "here",
      "delete",
      "add",
      "vacation.",
      "time.select",
      "all",
      "day",
      "event",
      "applicable.",
      "assignment",
      "strategyhow",
      "shiftshow",
      "vacationhow"
    ],
    "language": "en",
    "word_count": 103,
    "importance_score": 3.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "set up the working hours for your employees",
    "contentLower": "if you are the manager of a person, you can set up or edit their working hours. to set up or edit the working hours for an employee: log in to service management using your credentials. click the avatar in the menu bar and then select user profile. the profile & preferences page is displayed. click the calendar icon for the employee. the schedule for the employee is displayed. click manage working hours. the manage working hours dialog box is displayed. to edit existing working hours, edit the dialog box as required. to set up new working hours: select a time zone from the drop-down. this should match the location where the employee is working. select the working days. enter the start time and end time. these values apply to each of the selected working days. if you want different working hours for different days, click split working hours, and enter the appropriate values for each group of days. click save. how to set up or edit a vacation for an employee if you are the manager of a p",
    "keywordsLower": [
      "displayed.to",
      "vacation.to",
      "set",
      "working",
      "hours",
      "employees",
      "edit",
      "vacation",
      "employee",
      "related",
      "topics",
      "manager",
      "person",
      "hours.",
      "log",
      "service",
      "management",
      "credentials.",
      "click",
      "avatar",
      "menu",
      "bar",
      "select",
      "user",
      "profile.",
      "profile",
      "preferences",
      "page",
      "displayed.",
      "calendar",
      "icon",
      "employee.",
      "schedule",
      "manage",
      "dialog",
      "box",
      "existing",
      "required.",
      "new",
      "time",
      "zone",
      "drop-down.",
      "match",
      "location",
      "working.",
      "days.",
      "enter",
      "start",
      "end",
      "time.",
      "values",
      "apply",
      "selected",
      "want",
      "different",
      "days",
      "split",
      "appropriate",
      "group",
      "save.",
      "vacations.",
      "on-call",
      "shifts",
      "automatically",
      "adjusted",
      "reflect",
      "still",
      "appear",
      "shift",
      "during",
      "period.",
      "managers",
      "manually",
      "update",
      "absence.",
      "credentials.click",
      "displayed.click",
      "navigate",
      "it.",
      "here",
      "delete",
      "add",
      "vacation.",
      "time.select",
      "all",
      "day",
      "event",
      "applicable.",
      "assignment",
      "strategyhow",
      "shiftshow",
      "vacationhow"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Set up on-call shifts",
    "content": "Each group that's using On-Call Schedule Management, can set up their on-call shifts. Each on-call shift defines up to three group members who are on call: primary, first backup, and second backup. To set up an on-call shift for a group: From the main menu, select Run > On-Call Schedule. Select the appropriate group. Click View group calendar. Click Add on-call shift. The New on-call shift dialog box is displayed. Select a Time zone from the drop-down. This should match the location where the group is working. Select either Recurring event or One time event. For a one time event, enter the Start time and End time. For a recurring event, enter the Start time and End time. Alternatively, you may edit Duration and End time is automatically updated. For a recurring event, complete the Repeat every, Repeat on, Effective from, and Until fields. If you select No end date, the shift runs perpetually. Select Rotate on every shift if you want Service Management to automatically rotate the on-cal",
    "url": "oncallshifts",
    "filename": "oncallshifts",
    "headings": [
      "How to edit an on-call shift",
      "How to delete an on-call shift",
      "Limitation",
      "Related topics"
    ],
    "keywords": [
      "set",
      "on-call",
      "shifts",
      "edit",
      "shift",
      "delete",
      "limitation",
      "related",
      "topics",
      "group",
      "schedule",
      "management",
      "shifts.",
      "defines",
      "three",
      "members",
      "call",
      "primary",
      "first",
      "backup",
      "second",
      "backup.",
      "main",
      "menu",
      "select",
      "run",
      "schedule.",
      "appropriate",
      "group.",
      "click",
      "view",
      "calendar.",
      "add",
      "shift.",
      "new",
      "dialog",
      "box",
      "displayed.",
      "time",
      "zone",
      "drop-down.",
      "match",
      "location",
      "working.",
      "either",
      "recurring",
      "event",
      "one",
      "event.",
      "enter",
      "start",
      "end",
      "time.",
      "alternatively",
      "duration",
      "automatically",
      "updated.",
      "complete",
      "repeat",
      "every",
      "effective",
      "until",
      "fields.",
      "date",
      "runs",
      "perpetually.",
      "rotate",
      "want",
      "service",
      "maximum",
      "single",
      "default",
      "arrangement",
      "there",
      "member",
      "rotation",
      "two",
      "position",
      "alternates",
      "between",
      "follows",
      "rotating",
      "starts",
      "top",
      "continues",
      "downwards.",
      "example",
      "five",
      "listed",
      "order",
      "here",
      "starting",
      "priority",
      "order.",
      "therefore",
      "third",
      "another",
      "appropriate.",
      "access",
      "calendar"
    ],
    "language": "en",
    "word_count": 112,
    "importance_score": 5.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "set up on-call shifts",
    "contentLower": "each group that's using on-call schedule management, can set up their on-call shifts. each on-call shift defines up to three group members who are on call: primary, first backup, and second backup. to set up an on-call shift for a group: from the main menu, select run > on-call schedule. select the appropriate group. click view group calendar. click add on-call shift. the new on-call shift dialog box is displayed. select a time zone from the drop-down. this should match the location where the group is working. select either recurring event or one time event. for a one time event, enter the start time and end time. for a recurring event, enter the start time and end time. alternatively, you may edit duration and end time is automatically updated. for a recurring event, complete the repeat every, repeat on, effective from, and until fields. if you select no end date, the shift runs perpetually. select rotate on every shift if you want service management to automatically rotate the on-cal",
    "keywordsLower": [
      "set",
      "on-call",
      "shifts",
      "edit",
      "shift",
      "delete",
      "limitation",
      "related",
      "topics",
      "group",
      "schedule",
      "management",
      "shifts.",
      "defines",
      "three",
      "members",
      "call",
      "primary",
      "first",
      "backup",
      "second",
      "backup.",
      "main",
      "menu",
      "select",
      "run",
      "schedule.",
      "appropriate",
      "group.",
      "click",
      "view",
      "calendar.",
      "add",
      "shift.",
      "new",
      "dialog",
      "box",
      "displayed.",
      "time",
      "zone",
      "drop-down.",
      "match",
      "location",
      "working.",
      "either",
      "recurring",
      "event",
      "one",
      "event.",
      "enter",
      "start",
      "end",
      "time.",
      "alternatively",
      "duration",
      "automatically",
      "updated.",
      "complete",
      "repeat",
      "every",
      "effective",
      "until",
      "fields.",
      "date",
      "runs",
      "perpetually.",
      "rotate",
      "want",
      "service",
      "maximum",
      "single",
      "default",
      "arrangement",
      "there",
      "member",
      "rotation",
      "two",
      "position",
      "alternates",
      "between",
      "follows",
      "rotating",
      "starts",
      "top",
      "continues",
      "downwards.",
      "example",
      "five",
      "listed",
      "order",
      "here",
      "starting",
      "priority",
      "order.",
      "therefore",
      "third",
      "another",
      "appropriate.",
      "access",
      "calendar"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Set up assignment strategy",
    "content": "Assignment strategy defines how the system distributes tickets assigned to a group - which aren't directly assigned to a person. You set assignment strategy at the group level. To set up assignment strategy: From the main menu, select Administration > Master Data > People > Groups. Select the group, and then click Details. In the General section of the General tab, click Assignment strategy, and select one of the following: Value Description None The out-of-the-box default. No assignment strategy is set. Universal The ticket or email notification goes to all members of the group. Cascading On reaching Time in Group (OLA) of 0% (when the ticket is created), the ticket goes to the primary on-call group member. On reaching Time in Group (OLA) of 15%, and there is still no assigned person, the email notification goes to the first backup on-call group member. On reaching Time in Group (OLA) of 35%, and there is still no assigned person, the email notification goes to the second backup on-ca",
    "url": "assignmentstrategy",
    "filename": "assignmentstrategy",
    "headings": [
      "Related topics"
    ],
    "keywords": [
      "set",
      "assignment",
      "strategy",
      "related",
      "topics",
      "defines",
      "system",
      "distributes",
      "tickets",
      "assigned",
      "group",
      "aren",
      "directly",
      "person.",
      "level.",
      "main",
      "menu",
      "select",
      "administration",
      "master",
      "data",
      "people",
      "groups.",
      "click",
      "details.",
      "general",
      "section",
      "tab",
      "one",
      "following",
      "value",
      "description",
      "none",
      "out-of-the-box",
      "default.",
      "set.",
      "universal",
      "ticket",
      "email",
      "notification",
      "goes",
      "all",
      "members",
      "group.",
      "cascading",
      "reaching",
      "time",
      "ola",
      "created",
      "primary",
      "on-call",
      "member.",
      "15",
      "there",
      "still",
      "person",
      "first",
      "backup",
      "35",
      "second",
      "information",
      "about",
      "see",
      "slt",
      "settings.",
      "directed",
      "option",
      "field",
      "available",
      "dispatcher.",
      "drop-down.",
      "dispatcher",
      "member",
      "leave",
      "blank",
      "notifications",
      "sent.",
      "responsible",
      "onward",
      "distribution",
      "notifications.",
      "automatic",
      "automatically",
      "save.",
      "edit",
      "working",
      "hours",
      "employee",
      "shifts",
      "add",
      "vacation"
    ],
    "language": "en",
    "word_count": 108,
    "importance_score": 3.5,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "set up assignment strategy",
    "contentLower": "assignment strategy defines how the system distributes tickets assigned to a group - which aren't directly assigned to a person. you set assignment strategy at the group level. to set up assignment strategy: from the main menu, select administration > master data > people > groups. select the group, and then click details. in the general section of the general tab, click assignment strategy, and select one of the following: value description none the out-of-the-box default. no assignment strategy is set. universal the ticket or email notification goes to all members of the group. cascading on reaching time in group (ola) of 0% (when the ticket is created), the ticket goes to the primary on-call group member. on reaching time in group (ola) of 15%, and there is still no assigned person, the email notification goes to the first backup on-call group member. on reaching time in group (ola) of 35%, and there is still no assigned person, the email notification goes to the second backup on-ca",
    "keywordsLower": [
      "set",
      "assignment",
      "strategy",
      "related",
      "topics",
      "defines",
      "system",
      "distributes",
      "tickets",
      "assigned",
      "group",
      "aren",
      "directly",
      "person.",
      "level.",
      "main",
      "menu",
      "select",
      "administration",
      "master",
      "data",
      "people",
      "groups.",
      "click",
      "details.",
      "general",
      "section",
      "tab",
      "one",
      "following",
      "value",
      "description",
      "none",
      "out-of-the-box",
      "default.",
      "set.",
      "universal",
      "ticket",
      "email",
      "notification",
      "goes",
      "all",
      "members",
      "group.",
      "cascading",
      "reaching",
      "time",
      "ola",
      "created",
      "primary",
      "on-call",
      "member.",
      "15",
      "there",
      "still",
      "person",
      "first",
      "backup",
      "35",
      "second",
      "information",
      "about",
      "see",
      "slt",
      "settings.",
      "directed",
      "option",
      "field",
      "available",
      "dispatcher.",
      "drop-down.",
      "dispatcher",
      "member",
      "leave",
      "blank",
      "notifications",
      "sent.",
      "responsible",
      "onward",
      "distribution",
      "notifications.",
      "automatic",
      "automatically",
      "save.",
      "edit",
      "working",
      "hours",
      "employee",
      "shifts",
      "add",
      "vacation"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Software Asset Management",
    "content": "Software Asset Management in Service Management helps you to efficiently manage, control, and protect your software assets at each phase of their whole life cycle. Your software assets include software licenses: legal instruments governing the right to use software. Managing software assets effectively can benefit your organization in various ways. For example, by connecting the IT software investment to business services, by protecting and reducing ongoing software investment, and by eliminating or mitigating license compliance issues. The data in Service Management about software licenses, license contracts, license models, and metrics, details what you need to know about your software assets, and is a starting point for software asset management. New SAM capability Previously, Service Management provides a Software Asset Management application with limited features. Now a new SAM solution is available in Service Management. The new SAM capability can retrieve license data from Servi",
    "url": "softwareassetmgmt",
    "filename": "softwareassetmgmt",
    "headings": [
      "New SAM capability",
      "Related topics"
    ],
    "keywords": [
      "software",
      "asset",
      "management",
      "new",
      "sam",
      "capability",
      "related",
      "topics",
      "service",
      "helps",
      "efficiently",
      "manage",
      "control",
      "protect",
      "assets",
      "phase",
      "whole",
      "life",
      "cycle.",
      "include",
      "licenses",
      "legal",
      "instruments",
      "governing",
      "right",
      "software.",
      "managing",
      "effectively",
      "benefit",
      "organization",
      "various",
      "ways.",
      "example",
      "connecting",
      "investment",
      "business",
      "services",
      "protecting",
      "reducing",
      "ongoing",
      "eliminating",
      "mitigating",
      "license",
      "compliance",
      "issues.",
      "data",
      "about",
      "contracts",
      "models",
      "metrics",
      "details",
      "what",
      "need",
      "know",
      "starting",
      "point",
      "management.",
      "previously",
      "provides",
      "application",
      "limited",
      "features.",
      "now",
      "solution",
      "available",
      "retrieve",
      "hardware",
      "installation",
      "ud",
      "ucmdb.",
      "calculate",
      "analyze",
      "compliance.",
      "learn",
      "information",
      "such",
      "status",
      "consumed",
      "per",
      "machine",
      "allocation",
      "risks",
      "enterprise",
      "potential",
      "cost",
      "savings.",
      "licensing",
      "requirements",
      "see",
      "licensing.",
      "install",
      "enable",
      "add-on",
      "capabilities",
      "sam.",
      "after",
      "additional",
      "menu",
      "items",
      "help"
    ],
    "language": "en",
    "word_count": 103,
    "importance_score": 4.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "software asset management",
    "contentLower": "software asset management in service management helps you to efficiently manage, control, and protect your software assets at each phase of their whole life cycle. your software assets include software licenses: legal instruments governing the right to use software. managing software assets effectively can benefit your organization in various ways. for example, by connecting the it software investment to business services, by protecting and reducing ongoing software investment, and by eliminating or mitigating license compliance issues. the data in service management about software licenses, license contracts, license models, and metrics, details what you need to know about your software assets, and is a starting point for software asset management. new sam capability previously, service management provides a software asset management application with limited features. now a new sam solution is available in service management. the new sam capability can retrieve license data from servi",
    "keywordsLower": [
      "software",
      "asset",
      "management",
      "new",
      "sam",
      "capability",
      "related",
      "topics",
      "service",
      "helps",
      "efficiently",
      "manage",
      "control",
      "protect",
      "assets",
      "phase",
      "whole",
      "life",
      "cycle.",
      "include",
      "licenses",
      "legal",
      "instruments",
      "governing",
      "right",
      "software.",
      "managing",
      "effectively",
      "benefit",
      "organization",
      "various",
      "ways.",
      "example",
      "connecting",
      "investment",
      "business",
      "services",
      "protecting",
      "reducing",
      "ongoing",
      "eliminating",
      "mitigating",
      "license",
      "compliance",
      "issues.",
      "data",
      "about",
      "contracts",
      "models",
      "metrics",
      "details",
      "what",
      "need",
      "know",
      "starting",
      "point",
      "management.",
      "previously",
      "provides",
      "application",
      "limited",
      "features.",
      "now",
      "solution",
      "available",
      "retrieve",
      "hardware",
      "installation",
      "ud",
      "ucmdb.",
      "calculate",
      "analyze",
      "compliance.",
      "learn",
      "information",
      "such",
      "status",
      "consumed",
      "per",
      "machine",
      "allocation",
      "risks",
      "enterprise",
      "potential",
      "cost",
      "savings.",
      "licensing",
      "requirements",
      "see",
      "licensing.",
      "install",
      "enable",
      "add-on",
      "capabilities",
      "sam.",
      "after",
      "additional",
      "menu",
      "items",
      "help"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Retire a license metric record",
    "content": "Note You must have the appropriate permissions to be able to retire a license metric. If you retire a license metric, this has no effect on existing records. To retire a license metric record means changing its status, as shown in the workflow snapshot at the top of the record, from Active to Inactive. From the main menu, select Run > Software Asset > License Metrics. Select the license metric record. Click the record identifier in the ID column to display the selected record. Click Inactive, then Save. Related topics License metrics How to create a license metric record How to edit a license metric record",
    "url": "retirelicensetype",
    "filename": "retirelicensetype",
    "headings": [
      "Related topics"
    ],
    "keywords": [
      "retire",
      "license",
      "metric",
      "record",
      "related",
      "topics",
      "note",
      "appropriate",
      "permissions",
      "able",
      "metric.",
      "effect",
      "existing",
      "records.",
      "means",
      "changing",
      "status",
      "shown",
      "workflow",
      "snapshot",
      "top",
      "active",
      "inactive.",
      "main",
      "menu",
      "select",
      "run",
      "software",
      "asset",
      "metrics.",
      "record.",
      "click",
      "identifier",
      "id",
      "column",
      "display",
      "selected",
      "inactive",
      "save.",
      "metrics",
      "create",
      "edit"
    ],
    "language": "en",
    "word_count": 66,
    "importance_score": 3.5,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "retire a license metric record",
    "contentLower": "note you must have the appropriate permissions to be able to retire a license metric. if you retire a license metric, this has no effect on existing records. to retire a license metric record means changing its status, as shown in the workflow snapshot at the top of the record, from active to inactive. from the main menu, select run > software asset > license metrics. select the license metric record. click the record identifier in the id column to display the selected record. click inactive, then save. related topics license metrics how to create a license metric record how to edit a license metric record",
    "keywordsLower": [
      "retire",
      "license",
      "metric",
      "record",
      "related",
      "topics",
      "note",
      "appropriate",
      "permissions",
      "able",
      "metric.",
      "effect",
      "existing",
      "records.",
      "means",
      "changing",
      "status",
      "shown",
      "workflow",
      "snapshot",
      "top",
      "active",
      "inactive.",
      "main",
      "menu",
      "select",
      "run",
      "software",
      "asset",
      "metrics.",
      "record.",
      "click",
      "identifier",
      "id",
      "column",
      "display",
      "selected",
      "inactive",
      "save.",
      "metrics",
      "create",
      "edit"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Retire a license model",
    "content": "Note You must have the appropriate permissions to be able to retire a license model. If you retire a license model, this has no effect on existing license records. To retire a license model means changing its status, as shown in the workflow snapshot at the top of the model, from Active to Inactive. From the main menu, select Run > Software Asset > License Models. Select the license model. Click the record identifier in the Id column to display the selected record. Click INACTIVE. Click Save on the toolbar. Related topics License models How to create a license model How to edit a license model",
    "url": "retirelicensemodel",
    "filename": "retirelicensemodel",
    "headings": [
      "Related topics"
    ],
    "keywords": [
      "retire",
      "license",
      "model",
      "related",
      "topics",
      "note",
      "appropriate",
      "permissions",
      "able",
      "model.",
      "effect",
      "existing",
      "records.",
      "means",
      "changing",
      "status",
      "shown",
      "workflow",
      "snapshot",
      "top",
      "active",
      "inactive.",
      "main",
      "menu",
      "select",
      "run",
      "software",
      "asset",
      "models.",
      "click",
      "record",
      "identifier",
      "id",
      "column",
      "display",
      "selected",
      "record.",
      "save",
      "toolbar.",
      "models",
      "create",
      "edit"
    ],
    "language": "en",
    "word_count": 64,
    "importance_score": 3.5,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "retire a license model",
    "contentLower": "note you must have the appropriate permissions to be able to retire a license model. if you retire a license model, this has no effect on existing license records. to retire a license model means changing its status, as shown in the workflow snapshot at the top of the model, from active to inactive. from the main menu, select run > software asset > license models. select the license model. click the record identifier in the id column to display the selected record. click inactive. click save on the toolbar. related topics license models how to create a license model how to edit a license model",
    "keywordsLower": [
      "retire",
      "license",
      "model",
      "related",
      "topics",
      "note",
      "appropriate",
      "permissions",
      "able",
      "model.",
      "effect",
      "existing",
      "records.",
      "means",
      "changing",
      "status",
      "shown",
      "workflow",
      "snapshot",
      "top",
      "active",
      "inactive.",
      "main",
      "menu",
      "select",
      "run",
      "software",
      "asset",
      "models.",
      "click",
      "record",
      "identifier",
      "id",
      "column",
      "display",
      "selected",
      "record.",
      "save",
      "toolbar.",
      "models",
      "create",
      "edit"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Software titles",
    "content": "Note This functionality isn't fully developed, and is only available on a restricted release basis. In Service Management, software titles are a type of asset model: a classification that's applied to your installed software to help define how it's managed. An installation is a software installed on a device that conforms to a software title. Synchronization enables UCMDB to populate Service Management with details of your installations, and based on that information, software titles are created. In addition, details of the software installed on a device are displayed on the Software tab of the device record.",
    "url": "softwaretitles",
    "filename": "softwaretitles",
    "headings": [],
    "keywords": [
      "software",
      "titles",
      "note",
      "functionality",
      "isn",
      "fully",
      "developed",
      "available",
      "restricted",
      "release",
      "basis.",
      "service",
      "management",
      "type",
      "asset",
      "model",
      "classification",
      "applied",
      "installed",
      "help",
      "define",
      "managed.",
      "installation",
      "device",
      "conforms",
      "title.",
      "synchronization",
      "enables",
      "ucmdb",
      "populate",
      "details",
      "installations",
      "based",
      "information",
      "created.",
      "addition",
      "displayed",
      "tab",
      "record."
    ],
    "language": "en",
    "word_count": 58,
    "importance_score": 2.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "software titles",
    "contentLower": "note this functionality isn't fully developed, and is only available on a restricted release basis. in service management, software titles are a type of asset model: a classification that's applied to your installed software to help define how it's managed. an installation is a software installed on a device that conforms to a software title. synchronization enables ucmdb to populate service management with details of your installations, and based on that information, software titles are created. in addition, details of the software installed on a device are displayed on the software tab of the device record.",
    "keywordsLower": [
      "software",
      "titles",
      "note",
      "functionality",
      "isn",
      "fully",
      "developed",
      "available",
      "restricted",
      "release",
      "basis.",
      "service",
      "management",
      "type",
      "asset",
      "model",
      "classification",
      "applied",
      "installed",
      "help",
      "define",
      "managed.",
      "installation",
      "device",
      "conforms",
      "title.",
      "synchronization",
      "enables",
      "ucmdb",
      "populate",
      "details",
      "installations",
      "based",
      "information",
      "created.",
      "addition",
      "displayed",
      "tab",
      "record."
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "SAM Home",
    "content": "SAM Home is the landing page after you sign in to SAM. When you enter the SAM Home, the On-premises tab page appears by default. On-premises tab On the left pane, open the Publisher list. It includes an Overview dashboard and some publisher-specific dashboards for on-premises products. Overview dashboard The Overview dashboard provides an overview of all on-premises products, including their compliance status and the most at-risk products assessed based on the latest compliance calculation result. This table lists the charts on the Overview dashboard. You can click the bars to drill down and view more information about product compliance. Chart Description Note Current compliance meter Displays the compliance status of managed products, excluding those that don't exist in the production environment. Click a bar to view a list of compliant or noncompliant products and their compliance information. Created at: The time when the product record is created. Estimated cost: The estimated cos",
    "url": "samhome",
    "filename": "samhome",
    "headings": [
      "On-premises tab",
      "Overview dashboard",
      "List view columns",
      "Publisher-specific dashboards",
      "Additional charts for specific publishers",
      "Oracle",
      "Red Hat",
      "SaaS tab",
      "Overview dashboard",
      "Publisher-specific dashboards",
      "Related topics"
    ],
    "keywords": [
      "sam",
      "home",
      "on-premises",
      "tab",
      "overview",
      "dashboard",
      "list",
      "view",
      "columns",
      "publisher-specific",
      "dashboards",
      "additional",
      "charts",
      "specific",
      "publishers",
      "oracle",
      "red",
      "hat",
      "saas",
      "related",
      "topics",
      "landing",
      "page",
      "after",
      "sign",
      "sam.",
      "enter",
      "appears",
      "default.",
      "left",
      "pane",
      "open",
      "publisher",
      "list.",
      "includes",
      "products.",
      "provides",
      "all",
      "products",
      "including",
      "compliance",
      "status",
      "most",
      "at-risk",
      "assessed",
      "based",
      "latest",
      "calculation",
      "result.",
      "table",
      "lists",
      "dashboard.",
      "click",
      "bars",
      "drill",
      "information",
      "about",
      "product",
      "compliance.",
      "chart",
      "description",
      "note",
      "current",
      "meter",
      "displays",
      "managed",
      "excluding",
      "don",
      "exist",
      "production",
      "environment.",
      "bar",
      "compliant",
      "noncompliant",
      "information.",
      "created",
      "time",
      "record",
      "created.",
      "estimated",
      "cost",
      "calculated",
      "license",
      "gap",
      "between",
      "software",
      "installations",
      "consumed",
      "licenses.",
      "field",
      "see",
      "trend",
      "past",
      "months",
      "changes",
      "six",
      "months.",
      "hover",
      "over",
      "number"
    ],
    "language": "en",
    "word_count": 100,
    "importance_score": 6.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "sam home",
    "contentLower": "sam home is the landing page after you sign in to sam. when you enter the sam home, the on-premises tab page appears by default. on-premises tab on the left pane, open the publisher list. it includes an overview dashboard and some publisher-specific dashboards for on-premises products. overview dashboard the overview dashboard provides an overview of all on-premises products, including their compliance status and the most at-risk products assessed based on the latest compliance calculation result. this table lists the charts on the overview dashboard. you can click the bars to drill down and view more information about product compliance. chart description note current compliance meter displays the compliance status of managed products, excluding those that don't exist in the production environment. click a bar to view a list of compliant or noncompliant products and their compliance information. created at: the time when the product record is created. estimated cost: the estimated cos",
    "keywordsLower": [
      "sam",
      "home",
      "on-premises",
      "tab",
      "overview",
      "dashboard",
      "list",
      "view",
      "columns",
      "publisher-specific",
      "dashboards",
      "additional",
      "charts",
      "specific",
      "publishers",
      "oracle",
      "red",
      "hat",
      "saas",
      "related",
      "topics",
      "landing",
      "page",
      "after",
      "sign",
      "sam.",
      "enter",
      "appears",
      "default.",
      "left",
      "pane",
      "open",
      "publisher",
      "list.",
      "includes",
      "products.",
      "provides",
      "all",
      "products",
      "including",
      "compliance",
      "status",
      "most",
      "at-risk",
      "assessed",
      "based",
      "latest",
      "calculation",
      "result.",
      "table",
      "lists",
      "dashboard.",
      "click",
      "bars",
      "drill",
      "information",
      "about",
      "product",
      "compliance.",
      "chart",
      "description",
      "note",
      "current",
      "meter",
      "displays",
      "managed",
      "excluding",
      "don",
      "exist",
      "production",
      "environment.",
      "bar",
      "compliant",
      "noncompliant",
      "information.",
      "created",
      "time",
      "record",
      "created.",
      "estimated",
      "cost",
      "calculated",
      "license",
      "gap",
      "between",
      "software",
      "installations",
      "consumed",
      "licenses.",
      "field",
      "see",
      "trend",
      "past",
      "months",
      "changes",
      "six",
      "months.",
      "hover",
      "over",
      "number"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Retire a license model",
    "content": "Note You must have the appropriate permissions to be able to retire a license model. If you retire a license model, this has no effect on existing license records. To retire a license model means changing its status, as shown in the workflow snapshot at the top of the model, from Active to Inactive. From the main menu, select Run > Software Asset > License Models. Select the license model. Click the record identifier in the Id column to display the selected record. Click Move to: Inactive. If the system finds a linked version, you'll see the \"Failed to deactivate this license model because it's linked to a product that's still using the license\" message when moving the license model to the INACTIVE phase. In this case, decouple all the relationships between this license model and all linked product versions, and then deactivate the license model. The error message pops up because there is an out-of-the-box business rule for checking if any product version links to this asset model. You",
    "url": "samretirelicensemodel",
    "filename": "samretirelicensemodel",
    "headings": [
      "Related topics"
    ],
    "keywords": [
      "retire",
      "license",
      "model",
      "related",
      "topics",
      "note",
      "appropriate",
      "permissions",
      "able",
      "model.",
      "effect",
      "existing",
      "records.",
      "means",
      "changing",
      "status",
      "shown",
      "workflow",
      "snapshot",
      "top",
      "active",
      "inactive.",
      "main",
      "menu",
      "select",
      "run",
      "software",
      "asset",
      "models.",
      "click",
      "record",
      "identifier",
      "id",
      "column",
      "display",
      "selected",
      "record.",
      "move",
      "system",
      "finds",
      "linked",
      "version",
      "ll",
      "see",
      "failed",
      "deactivate",
      "because",
      "product",
      "still",
      "message",
      "moving",
      "inactive",
      "phase.",
      "case",
      "decouple",
      "all",
      "relationships",
      "between",
      "versions",
      "error",
      "pops",
      "there",
      "out-of-the-box",
      "business",
      "rule",
      "checking",
      "any",
      "links",
      "check",
      "studio",
      "assetmodel",
      "normal",
      "transition",
      "save",
      "toolbar.",
      "models",
      "create",
      "edit"
    ],
    "language": "en",
    "word_count": 104,
    "importance_score": 3.5,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "retire a license model",
    "contentLower": "note you must have the appropriate permissions to be able to retire a license model. if you retire a license model, this has no effect on existing license records. to retire a license model means changing its status, as shown in the workflow snapshot at the top of the model, from active to inactive. from the main menu, select run > software asset > license models. select the license model. click the record identifier in the id column to display the selected record. click move to: inactive. if the system finds a linked version, you'll see the \"failed to deactivate this license model because it's linked to a product that's still using the license\" message when moving the license model to the inactive phase. in this case, decouple all the relationships between this license model and all linked product versions, and then deactivate the license model. the error message pops up because there is an out-of-the-box business rule for checking if any product version links to this asset model. you",
    "keywordsLower": [
      "retire",
      "license",
      "model",
      "related",
      "topics",
      "note",
      "appropriate",
      "permissions",
      "able",
      "model.",
      "effect",
      "existing",
      "records.",
      "means",
      "changing",
      "status",
      "shown",
      "workflow",
      "snapshot",
      "top",
      "active",
      "inactive.",
      "main",
      "menu",
      "select",
      "run",
      "software",
      "asset",
      "models.",
      "click",
      "record",
      "identifier",
      "id",
      "column",
      "display",
      "selected",
      "record.",
      "move",
      "system",
      "finds",
      "linked",
      "version",
      "ll",
      "see",
      "failed",
      "deactivate",
      "because",
      "product",
      "still",
      "message",
      "moving",
      "inactive",
      "phase.",
      "case",
      "decouple",
      "all",
      "relationships",
      "between",
      "versions",
      "error",
      "pops",
      "there",
      "out-of-the-box",
      "business",
      "rule",
      "checking",
      "any",
      "links",
      "check",
      "studio",
      "assetmodel",
      "normal",
      "transition",
      "save",
      "toolbar.",
      "models",
      "create",
      "edit"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Supported software titles",
    "content": "This section lists the software titles that SAM supports and describes the license rules that SAM provides out of the box for license consumption calculation. The OOTB license rules aren't editable. You can reuse them or create new ones if necessary. Currently, these license rules can only help calculate license consumption per Host, OSE, and User, but they don't support the software maintenance contracts. The OOTB license rules that SAM offers include generic license rules and publisher-specific license rules. Different license rules might require different parameters. You need to configure the right discovery jobs to collect required software deployment data from UD/UCMDB. Generally, if a license rule accepts a parameter that contains information on software installations on a physical device, the relationships between the virtual machine and its underlying physical infrastructure also need to be discovered. For more information, see the Prerequisites section. Generic This table list",
    "url": "samsoftwaretitles",
    "filename": "samsoftwaretitles",
    "headings": [
      "Generic",
      "Publisher-specific (on-premises)",
      "Microsoft",
      "Microsoft products",
      "License rules for Microsoft products",
      "Licensing for 2012 Enterprise Edition, using core factor when the product runs on a physical OSE",
      "Licensing for 2012 Standard Edition, using core factor when the product runs on a physical OSE",
      "Licensing for 2016 Enterprise Edition, without core factor applied",
      "Licensing for 2016 Standard Edition, without core factor applied",
      "Licensing for 2012 Standard Edition when the product runs on an OSE",
      "Licensing for 2010 Enterprise Edition, using Per Processor when the product runs on a physical OSE",
      "Licensing for 2010 Standard Edition, using Per Processor when the product runs on a physical OSE",
      "Licensing for 2016 Datacenter Edition and higher",
      "Licensing for 2016 Standard Edition and higher",
      "Licensing for 2012 Datacenter Edition and higher",
      "Licensing for 2012 Standard Edition and higher",
      "Licensing for desktop applications",
      "Licensing for server software",
      "Licensing for desktop operating systems",
      "Application-level clusters for Microsoft products"
    ],
    "keywords": [
      "8.1",
      "6.5",
      "6.7",
      "https://www.oracle.com/assets/partitioning-070609.pdf",
      "070634.pdf",
      "http://go.microsoft.com/fwlink/?LinkID=229882",
      "oracle.com",
      "6.0",
      "7.0",
      "microsoft.com",
      "070609.pdf",
      "https://www.oracle.com/us/solutions/midsize/processor-core-factor-table-070634.pdf",
      "supported",
      "software",
      "titles",
      "generic",
      "publisher-specific",
      "on-premises",
      "microsoft",
      "products",
      "license",
      "rules",
      "licensing",
      "2012",
      "enterprise",
      "edition",
      "core",
      "factor",
      "product",
      "runs",
      "physical",
      "ose",
      "standard",
      "2016",
      "applied",
      "2010",
      "per",
      "processor",
      "datacenter",
      "higher",
      "desktop",
      "applications",
      "server",
      "operating",
      "systems",
      "application-level",
      "clusters",
      "ibm",
      "ilmt-managed",
      "pvu",
      "rule",
      "lmt",
      "solution",
      "rvu",
      "vmware",
      "per-cpu",
      "vsphere",
      "portable",
      "unit",
      "plu",
      "per-instance",
      "oracle",
      "lms",
      "database",
      "metric",
      "adobe",
      "cc",
      "user-based",
      "red",
      "hat",
      "linux",
      "rhel",
      "virtual",
      "datacenters",
      "broadcom",
      "per-device",
      "autodesk",
      "single",
      "user",
      "subscription",
      "saas",
      "related",
      "topics",
      "section",
      "lists",
      "sam",
      "supports",
      "describes",
      "provides",
      "out",
      "box",
      "consumption",
      "calculation.",
      "ootb",
      "aren",
      "editable.",
      "reuse",
      "create",
      "new",
      "ones"
    ],
    "language": "en",
    "word_count": 104,
    "importance_score": 6.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "supported software titles",
    "contentLower": "this section lists the software titles that sam supports and describes the license rules that sam provides out of the box for license consumption calculation. the ootb license rules aren't editable. you can reuse them or create new ones if necessary. currently, these license rules can only help calculate license consumption per host, ose, and user, but they don't support the software maintenance contracts. the ootb license rules that sam offers include generic license rules and publisher-specific license rules. different license rules might require different parameters. you need to configure the right discovery jobs to collect required software deployment data from ud/ucmdb. generally, if a license rule accepts a parameter that contains information on software installations on a physical device, the relationships between the virtual machine and its underlying physical infrastructure also need to be discovered. for more information, see the prerequisites section. generic this table list",
    "keywordsLower": [
      "8.1",
      "6.5",
      "6.7",
      "https://www.oracle.com/assets/partitioning-070609.pdf",
      "070634.pdf",
      "http://go.microsoft.com/fwlink/?linkid=229882",
      "oracle.com",
      "6.0",
      "7.0",
      "microsoft.com",
      "070609.pdf",
      "https://www.oracle.com/us/solutions/midsize/processor-core-factor-table-070634.pdf",
      "supported",
      "software",
      "titles",
      "generic",
      "publisher-specific",
      "on-premises",
      "microsoft",
      "products",
      "license",
      "rules",
      "licensing",
      "2012",
      "enterprise",
      "edition",
      "core",
      "factor",
      "product",
      "runs",
      "physical",
      "ose",
      "standard",
      "2016",
      "applied",
      "2010",
      "per",
      "processor",
      "datacenter",
      "higher",
      "desktop",
      "applications",
      "server",
      "operating",
      "systems",
      "application-level",
      "clusters",
      "ibm",
      "ilmt-managed",
      "pvu",
      "rule",
      "lmt",
      "solution",
      "rvu",
      "vmware",
      "per-cpu",
      "vsphere",
      "portable",
      "unit",
      "plu",
      "per-instance",
      "oracle",
      "lms",
      "database",
      "metric",
      "adobe",
      "cc",
      "user-based",
      "red",
      "hat",
      "linux",
      "rhel",
      "virtual",
      "datacenters",
      "broadcom",
      "per-device",
      "autodesk",
      "single",
      "user",
      "subscription",
      "saas",
      "related",
      "topics",
      "section",
      "lists",
      "sam",
      "supports",
      "describes",
      "provides",
      "out",
      "box",
      "consumption",
      "calculation.",
      "ootb",
      "aren",
      "editable.",
      "reuse",
      "create",
      "new",
      "ones"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "SAM best practice",
    "content": "This section gives you a best practice of how to use SAM to manage product compliance. Prerequisites SAM calculates license consumption based on the inventory data in UCMDB. Typically, the inventory data includes software CIs, node CIs, and their relationships. Many modern server applications are deployed on virtual machines and are licensed considering the underlying physical infrastructure, usually including information of the physical device, physical processor, and the virtualization technologies used to build the virtual machine. Therefore, the relationships between the virtual machine and its hosted device are also required. To collect sufficient inventory data for license consumption calculation, you need to configure the proper inventory discovery jobs by using the Universal Discovery capability. Note that to leverage the Universal Discovery capability of UD/UCMDB, you must have a UCMDB installation that Service Management supports (see the integration support matrix). Discover",
    "url": "sambestpracticesmax",
    "filename": "sambestpracticesmax",
    "headings": [
      "Prerequisites",
      "(Optional) Deploy sample data",
      "Must-have steps for using SAM",
      "Data flow",
      "Generate a compliance report for on-premises products",
      "Data preparation",
      "Configuration",
      "Calculation",
      "Compliance and analysis",
      "Generate a compliance report for SaaS products",
      "Calculation",
      "Compliance and analysis",
      "CITs and attributes",
      "Related topics"
    ],
    "keywords": [
      "sam",
      "best",
      "practice",
      "prerequisites",
      "optional",
      "deploy",
      "sample",
      "data",
      "must-have",
      "steps",
      "flow",
      "generate",
      "compliance",
      "report",
      "on-premises",
      "products",
      "preparation",
      "configuration",
      "calculation",
      "analysis",
      "saas",
      "cits",
      "attributes",
      "related",
      "topics",
      "section",
      "gives",
      "manage",
      "product",
      "compliance.",
      "calculates",
      "license",
      "consumption",
      "based",
      "inventory",
      "ucmdb.",
      "typically",
      "includes",
      "software",
      "cis",
      "node",
      "relationships.",
      "many",
      "modern",
      "server",
      "applications",
      "deployed",
      "virtual",
      "machines",
      "licensed",
      "considering",
      "underlying",
      "physical",
      "infrastructure",
      "usually",
      "including",
      "information",
      "device",
      "processor",
      "virtualization",
      "technologies",
      "build",
      "machine.",
      "therefore",
      "relationships",
      "between",
      "machine",
      "hosted",
      "required.",
      "collect",
      "sufficient",
      "need",
      "configure",
      "proper",
      "discovery",
      "jobs",
      "universal",
      "capability.",
      "note",
      "leverage",
      "capability",
      "ud",
      "ucmdb",
      "installation",
      "service",
      "management",
      "supports",
      "see",
      "integration",
      "support",
      "matrix",
      "discover",
      "relevant",
      "under",
      "hosts",
      "resources",
      "category.",
      "recognition",
      "critical",
      "ensure"
    ],
    "language": "en",
    "word_count": 94,
    "importance_score": 6.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "sam best practice",
    "contentLower": "this section gives you a best practice of how to use sam to manage product compliance. prerequisites sam calculates license consumption based on the inventory data in ucmdb. typically, the inventory data includes software cis, node cis, and their relationships. many modern server applications are deployed on virtual machines and are licensed considering the underlying physical infrastructure, usually including information of the physical device, physical processor, and the virtualization technologies used to build the virtual machine. therefore, the relationships between the virtual machine and its hosted device are also required. to collect sufficient inventory data for license consumption calculation, you need to configure the proper inventory discovery jobs by using the universal discovery capability. note that to leverage the universal discovery capability of ud/ucmdb, you must have a ucmdb installation that service management supports (see the integration support matrix). discover",
    "keywordsLower": [
      "sam",
      "best",
      "practice",
      "prerequisites",
      "optional",
      "deploy",
      "sample",
      "data",
      "must-have",
      "steps",
      "flow",
      "generate",
      "compliance",
      "report",
      "on-premises",
      "products",
      "preparation",
      "configuration",
      "calculation",
      "analysis",
      "saas",
      "cits",
      "attributes",
      "related",
      "topics",
      "section",
      "gives",
      "manage",
      "product",
      "compliance.",
      "calculates",
      "license",
      "consumption",
      "based",
      "inventory",
      "ucmdb.",
      "typically",
      "includes",
      "software",
      "cis",
      "node",
      "relationships.",
      "many",
      "modern",
      "server",
      "applications",
      "deployed",
      "virtual",
      "machines",
      "licensed",
      "considering",
      "underlying",
      "physical",
      "infrastructure",
      "usually",
      "including",
      "information",
      "device",
      "processor",
      "virtualization",
      "technologies",
      "build",
      "machine.",
      "therefore",
      "relationships",
      "between",
      "machine",
      "hosted",
      "required.",
      "collect",
      "sufficient",
      "need",
      "configure",
      "proper",
      "discovery",
      "jobs",
      "universal",
      "capability.",
      "note",
      "leverage",
      "capability",
      "ud",
      "ucmdb",
      "installation",
      "service",
      "management",
      "supports",
      "see",
      "integration",
      "support",
      "matrix",
      "discover",
      "relevant",
      "under",
      "hosts",
      "resources",
      "category.",
      "recognition",
      "critical",
      "ensure"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Set up SaaS products for license compliance calculation",
    "content": "This page provides the following information about working with SaaS products in SAM: The overall SaaS product configuration process for license compliance calculation Guidelines for configuring integration scenarios for SaaS products that don't have predefined scenario templates Importing data from SaaS products To manage license compliance for SaaS products, you can import relevant data via integrations with SaaS products. SAM supports the following types of data import from SaaS product vendors: License import If the SaaS product provides a \"Get license data\" API, you can use the API and the Local System Create or update license action to import license data into SAM. License consumption import If the SaaS product provides a \"Get license usage data\" API that can return effective license points and license consumption data, you can use the API and the Local System Create license consumption action to import the data into SAM. SAM will then generate a compliance report based on the im",
    "url": "integratesamwithsaasapplications",
    "filename": "integratesamwithsaasapplications",
    "headings": [
      "Importing data from SaaS products",
      "SaaS product configuration process",
      "Prepare an integration user",
      "SaaS product integration scenario configuration guidelines",
      "Scenarios to configure for each SaaS product"
    ],
    "keywords": [
      "set",
      "saas",
      "products",
      "license",
      "compliance",
      "calculation",
      "importing",
      "data",
      "product",
      "configuration",
      "process",
      "prepare",
      "integration",
      "user",
      "scenario",
      "guidelines",
      "scenarios",
      "configure",
      "page",
      "provides",
      "following",
      "information",
      "about",
      "working",
      "sam",
      "overall",
      "configuring",
      "don",
      "predefined",
      "templates",
      "manage",
      "import",
      "relevant",
      "via",
      "integrations",
      "products.",
      "supports",
      "types",
      "vendors",
      "get",
      "api",
      "local",
      "system",
      "create",
      "update",
      "action",
      "sam.",
      "consumption",
      "usage",
      "return",
      "effective",
      "points",
      "generate",
      "report",
      "based",
      "imported",
      "data.",
      "entitlement",
      "optimization",
      "whether",
      "active",
      "service",
      "management",
      "person",
      "record",
      "status",
      "last",
      "login",
      "date.",
      "calculate",
      "retrieved",
      "perform",
      "steps.",
      "step",
      "description",
      "register",
      "application",
      "portal",
      "first",
      "product.",
      "generates",
      "tokens",
      "credentials",
      "endpoint.",
      "see",
      "documentation",
      "vendor.",
      "suite",
      "administration",
      "dedicated",
      "integration.",
      "section",
      "below",
      "procedure.",
      "studio",
      "endpoint",
      "consumption-related",
      "engine",
      "general",
      "including"
    ],
    "language": "en",
    "word_count": 113,
    "importance_score": 4.5,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "set up saas products for license compliance calculation",
    "contentLower": "this page provides the following information about working with saas products in sam: the overall saas product configuration process for license compliance calculation guidelines for configuring integration scenarios for saas products that don't have predefined scenario templates importing data from saas products to manage license compliance for saas products, you can import relevant data via integrations with saas products. sam supports the following types of data import from saas product vendors: license import if the saas product provides a \"get license data\" api, you can use the api and the local system create or update license action to import license data into sam. license consumption import if the saas product provides a \"get license usage data\" api that can return effective license points and license consumption data, you can use the api and the local system create license consumption action to import the data into sam. sam will then generate a compliance report based on the im",
    "keywordsLower": [
      "set",
      "saas",
      "products",
      "license",
      "compliance",
      "calculation",
      "importing",
      "data",
      "product",
      "configuration",
      "process",
      "prepare",
      "integration",
      "user",
      "scenario",
      "guidelines",
      "scenarios",
      "configure",
      "page",
      "provides",
      "following",
      "information",
      "about",
      "working",
      "sam",
      "overall",
      "configuring",
      "don",
      "predefined",
      "templates",
      "manage",
      "import",
      "relevant",
      "via",
      "integrations",
      "products.",
      "supports",
      "types",
      "vendors",
      "get",
      "api",
      "local",
      "system",
      "create",
      "update",
      "action",
      "sam.",
      "consumption",
      "usage",
      "return",
      "effective",
      "points",
      "generate",
      "report",
      "based",
      "imported",
      "data.",
      "entitlement",
      "optimization",
      "whether",
      "active",
      "service",
      "management",
      "person",
      "record",
      "status",
      "last",
      "login",
      "date.",
      "calculate",
      "retrieved",
      "perform",
      "steps.",
      "step",
      "description",
      "register",
      "application",
      "portal",
      "first",
      "product.",
      "generates",
      "tokens",
      "credentials",
      "endpoint.",
      "see",
      "documentation",
      "vendor.",
      "suite",
      "administration",
      "dedicated",
      "integration.",
      "section",
      "below",
      "procedure.",
      "studio",
      "endpoint",
      "consumption-related",
      "engine",
      "general",
      "including"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Set up integration with on-premises products for license compliance calculation",
    "content": "This page provides information about using integration to perform license compliance calculation for on-premises products in SAM: The overall configuration process Guidelines for configuring integration scenarios Importing data via integration To manage license compliance for certain on-premises products, you can import license consumption data via integrations with the products. If the product provides a \"Get license usage data\" API that can return effective license points and license consumption data, you can use the API and the Local System action Create license consumption action to import the data into SAM. SAM will then generate a compliance report based on the imported data. Configuration process To set up the product for license compliance calculation via integrations, perform the following steps. Step Where Description Prepare for  integration N/A As the first step in the integration process, learn the integration details, such as the authentication details, by reading the pro",
    "url": "integratesamithonpremprod",
    "filename": "integratesamithonpremprod",
    "headings": [
      "Importing data via integration",
      "Configuration process",
      "Prepare an integration user",
      "Integration scenario configuration guidelines",
      "Scenario to configure for each product"
    ],
    "keywords": [
      "set",
      "integration",
      "on-premises",
      "products",
      "license",
      "compliance",
      "calculation",
      "importing",
      "data",
      "via",
      "configuration",
      "process",
      "prepare",
      "user",
      "scenario",
      "guidelines",
      "configure",
      "product",
      "page",
      "provides",
      "information",
      "about",
      "perform",
      "sam",
      "overall",
      "configuring",
      "scenarios",
      "manage",
      "certain",
      "import",
      "consumption",
      "integrations",
      "products.",
      "get",
      "usage",
      "api",
      "return",
      "effective",
      "points",
      "local",
      "system",
      "action",
      "create",
      "sam.",
      "generate",
      "report",
      "based",
      "imported",
      "data.",
      "following",
      "steps.",
      "step",
      "description",
      "first",
      "learn",
      "details",
      "such",
      "authentication",
      "reading",
      "vendor",
      "documentation.",
      "required",
      "prerequisite",
      "steps",
      "target",
      "system.",
      "suite",
      "administration",
      "dedicated",
      "integration.",
      "see",
      "section",
      "below.",
      "studio",
      "endpoint",
      "consumption-related",
      "engine",
      "general",
      "procedure.",
      "including",
      "creating",
      "studio-related",
      "endpoints",
      "administrator",
      "role.",
      "note",
      "trigger",
      "sam-related",
      "through",
      "calculate",
      "scheduler",
      "button",
      "because",
      "methods",
      "pass",
      "context",
      "scenarios.",
      "time.",
      "refer",
      "below"
    ],
    "language": "en",
    "word_count": 104,
    "importance_score": 4.5,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "set up integration with on-premises products for license compliance calculation",
    "contentLower": "this page provides information about using integration to perform license compliance calculation for on-premises products in sam: the overall configuration process guidelines for configuring integration scenarios importing data via integration to manage license compliance for certain on-premises products, you can import license consumption data via integrations with the products. if the product provides a \"get license usage data\" api that can return effective license points and license consumption data, you can use the api and the local system action create license consumption action to import the data into sam. sam will then generate a compliance report based on the imported data. configuration process to set up the product for license compliance calculation via integrations, perform the following steps. step where description prepare for  integration n/a as the first step in the integration process, learn the integration details, such as the authentication details, by reading the pro",
    "keywordsLower": [
      "set",
      "integration",
      "on-premises",
      "products",
      "license",
      "compliance",
      "calculation",
      "importing",
      "data",
      "via",
      "configuration",
      "process",
      "prepare",
      "user",
      "scenario",
      "guidelines",
      "configure",
      "product",
      "page",
      "provides",
      "information",
      "about",
      "perform",
      "sam",
      "overall",
      "configuring",
      "scenarios",
      "manage",
      "certain",
      "import",
      "consumption",
      "integrations",
      "products.",
      "get",
      "usage",
      "api",
      "return",
      "effective",
      "points",
      "local",
      "system",
      "action",
      "create",
      "sam.",
      "generate",
      "report",
      "based",
      "imported",
      "data.",
      "following",
      "steps.",
      "step",
      "description",
      "first",
      "learn",
      "details",
      "such",
      "authentication",
      "reading",
      "vendor",
      "documentation.",
      "required",
      "prerequisite",
      "steps",
      "target",
      "system.",
      "suite",
      "administration",
      "dedicated",
      "integration.",
      "see",
      "section",
      "below.",
      "studio",
      "endpoint",
      "consumption-related",
      "engine",
      "general",
      "procedure.",
      "including",
      "creating",
      "studio-related",
      "endpoints",
      "administrator",
      "role.",
      "note",
      "trigger",
      "sam-related",
      "through",
      "calculate",
      "scheduler",
      "button",
      "because",
      "methods",
      "pass",
      "context",
      "scenarios.",
      "time.",
      "refer",
      "below"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "SAM data model",
    "content": "This page describes the SAM data model, which consists of SAM-related record types. Getting familiar with the SAM data model will help you: Create SAM reports in the Service Management report module. Visualize your SAM data by using the Service Management OData service (which includes the SAM data model) as a data source in one of the data visualization tools, such as Power BI. SAM record types The following lists the SAM-related record types. Record type name Display name Description Available in the report module Available in the OData service SoftwarePublisher Software publisher Software publisher X X Product Product Product X X ProductVersion Product version Product version X X LicenseMetric License metric License metric X X OrganizationComplianceScope Organization compliance scope Organization compliance scope X X ProductCompliance Product compliance Product compliance X X ProductVersionCompliance Product version compliance Product version compliance X X LicenseUsage License usage",
    "url": "samdatamodel",
    "filename": "samdatamodel",
    "headings": [
      "SAM record types",
      "View SAM record types in Service Management Studio",
      "SoftwarePublisher (Software Publisher)",
      "Product (Product)",
      "ProductVersion (Product version)",
      "LicenseMetric (License Metric)",
      "OrganizationComplianceScope(Organization compliance scope)",
      "ProductCompliance (Product Compliance)",
      "ProductVersionCompliance (Product Version Compliance)",
      "SamNode (Node)",
      "SamPersonComplianceAnalysis (Person compliance analysis)",
      "SamNodeComplianceAnalysis (Node compliance analysis)",
      "SamLicensePoolLicenseRelation (License pool and license relationship)",
      "SamLicensePool (License summary)",
      "SamNodeAllocatedLicense (Node allocated license)",
      "SamPersonAllocatedLicense (Person allocated license)",
      "SamDiscoveredProduct (Discovered product)",
      "SamSaasUserEntitlement (SaaS user entitlement)",
      "LicenseUsage (License usage)",
      "SAM data models"
    ],
    "keywords": [
      "sam",
      "data",
      "model",
      "record",
      "types",
      "view",
      "service",
      "management",
      "studio",
      "softwarepublisher",
      "software",
      "publisher",
      "product",
      "productversion",
      "version",
      "licensemetric",
      "license",
      "metric",
      "organizationcompliancescope",
      "organization",
      "compliance",
      "scope",
      "productcompliance",
      "productversioncompliance",
      "samnode",
      "node",
      "sampersoncomplianceanalysis",
      "person",
      "analysis",
      "samnodecomplianceanalysis",
      "samlicensepoollicenserelation",
      "pool",
      "relationship",
      "samlicensepool",
      "summary",
      "samnodeallocatedlicense",
      "allocated",
      "sampersonallocatedlicense",
      "samdiscoveredproduct",
      "discovered",
      "samsaasuserentitlement",
      "saas",
      "user",
      "entitlement",
      "licenseusage",
      "usage",
      "models",
      "page",
      "describes",
      "consists",
      "sam-related",
      "types.",
      "getting",
      "familiar",
      "help",
      "create",
      "reports",
      "report",
      "module.",
      "visualize",
      "odata",
      "includes",
      "source",
      "one",
      "visualization",
      "tools",
      "such",
      "power",
      "bi.",
      "following",
      "lists",
      "type",
      "name",
      "display",
      "description",
      "available",
      "module",
      "per",
      "synced",
      "ud",
      "ucmdb",
      "effective",
      "points",
      "consumption",
      "between",
      "detail",
      "products",
      "fields",
      "field",
      "properties",
      "studio.",
      "main",
      "menu",
      "choose",
      "administration",
      "configuration",
      "appears",
      "find",
      "drop-down",
      "list"
    ],
    "language": "en",
    "word_count": 119,
    "importance_score": 6.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "sam data model",
    "contentLower": "this page describes the sam data model, which consists of sam-related record types. getting familiar with the sam data model will help you: create sam reports in the service management report module. visualize your sam data by using the service management odata service (which includes the sam data model) as a data source in one of the data visualization tools, such as power bi. sam record types the following lists the sam-related record types. record type name display name description available in the report module available in the odata service softwarepublisher software publisher software publisher x x product product product x x productversion product version product version x x licensemetric license metric license metric x x organizationcompliancescope organization compliance scope organization compliance scope x x productcompliance product compliance product compliance x x productversioncompliance product version compliance product version compliance x x licenseusage license usage",
    "keywordsLower": [
      "sam",
      "data",
      "model",
      "record",
      "types",
      "view",
      "service",
      "management",
      "studio",
      "softwarepublisher",
      "software",
      "publisher",
      "product",
      "productversion",
      "version",
      "licensemetric",
      "license",
      "metric",
      "organizationcompliancescope",
      "organization",
      "compliance",
      "scope",
      "productcompliance",
      "productversioncompliance",
      "samnode",
      "node",
      "sampersoncomplianceanalysis",
      "person",
      "analysis",
      "samnodecomplianceanalysis",
      "samlicensepoollicenserelation",
      "pool",
      "relationship",
      "samlicensepool",
      "summary",
      "samnodeallocatedlicense",
      "allocated",
      "sampersonallocatedlicense",
      "samdiscoveredproduct",
      "discovered",
      "samsaasuserentitlement",
      "saas",
      "user",
      "entitlement",
      "licenseusage",
      "usage",
      "models",
      "page",
      "describes",
      "consists",
      "sam-related",
      "types.",
      "getting",
      "familiar",
      "help",
      "create",
      "reports",
      "report",
      "module.",
      "visualize",
      "odata",
      "includes",
      "source",
      "one",
      "visualization",
      "tools",
      "such",
      "power",
      "bi.",
      "following",
      "lists",
      "type",
      "name",
      "display",
      "description",
      "available",
      "module",
      "per",
      "synced",
      "ud",
      "ucmdb",
      "effective",
      "points",
      "consumption",
      "between",
      "detail",
      "products",
      "fields",
      "field",
      "properties",
      "studio.",
      "main",
      "menu",
      "choose",
      "administration",
      "configuration",
      "appears",
      "find",
      "drop-down",
      "list"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Run and view net value simulation",
    "content": "Read this topic to learn how to run the net value simulation and how to view the graphical net value trend. How to run net value simulation To run the net value simulation, follow these steps: From the main menu, select Build > Financials > Net Value Simulation. Select the asset type from the following: Devices Infrastructure & Peripheral Licenses Click the Filter button in each asset type to filter the simulation criteria. This narrows down the simulation scope. From Run simulation by, select from the following: DATE: Click the Calendar button to specify a date. The Simulated net value column in the right panel shows the estimated net value of the selected asset on the date that's specified. VALUE: Fill in a value in the Less than field. When the net value is less than the specified value for the first time, the following columns will be displayed in the right panel: Simulated net value: Shows the estimated value of the asset record that meet the criteria for the first time. Simulated",
    "url": "runsimulation",
    "filename": "runsimulation",
    "headings": [
      "How to run net value simulation",
      "How to view net value trend",
      "Related topics"
    ],
    "keywords": [
      "run",
      "view",
      "net",
      "value",
      "simulation",
      "trend",
      "related",
      "topics",
      "read",
      "topic",
      "learn",
      "graphical",
      "trend.",
      "follow",
      "steps",
      "main",
      "menu",
      "select",
      "build",
      "financials",
      "simulation.",
      "asset",
      "type",
      "following",
      "devices",
      "infrastructure",
      "peripheral",
      "licenses",
      "click",
      "filter",
      "button",
      "criteria.",
      "narrows",
      "scope.",
      "date",
      "calendar",
      "specify",
      "date.",
      "simulated",
      "column",
      "right",
      "panel",
      "shows",
      "estimated",
      "selected",
      "specified.",
      "fill",
      "less",
      "field.",
      "specified",
      "first",
      "time",
      "columns",
      "displayed",
      "record",
      "meet",
      "criteria",
      "time.",
      "meets",
      "note",
      "calculated",
      "based",
      "depreciation",
      "rate",
      "asset.",
      "isn",
      "depreciated",
      "period",
      "last",
      "duration",
      "day",
      "column.",
      "all",
      "records",
      "table",
      "panel.",
      "certain",
      "displayed.",
      "pointing",
      "line",
      "predicted",
      "various",
      "dates.",
      "there",
      "fixed",
      "assets",
      "associated",
      "under",
      "well."
    ],
    "language": "en",
    "word_count": 109,
    "importance_score": 3.5,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "run and view net value simulation",
    "contentLower": "read this topic to learn how to run the net value simulation and how to view the graphical net value trend. how to run net value simulation to run the net value simulation, follow these steps: from the main menu, select build > financials > net value simulation. select the asset type from the following: devices infrastructure & peripheral licenses click the filter button in each asset type to filter the simulation criteria. this narrows down the simulation scope. from run simulation by, select from the following: date: click the calendar button to specify a date. the simulated net value column in the right panel shows the estimated net value of the selected asset on the date that's specified. value: fill in a value in the less than field. when the net value is less than the specified value for the first time, the following columns will be displayed in the right panel: simulated net value: shows the estimated value of the asset record that meet the criteria for the first time. simulated",
    "keywordsLower": [
      "run",
      "view",
      "net",
      "value",
      "simulation",
      "trend",
      "related",
      "topics",
      "read",
      "topic",
      "learn",
      "graphical",
      "trend.",
      "follow",
      "steps",
      "main",
      "menu",
      "select",
      "build",
      "financials",
      "simulation.",
      "asset",
      "type",
      "following",
      "devices",
      "infrastructure",
      "peripheral",
      "licenses",
      "click",
      "filter",
      "button",
      "criteria.",
      "narrows",
      "scope.",
      "date",
      "calendar",
      "specify",
      "date.",
      "simulated",
      "column",
      "right",
      "panel",
      "shows",
      "estimated",
      "selected",
      "specified.",
      "fill",
      "less",
      "field.",
      "specified",
      "first",
      "time",
      "columns",
      "displayed",
      "record",
      "meet",
      "criteria",
      "time.",
      "meets",
      "note",
      "calculated",
      "based",
      "depreciation",
      "rate",
      "asset.",
      "isn",
      "depreciated",
      "period",
      "last",
      "duration",
      "day",
      "column.",
      "all",
      "records",
      "table",
      "panel.",
      "certain",
      "displayed.",
      "pointing",
      "line",
      "predicted",
      "various",
      "dates.",
      "there",
      "fixed",
      "assets",
      "associated",
      "under",
      "well."
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Run and monitor flows",
    "content": "The Tenant Admin and the Tenant User are responsible for running and monitoring flows. After deploying the content packs, the Tenant Admin and the Tenant User can run flows and monitor the flow runs. The following topics describe the steps involved in running and monitoring the flows. Overview of running and monitoring a flow Run a flow Track and manage flow runs Adjust the display of flow runs Test and troubleshooting a flow run",
    "url": "runningflows",
    "filename": "runningflows",
    "headings": [],
    "keywords": [
      "run",
      "monitor",
      "flows",
      "tenant",
      "admin",
      "user",
      "responsible",
      "running",
      "monitoring",
      "flows.",
      "after",
      "deploying",
      "content",
      "packs",
      "flow",
      "runs.",
      "following",
      "topics",
      "describe",
      "steps",
      "involved",
      "overview",
      "track",
      "manage",
      "runs",
      "adjust",
      "display",
      "test",
      "troubleshooting"
    ],
    "language": "en",
    "word_count": 50,
    "importance_score": 2.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "run and monitor flows",
    "contentLower": "the tenant admin and the tenant user are responsible for running and monitoring flows. after deploying the content packs, the tenant admin and the tenant user can run flows and monitor the flow runs. the following topics describe the steps involved in running and monitoring the flows. overview of running and monitoring a flow run a flow track and manage flow runs adjust the display of flow runs test and troubleshooting a flow run",
    "keywordsLower": [
      "run",
      "monitor",
      "flows",
      "tenant",
      "admin",
      "user",
      "responsible",
      "running",
      "monitoring",
      "flows.",
      "after",
      "deploying",
      "content",
      "packs",
      "flow",
      "runs.",
      "following",
      "topics",
      "describe",
      "steps",
      "involved",
      "overview",
      "track",
      "manage",
      "runs",
      "adjust",
      "display",
      "test",
      "troubleshooting"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Run a flow",
    "content": "This topic contains details related to running the flow from Operations Orchestration (OO) Central. You can run flows from the following interfaces: From the Run Management workspace using the FLOW LAUNCHER tab From the Content Management workspace using the FLOW LIBRARY tab When running flows on an Internal OO RAS worker, you can: Use the Java and Python based operations with restricted file system access in the following paths: For Java and Jython based operations - /tmp/temp/content-java For Python based operations - /tmp/temp/content-python Run the flows to leverage the following system tools/executables: ping, date, echo, base32, base64, xargs Run a flow from a flow launcher tab In the FLOW LAUNCHER tab in the Run Management workspace, you can select a flow, view its details, prepare it for running, and start the run. User interface elements of the flow launcher tab GUI item Description Filter By To locate the flow that you need, enter part or all the flow path or its ID in the Fi",
    "url": "runooflow",
    "filename": "runooflow",
    "headings": [
      "Run a flow from a flow launcher tab",
      "User interface elements of the flow launcher tab",
      "Run a flow from flow library tab",
      "Run an interactive flow",
      "Run a flow with a Paused - No Workers interaction",
      "Run an AFL flow with non-blocking step",
      "Related topics"
    ],
    "keywords": [
      "run",
      "flow",
      "launcher",
      "tab",
      "user",
      "interface",
      "elements",
      "library",
      "interactive",
      "paused",
      "workers",
      "interaction",
      "afl",
      "non-blocking",
      "step",
      "related",
      "topics",
      "topic",
      "contains",
      "details",
      "running",
      "operations",
      "orchestration",
      "oo",
      "central.",
      "flows",
      "following",
      "interfaces",
      "management",
      "workspace",
      "content",
      "internal",
      "ras",
      "worker",
      "java",
      "python",
      "based",
      "restricted",
      "file",
      "system",
      "access",
      "paths",
      "jython",
      "tmp",
      "temp",
      "content-java",
      "content-python",
      "leverage",
      "tools",
      "executables",
      "ping",
      "date",
      "echo",
      "base32",
      "base64",
      "xargs",
      "select",
      "view",
      "prepare",
      "start",
      "run.",
      "gui",
      "item",
      "description",
      "filter",
      "locate",
      "need",
      "enter",
      "part",
      "all",
      "path",
      "id",
      "text",
      "box",
      "flows.",
      "tree",
      "displays",
      "permission",
      "view.",
      "expand",
      "collapse",
      "nodes",
      "see",
      "different",
      "folders.",
      "pane",
      "information",
      "about",
      "selected",
      "flow.",
      "open",
      "graph",
      "click",
      "button",
      "display",
      "graphical",
      "representation",
      "uuid",
      "pack",
      "came"
    ],
    "language": "en",
    "word_count": 109,
    "importance_score": 6.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "run a flow",
    "contentLower": "this topic contains details related to running the flow from operations orchestration (oo) central. you can run flows from the following interfaces: from the run management workspace using the flow launcher tab from the content management workspace using the flow library tab when running flows on an internal oo ras worker, you can: use the java and python based operations with restricted file system access in the following paths: for java and jython based operations - /tmp/temp/content-java for python based operations - /tmp/temp/content-python run the flows to leverage the following system tools/executables: ping, date, echo, base32, base64, xargs run a flow from a flow launcher tab in the flow launcher tab in the run management workspace, you can select a flow, view its details, prepare it for running, and start the run. user interface elements of the flow launcher tab gui item description filter by to locate the flow that you need, enter part or all the flow path or its id in the fi",
    "keywordsLower": [
      "run",
      "flow",
      "launcher",
      "tab",
      "user",
      "interface",
      "elements",
      "library",
      "interactive",
      "paused",
      "workers",
      "interaction",
      "afl",
      "non-blocking",
      "step",
      "related",
      "topics",
      "topic",
      "contains",
      "details",
      "running",
      "operations",
      "orchestration",
      "oo",
      "central.",
      "flows",
      "following",
      "interfaces",
      "management",
      "workspace",
      "content",
      "internal",
      "ras",
      "worker",
      "java",
      "python",
      "based",
      "restricted",
      "file",
      "system",
      "access",
      "paths",
      "jython",
      "tmp",
      "temp",
      "content-java",
      "content-python",
      "leverage",
      "tools",
      "executables",
      "ping",
      "date",
      "echo",
      "base32",
      "base64",
      "xargs",
      "select",
      "view",
      "prepare",
      "start",
      "run.",
      "gui",
      "item",
      "description",
      "filter",
      "locate",
      "need",
      "enter",
      "part",
      "all",
      "path",
      "id",
      "text",
      "box",
      "flows.",
      "tree",
      "displays",
      "permission",
      "view.",
      "expand",
      "collapse",
      "nodes",
      "see",
      "different",
      "folders.",
      "pane",
      "information",
      "about",
      "selected",
      "flow.",
      "open",
      "graph",
      "click",
      "button",
      "display",
      "graphical",
      "representation",
      "uuid",
      "pack",
      "came"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Track and manage flow runs",
    "content": "This topic gives details on how you can use the RUN EXPLORER tab to track and monitor the progress of a flow(s). You can perform the following actions on the flow(s) from the RUN EXPLORER tab: View the basic details of the completed flow(s) View the advanced details about the flow(s) Pause the running flow(s) Resume the paused flow(s) Reassign the paused flow(s) to another user Cancel the running flow(s) Select the flow(s) Refresh the flow(s) The display of runs depends on the content permissions granted for your role. You can view only those runs of flows that you have permission for. The RUN EXPLORER gets auto refreshed. The view gets updated whenever a new run starts or when the run has its status, duration, or user updated. If you are unable to locate a flow run, you can use the filter capabilities of the RUN EXPLORER to find the flow run that you need. View basic details about a flow run Click Run Management to display the workspace. Click the RUN EXPLORER tab. View the basic deta",
    "url": "trackmanageooflowruns",
    "filename": "trackmanageooflowruns",
    "headings": [
      "View basic details about a flow run",
      "Display advanced details about a flow run",
      "Pause a flow run",
      "Resume the paused flow run.",
      "Cancel a flow run",
      "Select multiple runs",
      "Reassign ownership of a flow run",
      "Refresh the flow runs",
      "Related topics"
    ],
    "keywords": [
      "track",
      "manage",
      "flow",
      "runs",
      "view",
      "basic",
      "details",
      "about",
      "run",
      "display",
      "advanced",
      "pause",
      "resume",
      "paused",
      "run.",
      "cancel",
      "select",
      "multiple",
      "reassign",
      "ownership",
      "refresh",
      "related",
      "topics",
      "topic",
      "gives",
      "explorer",
      "tab",
      "monitor",
      "progress",
      "perform",
      "following",
      "actions",
      "completed",
      "running",
      "another",
      "user",
      "depends",
      "content",
      "permissions",
      "granted",
      "role.",
      "flows",
      "permission",
      "for.",
      "gets",
      "auto",
      "refreshed.",
      "updated",
      "whenever",
      "new",
      "starts",
      "status",
      "duration",
      "updated.",
      "unable",
      "locate",
      "filter",
      "capabilities",
      "find",
      "need.",
      "click",
      "management",
      "workspace.",
      "tab.",
      "tabular",
      "form",
      "such",
      "information",
      "users.",
      "custom",
      "name",
      "provided",
      "instead",
      "default",
      "name.",
      "want",
      "look",
      "detail.",
      "drill",
      "button",
      "end",
      "row",
      "selected",
      "additionally",
      "double-click",
      "see",
      "information.",
      "displays",
      "table.",
      "one",
      "currently",
      "running.",
      "toolbar.",
      "changes",
      "pending",
      "paused.",
      "available",
      "all",
      "note",
      "get"
    ],
    "language": "en",
    "word_count": 118,
    "importance_score": 6.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "track and manage flow runs",
    "contentLower": "this topic gives details on how you can use the run explorer tab to track and monitor the progress of a flow(s). you can perform the following actions on the flow(s) from the run explorer tab: view the basic details of the completed flow(s) view the advanced details about the flow(s) pause the running flow(s) resume the paused flow(s) reassign the paused flow(s) to another user cancel the running flow(s) select the flow(s) refresh the flow(s) the display of runs depends on the content permissions granted for your role. you can view only those runs of flows that you have permission for. the run explorer gets auto refreshed. the view gets updated whenever a new run starts or when the run has its status, duration, or user updated. if you are unable to locate a flow run, you can use the filter capabilities of the run explorer to find the flow run that you need. view basic details about a flow run click run management to display the workspace. click the run explorer tab. view the basic deta",
    "keywordsLower": [
      "track",
      "manage",
      "flow",
      "runs",
      "view",
      "basic",
      "details",
      "about",
      "run",
      "display",
      "advanced",
      "pause",
      "resume",
      "paused",
      "run.",
      "cancel",
      "select",
      "multiple",
      "reassign",
      "ownership",
      "refresh",
      "related",
      "topics",
      "topic",
      "gives",
      "explorer",
      "tab",
      "monitor",
      "progress",
      "perform",
      "following",
      "actions",
      "completed",
      "running",
      "another",
      "user",
      "depends",
      "content",
      "permissions",
      "granted",
      "role.",
      "flows",
      "permission",
      "for.",
      "gets",
      "auto",
      "refreshed.",
      "updated",
      "whenever",
      "new",
      "starts",
      "status",
      "duration",
      "updated.",
      "unable",
      "locate",
      "filter",
      "capabilities",
      "find",
      "need.",
      "click",
      "management",
      "workspace.",
      "tab.",
      "tabular",
      "form",
      "such",
      "information",
      "users.",
      "custom",
      "name",
      "provided",
      "instead",
      "default",
      "name.",
      "want",
      "look",
      "detail.",
      "drill",
      "button",
      "end",
      "row",
      "selected",
      "additionally",
      "double-click",
      "see",
      "information.",
      "displays",
      "table.",
      "one",
      "currently",
      "running.",
      "toolbar.",
      "changes",
      "pending",
      "paused.",
      "available",
      "all",
      "note",
      "get"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Test and troubleshoot a flow run",
    "content": "After you have triggered a flow run, you can drill down into the run and investigate its progress in detail. This is particularly helpful if a flow run fails. When you click Drill down at the end of a row in the RUN EXPLORER, detailed information about the selected run display. You can also double-click a row to drill down to see this information. To the left, the Run Tree displays the steps in the run and the transition messages. The Run Tree highlights the currently running step and displays information about the progress of the run. If a flow fails, you will see at which step the failure occurred. The steps and transition messages are automatically refreshed as the run progresses. There are a number of collapsible views that you can use to display different kinds of information: Information about the flow—Flow ID, flow name, path, description, flow inputs, and flow outputs. Click the Down arrow in the center of the RUN EXPLORER drill down view toolbar. Information about a selected s",
    "url": "testtroubleshootooflowrun",
    "filename": "testtroubleshootooflowrun",
    "headings": [
      "User interface elements",
      "Run Tree",
      "Run Info > Step Details tab (Detailed Step Persistence)",
      "Run Info > Flow Graph tab",
      "Run Log",
      "Run Log > Find dialog box",
      "Flow Information",
      "Display details about the steps in a flow run",
      "Display the graph of a flow run",
      "Display the Run Log with details of the entire run",
      "Find a step in the Run Log",
      "Toggle between viewing a step in the Run Tree and Flow Graph and in the Run Log",
      "Collapse the run tree",
      "Adjust the width of the Run info pane",
      "Display details about the flow",
      "Export the Run Log as a text file",
      "Export the Run Log as a CSV file",
      "Related topics"
    ],
    "keywords": [
      "http://superuser.com/questions/280603/how-to-set-character-encoding-when-opening-excel",
      "1.5",
      "superuser.com",
      "test",
      "troubleshoot",
      "flow",
      "run",
      "user",
      "interface",
      "elements",
      "tree",
      "info",
      "step",
      "details",
      "tab",
      "detailed",
      "persistence",
      "graph",
      "log",
      "find",
      "dialog",
      "box",
      "information",
      "display",
      "about",
      "steps",
      "entire",
      "toggle",
      "between",
      "viewing",
      "collapse",
      "adjust",
      "width",
      "pane",
      "export",
      "text",
      "file",
      "csv",
      "related",
      "topics",
      "after",
      "triggered",
      "drill",
      "investigate",
      "progress",
      "detail.",
      "particularly",
      "helpful",
      "fails.",
      "click",
      "end",
      "row",
      "explorer",
      "selected",
      "display.",
      "double-click",
      "see",
      "information.",
      "left",
      "displays",
      "transition",
      "messages.",
      "highlights",
      "currently",
      "running",
      "run.",
      "fails",
      "failure",
      "occurred.",
      "messages",
      "automatically",
      "refreshed",
      "progresses.",
      "there",
      "number",
      "collapsible",
      "views",
      "different",
      "kinds",
      "id",
      "name",
      "path",
      "description",
      "inputs",
      "outputs.",
      "arrow",
      "center",
      "view",
      "toolbar.",
      "start",
      "time",
      "result",
      "duration",
      "results",
      "worker",
      "group",
      "executed",
      "more.",
      "tab.",
      "running."
    ],
    "language": "en",
    "word_count": 100,
    "importance_score": 5.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "test and troubleshoot a flow run",
    "contentLower": "after you have triggered a flow run, you can drill down into the run and investigate its progress in detail. this is particularly helpful if a flow run fails. when you click drill down at the end of a row in the run explorer, detailed information about the selected run display. you can also double-click a row to drill down to see this information. to the left, the run tree displays the steps in the run and the transition messages. the run tree highlights the currently running step and displays information about the progress of the run. if a flow fails, you will see at which step the failure occurred. the steps and transition messages are automatically refreshed as the run progresses. there are a number of collapsible views that you can use to display different kinds of information: information about the flow—flow id, flow name, path, description, flow inputs, and flow outputs. click the down arrow in the center of the run explorer drill down view toolbar. information about a selected s",
    "keywordsLower": [
      "http://superuser.com/questions/280603/how-to-set-character-encoding-when-opening-excel",
      "1.5",
      "superuser.com",
      "test",
      "troubleshoot",
      "flow",
      "run",
      "user",
      "interface",
      "elements",
      "tree",
      "info",
      "step",
      "details",
      "tab",
      "detailed",
      "persistence",
      "graph",
      "log",
      "find",
      "dialog",
      "box",
      "information",
      "display",
      "about",
      "steps",
      "entire",
      "toggle",
      "between",
      "viewing",
      "collapse",
      "adjust",
      "width",
      "pane",
      "export",
      "text",
      "file",
      "csv",
      "related",
      "topics",
      "after",
      "triggered",
      "drill",
      "investigate",
      "progress",
      "detail.",
      "particularly",
      "helpful",
      "fails.",
      "click",
      "end",
      "row",
      "explorer",
      "selected",
      "display.",
      "double-click",
      "see",
      "information.",
      "left",
      "displays",
      "transition",
      "messages.",
      "highlights",
      "currently",
      "running",
      "run.",
      "fails",
      "failure",
      "occurred.",
      "messages",
      "automatically",
      "refreshed",
      "progresses.",
      "there",
      "number",
      "collapsible",
      "views",
      "different",
      "kinds",
      "id",
      "name",
      "path",
      "description",
      "inputs",
      "outputs.",
      "arrow",
      "center",
      "view",
      "toolbar.",
      "start",
      "time",
      "result",
      "duration",
      "results",
      "worker",
      "group",
      "executed",
      "more.",
      "tab.",
      "running."
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Set up configuration items for a content pack",
    "content": "After deploying a content pack to the Operations Orchestration Central (OO Central) server, the user with the permission oo_cpManage may need to configure the content of this content pack to adjust it to the environment. This includes setting up the: System accounts - Often, content packs come with system accounts configured. For example, if you are deploying a content pack for an Oracle database, it will include Oracle user accounts. You will need to create Central user names and map them to the system accounts in the content pack. System properties - Often, content packs come with system properties configured. You may want to override these properties in OO Central. In the OO Central UI, you can edit system accounts and system properties that are in a content pack created using the OO Workflow Designer and OO Studio. Group aliases - If the content pack includes operations that are assigned to group aliases, rather than actual worker groups, you will need to map these group aliases to",
    "url": "setupooconfigitems",
    "filename": "setupooconfigitems",
    "headings": [
      "Assigning permissions to system account and system properties",
      "View information about configuration items",
      "Display configuration items in a content pack",
      "Add configuration items to a content pack",
      "Edit a system account in a content pack",
      "Edit permissions for a system account folder",
      "Edit a system property in a content pack",
      "Assign a worker group to a worker group alias",
      "Revert configuration items to their original value",
      "Delete configuration items in a content pack",
      "Reference material",
      "Configuration Items tree",
      "Edit System Account dialog box",
      "Edit System Account dialog box - Folder",
      "System Property Details dialog box",
      "Group Alias Details dialog box",
      "Related topics"
    ],
    "keywords": [
      "set",
      "configuration",
      "items",
      "content",
      "pack",
      "assigning",
      "permissions",
      "system",
      "account",
      "properties",
      "view",
      "information",
      "about",
      "display",
      "add",
      "edit",
      "folder",
      "property",
      "assign",
      "worker",
      "group",
      "alias",
      "revert",
      "original",
      "value",
      "delete",
      "reference",
      "material",
      "tree",
      "dialog",
      "box",
      "details",
      "related",
      "topics",
      "after",
      "deploying",
      "operations",
      "orchestration",
      "central",
      "oo",
      "server",
      "user",
      "permission",
      "need",
      "configure",
      "adjust",
      "environment.",
      "includes",
      "setting",
      "accounts",
      "often",
      "packs",
      "come",
      "configured.",
      "example",
      "oracle",
      "database",
      "include",
      "accounts.",
      "create",
      "names",
      "map",
      "pack.",
      "want",
      "override",
      "central.",
      "ui",
      "created",
      "workflow",
      "designer",
      "studio.",
      "aliases",
      "assigned",
      "rather",
      "actual",
      "groups",
      "groups.",
      "name",
      "same",
      "mapped",
      "automatically",
      "default.",
      "access",
      "click",
      "management",
      "tab.",
      "tab",
      "visible",
      "role",
      "manage",
      "permission.",
      "able",
      "control",
      "flow.",
      "feature",
      "useful",
      "flows",
      "multiple",
      "departments",
      "hide"
    ],
    "language": "en",
    "word_count": 103,
    "importance_score": 5.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "set up configuration items for a content pack",
    "contentLower": "after deploying a content pack to the operations orchestration central (oo central) server, the user with the permission oo_cpmanage may need to configure the content of this content pack to adjust it to the environment. this includes setting up the: system accounts - often, content packs come with system accounts configured. for example, if you are deploying a content pack for an oracle database, it will include oracle user accounts. you will need to create central user names and map them to the system accounts in the content pack. system properties - often, content packs come with system properties configured. you may want to override these properties in oo central. in the oo central ui, you can edit system accounts and system properties that are in a content pack created using the oo workflow designer and oo studio. group aliases - if the content pack includes operations that are assigned to group aliases, rather than actual worker groups, you will need to map these group aliases to",
    "keywordsLower": [
      "set",
      "configuration",
      "items",
      "content",
      "pack",
      "assigning",
      "permissions",
      "system",
      "account",
      "properties",
      "view",
      "information",
      "about",
      "display",
      "add",
      "edit",
      "folder",
      "property",
      "assign",
      "worker",
      "group",
      "alias",
      "revert",
      "original",
      "value",
      "delete",
      "reference",
      "material",
      "tree",
      "dialog",
      "box",
      "details",
      "related",
      "topics",
      "after",
      "deploying",
      "operations",
      "orchestration",
      "central",
      "oo",
      "server",
      "user",
      "permission",
      "need",
      "configure",
      "adjust",
      "environment.",
      "includes",
      "setting",
      "accounts",
      "often",
      "packs",
      "come",
      "configured.",
      "example",
      "oracle",
      "database",
      "include",
      "accounts.",
      "create",
      "names",
      "map",
      "pack.",
      "want",
      "override",
      "central.",
      "ui",
      "created",
      "workflow",
      "designer",
      "studio.",
      "aliases",
      "assigned",
      "rather",
      "actual",
      "groups",
      "groups.",
      "name",
      "same",
      "mapped",
      "automatically",
      "default.",
      "access",
      "click",
      "management",
      "tab.",
      "tab",
      "visible",
      "role",
      "manage",
      "permission.",
      "able",
      "control",
      "flow.",
      "feature",
      "useful",
      "flows",
      "multiple",
      "departments",
      "hide"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Service instance management",
    "content": "A subscription originates with a subscription request, initiated by the subscriber (end user)  in the Service Portal. After a subscription request is approved, a service instance is created. A service instance is also created when performing a test deployment from the DEPLOYMENTS tab for a service design. The test deployments and subscriptions listed in the DEPLOYMENTS tab contain a link to launch the service instance detail page of Deployment Operations. You can view the tree of all the components that are part of the deployed instance. To view the summary and details of service instances, go to Run > Deployment Operations > Instance Management. The service instances are listed by Instances, Design, or Users. By default, the instances are listed By Instance. Select the By Design option to view the list of instances deployed for a design. The Designs panel will display the name and version of the design. You can use the Search box to search for designs based on the design name or versi",
    "url": "mgmtconssoinstancemanagement",
    "filename": "mgmtconssoinstancemanagement",
    "headings": [
      "Summary",
      "Service Instances",
      "Service Instance details",
      "Component details",
      "Provider details",
      "Log details",
      "Resume, reset, or fail the service instance paused due to an error in an action",
      "Resume or fail an instance paused during provisioning due to an error in an action",
      "Resume, reset, or fail an instance paused during modification due to an error in an action",
      "Resume an instance paused during cancellation due to an error in an action",
      "Resume, reset, or fail the service instance paused on successful completion of an action",
      "Resume or fail an instance paused during provisioning on successful completion of an action",
      "Resume, reset or fail an instance paused during modification on successful completion of an action",
      "Resume an instance paused during cancellation on successful completion of an action",
      "Resume a paused service instance using an API"
    ],
    "keywords": [
      "https://myHost.myLab.net/dnd-operations-gateway/#/instance/2c90849e787b42d901787b790e4a6638/components",
      "https://<hostname>/<tenantId>/dnd/api/service/instance/<instanceId>/resume",
      "myLab.net",
      "https://<hostname>/dnd-operations-gateway/#/instance/<instanceId>/components",
      "service",
      "instance",
      "management",
      "summary",
      "instances",
      "details",
      "component",
      "provider",
      "log",
      "resume",
      "reset",
      "fail",
      "paused",
      "due",
      "error",
      "action",
      "during",
      "provisioning",
      "modification",
      "cancellation",
      "successful",
      "completion",
      "api",
      "subscription",
      "originates",
      "request",
      "initiated",
      "subscriber",
      "end",
      "user",
      "portal.",
      "after",
      "approved",
      "created.",
      "created",
      "performing",
      "test",
      "deployment",
      "deployments",
      "tab",
      "design.",
      "subscriptions",
      "listed",
      "contain",
      "link",
      "launch",
      "detail",
      "page",
      "operations.",
      "view",
      "tree",
      "all",
      "components",
      "part",
      "deployed",
      "instance.",
      "go",
      "run",
      "operations",
      "management.",
      "design",
      "users.",
      "default",
      "select",
      "option",
      "list",
      "designs",
      "panel",
      "display",
      "name",
      "version",
      "search",
      "box",
      "based",
      "version.",
      "it.",
      "users",
      "owned",
      "user.",
      "email",
      "id",
      "username.",
      "address",
      "isn",
      "supported.",
      "available",
      "top",
      "name.",
      "multiple",
      "keywords.",
      "provides",
      "following",
      "charts",
      "number",
      "active",
      "progress"
    ],
    "language": "en",
    "word_count": 95,
    "importance_score": 6.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "service instance management",
    "contentLower": "a subscription originates with a subscription request, initiated by the subscriber (end user)  in the service portal. after a subscription request is approved, a service instance is created. a service instance is also created when performing a test deployment from the deployments tab for a service design. the test deployments and subscriptions listed in the deployments tab contain a link to launch the service instance detail page of deployment operations. you can view the tree of all the components that are part of the deployed instance. to view the summary and details of service instances, go to run > deployment operations > instance management. the service instances are listed by instances, design, or users. by default, the instances are listed by instance. select the by design option to view the list of instances deployed for a design. the designs panel will display the name and version of the design. you can use the search box to search for designs based on the design name or versi",
    "keywordsLower": [
      "https://myhost.mylab.net/dnd-operations-gateway/#/instance/2c90849e787b42d901787b790e4a6638/components",
      "https://<hostname>/<tenantid>/dnd/api/service/instance/<instanceid>/resume",
      "mylab.net",
      "https://<hostname>/dnd-operations-gateway/#/instance/<instanceid>/components",
      "service",
      "instance",
      "management",
      "summary",
      "instances",
      "details",
      "component",
      "provider",
      "log",
      "resume",
      "reset",
      "fail",
      "paused",
      "due",
      "error",
      "action",
      "during",
      "provisioning",
      "modification",
      "cancellation",
      "successful",
      "completion",
      "api",
      "subscription",
      "originates",
      "request",
      "initiated",
      "subscriber",
      "end",
      "user",
      "portal.",
      "after",
      "approved",
      "created.",
      "created",
      "performing",
      "test",
      "deployment",
      "deployments",
      "tab",
      "design.",
      "subscriptions",
      "listed",
      "contain",
      "link",
      "launch",
      "detail",
      "page",
      "operations.",
      "view",
      "tree",
      "all",
      "components",
      "part",
      "deployed",
      "instance.",
      "go",
      "run",
      "operations",
      "management.",
      "design",
      "users.",
      "default",
      "select",
      "option",
      "list",
      "designs",
      "panel",
      "display",
      "name",
      "version",
      "search",
      "box",
      "based",
      "version.",
      "it.",
      "users",
      "owned",
      "user.",
      "email",
      "id",
      "username.",
      "address",
      "isn",
      "supported.",
      "available",
      "top",
      "name.",
      "multiple",
      "keywords.",
      "provides",
      "following",
      "charts",
      "number",
      "active",
      "progress"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Service Designer",
    "content": "Log in to Service Management Portal and from the main menu, select Build > Design to go to Service Designer. Service Designer will list the service design tags, a list of all service designs, and up to five version numbers for each service design. View a list of service design tags in the left pane of the All Designs area. Click a tag to view the list of service designs and versions associated with the selected tag. Use the following icons and features to navigate and perform tasks in the Design area: Item Description Search box Enter text to filter the results based on a keyword search of display name, description, and version. Click the gear icon to select any of the following actions: Create Design — Add a new design. For more information about configuration options, see the topic on Add a service design. Import Design — Import a service design. For more information, see the topic on Import and export a service design. Manage Design Tags — Manage tags. For more information, see the ",
    "url": "mgmtconssdviewall",
    "filename": "mgmtconssdviewall",
    "headings": [
      "Related topics"
    ],
    "keywords": [
      "service",
      "designer",
      "related",
      "topics",
      "log",
      "management",
      "portal",
      "main",
      "menu",
      "select",
      "build",
      "design",
      "go",
      "designer.",
      "list",
      "tags",
      "all",
      "designs",
      "five",
      "version",
      "numbers",
      "design.",
      "view",
      "left",
      "pane",
      "area.",
      "click",
      "tag",
      "versions",
      "associated",
      "selected",
      "tag.",
      "following",
      "icons",
      "features",
      "navigate",
      "perform",
      "tasks",
      "area",
      "item",
      "description",
      "search",
      "box",
      "enter",
      "text",
      "filter",
      "results",
      "based",
      "keyword",
      "display",
      "name",
      "version.",
      "gear",
      "icon",
      "any",
      "actions",
      "create",
      "add",
      "new",
      "information",
      "about",
      "configuration",
      "options",
      "see",
      "topic",
      "import",
      "export",
      "manage",
      "tags.",
      "refresh",
      "data",
      "view.",
      "overview",
      "tab",
      "task",
      "versions.",
      "number",
      "names",
      "latest",
      "sorted",
      "creation",
      "date.",
      "links",
      "page.",
      "details",
      "layout",
      "there",
      "link",
      "open",
      "page",
      "displays",
      "complete",
      "existing",
      "sequenced",
      "options."
    ],
    "language": "en",
    "word_count": 112,
    "importance_score": 3.5,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "service designer",
    "contentLower": "log in to service management portal and from the main menu, select build > design to go to service designer. service designer will list the service design tags, a list of all service designs, and up to five version numbers for each service design. view a list of service design tags in the left pane of the all designs area. click a tag to view the list of service designs and versions associated with the selected tag. use the following icons and features to navigate and perform tasks in the design area: item description search box enter text to filter the results based on a keyword search of display name, description, and version. click the gear icon to select any of the following actions: create design — add a new design. for more information about configuration options, see the topic on add a service design. import design — import a service design. for more information, see the topic on import and export a service design. manage design tags — manage tags. for more information, see the ",
    "keywordsLower": [
      "service",
      "designer",
      "related",
      "topics",
      "log",
      "management",
      "portal",
      "main",
      "menu",
      "select",
      "build",
      "design",
      "go",
      "designer.",
      "list",
      "tags",
      "all",
      "designs",
      "five",
      "version",
      "numbers",
      "design.",
      "view",
      "left",
      "pane",
      "area.",
      "click",
      "tag",
      "versions",
      "associated",
      "selected",
      "tag.",
      "following",
      "icons",
      "features",
      "navigate",
      "perform",
      "tasks",
      "area",
      "item",
      "description",
      "search",
      "box",
      "enter",
      "text",
      "filter",
      "results",
      "based",
      "keyword",
      "display",
      "name",
      "version.",
      "gear",
      "icon",
      "any",
      "actions",
      "create",
      "add",
      "new",
      "information",
      "about",
      "configuration",
      "options",
      "see",
      "topic",
      "import",
      "export",
      "manage",
      "tags.",
      "refresh",
      "data",
      "view.",
      "overview",
      "tab",
      "task",
      "versions.",
      "number",
      "names",
      "latest",
      "sorted",
      "creation",
      "date.",
      "links",
      "page.",
      "details",
      "layout",
      "there",
      "link",
      "open",
      "page",
      "displays",
      "complete",
      "existing",
      "sequenced",
      "options."
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Service Design overview",
    "content": "Select a service design to view details of a single specific service design. The Overview tab provides a summary of the design, and the Versions tab provides a summary of the design versions. View design overview — In the Overview tab of the service design page, you can see the display name, description, and tags for the design. View versions — In the Versions tab of the service design page, you can view the design version, description, and creation date. You will also see labels for published designs. Create new version — On the service design page, click the gear icon and select Create New Version to create a new version of the design. For descriptions of the specific properties, see the topic on Design versions. Edit a design — Click the gear icon and select Edit to modify the display name, description, image, or tags of the design. For descriptions of the specific properties, see the topic on Create a service design. Delete a design — Click the gear icon and select Delete to delete",
    "url": "mgmtconssdview",
    "filename": "mgmtconssdview",
    "headings": [
      "View design version overview",
      "Design version tasks",
      "Tasks"
    ],
    "keywords": [
      "service",
      "design",
      "overview",
      "view",
      "version",
      "tasks",
      "select",
      "details",
      "single",
      "specific",
      "design.",
      "tab",
      "provides",
      "summary",
      "versions",
      "versions.",
      "page",
      "see",
      "display",
      "name",
      "description",
      "tags",
      "creation",
      "date.",
      "labels",
      "published",
      "designs.",
      "create",
      "new",
      "click",
      "gear",
      "icon",
      "descriptions",
      "properties",
      "topic",
      "edit",
      "modify",
      "image",
      "delete",
      "deleted",
      "exist.",
      "following",
      "information",
      "about",
      "displayed",
      "item",
      "name.",
      "description.",
      "preview",
      "hierarchy.",
      "clicking",
      "opens",
      "larger",
      "separate",
      "dialog.",
      "any",
      "changes",
      "made",
      "dialog",
      "aren",
      "saved",
      "don",
      "affect",
      "appears",
      "sequenced",
      "designer.",
      "version.",
      "url",
      "optional",
      "contain",
      "indicates",
      "displays",
      "upper",
      "left.",
      "label",
      "right.",
      "visible",
      "available",
      "selection",
      "basis",
      "offering",
      "offerings",
      "area.",
      "fields.",
      "publish",
      "unpublish",
      "currently",
      "offering.",
      "modified.",
      "however",
      "save",
      "editable",
      "designs",
      "based",
      "created",
      "it.",
      "unpublished.",
      "after",
      "upgrade",
      "try"
    ],
    "language": "en",
    "word_count": 108,
    "importance_score": 4.5,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "service design overview",
    "contentLower": "select a service design to view details of a single specific service design. the overview tab provides a summary of the design, and the versions tab provides a summary of the design versions. view design overview — in the overview tab of the service design page, you can see the display name, description, and tags for the design. view versions — in the versions tab of the service design page, you can view the design version, description, and creation date. you will also see labels for published designs. create new version — on the service design page, click the gear icon and select create new version to create a new version of the design. for descriptions of the specific properties, see the topic on design versions. edit a design — click the gear icon and select edit to modify the display name, description, image, or tags of the design. for descriptions of the specific properties, see the topic on create a service design. delete a design — click the gear icon and select delete to delete",
    "keywordsLower": [
      "service",
      "design",
      "overview",
      "view",
      "version",
      "tasks",
      "select",
      "details",
      "single",
      "specific",
      "design.",
      "tab",
      "provides",
      "summary",
      "versions",
      "versions.",
      "page",
      "see",
      "display",
      "name",
      "description",
      "tags",
      "creation",
      "date.",
      "labels",
      "published",
      "designs.",
      "create",
      "new",
      "click",
      "gear",
      "icon",
      "descriptions",
      "properties",
      "topic",
      "edit",
      "modify",
      "image",
      "delete",
      "deleted",
      "exist.",
      "following",
      "information",
      "about",
      "displayed",
      "item",
      "name.",
      "description.",
      "preview",
      "hierarchy.",
      "clicking",
      "opens",
      "larger",
      "separate",
      "dialog.",
      "any",
      "changes",
      "made",
      "dialog",
      "aren",
      "saved",
      "don",
      "affect",
      "appears",
      "sequenced",
      "designer.",
      "version.",
      "url",
      "optional",
      "contain",
      "indicates",
      "displays",
      "upper",
      "left.",
      "label",
      "right.",
      "visible",
      "available",
      "selection",
      "basis",
      "offering",
      "offerings",
      "area.",
      "fields.",
      "publish",
      "unpublish",
      "currently",
      "offering.",
      "modified.",
      "however",
      "save",
      "editable",
      "designs",
      "based",
      "created",
      "it.",
      "unpublished.",
      "after",
      "upgrade",
      "try"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Sequenced design configuration options",
    "content": "The Configuration Options tab allows you to create sets of options for service design. Select a version of the design to view the Configurations Options tab. Option sets are made available in the Offerings area, where they can be further refined by setting pricing for options, hiding options, and setting values for option properties. Configuration options are then exposed to subscribers in the Service Portal. These options allow the user to select values that customize the service offering for their personal needs. For example, you can create an option set called Number of Servers, which is configured as follows: The option set has three options, Small, Medium, and Large. Each option has a property called NSERVERS. Each option has a unique, specified value for NSERVERS, either Small (2 servers), Medium (4 servers), or Large (8 servers). A binding is created from the NSERVERS property to a corresponding NSERVERS property on a Server Group service component. This use of a configuration o",
    "url": "mgmtconssdsubsoptionabt",
    "filename": "mgmtconssdsubsoptionabt",
    "headings": [
      "Configuration options workflow",
      "Related topics"
    ],
    "keywords": [
      "sequenced",
      "design",
      "configuration",
      "options",
      "workflow",
      "related",
      "topics",
      "tab",
      "allows",
      "create",
      "sets",
      "service",
      "design.",
      "select",
      "version",
      "view",
      "configurations",
      "tab.",
      "option",
      "made",
      "available",
      "offerings",
      "area",
      "further",
      "refined",
      "setting",
      "pricing",
      "hiding",
      "values",
      "properties.",
      "exposed",
      "subscribers",
      "portal.",
      "allow",
      "user",
      "customize",
      "offering",
      "personal",
      "needs.",
      "example",
      "set",
      "called",
      "number",
      "servers",
      "configured",
      "follows",
      "three",
      "small",
      "medium",
      "large.",
      "property",
      "nservers.",
      "unique",
      "specified",
      "value",
      "nservers",
      "either",
      "large",
      "binding",
      "created",
      "corresponding",
      "server",
      "group",
      "component.",
      "push",
      "component",
      "target",
      "described",
      "below.",
      "portal",
      "provides",
      "desired",
      "servers.",
      "best",
      "practice",
      "copy",
      "paste",
      "set.",
      "keep",
      "same",
      "display",
      "name",
      "incrementally",
      "numbered",
      "ascending",
      "order.",
      "see",
      "topic",
      "controls.",
      "one",
      "option.",
      "add",
      "properties",
      "options.",
      "save",
      "bindings",
      "expect",
      "given",
      "provided",
      "configure"
    ],
    "language": "en",
    "word_count": 101,
    "importance_score": 4.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "sequenced design configuration options",
    "contentLower": "the configuration options tab allows you to create sets of options for service design. select a version of the design to view the configurations options tab. option sets are made available in the offerings area, where they can be further refined by setting pricing for options, hiding options, and setting values for option properties. configuration options are then exposed to subscribers in the service portal. these options allow the user to select values that customize the service offering for their personal needs. for example, you can create an option set called number of servers, which is configured as follows: the option set has three options, small, medium, and large. each option has a property called nservers. each option has a unique, specified value for nservers, either small (2 servers), medium (4 servers), or large (8 servers). a binding is created from the nservers property to a corresponding nservers property on a server group service component. this use of a configuration o",
    "keywordsLower": [
      "sequenced",
      "design",
      "configuration",
      "options",
      "workflow",
      "related",
      "topics",
      "tab",
      "allows",
      "create",
      "sets",
      "service",
      "design.",
      "select",
      "version",
      "view",
      "configurations",
      "tab.",
      "option",
      "made",
      "available",
      "offerings",
      "area",
      "further",
      "refined",
      "setting",
      "pricing",
      "hiding",
      "values",
      "properties.",
      "exposed",
      "subscribers",
      "portal.",
      "allow",
      "user",
      "customize",
      "offering",
      "personal",
      "needs.",
      "example",
      "set",
      "called",
      "number",
      "servers",
      "configured",
      "follows",
      "three",
      "small",
      "medium",
      "large.",
      "property",
      "nservers.",
      "unique",
      "specified",
      "value",
      "nservers",
      "either",
      "large",
      "binding",
      "created",
      "corresponding",
      "server",
      "group",
      "component.",
      "push",
      "component",
      "target",
      "described",
      "below.",
      "portal",
      "provides",
      "desired",
      "servers.",
      "best",
      "practice",
      "copy",
      "paste",
      "set.",
      "keep",
      "same",
      "display",
      "name",
      "incrementally",
      "numbered",
      "ascending",
      "order.",
      "see",
      "topic",
      "controls.",
      "one",
      "option.",
      "add",
      "properties",
      "options.",
      "save",
      "bindings",
      "expect",
      "given",
      "provided",
      "configure"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Reorder configuration option sets and options",
    "content": "The Configuration Options tab isn't editable if you publish the service design. To change to order of option sets or options: Select the service design version whose configuration options and option sets you want to reorder. Select the Configuration Options tab. Select an option set and then use <Ctrl>+ the arrow keys to move the selection in the list. You can also reorder an option set by clicking and dragging it. Click Navigate to Option Set to view the options for an option set. Select an option and then use <Ctrl>+ the arrow keys to move the selection in the list. You can also reorder an option by clicking and dragging it. For descriptions of the additional icons available on the Configuration Options tab, see Sequenced design configuration options.",
    "url": "mgmtconssdsubsoptionpropreorder",
    "filename": "mgmtconssdsubsoptionpropreorder",
    "headings": [],
    "keywords": [
      "reorder",
      "configuration",
      "option",
      "sets",
      "options",
      "tab",
      "isn",
      "editable",
      "publish",
      "service",
      "design.",
      "change",
      "order",
      "select",
      "design",
      "version",
      "whose",
      "want",
      "reorder.",
      "tab.",
      "set",
      "arrow",
      "keys",
      "move",
      "selection",
      "list.",
      "clicking",
      "dragging",
      "it.",
      "click",
      "navigate",
      "view",
      "set.",
      "descriptions",
      "additional",
      "icons",
      "available",
      "see",
      "sequenced",
      "options."
    ],
    "language": "en",
    "word_count": 80,
    "importance_score": 2.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "reorder configuration option sets and options",
    "contentLower": "the configuration options tab isn't editable if you publish the service design. to change to order of option sets or options: select the service design version whose configuration options and option sets you want to reorder. select the configuration options tab. select an option set and then use <ctrl>+ the arrow keys to move the selection in the list. you can also reorder an option set by clicking and dragging it. click navigate to option set to view the options for an option set. select an option and then use <ctrl>+ the arrow keys to move the selection in the list. you can also reorder an option by clicking and dragging it. for descriptions of the additional icons available on the configuration options tab, see sequenced design configuration options.",
    "keywordsLower": [
      "reorder",
      "configuration",
      "option",
      "sets",
      "options",
      "tab",
      "isn",
      "editable",
      "publish",
      "service",
      "design.",
      "change",
      "order",
      "select",
      "design",
      "version",
      "whose",
      "want",
      "reorder.",
      "tab.",
      "set",
      "arrow",
      "keys",
      "move",
      "selection",
      "list.",
      "clicking",
      "dragging",
      "it.",
      "click",
      "navigate",
      "view",
      "set.",
      "descriptions",
      "additional",
      "icons",
      "available",
      "see",
      "sequenced",
      "options."
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Select Property to Map to Script Parameter",
    "content": "This dialog is used to map option property values to script parameters, allowing the value of an option property in one option to be read by a script associated with an option property in another option. For example, the value of a Region property in one option can be supplied as a script parameter to a Site option property; the script used by the Site option property can then return a list of applicable sites for the chosen region. After selecting the property, click Select to close the dialog. The selected option property, and its path, will be displayed in the Configure Parameters dialog. If you select a property on the same option as the property for which script parameters are being configured, a Client token will be used rather than an option property mapping. This will be displayed as: [CLIENT:<property_name>] in the Configure Parameters dialog. You can't configure an option property mapping to the same property for which script parameters are being configured.",
    "url": "selectpropertytomaptoscriptparameter",
    "filename": "selectpropertytomaptoscriptparameter",
    "headings": [],
    "keywords": [
      "select",
      "property",
      "map",
      "script",
      "parameter",
      "dialog",
      "option",
      "values",
      "parameters",
      "allowing",
      "value",
      "one",
      "read",
      "associated",
      "another",
      "option.",
      "example",
      "region",
      "supplied",
      "site",
      "return",
      "list",
      "applicable",
      "sites",
      "chosen",
      "region.",
      "after",
      "selecting",
      "click",
      "close",
      "dialog.",
      "selected",
      "path",
      "displayed",
      "configure",
      "same",
      "configured",
      "client",
      "token",
      "rather",
      "mapping.",
      "mapping",
      "configured."
    ],
    "language": "en",
    "word_count": 91,
    "importance_score": 2.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "select property to map to script parameter",
    "contentLower": "this dialog is used to map option property values to script parameters, allowing the value of an option property in one option to be read by a script associated with an option property in another option. for example, the value of a region property in one option can be supplied as a script parameter to a site option property; the script used by the site option property can then return a list of applicable sites for the chosen region. after selecting the property, click select to close the dialog. the selected option property, and its path, will be displayed in the configure parameters dialog. if you select a property on the same option as the property for which script parameters are being configured, a client token will be used rather than an option property mapping. this will be displayed as: [client:<property_name>] in the configure parameters dialog. you can't configure an option property mapping to the same property for which script parameters are being configured.",
    "keywordsLower": [
      "select",
      "property",
      "map",
      "script",
      "parameter",
      "dialog",
      "option",
      "values",
      "parameters",
      "allowing",
      "value",
      "one",
      "read",
      "associated",
      "another",
      "option.",
      "example",
      "region",
      "supplied",
      "site",
      "return",
      "list",
      "applicable",
      "sites",
      "chosen",
      "region.",
      "after",
      "selecting",
      "click",
      "close",
      "dialog.",
      "selected",
      "path",
      "displayed",
      "configure",
      "same",
      "configured",
      "client",
      "token",
      "rather",
      "mapping.",
      "mapping",
      "configured."
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Service design failure handling",
    "content": "The Failure Handling tab allows you to configure whether to pause or fail a service instance when an action error occurs during Provisioning, Modification, or Cancellation (De-Provisioning). The Provisioning lifecycle stages include Initializing, Reserving, and Deploying, the Modification lifecycle stage is Modifying, and the Cancellation or De-Provisioning lifecycle stages include Un-deploying, Un-reserving, and Un-initializing.  For more information on lifecycle stages, see Lifecycle actions for service design. If you select Pause on Errors for a lifecycle stage, a service instance created from this design will pause when an action error occurs, provided that Fail on Error is selected in the configuration for the action.  This provides an operator the opportunity to triage the error and optionally resume the instance in the Instance Management UI. To access the Failure Handling functionality, select the Failure Handling tab of a design. Failure handling options The failure handling o",
    "url": "mgmtconssdfailurehandling",
    "filename": "mgmtconssdfailurehandling",
    "headings": [
      "Failure handling options",
      "Configure service instance transition timeout",
      "Related Topics"
    ],
    "keywords": [
      "service",
      "design",
      "failure",
      "handling",
      "options",
      "configure",
      "instance",
      "transition",
      "timeout",
      "related",
      "topics",
      "tab",
      "allows",
      "whether",
      "pause",
      "fail",
      "action",
      "error",
      "occurs",
      "during",
      "provisioning",
      "modification",
      "cancellation",
      "de-provisioning",
      "lifecycle",
      "stages",
      "include",
      "initializing",
      "reserving",
      "deploying",
      "stage",
      "modifying",
      "un-deploying",
      "un-reserving",
      "un-initializing.",
      "information",
      "see",
      "actions",
      "design.",
      "select",
      "errors",
      "created",
      "provided",
      "selected",
      "configuration",
      "action.",
      "provides",
      "operator",
      "opportunity",
      "triage",
      "optionally",
      "resume",
      "management",
      "ui.",
      "access",
      "functionality",
      "available",
      "below.",
      "indicates",
      "configured",
      "run.",
      "subscriber",
      "subscription",
      "status",
      "terminated.",
      "stop",
      "pending.",
      "later",
      "resumed",
      "failed",
      "operator.",
      "active",
      "able",
      "attempt",
      "another",
      "modification.",
      "active.",
      "reset",
      "canceled.",
      "system",
      "polls",
      "24",
      "hours.",
      "pauses",
      "hour",
      "elapse",
      "before",
      "completes",
      "current",
      "stage.",
      "provisioned",
      "elapses",
      "terminate",
      "subscription.",
      "modified",
      "further",
      "modifications",
      "allowed.",
      "increase",
      "default"
    ],
    "language": "en",
    "word_count": 94,
    "importance_score": 4.5,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "service design failure handling",
    "contentLower": "the failure handling tab allows you to configure whether to pause or fail a service instance when an action error occurs during provisioning, modification, or cancellation (de-provisioning). the provisioning lifecycle stages include initializing, reserving, and deploying, the modification lifecycle stage is modifying, and the cancellation or de-provisioning lifecycle stages include un-deploying, un-reserving, and un-initializing.  for more information on lifecycle stages, see lifecycle actions for service design. if you select pause on errors for a lifecycle stage, a service instance created from this design will pause when an action error occurs, provided that fail on error is selected in the configuration for the action.  this provides an operator the opportunity to triage the error and optionally resume the instance in the instance management ui. to access the failure handling functionality, select the failure handling tab of a design. failure handling options the failure handling o",
    "keywordsLower": [
      "service",
      "design",
      "failure",
      "handling",
      "options",
      "configure",
      "instance",
      "transition",
      "timeout",
      "related",
      "topics",
      "tab",
      "allows",
      "whether",
      "pause",
      "fail",
      "action",
      "error",
      "occurs",
      "during",
      "provisioning",
      "modification",
      "cancellation",
      "de-provisioning",
      "lifecycle",
      "stages",
      "include",
      "initializing",
      "reserving",
      "deploying",
      "stage",
      "modifying",
      "un-deploying",
      "un-reserving",
      "un-initializing.",
      "information",
      "see",
      "actions",
      "design.",
      "select",
      "errors",
      "created",
      "provided",
      "selected",
      "configuration",
      "action.",
      "provides",
      "operator",
      "opportunity",
      "triage",
      "optionally",
      "resume",
      "management",
      "ui.",
      "access",
      "functionality",
      "available",
      "below.",
      "indicates",
      "configured",
      "run.",
      "subscriber",
      "subscription",
      "status",
      "terminated.",
      "stop",
      "pending.",
      "later",
      "resumed",
      "failed",
      "operator.",
      "active",
      "able",
      "attempt",
      "another",
      "modification.",
      "active.",
      "reset",
      "canceled.",
      "system",
      "polls",
      "24",
      "hours.",
      "pauses",
      "hour",
      "elapse",
      "before",
      "completes",
      "current",
      "stage.",
      "provisioned",
      "elapses",
      "terminate",
      "subscription.",
      "modified",
      "further",
      "modifications",
      "allowed.",
      "increase",
      "default"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Service design deployments",
    "content": "The DEPLOYMENTS tab displays test deployments and subscriptions created for a service design. Test Deployment:  You create a test deployment from the DEPLOYMENTS tab for a service design to test the service design properties and configurations as a developer. A test deployment has the tag Test Deployment associated with it. You can cancel or delete a test deployment. Subscription: A subscription originates with a subscription request, initiated by the subscriber (end user) in the Service Portal. You can differentiate a subscription from a test deployment by the tag subscription associated with it. You can't cancel or delete the deployment for a subscription. You can cancel or delete a subscription from the Service Portal only. To view deployments Go to Build > Design > SERVICE DESIGNER. Select a version of a service design. Select the DEPLOYMENTS tab to view test deployments and subscriptions created for a service design. If you are a tenant administrator, you can see all the subscript",
    "url": "mgmtconssddeployments",
    "filename": "mgmtconssddeployments",
    "headings": [
      "To view deployments",
      "Related topics"
    ],
    "keywords": [
      "service",
      "design",
      "deployments",
      "view",
      "related",
      "topics",
      "tab",
      "displays",
      "test",
      "subscriptions",
      "created",
      "design.",
      "deployment",
      "create",
      "properties",
      "configurations",
      "developer.",
      "tag",
      "associated",
      "it.",
      "cancel",
      "delete",
      "deployment.",
      "subscription",
      "originates",
      "request",
      "initiated",
      "subscriber",
      "end",
      "user",
      "portal.",
      "differentiate",
      "subscription.",
      "portal",
      "only.",
      "go",
      "build",
      "designer.",
      "select",
      "version",
      "tenant",
      "administrator",
      "see",
      "all",
      "deployments.",
      "designer",
      "you.",
      "search",
      "box",
      "filter",
      "name",
      "description.",
      "listed",
      "contain",
      "link",
      "launch",
      "instance",
      "detail",
      "page",
      "operations.",
      "tree",
      "components",
      "part",
      "deployed",
      "instance.",
      "navigate",
      "main",
      "operations",
      "instances.",
      "details",
      "deploy",
      "new",
      "information",
      "instances",
      "management."
    ],
    "language": "en",
    "word_count": 94,
    "importance_score": 4.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "service design deployments",
    "contentLower": "the deployments tab displays test deployments and subscriptions created for a service design. test deployment:  you create a test deployment from the deployments tab for a service design to test the service design properties and configurations as a developer. a test deployment has the tag test deployment associated with it. you can cancel or delete a test deployment. subscription: a subscription originates with a subscription request, initiated by the subscriber (end user) in the service portal. you can differentiate a subscription from a test deployment by the tag subscription associated with it. you can't cancel or delete the deployment for a subscription. you can cancel or delete a subscription from the service portal only. to view deployments go to build > design > service designer. select a version of a service design. select the deployments tab to view test deployments and subscriptions created for a service design. if you are a tenant administrator, you can see all the subscript",
    "keywordsLower": [
      "service",
      "design",
      "deployments",
      "view",
      "related",
      "topics",
      "tab",
      "displays",
      "test",
      "subscriptions",
      "created",
      "design.",
      "deployment",
      "create",
      "properties",
      "configurations",
      "developer.",
      "tag",
      "associated",
      "it.",
      "cancel",
      "delete",
      "deployment.",
      "subscription",
      "originates",
      "request",
      "initiated",
      "subscriber",
      "end",
      "user",
      "portal.",
      "differentiate",
      "subscription.",
      "portal",
      "only.",
      "go",
      "build",
      "designer.",
      "select",
      "version",
      "tenant",
      "administrator",
      "see",
      "all",
      "deployments.",
      "designer",
      "you.",
      "search",
      "box",
      "filter",
      "name",
      "description.",
      "listed",
      "contain",
      "link",
      "launch",
      "instance",
      "detail",
      "page",
      "operations.",
      "tree",
      "components",
      "part",
      "deployed",
      "instance.",
      "navigate",
      "main",
      "operations",
      "instances.",
      "details",
      "deploy",
      "new",
      "information",
      "instances",
      "management."
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Service design components",
    "content": "From the main menu go to Build > Design > Service Components. A service component is an element of service design. A service component limits the type of child components and category of resource offerings. A component also known as a service component represents one service design element required to realize a service subscription. It provides a framework to describe the actions and resource offerings required to realize, manage, and retire the service design. Component palettes Component palettes are the grouping structure for component types (described below). Each palette contains a group of component types you can choose from when creating service components in service design. By default one palette is available. . This palette allows you to reuse the installed component types, and templates, or you can create your own component palettes, types and templates from the base set, (with some restrictions). When creating component types from other palettes, you must take care to preven",
    "url": "mgmtconssdservicecompabout",
    "filename": "mgmtconssdservicecompabout",
    "headings": [
      "Component palettes",
      "Component types",
      "CI type based palette",
      "Component templates",
      "Related topics"
    ],
    "keywords": [
      "service",
      "design",
      "components",
      "component",
      "palettes",
      "types",
      "ci",
      "type",
      "based",
      "palette",
      "templates",
      "related",
      "topics",
      "main",
      "menu",
      "go",
      "build",
      "components.",
      "element",
      "design.",
      "limits",
      "child",
      "category",
      "resource",
      "offerings.",
      "known",
      "represents",
      "one",
      "required",
      "realize",
      "subscription.",
      "provides",
      "framework",
      "describe",
      "actions",
      "offerings",
      "manage",
      "retire",
      "grouping",
      "structure",
      "described",
      "below",
      "contains",
      "group",
      "choose",
      "creating",
      "default",
      "available.",
      "allows",
      "reuse",
      "installed",
      "create",
      "own",
      "base",
      "set",
      "restrictions",
      "take",
      "care",
      "prevent",
      "circular",
      "dependencies",
      "however",
      "conforming",
      "suggested",
      "best",
      "practices",
      "help",
      "meet",
      "organization",
      "needs.",
      "hierarchical",
      "classification",
      "rules",
      "constrain",
      "designs",
      "constructed",
      "helping",
      "designer",
      "properly",
      "construct",
      "constraints",
      "limit",
      "connected",
      "categories",
      "bound",
      "type.",
      "types.",
      "import",
      "legacy",
      "get",
      "number",
      "palette.",
      "non-ci",
      "aligned",
      "ucmdb",
      "system.",
      "listed",
      "following",
      "table.",
      "out-of-the-box"
    ],
    "language": "en",
    "word_count": 97,
    "importance_score": 5.5,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "service design components",
    "contentLower": "from the main menu go to build > design > service components. a service component is an element of service design. a service component limits the type of child components and category of resource offerings. a component also known as a service component represents one service design element required to realize a service subscription. it provides a framework to describe the actions and resource offerings required to realize, manage, and retire the service design. component palettes component palettes are the grouping structure for component types (described below). each palette contains a group of component types you can choose from when creating service components in service design. by default one palette is available. . this palette allows you to reuse the installed component types, and templates, or you can create your own component palettes, types and templates from the base set, (with some restrictions). when creating component types from other palettes, you must take care to preven",
    "keywordsLower": [
      "service",
      "design",
      "components",
      "component",
      "palettes",
      "types",
      "ci",
      "type",
      "based",
      "palette",
      "templates",
      "related",
      "topics",
      "main",
      "menu",
      "go",
      "build",
      "components.",
      "element",
      "design.",
      "limits",
      "child",
      "category",
      "resource",
      "offerings.",
      "known",
      "represents",
      "one",
      "required",
      "realize",
      "subscription.",
      "provides",
      "framework",
      "describe",
      "actions",
      "offerings",
      "manage",
      "retire",
      "grouping",
      "structure",
      "described",
      "below",
      "contains",
      "group",
      "choose",
      "creating",
      "default",
      "available.",
      "allows",
      "reuse",
      "installed",
      "create",
      "own",
      "base",
      "set",
      "restrictions",
      "take",
      "care",
      "prevent",
      "circular",
      "dependencies",
      "however",
      "conforming",
      "suggested",
      "best",
      "practices",
      "help",
      "meet",
      "organization",
      "needs.",
      "hierarchical",
      "classification",
      "rules",
      "constrain",
      "designs",
      "constructed",
      "helping",
      "designer",
      "properly",
      "construct",
      "constraints",
      "limit",
      "connected",
      "categories",
      "bound",
      "type.",
      "types.",
      "import",
      "legacy",
      "get",
      "number",
      "palette.",
      "non-ci",
      "aligned",
      "ucmdb",
      "system.",
      "listed",
      "following",
      "table.",
      "out-of-the-box"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Select Tokens",
    "content": "A token is a system value that's automatically resolved internally when the property is read. Token values are available only for the following: String property for a component type, component template, service component in a design, or resource offering Parameter when a topology component operation has a mapping type of Context Property Token String parameter input for an action A parameter value to a script that's configured on configuration options property that's configured for Input Validation A parameter value to a script that's configured on configuration options property of type List that's Dynamic Entry A parameter value to a script that's configured on a user operation input parameter that's configured for Input Validation A parameter value to a script that's configured on a user operation input parameter that has a mapping type of Prompt User List with the list configured for Dynamic Entry The Design and Deploy (DND) capability doesn't support some tokens. The following tabl",
    "url": "mgmtconscomptypeselecttokens",
    "filename": "mgmtconscomptypeselecttokens",
    "headings": [
      "Server-side tokens",
      "Client-side tokens",
      "Portal tokens"
    ],
    "keywords": [
      "select",
      "tokens",
      "server-side",
      "client-side",
      "portal",
      "token",
      "system",
      "value",
      "automatically",
      "resolved",
      "internally",
      "property",
      "read.",
      "values",
      "available",
      "following",
      "string",
      "component",
      "type",
      "template",
      "service",
      "design",
      "resource",
      "offering",
      "parameter",
      "topology",
      "operation",
      "mapping",
      "context",
      "input",
      "action",
      "script",
      "configured",
      "configuration",
      "options",
      "validation",
      "list",
      "dynamic",
      "entry",
      "user",
      "prompt",
      "deploy",
      "dnd",
      "capability",
      "doesn",
      "support",
      "tokens.",
      "tables",
      "show",
      "descriptions",
      "applicable",
      "areas",
      "whether",
      "supported",
      "dnd.",
      "description",
      "applies",
      "name",
      "resolves",
      "order",
      "initially",
      "ordering",
      "subscription",
      "modifying",
      "existing",
      "subscription.",
      "parent",
      "id",
      "component.",
      "offerings",
      "refers",
      "associated",
      "design.",
      "provider",
      "selection",
      "binding",
      "created",
      "time.",
      "selected",
      "pool",
      "blueprint",
      "id.",
      "catalog",
      "action.",
      "example",
      "server",
      "instance",
      "request",
      "organization",
      "request.",
      "subscriber",
      "email",
      "address",
      "subscriber.",
      "client",
      "allows",
      "dependency",
      "another",
      "same",
      "option."
    ],
    "language": "en",
    "word_count": 105,
    "importance_score": 4.5,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "select tokens",
    "contentLower": "a token is a system value that's automatically resolved internally when the property is read. token values are available only for the following: string property for a component type, component template, service component in a design, or resource offering parameter when a topology component operation has a mapping type of context property token string parameter input for an action a parameter value to a script that's configured on configuration options property that's configured for input validation a parameter value to a script that's configured on configuration options property of type list that's dynamic entry a parameter value to a script that's configured on a user operation input parameter that's configured for input validation a parameter value to a script that's configured on a user operation input parameter that has a mapping type of prompt user list with the list configured for dynamic entry the design and deploy (dnd) capability doesn't support some tokens. the following tabl",
    "keywordsLower": [
      "select",
      "tokens",
      "server-side",
      "client-side",
      "portal",
      "token",
      "system",
      "value",
      "automatically",
      "resolved",
      "internally",
      "property",
      "read.",
      "values",
      "available",
      "following",
      "string",
      "component",
      "type",
      "template",
      "service",
      "design",
      "resource",
      "offering",
      "parameter",
      "topology",
      "operation",
      "mapping",
      "context",
      "input",
      "action",
      "script",
      "configured",
      "configuration",
      "options",
      "validation",
      "list",
      "dynamic",
      "entry",
      "user",
      "prompt",
      "deploy",
      "dnd",
      "capability",
      "doesn",
      "support",
      "tokens.",
      "tables",
      "show",
      "descriptions",
      "applicable",
      "areas",
      "whether",
      "supported",
      "dnd.",
      "description",
      "applies",
      "name",
      "resolves",
      "order",
      "initially",
      "ordering",
      "subscription",
      "modifying",
      "existing",
      "subscription.",
      "parent",
      "id",
      "component.",
      "offerings",
      "refers",
      "associated",
      "design.",
      "provider",
      "selection",
      "binding",
      "created",
      "time.",
      "selected",
      "pool",
      "blueprint",
      "id.",
      "catalog",
      "action.",
      "example",
      "server",
      "instance",
      "request",
      "organization",
      "request.",
      "subscriber",
      "email",
      "address",
      "subscriber.",
      "client",
      "allows",
      "dependency",
      "another",
      "same",
      "option."
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Remove a constraint",
    "content": "For information about constraints, see View constraints of a component type. You can't remove a constraint from a component type if it's locked. In addition, you can't remove a constraint that's already available by default. However, you can add constraints to the delivered component types, and then you can remove constraints that you added. To remove a constraint In the left pane of the Sequenced Components area, select the component palette that contains the component type from which you want to remove a constraint. Click the component type from which you want to remove a constraint. Select the Constraints tab. Select the type of constraint you want to delete: Component Types or Resource Categories. Click the gear icon for the constraint and select Delete. Click Yes in the confirmation dialog. Related topics View constraints of a component type",
    "url": "mgmtconscomptyperemoveconstraint",
    "filename": "mgmtconscomptyperemoveconstraint",
    "headings": [
      "To remove a constraint",
      "Related topics"
    ],
    "keywords": [
      "remove",
      "constraint",
      "related",
      "topics",
      "information",
      "about",
      "constraints",
      "see",
      "view",
      "component",
      "type.",
      "type",
      "locked.",
      "addition",
      "already",
      "available",
      "default.",
      "however",
      "add",
      "delivered",
      "types",
      "added.",
      "left",
      "pane",
      "sequenced",
      "components",
      "area",
      "select",
      "palette",
      "contains",
      "want",
      "constraint.",
      "click",
      "tab.",
      "delete",
      "resource",
      "categories.",
      "gear",
      "icon",
      "delete.",
      "confirmation",
      "dialog."
    ],
    "language": "en",
    "word_count": 83,
    "importance_score": 4.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "remove a constraint",
    "contentLower": "for information about constraints, see view constraints of a component type. you can't remove a constraint from a component type if it's locked. in addition, you can't remove a constraint that's already available by default. however, you can add constraints to the delivered component types, and then you can remove constraints that you added. to remove a constraint in the left pane of the sequenced components area, select the component palette that contains the component type from which you want to remove a constraint. click the component type from which you want to remove a constraint. select the constraints tab. select the type of constraint you want to delete: component types or resource categories. click the gear icon for the constraint and select delete. click yes in the confirmation dialog. related topics view constraints of a component type",
    "keywordsLower": [
      "remove",
      "constraint",
      "related",
      "topics",
      "information",
      "about",
      "constraints",
      "see",
      "view",
      "component",
      "type.",
      "type",
      "locked.",
      "addition",
      "already",
      "available",
      "default.",
      "however",
      "add",
      "delivered",
      "types",
      "added.",
      "left",
      "pane",
      "sequenced",
      "components",
      "area",
      "select",
      "palette",
      "contains",
      "want",
      "constraint.",
      "click",
      "tab.",
      "delete",
      "resource",
      "categories.",
      "gear",
      "icon",
      "delete.",
      "confirmation",
      "dialog."
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Resource accounting",
    "content": "For more information about associating resource offerings to service components, see the topic Associate resource offerings with component templates. Resource accounting actions track the utilization of resources in a resource pool. The following out-of-the-box accounting actions are added to the resource offerings when you enable resource accounting: Increase Resource Utilization — This action is configured to run during the After phase of the Reserving lifecycle stage. Decrease Resource Utilization — This action is configured to run during the After phase of the Un-reserving lifecycle stage. Tasks Navigate to or View — In the left pane of the All Designs area, select the tag associated with the design you want to view, and select the service design. In the Designer tab, select the service component whose resource accounting action properties you want to view. In the right pane, click the gear icon and select Edit Component. In the Resource Offerings tab, select the resource offering.",
    "url": "comptmpltroresourceaccounting",
    "filename": "comptmpltroresourceaccounting",
    "headings": [
      "Tasks",
      "Best practices",
      "Related topics"
    ],
    "keywords": [
      "resource",
      "accounting",
      "tasks",
      "best",
      "practices",
      "related",
      "topics",
      "information",
      "about",
      "associating",
      "offerings",
      "service",
      "components",
      "see",
      "topic",
      "associate",
      "component",
      "templates.",
      "actions",
      "track",
      "utilization",
      "resources",
      "pool.",
      "following",
      "out-of-the-box",
      "added",
      "enable",
      "increase",
      "action",
      "configured",
      "run",
      "during",
      "after",
      "phase",
      "reserving",
      "lifecycle",
      "stage.",
      "decrease",
      "un-reserving",
      "navigate",
      "view",
      "left",
      "pane",
      "all",
      "designs",
      "area",
      "select",
      "tag",
      "associated",
      "design",
      "want",
      "design.",
      "designer",
      "tab",
      "whose",
      "properties",
      "view.",
      "right",
      "click",
      "gear",
      "icon",
      "edit",
      "component.",
      "offering.",
      "panel",
      "display",
      "accounting.",
      "tab.",
      "offering",
      "checkbox",
      "right.",
      "two",
      "internal",
      "automatically",
      "disable",
      "deselect",
      "removed",
      "enabled",
      "disabled",
      "part",
      "published",
      "create",
      "group-level",
      "components.",
      "example",
      "don",
      "server",
      "group",
      "instead",
      "templates"
    ],
    "language": "en",
    "word_count": 101,
    "importance_score": 4.5,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "resource accounting",
    "contentLower": "for more information about associating resource offerings to service components, see the topic associate resource offerings with component templates. resource accounting actions track the utilization of resources in a resource pool. the following out-of-the-box accounting actions are added to the resource offerings when you enable resource accounting: increase resource utilization — this action is configured to run during the after phase of the reserving lifecycle stage. decrease resource utilization — this action is configured to run during the after phase of the un-reserving lifecycle stage. tasks navigate to or view — in the left pane of the all designs area, select the tag associated with the design you want to view, and select the service design. in the designer tab, select the service component whose resource accounting action properties you want to view. in the right pane, click the gear icon and select edit component. in the resource offerings tab, select the resource offering.",
    "keywordsLower": [
      "resource",
      "accounting",
      "tasks",
      "best",
      "practices",
      "related",
      "topics",
      "information",
      "about",
      "associating",
      "offerings",
      "service",
      "components",
      "see",
      "topic",
      "associate",
      "component",
      "templates.",
      "actions",
      "track",
      "utilization",
      "resources",
      "pool.",
      "following",
      "out-of-the-box",
      "added",
      "enable",
      "increase",
      "action",
      "configured",
      "run",
      "during",
      "after",
      "phase",
      "reserving",
      "lifecycle",
      "stage.",
      "decrease",
      "un-reserving",
      "navigate",
      "view",
      "left",
      "pane",
      "all",
      "designs",
      "area",
      "select",
      "tag",
      "associated",
      "design",
      "want",
      "design.",
      "designer",
      "tab",
      "whose",
      "properties",
      "view.",
      "right",
      "click",
      "gear",
      "icon",
      "edit",
      "component.",
      "offering.",
      "panel",
      "display",
      "accounting.",
      "tab.",
      "offering",
      "checkbox",
      "right.",
      "two",
      "internal",
      "automatically",
      "disable",
      "deselect",
      "removed",
      "enabled",
      "disabled",
      "part",
      "published",
      "create",
      "group-level",
      "components.",
      "example",
      "don",
      "server",
      "group",
      "instead",
      "templates"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Resource accounting",
    "content": "Resource accounting actions track the utilization of resources in a resource pool. The following out-of-the-box accounting actions are added to the resource offerings when you enable resource accounting: Increase Resource Utilization — This action is configured to run during the After phase of the Reserving lifecycle stage. Decrease Resource Utilization — This action is configured to run during the After phase of the Un-reserving lifecycle stage. Tasks Navigate to or View — In the left pane of the All Designs area, select the tag associated with the design you want to view, and select the service design. In the Designer tab, select the service component whose resource accounting action properties you want to view. In the right pane, click the gear icon and select Edit Component. In the Resource Offerings tab, select the resource offering. The panel on the right will display information about Resource Accounting. Enable (Resource Accounting) — Navigate to the Resource Offerings tab. Sel",
    "url": "mgmtconssdroresourceaccounting",
    "filename": "mgmtconssdroresourceaccounting",
    "headings": [
      "Tasks",
      "Best practices"
    ],
    "keywords": [
      "resource",
      "accounting",
      "tasks",
      "best",
      "practices",
      "actions",
      "track",
      "utilization",
      "resources",
      "pool.",
      "following",
      "out-of-the-box",
      "added",
      "offerings",
      "enable",
      "increase",
      "action",
      "configured",
      "run",
      "during",
      "after",
      "phase",
      "reserving",
      "lifecycle",
      "stage.",
      "decrease",
      "un-reserving",
      "navigate",
      "view",
      "left",
      "pane",
      "all",
      "designs",
      "area",
      "select",
      "tag",
      "associated",
      "design",
      "want",
      "service",
      "design.",
      "designer",
      "tab",
      "component",
      "whose",
      "properties",
      "view.",
      "right",
      "click",
      "gear",
      "icon",
      "edit",
      "component.",
      "offering.",
      "panel",
      "display",
      "information",
      "about",
      "accounting.",
      "tab.",
      "offering",
      "checkbox",
      "right.",
      "two",
      "internal",
      "automatically",
      "disable",
      "deselect",
      "removed",
      "enabled",
      "disabled",
      "part",
      "published",
      "create",
      "group-level",
      "components.",
      "example",
      "don",
      "server",
      "group",
      "instead"
    ],
    "language": "en",
    "word_count": 102,
    "importance_score": 4.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "resource accounting",
    "contentLower": "resource accounting actions track the utilization of resources in a resource pool. the following out-of-the-box accounting actions are added to the resource offerings when you enable resource accounting: increase resource utilization — this action is configured to run during the after phase of the reserving lifecycle stage. decrease resource utilization — this action is configured to run during the after phase of the un-reserving lifecycle stage. tasks navigate to or view — in the left pane of the all designs area, select the tag associated with the design you want to view, and select the service design. in the designer tab, select the service component whose resource accounting action properties you want to view. in the right pane, click the gear icon and select edit component. in the resource offerings tab, select the resource offering. the panel on the right will display information about resource accounting. enable (resource accounting) — navigate to the resource offerings tab. sel",
    "keywordsLower": [
      "resource",
      "accounting",
      "tasks",
      "best",
      "practices",
      "actions",
      "track",
      "utilization",
      "resources",
      "pool.",
      "following",
      "out-of-the-box",
      "added",
      "offerings",
      "enable",
      "increase",
      "action",
      "configured",
      "run",
      "during",
      "after",
      "phase",
      "reserving",
      "lifecycle",
      "stage.",
      "decrease",
      "un-reserving",
      "navigate",
      "view",
      "left",
      "pane",
      "all",
      "designs",
      "area",
      "select",
      "tag",
      "associated",
      "design",
      "want",
      "service",
      "design.",
      "designer",
      "tab",
      "component",
      "whose",
      "properties",
      "view.",
      "right",
      "click",
      "gear",
      "icon",
      "edit",
      "component.",
      "offering.",
      "panel",
      "display",
      "information",
      "about",
      "accounting.",
      "tab.",
      "offering",
      "checkbox",
      "right.",
      "two",
      "internal",
      "automatically",
      "disable",
      "deselect",
      "removed",
      "enabled",
      "disabled",
      "part",
      "published",
      "create",
      "group-level",
      "components.",
      "example",
      "don",
      "server",
      "group",
      "instead"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Service design component properties",
    "content": "For more advanced configuration of the properties on a component, including the ability to add or delete properties, use the Edit Component menu. For more information, see Edit a service component. Properties for service components are user-defined properties that you may want to create in the following situations: When a service component receives its value from a subscriber option. For example, you may wish to receive the number of CPUs for a server after its value has been specified in the Service Portal. To do this, create a property (for example, NCPU) on the server service component and create a subscriber option property (for example, NCPU). Finally, use a target binding, as described in the topic Sequenced design subscriber options, to push the value from the subscriber option to the server NCPU property. When an action that runs on a service component or its associated resource offering expects a property value with a given name and value to exist on the service component. For",
    "url": "mgmtconssdservicecompropabt",
    "filename": "mgmtconssdservicecompropabt",
    "headings": [
      "Tasks",
      "Related topics"
    ],
    "keywords": [
      "service",
      "design",
      "component",
      "properties",
      "tasks",
      "related",
      "topics",
      "advanced",
      "configuration",
      "including",
      "ability",
      "add",
      "delete",
      "edit",
      "menu.",
      "information",
      "see",
      "component.",
      "components",
      "user-defined",
      "want",
      "create",
      "following",
      "situations",
      "receives",
      "value",
      "subscriber",
      "option.",
      "example",
      "wish",
      "receive",
      "number",
      "cpus",
      "server",
      "after",
      "specified",
      "portal.",
      "property",
      "ncpu",
      "option",
      "finally",
      "target",
      "binding",
      "described",
      "topic",
      "sequenced",
      "options",
      "push",
      "property.",
      "action",
      "runs",
      "associated",
      "resource",
      "offering",
      "expects",
      "given",
      "name",
      "exist",
      "need",
      "retrieve",
      "ip",
      "address",
      "stored",
      "mapping",
      "between",
      "obtains",
      "another",
      "design.",
      "software",
      "application",
      "tier",
      "know",
      "id",
      "group.",
      "group",
      "called",
      "token",
      "whose",
      "contains",
      "pulled",
      "pull",
      "mapping.",
      "type",
      "relationship",
      "binding.",
      "about",
      "bindings",
      "options.",
      "expose",
      "explicitly",
      "defined",
      "set",
      "result",
      "execution",
      "hostname",
      "part",
      "deploying",
      "managed",
      "panel",
      "menu"
    ],
    "language": "en",
    "word_count": 92,
    "importance_score": 4.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "service design component properties",
    "contentLower": "for more advanced configuration of the properties on a component, including the ability to add or delete properties, use the edit component menu. for more information, see edit a service component. properties for service components are user-defined properties that you may want to create in the following situations: when a service component receives its value from a subscriber option. for example, you may wish to receive the number of cpus for a server after its value has been specified in the service portal. to do this, create a property (for example, ncpu) on the server service component and create a subscriber option property (for example, ncpu). finally, use a target binding, as described in the topic sequenced design subscriber options, to push the value from the subscriber option to the server ncpu property. when an action that runs on a service component or its associated resource offering expects a property value with a given name and value to exist on the service component. for",
    "keywordsLower": [
      "service",
      "design",
      "component",
      "properties",
      "tasks",
      "related",
      "topics",
      "advanced",
      "configuration",
      "including",
      "ability",
      "add",
      "delete",
      "edit",
      "menu.",
      "information",
      "see",
      "component.",
      "components",
      "user-defined",
      "want",
      "create",
      "following",
      "situations",
      "receives",
      "value",
      "subscriber",
      "option.",
      "example",
      "wish",
      "receive",
      "number",
      "cpus",
      "server",
      "after",
      "specified",
      "portal.",
      "property",
      "ncpu",
      "option",
      "finally",
      "target",
      "binding",
      "described",
      "topic",
      "sequenced",
      "options",
      "push",
      "property.",
      "action",
      "runs",
      "associated",
      "resource",
      "offering",
      "expects",
      "given",
      "name",
      "exist",
      "need",
      "retrieve",
      "ip",
      "address",
      "stored",
      "mapping",
      "between",
      "obtains",
      "another",
      "design.",
      "software",
      "application",
      "tier",
      "know",
      "id",
      "group.",
      "group",
      "called",
      "token",
      "whose",
      "contains",
      "pulled",
      "pull",
      "mapping.",
      "type",
      "relationship",
      "binding.",
      "about",
      "bindings",
      "options.",
      "expose",
      "explicitly",
      "defined",
      "set",
      "result",
      "execution",
      "hostname",
      "part",
      "deploying",
      "managed",
      "panel",
      "menu"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Resource offerings for sequenced designs",
    "content": "From the main menu go to Build > Design > Resource Offerings. A resource offering links the capabilities of providers to the provisioning requirements of a service design. For example, you can create a resource offering that corresponds to a specific VMware vCenter VM template that can be cloned to create a VM. A resource offering includes a user-specified set of lifecycle actions that are performed during the provisioning of the resource offering. A resource offering can also include actions that will be exposed to a subscriber in the Service Portal. A resource offering may include one or more user-created properties that can be used to pass or exchange information with Operations Orchestration during the provisioning of the resource offering. The following tasks can be performed for a Resource Offering: Create Resource Offerings Import Resource Offerings Manage Resource Category Scenarios The following scenarios describe a few of the ways you can use resource offerings: A resource of",
    "url": "mgmtconsroabout",
    "filename": "mgmtconsroabout",
    "headings": [
      "Scenarios",
      "Related topics"
    ],
    "keywords": [
      "5.3",
      "resource",
      "offerings",
      "sequenced",
      "designs",
      "scenarios",
      "related",
      "topics",
      "main",
      "menu",
      "go",
      "build",
      "design",
      "offerings.",
      "offering",
      "links",
      "capabilities",
      "providers",
      "provisioning",
      "requirements",
      "service",
      "design.",
      "example",
      "create",
      "corresponds",
      "specific",
      "vmware",
      "vcenter",
      "vm",
      "template",
      "cloned",
      "vm.",
      "includes",
      "user-specified",
      "set",
      "lifecycle",
      "actions",
      "performed",
      "during",
      "offering.",
      "include",
      "exposed",
      "subscriber",
      "portal.",
      "one",
      "user-created",
      "properties",
      "pass",
      "exchange",
      "information",
      "operations",
      "orchestration",
      "following",
      "tasks",
      "import",
      "manage",
      "category",
      "describe",
      "few",
      "ways",
      "configure",
      "capability",
      "offered",
      "provider",
      "group",
      "same",
      "type",
      "named",
      "red",
      "hat",
      "64-bit",
      "rhel53x64",
      "provisioned",
      "results",
      "created.",
      "such",
      "likely",
      "contain",
      "property",
      "specifies",
      "precise",
      "name",
      "associated",
      "case",
      "need",
      "every",
      "wish",
      "general",
      "provision",
      "any",
      "template.",
      "requires",
      "component",
      "specify",
      "single",
      "needed",
      "expose",
      "functionality",
      "designs.",
      "primary"
    ],
    "language": "en",
    "word_count": 91,
    "importance_score": 4.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "resource offerings for sequenced designs",
    "contentLower": "from the main menu go to build > design > resource offerings. a resource offering links the capabilities of providers to the provisioning requirements of a service design. for example, you can create a resource offering that corresponds to a specific vmware vcenter vm template that can be cloned to create a vm. a resource offering includes a user-specified set of lifecycle actions that are performed during the provisioning of the resource offering. a resource offering can also include actions that will be exposed to a subscriber in the service portal. a resource offering may include one or more user-created properties that can be used to pass or exchange information with operations orchestration during the provisioning of the resource offering. the following tasks can be performed for a resource offering: create resource offerings import resource offerings manage resource category scenarios the following scenarios describe a few of the ways you can use resource offerings: a resource of",
    "keywordsLower": [
      "5.3",
      "resource",
      "offerings",
      "sequenced",
      "designs",
      "scenarios",
      "related",
      "topics",
      "main",
      "menu",
      "go",
      "build",
      "design",
      "offerings.",
      "offering",
      "links",
      "capabilities",
      "providers",
      "provisioning",
      "requirements",
      "service",
      "design.",
      "example",
      "create",
      "corresponds",
      "specific",
      "vmware",
      "vcenter",
      "vm",
      "template",
      "cloned",
      "vm.",
      "includes",
      "user-specified",
      "set",
      "lifecycle",
      "actions",
      "performed",
      "during",
      "offering.",
      "include",
      "exposed",
      "subscriber",
      "portal.",
      "one",
      "user-created",
      "properties",
      "pass",
      "exchange",
      "information",
      "operations",
      "orchestration",
      "following",
      "tasks",
      "import",
      "manage",
      "category",
      "describe",
      "few",
      "ways",
      "configure",
      "capability",
      "offered",
      "provider",
      "group",
      "same",
      "type",
      "named",
      "red",
      "hat",
      "64-bit",
      "rhel53x64",
      "provisioned",
      "results",
      "created.",
      "such",
      "likely",
      "contain",
      "property",
      "specifies",
      "precise",
      "name",
      "associated",
      "case",
      "need",
      "every",
      "wish",
      "general",
      "provision",
      "any",
      "template.",
      "requires",
      "component",
      "specify",
      "single",
      "needed",
      "expose",
      "functionality",
      "designs.",
      "primary"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Resource offering tabs",
    "content": "A resource-offering landing page has the following tabs: Overview tab – Displays the resource offering's name and details, and allows you to edit, copy, export, or delete the resource offering. Providers tab – Displays information about current providers associated with the resource offering. The tab also allows you to create a provider association, and to select the provider. Properties tab – Displays information about the resource offering properties, and allows you to create, edit, and delete properties. Lifecycle tab – Displays the resource offering lifecycles and allows you to chose or select a stage, and edit, delete, save as, or export a resource offering at a particular stage. User Operations tab – Displays user operations associated with a resource offering, and allows you to add, edit, delete, copy, or export resource offerings associated with a user operation. Component Templates tab – Allows you to view component templates associated with a resource offering, and edit, copy",
    "url": "mgmtconsrotabs",
    "filename": "mgmtconsrotabs",
    "headings": [],
    "keywords": [
      "resource",
      "offering",
      "tabs",
      "resource-offering",
      "landing",
      "page",
      "following",
      "overview",
      "tab",
      "displays",
      "name",
      "details",
      "allows",
      "edit",
      "copy",
      "export",
      "delete",
      "offering.",
      "providers",
      "information",
      "about",
      "current",
      "associated",
      "create",
      "provider",
      "association",
      "select",
      "provider.",
      "properties",
      "properties.",
      "lifecycle",
      "lifecycles",
      "chose",
      "stage",
      "save",
      "particular",
      "stage.",
      "user",
      "operations",
      "add",
      "offerings",
      "operation.",
      "component",
      "templates",
      "view",
      "template.",
      "service",
      "designs",
      "design",
      "service-design",
      "associations"
    ],
    "language": "en",
    "word_count": 103,
    "importance_score": 3.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "resource offering tabs",
    "contentLower": "a resource-offering landing page has the following tabs: overview tab – displays the resource offering's name and details, and allows you to edit, copy, export, or delete the resource offering. providers tab – displays information about current providers associated with the resource offering. the tab also allows you to create a provider association, and to select the provider. properties tab – displays information about the resource offering properties, and allows you to create, edit, and delete properties. lifecycle tab – displays the resource offering lifecycles and allows you to chose or select a stage, and edit, delete, save as, or export a resource offering at a particular stage. user operations tab – displays user operations associated with a resource offering, and allows you to add, edit, delete, copy, or export resource offerings associated with a user operation. component templates tab – allows you to view component templates associated with a resource offering, and edit, copy",
    "keywordsLower": [
      "resource",
      "offering",
      "tabs",
      "resource-offering",
      "landing",
      "page",
      "following",
      "overview",
      "tab",
      "displays",
      "name",
      "details",
      "allows",
      "edit",
      "copy",
      "export",
      "delete",
      "offering.",
      "providers",
      "information",
      "about",
      "current",
      "associated",
      "create",
      "provider",
      "association",
      "select",
      "provider.",
      "properties",
      "properties.",
      "lifecycle",
      "lifecycles",
      "chose",
      "stage",
      "save",
      "particular",
      "stage.",
      "user",
      "operations",
      "add",
      "offerings",
      "operation.",
      "component",
      "templates",
      "view",
      "template.",
      "service",
      "designs",
      "design",
      "service-design",
      "associations"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Resource offerings providers",
    "content": "Providers are management platforms that offer centralized control over the infrastructure and resources that a cloud computing environment uses. One provider can deploy virtual machines, while another provider can monitor applications. A provider corresponds to the specific instance of an application and integrates with the application to help instantiate service designs. A provider type allows you to classify providers for improved filtering and identification and includes some predefined, out-of-the-box provider types. Each instance of a resource offering can have a single provider type. In addition, resource offerings can be associated only with providers that share the same provider type. After adding a resource offering to a service component, you must create one or more provider selection actions for that resource offering. Be sure to do this if you have configured a resource environment for a catalog in order to control which resource providers should be used when service offeri",
    "url": "mgmtconsroprovidertab",
    "filename": "mgmtconsroprovidertab",
    "headings": [
      "Tasks",
      "Related topics"
    ],
    "keywords": [
      "resource",
      "offerings",
      "providers",
      "tasks",
      "related",
      "topics",
      "management",
      "platforms",
      "offer",
      "centralized",
      "control",
      "over",
      "infrastructure",
      "resources",
      "cloud",
      "computing",
      "environment",
      "uses.",
      "one",
      "provider",
      "deploy",
      "virtual",
      "machines",
      "while",
      "another",
      "monitor",
      "applications.",
      "corresponds",
      "specific",
      "instance",
      "application",
      "integrates",
      "help",
      "instantiate",
      "service",
      "designs.",
      "type",
      "allows",
      "classify",
      "improved",
      "filtering",
      "identification",
      "includes",
      "predefined",
      "out-of-the-box",
      "types.",
      "offering",
      "single",
      "type.",
      "addition",
      "associated",
      "share",
      "same",
      "after",
      "adding",
      "component",
      "create",
      "selection",
      "actions",
      "offering.",
      "sure",
      "configured",
      "catalog",
      "order",
      "ordered",
      "catalog.",
      "otherwise",
      "default",
      "random",
      "occurs",
      "aren",
      "called",
      "ignore",
      "association",
      "run",
      "during",
      "before",
      "phase",
      "reserving",
      "lifecycle",
      "stage",
      "changed.",
      "product",
      "ships",
      "internal",
      "selection.",
      "information",
      "about",
      "see",
      "actions.",
      "tab",
      "displays",
      "current",
      "accessible",
      "details",
      "page.",
      "perform",
      "following",
      "gear",
      "icon"
    ],
    "language": "en",
    "word_count": 89,
    "importance_score": 4.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "resource offerings providers",
    "contentLower": "providers are management platforms that offer centralized control over the infrastructure and resources that a cloud computing environment uses. one provider can deploy virtual machines, while another provider can monitor applications. a provider corresponds to the specific instance of an application and integrates with the application to help instantiate service designs. a provider type allows you to classify providers for improved filtering and identification and includes some predefined, out-of-the-box provider types. each instance of a resource offering can have a single provider type. in addition, resource offerings can be associated only with providers that share the same provider type. after adding a resource offering to a service component, you must create one or more provider selection actions for that resource offering. be sure to do this if you have configured a resource environment for a catalog in order to control which resource providers should be used when service offeri",
    "keywordsLower": [
      "resource",
      "offerings",
      "providers",
      "tasks",
      "related",
      "topics",
      "management",
      "platforms",
      "offer",
      "centralized",
      "control",
      "over",
      "infrastructure",
      "resources",
      "cloud",
      "computing",
      "environment",
      "uses.",
      "one",
      "provider",
      "deploy",
      "virtual",
      "machines",
      "while",
      "another",
      "monitor",
      "applications.",
      "corresponds",
      "specific",
      "instance",
      "application",
      "integrates",
      "help",
      "instantiate",
      "service",
      "designs.",
      "type",
      "allows",
      "classify",
      "improved",
      "filtering",
      "identification",
      "includes",
      "predefined",
      "out-of-the-box",
      "types.",
      "offering",
      "single",
      "type.",
      "addition",
      "associated",
      "share",
      "same",
      "after",
      "adding",
      "component",
      "create",
      "selection",
      "actions",
      "offering.",
      "sure",
      "configured",
      "catalog",
      "order",
      "ordered",
      "catalog.",
      "otherwise",
      "default",
      "random",
      "occurs",
      "aren",
      "called",
      "ignore",
      "association",
      "run",
      "during",
      "before",
      "phase",
      "reserving",
      "lifecycle",
      "stage",
      "changed.",
      "product",
      "ships",
      "internal",
      "selection.",
      "information",
      "about",
      "see",
      "actions.",
      "tab",
      "displays",
      "current",
      "accessible",
      "details",
      "page.",
      "perform",
      "following",
      "gear",
      "icon"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Resource offering properties",
    "content": "From the Properties tab for a resource offering, you can perform the following tasks: Create a property — Click Create. See property types and values below. Edit a property — Click the gear icon next to a property and select Edit. You can edit a property's display name, description, and property value. View references to a property — Click View References. See View resource offering property references. Delete a property — Click the gear icon next to a property and select Delete. Property types and values Type Property information All Name — A unique name for the property. Display Name — A unique name for the property. Description — A description of the property. Consumer Visible — Select this option to indicate that this property will be made visible in the Service Portal. Boolean Property Value — Select either True or False. Integer Resource Type and Unit for a Measurable Property — Select this option if you want the property to be specified as a measurable unit. Property Value — Sel",
    "url": "mgmtconsropropertiestab",
    "filename": "mgmtconsropropertiestab",
    "headings": [
      "Property types and values",
      "Related topics"
    ],
    "keywords": [
      "resource",
      "offering",
      "properties",
      "property",
      "types",
      "values",
      "related",
      "topics",
      "tab",
      "perform",
      "following",
      "tasks",
      "create",
      "click",
      "create.",
      "see",
      "below.",
      "edit",
      "gear",
      "icon",
      "next",
      "select",
      "edit.",
      "display",
      "name",
      "description",
      "value.",
      "view",
      "references",
      "references.",
      "delete",
      "delete.",
      "type",
      "information",
      "all",
      "unique",
      "property.",
      "consumer",
      "visible",
      "option",
      "indicate",
      "made",
      "service",
      "portal.",
      "boolean",
      "value",
      "either",
      "true",
      "false.",
      "integer",
      "unit",
      "measurable",
      "want",
      "specified",
      "unit.",
      "positive",
      "negative",
      "whole",
      "number",
      "zero.",
      "enter",
      "decimal",
      "truncated",
      "nearest",
      "integer.",
      "maximum",
      "allowed",
      "2147483647",
      "minimum",
      "-2147483648",
      "outside",
      "bounds",
      "automatically",
      "converted",
      "closest",
      "list",
      "icons",
      "add",
      "item",
      "remove",
      "items.",
      "string",
      "characters.",
      "confidential",
      "data",
      "box",
      "mask",
      "read",
      "portal",
      "encryption",
      "performed."
    ],
    "language": "en",
    "word_count": 109,
    "importance_score": 4.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "resource offering properties",
    "contentLower": "from the properties tab for a resource offering, you can perform the following tasks: create a property — click create. see property types and values below. edit a property — click the gear icon next to a property and select edit. you can edit a property's display name, description, and property value. view references to a property — click view references. see view resource offering property references. delete a property — click the gear icon next to a property and select delete. property types and values type property information all name — a unique name for the property. display name — a unique name for the property. description — a description of the property. consumer visible — select this option to indicate that this property will be made visible in the service portal. boolean property value — select either true or false. integer resource type and unit for a measurable property — select this option if you want the property to be specified as a measurable unit. property value — sel",
    "keywordsLower": [
      "resource",
      "offering",
      "properties",
      "property",
      "types",
      "values",
      "related",
      "topics",
      "tab",
      "perform",
      "following",
      "tasks",
      "create",
      "click",
      "create.",
      "see",
      "below.",
      "edit",
      "gear",
      "icon",
      "next",
      "select",
      "edit.",
      "display",
      "name",
      "description",
      "value.",
      "view",
      "references",
      "references.",
      "delete",
      "delete.",
      "type",
      "information",
      "all",
      "unique",
      "property.",
      "consumer",
      "visible",
      "option",
      "indicate",
      "made",
      "service",
      "portal.",
      "boolean",
      "value",
      "either",
      "true",
      "false.",
      "integer",
      "unit",
      "measurable",
      "want",
      "specified",
      "unit.",
      "positive",
      "negative",
      "whole",
      "number",
      "zero.",
      "enter",
      "decimal",
      "truncated",
      "nearest",
      "integer.",
      "maximum",
      "allowed",
      "2147483647",
      "minimum",
      "-2147483648",
      "outside",
      "bounds",
      "automatically",
      "converted",
      "closest",
      "list",
      "icons",
      "add",
      "item",
      "remove",
      "items.",
      "string",
      "characters.",
      "confidential",
      "data",
      "box",
      "mask",
      "read",
      "portal",
      "encryption",
      "performed."
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Resource offering component template tab",
    "content": "Components are elements of service design, sequenced or topological. A component template is a specialized version of a component type and is used to simplify service-design creation. Component templates include customized settings for properties, lifecycle actions, and resource offerings normally created in a service design. Sequenced components aren't associated with providers or provider types. From the Components tab, you can view the topological components associated with a specific provider instance and manage the topological components. Note: Provider components are applicable only to topology components and aren't applicable to sequenced components. Tasks The Component Templates tab, in the resource-offering's details page, allows you to perform several tasks: View list - View a list of component templates associated with a resource offering. Select a component template - Click a component-template name to select it and display its details page. See topic View component templat",
    "url": "mgmtconsrocomptemplatetab",
    "filename": "mgmtconsrocomptemplatetab",
    "headings": [
      "Tasks",
      "Related topics"
    ],
    "keywords": [
      "resource",
      "offering",
      "component",
      "template",
      "tab",
      "tasks",
      "related",
      "topics",
      "components",
      "elements",
      "service",
      "design",
      "sequenced",
      "topological.",
      "specialized",
      "version",
      "type",
      "simplify",
      "service-design",
      "creation.",
      "templates",
      "include",
      "customized",
      "settings",
      "properties",
      "lifecycle",
      "actions",
      "offerings",
      "normally",
      "created",
      "design.",
      "aren",
      "associated",
      "providers",
      "provider",
      "types.",
      "view",
      "topological",
      "specific",
      "instance",
      "manage",
      "components.",
      "note",
      "applicable",
      "topology",
      "resource-offering",
      "details",
      "page",
      "allows",
      "perform",
      "several",
      "list",
      "offering.",
      "select",
      "click",
      "component-template",
      "name",
      "display",
      "page.",
      "see",
      "topic",
      "add",
      "edit",
      "copy",
      "delete",
      "template."
    ],
    "language": "en",
    "word_count": 101,
    "importance_score": 4.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "resource offering component template tab",
    "contentLower": "components are elements of service design, sequenced or topological. a component template is a specialized version of a component type and is used to simplify service-design creation. component templates include customized settings for properties, lifecycle actions, and resource offerings normally created in a service design. sequenced components aren't associated with providers or provider types. from the components tab, you can view the topological components associated with a specific provider instance and manage the topological components. note: provider components are applicable only to topology components and aren't applicable to sequenced components. tasks the component templates tab, in the resource-offering's details page, allows you to perform several tasks: view list - view a list of component templates associated with a resource offering. select a component template - click a component-template name to select it and display its details page. see topic view component templat",
    "keywordsLower": [
      "resource",
      "offering",
      "component",
      "template",
      "tab",
      "tasks",
      "related",
      "topics",
      "components",
      "elements",
      "service",
      "design",
      "sequenced",
      "topological.",
      "specialized",
      "version",
      "type",
      "simplify",
      "service-design",
      "creation.",
      "templates",
      "include",
      "customized",
      "settings",
      "properties",
      "lifecycle",
      "actions",
      "offerings",
      "normally",
      "created",
      "design.",
      "aren",
      "associated",
      "providers",
      "provider",
      "types.",
      "view",
      "topological",
      "specific",
      "instance",
      "manage",
      "components.",
      "note",
      "applicable",
      "topology",
      "resource-offering",
      "details",
      "page",
      "allows",
      "perform",
      "several",
      "list",
      "offering.",
      "select",
      "click",
      "component-template",
      "name",
      "display",
      "page.",
      "see",
      "topic",
      "add",
      "edit",
      "copy",
      "delete",
      "template."
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Resource offerings service designs tab",
    "content": "To provide on-demand, automated service delivery, you create, configure, and modify service designs. A service design is a template (or blueprint) for an orderable service. Service designs include a hierarchy of service components, resource bindings, subscriber options, lifecycle actions, and custom properties, as defined by the Service Designer. Service components and their relationships in a service design define the framework for creating the service. Service designs also provide a structure for options that consumers can select when ordering a service. You can re-use designs for multiple service offerings, with each service offering customized to meet the needs of different consumer organizations and groups. You can also leverage service designs shipped with the product as well as exporting and importing designs between systems. Tasks The Service Design tab, in the resource offerings details page, allows you to perform several tasks: View list - View a list of service designs that ",
    "url": "mgmtconsroservicedesignstab",
    "filename": "mgmtconsroservicedesignstab",
    "headings": [
      "Tasks",
      "Related topics"
    ],
    "keywords": [
      "resource",
      "offerings",
      "service",
      "designs",
      "tab",
      "tasks",
      "related",
      "topics",
      "provide",
      "on-demand",
      "automated",
      "delivery",
      "create",
      "configure",
      "modify",
      "designs.",
      "design",
      "template",
      "blueprint",
      "orderable",
      "service.",
      "include",
      "hierarchy",
      "components",
      "bindings",
      "subscriber",
      "options",
      "lifecycle",
      "actions",
      "custom",
      "properties",
      "defined",
      "designer.",
      "relationships",
      "define",
      "framework",
      "creating",
      "structure",
      "consumers",
      "select",
      "ordering",
      "re-use",
      "multiple",
      "offering",
      "customized",
      "meet",
      "needs",
      "different",
      "consumer",
      "organizations",
      "groups.",
      "leverage",
      "shipped",
      "product",
      "well",
      "exporting",
      "importing",
      "between",
      "systems.",
      "details",
      "page",
      "allows",
      "perform",
      "several",
      "view",
      "list",
      "offerings.",
      "click",
      "service-design",
      "name",
      "display",
      "details.",
      "see",
      "topic",
      "version",
      "add",
      "edit",
      "copy",
      "delete",
      "design."
    ],
    "language": "en",
    "word_count": 99,
    "importance_score": 4.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "resource offerings service designs tab",
    "contentLower": "to provide on-demand, automated service delivery, you create, configure, and modify service designs. a service design is a template (or blueprint) for an orderable service. service designs include a hierarchy of service components, resource bindings, subscriber options, lifecycle actions, and custom properties, as defined by the service designer. service components and their relationships in a service design define the framework for creating the service. service designs also provide a structure for options that consumers can select when ordering a service. you can re-use designs for multiple service offerings, with each service offering customized to meet the needs of different consumer organizations and groups. you can also leverage service designs shipped with the product as well as exporting and importing designs between systems. tasks the service design tab, in the resource offerings details page, allows you to perform several tasks: view list - view a list of service designs that ",
    "keywordsLower": [
      "resource",
      "offerings",
      "service",
      "designs",
      "tab",
      "tasks",
      "related",
      "topics",
      "provide",
      "on-demand",
      "automated",
      "delivery",
      "create",
      "configure",
      "modify",
      "designs.",
      "design",
      "template",
      "blueprint",
      "orderable",
      "service.",
      "include",
      "hierarchy",
      "components",
      "bindings",
      "subscriber",
      "options",
      "lifecycle",
      "actions",
      "custom",
      "properties",
      "defined",
      "designer.",
      "relationships",
      "define",
      "framework",
      "creating",
      "structure",
      "consumers",
      "select",
      "ordering",
      "re-use",
      "multiple",
      "offering",
      "customized",
      "meet",
      "needs",
      "different",
      "consumer",
      "organizations",
      "groups.",
      "leverage",
      "shipped",
      "product",
      "well",
      "exporting",
      "importing",
      "between",
      "systems.",
      "details",
      "page",
      "allows",
      "perform",
      "several",
      "view",
      "list",
      "offerings.",
      "click",
      "service-design",
      "name",
      "display",
      "details.",
      "see",
      "topic",
      "version",
      "add",
      "edit",
      "copy",
      "delete",
      "design."
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Select or remove providers for a resource offering",
    "content": "For a resource offering to be successfully provisioned at subscription ordering time, at least one resource provider must be associated with the resource offering. Additional restrictions exist if resource environments are associated to service catalogs. When you associate a resource offering with a provider, the following must be true for successful provisioning: The associated providers support the resource offering and can deploy it when a service instance is provisioned. If a resource offering is associated with multiple providers, the resource offering must be exactly the same on each of the associated providers. For example, the VMware vCenter template must be exactly the same on all the associated providers. Select providers for a resource offering You must select at least one provider for a resource offering if you want to use the resource offering in service designs. To select a provider, in the resource offering's details page, click the Providers tab, then click Select Provi",
    "url": "mgmtconsroassocdissocproviders",
    "filename": "mgmtconsroassocdissocproviders",
    "headings": [
      "Select providers for a resource offering",
      "Delete providers from a resource offering",
      "Associate resource offerings with the deployment resource provider"
    ],
    "keywords": [
      "select",
      "remove",
      "providers",
      "resource",
      "offering",
      "delete",
      "associate",
      "offerings",
      "deployment",
      "provider",
      "successfully",
      "provisioned",
      "subscription",
      "ordering",
      "time",
      "least",
      "one",
      "associated",
      "offering.",
      "additional",
      "restrictions",
      "exist",
      "environments",
      "service",
      "catalogs.",
      "following",
      "true",
      "successful",
      "provisioning",
      "support",
      "deploy",
      "instance",
      "provisioned.",
      "multiple",
      "exactly",
      "same",
      "providers.",
      "example",
      "vmware",
      "vcenter",
      "template",
      "all",
      "want",
      "designs.",
      "details",
      "page",
      "click",
      "tab",
      "name",
      "select.",
      "tab.",
      "gear",
      "icon",
      "remove.",
      "action",
      "deletes",
      "doesn",
      "itself.",
      "need",
      "conditions",
      "fresh",
      "suite",
      "installation",
      "any",
      "provider.",
      "performed",
      "upgrade",
      "new",
      "version",
      "follow",
      "steps",
      "listed",
      "below",
      "log",
      "agent",
      "interface",
      "administrator.",
      "dashboard",
      "go",
      "administration",
      "utilities",
      "list.",
      "toolbar",
      "offerings.",
      "button.",
      "add",
      "save"
    ],
    "language": "en",
    "word_count": 92,
    "importance_score": 3.5,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "select or remove providers for a resource offering",
    "contentLower": "for a resource offering to be successfully provisioned at subscription ordering time, at least one resource provider must be associated with the resource offering. additional restrictions exist if resource environments are associated to service catalogs. when you associate a resource offering with a provider, the following must be true for successful provisioning: the associated providers support the resource offering and can deploy it when a service instance is provisioned. if a resource offering is associated with multiple providers, the resource offering must be exactly the same on each of the associated providers. for example, the vmware vcenter template must be exactly the same on all the associated providers. select providers for a resource offering you must select at least one provider for a resource offering if you want to use the resource offering in service designs. to select a provider, in the resource offering's details page, click the providers tab, then click select provi",
    "keywordsLower": [
      "select",
      "remove",
      "providers",
      "resource",
      "offering",
      "delete",
      "associate",
      "offerings",
      "deployment",
      "provider",
      "successfully",
      "provisioned",
      "subscription",
      "ordering",
      "time",
      "least",
      "one",
      "associated",
      "offering.",
      "additional",
      "restrictions",
      "exist",
      "environments",
      "service",
      "catalogs.",
      "following",
      "true",
      "successful",
      "provisioning",
      "support",
      "deploy",
      "instance",
      "provisioned.",
      "multiple",
      "exactly",
      "same",
      "providers.",
      "example",
      "vmware",
      "vcenter",
      "template",
      "all",
      "want",
      "designs.",
      "details",
      "page",
      "click",
      "tab",
      "name",
      "select.",
      "tab.",
      "gear",
      "icon",
      "remove.",
      "action",
      "deletes",
      "doesn",
      "itself.",
      "need",
      "conditions",
      "fresh",
      "suite",
      "installation",
      "any",
      "provider.",
      "performed",
      "upgrade",
      "new",
      "version",
      "follow",
      "steps",
      "listed",
      "below",
      "log",
      "agent",
      "interface",
      "administrator.",
      "dashboard",
      "go",
      "administration",
      "utilities",
      "list.",
      "toolbar",
      "offerings.",
      "button.",
      "add",
      "save"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Service design - Manage tags",
    "content": "Tags are a label you can use to provide a structure for organizing and grouping related items. From the All Designs area, click the gear icon and select Manage Design Tags. In the Manage Tags dialog, you can create, edit, and delete tags. Tag properties Field name Description Display Name The name you provide for this tag. Description The description you provide for this tag. Image An image that displays for the tag. Click Change Image. Choose the image you want, and click Select. Click Upload to add your own image. Supported file extensions include .jpg, .jpeg, .gif, and .png. The recommended image size is 256 by 256 pixels, and the image will be scaled to the appropriate size. Color A color used to display the tag.",
    "url": "mgmtconssdtagmanage",
    "filename": "mgmtconssdtagmanage",
    "headings": [
      "Tag properties"
    ],
    "keywords": [
      "service",
      "design",
      "manage",
      "tags",
      "tag",
      "properties",
      "label",
      "provide",
      "structure",
      "organizing",
      "grouping",
      "related",
      "items.",
      "all",
      "designs",
      "area",
      "click",
      "gear",
      "icon",
      "select",
      "tags.",
      "dialog",
      "create",
      "edit",
      "delete",
      "field",
      "name",
      "description",
      "display",
      "tag.",
      "image",
      "displays",
      "change",
      "image.",
      "choose",
      "want",
      "select.",
      "upload",
      "add",
      "own",
      "supported",
      "file",
      "extensions",
      "include",
      ".jpg",
      ".jpeg",
      ".gif",
      ".png.",
      "recommended",
      "size",
      "256",
      "pixels",
      "scaled",
      "appropriate",
      "size.",
      "color"
    ],
    "language": "en",
    "word_count": 82,
    "importance_score": 3.5,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "service design - manage tags",
    "contentLower": "tags are a label you can use to provide a structure for organizing and grouping related items. from the all designs area, click the gear icon and select manage design tags. in the manage tags dialog, you can create, edit, and delete tags. tag properties field name description display name the name you provide for this tag. description the description you provide for this tag. image an image that displays for the tag. click change image. choose the image you want, and click select. click upload to add your own image. supported file extensions include .jpg, .jpeg, .gif, and .png. the recommended image size is 256 by 256 pixels, and the image will be scaled to the appropriate size. color a color used to display the tag.",
    "keywordsLower": [
      "service",
      "design",
      "manage",
      "tags",
      "tag",
      "properties",
      "label",
      "provide",
      "structure",
      "organizing",
      "grouping",
      "related",
      "items.",
      "all",
      "designs",
      "area",
      "click",
      "gear",
      "icon",
      "select",
      "tags.",
      "dialog",
      "create",
      "edit",
      "delete",
      "field",
      "name",
      "description",
      "display",
      "tag.",
      "image",
      "displays",
      "change",
      "image.",
      "choose",
      "want",
      "select.",
      "upload",
      "add",
      "own",
      "supported",
      "file",
      "extensions",
      "include",
      ".jpg",
      ".jpeg",
      ".gif",
      ".png.",
      "recommended",
      "size",
      "256",
      "pixels",
      "scaled",
      "appropriate",
      "size.",
      "color"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Set up the workspace",
    "content": "Before you begin to use the OO Workflow Designer, you need to set up your workspace. To set up your workspace, complete the following tasks: Set up Source Control Management (SCM) to allow multiple authors to collaborate on the same project. If you do not want to use SCM, you can work on a local project. All changes and modifications will be saved only in the database, and you will not be able to recover or revert any of the changes. Import Content Packs into the workspace to use the content in your projects. Create one or more Projects. Set up the System Properties for your projects. The access to the workspace and the project in OO Workflow Designer is user-specific. For example, if authors A and B are using a common computer, and if A logs into the computer, only A's workspace and projects are displayed. You can also manage workspace by setting pre-defined values for zoom and Undo/Redo capabilities in OO Workflow Designer. Configure the workspace To configure the workspace, complete",
    "url": "setupworkspace",
    "filename": "setupworkspace",
    "headings": [
      "Configure the workspace"
    ],
    "keywords": [
      "set",
      "workspace",
      "configure",
      "before",
      "begin",
      "oo",
      "workflow",
      "designer",
      "need",
      "workspace.",
      "complete",
      "following",
      "tasks",
      "source",
      "control",
      "management",
      "scm",
      "allow",
      "multiple",
      "authors",
      "collaborate",
      "same",
      "project.",
      "want",
      "work",
      "local",
      "all",
      "changes",
      "modifications",
      "saved",
      "database",
      "able",
      "recover",
      "revert",
      "any",
      "changes.",
      "import",
      "content",
      "packs",
      "projects.",
      "create",
      "one",
      "system",
      "properties",
      "access",
      "project",
      "user-specific.",
      "example",
      "common",
      "computer",
      "logs",
      "projects",
      "displayed.",
      "manage",
      "setting",
      "pre-defined",
      "values",
      "zoom",
      "undo",
      "redo",
      "capabilities",
      "designer.",
      "steps",
      "follows",
      "top-right",
      "corner",
      "click",
      "settings",
      "button",
      "select",
      "option.",
      "under",
      "flow",
      "editor",
      "tab",
      "show",
      "grid",
      "enable",
      "disable.",
      "default",
      "enabled.",
      "value",
      "field",
      "enter",
      "preferred",
      "value.",
      "100",
      "percent.",
      "autosave",
      "interval",
      "time",
      "minutes.",
      "10",
      "jump",
      "history",
      "limit",
      "view",
      "actions.",
      "save",
      "cancel"
    ],
    "language": "en",
    "word_count": 89,
    "importance_score": 3.5,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "set up the workspace",
    "contentLower": "before you begin to use the oo workflow designer, you need to set up your workspace. to set up your workspace, complete the following tasks: set up source control management (scm) to allow multiple authors to collaborate on the same project. if you do not want to use scm, you can work on a local project. all changes and modifications will be saved only in the database, and you will not be able to recover or revert any of the changes. import content packs into the workspace to use the content in your projects. create one or more projects. set up the system properties for your projects. the access to the workspace and the project in oo workflow designer is user-specific. for example, if authors a and b are using a common computer, and if a logs into the computer, only a's workspace and projects are displayed. you can also manage workspace by setting pre-defined values for zoom and undo/redo capabilities in oo workflow designer. configure the workspace to configure the workspace, complete",
    "keywordsLower": [
      "set",
      "workspace",
      "configure",
      "before",
      "begin",
      "oo",
      "workflow",
      "designer",
      "need",
      "workspace.",
      "complete",
      "following",
      "tasks",
      "source",
      "control",
      "management",
      "scm",
      "allow",
      "multiple",
      "authors",
      "collaborate",
      "same",
      "project.",
      "want",
      "work",
      "local",
      "all",
      "changes",
      "modifications",
      "saved",
      "database",
      "able",
      "recover",
      "revert",
      "any",
      "changes.",
      "import",
      "content",
      "packs",
      "projects.",
      "create",
      "one",
      "system",
      "properties",
      "access",
      "project",
      "user-specific.",
      "example",
      "common",
      "computer",
      "logs",
      "projects",
      "displayed.",
      "manage",
      "setting",
      "pre-defined",
      "values",
      "zoom",
      "undo",
      "redo",
      "capabilities",
      "designer.",
      "steps",
      "follows",
      "top-right",
      "corner",
      "click",
      "settings",
      "button",
      "select",
      "option.",
      "under",
      "flow",
      "editor",
      "tab",
      "show",
      "grid",
      "enable",
      "disable.",
      "default",
      "enabled.",
      "value",
      "field",
      "enter",
      "preferred",
      "value.",
      "100",
      "percent.",
      "autosave",
      "interval",
      "time",
      "minutes.",
      "10",
      "jump",
      "history",
      "limit",
      "view",
      "actions.",
      "save",
      "cancel"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Set up and work with source control management",
    "content": "If you work in a multi-author environment, working with a Source Control Management (SCM) enables you to manage your project in a centralized location and collaborate on it with other authors. It also enables you to recover or revert changes. Using the Git functionality, you can connect to a remote repository on a server (such as GitHub, for example) or connect to a shared file system. Important Working with Source Control Management is not mandatory, but it is recommended. You can attach only one repository per workspace. Within that repository, it is possible to have multiple projects. Git terminology Pull changes In Git, downloading the latest version of the files from the remote repository is known as a \"Pull\" action. After you complete a \"Pull\" action, new files are added to your projects and files that were modified in Git are updated in your project. It is recommended to pull the latest version each day, before starting to work on the files. Committ and push changes In some Git ",
    "url": "scmsetup",
    "filename": "scmsetup",
    "headings": [
      "Git terminology",
      "Set up SCM for the project",
      "Import a Git repository using the HTTPS protocol",
      "Import a Git repository using the SSH protocol",
      "Import a AWS CodeCommit repository using the SSH protocol",
      "Import a Git repository using the file system protocol",
      "Manage Git repositories using SCM",
      "Delete a Git repository from the workspace",
      "Edit a Git repository in the workspace",
      "Track local changes",
      "Manage changes using Git Stash",
      "Pull the most recent changes from the repository",
      "Commit and push your changes to a remote repository",
      "Resolve conflicts",
      "Revert to a previous version",
      "View the SCM message history",
      "Related topics"
    ],
    "keywords": [
      "https://<domain>/<username>/<repository_name>.git",
      "amazonaws.com",
      "file://<hostname",
      "repo.bin",
      "codecommit.us",
      "repo.bat",
      "ssh://Your-SSH-Key-ID@git-codecommit.us-east-2.amazonaws.com/v1/repos/Repo",
      "set",
      "work",
      "source",
      "control",
      "management",
      "git",
      "terminology",
      "scm",
      "project",
      "import",
      "repository",
      "https",
      "protocol",
      "ssh",
      "aws",
      "codecommit",
      "file",
      "system",
      "manage",
      "repositories",
      "delete",
      "workspace",
      "edit",
      "track",
      "local",
      "changes",
      "stash",
      "pull",
      "most",
      "recent",
      "commit",
      "push",
      "remote",
      "resolve",
      "conflicts",
      "revert",
      "previous",
      "version",
      "view",
      "message",
      "history",
      "related",
      "topics",
      "multi-author",
      "environment",
      "working",
      "enables",
      "centralized",
      "location",
      "collaborate",
      "authors.",
      "recover",
      "changes.",
      "functionality",
      "connect",
      "server",
      "such",
      "github",
      "example",
      "shared",
      "system.",
      "important",
      "mandatory",
      "recommended.",
      "attach",
      "one",
      "per",
      "workspace.",
      "possible",
      "multiple",
      "projects.",
      "downloading",
      "latest",
      "files",
      "known",
      "action.",
      "after",
      "complete",
      "action",
      "new",
      "added",
      "projects",
      "modified",
      "updated",
      "project.",
      "recommended",
      "day",
      "before",
      "starting",
      "files.",
      "committ",
      "applications",
      "there"
    ],
    "language": "en",
    "word_count": 93,
    "importance_score": 5.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "set up and work with source control management",
    "contentLower": "if you work in a multi-author environment, working with a source control management (scm) enables you to manage your project in a centralized location and collaborate on it with other authors. it also enables you to recover or revert changes. using the git functionality, you can connect to a remote repository on a server (such as github, for example) or connect to a shared file system. important working with source control management is not mandatory, but it is recommended. you can attach only one repository per workspace. within that repository, it is possible to have multiple projects. git terminology pull changes in git, downloading the latest version of the files from the remote repository is known as a \"pull\" action. after you complete a \"pull\" action, new files are added to your projects and files that were modified in git are updated in your project. it is recommended to pull the latest version each day, before starting to work on the files. committ and push changes in some git ",
    "keywordsLower": [
      "https://<domain>/<username>/<repository_name>.git",
      "amazonaws.com",
      "file://<hostname",
      "repo.bin",
      "codecommit.us",
      "repo.bat",
      "ssh://your-ssh-key-id@git-codecommit.us-east-2.amazonaws.com/v1/repos/repo",
      "set",
      "work",
      "source",
      "control",
      "management",
      "git",
      "terminology",
      "scm",
      "project",
      "import",
      "repository",
      "https",
      "protocol",
      "ssh",
      "aws",
      "codecommit",
      "file",
      "system",
      "manage",
      "repositories",
      "delete",
      "workspace",
      "edit",
      "track",
      "local",
      "changes",
      "stash",
      "pull",
      "most",
      "recent",
      "commit",
      "push",
      "remote",
      "resolve",
      "conflicts",
      "revert",
      "previous",
      "version",
      "view",
      "message",
      "history",
      "related",
      "topics",
      "multi-author",
      "environment",
      "working",
      "enables",
      "centralized",
      "location",
      "collaborate",
      "authors.",
      "recover",
      "changes.",
      "functionality",
      "connect",
      "server",
      "such",
      "github",
      "example",
      "shared",
      "system.",
      "important",
      "mandatory",
      "recommended.",
      "attach",
      "one",
      "per",
      "workspace.",
      "possible",
      "multiple",
      "projects.",
      "downloading",
      "latest",
      "files",
      "known",
      "action.",
      "after",
      "complete",
      "action",
      "new",
      "added",
      "projects",
      "modified",
      "updated",
      "project.",
      "recommended",
      "day",
      "before",
      "starting",
      "files.",
      "committ",
      "applications",
      "there"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Set up source control management for the project",
    "content": "Using the Git functionality, you can either connect to a remote repository on a server (recommended), such as, Stash, or connect to a shared file system. Why do this? If you work in a multi-author environment, working with a source control management tool enables you to save your project in a centralized location and share content with other authors. It also enables you to recover or revert changes. In order to set up Source Control Management (SCM) for OO Workflow Designer, you need to import a Git repository to your workspace. There are several protocols that you can use to import the repository: HTTPS (secured) SSH (secured) File System (not secured) - use this protocol if you do not have a Git server account If you already have an unversioned project in your workspace (i.e., saved locally and not part of the Git repository), when you import a repository, this project will be added to your local version of the repository. You will be able to commit and push this project to the remot",
    "url": "scm",
    "filename": "scm",
    "headings": [
      "Import a Git repository using the HTTPS protocol",
      "Import a Git repository using the SSH protocol",
      "Import a AWS CodeCommit repository using the SSH protocol",
      "Import a Git repository using the file system protocol",
      "Manage Git repositories using SCM",
      "Delete a Git repository from the workspace",
      "Edit a Git repository in the workspace",
      "Related topics"
    ],
    "keywords": [
      "https://<domain>/<username>/<repository_name>.git",
      "amazonaws.com",
      "file://<hostname",
      "repo.bin",
      "codecommit.us",
      "repo.bat",
      "ssh://Your-SSH-Key-ID@git-codecommit.us-east-2.amazonaws.com/v1/repos/Repo",
      "set",
      "source",
      "control",
      "management",
      "project",
      "import",
      "git",
      "repository",
      "https",
      "protocol",
      "ssh",
      "aws",
      "codecommit",
      "file",
      "system",
      "manage",
      "repositories",
      "scm",
      "delete",
      "workspace",
      "edit",
      "related",
      "topics",
      "functionality",
      "either",
      "connect",
      "remote",
      "server",
      "recommended",
      "such",
      "stash",
      "shared",
      "system.",
      "work",
      "multi-author",
      "environment",
      "working",
      "tool",
      "enables",
      "save",
      "centralized",
      "location",
      "share",
      "content",
      "authors.",
      "recover",
      "revert",
      "changes.",
      "order",
      "oo",
      "workflow",
      "designer",
      "need",
      "workspace.",
      "there",
      "several",
      "protocols",
      "secured",
      "account",
      "already",
      "unversioned",
      "i.e.",
      "saved",
      "locally",
      "part",
      "added",
      "local",
      "version",
      "repository.",
      "able",
      "commit",
      "push",
      "projects",
      "right",
      "structure",
      "appear",
      "pane",
      "designer.",
      "click",
      "button",
      "select",
      "dialog",
      "displayed.",
      "type.",
      "url",
      "field",
      "enter",
      "format",
      ".git.",
      "email",
      "address",
      "full",
      "name."
    ],
    "language": "en",
    "word_count": 91,
    "importance_score": 5.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "set up source control management for the project",
    "contentLower": "using the git functionality, you can either connect to a remote repository on a server (recommended), such as, stash, or connect to a shared file system. why do this? if you work in a multi-author environment, working with a source control management tool enables you to save your project in a centralized location and share content with other authors. it also enables you to recover or revert changes. in order to set up source control management (scm) for oo workflow designer, you need to import a git repository to your workspace. there are several protocols that you can use to import the repository: https (secured) ssh (secured) file system (not secured) - use this protocol if you do not have a git server account if you already have an unversioned project in your workspace (i.e., saved locally and not part of the git repository), when you import a repository, this project will be added to your local version of the repository. you will be able to commit and push this project to the remot",
    "keywordsLower": [
      "https://<domain>/<username>/<repository_name>.git",
      "amazonaws.com",
      "file://<hostname",
      "repo.bin",
      "codecommit.us",
      "repo.bat",
      "ssh://your-ssh-key-id@git-codecommit.us-east-2.amazonaws.com/v1/repos/repo",
      "set",
      "source",
      "control",
      "management",
      "project",
      "import",
      "git",
      "repository",
      "https",
      "protocol",
      "ssh",
      "aws",
      "codecommit",
      "file",
      "system",
      "manage",
      "repositories",
      "scm",
      "delete",
      "workspace",
      "edit",
      "related",
      "topics",
      "functionality",
      "either",
      "connect",
      "remote",
      "server",
      "recommended",
      "such",
      "stash",
      "shared",
      "system.",
      "work",
      "multi-author",
      "environment",
      "working",
      "tool",
      "enables",
      "save",
      "centralized",
      "location",
      "share",
      "content",
      "authors.",
      "recover",
      "revert",
      "changes.",
      "order",
      "oo",
      "workflow",
      "designer",
      "need",
      "workspace.",
      "there",
      "several",
      "protocols",
      "secured",
      "account",
      "already",
      "unversioned",
      "i.e.",
      "saved",
      "locally",
      "part",
      "added",
      "local",
      "version",
      "repository.",
      "able",
      "commit",
      "push",
      "projects",
      "right",
      "structure",
      "appear",
      "pane",
      "designer.",
      "click",
      "button",
      "select",
      "dialog",
      "displayed.",
      "type.",
      "url",
      "field",
      "enter",
      "format",
      ".git.",
      "email",
      "address",
      "full",
      "name."
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Set up the OO Workflow Designer Project",
    "content": "Before starting to create flows, you need to set up a project in which to work. Naming projects and folders Names must be unique within their folders. Names are not case-sensitive, so names such as \"Ping\" and \"ping\" are considered duplicates. However, when calling an item, make sure to use the correct case. Names can contain alphanumeric characters (A-Z, a-z, 0-9), hyphens ( - ), and underscores ( _ ). Project names and Folder names cannot contain white spaces, parentheses ( () ), square brackets ( [] ), and curly braces ( {} ). Names cannot be identical to the following Windows reserved words: CON, PRN, AUX, CLOCK$, COM1, COM2, COM3, COM4, COM5, COM6, COM7, COM8, COM9, NUL, LPT1, LPT2, LPT3, LPT4, LPT5, LPT6, LPT7, LPT8, LPT9 . Create a project In the Projects pane, click the Create New Project button. Enter a name for the project and click OK or press the Enter key. The new project is displayed in the Projects pane. The new project already includes the basic folder hierarchy: the Lib",
    "url": "setupdesignerproject",
    "filename": "setupdesignerproject",
    "headings": [
      "Naming projects and folders",
      "Create a project",
      "Manage the folders in the project",
      "Manage the flows, decisions, and operations in the project",
      "Project validation",
      "Related topics"
    ],
    "keywords": [
      "set",
      "oo",
      "workflow",
      "designer",
      "project",
      "naming",
      "projects",
      "folders",
      "create",
      "manage",
      "flows",
      "decisions",
      "operations",
      "validation",
      "related",
      "topics",
      "before",
      "starting",
      "need",
      "work.",
      "names",
      "unique",
      "folders.",
      "case-sensitive",
      "such",
      "ping",
      "considered",
      "duplicates.",
      "however",
      "calling",
      "item",
      "make",
      "sure",
      "correct",
      "case.",
      "contain",
      "alphanumeric",
      "characters",
      "a-z",
      "0-9",
      "hyphens",
      "underscores",
      "folder",
      "cannot",
      "white",
      "spaces",
      "parentheses",
      "square",
      "brackets",
      "curly",
      "braces",
      "identical",
      "following",
      "windows",
      "reserved",
      "words",
      "con",
      "prn",
      "aux",
      "clock",
      "com1",
      "com2",
      "com3",
      "com4",
      "com5",
      "com6",
      "com7",
      "com8",
      "com9",
      "nul",
      "lpt1",
      "lpt2",
      "lpt3",
      "lpt4",
      "lpt5",
      "lpt6",
      "lpt7",
      "lpt8",
      "lpt9",
      "pane",
      "click",
      "new",
      "button.",
      "enter",
      "name",
      "ok",
      "press",
      "key.",
      "displayed",
      "pane.",
      "already",
      "includes",
      "basic",
      "hierarchy",
      "library",
      "store",
      "configuration",
      "system",
      "properties",
      "property"
    ],
    "language": "en",
    "word_count": 116,
    "importance_score": 5.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "set up the oo workflow designer project",
    "contentLower": "before starting to create flows, you need to set up a project in which to work. naming projects and folders names must be unique within their folders. names are not case-sensitive, so names such as \"ping\" and \"ping\" are considered duplicates. however, when calling an item, make sure to use the correct case. names can contain alphanumeric characters (a-z, a-z, 0-9), hyphens ( - ), and underscores ( _ ). project names and folder names cannot contain white spaces, parentheses ( () ), square brackets ( [] ), and curly braces ( {} ). names cannot be identical to the following windows reserved words: con, prn, aux, clock$, com1, com2, com3, com4, com5, com6, com7, com8, com9, nul, lpt1, lpt2, lpt3, lpt4, lpt5, lpt6, lpt7, lpt8, lpt9 . create a project in the projects pane, click the create new project button. enter a name for the project and click ok or press the enter key. the new project is displayed in the projects pane. the new project already includes the basic folder hierarchy: the lib",
    "keywordsLower": [
      "set",
      "oo",
      "workflow",
      "designer",
      "project",
      "naming",
      "projects",
      "folders",
      "create",
      "manage",
      "flows",
      "decisions",
      "operations",
      "validation",
      "related",
      "topics",
      "before",
      "starting",
      "need",
      "work.",
      "names",
      "unique",
      "folders.",
      "case-sensitive",
      "such",
      "ping",
      "considered",
      "duplicates.",
      "however",
      "calling",
      "item",
      "make",
      "sure",
      "correct",
      "case.",
      "contain",
      "alphanumeric",
      "characters",
      "a-z",
      "0-9",
      "hyphens",
      "underscores",
      "folder",
      "cannot",
      "white",
      "spaces",
      "parentheses",
      "square",
      "brackets",
      "curly",
      "braces",
      "identical",
      "following",
      "windows",
      "reserved",
      "words",
      "con",
      "prn",
      "aux",
      "clock",
      "com1",
      "com2",
      "com3",
      "com4",
      "com5",
      "com6",
      "com7",
      "com8",
      "com9",
      "nul",
      "lpt1",
      "lpt2",
      "lpt3",
      "lpt4",
      "lpt5",
      "lpt6",
      "lpt7",
      "lpt8",
      "lpt9",
      "pane",
      "click",
      "new",
      "button.",
      "enter",
      "name",
      "ok",
      "press",
      "key.",
      "displayed",
      "pane.",
      "already",
      "includes",
      "basic",
      "hierarchy",
      "library",
      "store",
      "configuration",
      "system",
      "properties",
      "property"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Step details in AFL flows",
    "content": "The Step Inspector pane allows you to view and edit information about steps and transitions from an AFL flow. Note: Editing is only available for AFL flows from the Projects pane. The Dependencies pane flows remain read-only. Open step details in Step Inspector Select a step from any AFL flow, then click the Inspector tab at the bottom of the AFL canvas to expand or collapse the pane. The Step Inspector for steps allows you to view and edit data in the following tabs: Tab Description Inputs The Inputs tab displays the step inputs. Selecting a step input will populate the Inputs details pane on the right. Results The Results tab displays the outputs defined for a particular step. Display The Display tab shows if a prompt will display before this particular step is executed. If you enable this option, the information about the title of the prompt, prompt sizes, and prompt text will display in the corresponding boxes. Description The Description tab shows the step description. Advanced Th",
    "url": "stepinspectorwkfdesigner",
    "filename": "stepinspectorwkfdesigner",
    "headings": [
      "Open step details in Step Inspector",
      "Inputs tab GUI items",
      "Results tab GUI items",
      "Display tab",
      "Description tab",
      "Advanced tab GUI items",
      "Scriptlet tab",
      "View transition details in Step Inspector",
      "View parallel step details in Step Inspector"
    ],
    "keywords": [
      "3.14",
      "step",
      "details",
      "afl",
      "flows",
      "open",
      "inspector",
      "inputs",
      "tab",
      "gui",
      "items",
      "results",
      "display",
      "description",
      "advanced",
      "scriptlet",
      "view",
      "transition",
      "parallel",
      "pane",
      "allows",
      "edit",
      "information",
      "about",
      "steps",
      "transitions",
      "flow.",
      "note",
      "editing",
      "available",
      "projects",
      "pane.",
      "dependencies",
      "remain",
      "read-only.",
      "select",
      "any",
      "flow",
      "click",
      "bottom",
      "canvas",
      "expand",
      "collapse",
      "data",
      "following",
      "tabs",
      "displays",
      "inputs.",
      "selecting",
      "input",
      "populate",
      "right.",
      "outputs",
      "defined",
      "particular",
      "step.",
      "shows",
      "prompt",
      "before",
      "executed.",
      "enable",
      "option",
      "title",
      "sizes",
      "text",
      "corresponding",
      "boxes.",
      "description.",
      "options",
      "chosen",
      "persistence",
      "detailed",
      "concise",
      "execution",
      "settings",
      "regarding",
      "rerun",
      "point",
      "throttle",
      "latter",
      "displayed",
      "multi-instance",
      "steps.",
      "operation-specific",
      "such",
      "link",
      "actual",
      "name",
      "operation",
      "location",
      "path.",
      "contains",
      "script",
      "editor",
      "formatted",
      "javascript",
      "code",
      "added",
      "below",
      "item"
    ],
    "language": "en",
    "word_count": 111,
    "importance_score": 6.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "step details in afl flows",
    "contentLower": "the step inspector pane allows you to view and edit information about steps and transitions from an afl flow. note: editing is only available for afl flows from the projects pane. the dependencies pane flows remain read-only. open step details in step inspector select a step from any afl flow, then click the inspector tab at the bottom of the afl canvas to expand or collapse the pane. the step inspector for steps allows you to view and edit data in the following tabs: tab description inputs the inputs tab displays the step inputs. selecting a step input will populate the inputs details pane on the right. results the results tab displays the outputs defined for a particular step. display the display tab shows if a prompt will display before this particular step is executed. if you enable this option, the information about the title of the prompt, prompt sizes, and prompt text will display in the corresponding boxes. description the description tab shows the step description. advanced th",
    "keywordsLower": [
      "3.14",
      "step",
      "details",
      "afl",
      "flows",
      "open",
      "inspector",
      "inputs",
      "tab",
      "gui",
      "items",
      "results",
      "display",
      "description",
      "advanced",
      "scriptlet",
      "view",
      "transition",
      "parallel",
      "pane",
      "allows",
      "edit",
      "information",
      "about",
      "steps",
      "transitions",
      "flow.",
      "note",
      "editing",
      "available",
      "projects",
      "pane.",
      "dependencies",
      "remain",
      "read-only.",
      "select",
      "any",
      "flow",
      "click",
      "bottom",
      "canvas",
      "expand",
      "collapse",
      "data",
      "following",
      "tabs",
      "displays",
      "inputs.",
      "selecting",
      "input",
      "populate",
      "right.",
      "outputs",
      "defined",
      "particular",
      "step.",
      "shows",
      "prompt",
      "before",
      "executed.",
      "enable",
      "option",
      "title",
      "sizes",
      "text",
      "corresponding",
      "boxes.",
      "description.",
      "options",
      "chosen",
      "persistence",
      "detailed",
      "concise",
      "execution",
      "settings",
      "regarding",
      "rerun",
      "point",
      "throttle",
      "latter",
      "displayed",
      "multi-instance",
      "steps.",
      "operation-specific",
      "such",
      "link",
      "actual",
      "name",
      "operation",
      "location",
      "path.",
      "contains",
      "script",
      "editor",
      "formatted",
      "javascript",
      "code",
      "added",
      "below",
      "item"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Troubleshoot",
    "content": "This section helps you identify and resolve some issues that you might come across while using the suite. After detecting a problem, follow these steps: Check the Known issues section in the Release notes. Check for the availability of patches that may have fixed some known issues. Refer to the troubleshooting topics to find solutions. Check if the issue relates to a third-party product. Contact the respective vendor for support. If you are still unable to resolve the issue on your own, then analyze the SMAX logs and contact the support team. Related topics To see a list of known issues, see Known issues. To check for the latest patch for Service Management,see Release notes. For more information on how to access logs, see Where to find suite logs. To contact the support team, see Contact support.",
    "url": "troubleshoot",
    "filename": "troubleshoot",
    "headings": [
      "Related topics"
    ],
    "keywords": [
      "troubleshoot",
      "related",
      "topics",
      "section",
      "helps",
      "identify",
      "resolve",
      "issues",
      "come",
      "across",
      "while",
      "suite.",
      "after",
      "detecting",
      "problem",
      "follow",
      "steps",
      "check",
      "known",
      "release",
      "notes.",
      "availability",
      "patches",
      "fixed",
      "issues.",
      "refer",
      "troubleshooting",
      "find",
      "solutions.",
      "issue",
      "relates",
      "third-party",
      "product.",
      "contact",
      "respective",
      "vendor",
      "support.",
      "still",
      "unable",
      "own",
      "analyze",
      "smax",
      "logs",
      "support",
      "team.",
      "see",
      "list",
      "latest",
      "patch",
      "service",
      "management",
      "information",
      "access",
      "suite",
      "logs.",
      "team"
    ],
    "language": "en",
    "word_count": 82,
    "importance_score": 3.5,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "troubleshoot",
    "contentLower": "this section helps you identify and resolve some issues that you might come across while using the suite. after detecting a problem, follow these steps: check the known issues section in the release notes. check for the availability of patches that may have fixed some known issues. refer to the troubleshooting topics to find solutions. check if the issue relates to a third-party product. contact the respective vendor for support. if you are still unable to resolve the issue on your own, then analyze the smax logs and contact the support team. related topics to see a list of known issues, see known issues. to check for the latest patch for service management,see release notes. for more information on how to access logs, see where to find suite logs. to contact the support team, see contact support.",
    "keywordsLower": [
      "troubleshoot",
      "related",
      "topics",
      "section",
      "helps",
      "identify",
      "resolve",
      "issues",
      "come",
      "across",
      "while",
      "suite.",
      "after",
      "detecting",
      "problem",
      "follow",
      "steps",
      "check",
      "known",
      "release",
      "notes.",
      "availability",
      "patches",
      "fixed",
      "issues.",
      "refer",
      "troubleshooting",
      "find",
      "solutions.",
      "issue",
      "relates",
      "third-party",
      "product.",
      "contact",
      "respective",
      "vendor",
      "support.",
      "still",
      "unable",
      "own",
      "analyze",
      "smax",
      "logs",
      "support",
      "team.",
      "see",
      "list",
      "latest",
      "patch",
      "service",
      "management",
      "information",
      "access",
      "suite",
      "logs.",
      "team"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Troubleshoot installation",
    "content": "This section provides the following troubleshooting topics. 0 of X required images are available in the registry Can't export the NFS volumes Can't log in to Docker Hub Can't mount an NFS server from a worker node Disk IOPS spikes on AKS worker nodes The performance of Azure File is poor in West US 2 Fail to configure a load balancer (AKS) \"NodeInstanceRole is not authorized to perform\" error during the installation on AWS Suite installation failed Can't reinstall the suite Bastion node cannot connect to the EKS cluster",
    "url": "troubleshootinstall",
    "filename": "troubleshootinstall",
    "headings": [],
    "keywords": [
      "troubleshoot",
      "installation",
      "section",
      "provides",
      "following",
      "troubleshooting",
      "topics.",
      "required",
      "images",
      "available",
      "registry",
      "export",
      "nfs",
      "volumes",
      "log",
      "docker",
      "hub",
      "mount",
      "server",
      "worker",
      "node",
      "disk",
      "iops",
      "spikes",
      "aks",
      "nodes",
      "performance",
      "azure",
      "file",
      "poor",
      "west",
      "fail",
      "configure",
      "load",
      "balancer",
      "nodeinstancerole",
      "authorized",
      "perform",
      "error",
      "during",
      "aws",
      "suite",
      "failed",
      "reinstall",
      "bastion",
      "cannot",
      "connect",
      "eks",
      "cluster"
    ],
    "language": "en",
    "word_count": 63,
    "importance_score": 2.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "troubleshoot installation",
    "contentLower": "this section provides the following troubleshooting topics. 0 of x required images are available in the registry can't export the nfs volumes can't log in to docker hub can't mount an nfs server from a worker node disk iops spikes on aks worker nodes the performance of azure file is poor in west us 2 fail to configure a load balancer (aks) \"nodeinstancerole is not authorized to perform\" error during the installation on aws suite installation failed can't reinstall the suite bastion node cannot connect to the eks cluster",
    "keywordsLower": [
      "troubleshoot",
      "installation",
      "section",
      "provides",
      "following",
      "troubleshooting",
      "topics.",
      "required",
      "images",
      "available",
      "registry",
      "export",
      "nfs",
      "volumes",
      "log",
      "docker",
      "hub",
      "mount",
      "server",
      "worker",
      "node",
      "disk",
      "iops",
      "spikes",
      "aks",
      "nodes",
      "performance",
      "azure",
      "file",
      "poor",
      "west",
      "fail",
      "configure",
      "load",
      "balancer",
      "nodeinstancerole",
      "authorized",
      "perform",
      "error",
      "during",
      "aws",
      "suite",
      "failed",
      "reinstall",
      "bastion",
      "cannot",
      "connect",
      "eks",
      "cluster"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "The performance of Azure File is poor in West US 2",
    "content": "When you are deploying the suite on Azure and use Azure Files as the storage service, Azure File’s performance might be poorer in the West US 2 region than in other regions. This might cause the suite installation to fail or slow down the system response after installation. Cause The cause of this issue is unknown. Solution 1 Use Azure NetApp Files as the storage service instead which has more stable and higher performance. Solution 2 To ensure stable performance in West US 2, you can provision an Azure file share of a larger size. Related topics Sizing on AKS",
    "url": "azurefileregion",
    "filename": "azurefileregion",
    "headings": [
      "Cause",
      "Solution 1",
      "Solution 2",
      "Related topics"
    ],
    "keywords": [
      "performance",
      "azure",
      "file",
      "poor",
      "west",
      "cause",
      "solution",
      "related",
      "topics",
      "deploying",
      "suite",
      "files",
      "storage",
      "service",
      "poorer",
      "region",
      "regions.",
      "installation",
      "fail",
      "slow",
      "system",
      "response",
      "after",
      "installation.",
      "issue",
      "unknown.",
      "netapp",
      "instead",
      "stable",
      "higher",
      "performance.",
      "ensure",
      "provision",
      "share",
      "larger",
      "size.",
      "sizing",
      "aks"
    ],
    "language": "en",
    "word_count": 63,
    "importance_score": 3.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "the performance of azure file is poor in west us 2",
    "contentLower": "when you are deploying the suite on azure and use azure files as the storage service, azure file’s performance might be poorer in the west us 2 region than in other regions. this might cause the suite installation to fail or slow down the system response after installation. cause the cause of this issue is unknown. solution 1 use azure netapp files as the storage service instead which has more stable and higher performance. solution 2 to ensure stable performance in west us 2, you can provision an azure file share of a larger size. related topics sizing on aks",
    "keywordsLower": [
      "performance",
      "azure",
      "file",
      "poor",
      "west",
      "cause",
      "solution",
      "related",
      "topics",
      "deploying",
      "suite",
      "files",
      "storage",
      "service",
      "poorer",
      "region",
      "regions.",
      "installation",
      "fail",
      "slow",
      "system",
      "response",
      "after",
      "installation.",
      "issue",
      "unknown.",
      "netapp",
      "instead",
      "stable",
      "higher",
      "performance.",
      "ensure",
      "provision",
      "share",
      "larger",
      "size.",
      "sizing",
      "aks"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Suite installation failed",
    "content": "The suite installation failed. Additionally, when you locate the failed pod and then enter the pod log, the following error appears: - Failed to execute statement: REVOKE CONNECT ON DATABASE xservices_rms FROM public; ALTER DATABASE xservices_rms CONNECTION LIMIT 0; SELECT pg_terminate_backend(pid) FROM pg_stat_activity WHERE datname = 'xservices_rms' and pid <> pg_backend_pid(); connected with db=maas_admin user: maas_admin ERROR: must be a superuser to terminate superuser process org.postgresql.util.PSQLException: ERROR: must be a superuser to terminate superuser process or org.springframework.jdbc.UncategorizedSQLException: StatementCallback; uncategorized SQLException for SQL [CREATE DATABASE \"xservices_rms\" ENCODING = 'UTF8' TEMPLATE = maas_template LC_COLLATE = 'en_US.UTF-8' LC_CTYPE = 'en_US.UTF-8' CONNECTION LIMIT = -1]; SQL state [55006]; error code [0]; ERROR: source database \"maas_template\" is being accessed by other users Detail: There is 1 other session using the database.",
    "url": "suiteinstallationfailed",
    "filename": "suiteinstallationfailed",
    "headings": [
      "Cause",
      "Solution"
    ],
    "keywords": [
      "en_US.UTF",
      "postgresql.util",
      "springframework.jdbc",
      "suite",
      "installation",
      "failed",
      "cause",
      "solution",
      "failed.",
      "additionally",
      "locate",
      "pod",
      "enter",
      "log",
      "following",
      "error",
      "appears",
      "execute",
      "statement",
      "revoke",
      "connect",
      "database",
      "public",
      "alter",
      "connection",
      "limit",
      "select",
      "pid",
      "datname",
      "connected",
      "db",
      "user",
      "superuser",
      "terminate",
      "process",
      "org.postgresql.util.psqlexception",
      "org.springframework.jdbc.uncategorizedsqlexception",
      "statementcallback",
      "uncategorized",
      "sqlexception",
      "sql",
      "create",
      "encoding",
      "utf8",
      "template",
      "-1",
      "state",
      "55006",
      "code",
      "source",
      "accessed",
      "users",
      "detail",
      "there",
      "session",
      "database.",
      "nested",
      "exception",
      "note",
      "commands",
      "view",
      "kubectl",
      "get",
      "pods",
      "--all-namespaces",
      "--show-all",
      "grep",
      "xruntime",
      "logs",
      "-f",
      "itom-xruntime-",
      "-n",
      "issue",
      "occurs",
      "because",
      "activities",
      "follow",
      "steps",
      "solve",
      "postgresql",
      "postgres",
      "username",
      "password",
      "run",
      "command",
      "xie",
      "scheduler",
      "see",
      "belong",
      "usernames",
      "uninstall",
      "suite.",
      "again",
      "kill",
      "all",
      "reinstall"
    ],
    "language": "en",
    "word_count": 90,
    "importance_score": 4.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "suite installation failed",
    "contentLower": "the suite installation failed. additionally, when you locate the failed pod and then enter the pod log, the following error appears: - failed to execute statement: revoke connect on database xservices_rms from public; alter database xservices_rms connection limit 0; select pg_terminate_backend(pid) from pg_stat_activity where datname = 'xservices_rms' and pid <> pg_backend_pid(); connected with db=maas_admin user: maas_admin error: must be a superuser to terminate superuser process org.postgresql.util.psqlexception: error: must be a superuser to terminate superuser process or org.springframework.jdbc.uncategorizedsqlexception: statementcallback; uncategorized sqlexception for sql [create database \"xservices_rms\" encoding = 'utf8' template = maas_template lc_collate = 'en_us.utf-8' lc_ctype = 'en_us.utf-8' connection limit = -1]; sql state [55006]; error code [0]; error: source database \"maas_template\" is being accessed by other users detail: there is 1 other session using the database.",
    "keywordsLower": [
      "en_us.utf",
      "postgresql.util",
      "springframework.jdbc",
      "suite",
      "installation",
      "failed",
      "cause",
      "solution",
      "failed.",
      "additionally",
      "locate",
      "pod",
      "enter",
      "log",
      "following",
      "error",
      "appears",
      "execute",
      "statement",
      "revoke",
      "connect",
      "database",
      "public",
      "alter",
      "connection",
      "limit",
      "select",
      "pid",
      "datname",
      "connected",
      "db",
      "user",
      "superuser",
      "terminate",
      "process",
      "org.postgresql.util.psqlexception",
      "org.springframework.jdbc.uncategorizedsqlexception",
      "statementcallback",
      "uncategorized",
      "sqlexception",
      "sql",
      "create",
      "encoding",
      "utf8",
      "template",
      "-1",
      "state",
      "55006",
      "code",
      "source",
      "accessed",
      "users",
      "detail",
      "there",
      "session",
      "database.",
      "nested",
      "exception",
      "note",
      "commands",
      "view",
      "kubectl",
      "get",
      "pods",
      "--all-namespaces",
      "--show-all",
      "grep",
      "xruntime",
      "logs",
      "-f",
      "itom-xruntime-",
      "-n",
      "issue",
      "occurs",
      "because",
      "activities",
      "follow",
      "steps",
      "solve",
      "postgresql",
      "postgres",
      "username",
      "password",
      "run",
      "command",
      "xie",
      "scheduler",
      "see",
      "belong",
      "usernames",
      "uninstall",
      "suite.",
      "again",
      "kill",
      "all",
      "reinstall"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Troubleshoot upgrade",
    "content": "This section provides the following troubleshooting topics: \"Failed to find CDF_HOME\" error Failed to launch controller with Init:Error for EKS upgrade Failed to pull image because docker storage is full Platform pod fails to start after OMT upgrade The Update button on OMT Management Portal is not working well Suite upgrade fails due to hardware resource shortage \"Device is busy\" or \"waiting for lo/CPU to become free\" error messages during upgrade Jobs don't run after a OMT upgrade \"Waiting for upgrade finished timeout\" error during OMT upgrade Tenant content validation fails System status check fails OMT service status check fails Cluster resource usage check issue Tenant upgrade fails because license has expired Post-upgrade actions failed Tenant upgrade failed because LWSSO token was not found",
    "url": "troubleshootupgrade",
    "filename": "troubleshootupgrade",
    "headings": [],
    "keywords": [
      "troubleshoot",
      "upgrade",
      "section",
      "provides",
      "following",
      "troubleshooting",
      "topics",
      "failed",
      "find",
      "error",
      "launch",
      "controller",
      "init",
      "eks",
      "pull",
      "image",
      "because",
      "docker",
      "storage",
      "full",
      "platform",
      "pod",
      "fails",
      "start",
      "after",
      "omt",
      "update",
      "button",
      "management",
      "portal",
      "working",
      "well",
      "suite",
      "due",
      "hardware",
      "resource",
      "shortage",
      "device",
      "busy",
      "waiting",
      "lo",
      "cpu",
      "become",
      "free",
      "messages",
      "during",
      "jobs",
      "don",
      "run",
      "finished",
      "timeout",
      "tenant",
      "content",
      "validation",
      "system",
      "status",
      "check",
      "service",
      "cluster",
      "usage",
      "issue",
      "license",
      "expired",
      "post-upgrade",
      "actions",
      "lwsso",
      "token",
      "found"
    ],
    "language": "en",
    "word_count": 106,
    "importance_score": 3.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "troubleshoot upgrade",
    "contentLower": "this section provides the following troubleshooting topics: \"failed to find cdf_home\" error failed to launch controller with init:error for eks upgrade failed to pull image because docker storage is full platform pod fails to start after omt upgrade the update button on omt management portal is not working well suite upgrade fails due to hardware resource shortage \"device is busy\" or \"waiting for lo/cpu to become free\" error messages during upgrade jobs don't run after a omt upgrade \"waiting for upgrade finished timeout\" error during omt upgrade tenant content validation fails system status check fails omt service status check fails cluster resource usage check issue tenant upgrade fails because license has expired post-upgrade actions failed tenant upgrade failed because lwsso token was not found",
    "keywordsLower": [
      "troubleshoot",
      "upgrade",
      "section",
      "provides",
      "following",
      "troubleshooting",
      "topics",
      "failed",
      "find",
      "error",
      "launch",
      "controller",
      "init",
      "eks",
      "pull",
      "image",
      "because",
      "docker",
      "storage",
      "full",
      "platform",
      "pod",
      "fails",
      "start",
      "after",
      "omt",
      "update",
      "button",
      "management",
      "portal",
      "working",
      "well",
      "suite",
      "due",
      "hardware",
      "resource",
      "shortage",
      "device",
      "busy",
      "waiting",
      "lo",
      "cpu",
      "become",
      "free",
      "messages",
      "during",
      "jobs",
      "don",
      "run",
      "finished",
      "timeout",
      "tenant",
      "content",
      "validation",
      "system",
      "status",
      "check",
      "service",
      "cluster",
      "usage",
      "issue",
      "license",
      "expired",
      "post-upgrade",
      "actions",
      "lwsso",
      "token",
      "found"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "The itom-xruntime-upgrade-tenants pod fails",
    "content": "The itom-xruntime-upgrade-tenants pod fails, and you can find the following or a similar error message in the log file. 2025-05-15T10:32:23.227+0200 INFO ThreadPoolExecutor-0_3-140391310456384 Round No.90 - tenant 477204788, actualStatus is Upgrade, initialStatus is Active, upgradeStatus is RUNNING, content version is v29 2025-05-15T10:32:23.228+0200 ERROR ThreadPoolExecutor-0_3-140391310456384 Round No.90 - Tenant 477204788 upgrade content failed! Cause The default timeout and backOffLimit settings in the suite-upgrade-tenant job were inadequate for handling upgrades of instances with large data volumes. Solution Make the TENANT_UPGRADE_TIMEOUT_MINUTE  and backOffLimit configurable. To customize the xruntime-upgrade-tenants job execution resiliency, follow the steps: Step 1: Create a custom YAML named itom-xruntime-upgrade-tenants.yaml, configure backoffLimit as 6 (or as needed) and tenantUpgradeTimeoutMinute as 360(or as needed) xruntime: xruntime-upgrade-tenants: deployment: upgrade",
    "url": "increasetenantupgradetimeout",
    "filename": "increasetenantupgradetimeout",
    "headings": [
      "Cause",
      "Solution"
    ],
    "keywords": [
      "No.90",
      "23.228",
      "chart.tgz",
      "tenants.yaml",
      "23.227",
      "values.yaml",
      "itsma.yaml",
      "itom-xruntime-upgrade-tenants",
      "pod",
      "fails",
      "cause",
      "solution",
      "find",
      "following",
      "similar",
      "error",
      "message",
      "log",
      "file.",
      "2025-05-15t10",
      "32",
      "0200",
      "info",
      "round",
      "tenant",
      "477204788",
      "actualstatus",
      "upgrade",
      "initialstatus",
      "active",
      "upgradestatus",
      "running",
      "content",
      "version",
      "v29",
      "failed",
      "default",
      "timeout",
      "backofflimit",
      "settings",
      "suite-upgrade-tenant",
      "job",
      "inadequate",
      "handling",
      "upgrades",
      "instances",
      "large",
      "data",
      "volumes.",
      "make",
      "configurable.",
      "customize",
      "xruntime-upgrade-tenants",
      "execution",
      "resiliency",
      "follow",
      "steps",
      "step",
      "create",
      "custom",
      "yaml",
      "named",
      "itom-xruntime-upgrade-tenants.yaml",
      "configure",
      "needed",
      "tenantupgradetimeoutminute",
      "360",
      "xruntime",
      "deployment",
      "upgradetenant",
      "run",
      "command",
      "export",
      "existing",
      "itsma",
      "installation",
      "helm",
      "get",
      "values",
      "-n",
      "-o",
      "retry",
      "customized",
      "config",
      "esm-chart.tgz",
      "-f",
      "example",
      "sma",
      "sma-values.yaml"
    ],
    "language": "en",
    "word_count": 89,
    "importance_score": 4.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "the itom-xruntime-upgrade-tenants pod fails",
    "contentLower": "the itom-xruntime-upgrade-tenants pod fails, and you can find the following or a similar error message in the log file. 2025-05-15t10:32:23.227+0200 info threadpoolexecutor-0_3-140391310456384 round no.90 - tenant 477204788, actualstatus is upgrade, initialstatus is active, upgradestatus is running, content version is v29 2025-05-15t10:32:23.228+0200 error threadpoolexecutor-0_3-140391310456384 round no.90 - tenant 477204788 upgrade content failed! cause the default timeout and backofflimit settings in the suite-upgrade-tenant job were inadequate for handling upgrades of instances with large data volumes. solution make the tenant_upgrade_timeout_minute  and backofflimit configurable. to customize the xruntime-upgrade-tenants job execution resiliency, follow the steps: step 1: create a custom yaml named itom-xruntime-upgrade-tenants.yaml, configure backofflimit as 6 (or as needed) and tenantupgradetimeoutminute as 360(or as needed) xruntime: xruntime-upgrade-tenants: deployment: upgrade",
    "keywordsLower": [
      "no.90",
      "23.228",
      "chart.tgz",
      "tenants.yaml",
      "23.227",
      "values.yaml",
      "itsma.yaml",
      "itom-xruntime-upgrade-tenants",
      "pod",
      "fails",
      "cause",
      "solution",
      "find",
      "following",
      "similar",
      "error",
      "message",
      "log",
      "file.",
      "2025-05-15t10",
      "32",
      "0200",
      "info",
      "round",
      "tenant",
      "477204788",
      "actualstatus",
      "upgrade",
      "initialstatus",
      "active",
      "upgradestatus",
      "running",
      "content",
      "version",
      "v29",
      "failed",
      "default",
      "timeout",
      "backofflimit",
      "settings",
      "suite-upgrade-tenant",
      "job",
      "inadequate",
      "handling",
      "upgrades",
      "instances",
      "large",
      "data",
      "volumes.",
      "make",
      "configurable.",
      "customize",
      "xruntime-upgrade-tenants",
      "execution",
      "resiliency",
      "follow",
      "steps",
      "step",
      "create",
      "custom",
      "yaml",
      "named",
      "itom-xruntime-upgrade-tenants.yaml",
      "configure",
      "needed",
      "tenantupgradetimeoutminute",
      "360",
      "xruntime",
      "deployment",
      "upgradetenant",
      "run",
      "command",
      "export",
      "existing",
      "itsma",
      "installation",
      "helm",
      "get",
      "values",
      "-n",
      "-o",
      "retry",
      "customized",
      "config",
      "esm-chart.tgz",
      "-f",
      "example",
      "sma",
      "sma-values.yaml"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "SAM Deployment Failed Post FP Upgrade",
    "content": "If the SAM Day 2 feature enablement (via helm upgrade) fails with an error, check the error log file. The following is the screenshot of the error log file. Added here for your reference: Solution In the sam-ui-deployment pods check for the password: ssm-user@ip- ~]$ kubectl exec -it sam-ui-deployment-d59f5f7f4-85rls -n itsma-krc9q -c sam-ui bash bash-5.1$ get_secret itom_itsma_db_password_secret_key PASS=Password1 bash-5.1$ get_secret itom_itsma_dba_password_secret_key PASS=postgres If the passwords shown in step 1 are not valid, please update the password using the following commands: bash-5.1$ update_secret itom_itsma_db_password_secret_key <valid_password> itom-sam bash-5.1$ update_secret itom_itsma_dba_password_secret_key <valid_password> itom-sam Retry helm upgrade with the values where sam capability is set as true.",
    "url": "samdeployfailedpostupgrade",
    "filename": "samdeployfailedpostupgrade",
    "headings": [
      "Solution"
    ],
    "keywords": [
      "5.1",
      "sam",
      "deployment",
      "failed",
      "post",
      "fp",
      "upgrade",
      "solution",
      "day",
      "feature",
      "enablement",
      "via",
      "helm",
      "fails",
      "error",
      "check",
      "log",
      "file.",
      "following",
      "screenshot",
      "added",
      "here",
      "reference",
      "sam-ui-deployment",
      "pods",
      "password",
      "ssm-user",
      "ip-",
      "kubectl",
      "exec",
      "-it",
      "sam-ui-deployment-d59f5f7f4-85rls",
      "-n",
      "itsma-krc9q",
      "-c",
      "sam-ui",
      "bash",
      "bash-5.1",
      "pass",
      "password1",
      "postgres",
      "passwords",
      "shown",
      "step",
      "valid",
      "please",
      "update",
      "commands",
      "itom-sam",
      "retry",
      "values",
      "capability",
      "set",
      "true."
    ],
    "language": "en",
    "word_count": 80,
    "importance_score": 2.5,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "sam deployment failed post fp upgrade",
    "contentLower": "if the sam day 2 feature enablement (via helm upgrade) fails with an error, check the error log file. the following is the screenshot of the error log file. added here for your reference: solution in the sam-ui-deployment pods check for the password: ssm-user@ip- ~]$ kubectl exec -it sam-ui-deployment-d59f5f7f4-85rls -n itsma-krc9q -c sam-ui bash bash-5.1$ get_secret itom_itsma_db_password_secret_key pass=password1 bash-5.1$ get_secret itom_itsma_dba_password_secret_key pass=postgres if the passwords shown in step 1 are not valid, please update the password using the following commands: bash-5.1$ update_secret itom_itsma_db_password_secret_key <valid_password> itom-sam bash-5.1$ update_secret itom_itsma_dba_password_secret_key <valid_password> itom-sam retry helm upgrade with the values where sam capability is set as true.",
    "keywordsLower": [
      "5.1",
      "sam",
      "deployment",
      "failed",
      "post",
      "fp",
      "upgrade",
      "solution",
      "day",
      "feature",
      "enablement",
      "via",
      "helm",
      "fails",
      "error",
      "check",
      "log",
      "file.",
      "following",
      "screenshot",
      "added",
      "here",
      "reference",
      "sam-ui-deployment",
      "pods",
      "password",
      "ssm-user",
      "ip-",
      "kubectl",
      "exec",
      "-it",
      "sam-ui-deployment-d59f5f7f4-85rls",
      "-n",
      "itsma-krc9q",
      "-c",
      "sam-ui",
      "bash",
      "bash-5.1",
      "pass",
      "password1",
      "postgres",
      "passwords",
      "shown",
      "step",
      "valid",
      "please",
      "update",
      "commands",
      "itom-sam",
      "retry",
      "values",
      "capability",
      "set",
      "true."
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Tenant upgrade fails with \"Duplicate key violation: field name 'Id' \" error",
    "content": "Tenant upgrade fails during an upgrade. The upgrade fails with a error in the itom-xruntime-platform-xxxxxxxxxx-xxxxx-2024-03-26/maas/maas_upg_step_audit.log log file as below: INFO |shared-pool-1-thread-6|1xx.xx.xx.xxx|platform-webapp|bo-integration@dummy.com||857561481|RID-d1e6e191-0e56-451f-8df0-8101c15a6b4e|RID-d1e6e191-0e56-451f-8df0-8101c15a6b4e| AviatorModelContentUpgrade->AviatorModelContentUpgrade : AviatorModelUpgrade batch insert AviatorModel failed, exception message: Duplicate key violation: field name 'Id' INFO |shared-pool-1-thread-5|1xx.xx.xx.xxx|platform-webapp|bo-integration@dummy.com||857561481|RID-0a4ecaf0-eab6-4e62-8769-5e5fea306a51|RID-0a4ecaf0-eab6-4e62-8769-5e5fea306a51| About to copy workflow of entity type [AviatorModel] of targetVersion: [v26] Cause When performing insert operation for entities_<tenant_id>, EMS service will allocate an entity ID. If this ID is being used by other record, a key violation error occurs. Solution This solution will check next val",
    "url": "upgradefailedduplicatekeyerror",
    "filename": "upgradefailedduplicatekeyerror",
    "headings": [
      "Cause",
      "Solution"
    ],
    "keywords": [
      "dummy.com",
      "1xx.xx",
      "xx.xxx",
      "tenant_list.json",
      "http://$svc_ip:8090/rest/operator/TenantManagement/tenants",
      "tenant_ids.log",
      "check_tenant_sequence.sh",
      "maas_upg_step_audit.log",
      "http://$svc_ip:8090/auth/authentication-endpoint/authenticate/token",
      "tenant",
      "upgrade",
      "fails",
      "duplicate",
      "key",
      "violation",
      "field",
      "name",
      "id",
      "error",
      "cause",
      "solution",
      "during",
      "upgrade.",
      "itom-xruntime-platform-xxxxxxxxxx-xxxxx-2024-03-26",
      "maas",
      "log",
      "file",
      "below",
      "info",
      "shared-pool-1-thread-6",
      "1xx.xx.xx.xxx",
      "platform-webapp",
      "bo-integration",
      "857561481",
      "rid-d1e6e191-0e56-451f-8df0-8101c15a6b4e",
      "aviatormodelcontentupgrade-",
      "aviatormodelcontentupgrade",
      "aviatormodelupgrade",
      "batch",
      "insert",
      "aviatormodel",
      "failed",
      "exception",
      "message",
      "shared-pool-1-thread-5",
      "rid-0a4ecaf0-eab6-4e62-8769-5e5fea306a51",
      "about",
      "copy",
      "workflow",
      "entity",
      "type",
      "targetversion",
      "v26",
      "performing",
      "operation",
      "ems",
      "service",
      "allocate",
      "id.",
      "record",
      "occurs.",
      "check",
      "next",
      "value",
      "sequence",
      "make",
      "sure",
      "allocated",
      "another",
      "record.",
      "perform",
      "system",
      "diagnosis.",
      "set",
      "sma",
      "toolkit",
      "see",
      "support",
      "assistant",
      "details.",
      "open",
      "navigate",
      "tmp",
      "folder",
      "following",
      "command.",
      "kubectl",
      "exec",
      "-it",
      "get",
      "pods",
      "-n",
      "ns",
      "grep",
      "itsma",
      "cut",
      "-f1",
      "-d",
      "itom-toolkit",
      "awk"
    ],
    "language": "en",
    "word_count": 86,
    "importance_score": 1.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "tenant upgrade fails with \"duplicate key violation: field name 'id' \" error",
    "contentLower": "tenant upgrade fails during an upgrade. the upgrade fails with a error in the itom-xruntime-platform-xxxxxxxxxx-xxxxx-2024-03-26/maas/maas_upg_step_audit.log log file as below: info |shared-pool-1-thread-6|1xx.xx.xx.xxx|platform-webapp|bo-integration@dummy.com||857561481|rid-d1e6e191-0e56-451f-8df0-8101c15a6b4e|rid-d1e6e191-0e56-451f-8df0-8101c15a6b4e| aviatormodelcontentupgrade->aviatormodelcontentupgrade : aviatormodelupgrade batch insert aviatormodel failed, exception message: duplicate key violation: field name 'id' info |shared-pool-1-thread-5|1xx.xx.xx.xxx|platform-webapp|bo-integration@dummy.com||857561481|rid-0a4ecaf0-eab6-4e62-8769-5e5fea306a51|rid-0a4ecaf0-eab6-4e62-8769-5e5fea306a51| about to copy workflow of entity type [aviatormodel] of targetversion: [v26] cause when performing insert operation for entities_<tenant_id>, ems service will allocate an entity id. if this id is being used by other record, a key violation error occurs. solution this solution will check next val",
    "keywordsLower": [
      "dummy.com",
      "1xx.xx",
      "xx.xxx",
      "tenant_list.json",
      "http://$svc_ip:8090/rest/operator/tenantmanagement/tenants",
      "tenant_ids.log",
      "check_tenant_sequence.sh",
      "maas_upg_step_audit.log",
      "http://$svc_ip:8090/auth/authentication-endpoint/authenticate/token",
      "tenant",
      "upgrade",
      "fails",
      "duplicate",
      "key",
      "violation",
      "field",
      "name",
      "id",
      "error",
      "cause",
      "solution",
      "during",
      "upgrade.",
      "itom-xruntime-platform-xxxxxxxxxx-xxxxx-2024-03-26",
      "maas",
      "log",
      "file",
      "below",
      "info",
      "shared-pool-1-thread-6",
      "1xx.xx.xx.xxx",
      "platform-webapp",
      "bo-integration",
      "857561481",
      "rid-d1e6e191-0e56-451f-8df0-8101c15a6b4e",
      "aviatormodelcontentupgrade-",
      "aviatormodelcontentupgrade",
      "aviatormodelupgrade",
      "batch",
      "insert",
      "aviatormodel",
      "failed",
      "exception",
      "message",
      "shared-pool-1-thread-5",
      "rid-0a4ecaf0-eab6-4e62-8769-5e5fea306a51",
      "about",
      "copy",
      "workflow",
      "entity",
      "type",
      "targetversion",
      "v26",
      "performing",
      "operation",
      "ems",
      "service",
      "allocate",
      "id.",
      "record",
      "occurs.",
      "check",
      "next",
      "value",
      "sequence",
      "make",
      "sure",
      "allocated",
      "another",
      "record.",
      "perform",
      "system",
      "diagnosis.",
      "set",
      "sma",
      "toolkit",
      "see",
      "support",
      "assistant",
      "details.",
      "open",
      "navigate",
      "tmp",
      "folder",
      "following",
      "command.",
      "kubectl",
      "exec",
      "-it",
      "get",
      "pods",
      "-n",
      "ns",
      "grep",
      "itsma",
      "cut",
      "-f1",
      "-d",
      "itom-toolkit",
      "awk"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Tenant upgrade fails with \"CustomizedTabConfigRestEndPointUpgrader\" error",
    "content": "The suite upgrade fails at the tenant upgrade stage. In the log file, there's a \"CustomizedTabConfigRestEndPointUpgrader\" error. Cause There's a custom field added in Grid columns under the Customized Tab setting, but this field has already been deleted from Studio. Solution Contact your support team to help skipping the \"CustomizedTabConfigRestEndPointUpgrader\" step during content upgrade.",
    "url": "upgradefailcustomizedtaberror",
    "filename": "upgradefailcustomizedtaberror",
    "headings": [
      "Cause",
      "Solution"
    ],
    "keywords": [
      "tenant",
      "upgrade",
      "fails",
      "customizedtabconfigrestendpointupgrader",
      "error",
      "cause",
      "solution",
      "suite",
      "stage.",
      "log",
      "file",
      "there",
      "error.",
      "custom",
      "field",
      "added",
      "grid",
      "columns",
      "under",
      "customized",
      "tab",
      "setting",
      "already",
      "deleted",
      "studio.",
      "contact",
      "support",
      "team",
      "help",
      "skipping",
      "step",
      "during",
      "content",
      "upgrade."
    ],
    "language": "en",
    "word_count": 44,
    "importance_score": 2.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "tenant upgrade fails with \"customizedtabconfigrestendpointupgrader\" error",
    "contentLower": "the suite upgrade fails at the tenant upgrade stage. in the log file, there's a \"customizedtabconfigrestendpointupgrader\" error. cause there's a custom field added in grid columns under the customized tab setting, but this field has already been deleted from studio. solution contact your support team to help skipping the \"customizedtabconfigrestendpointupgrader\" step during content upgrade.",
    "keywordsLower": [
      "tenant",
      "upgrade",
      "fails",
      "customizedtabconfigrestendpointupgrader",
      "error",
      "cause",
      "solution",
      "suite",
      "stage.",
      "log",
      "file",
      "there",
      "error.",
      "custom",
      "field",
      "added",
      "grid",
      "columns",
      "under",
      "customized",
      "tab",
      "setting",
      "already",
      "deleted",
      "studio.",
      "contact",
      "support",
      "team",
      "help",
      "skipping",
      "step",
      "during",
      "content",
      "upgrade."
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Suite upgrade fails and the suite pod stays in a Pending state",
    "content": "When you try to upgrade a suite, the suite upgrade pod stays in the Pending state. Additionally, you may notice that some volumes are missing from the environment. Cause This issue occurs because an unknown service deletes the volumes. Solution Copy the following text to a file and name it volumes.json. Update the placeholders with the actual values. [{ \"volume_name\": <the volume name> \"nfs_server\": <the NFS server IP/host to create the PV> \"nfs_path\": <the path to the NFS server to create the PV> \"storage_class\": <the storage class name> \"storage_capability\": <the storage capability of the volume> }] For example: [{ \"volume_name\":\"demo1\", \"nfs_server\":\"16.111.xxx.xxx\", \"nfs_path\":\"/var/vols/itom/demo1\", \"storage_class\":\"cdf-default\", \"storage_capability\":\"1Mi\" },{ \"volume_name\":\"demo2\", \"nfs_server\":\"16.111.xxx.xxx\", \"nfs_path\":\"/var/vols/itom/demo2\", \"storage_class\":\"cdf-default\", \"storage_capability\":\"1Mi\" }] Run the following command to change the permission of the file: chmod 744 ",
    "url": "suiteupgradefailpodspending",
    "filename": "suiteupgradefailpodspending",
    "headings": [
      "Cause",
      "Solution"
    ],
    "keywords": [
      "16.111",
      "xxx.xxx",
      "createVolumes.sh",
      "volumes.json",
      "suite",
      "upgrade",
      "fails",
      "pod",
      "stays",
      "pending",
      "state",
      "cause",
      "solution",
      "try",
      "state.",
      "additionally",
      "notice",
      "volumes",
      "missing",
      "environment.",
      "issue",
      "occurs",
      "because",
      "unknown",
      "service",
      "deletes",
      "volumes.",
      "copy",
      "following",
      "text",
      "file",
      "name",
      "volumes.json.",
      "update",
      "placeholders",
      "actual",
      "values.",
      "example",
      "demo1",
      "16.111.xxx.xxx",
      "var",
      "vols",
      "itom",
      "cdf-default",
      "1mi",
      "demo2",
      "run",
      "command",
      "change",
      "permission",
      "chmod",
      "744",
      "bin",
      "bash",
      "usage",
      "echo",
      "--config",
      "--namespace",
      "create",
      "all",
      "exit",
      "while",
      "-z",
      "case",
      "parameter",
      "requires",
      "value.",
      "fi",
      "shift",
      "esac",
      "-h",
      "--help",
      "help",
      "done",
      "createvolumes",
      "start",
      "namespace",
      "local",
      "cat",
      "jq",
      "-c",
      "dev",
      "null",
      "xargs",
      "-d",
      "volume",
      "-r",
      "pvname",
      "pvc",
      "pv",
      "urandom",
      "tr",
      "-cd",
      "alnum",
      "head",
      "kind",
      "persistentvolume",
      "apiversion",
      "v1",
      "metadata"
    ],
    "language": "en",
    "word_count": 81,
    "importance_score": 2.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "suite upgrade fails and the suite pod stays in a pending state",
    "contentLower": "when you try to upgrade a suite, the suite upgrade pod stays in the pending state. additionally, you may notice that some volumes are missing from the environment. cause this issue occurs because an unknown service deletes the volumes. solution copy the following text to a file and name it volumes.json. update the placeholders with the actual values. [{ \"volume_name\": <the volume name> \"nfs_server\": <the nfs server ip/host to create the pv> \"nfs_path\": <the path to the nfs server to create the pv> \"storage_class\": <the storage class name> \"storage_capability\": <the storage capability of the volume> }] for example: [{ \"volume_name\":\"demo1\", \"nfs_server\":\"16.111.xxx.xxx\", \"nfs_path\":\"/var/vols/itom/demo1\", \"storage_class\":\"cdf-default\", \"storage_capability\":\"1mi\" },{ \"volume_name\":\"demo2\", \"nfs_server\":\"16.111.xxx.xxx\", \"nfs_path\":\"/var/vols/itom/demo2\", \"storage_class\":\"cdf-default\", \"storage_capability\":\"1mi\" }] run the following command to change the permission of the file: chmod 744 ",
    "keywordsLower": [
      "16.111",
      "xxx.xxx",
      "createvolumes.sh",
      "volumes.json",
      "suite",
      "upgrade",
      "fails",
      "pod",
      "stays",
      "pending",
      "state",
      "cause",
      "solution",
      "try",
      "state.",
      "additionally",
      "notice",
      "volumes",
      "missing",
      "environment.",
      "issue",
      "occurs",
      "because",
      "unknown",
      "service",
      "deletes",
      "volumes.",
      "copy",
      "following",
      "text",
      "file",
      "name",
      "volumes.json.",
      "update",
      "placeholders",
      "actual",
      "values.",
      "example",
      "demo1",
      "16.111.xxx.xxx",
      "var",
      "vols",
      "itom",
      "cdf-default",
      "1mi",
      "demo2",
      "run",
      "command",
      "change",
      "permission",
      "chmod",
      "744",
      "bin",
      "bash",
      "usage",
      "echo",
      "--config",
      "--namespace",
      "create",
      "all",
      "exit",
      "while",
      "-z",
      "case",
      "parameter",
      "requires",
      "value.",
      "fi",
      "shift",
      "esac",
      "-h",
      "--help",
      "help",
      "done",
      "createvolumes",
      "start",
      "namespace",
      "local",
      "cat",
      "jq",
      "-c",
      "dev",
      "null",
      "xargs",
      "-d",
      "volume",
      "-r",
      "pvname",
      "pvc",
      "pv",
      "urandom",
      "tr",
      "-cd",
      "alnum",
      "head",
      "kind",
      "persistentvolume",
      "apiversion",
      "v1",
      "metadata"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "The Update button on OMT Management Portal is not working well",
    "content": "When you try to perform the suite update on the Management Portal, it takes a long period to respond, or the Update button does not work. You can run the following command on one of the control plane nodes to check the error messages: kubectl get pods -n core |grep portal-ingress-controller Your terminal resembles the following: [root@sh ~]# kubectl get pods -n core |grep portal-ingress-controller portal-ingress-controller-7f8f65f564-kcdnk 2/2 Running 0 27d Run the following command to check the portal-ingress-controller logs. Replace <portal-ingress-controller> with the pod name you received from the previous step. kubectl logs -f <portal-ingress-controller> -n core -c nginx-ingress-lb You may receive error messages that resemble the following: server returned error code: 3: name error. conext: ngx.timer 2020/12/1 12:59:0 [error]] 510#510: *33250 [lua] dnx.lua:152: dns_lookup(): failed to query the DNS server for suite-upgrade_svc-demo.demo-qppz4.svc.cluster.local: server returned err",
    "url": "mngportalnotresponsivewell",
    "filename": "mngportalnotresponsivewell",
    "headings": [
      "Cause",
      "Solution"
    ],
    "keywords": [
      "core.yaml",
      "demo.demo",
      "qppz4.svc",
      "dnx.lua",
      "update",
      "button",
      "omt",
      "management",
      "portal",
      "working",
      "well",
      "cause",
      "solution",
      "try",
      "perform",
      "suite",
      "takes",
      "long",
      "period",
      "respond",
      "work.",
      "run",
      "following",
      "command",
      "one",
      "control",
      "plane",
      "nodes",
      "check",
      "error",
      "messages",
      "kubectl",
      "get",
      "pods",
      "-n",
      "core",
      "grep",
      "portal-ingress-controller",
      "terminal",
      "resembles",
      "root",
      "sh",
      "portal-ingress-controller-7f8f65f564-kcdnk",
      "running",
      "27d",
      "logs.",
      "replace",
      "pod",
      "name",
      "received",
      "previous",
      "step.",
      "logs",
      "-f",
      "-c",
      "nginx-ingress-lb",
      "receive",
      "resemble",
      "server",
      "returned",
      "code",
      "error.",
      "conext",
      "ngx.timer",
      "2020",
      "12",
      "59",
      "510",
      "33250",
      "lua",
      "152",
      "failed",
      "query",
      "dns",
      "508",
      "33253",
      "issue",
      "occurs",
      "because",
      "upgrade",
      "ingress",
      "fails",
      "work",
      "well.",
      "log",
      "nodes.",
      "back",
      "suite-upgrade-ing-core",
      "under",
      "namespace.",
      "exist",
      "ignore",
      "-o",
      "yaml",
      "suite-upgrade-ing-core.yaml",
      "delete",
      "namespace",
      "ns",
      "actual",
      "suite-upgrade-ing-"
    ],
    "language": "en",
    "word_count": 110,
    "importance_score": 2.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "the update button on omt management portal is not working well",
    "contentLower": "when you try to perform the suite update on the management portal, it takes a long period to respond, or the update button does not work. you can run the following command on one of the control plane nodes to check the error messages: kubectl get pods -n core |grep portal-ingress-controller your terminal resembles the following: [root@sh ~]# kubectl get pods -n core |grep portal-ingress-controller portal-ingress-controller-7f8f65f564-kcdnk 2/2 running 0 27d run the following command to check the portal-ingress-controller logs. replace <portal-ingress-controller> with the pod name you received from the previous step. kubectl logs -f <portal-ingress-controller> -n core -c nginx-ingress-lb you may receive error messages that resemble the following: server returned error code: 3: name error. conext: ngx.timer 2020/12/1 12:59:0 [error]] 510#510: *33250 [lua] dnx.lua:152: dns_lookup(): failed to query the dns server for suite-upgrade_svc-demo.demo-qppz4.svc.cluster.local: server returned err",
    "keywordsLower": [
      "core.yaml",
      "demo.demo",
      "qppz4.svc",
      "dnx.lua",
      "update",
      "button",
      "omt",
      "management",
      "portal",
      "working",
      "well",
      "cause",
      "solution",
      "try",
      "perform",
      "suite",
      "takes",
      "long",
      "period",
      "respond",
      "work.",
      "run",
      "following",
      "command",
      "one",
      "control",
      "plane",
      "nodes",
      "check",
      "error",
      "messages",
      "kubectl",
      "get",
      "pods",
      "-n",
      "core",
      "grep",
      "portal-ingress-controller",
      "terminal",
      "resembles",
      "root",
      "sh",
      "portal-ingress-controller-7f8f65f564-kcdnk",
      "running",
      "27d",
      "logs.",
      "replace",
      "pod",
      "name",
      "received",
      "previous",
      "step.",
      "logs",
      "-f",
      "-c",
      "nginx-ingress-lb",
      "receive",
      "resemble",
      "server",
      "returned",
      "code",
      "error.",
      "conext",
      "ngx.timer",
      "2020",
      "12",
      "59",
      "510",
      "33250",
      "lua",
      "152",
      "failed",
      "query",
      "dns",
      "508",
      "33253",
      "issue",
      "occurs",
      "because",
      "upgrade",
      "ingress",
      "fails",
      "work",
      "well.",
      "log",
      "nodes.",
      "back",
      "suite-upgrade-ing-core",
      "under",
      "namespace.",
      "exist",
      "ignore",
      "-o",
      "yaml",
      "suite-upgrade-ing-core.yaml",
      "delete",
      "namespace",
      "ns",
      "actual",
      "suite-upgrade-ing-"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "replaceExternalAccessHost script fails with \"Waiting for idm pod ready...\"",
    "content": "When you run the replaceExternalAccessHost.sh script to change the external access host of the OMT cluster, the script becomes stuck when it tries to request the IdM pod: Waiting for idm pod ready... This issue occurs if the old FQDN is no longer available. This is most likely to occur when you try to recover the backup environment of another VM. Cause This issue occurs because the backup environment still has the old FQDN information, but new VM can't access that FQDN. Solution Run the following command to edit the EXTERNAL_ACCESS_HOST key in the base-configmap in the OMT_namespace to use an FQDN which is accessible: kubectl patch configmap/base-configmap -n <CDF_namespace> -p '{\"data\":{\"EXTERNAL_ACCESS_HOST\":\"<NEW_FQDN>\"}}' In this command, <CDF_namespace> is a placehoder for the OMT_namespace and <NEW_FQDN> is a placeholder for an FQDN that's accessible from the new VM. Run the replaceExternalAccessHost.sh script to change the external access host of the OMT cluster.",
    "url": "cannotchangefqdn",
    "filename": "cannotchangefqdn",
    "headings": [
      "Cause",
      "Solution"
    ],
    "keywords": [
      "replaceExternalAccessHost.sh",
      "replaceexternalaccesshost",
      "script",
      "fails",
      "waiting",
      "idm",
      "pod",
      "ready...",
      "cause",
      "solution",
      "run",
      "change",
      "external",
      "access",
      "host",
      "omt",
      "cluster",
      "becomes",
      "stuck",
      "tries",
      "request",
      "issue",
      "occurs",
      "old",
      "fqdn",
      "longer",
      "available.",
      "most",
      "likely",
      "occur",
      "try",
      "recover",
      "backup",
      "environment",
      "another",
      "vm.",
      "because",
      "still",
      "information",
      "new",
      "vm",
      "fqdn.",
      "following",
      "command",
      "edit",
      "key",
      "base-configmap",
      "accessible",
      "kubectl",
      "patch",
      "configmap",
      "-n",
      "-p",
      "data",
      "placehoder",
      "placeholder",
      "cluster."
    ],
    "language": "en",
    "word_count": 94,
    "importance_score": 3.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "replaceexternalaccesshost script fails with \"waiting for idm pod ready...\"",
    "contentLower": "when you run the replaceexternalaccesshost.sh script to change the external access host of the omt cluster, the script becomes stuck when it tries to request the idm pod: waiting for idm pod ready... this issue occurs if the old fqdn is no longer available. this is most likely to occur when you try to recover the backup environment of another vm. cause this issue occurs because the backup environment still has the old fqdn information, but new vm can't access that fqdn. solution run the following command to edit the external_access_host key in the base-configmap in the omt_namespace to use an fqdn which is accessible: kubectl patch configmap/base-configmap -n <cdf_namespace> -p '{\"data\":{\"external_access_host\":\"<new_fqdn>\"}}' in this command, <cdf_namespace> is a placehoder for the omt_namespace and <new_fqdn> is a placeholder for an fqdn that's accessible from the new vm. run the replaceexternalaccesshost.sh script to change the external access host of the omt cluster.",
    "keywordsLower": [
      "replaceexternalaccesshost.sh",
      "replaceexternalaccesshost",
      "script",
      "fails",
      "waiting",
      "idm",
      "pod",
      "ready...",
      "cause",
      "solution",
      "run",
      "change",
      "external",
      "access",
      "host",
      "omt",
      "cluster",
      "becomes",
      "stuck",
      "tries",
      "request",
      "issue",
      "occurs",
      "old",
      "fqdn",
      "longer",
      "available.",
      "most",
      "likely",
      "occur",
      "try",
      "recover",
      "backup",
      "environment",
      "another",
      "vm.",
      "because",
      "still",
      "information",
      "new",
      "vm",
      "fqdn.",
      "following",
      "command",
      "edit",
      "key",
      "base-configmap",
      "accessible",
      "kubectl",
      "patch",
      "configmap",
      "-n",
      "-p",
      "data",
      "placehoder",
      "placeholder",
      "cluster."
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Suite upgrade fails due to hardware resource shortage",
    "content": "You fail to upgrade the suite to this release. Additionally, you can find the following error in the <global-volume>/logs/update/deployer.log (for example: /var/vols/itom/global-volume/logs/update/deployer.log) file: Excepion: java.lang.IndexOutOfBoundsException The following figure shows an example. Root cause The suite system doesn't have enough hardware resources. Solution Add hardware resources according to the suite sizing guide of this release. Retry the suite version update.",
    "url": "upgradefailsduetoresourceshortage",
    "filename": "upgradefailsduetoresourceshortage",
    "headings": [
      "Root cause",
      "Solution"
    ],
    "keywords": [
      "java.lang",
      "deployer.log",
      "suite",
      "upgrade",
      "fails",
      "due",
      "hardware",
      "resource",
      "shortage",
      "root",
      "cause",
      "solution",
      "fail",
      "release.",
      "additionally",
      "find",
      "following",
      "error",
      "logs",
      "update",
      "example",
      "var",
      "vols",
      "itom",
      "global-volume",
      "file",
      "excepion",
      "java.lang.indexoutofboundsexception",
      "figure",
      "shows",
      "example.",
      "system",
      "doesn",
      "enough",
      "resources.",
      "add",
      "resources",
      "according",
      "sizing",
      "guide",
      "retry",
      "version",
      "update."
    ],
    "language": "en",
    "word_count": 55,
    "importance_score": 2.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "suite upgrade fails due to hardware resource shortage",
    "contentLower": "you fail to upgrade the suite to this release. additionally, you can find the following error in the <global-volume>/logs/update/deployer.log (for example: /var/vols/itom/global-volume/logs/update/deployer.log) file: excepion: java.lang.indexoutofboundsexception the following figure shows an example. root cause the suite system doesn't have enough hardware resources. solution add hardware resources according to the suite sizing guide of this release. retry the suite version update.",
    "keywordsLower": [
      "java.lang",
      "deployer.log",
      "suite",
      "upgrade",
      "fails",
      "due",
      "hardware",
      "resource",
      "shortage",
      "root",
      "cause",
      "solution",
      "fail",
      "release.",
      "additionally",
      "find",
      "following",
      "error",
      "logs",
      "update",
      "example",
      "var",
      "vols",
      "itom",
      "global-volume",
      "file",
      "excepion",
      "java.lang.indexoutofboundsexception",
      "figure",
      "shows",
      "example.",
      "system",
      "doesn",
      "enough",
      "resources.",
      "add",
      "resources",
      "according",
      "sizing",
      "guide",
      "retry",
      "version",
      "update."
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Suite upgrade gets stuck at the storage configuration step",
    "content": "The suite version update process gets stuck at the Configure storage screen: If you run the kubectl logs suite-conf-pod-itsma-xxxxxxx -n core command on a control plane node (on-premises) or the bastion node (managed Kubernetes), you can see many \"Operation not permitted\" errors. Cause The suite-conf-pod-itsma pod is running in 1/2 state or has crashed because operations are not permitted for certain storage volumes. Solution Perform the steps according to your environment: on-premises or managed Kubernetes (public cloud). On-premises Log in to the NFS server as root or a sudo user.Change the owner of certain storage folders as described in Change the owner of certain storage folders.Run the following command on a control plane node: kubectl delete suite-conf-pod-itsma-xxxxxx -n core Wait until the suite-conf-pod-itsma pod is running in 2/2 state.Refresh the Configure storage browser screen, and then continue with the suite version update process. Managed Kubernetes Log in to the basti",
    "url": "suiteupgradestuckatconfigurestorage",
    "filename": "suiteupgradestuckatconfigurestorage",
    "headings": [
      "Cause",
      "Solution",
      "On-premises",
      "Managed Kubernetes"
    ],
    "keywords": [
      "folders.Run",
      "suite",
      "upgrade",
      "gets",
      "stuck",
      "storage",
      "configuration",
      "step",
      "cause",
      "solution",
      "on-premises",
      "managed",
      "kubernetes",
      "version",
      "update",
      "process",
      "configure",
      "screen",
      "run",
      "kubectl",
      "logs",
      "suite-conf-pod-itsma-xxxxxxx",
      "-n",
      "core",
      "command",
      "control",
      "plane",
      "node",
      "bastion",
      "see",
      "many",
      "operation",
      "permitted",
      "errors.",
      "suite-conf-pod-itsma",
      "pod",
      "running",
      "state",
      "crashed",
      "because",
      "operations",
      "certain",
      "volumes.",
      "perform",
      "steps",
      "according",
      "environment",
      "public",
      "cloud",
      "log",
      "nfs",
      "server",
      "root",
      "sudo",
      "user.change",
      "owner",
      "folders",
      "described",
      "change",
      "following",
      "delete",
      "suite-conf-pod-itsma-xxxxxx",
      "wait",
      "until",
      "state.refresh",
      "browser",
      "continue",
      "process.",
      "node.change"
    ],
    "language": "en",
    "word_count": 108,
    "importance_score": 4.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "suite upgrade gets stuck at the storage configuration step",
    "contentLower": "the suite version update process gets stuck at the configure storage screen: if you run the kubectl logs suite-conf-pod-itsma-xxxxxxx -n core command on a control plane node (on-premises) or the bastion node (managed kubernetes), you can see many \"operation not permitted\" errors. cause the suite-conf-pod-itsma pod is running in 1/2 state or has crashed because operations are not permitted for certain storage volumes. solution perform the steps according to your environment: on-premises or managed kubernetes (public cloud). on-premises log in to the nfs server as root or a sudo user.change the owner of certain storage folders as described in change the owner of certain storage folders.run the following command on a control plane node: kubectl delete suite-conf-pod-itsma-xxxxxx -n core wait until the suite-conf-pod-itsma pod is running in 2/2 state.refresh the configure storage browser screen, and then continue with the suite version update process. managed kubernetes log in to the basti",
    "keywordsLower": [
      "folders.run",
      "suite",
      "upgrade",
      "gets",
      "stuck",
      "storage",
      "configuration",
      "step",
      "cause",
      "solution",
      "on-premises",
      "managed",
      "kubernetes",
      "version",
      "update",
      "process",
      "configure",
      "screen",
      "run",
      "kubectl",
      "logs",
      "suite-conf-pod-itsma-xxxxxxx",
      "-n",
      "core",
      "command",
      "control",
      "plane",
      "node",
      "bastion",
      "see",
      "many",
      "operation",
      "permitted",
      "errors.",
      "suite-conf-pod-itsma",
      "pod",
      "running",
      "state",
      "crashed",
      "because",
      "operations",
      "certain",
      "volumes.",
      "perform",
      "steps",
      "according",
      "environment",
      "public",
      "cloud",
      "log",
      "nfs",
      "server",
      "root",
      "sudo",
      "user.change",
      "owner",
      "folders",
      "described",
      "change",
      "following",
      "delete",
      "suite-conf-pod-itsma-xxxxxx",
      "wait",
      "until",
      "state.refresh",
      "browser",
      "continue",
      "process.",
      "node.change"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Tenant content validation fails",
    "content": "Before the version update process starts, the tenant content precheck validates out-of-the-box workflows and forms in the suite environment to ensure metadata integrity. This validation may fail. Possible causes Cause 1: The content validation job in the database is still in Running status. Cause 2: A timeout error occurs. Cause 3: Dirty data is detected. Cause 4: Incomplete or inconsistent data is detected. Solutions The first step is to get the content validation report. You can do this by clicking Show Report on the upgrade UI.  If, for some reason, you are unable to get the report from the UI, you can get it using the API. Complete the following steps to get the validation report using the API. Run the following command to get the content verification jobId from the log: cat maas_upg_verification.log |grep \"Content Validation Job ended! JobId: \" The command output contains the job ID. The output resembles the following example: Id=\"4b4f3925-c195-4ead-bd0f-8044e48d1334\" Run the foll",
    "url": "tenantcontentvalidationfails",
    "filename": "tenantcontentvalidationfails",
    "headings": [
      "Possible causes",
      "Solutions",
      "Solutions (helm deployment)",
      "Solution for cause 1",
      "Solution for cause 2",
      "Number of threads",
      "Content validation job timeout",
      "Content validation job timeout (helm deployment)",
      "Solution for cause 3",
      "Solution for cause 4",
      "Workflow error 1: Rule definition ID is null",
      "Workflow error 2: Illegal rule definition type",
      "Form error 1: Missing localization reference",
      "Form Error 2: Mismatched modelAttribute for MANY2MANY relation"
    ],
    "keywords": [
      "exists.Tthe",
      "dummy.com",
      "v2018.05",
      "detail.json",
      "report.json",
      "maas_upg_verification.log",
      "checkContent.sh",
      "https://itom-xruntime-gateway-content-validation-svc:8443",
      "tenant",
      "content",
      "validation",
      "fails",
      "possible",
      "causes",
      "solutions",
      "helm",
      "deployment",
      "solution",
      "cause",
      "number",
      "threads",
      "job",
      "timeout",
      "workflow",
      "error",
      "rule",
      "definition",
      "id",
      "null",
      "illegal",
      "type",
      "form",
      "missing",
      "localization",
      "reference",
      "mismatched",
      "modelattribute",
      "many2many",
      "relation",
      "before",
      "version",
      "update",
      "process",
      "starts",
      "precheck",
      "validates",
      "out-of-the-box",
      "workflows",
      "forms",
      "suite",
      "environment",
      "ensure",
      "metadata",
      "integrity.",
      "fail.",
      "database",
      "still",
      "running",
      "status.",
      "occurs.",
      "dirty",
      "data",
      "detected.",
      "incomplete",
      "inconsistent",
      "first",
      "step",
      "get",
      "report.",
      "clicking",
      "show",
      "report",
      "upgrade",
      "ui.",
      "reason",
      "unable",
      "ui",
      "api.",
      "complete",
      "following",
      "steps",
      "run",
      "command",
      "verification",
      "jobid",
      "log",
      "cat",
      "grep",
      "ended",
      "output",
      "contains",
      "id.",
      "resembles",
      "example",
      "4b4f3925-c195-4ead-bd0f-8044e48d1334",
      "commands",
      "pods",
      "ns",
      "kubectl",
      "itsma"
    ],
    "language": "en",
    "word_count": 105,
    "importance_score": 6.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "tenant content validation fails",
    "contentLower": "before the version update process starts, the tenant content precheck validates out-of-the-box workflows and forms in the suite environment to ensure metadata integrity. this validation may fail. possible causes cause 1: the content validation job in the database is still in running status. cause 2: a timeout error occurs. cause 3: dirty data is detected. cause 4: incomplete or inconsistent data is detected. solutions the first step is to get the content validation report. you can do this by clicking show report on the upgrade ui.  if, for some reason, you are unable to get the report from the ui, you can get it using the api. complete the following steps to get the validation report using the api. run the following command to get the content verification jobid from the log: cat maas_upg_verification.log |grep \"content validation job ended! jobid: \" the command output contains the job id. the output resembles the following example: id=\"4b4f3925-c195-4ead-bd0f-8044e48d1334\" run the foll",
    "keywordsLower": [
      "exists.tthe",
      "dummy.com",
      "v2018.05",
      "detail.json",
      "report.json",
      "maas_upg_verification.log",
      "checkcontent.sh",
      "https://itom-xruntime-gateway-content-validation-svc:8443",
      "tenant",
      "content",
      "validation",
      "fails",
      "possible",
      "causes",
      "solutions",
      "helm",
      "deployment",
      "solution",
      "cause",
      "number",
      "threads",
      "job",
      "timeout",
      "workflow",
      "error",
      "rule",
      "definition",
      "id",
      "null",
      "illegal",
      "type",
      "form",
      "missing",
      "localization",
      "reference",
      "mismatched",
      "modelattribute",
      "many2many",
      "relation",
      "before",
      "version",
      "update",
      "process",
      "starts",
      "precheck",
      "validates",
      "out-of-the-box",
      "workflows",
      "forms",
      "suite",
      "environment",
      "ensure",
      "metadata",
      "integrity.",
      "fail.",
      "database",
      "still",
      "running",
      "status.",
      "occurs.",
      "dirty",
      "data",
      "detected.",
      "incomplete",
      "inconsistent",
      "first",
      "step",
      "get",
      "report.",
      "clicking",
      "show",
      "report",
      "upgrade",
      "ui.",
      "reason",
      "unable",
      "ui",
      "api.",
      "complete",
      "following",
      "steps",
      "run",
      "command",
      "verification",
      "jobid",
      "log",
      "cat",
      "grep",
      "ended",
      "output",
      "contains",
      "id.",
      "resembles",
      "example",
      "4b4f3925-c195-4ead-bd0f-8044e48d1334",
      "commands",
      "pods",
      "ns",
      "kubectl",
      "itsma"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "System status check fails",
    "content": "As part of the suite version update precheck, the suite system status check is mainly focused on the status of all pods. If any pod is in Failed status, the status check will fail and you can't continue. Cause The root cause may be different from one pod to another. One possible cause lies in the fluentd and itom-logrotate daemonsets, both of which aren't used by SMA. Solution Run the following commands on a control plane node (embedded Kubernetes) or the bastion node (managed Kubernetes) to delete the fluentd and itom-logrotate daemonsets: kubectl delete daemonset fluentd --namespace=core kubectl delete daemonset itom-logrotate --namespace=core Then, retry the version update precheck. If the problem still persists, contact the support team.",
    "url": "systemstatuscheckfails",
    "filename": "systemstatuscheckfails",
    "headings": [
      "Cause",
      "Solution"
    ],
    "keywords": [
      "system",
      "status",
      "check",
      "fails",
      "cause",
      "solution",
      "part",
      "suite",
      "version",
      "update",
      "precheck",
      "mainly",
      "focused",
      "all",
      "pods.",
      "any",
      "pod",
      "failed",
      "fail",
      "continue.",
      "root",
      "different",
      "one",
      "another.",
      "possible",
      "lies",
      "fluentd",
      "itom-logrotate",
      "daemonsets",
      "both",
      "aren",
      "sma.",
      "run",
      "following",
      "commands",
      "control",
      "plane",
      "node",
      "embedded",
      "kubernetes",
      "bastion",
      "managed",
      "delete",
      "kubectl",
      "daemonset",
      "--namespace",
      "core",
      "retry",
      "precheck.",
      "problem",
      "still",
      "persists",
      "contact",
      "support",
      "team."
    ],
    "language": "en",
    "word_count": 84,
    "importance_score": 4.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "system status check fails",
    "contentLower": "as part of the suite version update precheck, the suite system status check is mainly focused on the status of all pods. if any pod is in failed status, the status check will fail and you can't continue. cause the root cause may be different from one pod to another. one possible cause lies in the fluentd and itom-logrotate daemonsets, both of which aren't used by sma. solution run the following commands on a control plane node (embedded kubernetes) or the bastion node (managed kubernetes) to delete the fluentd and itom-logrotate daemonsets: kubectl delete daemonset fluentd --namespace=core kubectl delete daemonset itom-logrotate --namespace=core then, retry the version update precheck. if the problem still persists, contact the support team.",
    "keywordsLower": [
      "system",
      "status",
      "check",
      "fails",
      "cause",
      "solution",
      "part",
      "suite",
      "version",
      "update",
      "precheck",
      "mainly",
      "focused",
      "all",
      "pods.",
      "any",
      "pod",
      "failed",
      "fail",
      "continue.",
      "root",
      "different",
      "one",
      "another.",
      "possible",
      "lies",
      "fluentd",
      "itom-logrotate",
      "daemonsets",
      "both",
      "aren",
      "sma.",
      "run",
      "following",
      "commands",
      "control",
      "plane",
      "node",
      "embedded",
      "kubernetes",
      "bastion",
      "managed",
      "delete",
      "kubectl",
      "daemonset",
      "--namespace",
      "core",
      "retry",
      "precheck.",
      "problem",
      "still",
      "persists",
      "contact",
      "support",
      "team."
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Tenant upgrade failed because LWSSO token was not found",
    "content": "The suite upgrade fails at the tenant upgrade stage with the following error message: Error: the status of job \"itom-xruntime-upgrade-tenants\" is CrashLoopBackOff Cause This issue occurs because the suite is unable to retrieve the LWSSO token from the IDM Service, resulting in the following error: ERROR : Fail org.springframework.web.client.HttpClientErrorException$Forbidden: 403 : [LWSSO token not found by IdM API for BO integration user: bo-integration@dummy.com]\",\"exceptionCause\":\"403 : [LWSSO token not found by IdM API for BO integration user: bo-integration@dummy.com]\"} You can confirm this error with the following error message in the IDM log: ERROR [https-jese-nio-8443-exec-9] com.hp.ccue.identity.lwsso.LwSssoCookieTokenWriter [] - Unable to write LW SSo tokenWrote SSO token to LW SSO failed. com.hp.ccu.identity.lwssoImpl.exeception.SssoBaseException: Wrote SSO token to LW_SSO failed. Solution Log in to https://<FQDN>/idm-admin, navigate to SYSTEM SETTINGS -> Enable Advanced Set",
    "url": "tenantupgradefailsduetomissingtoken",
    "filename": "tenantupgradefailsduetomissingtoken",
    "headings": [
      "Cause",
      "Solution"
    ],
    "keywords": [
      "dummy.com",
      "0.0.0",
      "nio-8443",
      "https://<FQDN>/idm-admin",
      "com.hp",
      "springframework.web",
      "0.0.0.0",
      "tenant",
      "upgrade",
      "failed",
      "because",
      "lwsso",
      "token",
      "found",
      "cause",
      "solution",
      "suite",
      "fails",
      "stage",
      "following",
      "error",
      "message",
      "status",
      "job",
      "itom-xruntime-upgrade-tenants",
      "crashloopbackoff",
      "issue",
      "occurs",
      "unable",
      "retrieve",
      "idm",
      "service",
      "resulting",
      "fail",
      "org.springframework.web.client.httpclienterrorexception",
      "forbidden",
      "403",
      "api",
      "bo",
      "integration",
      "user",
      "bo-integration",
      "exceptioncause",
      "confirm",
      "log",
      "https-jese-nio-8443-exec-9",
      "com.hp.ccue.identity.lwsso.lwsssocookietokenwriter",
      "write",
      "lw",
      "sso",
      "tokenwrote",
      "failed.",
      "com.hp.ccu.identity.lwssoimpl.exeception.sssobaseexception",
      "wrote",
      "https",
      "idm-admin",
      "navigate",
      "system",
      "settings",
      "enable",
      "advanced",
      "top",
      "right",
      "corner",
      "reverse",
      "proxy",
      "values",
      "set",
      "below",
      "ip",
      "enabled",
      "true"
    ],
    "language": "en",
    "word_count": 98,
    "importance_score": 3.3,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "tenant upgrade failed because lwsso token was not found",
    "contentLower": "the suite upgrade fails at the tenant upgrade stage with the following error message: error: the status of job \"itom-xruntime-upgrade-tenants\" is crashloopbackoff cause this issue occurs because the suite is unable to retrieve the lwsso token from the idm service, resulting in the following error: error : fail org.springframework.web.client.httpclienterrorexception$forbidden: 403 : [lwsso token not found by idm api for bo integration user: bo-integration@dummy.com]\",\"exceptioncause\":\"403 : [lwsso token not found by idm api for bo integration user: bo-integration@dummy.com]\"} you can confirm this error with the following error message in the idm log: error [https-jese-nio-8443-exec-9] com.hp.ccue.identity.lwsso.lwsssocookietokenwriter [] - unable to write lw sso tokenwrote sso token to lw sso failed. com.hp.ccu.identity.lwssoimpl.exeception.sssobaseexception: wrote sso token to lw_sso failed. solution log in to https://<fqdn>/idm-admin, navigate to system settings -> enable advanced set",
    "keywordsLower": [
      "dummy.com",
      "0.0.0",
      "nio-8443",
      "https://<fqdn>/idm-admin",
      "com.hp",
      "springframework.web",
      "0.0.0.0",
      "tenant",
      "upgrade",
      "failed",
      "because",
      "lwsso",
      "token",
      "found",
      "cause",
      "solution",
      "suite",
      "fails",
      "stage",
      "following",
      "error",
      "message",
      "status",
      "job",
      "itom-xruntime-upgrade-tenants",
      "crashloopbackoff",
      "issue",
      "occurs",
      "unable",
      "retrieve",
      "idm",
      "service",
      "resulting",
      "fail",
      "org.springframework.web.client.httpclienterrorexception",
      "forbidden",
      "403",
      "api",
      "bo",
      "integration",
      "user",
      "bo-integration",
      "exceptioncause",
      "confirm",
      "log",
      "https-jese-nio-8443-exec-9",
      "com.hp.ccue.identity.lwsso.lwsssocookietokenwriter",
      "write",
      "lw",
      "sso",
      "tokenwrote",
      "failed.",
      "com.hp.ccu.identity.lwssoimpl.exeception.sssobaseexception",
      "wrote",
      "https",
      "idm-admin",
      "navigate",
      "system",
      "settings",
      "enable",
      "advanced",
      "top",
      "right",
      "corner",
      "reverse",
      "proxy",
      "values",
      "set",
      "below",
      "ip",
      "enabled",
      "true"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Tenant upgrade fails because tenant state changes due to license expiration",
    "content": "The suite upgrade fails at the tenant upgrade stage. You find error messages that resemble the following in the upgrade.log file (for example: /var/vols/itom/logging-volume/xservices/upgradetenant/itom-xruntime-upgrade-tenants-yyyy-mm-dd/upgrade.log): 2021-01-18 11:49:19,380 : MainThread : 140002658956608 : INFO : tenant 602824400, status is Inactive; content version is v19 2021-01-18 11:49:39,401 : MainThread : 140002658956608 : INFO : -----------------check tenants iteration No.90 2021-01-18 11:49:40,083 : MainThread : 140002658956608 : INFO : tenant 602824400, status is Inactive; content version is v19 2021-01-18 11:50:00,100 : MainThread : 140002658956608 : ERROR : upgrade content failed! 2021-01-18 11:50:00,109 : MainThread : 140002658956608 : ERROR : upgrade content failed! abort! 2021-01-18 11:50:00,109 : MainThread : 140002658956608 : ERROR : Upgrade tenants in parallel failed! System exit with code -1 Parameter PWD is NULL 2021-01-18 11:50:01,133 : MainThread : 140513077261632",
    "url": "tenantupgradefailsduetolicenseexpiration",
    "filename": "tenantupgradefailsduetolicenseexpiration",
    "headings": [
      "Cause",
      "Solution"
    ],
    "keywords": [
      "No.90",
      "upgrade.log",
      "https://<External_Access_Host>/bo",
      "tenant",
      "upgrade",
      "fails",
      "because",
      "state",
      "changes",
      "due",
      "license",
      "expiration",
      "cause",
      "solution",
      "suite",
      "stage.",
      "find",
      "error",
      "messages",
      "resemble",
      "following",
      "file",
      "example",
      "var",
      "vols",
      "itom",
      "logging-volume",
      "xservices",
      "upgradetenant",
      "itom-xruntime-upgrade-tenants-yyyy-mm-dd",
      "2021-01-18",
      "11",
      "49",
      "19",
      "380",
      "mainthread",
      "140002658956608",
      "info",
      "602824400",
      "status",
      "inactive",
      "content",
      "version",
      "v19",
      "39",
      "401",
      "-----------------check",
      "tenants",
      "iteration",
      "40",
      "083",
      "50",
      "00",
      "100",
      "failed",
      "109",
      "abort",
      "parallel",
      "system",
      "exit",
      "code",
      "-1",
      "parameter",
      "pwd",
      "null",
      "01",
      "133",
      "140513077261632",
      "wrong",
      "args",
      "action",
      "gettenants",
      "getstatus",
      "host",
      "user",
      "15",
      "680",
      "139719238546752",
      "runs",
      "job",
      "every",
      "night",
      "after",
      "midnight",
      "check",
      "validity",
      "tenant.",
      "expired",
      "moves",
      "state.",
      "initial",
      "active",
      "starts",
      "becomes",
      "while",
      "still",
      "progress",
      "fails.",
      "log",
      "postgresql"
    ],
    "language": "en",
    "word_count": 123,
    "importance_score": 2.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "tenant upgrade fails because tenant state changes due to license expiration",
    "contentLower": "the suite upgrade fails at the tenant upgrade stage. you find error messages that resemble the following in the upgrade.log file (for example: /var/vols/itom/logging-volume/xservices/upgradetenant/itom-xruntime-upgrade-tenants-yyyy-mm-dd/upgrade.log): 2021-01-18 11:49:19,380 : mainthread : 140002658956608 : info : tenant 602824400, status is inactive; content version is v19 2021-01-18 11:49:39,401 : mainthread : 140002658956608 : info : -----------------check tenants iteration no.90 2021-01-18 11:49:40,083 : mainthread : 140002658956608 : info : tenant 602824400, status is inactive; content version is v19 2021-01-18 11:50:00,100 : mainthread : 140002658956608 : error : upgrade content failed! 2021-01-18 11:50:00,109 : mainthread : 140002658956608 : error : upgrade content failed! abort! 2021-01-18 11:50:00,109 : mainthread : 140002658956608 : error : upgrade tenants in parallel failed! system exit with code -1 parameter pwd is null 2021-01-18 11:50:01,133 : mainthread : 140513077261632",
    "keywordsLower": [
      "no.90",
      "upgrade.log",
      "https://<external_access_host>/bo",
      "tenant",
      "upgrade",
      "fails",
      "because",
      "state",
      "changes",
      "due",
      "license",
      "expiration",
      "cause",
      "solution",
      "suite",
      "stage.",
      "find",
      "error",
      "messages",
      "resemble",
      "following",
      "file",
      "example",
      "var",
      "vols",
      "itom",
      "logging-volume",
      "xservices",
      "upgradetenant",
      "itom-xruntime-upgrade-tenants-yyyy-mm-dd",
      "2021-01-18",
      "11",
      "49",
      "19",
      "380",
      "mainthread",
      "140002658956608",
      "info",
      "602824400",
      "status",
      "inactive",
      "content",
      "version",
      "v19",
      "39",
      "401",
      "-----------------check",
      "tenants",
      "iteration",
      "40",
      "083",
      "50",
      "00",
      "100",
      "failed",
      "109",
      "abort",
      "parallel",
      "system",
      "exit",
      "code",
      "-1",
      "parameter",
      "pwd",
      "null",
      "01",
      "133",
      "140513077261632",
      "wrong",
      "args",
      "action",
      "gettenants",
      "getstatus",
      "host",
      "user",
      "15",
      "680",
      "139719238546752",
      "runs",
      "job",
      "every",
      "night",
      "after",
      "midnight",
      "check",
      "validity",
      "tenant.",
      "expired",
      "moves",
      "state.",
      "initial",
      "active",
      "starts",
      "becomes",
      "while",
      "still",
      "progress",
      "fails.",
      "log",
      "postgresql"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Suite upgrade getting stuck due to PostgreSQL VACUUM",
    "content": "The suite upgrade is getting stuck, and you can find \"localhost-startStop-1\" from the jstack log. To check the jstack log: Run the following commands on a control plane node or the bastion node: kubectl exec -it itom-xruntime-platform-xxxxxxxxxxxxxx -n <namespace> -c itom-xruntime-platform /bin/bash ps -ef |grep java jstack {JAVA_PID} > /tmp/dump.log Copy the /tmp/thread.log file to the NFS server, and then search for \"localhost-startStop-1\" in the log file. Additionally, if you run the following sql, you will see several sqls are blocked by the PostgreSQL VACUUM job: select pid, pg_blocking_pids(pid) as blocked_by, query as blocked_query from pg_stat_activity where pg_blocking_pids(pid)::text != '{}'; Cause A daily PostgreSQL VACUUM job is running during the upgrade. When a tenant has a large amount of garbage data in the suite database, this job has a big impact on the system performance. As a result, the platform pod can't get ready and the suite upgrade process gets stuck. Solution",
    "url": "suiteupgradestuckduetopgvacuum",
    "filename": "suiteupgradestuckduetopgvacuum",
    "headings": [
      "Cause",
      "Solution"
    ],
    "keywords": [
      "thread.log",
      "dump.log",
      "suite",
      "upgrade",
      "getting",
      "stuck",
      "due",
      "postgresql",
      "vacuum",
      "cause",
      "solution",
      "find",
      "localhost-startstop-1",
      "jstack",
      "log.",
      "check",
      "log",
      "run",
      "following",
      "commands",
      "control",
      "plane",
      "node",
      "bastion",
      "kubectl",
      "exec",
      "-it",
      "itom-xruntime-platform-xxxxxxxxxxxxxx",
      "-n",
      "-c",
      "itom-xruntime-platform",
      "bin",
      "bash",
      "ps",
      "-ef",
      "grep",
      "java",
      "tmp",
      "copy",
      "file",
      "nfs",
      "server",
      "search",
      "file.",
      "additionally",
      "sql",
      "see",
      "several",
      "sqls",
      "blocked",
      "job",
      "select",
      "pid",
      "query",
      "text",
      "daily",
      "running",
      "during",
      "upgrade.",
      "tenant",
      "large",
      "amount",
      "garbage",
      "data",
      "database",
      "big",
      "impact",
      "system",
      "performance.",
      "result",
      "platform",
      "pod",
      "get",
      "ready",
      "process",
      "gets",
      "stuck.",
      "stop",
      "relevant",
      "tenants",
      "continue",
      "administration",
      "suite-admin",
      "https",
      "bo.",
      "click",
      "open",
      "go",
      "application",
      "settings",
      "tab",
      "turn",
      "off",
      "enable",
      "option.",
      "repeat",
      "step",
      "tenants.",
      "ready.",
      "after"
    ],
    "language": "en",
    "word_count": 107,
    "importance_score": 3.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "suite upgrade getting stuck due to postgresql vacuum",
    "contentLower": "the suite upgrade is getting stuck, and you can find \"localhost-startstop-1\" from the jstack log. to check the jstack log: run the following commands on a control plane node or the bastion node: kubectl exec -it itom-xruntime-platform-xxxxxxxxxxxxxx -n <namespace> -c itom-xruntime-platform /bin/bash ps -ef |grep java jstack {java_pid} > /tmp/dump.log copy the /tmp/thread.log file to the nfs server, and then search for \"localhost-startstop-1\" in the log file. additionally, if you run the following sql, you will see several sqls are blocked by the postgresql vacuum job: select pid, pg_blocking_pids(pid) as blocked_by, query as blocked_query from pg_stat_activity where pg_blocking_pids(pid)::text != '{}'; cause a daily postgresql vacuum job is running during the upgrade. when a tenant has a large amount of garbage data in the suite database, this job has a big impact on the system performance. as a result, the platform pod can't get ready and the suite upgrade process gets stuck. solution",
    "keywordsLower": [
      "thread.log",
      "dump.log",
      "suite",
      "upgrade",
      "getting",
      "stuck",
      "due",
      "postgresql",
      "vacuum",
      "cause",
      "solution",
      "find",
      "localhost-startstop-1",
      "jstack",
      "log.",
      "check",
      "log",
      "run",
      "following",
      "commands",
      "control",
      "plane",
      "node",
      "bastion",
      "kubectl",
      "exec",
      "-it",
      "itom-xruntime-platform-xxxxxxxxxxxxxx",
      "-n",
      "-c",
      "itom-xruntime-platform",
      "bin",
      "bash",
      "ps",
      "-ef",
      "grep",
      "java",
      "tmp",
      "copy",
      "file",
      "nfs",
      "server",
      "search",
      "file.",
      "additionally",
      "sql",
      "see",
      "several",
      "sqls",
      "blocked",
      "job",
      "select",
      "pid",
      "query",
      "text",
      "daily",
      "running",
      "during",
      "upgrade.",
      "tenant",
      "large",
      "amount",
      "garbage",
      "data",
      "database",
      "big",
      "impact",
      "system",
      "performance.",
      "result",
      "platform",
      "pod",
      "get",
      "ready",
      "process",
      "gets",
      "stuck.",
      "stop",
      "relevant",
      "tenants",
      "continue",
      "administration",
      "suite-admin",
      "https",
      "bo.",
      "click",
      "open",
      "go",
      "application",
      "settings",
      "tab",
      "turn",
      "off",
      "enable",
      "option.",
      "repeat",
      "step",
      "tenants.",
      "ready.",
      "after"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "The DND upgrade pod can't start successfully",
    "content": "The itom-dnd-upgrade-job pod crashes during upgrade. If you run the kubectl logs itom-dnd-upgrade-job-xxx -n <itsma_namespace> -f command when this issue occurs, you see the following log: Caused by: sun.security.validator.ValidatorException: PKIX path building failed: sun.security.provider.certpath.SunCertPathBuilderException: unable to find valid certification path to requested target at java.base/sun.security.validator.PKIXValidator.doBuild(PKIXValidator.java:439) at java.base/sun.security.validator.PKIXValidator.engineValidate(PKIXValidator.java:306) at java.base/sun.security.validator.Validator.validate(Validator.java:264) at java.base/sun.security.ssl.X509TrustManagerImpl.checkTrusted(X509TrustManagerImpl.java:231) at java.base/sun.security.ssl.X509TrustManagerImpl.checkServerTrusted(X509TrustManagerImpl.java:132) at java.base/sun.security.ssl.CertificateMessage$T13CertificateConsumer.checkServerCerts(CertificateMessage.java:1335) This issue happens only in classic deployments. C",
    "url": "dndupgradepodnotup",
    "filename": "dndupgradepodnotup",
    "headings": [
      "Cause",
      "Solution"
    ],
    "keywords": [
      "cant",
      "Validator.java",
      "java.base",
      "CertificateMessage.java",
      "X509TrustManagerImpl.java",
      "PKIXValidator.java",
      "security.ssl",
      "updateSMAExternalDBInfo.sh",
      "dnd",
      "upgrade",
      "pod",
      "start",
      "successfully",
      "cause",
      "solution",
      "itom-dnd-upgrade-job",
      "crashes",
      "during",
      "upgrade.",
      "run",
      "kubectl",
      "logs",
      "itom-dnd-upgrade-job-xxx",
      "-n",
      "-f",
      "command",
      "issue",
      "occurs",
      "see",
      "following",
      "log",
      "caused",
      "sun.security.validator.validatorexception",
      "pkix",
      "path",
      "building",
      "failed",
      "sun.security.provider.certpath.suncertpathbuilderexception",
      "unable",
      "find",
      "valid",
      "certification",
      "requested",
      "target",
      "sun.security.validator.pkixvalidator.dobuild",
      "439",
      "sun.security.validator.pkixvalidator.enginevalidate",
      "306",
      "sun.security.validator.validator.validate",
      "264",
      "sun.security.ssl.x509trustmanagerimpl.checktrusted",
      "231",
      "sun.security.ssl.x509trustmanagerimpl.checkservertrusted",
      "132",
      "sun.security.ssl.certificatemessage",
      "t13certificateconsumer.checkservercerts",
      "1335",
      "happens",
      "classic",
      "deployments.",
      "because",
      "certificate",
      "vault",
      "updated",
      "correctly.",
      "perform",
      "steps.",
      "follow",
      "steps",
      "change",
      "cert",
      "postgresql",
      "topic",
      "prepare",
      "tool.",
      "commands",
      "update",
      "ca",
      "certificates",
      "cmp",
      "finops",
      "components",
      "--component",
      "cmpfinops",
      "--cacert",
      "retry",
      "suite",
      "described",
      "service",
      "management."
    ],
    "language": "en",
    "word_count": 67,
    "importance_score": 2.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "the dnd upgrade pod can't start successfully",
    "contentLower": "the itom-dnd-upgrade-job pod crashes during upgrade. if you run the kubectl logs itom-dnd-upgrade-job-xxx -n <itsma_namespace> -f command when this issue occurs, you see the following log: caused by: sun.security.validator.validatorexception: pkix path building failed: sun.security.provider.certpath.suncertpathbuilderexception: unable to find valid certification path to requested target at java.base/sun.security.validator.pkixvalidator.dobuild(pkixvalidator.java:439) at java.base/sun.security.validator.pkixvalidator.enginevalidate(pkixvalidator.java:306) at java.base/sun.security.validator.validator.validate(validator.java:264) at java.base/sun.security.ssl.x509trustmanagerimpl.checktrusted(x509trustmanagerimpl.java:231) at java.base/sun.security.ssl.x509trustmanagerimpl.checkservertrusted(x509trustmanagerimpl.java:132) at java.base/sun.security.ssl.certificatemessage$t13certificateconsumer.checkservercerts(certificatemessage.java:1335) this issue happens only in classic deployments. c",
    "keywordsLower": [
      "cant",
      "validator.java",
      "java.base",
      "certificatemessage.java",
      "x509trustmanagerimpl.java",
      "pkixvalidator.java",
      "security.ssl",
      "updatesmaexternaldbinfo.sh",
      "dnd",
      "upgrade",
      "pod",
      "start",
      "successfully",
      "cause",
      "solution",
      "itom-dnd-upgrade-job",
      "crashes",
      "during",
      "upgrade.",
      "run",
      "kubectl",
      "logs",
      "itom-dnd-upgrade-job-xxx",
      "-n",
      "-f",
      "command",
      "issue",
      "occurs",
      "see",
      "following",
      "log",
      "caused",
      "sun.security.validator.validatorexception",
      "pkix",
      "path",
      "building",
      "failed",
      "sun.security.provider.certpath.suncertpathbuilderexception",
      "unable",
      "find",
      "valid",
      "certification",
      "requested",
      "target",
      "sun.security.validator.pkixvalidator.dobuild",
      "439",
      "sun.security.validator.pkixvalidator.enginevalidate",
      "306",
      "sun.security.validator.validator.validate",
      "264",
      "sun.security.ssl.x509trustmanagerimpl.checktrusted",
      "231",
      "sun.security.ssl.x509trustmanagerimpl.checkservertrusted",
      "132",
      "sun.security.ssl.certificatemessage",
      "t13certificateconsumer.checkservercerts",
      "1335",
      "happens",
      "classic",
      "deployments.",
      "because",
      "certificate",
      "vault",
      "updated",
      "correctly.",
      "perform",
      "steps.",
      "follow",
      "steps",
      "change",
      "cert",
      "postgresql",
      "topic",
      "prepare",
      "tool.",
      "commands",
      "update",
      "ca",
      "certificates",
      "cmp",
      "finops",
      "components",
      "--component",
      "cmpfinops",
      "--cacert",
      "retry",
      "suite",
      "described",
      "service",
      "management."
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Troubleshoot integration",
    "content": "This section provides troubleshooting information about integrations.",
    "url": "troubleshootintegrate",
    "filename": "troubleshootintegrate",
    "headings": [],
    "keywords": [
      "troubleshoot",
      "integration",
      "section",
      "provides",
      "troubleshooting",
      "information",
      "about",
      "integrations."
    ],
    "language": "en",
    "word_count": 8,
    "importance_score": 2.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "troubleshoot integration",
    "contentLower": "this section provides troubleshooting information about integrations.",
    "keywordsLower": [
      "troubleshoot",
      "integration",
      "section",
      "provides",
      "troubleshooting",
      "information",
      "about",
      "integrations."
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Troubleshoot Microsoft 365 email integration",
    "content": "This section provides troubleshooting information for the email integration with Microsoft 365. Understand email process statuses Before troubleshooting, familiarize yourself with the different scenario running statuses: Finish, Failed, and Skipped. Finish Triggered manually or by a scheduler The Label field in the scenario running history shows three statuses: Success: The processed email was moved to the folder configured in the Settings rule for SuccessFolderName. Failed: The email failed to convert into a Service Management record and was moved to the folder configured in the Settings rule for ErrorFolderName. Skipped: The email was skipped because another scenario had already converted it into a Service Management record. The detailed result will be stored in the FinalResult variable in Output. Check the rule running history of “Set result to label” in the \"Process emails\" scenario. Trigger by listener A successfully processed email follows the <Record Type> – <Email subject> patt",
    "url": "troubleshootms365emailintegration",
    "filename": "troubleshootms365emailintegration",
    "headings": [
      "Understand email process statuses",
      "Finish",
      "Triggered manually or by a scheduler",
      "Trigger by listener",
      "Failed",
      "Skipped",
      "Issue: The \"Manage email subscription\" scenario always fails",
      "Symptom",
      "Cause",
      "Solution"
    ],
    "keywords": [
      "troubleshoot",
      "microsoft",
      "365",
      "email",
      "integration",
      "understand",
      "process",
      "statuses",
      "finish",
      "triggered",
      "manually",
      "scheduler",
      "trigger",
      "listener",
      "failed",
      "skipped",
      "issue",
      "manage",
      "subscription",
      "scenario",
      "always",
      "fails",
      "symptom",
      "cause",
      "solution",
      "section",
      "provides",
      "troubleshooting",
      "information",
      "365.",
      "before",
      "familiarize",
      "yourself",
      "different",
      "running",
      "skipped.",
      "label",
      "field",
      "history",
      "shows",
      "three",
      "success",
      "processed",
      "moved",
      "folder",
      "configured",
      "settings",
      "rule",
      "successfoldername.",
      "convert",
      "service",
      "management",
      "record",
      "errorfoldername.",
      "because",
      "another",
      "already",
      "converted",
      "record.",
      "detailed",
      "result",
      "stored",
      "finalresult",
      "variable",
      "output.",
      "check",
      "set",
      "emails",
      "scenario.",
      "successfully",
      "follows",
      "pattern",
      "such",
      "request",
      "system",
      "log",
      "failed.",
      "pattern.",
      "fail",
      "due",
      "incorrect",
      "configuration",
      "azure",
      "application.",
      "review",
      "execution",
      "identify",
      "why.",
      "returned",
      "response",
      "contain",
      "diagnostic",
      "information.",
      "status",
      "inactive.",
      "renewing",
      "creating",
      "subscriptions",
      "400",
      "code"
    ],
    "language": "en",
    "word_count": 96,
    "importance_score": 6.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "troubleshoot microsoft 365 email integration",
    "contentLower": "this section provides troubleshooting information for the email integration with microsoft 365. understand email process statuses before troubleshooting, familiarize yourself with the different scenario running statuses: finish, failed, and skipped. finish triggered manually or by a scheduler the label field in the scenario running history shows three statuses: success: the processed email was moved to the folder configured in the settings rule for successfoldername. failed: the email failed to convert into a service management record and was moved to the folder configured in the settings rule for errorfoldername. skipped: the email was skipped because another scenario had already converted it into a service management record. the detailed result will be stored in the finalresult variable in output. check the rule running history of “set result to label” in the \"process emails\" scenario. trigger by listener a successfully processed email follows the <record type> – <email subject> patt",
    "keywordsLower": [
      "troubleshoot",
      "microsoft",
      "365",
      "email",
      "integration",
      "understand",
      "process",
      "statuses",
      "finish",
      "triggered",
      "manually",
      "scheduler",
      "trigger",
      "listener",
      "failed",
      "skipped",
      "issue",
      "manage",
      "subscription",
      "scenario",
      "always",
      "fails",
      "symptom",
      "cause",
      "solution",
      "section",
      "provides",
      "troubleshooting",
      "information",
      "365.",
      "before",
      "familiarize",
      "yourself",
      "different",
      "running",
      "skipped.",
      "label",
      "field",
      "history",
      "shows",
      "three",
      "success",
      "processed",
      "moved",
      "folder",
      "configured",
      "settings",
      "rule",
      "successfoldername.",
      "convert",
      "service",
      "management",
      "record",
      "errorfoldername.",
      "because",
      "another",
      "already",
      "converted",
      "record.",
      "detailed",
      "result",
      "stored",
      "finalresult",
      "variable",
      "output.",
      "check",
      "set",
      "emails",
      "scenario.",
      "successfully",
      "follows",
      "pattern",
      "such",
      "request",
      "system",
      "log",
      "failed.",
      "pattern.",
      "fail",
      "due",
      "incorrect",
      "configuration",
      "azure",
      "application.",
      "review",
      "execution",
      "identify",
      "why.",
      "returned",
      "response",
      "contain",
      "diagnostic",
      "information.",
      "status",
      "inactive.",
      "renewing",
      "creating",
      "subscriptions",
      "400",
      "code"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Troubleshoot the OBM integration",
    "content": "This section provides troubleshooting information for theOperations Bridge Manager (OBM) integration. Logging the OBM event data sent to Service Management To assist with troubleshooting, modify the Groovy script to log the full OBM event data in its original form. Use the SMAGroovyAdapter script (v3.3 or later) from the OMi Integration with Service Management Automation package, available on the Marketplace. Locate the following line in the Groovy script: final String incident = eventToPayload(event, null, causeExternalRefId, duplicateChange) Add the following code after the line: if (m_log.isDebugEnabled()){ appendLogfile(\"========= Event Payload to Service Management\") appendLogfile(incident) } The event data will be written to this log file: <Gateway Server root directory>/log/opr-event-sync-adapter.log. Syntax error If a syntax error occurs while customizing the Groovy script, the Event Browser generates an event with a detailed error description. You can also check the log file a",
    "url": "troubleshootomiintegration",
    "filename": "troubleshootomiintegration",
    "headings": [
      "Logging the OBM event data sent to Service Management",
      "Syntax error"
    ],
    "keywords": [
      "adapter.log",
      "v3.3",
      "troubleshoot",
      "obm",
      "integration",
      "logging",
      "event",
      "data",
      "sent",
      "service",
      "management",
      "syntax",
      "error",
      "section",
      "provides",
      "troubleshooting",
      "information",
      "theoperations",
      "bridge",
      "manager",
      "integration.",
      "assist",
      "modify",
      "groovy",
      "script",
      "log",
      "full",
      "original",
      "form.",
      "smagroovyadapter",
      "later",
      "omi",
      "automation",
      "package",
      "available",
      "marketplace.",
      "locate",
      "following",
      "line",
      "final",
      "string",
      "incident",
      "eventtopayload",
      "null",
      "causeexternalrefid",
      "duplicatechange",
      "add",
      "code",
      "after",
      "appendlogfile",
      "payload",
      "written",
      "file",
      "opr-event-sync-adapter.log.",
      "occurs",
      "while",
      "customizing",
      "browser",
      "generates",
      "detailed",
      "description.",
      "check",
      "opr-event-sync-adapter.log",
      "guidance",
      "resolving",
      "issue."
    ],
    "language": "en",
    "word_count": 95,
    "importance_score": 4.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "troubleshoot the obm integration",
    "contentLower": "this section provides troubleshooting information for theoperations bridge manager (obm) integration. logging the obm event data sent to service management to assist with troubleshooting, modify the groovy script to log the full obm event data in its original form. use the smagroovyadapter script (v3.3 or later) from the omi integration with service management automation package, available on the marketplace. locate the following line in the groovy script: final string incident = eventtopayload(event, null, causeexternalrefid, duplicatechange) add the following code after the line: if (m_log.isdebugenabled()){ appendlogfile(\"========= event payload to service management\") appendlogfile(incident) } the event data will be written to this log file: <gateway server root directory>/log/opr-event-sync-adapter.log. syntax error if a syntax error occurs while customizing the groovy script, the event browser generates an event with a detailed error description. you can also check the log file a",
    "keywordsLower": [
      "adapter.log",
      "v3.3",
      "troubleshoot",
      "obm",
      "integration",
      "logging",
      "event",
      "data",
      "sent",
      "service",
      "management",
      "syntax",
      "error",
      "section",
      "provides",
      "troubleshooting",
      "information",
      "theoperations",
      "bridge",
      "manager",
      "integration.",
      "assist",
      "modify",
      "groovy",
      "script",
      "log",
      "full",
      "original",
      "form.",
      "smagroovyadapter",
      "later",
      "omi",
      "automation",
      "package",
      "available",
      "marketplace.",
      "locate",
      "following",
      "line",
      "final",
      "string",
      "incident",
      "eventtopayload",
      "null",
      "causeexternalrefid",
      "duplicatechange",
      "add",
      "code",
      "after",
      "appendlogfile",
      "payload",
      "written",
      "file",
      "opr-event-sync-adapter.log.",
      "occurs",
      "while",
      "customizing",
      "browser",
      "generates",
      "detailed",
      "description.",
      "check",
      "opr-event-sync-adapter.log",
      "guidance",
      "resolving",
      "issue."
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Troubleshoot Microsoft Teams integration",
    "content": "The following describes typical issues that may occur when you set up Microsoft Teams integration based on the built-in integration framework. SSL handshake failure When you or your Teams admin opens the consent link in a browser, the page displays an error about SSL handshake failure. Cause There're no proxy settings or the settings are incorrect. Solution Add or modify your proxy settings: Log in to Suite Administration as suite-admin: https://<External Access Host>/bo. Click the CONFIGURATION tab on the main menu, and then click Proxy Settings. Set the following fields: Proxy host: the hostname of the proxy you configured. Proxy port: the port number of the proxy. (Optional) Proxy username and Proxy password: enter the username and password if the proxy server requires authentication. Click SAVE. Failed to run function You have successfully saved the field mappings for an MS Teams channel, however, the integration fails at runtime. You can find the following message in the runtime l",
    "url": "troubleshootmsteamsintegration",
    "filename": "troubleshootmsteamsintegration",
    "headings": [
      "SSL handshake failure",
      "Cause",
      "Solution",
      "Failed to run function",
      "Cause",
      "Solution",
      "Failed to connect to MS Teams because required String parameter 'code' is not present",
      "Cause",
      "Solution",
      "Failed to connect to MS Teams because of mismatching reply URLs",
      "Cause",
      "Solution",
      "Failed to connect to MS Teams because the refresh token has expired due to inactivity",
      "Cause",
      "Solution",
      "Failed to send notification messages to the channel",
      "Cause",
      "Solution",
      "Failed to append comments to the Discussions tab",
      "Cause"
    ],
    "keywords": [
      "https://{your",
      "90.00",
      "engine.log",
      "16.30827542",
      "rrorHandler.java",
      "springframework.web",
      "https://<External",
      "HttpClientErrorException.java",
      "RestTemplate.java",
      "troubleshoot",
      "microsoft",
      "teams",
      "integration",
      "ssl",
      "handshake",
      "failure",
      "cause",
      "solution",
      "failed",
      "run",
      "function",
      "connect",
      "ms",
      "because",
      "required",
      "string",
      "parameter",
      "code",
      "present",
      "mismatching",
      "reply",
      "urls",
      "refresh",
      "token",
      "expired",
      "due",
      "inactivity",
      "send",
      "notification",
      "messages",
      "channel",
      "append",
      "comments",
      "discussions",
      "tab",
      "public",
      "fqdn",
      "isn",
      "working",
      "following",
      "describes",
      "typical",
      "issues",
      "occur",
      "set",
      "based",
      "built-in",
      "framework.",
      "admin",
      "opens",
      "consent",
      "link",
      "browser",
      "page",
      "displays",
      "error",
      "about",
      "failure.",
      "there",
      "re",
      "proxy",
      "settings",
      "incorrect.",
      "add",
      "modify",
      "log",
      "suite",
      "administration",
      "suite-admin",
      "https",
      "bo.",
      "click",
      "configuration",
      "main",
      "menu",
      "settings.",
      "fields",
      "host",
      "hostname",
      "configured.",
      "port",
      "number",
      "proxy.",
      "optional",
      "username",
      "password",
      "enter",
      "server",
      "requires",
      "authentication."
    ],
    "language": "en",
    "word_count": 105,
    "importance_score": 6.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "troubleshoot microsoft teams integration",
    "contentLower": "the following describes typical issues that may occur when you set up microsoft teams integration based on the built-in integration framework. ssl handshake failure when you or your teams admin opens the consent link in a browser, the page displays an error about ssl handshake failure. cause there're no proxy settings or the settings are incorrect. solution add or modify your proxy settings: log in to suite administration as suite-admin: https://<external access host>/bo. click the configuration tab on the main menu, and then click proxy settings. set the following fields: proxy host: the hostname of the proxy you configured. proxy port: the port number of the proxy. (optional) proxy username and proxy password: enter the username and password if the proxy server requires authentication. click save. failed to run function you have successfully saved the field mappings for an ms teams channel, however, the integration fails at runtime. you can find the following message in the runtime l",
    "keywordsLower": [
      "https://{your",
      "90.00",
      "engine.log",
      "16.30827542",
      "rrorhandler.java",
      "springframework.web",
      "https://<external",
      "httpclienterrorexception.java",
      "resttemplate.java",
      "troubleshoot",
      "microsoft",
      "teams",
      "integration",
      "ssl",
      "handshake",
      "failure",
      "cause",
      "solution",
      "failed",
      "run",
      "function",
      "connect",
      "ms",
      "because",
      "required",
      "string",
      "parameter",
      "code",
      "present",
      "mismatching",
      "reply",
      "urls",
      "refresh",
      "token",
      "expired",
      "due",
      "inactivity",
      "send",
      "notification",
      "messages",
      "channel",
      "append",
      "comments",
      "discussions",
      "tab",
      "public",
      "fqdn",
      "isn",
      "working",
      "following",
      "describes",
      "typical",
      "issues",
      "occur",
      "set",
      "based",
      "built-in",
      "framework.",
      "admin",
      "opens",
      "consent",
      "link",
      "browser",
      "page",
      "displays",
      "error",
      "about",
      "failure.",
      "there",
      "re",
      "proxy",
      "settings",
      "incorrect.",
      "add",
      "modify",
      "log",
      "suite",
      "administration",
      "suite-admin",
      "https",
      "bo.",
      "click",
      "configuration",
      "main",
      "menu",
      "settings.",
      "fields",
      "host",
      "hostname",
      "configured.",
      "port",
      "number",
      "proxy.",
      "optional",
      "username",
      "password",
      "enter",
      "server",
      "requires",
      "authentication."
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Troubleshoot Core Content integration",
    "content": "If the agent user sees an error or a blank page after clicking the Related documents tab, perform the following troubleshooting procedure: Go to Administration > Utilities > Integration > Endpoints, and select the Core Content endpoint to check the execution history for the integration. Log in to Core Content and see if the workspace that is supposed to be created by the integration scenario exists. If you use the integration scenario's default settings for workspace names, the workspace names should follow this pattern: <Service Management record type> <entity Id>. For example, incident 12345. Turn off the browser setting that blocks cross-site tracking. Chrome: Click Settings > Privacy and security > Third-party cookies. Make sure Allow third-party cookies (under Default behavior) is selected, and the Send a \"Do Not Track\" request with your browsing traffic option is turned off. Firefox: Click Settings > Privacy and Security, and select Custom under Enhanced Tracking Protection. Make",
    "url": "troubleshootcorecontentintg",
    "filename": "troubleshootcorecontentintg",
    "headings": [],
    "keywords": [
      "troubleshoot",
      "core",
      "content",
      "integration",
      "agent",
      "user",
      "sees",
      "error",
      "blank",
      "page",
      "after",
      "clicking",
      "related",
      "documents",
      "tab",
      "perform",
      "following",
      "troubleshooting",
      "procedure",
      "go",
      "administration",
      "utilities",
      "endpoints",
      "select",
      "endpoint",
      "check",
      "execution",
      "history",
      "integration.",
      "log",
      "see",
      "workspace",
      "supposed",
      "created",
      "scenario",
      "exists.",
      "default",
      "settings",
      "names",
      "follow",
      "pattern",
      "example",
      "incident",
      "12345.",
      "turn",
      "off",
      "browser",
      "setting",
      "blocks",
      "cross-site",
      "tracking.",
      "chrome",
      "click",
      "privacy",
      "security",
      "third-party",
      "cookies.",
      "make",
      "sure",
      "allow",
      "cookies",
      "under",
      "behavior",
      "selected",
      "send",
      "track",
      "request",
      "browsing",
      "traffic",
      "option",
      "turned",
      "off.",
      "firefox",
      "custom",
      "enhanced",
      "tracking",
      "protection.",
      "box",
      "drop-down",
      "menu.",
      "microsoft",
      "edge",
      "search",
      "services.",
      "prevention",
      "delete",
      "clear",
      "data",
      "internet",
      "explorer",
      "protection",
      "activex",
      "filtering",
      "data.",
      "safari",
      "preferences",
      "privacy.",
      "prevent",
      "checkbox",
      "selected."
    ],
    "language": "en",
    "word_count": 99,
    "importance_score": 3.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "troubleshoot core content integration",
    "contentLower": "if the agent user sees an error or a blank page after clicking the related documents tab, perform the following troubleshooting procedure: go to administration > utilities > integration > endpoints, and select the core content endpoint to check the execution history for the integration. log in to core content and see if the workspace that is supposed to be created by the integration scenario exists. if you use the integration scenario's default settings for workspace names, the workspace names should follow this pattern: <service management record type> <entity id>. for example, incident 12345. turn off the browser setting that blocks cross-site tracking. chrome: click settings > privacy and security > third-party cookies. make sure allow third-party cookies (under default behavior) is selected, and the send a \"do not track\" request with your browsing traffic option is turned off. firefox: click settings > privacy and security, and select custom under enhanced tracking protection. make",
    "keywordsLower": [
      "troubleshoot",
      "core",
      "content",
      "integration",
      "agent",
      "user",
      "sees",
      "error",
      "blank",
      "page",
      "after",
      "clicking",
      "related",
      "documents",
      "tab",
      "perform",
      "following",
      "troubleshooting",
      "procedure",
      "go",
      "administration",
      "utilities",
      "endpoints",
      "select",
      "endpoint",
      "check",
      "execution",
      "history",
      "integration.",
      "log",
      "see",
      "workspace",
      "supposed",
      "created",
      "scenario",
      "exists.",
      "default",
      "settings",
      "names",
      "follow",
      "pattern",
      "example",
      "incident",
      "12345.",
      "turn",
      "off",
      "browser",
      "setting",
      "blocks",
      "cross-site",
      "tracking.",
      "chrome",
      "click",
      "privacy",
      "security",
      "third-party",
      "cookies.",
      "make",
      "sure",
      "allow",
      "cookies",
      "under",
      "behavior",
      "selected",
      "send",
      "track",
      "request",
      "browsing",
      "traffic",
      "option",
      "turned",
      "off.",
      "firefox",
      "custom",
      "enhanced",
      "tracking",
      "protection.",
      "box",
      "drop-down",
      "menu.",
      "microsoft",
      "edge",
      "search",
      "services.",
      "prevention",
      "delete",
      "clear",
      "data",
      "internet",
      "explorer",
      "protection",
      "activex",
      "filtering",
      "data.",
      "safari",
      "preferences",
      "privacy.",
      "prevent",
      "checkbox",
      "selected."
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Troubleshoot email integration",
    "content": "The following issues may arise when using the email integration. Be advised that in certain cases, the user may receive an email indicating that an error occurred. Request cannot be created from inbound email Failed to process email due to unauthorized email domain Request creation fails due to validation errors Request creation fails due to user permission issues Cannot perform action from notification email Email action fails because token has expired Email action fails because token has already been used Email fails to be processed due to invalid security token Email fails to be processed due to unknown user or address Email fails to be processed due to user mismatch New emails aren't processed Email integration task doesn't start Email integration tasks time out Email integration configuration changes aren't applied Email integration logs The On-Premises Bridge logs are located in the C:\\ProgramData\\MicroFocus\\On-Premise Bridge Agent\\product\\log directory. This directory contains a",
    "url": "troubleshootopbemailinteg",
    "filename": "troubleshootopbemailinteg",
    "headings": [
      "Email integration logs",
      "Related topics"
    ],
    "keywords": [
      "domain.log",
      "controller.log",
      "troubleshoot",
      "email",
      "integration",
      "logs",
      "related",
      "topics",
      "following",
      "issues",
      "arise",
      "integration.",
      "advised",
      "certain",
      "cases",
      "user",
      "receive",
      "indicating",
      "error",
      "occurred.",
      "request",
      "cannot",
      "created",
      "inbound",
      "failed",
      "process",
      "due",
      "unauthorized",
      "domain",
      "creation",
      "fails",
      "validation",
      "errors",
      "permission",
      "perform",
      "action",
      "notification",
      "because",
      "token",
      "expired",
      "already",
      "processed",
      "invalid",
      "security",
      "unknown",
      "address",
      "mismatch",
      "new",
      "emails",
      "aren",
      "task",
      "doesn",
      "start",
      "tasks",
      "time",
      "out",
      "configuration",
      "changes",
      "applied",
      "on-premises",
      "bridge",
      "located",
      "programdata",
      "microfocus",
      "on-premise",
      "agent",
      "product",
      "log",
      "directory.",
      "directory",
      "contains",
      "controller",
      "folder",
      "email-integration-domain",
      "folder.",
      "confirm",
      "running",
      "look",
      "file.",
      "generally",
      "appear",
      "file",
      "login",
      "password",
      "working.",
      "email-integration-domain.log.x.x",
      "through",
      "most",
      "recent",
      "any",
      "errors.",
      "there",
      "external",
      "account",
      "incorrect.",
      "inbox",
      "found",
      "indicate",
      "firewall",
      "blocking"
    ],
    "language": "en",
    "word_count": 120,
    "importance_score": 4.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "troubleshoot email integration",
    "contentLower": "the following issues may arise when using the email integration. be advised that in certain cases, the user may receive an email indicating that an error occurred. request cannot be created from inbound email failed to process email due to unauthorized email domain request creation fails due to validation errors request creation fails due to user permission issues cannot perform action from notification email email action fails because token has expired email action fails because token has already been used email fails to be processed due to invalid security token email fails to be processed due to unknown user or address email fails to be processed due to user mismatch new emails aren't processed email integration task doesn't start email integration tasks time out email integration configuration changes aren't applied email integration logs the on-premises bridge logs are located in the c:\\programdata\\microfocus\\on-premise bridge agent\\product\\log directory. this directory contains a",
    "keywordsLower": [
      "domain.log",
      "controller.log",
      "troubleshoot",
      "email",
      "integration",
      "logs",
      "related",
      "topics",
      "following",
      "issues",
      "arise",
      "integration.",
      "advised",
      "certain",
      "cases",
      "user",
      "receive",
      "indicating",
      "error",
      "occurred.",
      "request",
      "cannot",
      "created",
      "inbound",
      "failed",
      "process",
      "due",
      "unauthorized",
      "domain",
      "creation",
      "fails",
      "validation",
      "errors",
      "permission",
      "perform",
      "action",
      "notification",
      "because",
      "token",
      "expired",
      "already",
      "processed",
      "invalid",
      "security",
      "unknown",
      "address",
      "mismatch",
      "new",
      "emails",
      "aren",
      "task",
      "doesn",
      "start",
      "tasks",
      "time",
      "out",
      "configuration",
      "changes",
      "applied",
      "on-premises",
      "bridge",
      "located",
      "programdata",
      "microfocus",
      "on-premise",
      "agent",
      "product",
      "log",
      "directory.",
      "directory",
      "contains",
      "controller",
      "folder",
      "email-integration-domain",
      "folder.",
      "confirm",
      "running",
      "look",
      "file.",
      "generally",
      "appear",
      "file",
      "login",
      "password",
      "working.",
      "email-integration-domain.log.x.x",
      "through",
      "most",
      "recent",
      "any",
      "errors.",
      "there",
      "external",
      "account",
      "incorrect.",
      "inbox",
      "found",
      "indicate",
      "firewall",
      "blocking"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Request can't be created from inbound email",
    "content": "The system can't create requests from inbound email. Causes Cause 1: the Enable request creation and actions from email option is disabled. Cause 2: the .eml file extension isn't in the attachment allowlist. Cause 3: The email address of the inbound email isn't in the SMA system. In this case, the system generates an \"unknown sender\" email if the Enable error notifications to unknown senders option is enabled on the Administration > Configuration > Service Portal Settings > Feature Settings page. Solutions Solution 1 Do the following: In the agent interface, select Administration > Configuration > Service Portal Settings > Feature Settings. In the Enable request creation and actions from email field, select On. Solution 2 Log in to Suite Administration as suite-admin, open the tenant record, click the Application settings tab, and then add eml to the Attachment allowlist field. Solution 3 Check that the user is using the correct email address that's defined in the user record in Servic",
    "url": "emailintegdisabled",
    "filename": "emailintegdisabled",
    "headings": [
      "Causes",
      "Solutions",
      "Solution 1",
      "Solution 2",
      "Solution 3"
    ],
    "keywords": [
      "cant",
      "request",
      "created",
      "inbound",
      "email",
      "causes",
      "solutions",
      "solution",
      "system",
      "create",
      "requests",
      "email.",
      "cause",
      "enable",
      "creation",
      "actions",
      "option",
      "disabled.",
      ".eml",
      "file",
      "extension",
      "isn",
      "attachment",
      "allowlist.",
      "address",
      "sma",
      "system.",
      "case",
      "generates",
      "unknown",
      "sender",
      "error",
      "notifications",
      "senders",
      "enabled",
      "administration",
      "configuration",
      "service",
      "portal",
      "settings",
      "feature",
      "page.",
      "following",
      "agent",
      "interface",
      "select",
      "settings.",
      "field",
      "on.",
      "log",
      "suite",
      "suite-admin",
      "open",
      "tenant",
      "record",
      "click",
      "application",
      "tab",
      "add",
      "eml",
      "allowlist",
      "field.",
      "check",
      "user",
      "correct",
      "defined",
      "management."
    ],
    "language": "en",
    "word_count": 113,
    "importance_score": 4.5,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "request can't be created from inbound email",
    "contentLower": "the system can't create requests from inbound email. causes cause 1: the enable request creation and actions from email option is disabled. cause 2: the .eml file extension isn't in the attachment allowlist. cause 3: the email address of the inbound email isn't in the sma system. in this case, the system generates an \"unknown sender\" email if the enable error notifications to unknown senders option is enabled on the administration > configuration > service portal settings > feature settings page. solutions solution 1 do the following: in the agent interface, select administration > configuration > service portal settings > feature settings. in the enable request creation and actions from email field, select on. solution 2 log in to suite administration as suite-admin, open the tenant record, click the application settings tab, and then add eml to the attachment allowlist field. solution 3 check that the user is using the correct email address that's defined in the user record in servic",
    "keywordsLower": [
      "cant",
      "request",
      "created",
      "inbound",
      "email",
      "causes",
      "solutions",
      "solution",
      "system",
      "create",
      "requests",
      "email.",
      "cause",
      "enable",
      "creation",
      "actions",
      "option",
      "disabled.",
      ".eml",
      "file",
      "extension",
      "isn",
      "attachment",
      "allowlist.",
      "address",
      "sma",
      "system.",
      "case",
      "generates",
      "unknown",
      "sender",
      "error",
      "notifications",
      "senders",
      "enabled",
      "administration",
      "configuration",
      "service",
      "portal",
      "settings",
      "feature",
      "page.",
      "following",
      "agent",
      "interface",
      "select",
      "settings.",
      "field",
      "on.",
      "log",
      "suite",
      "suite-admin",
      "open",
      "tenant",
      "record",
      "click",
      "application",
      "tab",
      "add",
      "eml",
      "allowlist",
      "field.",
      "check",
      "user",
      "correct",
      "defined",
      "management."
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Request creation fails due to validation errors",
    "content": "The task to create a request via email fails. The user receives the following email notification: We could not create your request because we need more information, which may be system-related. For details, contact your system administrator. To create a new request, log in to the Service Portal. Cause The creation of a request fails due to validation errors. Solution Fine-tune the request creation process: Make sure all users have an entitled default offering and that the default offering consists of default values for all mandatory request fields, OR that a request that has only a title and description can be created.",
    "url": "emailintegrequestcreationfailssystemrelated",
    "filename": "emailintegrequestcreationfailssystemrelated",
    "headings": [
      "Cause",
      "Solution"
    ],
    "keywords": [
      "request",
      "creation",
      "fails",
      "due",
      "validation",
      "errors",
      "cause",
      "solution",
      "task",
      "create",
      "via",
      "email",
      "fails.",
      "user",
      "receives",
      "following",
      "notification",
      "because",
      "need",
      "information",
      "system-related.",
      "details",
      "contact",
      "system",
      "administrator.",
      "new",
      "log",
      "service",
      "portal.",
      "errors.",
      "fine-tune",
      "process",
      "make",
      "sure",
      "all",
      "users",
      "entitled",
      "default",
      "offering",
      "consists",
      "values",
      "mandatory",
      "fields",
      "title",
      "description",
      "created."
    ],
    "language": "en",
    "word_count": 65,
    "importance_score": 3.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "request creation fails due to validation errors",
    "contentLower": "the task to create a request via email fails. the user receives the following email notification: we could not create your request because we need more information, which may be system-related. for details, contact your system administrator. to create a new request, log in to the service portal. cause the creation of a request fails due to validation errors. solution fine-tune the request creation process: make sure all users have an entitled default offering and that the default offering consists of default values for all mandatory request fields, or that a request that has only a title and description can be created.",
    "keywordsLower": [
      "request",
      "creation",
      "fails",
      "due",
      "validation",
      "errors",
      "cause",
      "solution",
      "task",
      "create",
      "via",
      "email",
      "fails.",
      "user",
      "receives",
      "following",
      "notification",
      "because",
      "need",
      "information",
      "system-related.",
      "details",
      "contact",
      "system",
      "administrator.",
      "new",
      "log",
      "service",
      "portal.",
      "errors.",
      "fine-tune",
      "process",
      "make",
      "sure",
      "all",
      "users",
      "entitled",
      "default",
      "offering",
      "consists",
      "values",
      "mandatory",
      "fields",
      "title",
      "description",
      "created."
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Request creation fails due to user permission issues",
    "content": "The task to create a request via email fails. The user receives the following email notification: We could not create your request because we need more information, which may be system-related. For details, contact your system administrator. To create a new request, log in to the Service Portal. Cause The creation of a request fails because a user doesn't have correct permission to create a request. By default, the Service Portal User role has permission to create requests. If a user can't create requests, the user is either not defined in Service Management or doesn't have the Service Portal User role. Solution Create the user in Service Management and assign them the Service Portal User role or the permission to create requests.",
    "url": "emailintegrequestcreationfailspermissionrelated",
    "filename": "emailintegrequestcreationfailspermissionrelated",
    "headings": [
      "Cause",
      "Solution"
    ],
    "keywords": [
      "request",
      "creation",
      "fails",
      "due",
      "user",
      "permission",
      "issues",
      "cause",
      "solution",
      "task",
      "create",
      "via",
      "email",
      "fails.",
      "receives",
      "following",
      "notification",
      "because",
      "need",
      "information",
      "system-related.",
      "details",
      "contact",
      "system",
      "administrator.",
      "new",
      "log",
      "service",
      "portal.",
      "doesn",
      "correct",
      "request.",
      "default",
      "portal",
      "role",
      "requests.",
      "requests",
      "either",
      "defined",
      "management",
      "role.",
      "assign"
    ],
    "language": "en",
    "word_count": 82,
    "importance_score": 3.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "request creation fails due to user permission issues",
    "contentLower": "the task to create a request via email fails. the user receives the following email notification: we could not create your request because we need more information, which may be system-related. for details, contact your system administrator. to create a new request, log in to the service portal. cause the creation of a request fails because a user doesn't have correct permission to create a request. by default, the service portal user role has permission to create requests. if a user can't create requests, the user is either not defined in service management or doesn't have the service portal user role. solution create the user in service management and assign them the service portal user role or the permission to create requests.",
    "keywordsLower": [
      "request",
      "creation",
      "fails",
      "due",
      "user",
      "permission",
      "issues",
      "cause",
      "solution",
      "task",
      "create",
      "via",
      "email",
      "fails.",
      "receives",
      "following",
      "notification",
      "because",
      "need",
      "information",
      "system-related.",
      "details",
      "contact",
      "system",
      "administrator.",
      "new",
      "log",
      "service",
      "portal.",
      "doesn",
      "correct",
      "request.",
      "default",
      "portal",
      "role",
      "requests.",
      "requests",
      "either",
      "defined",
      "management",
      "role.",
      "assign"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Troubleshoot infrastructure",
    "content": "This section provides the following troubleshooting topics: Pod stuck in Terminating status Pods in Pending state after worker node reboot Suite pods have errors and cannot recover Suite isn't accessible Performance: Linux buffer isn't released Performance: kernel soft lockup issue Performance: high CPU ready issues on ESX TLS protocol version and cipher suite issue Worker node is lost in K8S cluster Disk full issue with NFS server Invalid token when SAML users log in to the system",
    "url": "troubleshootinfra",
    "filename": "troubleshootinfra",
    "headings": [],
    "keywords": [
      "troubleshoot",
      "infrastructure",
      "section",
      "provides",
      "following",
      "troubleshooting",
      "topics",
      "pod",
      "stuck",
      "terminating",
      "status",
      "pods",
      "pending",
      "state",
      "after",
      "worker",
      "node",
      "reboot",
      "suite",
      "errors",
      "cannot",
      "recover",
      "isn",
      "accessible",
      "performance",
      "linux",
      "buffer",
      "released",
      "kernel",
      "soft",
      "lockup",
      "issue",
      "high",
      "cpu",
      "ready",
      "issues",
      "esx",
      "tls",
      "protocol",
      "version",
      "cipher",
      "lost",
      "k8s",
      "cluster",
      "disk",
      "full",
      "nfs",
      "server",
      "invalid",
      "token",
      "saml",
      "users",
      "log",
      "system"
    ],
    "language": "en",
    "word_count": 66,
    "importance_score": 2.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "troubleshoot infrastructure",
    "contentLower": "this section provides the following troubleshooting topics: pod stuck in terminating status pods in pending state after worker node reboot suite pods have errors and cannot recover suite isn't accessible performance: linux buffer isn't released performance: kernel soft lockup issue performance: high cpu ready issues on esx tls protocol version and cipher suite issue worker node is lost in k8s cluster disk full issue with nfs server invalid token when saml users log in to the system",
    "keywordsLower": [
      "troubleshoot",
      "infrastructure",
      "section",
      "provides",
      "following",
      "troubleshooting",
      "topics",
      "pod",
      "stuck",
      "terminating",
      "status",
      "pods",
      "pending",
      "state",
      "after",
      "worker",
      "node",
      "reboot",
      "suite",
      "errors",
      "cannot",
      "recover",
      "isn",
      "accessible",
      "performance",
      "linux",
      "buffer",
      "released",
      "kernel",
      "soft",
      "lockup",
      "issue",
      "high",
      "cpu",
      "ready",
      "issues",
      "esx",
      "tls",
      "protocol",
      "version",
      "cipher",
      "lost",
      "k8s",
      "cluster",
      "disk",
      "full",
      "nfs",
      "server",
      "invalid",
      "token",
      "saml",
      "users",
      "log",
      "system"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Suite pods have errors and can't recover",
    "content": "Suite pods have errors and can't go back to normal. Cause The cause for this issue is unknown. Solution Reinstall the suite. To do this, follow these steps: Uninstall the suite. Reinstall the suite from the ITOM OMT UI.",
    "url": "podscannotrecover",
    "filename": "podscannotrecover",
    "headings": [
      "Cause",
      "Solution"
    ],
    "keywords": [
      "cant",
      "suite",
      "pods",
      "errors",
      "recover",
      "cause",
      "solution",
      "go",
      "back",
      "normal.",
      "issue",
      "unknown.",
      "reinstall",
      "suite.",
      "follow",
      "steps",
      "uninstall",
      "itom",
      "omt",
      "ui."
    ],
    "language": "en",
    "word_count": 28,
    "importance_score": 2.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "suite pods have errors and can't recover",
    "contentLower": "suite pods have errors and can't go back to normal. cause the cause for this issue is unknown. solution reinstall the suite. to do this, follow these steps: uninstall the suite. reinstall the suite from the itom omt ui.",
    "keywordsLower": [
      "cant",
      "suite",
      "pods",
      "errors",
      "recover",
      "cause",
      "solution",
      "go",
      "back",
      "normal.",
      "issue",
      "unknown.",
      "reinstall",
      "suite.",
      "follow",
      "steps",
      "uninstall",
      "itom",
      "omt",
      "ui."
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Suite isn't accessible",
    "content": "The suite is down and you can't access the suite. Cause Run the following command on the control plane node or bastion host: kubectl get pods --all-namespaces -o wide Check the last column for the IP addresses of the pods' worker nodes. These pods used to run in parallel, but all the pods are now running on a single node if the IP addresses are the same. Solution Check the node status by running the kubectl describe node command. Pay attention to the events and resource parts. To ensure a stable suite deployment, it's advisable that you use three control plane nodes and at least three worker nodes depending on your suite size.",
    "url": "suitenotaccessible",
    "filename": "suitenotaccessible",
    "headings": [
      "Cause",
      "Solution"
    ],
    "keywords": [
      "isnt",
      "suite",
      "isn",
      "accessible",
      "cause",
      "solution",
      "access",
      "suite.",
      "run",
      "following",
      "command",
      "control",
      "plane",
      "node",
      "bastion",
      "host",
      "kubectl",
      "get",
      "pods",
      "--all-namespaces",
      "-o",
      "wide",
      "check",
      "last",
      "column",
      "ip",
      "addresses",
      "worker",
      "nodes.",
      "parallel",
      "all",
      "now",
      "running",
      "single",
      "same.",
      "status",
      "describe",
      "command.",
      "pay",
      "attention",
      "events",
      "resource",
      "parts.",
      "ensure",
      "stable",
      "deployment",
      "advisable",
      "three",
      "nodes",
      "least",
      "depending",
      "size."
    ],
    "language": "en",
    "word_count": 74,
    "importance_score": 4.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "suite isn't accessible",
    "contentLower": "the suite is down and you can't access the suite. cause run the following command on the control plane node or bastion host: kubectl get pods --all-namespaces -o wide check the last column for the ip addresses of the pods' worker nodes. these pods used to run in parallel, but all the pods are now running on a single node if the ip addresses are the same. solution check the node status by running the kubectl describe node command. pay attention to the events and resource parts. to ensure a stable suite deployment, it's advisable that you use three control plane nodes and at least three worker nodes depending on your suite size.",
    "keywordsLower": [
      "isnt",
      "suite",
      "isn",
      "accessible",
      "cause",
      "solution",
      "access",
      "suite.",
      "run",
      "following",
      "command",
      "control",
      "plane",
      "node",
      "bastion",
      "host",
      "kubectl",
      "get",
      "pods",
      "--all-namespaces",
      "-o",
      "wide",
      "check",
      "last",
      "column",
      "ip",
      "addresses",
      "worker",
      "nodes.",
      "parallel",
      "all",
      "now",
      "running",
      "single",
      "same.",
      "status",
      "describe",
      "command.",
      "pay",
      "attention",
      "events",
      "resource",
      "parts.",
      "ensure",
      "stable",
      "deployment",
      "advisable",
      "three",
      "nodes",
      "least",
      "depending",
      "size."
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "TLS protocol version and cipher suite issue",
    "content": "You may receive the following error message if your browser doesn't support TLSv1.2 and TLSv1.3 and particular cipher suite: Turn on TLS 1.0, TLS 1.1, TLS 1.2 and TLS 1.3 in Advanced settings and try connecting to https://example.domain:5443 again. If this error persists, it's possible that this site uses an unsupported protocol or cipher suite such as RC4 (link for the details), which isn't considered secure. Please contact your site administrator. You may encounter an SSL handshake failure error when you call the suite API or access the suite from a mobile device. Cause By default, the SMA ingress service has been set to support only TLS versions 1.2 and 1.3 and specific secure cipher suites in order to mitigate vulnerabilities in other SSL/TLS versions and cipher suites. Solution To resolve this issue, you can configure the suite to support other ciphers and lower version protocols by following these steps: This solution may increase system vulnerabilities. Be careful when you perfo",
    "url": "tlsprotocolversionissue",
    "filename": "tlsprotocolversionissue",
    "headings": [
      "Cause",
      "Solution"
    ],
    "keywords": [
      "1.0",
      "1.3",
      "https://example.domain:5443",
      "1.1",
      "1.2",
      "tls",
      "protocol",
      "version",
      "cipher",
      "suite",
      "issue",
      "cause",
      "solution",
      "receive",
      "following",
      "error",
      "message",
      "browser",
      "doesn",
      "support",
      "tlsv1.2",
      "tlsv1.3",
      "particular",
      "turn",
      "advanced",
      "settings",
      "try",
      "connecting",
      "https",
      "example.domain",
      "5443",
      "again.",
      "persists",
      "possible",
      "site",
      "uses",
      "unsupported",
      "such",
      "rc4",
      "link",
      "details",
      "isn",
      "considered",
      "secure.",
      "please",
      "contact",
      "administrator.",
      "encounter",
      "ssl",
      "handshake",
      "failure",
      "call",
      "api",
      "access",
      "mobile",
      "device.",
      "default",
      "sma",
      "ingress",
      "service",
      "set",
      "versions",
      "specific",
      "secure",
      "suites",
      "order",
      "mitigate",
      "vulnerabilities",
      "suites.",
      "resolve",
      "configure",
      "ciphers",
      "lower",
      "protocols",
      "steps",
      "increase",
      "system",
      "vulnerabilities.",
      "careful",
      "perform",
      "steps.",
      "log",
      "control",
      "plane",
      "node",
      "run",
      "command",
      "modify",
      "kubectl",
      "patch",
      "cm",
      "itom-ingress-controller-conf",
      "-n",
      "itsma1",
      "-p",
      "data",
      "ssl-protocols",
      "tlsv1.1",
      "tlsv1",
      "ssl-ciphers"
    ],
    "language": "en",
    "word_count": 111,
    "importance_score": 3.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "tls protocol version and cipher suite issue",
    "contentLower": "you may receive the following error message if your browser doesn't support tlsv1.2 and tlsv1.3 and particular cipher suite: turn on tls 1.0, tls 1.1, tls 1.2 and tls 1.3 in advanced settings and try connecting to https://example.domain:5443 again. if this error persists, it's possible that this site uses an unsupported protocol or cipher suite such as rc4 (link for the details), which isn't considered secure. please contact your site administrator. you may encounter an ssl handshake failure error when you call the suite api or access the suite from a mobile device. cause by default, the sma ingress service has been set to support only tls versions 1.2 and 1.3 and specific secure cipher suites in order to mitigate vulnerabilities in other ssl/tls versions and cipher suites. solution to resolve this issue, you can configure the suite to support other ciphers and lower version protocols by following these steps: this solution may increase system vulnerabilities. be careful when you perfo",
    "keywordsLower": [
      "1.0",
      "1.3",
      "https://example.domain:5443",
      "1.1",
      "1.2",
      "tls",
      "protocol",
      "version",
      "cipher",
      "suite",
      "issue",
      "cause",
      "solution",
      "receive",
      "following",
      "error",
      "message",
      "browser",
      "doesn",
      "support",
      "tlsv1.2",
      "tlsv1.3",
      "particular",
      "turn",
      "advanced",
      "settings",
      "try",
      "connecting",
      "https",
      "example.domain",
      "5443",
      "again.",
      "persists",
      "possible",
      "site",
      "uses",
      "unsupported",
      "such",
      "rc4",
      "link",
      "details",
      "isn",
      "considered",
      "secure.",
      "please",
      "contact",
      "administrator.",
      "encounter",
      "ssl",
      "handshake",
      "failure",
      "call",
      "api",
      "access",
      "mobile",
      "device.",
      "default",
      "sma",
      "ingress",
      "service",
      "set",
      "versions",
      "specific",
      "secure",
      "suites",
      "order",
      "mitigate",
      "vulnerabilities",
      "suites.",
      "resolve",
      "configure",
      "ciphers",
      "lower",
      "protocols",
      "steps",
      "increase",
      "system",
      "vulnerabilities.",
      "careful",
      "perform",
      "steps.",
      "log",
      "control",
      "plane",
      "node",
      "run",
      "command",
      "modify",
      "kubectl",
      "patch",
      "cm",
      "itom-ingress-controller-conf",
      "-n",
      "itsma1",
      "-p",
      "data",
      "ssl-protocols",
      "tlsv1.1",
      "tlsv1",
      "ssl-ciphers"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "RabbitMQ network partition occurs",
    "content": "A RabbitMQ network partition occurs. How to detect a RabbitMQ network partition in a living system When all three RabbitMQ pods are running with 2/2, check if the cluster has a split-brain. To do this, perform the following steps on a control plane node or the bastion node. Your machine must have the jq command installed to run some of the commands below. Before you begin, make sure your machine has already this command installed. Check the running status of RabbitMQ pods. nms=`kubectl get pods -A|grep rabbit|head -n 1|awk '{print $1}'`; if [[ `kubectl exec -it infra-rabbitmq-0 -c itom-xruntime-rabbitmq -n ${nms} -- rabbitmqctl cluster_status --formatter json| grep -v RABBITMQ_ERLANG_COOKIE |jq '.running_nodes'|jq 'length'` != \"3\" ]] && [[ `kubectl exec -it infra-rabbitmq-1 -c itom-xruntime-rabbitmq -n ${nms} -- rabbitmqctl cluster_status --formatter json| grep -v RABBITMQ_ERLANG_COOKIE |jq '.running_nodes'|jq 'length'` != \"3\" ]] && [[ `kubectl exec -it infra-rabbitmq-2 -c itom-xruntim",
    "url": "rabbitmqnetworkpartition",
    "filename": "rabbitmqnetworkpartition",
    "headings": [
      "How to detect a RabbitMQ network partition in a living system",
      "How to identify if a network partition has happened before",
      "Scenario 1",
      "Scenario 2"
    ],
    "keywords": [
      "xxxxx.svc",
      "1.saw",
      "x.xx",
      "2.saw",
      "0.saw",
      "rabbitmq",
      "network",
      "partition",
      "occurs",
      "detect",
      "living",
      "system",
      "identify",
      "happened",
      "before",
      "scenario",
      "occurs.",
      "all",
      "three",
      "pods",
      "running",
      "check",
      "cluster",
      "split-brain.",
      "perform",
      "following",
      "steps",
      "control",
      "plane",
      "node",
      "bastion",
      "node.",
      "machine",
      "jq",
      "command",
      "installed",
      "run",
      "commands",
      "below.",
      "begin",
      "make",
      "sure",
      "already",
      "installed.",
      "status",
      "pods.",
      "nms",
      "kubectl",
      "get",
      "-a",
      "grep",
      "rabbit",
      "head",
      "-n",
      "awk",
      "print",
      "exec",
      "-it",
      "infra-rabbitmq-0",
      "-c",
      "itom-xruntime-rabbitmq",
      "rabbitmqctl",
      "--formatter",
      "json",
      "-v",
      "length",
      "infra-rabbitmq-1",
      "infra-rabbitmq-2",
      "echo",
      "happens.",
      "else",
      "partition.",
      "fi",
      "see",
      "nodes",
      "rabbitmqnetworkpartition",
      "there",
      "try",
      "scale",
      "replica",
      "1.",
      "statefulset",
      "infra-rabbitmq",
      "itsma-undnc",
      "--replicas",
      "wait",
      "until",
      "becomes",
      "3.",
      "rerun",
      "step",
      "status.",
      "scaling",
      "out",
      "doesn",
      "help",
      "prepare",
      "refresh",
      "start.",
      "start"
    ],
    "language": "en",
    "word_count": 113,
    "importance_score": 5.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "rabbitmq network partition occurs",
    "contentLower": "a rabbitmq network partition occurs. how to detect a rabbitmq network partition in a living system when all three rabbitmq pods are running with 2/2, check if the cluster has a split-brain. to do this, perform the following steps on a control plane node or the bastion node. your machine must have the jq command installed to run some of the commands below. before you begin, make sure your machine has already this command installed. check the running status of rabbitmq pods. nms=`kubectl get pods -a|grep rabbit|head -n 1|awk '{print $1}'`; if [[ `kubectl exec -it infra-rabbitmq-0 -c itom-xruntime-rabbitmq -n ${nms} -- rabbitmqctl cluster_status --formatter json| grep -v rabbitmq_erlang_cookie |jq '.running_nodes'|jq 'length'` != \"3\" ]] && [[ `kubectl exec -it infra-rabbitmq-1 -c itom-xruntime-rabbitmq -n ${nms} -- rabbitmqctl cluster_status --formatter json| grep -v rabbitmq_erlang_cookie |jq '.running_nodes'|jq 'length'` != \"3\" ]] && [[ `kubectl exec -it infra-rabbitmq-2 -c itom-xruntim",
    "keywordsLower": [
      "xxxxx.svc",
      "1.saw",
      "x.xx",
      "2.saw",
      "0.saw",
      "rabbitmq",
      "network",
      "partition",
      "occurs",
      "detect",
      "living",
      "system",
      "identify",
      "happened",
      "before",
      "scenario",
      "occurs.",
      "all",
      "three",
      "pods",
      "running",
      "check",
      "cluster",
      "split-brain.",
      "perform",
      "following",
      "steps",
      "control",
      "plane",
      "node",
      "bastion",
      "node.",
      "machine",
      "jq",
      "command",
      "installed",
      "run",
      "commands",
      "below.",
      "begin",
      "make",
      "sure",
      "already",
      "installed.",
      "status",
      "pods.",
      "nms",
      "kubectl",
      "get",
      "-a",
      "grep",
      "rabbit",
      "head",
      "-n",
      "awk",
      "print",
      "exec",
      "-it",
      "infra-rabbitmq-0",
      "-c",
      "itom-xruntime-rabbitmq",
      "rabbitmqctl",
      "--formatter",
      "json",
      "-v",
      "length",
      "infra-rabbitmq-1",
      "infra-rabbitmq-2",
      "echo",
      "happens.",
      "else",
      "partition.",
      "fi",
      "see",
      "nodes",
      "rabbitmqnetworkpartition",
      "there",
      "try",
      "scale",
      "replica",
      "1.",
      "statefulset",
      "infra-rabbitmq",
      "itsma-undnc",
      "--replicas",
      "wait",
      "until",
      "becomes",
      "3.",
      "rerun",
      "step",
      "status.",
      "scaling",
      "out",
      "doesn",
      "help",
      "prepare",
      "refresh",
      "start.",
      "start"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "RabbitMQ isn't ready",
    "content": "The infra-rabbitmq-<n> (<n>=0, 1, or 2) pod isn't ready and its readiness state is stuck in 1/2. For example: NAME READY STATUS RESTARTS AGE infra-rabbitmq-0 1/2 Running 0 16h Cause This issue has many causes. For example: The environment wasn't shut down gracefully. For example, you powered off the environment without first shutting down Service Management and OMT.Your system has insufficient hardware resources.There are network connectivity issues between the NFS server and the worker nodes. Solution When RabbitMQ fails to start twice, the system automatically performs a fresh start of RabbitMQ. Therefore, when this issue occurs, first wait 15 minutes, and then check if the issue is resolved automatically. If the problem still persists, check the system resources and network connectivity. If there's no resource or network issue, manually restart RabbitMQ. To do this, follow these steps: Run the following command on a master node (embedded Kubernetes) or the bastion node (managed Kube",
    "url": "rabbitmqnotstart",
    "filename": "rabbitmqnotstart",
    "headings": [
      "Cause",
      "Solution"
    ],
    "keywords": [
      "isnt",
      "x.xx",
      "OMT.Your",
      "rabbitmq",
      "isn",
      "ready",
      "cause",
      "solution",
      "infra-rabbitmq-",
      "pod",
      "readiness",
      "state",
      "stuck",
      "2.",
      "example",
      "name",
      "status",
      "restarts",
      "age",
      "infra-rabbitmq-0",
      "running",
      "16h",
      "issue",
      "many",
      "causes.",
      "environment",
      "wasn",
      "shut",
      "gracefully.",
      "powered",
      "off",
      "first",
      "shutting",
      "service",
      "management",
      "system",
      "insufficient",
      "hardware",
      "resources.there",
      "network",
      "connectivity",
      "issues",
      "between",
      "nfs",
      "server",
      "worker",
      "nodes.",
      "fails",
      "start",
      "twice",
      "automatically",
      "performs",
      "fresh",
      "rabbitmq.",
      "therefore",
      "occurs",
      "wait",
      "15",
      "minutes",
      "check",
      "resolved",
      "automatically.",
      "problem",
      "still",
      "persists",
      "resources",
      "connectivity.",
      "there",
      "resource",
      "manually",
      "restart",
      "follow",
      "steps",
      "run",
      "following",
      "command",
      "master",
      "node",
      "embedded",
      "kubernetes",
      "bastion",
      "managed",
      "stop",
      "kubectl",
      "scale",
      "statefulset",
      "infra-rabbitmq",
      "-n",
      "--replicas",
      "until",
      "all",
      "pods",
      "terminated.",
      "remove",
      "data",
      "xservices",
      "x.x.x.xx",
      "mnesia",
      "folders",
      "server."
    ],
    "language": "en",
    "word_count": 111,
    "importance_score": 4.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "rabbitmq isn't ready",
    "contentLower": "the infra-rabbitmq-<n> (<n>=0, 1, or 2) pod isn't ready and its readiness state is stuck in 1/2. for example: name ready status restarts age infra-rabbitmq-0 1/2 running 0 16h cause this issue has many causes. for example: the environment wasn't shut down gracefully. for example, you powered off the environment without first shutting down service management and omt.your system has insufficient hardware resources.there are network connectivity issues between the nfs server and the worker nodes. solution when rabbitmq fails to start twice, the system automatically performs a fresh start of rabbitmq. therefore, when this issue occurs, first wait 15 minutes, and then check if the issue is resolved automatically. if the problem still persists, check the system resources and network connectivity. if there's no resource or network issue, manually restart rabbitmq. to do this, follow these steps: run the following command on a master node (embedded kubernetes) or the bastion node (managed kube",
    "keywordsLower": [
      "isnt",
      "x.xx",
      "omt.your",
      "rabbitmq",
      "isn",
      "ready",
      "cause",
      "solution",
      "infra-rabbitmq-",
      "pod",
      "readiness",
      "state",
      "stuck",
      "2.",
      "example",
      "name",
      "status",
      "restarts",
      "age",
      "infra-rabbitmq-0",
      "running",
      "16h",
      "issue",
      "many",
      "causes.",
      "environment",
      "wasn",
      "shut",
      "gracefully.",
      "powered",
      "off",
      "first",
      "shutting",
      "service",
      "management",
      "system",
      "insufficient",
      "hardware",
      "resources.there",
      "network",
      "connectivity",
      "issues",
      "between",
      "nfs",
      "server",
      "worker",
      "nodes.",
      "fails",
      "start",
      "twice",
      "automatically",
      "performs",
      "fresh",
      "rabbitmq.",
      "therefore",
      "occurs",
      "wait",
      "15",
      "minutes",
      "check",
      "resolved",
      "automatically.",
      "problem",
      "still",
      "persists",
      "resources",
      "connectivity.",
      "there",
      "resource",
      "manually",
      "restart",
      "follow",
      "steps",
      "run",
      "following",
      "command",
      "master",
      "node",
      "embedded",
      "kubernetes",
      "bastion",
      "managed",
      "stop",
      "kubectl",
      "scale",
      "statefulset",
      "infra-rabbitmq",
      "-n",
      "--replicas",
      "until",
      "all",
      "pods",
      "terminated.",
      "remove",
      "data",
      "xservices",
      "x.x.x.xx",
      "mnesia",
      "folders",
      "server."
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Troubleshoot Design and Deploy",
    "content": "This section covers the following troubleshooting topics. Collection of images doesn't start automatically Data limit exceeded for zone and instance Default proxy settings disappear while creating a provider integration DND application log files not found after upgrade DND capability deployment fails DND deployment fails with \"DND content install failed for tenant...\" error DND service consumes extra CPU cores causing higher utilization on worker node Dynamic options don't load after changing credentials Error when importing an image after upgrade ESM API: Call to SMAX failed External validation failed IA: Editing a design fails with 'auto_scaling_config error' Image aggregation page fails to load Image Aggregation - Null value in 'tenant_id' column Incorrect message displayed while accessing the menu \"Design\" Instance type doesn't load for IA running on public cloud java.lang.RuntimeException error while viewing status in Deployment Operations OO flow Get Guest Info fails with error j",
    "url": "troubleshoot_design_and_deploy",
    "filename": "troubleshoot_design_and_deploy",
    "headings": [],
    "keywords": [
      "java.lang",
      "troubleshoot",
      "design",
      "deploy",
      "section",
      "covers",
      "following",
      "troubleshooting",
      "topics.",
      "collection",
      "images",
      "doesn",
      "start",
      "automatically",
      "data",
      "limit",
      "exceeded",
      "zone",
      "instance",
      "default",
      "proxy",
      "settings",
      "disappear",
      "while",
      "creating",
      "provider",
      "integration",
      "dnd",
      "application",
      "log",
      "files",
      "found",
      "after",
      "upgrade",
      "capability",
      "deployment",
      "fails",
      "content",
      "install",
      "failed",
      "tenant...",
      "error",
      "service",
      "consumes",
      "extra",
      "cpu",
      "cores",
      "causing",
      "higher",
      "utilization",
      "worker",
      "node",
      "dynamic",
      "options",
      "don",
      "load",
      "changing",
      "credentials",
      "importing",
      "image",
      "esm",
      "api",
      "call",
      "smax",
      "external",
      "validation",
      "ia",
      "editing",
      "aggregation",
      "page",
      "null",
      "value",
      "column",
      "incorrect",
      "message",
      "displayed",
      "accessing",
      "menu",
      "type",
      "running",
      "public",
      "cloud",
      "java.lang.runtimeexception",
      "viewing",
      "status",
      "operations",
      "oo",
      "flow",
      "get",
      "guest",
      "info",
      "java.lang.nullpointerexception",
      "orchestration",
      "management",
      "session",
      "expires",
      "even",
      "though",
      "designer",
      "active"
    ],
    "language": "en",
    "word_count": 127,
    "importance_score": 3.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "troubleshoot design and deploy",
    "contentLower": "this section covers the following troubleshooting topics. collection of images doesn't start automatically data limit exceeded for zone and instance default proxy settings disappear while creating a provider integration dnd application log files not found after upgrade dnd capability deployment fails dnd deployment fails with \"dnd content install failed for tenant...\" error dnd service consumes extra cpu cores causing higher utilization on worker node dynamic options don't load after changing credentials error when importing an image after upgrade esm api: call to smax failed external validation failed ia: editing a design fails with 'auto_scaling_config error' image aggregation page fails to load image aggregation - null value in 'tenant_id' column incorrect message displayed while accessing the menu \"design\" instance type doesn't load for ia running on public cloud java.lang.runtimeexception error while viewing status in deployment operations oo flow get guest info fails with error j",
    "keywordsLower": [
      "java.lang",
      "troubleshoot",
      "design",
      "deploy",
      "section",
      "covers",
      "following",
      "troubleshooting",
      "topics.",
      "collection",
      "images",
      "doesn",
      "start",
      "automatically",
      "data",
      "limit",
      "exceeded",
      "zone",
      "instance",
      "default",
      "proxy",
      "settings",
      "disappear",
      "while",
      "creating",
      "provider",
      "integration",
      "dnd",
      "application",
      "log",
      "files",
      "found",
      "after",
      "upgrade",
      "capability",
      "deployment",
      "fails",
      "content",
      "install",
      "failed",
      "tenant...",
      "error",
      "service",
      "consumes",
      "extra",
      "cpu",
      "cores",
      "causing",
      "higher",
      "utilization",
      "worker",
      "node",
      "dynamic",
      "options",
      "don",
      "load",
      "changing",
      "credentials",
      "importing",
      "image",
      "esm",
      "api",
      "call",
      "smax",
      "external",
      "validation",
      "ia",
      "editing",
      "aggregation",
      "page",
      "null",
      "value",
      "column",
      "incorrect",
      "message",
      "displayed",
      "accessing",
      "menu",
      "type",
      "running",
      "public",
      "cloud",
      "java.lang.runtimeexception",
      "viewing",
      "status",
      "operations",
      "oo",
      "flow",
      "get",
      "guest",
      "info",
      "java.lang.nullpointerexception",
      "orchestration",
      "management",
      "session",
      "expires",
      "even",
      "though",
      "designer",
      "active"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Troubleshoot Cloud Cost Reporting",
    "content": "This section provides the following troubleshooting topics: Cloud cost data collection fails with a permission error on projection_columnsAccount names missing in Cloud Cost reports for AWS integrationsAccount names missing in Cloud Cost report filters for AWS integrationsAfter an upgrade, cloud cost data collection fails for AzureAfter an upgrade to 24.1, billing data collection fails for AWSAfter upgrade, data collection fails for cloud cost data providersAWS reports contain scientific notation characters in CSV formatBilling data collection fails after you update an integration's tagsCloud cost data providers are missing after the upgradeCMP FinOps functionality doesn't work because of SSL handshake failureData collection failure for a cloud providerData from deleted AWS integrations is still displayed in CMP FinOps reportsInsights aren't collected for AzureVertica database not reachable",
    "url": "troubleshootcgro",
    "filename": "troubleshootcgro",
    "headings": [],
    "keywords": [
      "24.1",
      "troubleshoot",
      "cloud",
      "cost",
      "reporting",
      "section",
      "provides",
      "following",
      "troubleshooting",
      "topics",
      "data",
      "collection",
      "fails",
      "permission",
      "error",
      "names",
      "missing",
      "reports",
      "aws",
      "integrationsaccount",
      "report",
      "filters",
      "integrationsafter",
      "upgrade",
      "azureafter",
      "billing",
      "awsafter",
      "providersaws",
      "contain",
      "scientific",
      "notation",
      "characters",
      "csv",
      "formatbilling",
      "after",
      "update",
      "integration",
      "tagscloud",
      "providers",
      "upgradecmp",
      "finops",
      "functionality",
      "doesn",
      "work",
      "because",
      "ssl",
      "handshake",
      "failuredata",
      "failure",
      "providerdata",
      "deleted",
      "integrations",
      "still",
      "displayed",
      "cmp",
      "reportsinsights",
      "aren",
      "collected",
      "azurevertica",
      "database",
      "reachable"
    ],
    "language": "en",
    "word_count": 102,
    "importance_score": 3.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "troubleshoot cloud cost reporting",
    "contentLower": "this section provides the following troubleshooting topics: cloud cost data collection fails with a permission error on projection_columnsaccount names missing in cloud cost reports for aws integrationsaccount names missing in cloud cost report filters for aws integrationsafter an upgrade, cloud cost data collection fails for azureafter an upgrade to 24.1, billing data collection fails for awsafter upgrade, data collection fails for cloud cost data providersaws reports contain scientific notation characters in csv formatbilling data collection fails after you update an integration's tagscloud cost data providers are missing after the upgradecmp finops functionality doesn't work because of ssl handshake failuredata collection failure for a cloud providerdata from deleted aws integrations is still displayed in cmp finops reportsinsights aren't collected for azurevertica database not reachable",
    "keywordsLower": [
      "24.1",
      "troubleshoot",
      "cloud",
      "cost",
      "reporting",
      "section",
      "provides",
      "following",
      "troubleshooting",
      "topics",
      "data",
      "collection",
      "fails",
      "permission",
      "error",
      "names",
      "missing",
      "reports",
      "aws",
      "integrationsaccount",
      "report",
      "filters",
      "integrationsafter",
      "upgrade",
      "azureafter",
      "billing",
      "awsafter",
      "providersaws",
      "contain",
      "scientific",
      "notation",
      "characters",
      "csv",
      "formatbilling",
      "after",
      "update",
      "integration",
      "tagscloud",
      "providers",
      "upgradecmp",
      "finops",
      "functionality",
      "doesn",
      "work",
      "because",
      "ssl",
      "handshake",
      "failuredata",
      "failure",
      "providerdata",
      "deleted",
      "integrations",
      "still",
      "displayed",
      "cmp",
      "reportsinsights",
      "aren",
      "collected",
      "azurevertica",
      "database",
      "reachable"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Troubleshoot Operations Orchestration",
    "content": "This section includes troubleshooting information for Operations Orchestration (OO) Containerized.",
    "url": "tsoo",
    "filename": "tsoo",
    "headings": [],
    "keywords": [
      "troubleshoot",
      "operations",
      "orchestration",
      "section",
      "includes",
      "troubleshooting",
      "information",
      "oo",
      "containerized."
    ],
    "language": "en",
    "word_count": 11,
    "importance_score": 2.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "troubleshoot operations orchestration",
    "contentLower": "this section includes troubleshooting information for operations orchestration (oo) containerized.",
    "keywordsLower": [
      "troubleshoot",
      "operations",
      "orchestration",
      "section",
      "includes",
      "troubleshooting",
      "information",
      "oo",
      "containerized."
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Subject Name Identification (SNI) failures",
    "content": "When sending http client requests to servers that host multiple websites on the same hostname and port common name or subject name, identification issues may occur, failing to identify the correct subject name. The result of such failures could be an error similar to: Error while executing http request: Certificate for <server_host> doesn't match any of the subject alternative names:[list_of_subject_alternative_names] even though the certificates seem correct. Known situations where this issue has been encountered include but are not limited to performing Azure resource sync calls or obtaining a SMAX authentication token. Cause In such situations, the Java implementation of subject name identification can fail to correctly identify and navigate to the correct site. Solutions Starting with 24.4.1 the Java SNI usage is controllable. To change the Java SNI usage: For Internal RAS: Perform a GET API call to the oo/rest/v1/{tenant_id}/fleetProperties/jsse.enableSNIExtension endpoint to see ",
    "url": "sniconfig",
    "filename": "sniconfig",
    "headings": [
      "Cause",
      "Solutions"
    ],
    "keywords": [
      "additional.XX",
      "wrapper.conf",
      "24.4.1",
      "wrapper.java",
      "subject",
      "name",
      "identification",
      "sni",
      "failures",
      "cause",
      "solutions",
      "sending",
      "http",
      "client",
      "requests",
      "servers",
      "host",
      "multiple",
      "websites",
      "same",
      "hostname",
      "port",
      "common",
      "issues",
      "occur",
      "failing",
      "identify",
      "correct",
      "name.",
      "result",
      "such",
      "error",
      "similar",
      "while",
      "executing",
      "request",
      "certificate",
      "doesn",
      "match",
      "any",
      "alternative",
      "names",
      "even",
      "though",
      "certificates",
      "seem",
      "correct.",
      "known",
      "situations",
      "issue",
      "encountered",
      "include",
      "limited",
      "performing",
      "azure",
      "resource",
      "sync",
      "calls",
      "obtaining",
      "smax",
      "authentication",
      "token.",
      "java",
      "implementation",
      "fail",
      "correctly",
      "navigate",
      "site.",
      "starting",
      "usage",
      "controllable.",
      "change",
      "internal",
      "ras",
      "perform",
      "get",
      "api",
      "call",
      "oo",
      "rest",
      "v1",
      "fleetproperties",
      "jsse.enablesniextension",
      "endpoint",
      "see",
      "current",
      "extension",
      "property",
      "value.",
      "put",
      "body",
      "propertyname",
      "propertyvalue",
      "false",
      "replacing",
      "value",
      "true",
      "opposite",
      "currently",
      "running"
    ],
    "language": "en",
    "word_count": 106,
    "importance_score": 4.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "subject name identification (sni) failures",
    "contentLower": "when sending http client requests to servers that host multiple websites on the same hostname and port common name or subject name, identification issues may occur, failing to identify the correct subject name. the result of such failures could be an error similar to: error while executing http request: certificate for <server_host> doesn't match any of the subject alternative names:[list_of_subject_alternative_names] even though the certificates seem correct. known situations where this issue has been encountered include but are not limited to performing azure resource sync calls or obtaining a smax authentication token. cause in such situations, the java implementation of subject name identification can fail to correctly identify and navigate to the correct site. solutions starting with 24.4.1 the java sni usage is controllable. to change the java sni usage: for internal ras: perform a get api call to the oo/rest/v1/{tenant_id}/fleetproperties/jsse.enablesniextension endpoint to see ",
    "keywordsLower": [
      "additional.xx",
      "wrapper.conf",
      "24.4.1",
      "wrapper.java",
      "subject",
      "name",
      "identification",
      "sni",
      "failures",
      "cause",
      "solutions",
      "sending",
      "http",
      "client",
      "requests",
      "servers",
      "host",
      "multiple",
      "websites",
      "same",
      "hostname",
      "port",
      "common",
      "issues",
      "occur",
      "failing",
      "identify",
      "correct",
      "name.",
      "result",
      "such",
      "error",
      "similar",
      "while",
      "executing",
      "request",
      "certificate",
      "doesn",
      "match",
      "any",
      "alternative",
      "names",
      "even",
      "though",
      "certificates",
      "seem",
      "correct.",
      "known",
      "situations",
      "issue",
      "encountered",
      "include",
      "limited",
      "performing",
      "azure",
      "resource",
      "sync",
      "calls",
      "obtaining",
      "smax",
      "authentication",
      "token.",
      "java",
      "implementation",
      "fail",
      "correctly",
      "navigate",
      "site.",
      "starting",
      "usage",
      "controllable.",
      "change",
      "internal",
      "ras",
      "perform",
      "get",
      "api",
      "call",
      "oo",
      "rest",
      "v1",
      "fleetproperties",
      "jsse.enablesniextension",
      "endpoint",
      "see",
      "current",
      "extension",
      "property",
      "value.",
      "put",
      "body",
      "propertyname",
      "propertyvalue",
      "false",
      "replacing",
      "value",
      "true",
      "opposite",
      "currently",
      "running"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Troubleshoot Smart Analytics",
    "content": "This section provides the troubleshooting information you may need when using Smart Analytics.",
    "url": "smartatroubleshooting",
    "filename": "smartatroubleshooting",
    "headings": [],
    "keywords": [
      "troubleshoot",
      "smart",
      "analytics",
      "section",
      "provides",
      "troubleshooting",
      "information",
      "need",
      "analytics."
    ],
    "language": "en",
    "word_count": 10,
    "importance_score": 2.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "troubleshoot smart analytics",
    "contentLower": "this section provides the troubleshooting information you may need when using smart analytics.",
    "keywordsLower": [
      "troubleshoot",
      "smart",
      "analytics",
      "section",
      "provides",
      "troubleshooting",
      "information",
      "need",
      "analytics."
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Search data is incomplete after an upgrade",
    "content": "After a system upgrade or a multi-hop upgrade, some data failed to be found using a global search. Cause You may have performed IDOL content scaling before an upgrade but haven't set the replicas of the content pod back to their default value after the upgrade. Therefore, the data in IDOL will be missing and the new data index will fail to be completed. Solution To resolve this issue, manually reset the replica count of the content StatefulSet to its original value after the upgrade. First, verify that all content pods are ready by using one of the following options: Option 1: check content pod status Log in to the bastion node. Go to the IDOL configuration folder in the Network File System (NFS): For helm version: <nfs_folder>/config-volume/idol For classic version: <nfs_folder> /smartanalytics-volume/config/idol Run the cat count command to view the contents of a file named count, as shown in the following example. {\"group\":{\"sawmetaContent\":1,\"sawContent\":2,\"sawarcContent\":1,\"stxCon",
    "url": "incompletesearchafterupgrade",
    "filename": "incompletesearchafterupgrade",
    "headings": [
      "Cause",
      "Solution"
    ],
    "keywords": [
      "search",
      "data",
      "incomplete",
      "after",
      "upgrade",
      "cause",
      "solution",
      "system",
      "multi-hop",
      "failed",
      "found",
      "global",
      "search.",
      "performed",
      "idol",
      "content",
      "scaling",
      "before",
      "haven",
      "set",
      "replicas",
      "pod",
      "back",
      "default",
      "value",
      "upgrade.",
      "therefore",
      "missing",
      "new",
      "index",
      "fail",
      "completed.",
      "resolve",
      "issue",
      "manually",
      "reset",
      "replica",
      "count",
      "statefulset",
      "original",
      "first",
      "verify",
      "all",
      "pods",
      "ready",
      "one",
      "following",
      "options",
      "option",
      "check",
      "status",
      "log",
      "bastion",
      "node.",
      "go",
      "configuration",
      "folder",
      "network",
      "file",
      "nfs",
      "helm",
      "version",
      "config-volume",
      "classic",
      "smartanalytics-volume",
      "config",
      "run",
      "cat",
      "command",
      "view",
      "contents",
      "named",
      "shown",
      "example.",
      "group",
      "sawmetacontent",
      "sawcontent",
      "sawarccontent",
      "stxcontent",
      "scale",
      "number",
      "saw-content",
      "known",
      "engines",
      "double",
      "number.",
      "example",
      "four",
      "expected.",
      "kubectl",
      "get",
      "-n",
      "itsma",
      "grep",
      "saw-con",
      "exist",
      "dah",
      "dih",
      "servers",
      "below."
    ],
    "language": "en",
    "word_count": 110,
    "importance_score": 3.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "search data is incomplete after an upgrade",
    "contentLower": "after a system upgrade or a multi-hop upgrade, some data failed to be found using a global search. cause you may have performed idol content scaling before an upgrade but haven't set the replicas of the content pod back to their default value after the upgrade. therefore, the data in idol will be missing and the new data index will fail to be completed. solution to resolve this issue, manually reset the replica count of the content statefulset to its original value after the upgrade. first, verify that all content pods are ready by using one of the following options: option 1: check content pod status log in to the bastion node. go to the idol configuration folder in the network file system (nfs): for helm version: <nfs_folder>/config-volume/idol for classic version: <nfs_folder> /smartanalytics-volume/config/idol run the cat count command to view the contents of a file named count, as shown in the following example. {\"group\":{\"sawmetacontent\":1,\"sawcontent\":2,\"sawarccontent\":1,\"stxcon",
    "keywordsLower": [
      "search",
      "data",
      "incomplete",
      "after",
      "upgrade",
      "cause",
      "solution",
      "system",
      "multi-hop",
      "failed",
      "found",
      "global",
      "search.",
      "performed",
      "idol",
      "content",
      "scaling",
      "before",
      "haven",
      "set",
      "replicas",
      "pod",
      "back",
      "default",
      "value",
      "upgrade.",
      "therefore",
      "missing",
      "new",
      "index",
      "fail",
      "completed.",
      "resolve",
      "issue",
      "manually",
      "reset",
      "replica",
      "count",
      "statefulset",
      "original",
      "first",
      "verify",
      "all",
      "pods",
      "ready",
      "one",
      "following",
      "options",
      "option",
      "check",
      "status",
      "log",
      "bastion",
      "node.",
      "go",
      "configuration",
      "folder",
      "network",
      "file",
      "nfs",
      "helm",
      "version",
      "config-volume",
      "classic",
      "smartanalytics-volume",
      "config",
      "run",
      "cat",
      "command",
      "view",
      "contents",
      "named",
      "shown",
      "example.",
      "group",
      "sawmetacontent",
      "sawcontent",
      "sawarccontent",
      "stxcontent",
      "scale",
      "number",
      "saw-content",
      "known",
      "engines",
      "double",
      "number.",
      "example",
      "four",
      "expected.",
      "kubectl",
      "get",
      "-n",
      "itsma",
      "grep",
      "saw-con",
      "exist",
      "dah",
      "dih",
      "servers",
      "below."
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "The smarta-stx-media pod crashes with the OOMKilled error",
    "content": "The smarta-stx-media pod crashes with the OOMKilled error. Cause The memory capacity of the smarta-stx-media pod is insufficient. Solution Log in to the control plane node as the root user. Run the following command to update the idol-shared memory value to 4GB or above: kubectl edit deployment smarta-stx-media -n itsma-n5am3 For example, go to the smarta-stx-media container and increase its memory limitation to 4 GB. Wait for the smarta-stx-media pod to restart. When the pod is ready, verify that the media memory is updated to 4 GB.",
    "url": "oomkillederror",
    "filename": "oomkillederror",
    "headings": [
      "Cause",
      "Solution"
    ],
    "keywords": [
      "smarta-stx-media",
      "pod",
      "crashes",
      "oomkilled",
      "error",
      "cause",
      "solution",
      "error.",
      "memory",
      "capacity",
      "insufficient.",
      "log",
      "control",
      "plane",
      "node",
      "root",
      "user.",
      "run",
      "following",
      "command",
      "update",
      "idol-shared",
      "value",
      "4gb",
      "above",
      "kubectl",
      "edit",
      "deployment",
      "-n",
      "itsma-n5am3",
      "example",
      "go",
      "container",
      "increase",
      "limitation",
      "gb.",
      "wait",
      "restart.",
      "ready",
      "verify",
      "media",
      "updated"
    ],
    "language": "en",
    "word_count": 59,
    "importance_score": 2.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "the smarta-stx-media pod crashes with the oomkilled error",
    "contentLower": "the smarta-stx-media pod crashes with the oomkilled error. cause the memory capacity of the smarta-stx-media pod is insufficient. solution log in to the control plane node as the root user. run the following command to update the idol-shared memory value to 4gb or above: kubectl edit deployment smarta-stx-media -n itsma-n5am3 for example, go to the smarta-stx-media container and increase its memory limitation to 4 gb. wait for the smarta-stx-media pod to restart. when the pod is ready, verify that the media memory is updated to 4 gb.",
    "keywordsLower": [
      "smarta-stx-media",
      "pod",
      "crashes",
      "oomkilled",
      "error",
      "cause",
      "solution",
      "error.",
      "memory",
      "capacity",
      "insufficient.",
      "log",
      "control",
      "plane",
      "node",
      "root",
      "user.",
      "run",
      "following",
      "command",
      "update",
      "idol-shared",
      "value",
      "4gb",
      "above",
      "kubectl",
      "edit",
      "deployment",
      "-n",
      "itsma-n5am3",
      "example",
      "go",
      "container",
      "increase",
      "limitation",
      "gb.",
      "wait",
      "restart.",
      "ready",
      "verify",
      "media",
      "updated"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Smart Analytics doesn't work properly in helm transformation",
    "content": "If you transform the suite from a classic deployment to a helm deployment, these issues might occur: The smarta-stx-category and smarta-stx-agentstore pods keep restarting during the training of smart tickets. The smarta-installer pod fails to start and there's an error in the log indicating that the pod can't mount the \"count\" file. Cause The permission to access the NFS file folder is incorrect. Solution To solve this issue, you need to change the owner of certain storage folders by following these steps: Log in to the NFS server. Run the following commands for each smart analytics volume: cd <smartanalytics-volume> find . -maxdepth 5 -type d -user root -group <GID> | wc -l Where: <GID> is the SYSTEM_GROUP_ID value defined in the install.properties file, which has a default value of 1999. <smartanalytics-volume> is the export path of the suite's smart analytics volume. There are three paths: /var/vols/itom/data/itsma-logging-volume-pvc-xxxxxx /var/vols/itom/data/itsma-data-volume-pvc",
    "url": "smartanotworkinghelmtransform",
    "filename": "smartanotworkinghelmtransform",
    "headings": [
      "Cause",
      "Solution"
    ],
    "keywords": [
      "doesnt",
      "smart",
      "analytics",
      "doesn",
      "work",
      "properly",
      "helm",
      "transformation",
      "cause",
      "solution",
      "transform",
      "suite",
      "classic",
      "deployment",
      "issues",
      "occur",
      "smarta-stx-category",
      "smarta-stx-agentstore",
      "pods",
      "keep",
      "restarting",
      "during",
      "training",
      "tickets.",
      "smarta-installer",
      "pod",
      "fails",
      "start",
      "there",
      "error",
      "log",
      "indicating",
      "mount",
      "count",
      "file.",
      "permission",
      "access",
      "nfs",
      "file",
      "folder",
      "incorrect.",
      "solve",
      "issue",
      "need",
      "change",
      "owner",
      "certain",
      "storage",
      "folders",
      "following",
      "steps",
      "server.",
      "run",
      "commands",
      "volume",
      "cd",
      "find",
      "-maxdepth",
      "-type",
      "-user",
      "root",
      "-group",
      "wc",
      "-l",
      "value",
      "defined",
      "install.properties",
      "default",
      "1999.",
      "export",
      "path",
      "volume.",
      "three",
      "paths",
      "var",
      "vols",
      "itom",
      "data",
      "itsma-logging-volume-pvc-xxxxxx",
      "itsma-data-volume-pvc-xxxxxx",
      "itsma-config-volume-pvc-xxxxxx",
      "example",
      "idol",
      "1999",
      "return",
      "step",
      "equal",
      "zero",
      "skip",
      "step.",
      "greater",
      "note",
      "insert",
      "sudo",
      "before",
      "chown",
      "result",
      "shows",
      "operation",
      "permitted"
    ],
    "language": "en",
    "word_count": 105,
    "importance_score": 3.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "smart analytics doesn't work properly in helm transformation",
    "contentLower": "if you transform the suite from a classic deployment to a helm deployment, these issues might occur: the smarta-stx-category and smarta-stx-agentstore pods keep restarting during the training of smart tickets. the smarta-installer pod fails to start and there's an error in the log indicating that the pod can't mount the \"count\" file. cause the permission to access the nfs file folder is incorrect. solution to solve this issue, you need to change the owner of certain storage folders by following these steps: log in to the nfs server. run the following commands for each smart analytics volume: cd <smartanalytics-volume> find . -maxdepth 5 -type d -user root -group <gid> | wc -l where: <gid> is the system_group_id value defined in the install.properties file, which has a default value of 1999. <smartanalytics-volume> is the export path of the suite's smart analytics volume. there are three paths: /var/vols/itom/data/itsma-logging-volume-pvc-xxxxxx /var/vols/itom/data/itsma-data-volume-pvc",
    "keywordsLower": [
      "doesnt",
      "smart",
      "analytics",
      "doesn",
      "work",
      "properly",
      "helm",
      "transformation",
      "cause",
      "solution",
      "transform",
      "suite",
      "classic",
      "deployment",
      "issues",
      "occur",
      "smarta-stx-category",
      "smarta-stx-agentstore",
      "pods",
      "keep",
      "restarting",
      "during",
      "training",
      "tickets.",
      "smarta-installer",
      "pod",
      "fails",
      "start",
      "there",
      "error",
      "log",
      "indicating",
      "mount",
      "count",
      "file.",
      "permission",
      "access",
      "nfs",
      "file",
      "folder",
      "incorrect.",
      "solve",
      "issue",
      "need",
      "change",
      "owner",
      "certain",
      "storage",
      "folders",
      "following",
      "steps",
      "server.",
      "run",
      "commands",
      "volume",
      "cd",
      "find",
      "-maxdepth",
      "-type",
      "-user",
      "root",
      "-group",
      "wc",
      "-l",
      "value",
      "defined",
      "install.properties",
      "default",
      "1999.",
      "export",
      "path",
      "volume.",
      "three",
      "paths",
      "var",
      "vols",
      "itom",
      "data",
      "itsma-logging-volume-pvc-xxxxxx",
      "itsma-data-volume-pvc-xxxxxx",
      "itsma-config-volume-pvc-xxxxxx",
      "example",
      "idol",
      "1999",
      "return",
      "step",
      "equal",
      "zero",
      "skip",
      "step.",
      "greater",
      "note",
      "insert",
      "sudo",
      "before",
      "chown",
      "result",
      "shows",
      "operation",
      "permitted"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "SmartA pods crashed during system version rollback",
    "content": "During the system rollback, the status of the Smart Analytics pods changed to CrashLoopBackOff. Additionally, the log of the crashed pods displays content that resembles the following: 15/04/2024 01:14:15 [1] 00-Always: Unable to initialise sentence breaking library (Missing file) \"chinesebreaking\" for language \"chinese\": Initialization failed 15/04/2024 01:14:15 [1] 99-Always: Failed to initialise language settings. Exiting Cause The language file doesn't match the current version. Solution To fix this issue, perform the following steps on the bastion node: Rename the langfiles to langfilesBak. mv /mnt/nfs/generic/var/vols/itom/itsma/config-volume/idol/langfiles /mnt/nfs/generic/var/vols/itom/itsma/config-volume/idol/langfilesBak Restart the following pod: kubectl delete pod smarta-installer-xxxxxxxx-xxxxxx -n <suite namespace> Check if new langfiles are created. ls /mnt/nfs/generic/var/vols/itom/itsma/config-volume/idol/langfiles Check if the Smart Analytics pods are back to normal. ",
    "url": "crashloopbackoff",
    "filename": "crashloopbackoff",
    "headings": [
      "Cause",
      "Solution"
    ],
    "keywords": [
      "smarta",
      "pods",
      "crashed",
      "during",
      "system",
      "version",
      "rollback",
      "cause",
      "solution",
      "status",
      "smart",
      "analytics",
      "changed",
      "crashloopbackoff.",
      "additionally",
      "log",
      "displays",
      "content",
      "resembles",
      "following",
      "15",
      "04",
      "2024",
      "01",
      "14",
      "00-always",
      "unable",
      "initialise",
      "sentence",
      "breaking",
      "library",
      "missing",
      "file",
      "chinesebreaking",
      "language",
      "chinese",
      "initialization",
      "failed",
      "99-always",
      "settings.",
      "exiting",
      "doesn",
      "match",
      "current",
      "version.",
      "fix",
      "issue",
      "perform",
      "steps",
      "bastion",
      "node",
      "rename",
      "langfiles",
      "langfilesbak.",
      "mv",
      "mnt",
      "nfs",
      "generic",
      "var",
      "vols",
      "itom",
      "itsma",
      "config-volume",
      "idol",
      "langfilesbak",
      "restart",
      "pod",
      "kubectl",
      "delete",
      "smarta-installer-xxxxxxxx-xxxxxx",
      "-n",
      "check",
      "new",
      "created.",
      "ls",
      "back",
      "normal.",
      "get",
      "-a",
      "grep"
    ],
    "language": "en",
    "word_count": 126,
    "importance_score": 3.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "smarta pods crashed during system version rollback",
    "contentLower": "during the system rollback, the status of the smart analytics pods changed to crashloopbackoff. additionally, the log of the crashed pods displays content that resembles the following: 15/04/2024 01:14:15 [1] 00-always: unable to initialise sentence breaking library (missing file) \"chinesebreaking\" for language \"chinese\": initialization failed 15/04/2024 01:14:15 [1] 99-always: failed to initialise language settings. exiting cause the language file doesn't match the current version. solution to fix this issue, perform the following steps on the bastion node: rename the langfiles to langfilesbak. mv /mnt/nfs/generic/var/vols/itom/itsma/config-volume/idol/langfiles /mnt/nfs/generic/var/vols/itom/itsma/config-volume/idol/langfilesbak restart the following pod: kubectl delete pod smarta-installer-xxxxxxxx-xxxxxx -n <suite namespace> check if new langfiles are created. ls /mnt/nfs/generic/var/vols/itom/itsma/config-volume/idol/langfiles check if the smart analytics pods are back to normal. ",
    "keywordsLower": [
      "smarta",
      "pods",
      "crashed",
      "during",
      "system",
      "version",
      "rollback",
      "cause",
      "solution",
      "status",
      "smart",
      "analytics",
      "changed",
      "crashloopbackoff.",
      "additionally",
      "log",
      "displays",
      "content",
      "resembles",
      "following",
      "15",
      "04",
      "2024",
      "01",
      "14",
      "00-always",
      "unable",
      "initialise",
      "sentence",
      "breaking",
      "library",
      "missing",
      "file",
      "chinesebreaking",
      "language",
      "chinese",
      "initialization",
      "failed",
      "99-always",
      "settings.",
      "exiting",
      "doesn",
      "match",
      "current",
      "version.",
      "fix",
      "issue",
      "perform",
      "steps",
      "bastion",
      "node",
      "rename",
      "langfiles",
      "langfilesbak.",
      "mv",
      "mnt",
      "nfs",
      "generic",
      "var",
      "vols",
      "itom",
      "itsma",
      "config-volume",
      "idol",
      "langfilesbak",
      "restart",
      "pod",
      "kubectl",
      "delete",
      "smarta-installer-xxxxxxxx-xxxxxx",
      "-n",
      "check",
      "new",
      "created.",
      "ls",
      "back",
      "normal.",
      "get",
      "-a",
      "grep"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "smarta-smart-ticket-task pod crashes with the out-of-memory error",
    "content": "The smarta-smart-ticket-task pod may crash due to the out-of-memory error coming from the compressed class space. When it happens, the pod status resembles the following: kubectl get po -A -w | grep task itsma-eks smarta-smart-ticket-task-6cdb84f776-xhvwl 1/2 Running 2 (56s ago) 6h14m Also, the log of the smarta-smart-ticket-task pod displays the content like this: ....... Terminating due to java.lang.OutOfMemoryError: Compressed class space Cause The default size for the Compressed Class Metadata Space is not enough and needs to be tuned. Solution To fix this issue, run the following commands in the Kubernetes master or bastion: itsma_namespace=`kubectl get namespace |grep itsma | cut -f1 -d \" \"` kubectl patch deployment smarta-smart-ticket-task --type=json -p='[{\"op\": \"add\",\"path\": \"/spec/template/spec/containers/1/env/30\",\"value\": {\"name\": \"COMPRESSED_CLASS_SPACE_SIZE\",\"value\": \"64M\"}}]' -n ${itsma_namespace} kubectl rollout status deployment smarta-smart-ticket-task -n $itsma_names",
    "url": "saticketpodsoom",
    "filename": "saticketpodsoom",
    "headings": [
      "Cause",
      "Solution"
    ],
    "keywords": [
      "java.lang",
      "smarta-smart-ticket-task",
      "pod",
      "crashes",
      "out-of-memory",
      "error",
      "cause",
      "solution",
      "crash",
      "due",
      "coming",
      "compressed",
      "class",
      "space.",
      "happens",
      "status",
      "resembles",
      "following",
      "kubectl",
      "get",
      "po",
      "-a",
      "-w",
      "grep",
      "task",
      "itsma-eks",
      "smarta-smart-ticket-task-6cdb84f776-xhvwl",
      "running",
      "56s",
      "ago",
      "6h14m",
      "log",
      "displays",
      "content",
      "like",
      "terminating",
      "java.lang.outofmemoryerror",
      "space",
      "default",
      "size",
      "metadata",
      "enough",
      "needs",
      "tuned.",
      "fix",
      "issue",
      "run",
      "commands",
      "kubernetes",
      "master",
      "bastion",
      "namespace",
      "itsma",
      "cut",
      "-f1",
      "-d",
      "patch",
      "deployment",
      "--type",
      "json",
      "-p",
      "op",
      "add",
      "path",
      "spec",
      "template",
      "containers",
      "env",
      "30",
      "value",
      "name",
      "64m",
      "-n",
      "rollout",
      "after",
      "back",
      "normal."
    ],
    "language": "en",
    "word_count": 108,
    "importance_score": 3.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "smarta-smart-ticket-task pod crashes with the out-of-memory error",
    "contentLower": "the smarta-smart-ticket-task pod may crash due to the out-of-memory error coming from the compressed class space. when it happens, the pod status resembles the following: kubectl get po -a -w | grep task itsma-eks smarta-smart-ticket-task-6cdb84f776-xhvwl 1/2 running 2 (56s ago) 6h14m also, the log of the smarta-smart-ticket-task pod displays the content like this: ....... terminating due to java.lang.outofmemoryerror: compressed class space cause the default size for the compressed class metadata space is not enough and needs to be tuned. solution to fix this issue, run the following commands in the kubernetes master or bastion: itsma_namespace=`kubectl get namespace |grep itsma | cut -f1 -d \" \"` kubectl patch deployment smarta-smart-ticket-task --type=json -p='[{\"op\": \"add\",\"path\": \"/spec/template/spec/containers/1/env/30\",\"value\": {\"name\": \"compressed_class_space_size\",\"value\": \"64m\"}}]' -n ${itsma_namespace} kubectl rollout status deployment smarta-smart-ticket-task -n $itsma_names",
    "keywordsLower": [
      "java.lang",
      "smarta-smart-ticket-task",
      "pod",
      "crashes",
      "out-of-memory",
      "error",
      "cause",
      "solution",
      "crash",
      "due",
      "coming",
      "compressed",
      "class",
      "space.",
      "happens",
      "status",
      "resembles",
      "following",
      "kubectl",
      "get",
      "po",
      "-a",
      "-w",
      "grep",
      "task",
      "itsma-eks",
      "smarta-smart-ticket-task-6cdb84f776-xhvwl",
      "running",
      "56s",
      "ago",
      "6h14m",
      "log",
      "displays",
      "content",
      "like",
      "terminating",
      "java.lang.outofmemoryerror",
      "space",
      "default",
      "size",
      "metadata",
      "enough",
      "needs",
      "tuned.",
      "fix",
      "issue",
      "run",
      "commands",
      "kubernetes",
      "master",
      "bastion",
      "namespace",
      "itsma",
      "cut",
      "-f1",
      "-d",
      "patch",
      "deployment",
      "--type",
      "json",
      "-p",
      "op",
      "add",
      "path",
      "spec",
      "template",
      "containers",
      "env",
      "30",
      "value",
      "name",
      "64m",
      "-n",
      "rollout",
      "after",
      "back",
      "normal."
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Smart Analytics may encounter pod crashes during the upgrade on AKS platform",
    "content": "During the upgrade on the AKS platform, Smart Analytics may encounter pod crashes. When it happens, the pod status resembles the following: [centos@7420150c-bastion ~]$ kubectl get po -n itsma-azfile|grep Crash smarta-saw-con-0 1/2 CrashLoopBackOff 9 (24s ago) 28m smarta-sawarc-con-0 1/2 CrashLoopBackOff 9 (41s ago) 29m smarta-sawmeta-con-0 1/2 CrashLoopBackOff 9 (2m35s ago) 29m smarta-stx-agent-645b5d69cc-92wb2 1/2 CrashLoopBackOff 10 (2m28s ago) 29m Also, the log of the crashed pod displays the content like this: kubectl logs -f smarta-stx-agent-645b5d69cc-92wb2 -n itsma-azfile -c smarta-stx-agent … … 10/01/2023 11:36:24 [1] 00-Always: Unable to load sentence breaking library \"chinesebreaking\" for language \"chinese\". File not found : /opt/content/langfiles/chinesebreaking.so: cannot open shared object file: No such file or directory 10/01/2023 11:36:24 [1] 99-Always: Failed to initialise language settings. Exiting Cause This issue occurs because of the file management on the AKS plat",
    "url": "sapodsaks",
    "filename": "sapodsaks",
    "headings": [
      "Cause",
      "Solution"
    ],
    "keywords": [
      "statefulset.apps",
      "chinesebreaking.so",
      "deployment.apps",
      "smart",
      "analytics",
      "encounter",
      "pod",
      "crashes",
      "during",
      "upgrade",
      "aks",
      "platform",
      "cause",
      "solution",
      "crashes.",
      "happens",
      "status",
      "resembles",
      "following",
      "centos",
      "7420150c-bastion",
      "kubectl",
      "get",
      "po",
      "-n",
      "itsma-azfile",
      "grep",
      "crash",
      "smarta-saw-con-0",
      "crashloopbackoff",
      "24s",
      "ago",
      "28m",
      "smarta-sawarc-con-0",
      "41s",
      "29m",
      "smarta-sawmeta-con-0",
      "2m35s",
      "smarta-stx-agent-645b5d69cc-92wb2",
      "10",
      "2m28s",
      "log",
      "crashed",
      "displays",
      "content",
      "like",
      "logs",
      "-f",
      "-c",
      "smarta-stx-agent",
      "01",
      "2023",
      "11",
      "36",
      "24",
      "00-always",
      "unable",
      "load",
      "sentence",
      "breaking",
      "library",
      "chinesebreaking",
      "language",
      "chinese",
      "file",
      "found",
      "opt",
      "langfiles",
      "cannot",
      "open",
      "shared",
      "object",
      "such",
      "directory",
      "99-always",
      "failed",
      "initialise",
      "settings.",
      "exiting",
      "issue",
      "occurs",
      "because",
      "management",
      "platform.",
      "fix",
      "perform",
      "steps",
      "list",
      "remember",
      "all",
      "statefulset",
      "configurations.",
      "9c5de9dc-bastion",
      "sts",
      "-a",
      "namespace",
      "name",
      "ready",
      "age",
      "cms-ns"
    ],
    "language": "en",
    "word_count": 129,
    "importance_score": 2.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "smart analytics may encounter pod crashes during the upgrade on aks platform",
    "contentLower": "during the upgrade on the aks platform, smart analytics may encounter pod crashes. when it happens, the pod status resembles the following: [centos@7420150c-bastion ~]$ kubectl get po -n itsma-azfile|grep crash smarta-saw-con-0 1/2 crashloopbackoff 9 (24s ago) 28m smarta-sawarc-con-0 1/2 crashloopbackoff 9 (41s ago) 29m smarta-sawmeta-con-0 1/2 crashloopbackoff 9 (2m35s ago) 29m smarta-stx-agent-645b5d69cc-92wb2 1/2 crashloopbackoff 10 (2m28s ago) 29m also, the log of the crashed pod displays the content like this: kubectl logs -f smarta-stx-agent-645b5d69cc-92wb2 -n itsma-azfile -c smarta-stx-agent … … 10/01/2023 11:36:24 [1] 00-always: unable to load sentence breaking library \"chinesebreaking\" for language \"chinese\". file not found : /opt/content/langfiles/chinesebreaking.so: cannot open shared object file: no such file or directory 10/01/2023 11:36:24 [1] 99-always: failed to initialise language settings. exiting cause this issue occurs because of the file management on the aks plat",
    "keywordsLower": [
      "statefulset.apps",
      "chinesebreaking.so",
      "deployment.apps",
      "smart",
      "analytics",
      "encounter",
      "pod",
      "crashes",
      "during",
      "upgrade",
      "aks",
      "platform",
      "cause",
      "solution",
      "crashes.",
      "happens",
      "status",
      "resembles",
      "following",
      "centos",
      "7420150c-bastion",
      "kubectl",
      "get",
      "po",
      "-n",
      "itsma-azfile",
      "grep",
      "crash",
      "smarta-saw-con-0",
      "crashloopbackoff",
      "24s",
      "ago",
      "28m",
      "smarta-sawarc-con-0",
      "41s",
      "29m",
      "smarta-sawmeta-con-0",
      "2m35s",
      "smarta-stx-agent-645b5d69cc-92wb2",
      "10",
      "2m28s",
      "log",
      "crashed",
      "displays",
      "content",
      "like",
      "logs",
      "-f",
      "-c",
      "smarta-stx-agent",
      "01",
      "2023",
      "11",
      "36",
      "24",
      "00-always",
      "unable",
      "load",
      "sentence",
      "breaking",
      "library",
      "chinesebreaking",
      "language",
      "chinese",
      "file",
      "found",
      "opt",
      "langfiles",
      "cannot",
      "open",
      "shared",
      "object",
      "such",
      "directory",
      "99-always",
      "failed",
      "initialise",
      "settings.",
      "exiting",
      "issue",
      "occurs",
      "because",
      "management",
      "platform.",
      "fix",
      "perform",
      "steps",
      "list",
      "remember",
      "all",
      "statefulset",
      "configurations.",
      "9c5de9dc-bastion",
      "sts",
      "-a",
      "namespace",
      "name",
      "ready",
      "age",
      "cms-ns"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "The content server restarts in a dead cycle due to the drecompact operation",
    "content": "The content server exits because it cannot complete the drecompact operation. When the content server restarts, it tries to resume the drecompact operation. Since the drecompact operation cannot be recovered, the content server is in a dead cycle of restart. The Index log displays the following content. 12/01/2023 12:02:10 [1] 30-Normal: DRECOMPACT summary: 12/01/2023 12:02:10 [1] 30-Normal: Stage: A (Start Compaction), Time: 0 seconds 12/01/2023 12:02:10 [1] 30-Normal: Stage: B (Refindex Compaction), Time: 5 seconds 12/01/2023 12:02:10 [1] 30-Normal: Stage: C-I (Nodetable switch), Time: 0 seconds 12/01/2023 12:02:10 [1] 30-Normal: Stage: C-II (Numeric Compaction), Time: 15 seconds 12/01/2023 12:02:10 [1] 30-Normal: Stage: C-III (Geoindex Compaction), Time: 0 seconds 12/01/2023 12:02:10 [1] 30-Normal: Stage: D-I (Dynterm Compaction), Time: 7 seconds 12/01/2023 12:02:10 [1] 30-Normal: Stage: D-II (Unstemmed Compaction), Time: 7 seconds 12/01/2023 12:02:10 [1] 30-Normal: Stage: D-III (Ph",
    "url": "contentserverdeadcycle",
    "filename": "contentserverdeadcycle",
    "headings": [
      "Cause",
      "Solution",
      "Solution 1",
      "Solution 2",
      "Solution 3"
    ],
    "keywords": [
      "https://smarta-saw-con-0:1443/action=indexerGetStatus&MaxResults=20&IndexCmd=DRECOMPACT",
      "https://<content",
      "dbbt.db",
      "https://smarta-sawarc-con-0:1443/action=indexerGetStatus&MaxResults=20&IndexCmd=DRECOMPACT",
      "content",
      "server",
      "restarts",
      "dead",
      "cycle",
      "due",
      "drecompact",
      "operation",
      "cause",
      "solution",
      "exits",
      "because",
      "cannot",
      "complete",
      "operation.",
      "tries",
      "resume",
      "since",
      "recovered",
      "restart.",
      "index",
      "log",
      "displays",
      "following",
      "content.",
      "12",
      "01",
      "2023",
      "02",
      "10",
      "30-normal",
      "summary",
      "stage",
      "start",
      "compaction",
      "time",
      "seconds",
      "refindex",
      "c-i",
      "nodetable",
      "switch",
      "c-ii",
      "numeric",
      "15",
      "c-iii",
      "geoindex",
      "d-i",
      "dynterm",
      "d-ii",
      "unstemmed",
      "d-iii",
      "phrase",
      "40",
      "reference",
      "38",
      "best",
      "term",
      "compact",
      "interrupted",
      "remaining",
      "stages",
      "attempted.",
      "application",
      "70-error",
      "unable",
      "abandoned",
      "99-always",
      "abandoned.",
      "exiting....",
      "issue",
      "arise",
      "several",
      "reasons",
      "one",
      "pod",
      "restarted",
      "during",
      "case",
      "refer",
      "3.",
      "try",
      "either",
      "solutions",
      "work",
      "around",
      "issue.",
      "run",
      "command",
      "scale",
      "problematic",
      "statefulset",
      "0.",
      "kubectl",
      "sts",
      "smarta-saw-con",
      "-n"
    ],
    "language": "en",
    "word_count": 163,
    "importance_score": 3.5,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "the content server restarts in a dead cycle due to the drecompact operation",
    "contentLower": "the content server exits because it cannot complete the drecompact operation. when the content server restarts, it tries to resume the drecompact operation. since the drecompact operation cannot be recovered, the content server is in a dead cycle of restart. the index log displays the following content. 12/01/2023 12:02:10 [1] 30-normal: drecompact summary: 12/01/2023 12:02:10 [1] 30-normal: stage: a (start compaction), time: 0 seconds 12/01/2023 12:02:10 [1] 30-normal: stage: b (refindex compaction), time: 5 seconds 12/01/2023 12:02:10 [1] 30-normal: stage: c-i (nodetable switch), time: 0 seconds 12/01/2023 12:02:10 [1] 30-normal: stage: c-ii (numeric compaction), time: 15 seconds 12/01/2023 12:02:10 [1] 30-normal: stage: c-iii (geoindex compaction), time: 0 seconds 12/01/2023 12:02:10 [1] 30-normal: stage: d-i (dynterm compaction), time: 7 seconds 12/01/2023 12:02:10 [1] 30-normal: stage: d-ii (unstemmed compaction), time: 7 seconds 12/01/2023 12:02:10 [1] 30-normal: stage: d-iii (ph",
    "keywordsLower": [
      "https://smarta-saw-con-0:1443/action=indexergetstatus&maxresults=20&indexcmd=drecompact",
      "https://<content",
      "dbbt.db",
      "https://smarta-sawarc-con-0:1443/action=indexergetstatus&maxresults=20&indexcmd=drecompact",
      "content",
      "server",
      "restarts",
      "dead",
      "cycle",
      "due",
      "drecompact",
      "operation",
      "cause",
      "solution",
      "exits",
      "because",
      "cannot",
      "complete",
      "operation.",
      "tries",
      "resume",
      "since",
      "recovered",
      "restart.",
      "index",
      "log",
      "displays",
      "following",
      "content.",
      "12",
      "01",
      "2023",
      "02",
      "10",
      "30-normal",
      "summary",
      "stage",
      "start",
      "compaction",
      "time",
      "seconds",
      "refindex",
      "c-i",
      "nodetable",
      "switch",
      "c-ii",
      "numeric",
      "15",
      "c-iii",
      "geoindex",
      "d-i",
      "dynterm",
      "d-ii",
      "unstemmed",
      "d-iii",
      "phrase",
      "40",
      "reference",
      "38",
      "best",
      "term",
      "compact",
      "interrupted",
      "remaining",
      "stages",
      "attempted.",
      "application",
      "70-error",
      "unable",
      "abandoned",
      "99-always",
      "abandoned.",
      "exiting....",
      "issue",
      "arise",
      "several",
      "reasons",
      "one",
      "pod",
      "restarted",
      "during",
      "case",
      "refer",
      "3.",
      "try",
      "either",
      "solutions",
      "work",
      "around",
      "issue.",
      "run",
      "command",
      "scale",
      "problematic",
      "statefulset",
      "0.",
      "kubectl",
      "sts",
      "smarta-saw-con",
      "-n"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Search fails occassionally",
    "content": "Sometimes, the keyword-based search returns nothing. Cause A possible cause for this issue is that the search is too slow, and the search process breaks down. Solution If you haven't changed the timeout values before, follow these steps: Log in to the control plane node or bastion node, and then run the following command: kubectl edit cm itom-sma-smarta-common-configuration-cm -n <namespace> Find the following fields: hystrix.command.default.execution.isolation.thread.timeoutInMilliseconds itsma.service.httpclient.default.socket-timeout Increase the timeout values for these two fields. For example, increase the value from 3000 to 4000. Restart the Smart Analytics service by using the following command: kubectl rollout restart deployment smarta-search -n itsma-xceej If you have changed the timeout values before updating the suite to the new version, follow these steps: Log in to the control plane node or bastion node, and then run the following command: kubectl edit deployment -n itsma-",
    "url": "searchfails",
    "filename": "searchfails",
    "headings": [
      "Cause",
      "Solution"
    ],
    "keywords": [
      "search",
      "fails",
      "occassionally",
      "cause",
      "solution",
      "sometimes",
      "keyword-based",
      "returns",
      "nothing.",
      "possible",
      "issue",
      "too",
      "slow",
      "process",
      "breaks",
      "down.",
      "haven",
      "changed",
      "timeout",
      "values",
      "before",
      "follow",
      "steps",
      "log",
      "control",
      "plane",
      "node",
      "bastion",
      "run",
      "following",
      "command",
      "kubectl",
      "edit",
      "cm",
      "itom-sma-smarta-common-configuration-cm",
      "-n",
      "find",
      "fields",
      "hystrix.command.default.execution.isolation.thread.timeoutinmilliseconds",
      "itsma.service.httpclient.default.socket-timeout",
      "increase",
      "two",
      "fields.",
      "example",
      "value",
      "3000",
      "4000.",
      "restart",
      "smart",
      "analytics",
      "service",
      "rollout",
      "deployment",
      "smarta-search",
      "itsma-xceej",
      "updating",
      "suite",
      "new",
      "version",
      "check",
      "note",
      "previously",
      "one",
      "field",
      "here.",
      "all",
      "changed.",
      "after",
      "upgrade",
      "update",
      "ones",
      "noted"
    ],
    "language": "en",
    "word_count": 94,
    "importance_score": 4.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "search fails occassionally",
    "contentLower": "sometimes, the keyword-based search returns nothing. cause a possible cause for this issue is that the search is too slow, and the search process breaks down. solution if you haven't changed the timeout values before, follow these steps: log in to the control plane node or bastion node, and then run the following command: kubectl edit cm itom-sma-smarta-common-configuration-cm -n <namespace> find the following fields: hystrix.command.default.execution.isolation.thread.timeoutinmilliseconds itsma.service.httpclient.default.socket-timeout increase the timeout values for these two fields. for example, increase the value from 3000 to 4000. restart the smart analytics service by using the following command: kubectl rollout restart deployment smarta-search -n itsma-xceej if you have changed the timeout values before updating the suite to the new version, follow these steps: log in to the control plane node or bastion node, and then run the following command: kubectl edit deployment -n itsma-",
    "keywordsLower": [
      "search",
      "fails",
      "occassionally",
      "cause",
      "solution",
      "sometimes",
      "keyword-based",
      "returns",
      "nothing.",
      "possible",
      "issue",
      "too",
      "slow",
      "process",
      "breaks",
      "down.",
      "haven",
      "changed",
      "timeout",
      "values",
      "before",
      "follow",
      "steps",
      "log",
      "control",
      "plane",
      "node",
      "bastion",
      "run",
      "following",
      "command",
      "kubectl",
      "edit",
      "cm",
      "itom-sma-smarta-common-configuration-cm",
      "-n",
      "find",
      "fields",
      "hystrix.command.default.execution.isolation.thread.timeoutinmilliseconds",
      "itsma.service.httpclient.default.socket-timeout",
      "increase",
      "two",
      "fields.",
      "example",
      "value",
      "3000",
      "4000.",
      "restart",
      "smart",
      "analytics",
      "service",
      "rollout",
      "deployment",
      "smarta-search",
      "itsma-xceej",
      "updating",
      "suite",
      "new",
      "version",
      "check",
      "note",
      "previously",
      "one",
      "field",
      "here.",
      "all",
      "changed.",
      "after",
      "upgrade",
      "update",
      "ones",
      "noted"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Stuck at \"Adding a new content group...\"",
    "content": "Smart Analytics gets stuck at \"Adding a new content group...\" after you click Add New Content Group. Cause This issue occurs due to a DIH connection error. Log in to a control plane node as root or a sudo user, and run the following command to get the pod name of smarta-installer: kubectl get pods -n <namespace> | grep installer Run the following command to access the installer's log: kubectl logs <installer pod name> -n <namespace> -c suite-config You can find the following text in the log. Connection refused: smarta-saw-dih-svc. Solution Log in to a control plane node as root or a sudo user, and run the following command to get the pod name of smarta-installer: kubectl get pods -n <namespace> | grep installer Run the following command to restart the installer pod: kubectl delete pod <installer pod name> -n <namespace> Log in to a control plane node as root or a sudo user, and check if smarta-saw-dih is running and ready. Run the following command to view the dih pod status: kubectl g",
    "url": "addcontentstuck",
    "filename": "addcontentstuck",
    "headings": [
      "Cause",
      "Solution"
    ],
    "keywords": [
      "https://smarta-saw-dih-svc:1443/action=indexergetstatus&index=<IndexID",
      "https://<pod",
      "stuck",
      "adding",
      "new",
      "content",
      "group...",
      "cause",
      "solution",
      "smart",
      "analytics",
      "gets",
      "after",
      "click",
      "add",
      "group.",
      "issue",
      "occurs",
      "due",
      "dih",
      "connection",
      "error.",
      "log",
      "control",
      "plane",
      "node",
      "root",
      "sudo",
      "user",
      "run",
      "following",
      "command",
      "get",
      "pod",
      "name",
      "smarta-installer",
      "kubectl",
      "pods",
      "-n",
      "grep",
      "installer",
      "access",
      "logs",
      "-c",
      "suite-config",
      "find",
      "text",
      "log.",
      "refused",
      "smarta-saw-dih-svc.",
      "restart",
      "delete",
      "check",
      "smarta-saw-dih",
      "running",
      "ready.",
      "view",
      "status",
      "-o",
      "wide",
      "saw-dih",
      "note",
      "ip",
      "pod.",
      "redistribute",
      "curl",
      "https",
      "1444",
      "dreredistribute",
      "noarchive",
      "true",
      "batchsize",
      "500",
      "compress",
      "false",
      "killduplicates",
      "index",
      "id.",
      "suite",
      "administration",
      "configurations",
      "tab",
      "go",
      "analytics.",
      "assistant",
      "double-click",
      "xservice",
      "enter",
      "action",
      "job",
      "status.",
      "smarta-saw-dih-svc",
      "1443",
      "indexergetstatus"
    ],
    "language": "en",
    "word_count": 116,
    "importance_score": 3.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "stuck at \"adding a new content group...\"",
    "contentLower": "smart analytics gets stuck at \"adding a new content group...\" after you click add new content group. cause this issue occurs due to a dih connection error. log in to a control plane node as root or a sudo user, and run the following command to get the pod name of smarta-installer: kubectl get pods -n <namespace> | grep installer run the following command to access the installer's log: kubectl logs <installer pod name> -n <namespace> -c suite-config you can find the following text in the log. connection refused: smarta-saw-dih-svc. solution log in to a control plane node as root or a sudo user, and run the following command to get the pod name of smarta-installer: kubectl get pods -n <namespace> | grep installer run the following command to restart the installer pod: kubectl delete pod <installer pod name> -n <namespace> log in to a control plane node as root or a sudo user, and check if smarta-saw-dih is running and ready. run the following command to view the dih pod status: kubectl g",
    "keywordsLower": [
      "https://smarta-saw-dih-svc:1443/action=indexergetstatus&index=<indexid",
      "https://<pod",
      "stuck",
      "adding",
      "new",
      "content",
      "group...",
      "cause",
      "solution",
      "smart",
      "analytics",
      "gets",
      "after",
      "click",
      "add",
      "group.",
      "issue",
      "occurs",
      "due",
      "dih",
      "connection",
      "error.",
      "log",
      "control",
      "plane",
      "node",
      "root",
      "sudo",
      "user",
      "run",
      "following",
      "command",
      "get",
      "pod",
      "name",
      "smarta-installer",
      "kubectl",
      "pods",
      "-n",
      "grep",
      "installer",
      "access",
      "logs",
      "-c",
      "suite-config",
      "find",
      "text",
      "log.",
      "refused",
      "smarta-saw-dih-svc.",
      "restart",
      "delete",
      "check",
      "smarta-saw-dih",
      "running",
      "ready.",
      "view",
      "status",
      "-o",
      "wide",
      "saw-dih",
      "note",
      "ip",
      "pod.",
      "redistribute",
      "curl",
      "https",
      "1444",
      "dreredistribute",
      "noarchive",
      "true",
      "batchsize",
      "500",
      "compress",
      "false",
      "killduplicates",
      "index",
      "id.",
      "suite",
      "administration",
      "configurations",
      "tab",
      "go",
      "analytics.",
      "assistant",
      "double-click",
      "xservice",
      "enter",
      "action",
      "job",
      "status.",
      "smarta-saw-dih-svc",
      "1443",
      "indexergetstatus"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Timeout when adding content groups",
    "content": "The following error message is displayed after you click Add New Content Group: \"The connection has timed out. You can check the status of content groups, DAH, and DIH in Smart Analytics Assistant..\" Cause This issue is caused by large content volume or DIH error Solution Log in to Suite Administration, click Configurations, in Smart Analytics tab, click Go to Smart Analytics. In Smart Analytics Assistant, double-click XService DIH, check the number of indexqueueuncompleted in the response. If the number is 0, the content group is added. If the number is larger than 1, wait for a while and try to add the content group again. If the number is 1, select View Index Status from the drop-down list and click RUN. Find the task with index_command as \"DREREDISTRIBUTE\" (change the MaxResults in the action box to a larger number if there is no such task), id the status is \"Processing in remote engine\", note the ID, enter the following action and click RUN: https://smarta-saw-dih-svc:1443/action=",
    "url": "addcontenttimeout",
    "filename": "addcontenttimeout",
    "headings": [
      "Cause",
      "Solution"
    ],
    "keywords": [
      "https://smarta-saw-dih-svc:1443/action=indexergetstatus&IndexAction=Cancel&Index=<IndexID",
      "timeout",
      "adding",
      "content",
      "groups",
      "cause",
      "solution",
      "following",
      "error",
      "message",
      "displayed",
      "after",
      "click",
      "add",
      "new",
      "group",
      "connection",
      "timed",
      "out.",
      "check",
      "status",
      "dah",
      "dih",
      "smart",
      "analytics",
      "assistant..",
      "issue",
      "caused",
      "large",
      "volume",
      "log",
      "suite",
      "administration",
      "configurations",
      "tab",
      "go",
      "analytics.",
      "assistant",
      "double-click",
      "xservice",
      "number",
      "indexqueueuncompleted",
      "response.",
      "added.",
      "larger",
      "wait",
      "while",
      "try",
      "again.",
      "select",
      "view",
      "index",
      "drop-down",
      "list",
      "run.",
      "find",
      "task",
      "dreredistribute",
      "change",
      "maxresults",
      "action",
      "box",
      "there",
      "such",
      "id",
      "processing",
      "remote",
      "engine",
      "note",
      "enter",
      "run",
      "https",
      "smarta-saw-dih-svc",
      "1443",
      "indexergetstatus",
      "indexaction",
      "cancel"
    ],
    "language": "en",
    "word_count": 111,
    "importance_score": 4.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "timeout when adding content groups",
    "contentLower": "the following error message is displayed after you click add new content group: \"the connection has timed out. you can check the status of content groups, dah, and dih in smart analytics assistant..\" cause this issue is caused by large content volume or dih error solution log in to suite administration, click configurations, in smart analytics tab, click go to smart analytics. in smart analytics assistant, double-click xservice dih, check the number of indexqueueuncompleted in the response. if the number is 0, the content group is added. if the number is larger than 1, wait for a while and try to add the content group again. if the number is 1, select view index status from the drop-down list and click run. find the task with index_command as \"dreredistribute\" (change the maxresults in the action box to a larger number if there is no such task), id the status is \"processing in remote engine\", note the id, enter the following action and click run: https://smarta-saw-dih-svc:1443/action=",
    "keywordsLower": [
      "https://smarta-saw-dih-svc:1443/action=indexergetstatus&indexaction=cancel&index=<indexid",
      "timeout",
      "adding",
      "content",
      "groups",
      "cause",
      "solution",
      "following",
      "error",
      "message",
      "displayed",
      "after",
      "click",
      "add",
      "new",
      "group",
      "connection",
      "timed",
      "out.",
      "check",
      "status",
      "dah",
      "dih",
      "smart",
      "analytics",
      "assistant..",
      "issue",
      "caused",
      "large",
      "volume",
      "log",
      "suite",
      "administration",
      "configurations",
      "tab",
      "go",
      "analytics.",
      "assistant",
      "double-click",
      "xservice",
      "number",
      "indexqueueuncompleted",
      "response.",
      "added.",
      "larger",
      "wait",
      "while",
      "try",
      "again.",
      "select",
      "view",
      "index",
      "drop-down",
      "list",
      "run.",
      "find",
      "task",
      "dreredistribute",
      "change",
      "maxresults",
      "action",
      "box",
      "there",
      "such",
      "id",
      "processing",
      "remote",
      "engine",
      "note",
      "enter",
      "run",
      "https",
      "smarta-saw-dih-svc",
      "1443",
      "indexergetstatus",
      "indexaction",
      "cancel"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "The search results of double-byte character set might be incomplete",
    "content": "The search accuracy of East Asian languages that belong to a double-byte character set (such as Chinese, Japanese, or Korean) requires case-by-case tuning. It may depend on various scenarios such as data distribution, search language, and so on. There is no universally applicable solution. However, for search accuracy in scenarios where East Asian languages are mixed with other languages (such as English), you can refer to the following solution for improvement. These procedures have achieved ideal results in customer environments. Classic deployment Log in to the control plane node or bastion node as root or a sudo user. Run the following command to change the config map: kubectl edit cm itom-sma-smarta-common-configuration-cm -n <suite_namespace> For example, kubectl edit cm itom-sma-smarta-common-configuration-cm -n itsma-1dmwm Change the detect_language_type to false. Run the following command to display all content files: kubectl get po -n <suite_namespace> | grep con- For example",
    "url": "enhacesearchdbcs",
    "filename": "enhacesearchdbcs",
    "headings": [
      "Classic deployment",
      "Helm deployment"
    ],
    "keywords": [
      "content.cfg",
      "1.0.0",
      "24.3",
      "values.yaml",
      "xxx.tgz",
      "international.dat",
      "search",
      "results",
      "double-byte",
      "character",
      "set",
      "incomplete",
      "classic",
      "deployment",
      "helm",
      "accuracy",
      "east",
      "asian",
      "languages",
      "belong",
      "such",
      "chinese",
      "japanese",
      "korean",
      "requires",
      "case-by-case",
      "tuning.",
      "depend",
      "various",
      "scenarios",
      "data",
      "distribution",
      "language",
      "on.",
      "there",
      "universally",
      "applicable",
      "solution.",
      "however",
      "mixed",
      "english",
      "refer",
      "following",
      "solution",
      "improvement.",
      "procedures",
      "achieved",
      "ideal",
      "customer",
      "environments.",
      "log",
      "control",
      "plane",
      "node",
      "bastion",
      "root",
      "sudo",
      "user.",
      "run",
      "command",
      "change",
      "config",
      "map",
      "kubectl",
      "edit",
      "cm",
      "itom-sma-smarta-common-configuration-cm",
      "-n",
      "example",
      "itsma-1dmwm",
      "false.",
      "display",
      "all",
      "content",
      "files",
      "get",
      "po",
      "grep",
      "con-",
      "nfs",
      "server",
      "add",
      "parameters",
      "languagetypes",
      "transliteration",
      "false",
      "ngram",
      "ngramorientalonly",
      "true",
      "hyphenchars",
      "none",
      "propernames",
      "augmentseparators",
      "stoplists",
      "see",
      "table",
      "configuration",
      "file",
      "locations.",
      "note"
    ],
    "language": "en",
    "word_count": 102,
    "importance_score": 3.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "the search results of double-byte character set might be incomplete",
    "contentLower": "the search accuracy of east asian languages that belong to a double-byte character set (such as chinese, japanese, or korean) requires case-by-case tuning. it may depend on various scenarios such as data distribution, search language, and so on. there is no universally applicable solution. however, for search accuracy in scenarios where east asian languages are mixed with other languages (such as english), you can refer to the following solution for improvement. these procedures have achieved ideal results in customer environments. classic deployment log in to the control plane node or bastion node as root or a sudo user. run the following command to change the config map: kubectl edit cm itom-sma-smarta-common-configuration-cm -n <suite_namespace> for example, kubectl edit cm itom-sma-smarta-common-configuration-cm -n itsma-1dmwm change the detect_language_type to false. run the following command to display all content files: kubectl get po -n <suite_namespace> | grep con- for example",
    "keywordsLower": [
      "content.cfg",
      "1.0.0",
      "24.3",
      "values.yaml",
      "xxx.tgz",
      "international.dat",
      "search",
      "results",
      "double-byte",
      "character",
      "set",
      "incomplete",
      "classic",
      "deployment",
      "helm",
      "accuracy",
      "east",
      "asian",
      "languages",
      "belong",
      "such",
      "chinese",
      "japanese",
      "korean",
      "requires",
      "case-by-case",
      "tuning.",
      "depend",
      "various",
      "scenarios",
      "data",
      "distribution",
      "language",
      "on.",
      "there",
      "universally",
      "applicable",
      "solution.",
      "however",
      "mixed",
      "english",
      "refer",
      "following",
      "solution",
      "improvement.",
      "procedures",
      "achieved",
      "ideal",
      "customer",
      "environments.",
      "log",
      "control",
      "plane",
      "node",
      "bastion",
      "root",
      "sudo",
      "user.",
      "run",
      "command",
      "change",
      "config",
      "map",
      "kubectl",
      "edit",
      "cm",
      "itom-sma-smarta-common-configuration-cm",
      "-n",
      "example",
      "itsma-1dmwm",
      "false.",
      "display",
      "all",
      "content",
      "files",
      "get",
      "po",
      "grep",
      "con-",
      "nfs",
      "server",
      "add",
      "parameters",
      "languagetypes",
      "transliteration",
      "false",
      "ngram",
      "ngramorientalonly",
      "true",
      "hyphenchars",
      "none",
      "propernames",
      "augmentseparators",
      "stoplists",
      "see",
      "table",
      "configuration",
      "file",
      "locations.",
      "note"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "The search results of Thai language might be incomplete",
    "content": "The search accuracy of Thai language in the Global Search and Service Portal requires further tuning. The sentence breaking issue may be the potential cause. You can refer to the following solution for improvement guidance, which uses NGram to split texts into tokens containing N characters. These procedures have achieved ideal outcomes in customer environments. Before you start, make sure you've enabled DetectLanguageType=true parameter. For more information, see How to include DetectLanguageType=true parameter. Log in to the control plane node or bastion node as root or a sudo user. Run the following command to display all content files: kubectl get po -n <suite_namespace> | grep con- For example, kubectl get po -n itsma-1dmwm | grep con- Log in to the NFS server and add the NGram=2 under the [thai] section to all content config files: [thai] Encodings=UTF8:thaiUTF8 SentenceBreaking=thaibreaking NGram=2 Stoplist=thai.dat IndexNumbers=1 HyphenChars=NONE AugmentSeparators=-_ See the fo",
    "url": "thaisearchaccuracy",
    "filename": "thaisearchaccuracy",
    "headings": [],
    "keywords": [
      "thai.dat",
      "content.cfg",
      "search",
      "results",
      "thai",
      "language",
      "incomplete",
      "accuracy",
      "global",
      "service",
      "portal",
      "requires",
      "further",
      "tuning.",
      "sentence",
      "breaking",
      "issue",
      "potential",
      "cause.",
      "refer",
      "following",
      "solution",
      "improvement",
      "guidance",
      "uses",
      "ngram",
      "split",
      "texts",
      "tokens",
      "containing",
      "characters.",
      "procedures",
      "achieved",
      "ideal",
      "outcomes",
      "customer",
      "environments.",
      "before",
      "start",
      "make",
      "sure",
      "ve",
      "enabled",
      "detectlanguagetype",
      "true",
      "parameter.",
      "information",
      "see",
      "include",
      "log",
      "control",
      "plane",
      "node",
      "bastion",
      "root",
      "sudo",
      "user.",
      "run",
      "command",
      "display",
      "all",
      "content",
      "files",
      "kubectl",
      "get",
      "po",
      "-n",
      "grep",
      "con-",
      "example",
      "itsma-1dmwm",
      "nfs",
      "server",
      "add",
      "under",
      "section",
      "config",
      "encodings",
      "utf8",
      "thaiutf8",
      "sentencebreaking",
      "thaibreaking",
      "stoplist",
      "indexnumbers",
      "hyphenchars",
      "none",
      "augmentseparators",
      "table",
      "configuration",
      "file",
      "locations.",
      "note",
      "found",
      "manually",
      "folder",
      "file.",
      "name",
      "location",
      "smarta-saw-con-0",
      "idol"
    ],
    "language": "en",
    "word_count": 116,
    "importance_score": 2.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "the search results of thai language might be incomplete",
    "contentLower": "the search accuracy of thai language in the global search and service portal requires further tuning. the sentence breaking issue may be the potential cause. you can refer to the following solution for improvement guidance, which uses ngram to split texts into tokens containing n characters. these procedures have achieved ideal outcomes in customer environments. before you start, make sure you've enabled detectlanguagetype=true parameter. for more information, see how to include detectlanguagetype=true parameter. log in to the control plane node or bastion node as root or a sudo user. run the following command to display all content files: kubectl get po -n <suite_namespace> | grep con- for example, kubectl get po -n itsma-1dmwm | grep con- log in to the nfs server and add the ngram=2 under the [thai] section to all content config files: [thai] encodings=utf8:thaiutf8 sentencebreaking=thaibreaking ngram=2 stoplist=thai.dat indexnumbers=1 hyphenchars=none augmentseparators=-_ see the fo",
    "keywordsLower": [
      "thai.dat",
      "content.cfg",
      "search",
      "results",
      "thai",
      "language",
      "incomplete",
      "accuracy",
      "global",
      "service",
      "portal",
      "requires",
      "further",
      "tuning.",
      "sentence",
      "breaking",
      "issue",
      "potential",
      "cause.",
      "refer",
      "following",
      "solution",
      "improvement",
      "guidance",
      "uses",
      "ngram",
      "split",
      "texts",
      "tokens",
      "containing",
      "characters.",
      "procedures",
      "achieved",
      "ideal",
      "outcomes",
      "customer",
      "environments.",
      "before",
      "start",
      "make",
      "sure",
      "ve",
      "enabled",
      "detectlanguagetype",
      "true",
      "parameter.",
      "information",
      "see",
      "include",
      "log",
      "control",
      "plane",
      "node",
      "bastion",
      "root",
      "sudo",
      "user.",
      "run",
      "command",
      "display",
      "all",
      "content",
      "files",
      "kubectl",
      "get",
      "po",
      "-n",
      "grep",
      "con-",
      "example",
      "itsma-1dmwm",
      "nfs",
      "server",
      "add",
      "under",
      "section",
      "config",
      "encodings",
      "utf8",
      "thaiutf8",
      "sentencebreaking",
      "thaibreaking",
      "stoplist",
      "indexnumbers",
      "hyphenchars",
      "none",
      "augmentseparators",
      "table",
      "configuration",
      "file",
      "locations.",
      "note",
      "found",
      "manually",
      "folder",
      "file.",
      "name",
      "location",
      "smarta-saw-con-0",
      "idol"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Search performance not improved",
    "content": "Search performance isn't improved after you add more content groups. Cause This issue occurs because the data isn't distributed to the new content groups. Solution Log in to the NFS server and go to the <Smart Analytics>/logs/idol/saw/dih folder. Run the command ls -ltr to find the last modified folder. Go to that folder and check if you can find the message \"50-Warning: Engine group configuration unchanged, distribution hash ring update not required.\" in the application.log. Log in to Suite Administration, click Configurations > on the Smart Analytics tab, click Go to Smart Analytics. In Smart Analytics Assistant, double-click XService DIH. Find the two latest engine IDs in the response. Enter the following action and click RUN. https://smarta-saw-dih-svc:1443/action=enginemanagement&EngineAction=Edit&Id=<EngineID>&Weight=0 Enter the following action and click RUN. https://smarta-saw-dih-svc:1443/action=enginemanagement&EngineAction=Edit&Id=<ENGINE ID>&Weight=1 Enter the following act",
    "url": "searchperfnotimproved",
    "filename": "searchperfnotimproved",
    "headings": [
      "Cause",
      "Solution"
    ],
    "keywords": [
      "https://smarta-saw-dih-svc:1443/DREREDISTRIBUTENoArchive=True&BatchSize=500&Compress=false&Delete=true&KillDuplicates=true",
      "application.log",
      "https://smarta-saw-dih-svc:1443/action=enginemanagement&EngineAction=Edit&Id=<ENGINE",
      "https://smarta-saw-dih-svc:1443/action=enginemanagement&EngineAction=Edit&Id=<EngineID>&Weight=0",
      "search",
      "performance",
      "improved",
      "cause",
      "solution",
      "isn",
      "after",
      "add",
      "content",
      "groups.",
      "issue",
      "occurs",
      "because",
      "data",
      "distributed",
      "new",
      "log",
      "nfs",
      "server",
      "go",
      "logs",
      "idol",
      "saw",
      "dih",
      "folder.",
      "run",
      "command",
      "ls",
      "-ltr",
      "find",
      "last",
      "modified",
      "folder",
      "check",
      "message",
      "50-warning",
      "engine",
      "group",
      "configuration",
      "unchanged",
      "distribution",
      "hash",
      "ring",
      "update",
      "required.",
      "application.log.",
      "suite",
      "administration",
      "click",
      "configurations",
      "smart",
      "analytics",
      "tab",
      "analytics.",
      "assistant",
      "double-click",
      "xservice",
      "dih.",
      "two",
      "latest",
      "ids",
      "response.",
      "enter",
      "following",
      "action",
      "run.",
      "https",
      "smarta-saw-dih-svc",
      "1443",
      "enginemanagement",
      "engineaction",
      "edit",
      "id",
      "weight",
      "dreredistributenoarchive",
      "true",
      "batchsize",
      "500",
      "compress",
      "false",
      "delete",
      "killduplicates",
      "select",
      "view",
      "index",
      "status",
      "drop-down",
      "list",
      "job",
      "status."
    ],
    "language": "en",
    "word_count": 114,
    "importance_score": 4.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "search performance not improved",
    "contentLower": "search performance isn't improved after you add more content groups. cause this issue occurs because the data isn't distributed to the new content groups. solution log in to the nfs server and go to the <smart analytics>/logs/idol/saw/dih folder. run the command ls -ltr to find the last modified folder. go to that folder and check if you can find the message \"50-warning: engine group configuration unchanged, distribution hash ring update not required.\" in the application.log. log in to suite administration, click configurations > on the smart analytics tab, click go to smart analytics. in smart analytics assistant, double-click xservice dih. find the two latest engine ids in the response. enter the following action and click run. https://smarta-saw-dih-svc:1443/action=enginemanagement&engineaction=edit&id=<engineid>&weight=0 enter the following action and click run. https://smarta-saw-dih-svc:1443/action=enginemanagement&engineaction=edit&id=<engine id>&weight=1 enter the following act",
    "keywordsLower": [
      "https://smarta-saw-dih-svc:1443/dreredistributenoarchive=true&batchsize=500&compress=false&delete=true&killduplicates=true",
      "application.log",
      "https://smarta-saw-dih-svc:1443/action=enginemanagement&engineaction=edit&id=<engine",
      "https://smarta-saw-dih-svc:1443/action=enginemanagement&engineaction=edit&id=<engineid>&weight=0",
      "search",
      "performance",
      "improved",
      "cause",
      "solution",
      "isn",
      "after",
      "add",
      "content",
      "groups.",
      "issue",
      "occurs",
      "because",
      "data",
      "distributed",
      "new",
      "log",
      "nfs",
      "server",
      "go",
      "logs",
      "idol",
      "saw",
      "dih",
      "folder.",
      "run",
      "command",
      "ls",
      "-ltr",
      "find",
      "last",
      "modified",
      "folder",
      "check",
      "message",
      "50-warning",
      "engine",
      "group",
      "configuration",
      "unchanged",
      "distribution",
      "hash",
      "ring",
      "update",
      "required.",
      "application.log.",
      "suite",
      "administration",
      "click",
      "configurations",
      "smart",
      "analytics",
      "tab",
      "analytics.",
      "assistant",
      "double-click",
      "xservice",
      "dih.",
      "two",
      "latest",
      "ids",
      "response.",
      "enter",
      "following",
      "action",
      "run.",
      "https",
      "smarta-saw-dih-svc",
      "1443",
      "enginemanagement",
      "engineaction",
      "edit",
      "id",
      "weight",
      "dreredistributenoarchive",
      "true",
      "batchsize",
      "500",
      "compress",
      "false",
      "delete",
      "killduplicates",
      "select",
      "view",
      "index",
      "status",
      "drop-down",
      "list",
      "job",
      "status."
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "smarta-saw-dah pod crashes with the OOMKilled error",
    "content": "The smarta-saw-dah pod crashes with the OOMKilled error. When you use kubectl describe pod command to fetch details about the smarta-saw-dah pod, the OOMKilled error occurs. Cause The idol-shared memory of the smarta-saw-dah pod isn't enough. Solution Log in to the control plane node as root user. Run the following command to update the idol-shared memory value from 96M to 256M: kubectl edit sts smarta-saw-dah -n itsma-a4iax Here is an example: After update, saw DAH pods will restart. After saw DAH pods are ready, you can double check if the idol-shared memory of the smarta-saw-dah pod is updated to 256M as required.",
    "url": "smartatspodcrashoom",
    "filename": "smartatspodcrashoom",
    "headings": [
      "Cause",
      "Solution"
    ],
    "keywords": [
      "smarta-saw-dah",
      "pod",
      "crashes",
      "oomkilled",
      "error",
      "cause",
      "solution",
      "error.",
      "kubectl",
      "describe",
      "command",
      "fetch",
      "details",
      "about",
      "occurs.",
      "idol-shared",
      "memory",
      "isn",
      "enough.",
      "log",
      "control",
      "plane",
      "node",
      "root",
      "user.",
      "run",
      "following",
      "update",
      "value",
      "96m",
      "256m",
      "edit",
      "sts",
      "-n",
      "itsma-a4iax",
      "here",
      "example",
      "after",
      "saw",
      "dah",
      "pods",
      "restart.",
      "ready",
      "double",
      "check",
      "updated",
      "required."
    ],
    "language": "en",
    "word_count": 74,
    "importance_score": 3.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "smarta-saw-dah pod crashes with the oomkilled error",
    "contentLower": "the smarta-saw-dah pod crashes with the oomkilled error. when you use kubectl describe pod command to fetch details about the smarta-saw-dah pod, the oomkilled error occurs. cause the idol-shared memory of the smarta-saw-dah pod isn't enough. solution log in to the control plane node as root user. run the following command to update the idol-shared memory value from 96m to 256m: kubectl edit sts smarta-saw-dah -n itsma-a4iax here is an example: after update, saw dah pods will restart. after saw dah pods are ready, you can double check if the idol-shared memory of the smarta-saw-dah pod is updated to 256m as required.",
    "keywordsLower": [
      "smarta-saw-dah",
      "pod",
      "crashes",
      "oomkilled",
      "error",
      "cause",
      "solution",
      "error.",
      "kubectl",
      "describe",
      "command",
      "fetch",
      "details",
      "about",
      "occurs.",
      "idol-shared",
      "memory",
      "isn",
      "enough.",
      "log",
      "control",
      "plane",
      "node",
      "root",
      "user.",
      "run",
      "following",
      "update",
      "value",
      "96m",
      "256m",
      "edit",
      "sts",
      "-n",
      "itsma-a4iax",
      "here",
      "example",
      "after",
      "saw",
      "dah",
      "pods",
      "restart.",
      "ready",
      "double",
      "check",
      "updated",
      "required."
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "smarta-saw-dah pod crashes frequently",
    "content": "The smarta-saw-dah pod crashes frequently. Cause The memory of the smarta-saw-dah pod isn't enough. Solution Check memory usage Method 1 Log in to the control plane node as root user. Run the following command to check how many memory is in use by the smarta-saw-dah pod: kubectl top po -n itsma-a4iax |grep smarta Here is an example: Check whether the memory value exceeds the limit: (2G)*80% =1638Mi=1.6G If the memory on the smarta-saw-dah pod exceeds 1.6G, update the memory value from 2G to 4G. Method 2 Log in to the control plane node as root user. Run the following command to identify which worker node is in use for the smarta-saw-dah pod: kubectl get pods -n itsma-a4iax -o wide |grep smarta Here is an example: Download SMA Operation Tookit tool, and run the check_resources.py python check resource script. Here is an example: If the memory on the worker node for the smarta-saw-dah pod exceeds 80% of the total memory, update the memory value from 2G to 4G. Update the memory value Run ",
    "url": "smartatspodcrash",
    "filename": "smartatspodcrash",
    "headings": [
      "Cause",
      "Solution",
      "Check memory usage",
      "Method 1",
      "Method 2",
      "Update the memory value"
    ],
    "keywords": [
      "1.6G",
      "check_resources.py",
      "smarta-saw-dah",
      "pod",
      "crashes",
      "frequently",
      "cause",
      "solution",
      "check",
      "memory",
      "usage",
      "method",
      "update",
      "value",
      "frequently.",
      "isn",
      "enough.",
      "log",
      "control",
      "plane",
      "node",
      "root",
      "user.",
      "run",
      "following",
      "command",
      "many",
      "kubectl",
      "top",
      "po",
      "-n",
      "itsma-a4iax",
      "grep",
      "smarta",
      "here",
      "example",
      "whether",
      "exceeds",
      "limit",
      "2g",
      "80",
      "1638mi",
      "4g.",
      "identify",
      "worker",
      "get",
      "pods",
      "-o",
      "wide",
      "download",
      "sma",
      "operation",
      "tookit",
      "tool",
      "python",
      "resource",
      "script.",
      "total",
      "4g",
      "edit",
      "sts",
      "itsma-fb9py",
      "after",
      "saw",
      "dah",
      "restart.",
      "ready",
      "double",
      "updated",
      "running",
      "describe",
      "smarta-saw-dah-0"
    ],
    "language": "en",
    "word_count": 122,
    "importance_score": 6.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "smarta-saw-dah pod crashes frequently",
    "contentLower": "the smarta-saw-dah pod crashes frequently. cause the memory of the smarta-saw-dah pod isn't enough. solution check memory usage method 1 log in to the control plane node as root user. run the following command to check how many memory is in use by the smarta-saw-dah pod: kubectl top po -n itsma-a4iax |grep smarta here is an example: check whether the memory value exceeds the limit: (2g)*80% =1638mi=1.6g if the memory on the smarta-saw-dah pod exceeds 1.6g, update the memory value from 2g to 4g. method 2 log in to the control plane node as root user. run the following command to identify which worker node is in use for the smarta-saw-dah pod: kubectl get pods -n itsma-a4iax -o wide |grep smarta here is an example: download sma operation tookit tool, and run the check_resources.py python check resource script. here is an example: if the memory on the worker node for the smarta-saw-dah pod exceeds 80% of the total memory, update the memory value from 2g to 4g. update the memory value run ",
    "keywordsLower": [
      "1.6g",
      "check_resources.py",
      "smarta-saw-dah",
      "pod",
      "crashes",
      "frequently",
      "cause",
      "solution",
      "check",
      "memory",
      "usage",
      "method",
      "update",
      "value",
      "frequently.",
      "isn",
      "enough.",
      "log",
      "control",
      "plane",
      "node",
      "root",
      "user.",
      "run",
      "following",
      "command",
      "many",
      "kubectl",
      "top",
      "po",
      "-n",
      "itsma-a4iax",
      "grep",
      "smarta",
      "here",
      "example",
      "whether",
      "exceeds",
      "limit",
      "2g",
      "80",
      "1638mi",
      "4g.",
      "identify",
      "worker",
      "get",
      "pods",
      "-o",
      "wide",
      "download",
      "sma",
      "operation",
      "tookit",
      "tool",
      "python",
      "resource",
      "script.",
      "total",
      "4g",
      "edit",
      "sts",
      "itsma-fb9py",
      "after",
      "saw",
      "dah",
      "restart.",
      "ready",
      "double",
      "updated",
      "running",
      "describe",
      "smarta-saw-dah-0"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Search is slow",
    "content": "Search is slow or Smart Analytics consumes too much disk space. Additionally, in Suite Administration (https://<EXTERNAL_ACCESS_HOST>/bo), if you go to Configurations > Smart Analytics > GO TO SMART ANALYTICS and double-click a content server in the Smart Analytics Components list, you'll find that the number of committed documents is more than 20% higher than the number of documents, as shown in the following figure. Cause This issue occurs because of IDOL restrictions. Solution Due to the large volume of data on XService Archive, perform the following procedures when the system has less traffic. You can either manually perform an IDOL index compaction or schedule it periodically to clean up and optimize the IDOL indexes. Prerequisite To ensure that the drecompact action can run successfully, verify that the dbbt.db file of each content pod is not 0 bytes in size. If the file size is 0, delete the file and restart the pod using the following steps: Log in to Suite Administration. Choo",
    "url": "searchslow",
    "filename": "searchslow",
    "headings": [
      "Cause",
      "Solution",
      "Prerequisite",
      "Manual IDOL index compaction",
      "Scheduled IDOL index compaction"
    ],
    "keywords": [
      "https://<EXTERNAL_ACCESS_HOST>/bo",
      "https://<content_pod_name>:1445/action=stop",
      "dbbt.db",
      "https://smarta-saw-dih-svc:1444/DRECOMPACT",
      "https://smarta-saw-con-0:1445/action=stop",
      "https://smarta-sawarc-dih-svc:1444/DRECOMPACT",
      "search",
      "slow",
      "cause",
      "solution",
      "prerequisite",
      "manual",
      "idol",
      "index",
      "compaction",
      "scheduled",
      "smart",
      "analytics",
      "consumes",
      "too",
      "much",
      "disk",
      "space.",
      "additionally",
      "suite",
      "administration",
      "https",
      "bo",
      "go",
      "configurations",
      "double-click",
      "content",
      "server",
      "components",
      "list",
      "ll",
      "find",
      "number",
      "committed",
      "documents",
      "20",
      "higher",
      "shown",
      "following",
      "figure.",
      "issue",
      "occurs",
      "because",
      "restrictions.",
      "due",
      "large",
      "volume",
      "data",
      "xservice",
      "archive",
      "perform",
      "procedures",
      "system",
      "less",
      "traffic.",
      "either",
      "manually",
      "schedule",
      "periodically",
      "clean",
      "optimize",
      "indexes.",
      "ensure",
      "drecompact",
      "action",
      "run",
      "successfully",
      "verify",
      "file",
      "pod",
      "bytes",
      "size.",
      "size",
      "delete",
      "restart",
      "steps",
      "log",
      "administration.",
      "choose",
      "click",
      "analytics.",
      "enter",
      "run.",
      "1445",
      "stop",
      "example",
      "check",
      "itsma-smarta-saw-con-0",
      "nfs",
      "directory",
      "smarta-saw-con-0",
      "dynterm",
      "ls",
      "-l",
      "command."
    ],
    "language": "en",
    "word_count": 100,
    "importance_score": 5.5,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "search is slow",
    "contentLower": "search is slow or smart analytics consumes too much disk space. additionally, in suite administration (https://<external_access_host>/bo), if you go to configurations > smart analytics > go to smart analytics and double-click a content server in the smart analytics components list, you'll find that the number of committed documents is more than 20% higher than the number of documents, as shown in the following figure. cause this issue occurs because of idol restrictions. solution due to the large volume of data on xservice archive, perform the following procedures when the system has less traffic. you can either manually perform an idol index compaction or schedule it periodically to clean up and optimize the idol indexes. prerequisite to ensure that the drecompact action can run successfully, verify that the dbbt.db file of each content pod is not 0 bytes in size. if the file size is 0, delete the file and restart the pod using the following steps: log in to suite administration. choo",
    "keywordsLower": [
      "https://<external_access_host>/bo",
      "https://<content_pod_name>:1445/action=stop",
      "dbbt.db",
      "https://smarta-saw-dih-svc:1444/drecompact",
      "https://smarta-saw-con-0:1445/action=stop",
      "https://smarta-sawarc-dih-svc:1444/drecompact",
      "search",
      "slow",
      "cause",
      "solution",
      "prerequisite",
      "manual",
      "idol",
      "index",
      "compaction",
      "scheduled",
      "smart",
      "analytics",
      "consumes",
      "too",
      "much",
      "disk",
      "space.",
      "additionally",
      "suite",
      "administration",
      "https",
      "bo",
      "go",
      "configurations",
      "double-click",
      "content",
      "server",
      "components",
      "list",
      "ll",
      "find",
      "number",
      "committed",
      "documents",
      "20",
      "higher",
      "shown",
      "following",
      "figure.",
      "issue",
      "occurs",
      "because",
      "restrictions.",
      "due",
      "large",
      "volume",
      "data",
      "xservice",
      "archive",
      "perform",
      "procedures",
      "system",
      "less",
      "traffic.",
      "either",
      "manually",
      "schedule",
      "periodically",
      "clean",
      "optimize",
      "indexes.",
      "ensure",
      "drecompact",
      "action",
      "run",
      "successfully",
      "verify",
      "file",
      "pod",
      "bytes",
      "size.",
      "size",
      "delete",
      "restart",
      "steps",
      "log",
      "administration.",
      "choose",
      "click",
      "analytics.",
      "enter",
      "run.",
      "1445",
      "stop",
      "example",
      "check",
      "itsma-smarta-saw-con-0",
      "nfs",
      "directory",
      "smarta-saw-con-0",
      "dynterm",
      "ls",
      "-l",
      "command."
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Troubleshoot Suite Administration",
    "content": "This section provides the following troubleshooting topics: A 500 general error occurs Cannot access the Suite Administration homepage Cannot clone or move a tenant Timeout when importing a tenant Cannot deploy a tenant Cannot cancel exporting, importing, or cloning a tenant Integration user password expires Too many audit records in database License file uploading fails with error 401 Manage Persons API stops processing User information not updated in the tenant License file uploading fails with error 401",
    "url": "suiteadmtroubleshooting",
    "filename": "suiteadmtroubleshooting",
    "headings": [],
    "keywords": [
      "troubleshoot",
      "suite",
      "administration",
      "section",
      "provides",
      "following",
      "troubleshooting",
      "topics",
      "500",
      "general",
      "error",
      "occurs",
      "cannot",
      "access",
      "homepage",
      "clone",
      "move",
      "tenant",
      "timeout",
      "importing",
      "deploy",
      "cancel",
      "exporting",
      "cloning",
      "integration",
      "user",
      "password",
      "expires",
      "too",
      "many",
      "audit",
      "records",
      "database",
      "license",
      "file",
      "uploading",
      "fails",
      "401",
      "manage",
      "persons",
      "api",
      "stops",
      "processing",
      "information",
      "updated"
    ],
    "language": "en",
    "word_count": 63,
    "importance_score": 2.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "troubleshoot suite administration",
    "contentLower": "this section provides the following troubleshooting topics: a 500 general error occurs cannot access the suite administration homepage cannot clone or move a tenant timeout when importing a tenant cannot deploy a tenant cannot cancel exporting, importing, or cloning a tenant integration user password expires too many audit records in database license file uploading fails with error 401 manage persons api stops processing user information not updated in the tenant license file uploading fails with error 401",
    "keywordsLower": [
      "troubleshoot",
      "suite",
      "administration",
      "section",
      "provides",
      "following",
      "troubleshooting",
      "topics",
      "500",
      "general",
      "error",
      "occurs",
      "cannot",
      "access",
      "homepage",
      "clone",
      "move",
      "tenant",
      "timeout",
      "importing",
      "deploy",
      "cancel",
      "exporting",
      "cloning",
      "integration",
      "user",
      "password",
      "expires",
      "too",
      "many",
      "audit",
      "records",
      "database",
      "license",
      "file",
      "uploading",
      "fails",
      "401",
      "manage",
      "persons",
      "api",
      "stops",
      "processing",
      "information",
      "updated"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Reset password, Unlock, Convert to user and Convert to contact buttons aren't available",
    "content": "In Suite Administration, the Manage users in tenant option is enabled for a tenant; however, the tenant admin can't click Reset password, Unlock, Convert to user or Convert to contact button in the Agent Interface. Cause The suite admin uses the Export tenant and Import tenant features to move a source tenant to the current tenant, and the Manage users in tenant option is disabled for the source tenant. Although the current tenant has the Manage users in tenant option enabled in Suite Administration, this option is disabled on the tenant side. Solution Ask the suite admin to do the following for the current tenant: Log in to Suite Administration. Turn off the Manage users in tenant option and click Save. Turn on this option and click Save.",
    "url": "resetpasswordunlockoptionsnotavailable",
    "filename": "resetpasswordunlockoptionsnotavailable",
    "headings": [
      "Cause",
      "Solution"
    ],
    "keywords": [
      "arent",
      "reset",
      "password",
      "unlock",
      "convert",
      "user",
      "contact",
      "buttons",
      "aren",
      "available",
      "cause",
      "solution",
      "suite",
      "administration",
      "manage",
      "users",
      "tenant",
      "option",
      "enabled",
      "however",
      "admin",
      "click",
      "button",
      "agent",
      "interface.",
      "uses",
      "export",
      "import",
      "features",
      "move",
      "source",
      "current",
      "disabled",
      "tenant.",
      "although",
      "side.",
      "ask",
      "following",
      "log",
      "administration.",
      "turn",
      "off",
      "save."
    ],
    "language": "en",
    "word_count": 91,
    "importance_score": 2.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "reset password, unlock, convert to user and convert to contact buttons aren't available",
    "contentLower": "in suite administration, the manage users in tenant option is enabled for a tenant; however, the tenant admin can't click reset password, unlock, convert to user or convert to contact button in the agent interface. cause the suite admin uses the export tenant and import tenant features to move a source tenant to the current tenant, and the manage users in tenant option is disabled for the source tenant. although the current tenant has the manage users in tenant option enabled in suite administration, this option is disabled on the tenant side. solution ask the suite admin to do the following for the current tenant: log in to suite administration. turn off the manage users in tenant option and click save. turn on this option and click save.",
    "keywordsLower": [
      "arent",
      "reset",
      "password",
      "unlock",
      "convert",
      "user",
      "contact",
      "buttons",
      "aren",
      "available",
      "cause",
      "solution",
      "suite",
      "administration",
      "manage",
      "users",
      "tenant",
      "option",
      "enabled",
      "however",
      "admin",
      "click",
      "button",
      "agent",
      "interface.",
      "uses",
      "export",
      "import",
      "features",
      "move",
      "source",
      "current",
      "disabled",
      "tenant.",
      "although",
      "side.",
      "ask",
      "following",
      "log",
      "administration.",
      "turn",
      "off",
      "save."
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Tenant import or export fails due to time out issues",
    "content": "When you try to import or export a tenant with a large volume of data, the export process times out and fails. Cause This issue occurs because the default timeout value for the operation is 120 minutes (2 hours). When you try to import or export a tenant with a large volume of data, this limit is exceeded. Solution Increase the timeout value of the import or export operation to a time longer than 120 minutes. To do this, follow these steps: Run the following command: kubectl edit deploy itom-bo-ats-deployment -n <namespace> Locate the JAVA_OPTS line and update the timeout value of the import (-Doperation.timeout.import=120) and/or export (-Doperation.timeout.export=120) as required. For example, to update the timeout value of both the import and export to 600 minutes (10 hours), make the following update: - env: - name: JAVA_OPTS value: -Djava.security.egd=file:/dev/./urandom -Doperation.timeout.import=600 -Doperation.timeout.export=600 - name: JVM_MAX_MEM_RATIO value: \"50\" Save your c",
    "url": "tenantexportfailtimeout",
    "filename": "tenantexportfailtimeout",
    "headings": [
      "Cause",
      "Solution"
    ],
    "keywords": [
      "security.egd",
      "tenant",
      "import",
      "export",
      "fails",
      "due",
      "time",
      "out",
      "issues",
      "cause",
      "solution",
      "try",
      "large",
      "volume",
      "data",
      "process",
      "times",
      "fails.",
      "issue",
      "occurs",
      "because",
      "default",
      "timeout",
      "value",
      "operation",
      "120",
      "minutes",
      "hours",
      "limit",
      "exceeded.",
      "increase",
      "longer",
      "minutes.",
      "follow",
      "steps",
      "run",
      "following",
      "command",
      "kubectl",
      "edit",
      "deploy",
      "itom-bo-ats-deployment",
      "-n",
      "locate",
      "line",
      "update",
      "-doperation.timeout.import",
      "-doperation.timeout.export",
      "required.",
      "example",
      "both",
      "600",
      "10",
      "make",
      "env",
      "name",
      "-djava.security.egd",
      "file",
      "dev",
      "urandom",
      "50",
      "save",
      "changes",
      "wait",
      "pod",
      "restart",
      "successfully."
    ],
    "language": "en",
    "word_count": 107,
    "importance_score": 3.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "tenant import or export fails due to time out issues",
    "contentLower": "when you try to import or export a tenant with a large volume of data, the export process times out and fails. cause this issue occurs because the default timeout value for the operation is 120 minutes (2 hours). when you try to import or export a tenant with a large volume of data, this limit is exceeded. solution increase the timeout value of the import or export operation to a time longer than 120 minutes. to do this, follow these steps: run the following command: kubectl edit deploy itom-bo-ats-deployment -n <namespace> locate the java_opts line and update the timeout value of the import (-doperation.timeout.import=120) and/or export (-doperation.timeout.export=120) as required. for example, to update the timeout value of both the import and export to 600 minutes (10 hours), make the following update: - env: - name: java_opts value: -djava.security.egd=file:/dev/./urandom -doperation.timeout.import=600 -doperation.timeout.export=600 - name: jvm_max_mem_ratio value: \"50\" save your c",
    "keywordsLower": [
      "security.egd",
      "tenant",
      "import",
      "export",
      "fails",
      "due",
      "time",
      "out",
      "issues",
      "cause",
      "solution",
      "try",
      "large",
      "volume",
      "data",
      "process",
      "times",
      "fails.",
      "issue",
      "occurs",
      "because",
      "default",
      "timeout",
      "value",
      "operation",
      "120",
      "minutes",
      "hours",
      "limit",
      "exceeded.",
      "increase",
      "longer",
      "minutes.",
      "follow",
      "steps",
      "run",
      "following",
      "command",
      "kubectl",
      "edit",
      "deploy",
      "itom-bo-ats-deployment",
      "-n",
      "locate",
      "line",
      "update",
      "-doperation.timeout.import",
      "-doperation.timeout.export",
      "required.",
      "example",
      "both",
      "600",
      "10",
      "make",
      "env",
      "name",
      "-djava.security.egd",
      "file",
      "dev",
      "urandom",
      "50",
      "save",
      "changes",
      "wait",
      "pod",
      "restart",
      "successfully."
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Timeout when importing a tenant",
    "content": "When you import a tenant in Suite Administration, if the data volume of the tenant is huge (for example, 18 GB), the system might stop responding during the importing process until it times out in the end. Cause The itom-bo-ats-deployment pod reaches the memory limit and restarts, which interrupts the tenant importing process. Solution Follow these steps to increase the memory limit for the itom-bo-ats-deployment pod: Get the itsma namespace in the control plane node: kubectl get namespace | grep \"itsma\" Update the itom-bo-ats-deployment resource limit: Run the command: kubectl edit deployment itom-bo-ats-deployment -n <itsma_namespace> Increase the value of the memory limit (for example, change the value to 4Gi). Save the file and exit. Wait for all the ats pods to be restarted. Re-import the tenant in Suite Administration. If you already have an \"IN-PROCESS\" job, wait for two hours and then re-import the tenant.",
    "url": "satsimporttenanttimeout",
    "filename": "satsimporttenanttimeout",
    "headings": [
      "Cause",
      "Solution"
    ],
    "keywords": [
      "timeout",
      "importing",
      "tenant",
      "cause",
      "solution",
      "import",
      "suite",
      "administration",
      "data",
      "volume",
      "huge",
      "example",
      "18",
      "gb",
      "system",
      "stop",
      "responding",
      "during",
      "process",
      "until",
      "times",
      "out",
      "end.",
      "itom-bo-ats-deployment",
      "pod",
      "reaches",
      "memory",
      "limit",
      "restarts",
      "interrupts",
      "process.",
      "follow",
      "steps",
      "increase",
      "get",
      "itsma",
      "namespace",
      "control",
      "plane",
      "node",
      "kubectl",
      "grep",
      "update",
      "resource",
      "run",
      "command",
      "edit",
      "deployment",
      "-n",
      "value",
      "change",
      "4gi",
      "save",
      "file",
      "exit.",
      "wait",
      "all",
      "ats",
      "pods",
      "restarted.",
      "re-import",
      "administration.",
      "already",
      "in-process",
      "job",
      "two",
      "hours",
      "tenant."
    ],
    "language": "en",
    "word_count": 93,
    "importance_score": 4.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "timeout when importing a tenant",
    "contentLower": "when you import a tenant in suite administration, if the data volume of the tenant is huge (for example, 18 gb), the system might stop responding during the importing process until it times out in the end. cause the itom-bo-ats-deployment pod reaches the memory limit and restarts, which interrupts the tenant importing process. solution follow these steps to increase the memory limit for the itom-bo-ats-deployment pod: get the itsma namespace in the control plane node: kubectl get namespace | grep \"itsma\" update the itom-bo-ats-deployment resource limit: run the command: kubectl edit deployment itom-bo-ats-deployment -n <itsma_namespace> increase the value of the memory limit (for example, change the value to 4gi). save the file and exit. wait for all the ats pods to be restarted. re-import the tenant in suite administration. if you already have an \"in-process\" job, wait for two hours and then re-import the tenant.",
    "keywordsLower": [
      "timeout",
      "importing",
      "tenant",
      "cause",
      "solution",
      "import",
      "suite",
      "administration",
      "data",
      "volume",
      "huge",
      "example",
      "18",
      "gb",
      "system",
      "stop",
      "responding",
      "during",
      "process",
      "until",
      "times",
      "out",
      "end.",
      "itom-bo-ats-deployment",
      "pod",
      "reaches",
      "memory",
      "limit",
      "restarts",
      "interrupts",
      "process.",
      "follow",
      "steps",
      "increase",
      "get",
      "itsma",
      "namespace",
      "control",
      "plane",
      "node",
      "kubectl",
      "grep",
      "update",
      "resource",
      "run",
      "command",
      "edit",
      "deployment",
      "-n",
      "value",
      "change",
      "4gi",
      "save",
      "file",
      "exit.",
      "wait",
      "all",
      "ats",
      "pods",
      "restarted.",
      "re-import",
      "administration.",
      "already",
      "in-process",
      "job",
      "two",
      "hours",
      "tenant."
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Too many audit records in database",
    "content": "The audit records are records that track user actions performed in Suite Administration. Each time a user performs an action such as creating a tenant, a new audit record gets created in the database. As time goes by, the accumulated audit data will get bigger and bigger, and might eventually affect the system performance. Cause Too many audit records in the database. Solution If you find your database data volume is too large or you experience performance issue, you can check the size of the tables for audit data. Then manually delete the audit data in your database. To delete the audit data in your database, follow these steps: Access the \"bo_user\" database in the suite. Truncate the table: Note: Make sure that you back up your data before you truncate it. TRUNCATE TABLE revinfo CASCADE;",
    "url": "satsdeleteauditrecords",
    "filename": "satsdeleteauditrecords",
    "headings": [
      "Cause",
      "Solution"
    ],
    "keywords": [
      "too",
      "many",
      "audit",
      "records",
      "database",
      "cause",
      "solution",
      "track",
      "user",
      "actions",
      "performed",
      "suite",
      "administration.",
      "time",
      "performs",
      "action",
      "such",
      "creating",
      "tenant",
      "new",
      "record",
      "gets",
      "created",
      "database.",
      "goes",
      "accumulated",
      "data",
      "get",
      "bigger",
      "eventually",
      "affect",
      "system",
      "performance.",
      "find",
      "volume",
      "large",
      "experience",
      "performance",
      "issue",
      "check",
      "size",
      "tables",
      "data.",
      "manually",
      "delete",
      "follow",
      "steps",
      "access",
      "suite.",
      "truncate",
      "table",
      "note",
      "make",
      "sure",
      "back",
      "before",
      "it.",
      "revinfo",
      "cascade"
    ],
    "language": "en",
    "word_count": 89,
    "importance_score": 3.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "too many audit records in database",
    "contentLower": "the audit records are records that track user actions performed in suite administration. each time a user performs an action such as creating a tenant, a new audit record gets created in the database. as time goes by, the accumulated audit data will get bigger and bigger, and might eventually affect the system performance. cause too many audit records in the database. solution if you find your database data volume is too large or you experience performance issue, you can check the size of the tables for audit data. then manually delete the audit data in your database. to delete the audit data in your database, follow these steps: access the \"bo_user\" database in the suite. truncate the table: note: make sure that you back up your data before you truncate it. truncate table revinfo cascade;",
    "keywordsLower": [
      "too",
      "many",
      "audit",
      "records",
      "database",
      "cause",
      "solution",
      "track",
      "user",
      "actions",
      "performed",
      "suite",
      "administration.",
      "time",
      "performs",
      "action",
      "such",
      "creating",
      "tenant",
      "new",
      "record",
      "gets",
      "created",
      "database.",
      "goes",
      "accumulated",
      "data",
      "get",
      "bigger",
      "eventually",
      "affect",
      "system",
      "performance.",
      "find",
      "volume",
      "large",
      "experience",
      "performance",
      "issue",
      "check",
      "size",
      "tables",
      "data.",
      "manually",
      "delete",
      "follow",
      "steps",
      "access",
      "suite.",
      "truncate",
      "table",
      "note",
      "make",
      "sure",
      "back",
      "before",
      "it.",
      "revinfo",
      "cascade"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "SAML users failed to log in",
    "content": "The SAML users can't log in to the suite. Cause This issue occurs due to the SAML certificate expiration. Log in to a control plane node or bastion node as root or a sudo user, and run the following command to get the pod name of idm: kubectl get pods -n <suite namespace> | grep idm Run the following command to access the installer's log: kubectl logs <idm pod name> -n <suite namespace> -c idm If there're more than one idm pod, run this command on each pod one by one. You can find the following text in the log. checkSignatureValue Signature verficiation failed Solution Log in to the control plane node or bastion node as root or a sudo user and run the following command to enter the idm container: namespace=$(kubectl get ns|grep itsma|head -1|awk '{print $1}') && pod=$(kubectl get po -n $namespace|grep idm|head -1|awk '{print $1}') && kubectl exec -ti $pod -n $namespace -c idm /bin/bash Run the following command to import the env parameters: export CERT_CN=<suite FQDN> export CERT_OU=<o",
    "url": "tssamluserlogin",
    "filename": "tssamluserlogin",
    "headings": [
      "Cause",
      "Solution"
    ],
    "keywords": [
      "https://<EXTERNAL_ACCESS_HOST>/idm-service/saml/metadata",
      "idm.saml",
      "smalKeystore.jks",
      "defaultKey.name",
      "samlKeystore.jks",
      "spring_saml_metadata.xml",
      "saml",
      "users",
      "failed",
      "log",
      "cause",
      "solution",
      "suite.",
      "issue",
      "occurs",
      "due",
      "certificate",
      "expiration.",
      "control",
      "plane",
      "node",
      "bastion",
      "root",
      "sudo",
      "user",
      "run",
      "following",
      "command",
      "get",
      "pod",
      "name",
      "idm",
      "kubectl",
      "pods",
      "-n",
      "grep",
      "access",
      "installer",
      "logs",
      "-c",
      "there",
      "re",
      "one",
      "one.",
      "find",
      "text",
      "log.",
      "checksignaturevalue",
      "signature",
      "verficiation",
      "enter",
      "container",
      "namespace",
      "ns",
      "itsma",
      "head",
      "-1",
      "awk",
      "print",
      "po",
      "exec",
      "-ti",
      "bin",
      "bash",
      "import",
      "env",
      "parameters",
      "export",
      "3650",
      "means",
      "validity",
      "period",
      "10",
      "years",
      "2048",
      "jks",
      "commands",
      "generate",
      "new",
      "file",
      "keytool",
      "-noprompt",
      "-genkey",
      "-dname",
      "cn",
      "ou",
      "st",
      "-keyalg",
      "rsa",
      "-alias",
      "-keystore",
      "-storepass",
      "-keypass",
      "-validity",
      "-keysize",
      "-deststoretype",
      "verify",
      "-list",
      "-storetype",
      "-v"
    ],
    "language": "en",
    "word_count": 129,
    "importance_score": 3.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "saml users failed to log in",
    "contentLower": "the saml users can't log in to the suite. cause this issue occurs due to the saml certificate expiration. log in to a control plane node or bastion node as root or a sudo user, and run the following command to get the pod name of idm: kubectl get pods -n <suite namespace> | grep idm run the following command to access the installer's log: kubectl logs <idm pod name> -n <suite namespace> -c idm if there're more than one idm pod, run this command on each pod one by one. you can find the following text in the log. checksignaturevalue signature verficiation failed solution log in to the control plane node or bastion node as root or a sudo user and run the following command to enter the idm container: namespace=$(kubectl get ns|grep itsma|head -1|awk '{print $1}') && pod=$(kubectl get po -n $namespace|grep idm|head -1|awk '{print $1}') && kubectl exec -ti $pod -n $namespace -c idm /bin/bash run the following command to import the env parameters: export cert_cn=<suite fqdn> export cert_ou=<o",
    "keywordsLower": [
      "https://<external_access_host>/idm-service/saml/metadata",
      "idm.saml",
      "smalkeystore.jks",
      "defaultkey.name",
      "samlkeystore.jks",
      "spring_saml_metadata.xml",
      "saml",
      "users",
      "failed",
      "log",
      "cause",
      "solution",
      "suite.",
      "issue",
      "occurs",
      "due",
      "certificate",
      "expiration.",
      "control",
      "plane",
      "node",
      "bastion",
      "root",
      "sudo",
      "user",
      "run",
      "following",
      "command",
      "get",
      "pod",
      "name",
      "idm",
      "kubectl",
      "pods",
      "-n",
      "grep",
      "access",
      "installer",
      "logs",
      "-c",
      "there",
      "re",
      "one",
      "one.",
      "find",
      "text",
      "log.",
      "checksignaturevalue",
      "signature",
      "verficiation",
      "enter",
      "container",
      "namespace",
      "ns",
      "itsma",
      "head",
      "-1",
      "awk",
      "print",
      "po",
      "exec",
      "-ti",
      "bin",
      "bash",
      "import",
      "env",
      "parameters",
      "export",
      "3650",
      "means",
      "validity",
      "period",
      "10",
      "years",
      "2048",
      "jks",
      "commands",
      "generate",
      "new",
      "file",
      "keytool",
      "-noprompt",
      "-genkey",
      "-dname",
      "cn",
      "ou",
      "st",
      "-keyalg",
      "rsa",
      "-alias",
      "-keystore",
      "-storepass",
      "-keypass",
      "-validity",
      "-keysize",
      "-deststoretype",
      "verify",
      "-list",
      "-storetype",
      "-v"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Troubleshoot Service Portal",
    "content": "This topic provides the following troubleshooting topics: Fail to match intents if inputs are similar characters in different languages Fail to log in to Service Portal with server error Service requests included in bundle stop responding in Log phase Embedded JavaScript can't run in Service Portal",
    "url": "tsserviceportal",
    "filename": "tsserviceportal",
    "headings": [],
    "keywords": [
      "troubleshoot",
      "service",
      "portal",
      "topic",
      "provides",
      "following",
      "troubleshooting",
      "topics",
      "fail",
      "match",
      "intents",
      "inputs",
      "similar",
      "characters",
      "different",
      "languages",
      "log",
      "server",
      "error",
      "requests",
      "included",
      "bundle",
      "stop",
      "responding",
      "phase",
      "embedded",
      "javascript",
      "run"
    ],
    "language": "en",
    "word_count": 36,
    "importance_score": 2.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "troubleshoot service portal",
    "contentLower": "this topic provides the following troubleshooting topics: fail to match intents if inputs are similar characters in different languages fail to log in to service portal with server error service requests included in bundle stop responding in log phase embedded javascript can't run in service portal",
    "keywordsLower": [
      "troubleshoot",
      "service",
      "portal",
      "topic",
      "provides",
      "following",
      "troubleshooting",
      "topics",
      "fail",
      "match",
      "intents",
      "inputs",
      "similar",
      "characters",
      "different",
      "languages",
      "log",
      "server",
      "error",
      "requests",
      "included",
      "bundle",
      "stop",
      "responding",
      "phase",
      "embedded",
      "javascript",
      "run"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Smart Virtual Agent doesn't provide intents after a suite upgrade",
    "content": "After you upgrade the suite, Smart Virtual Agent can't provide intents in the response. Cause The version of the trained model is too old and isn't compatible with the Natural Language Understanding (NLU) pod of your current tenant. Solution Log in to Agent Interface and navigate to Administration > Configuration > Virtual Agent Settings. Click INTENT in the navigation bar. Click Train to retrain the intents.",
    "url": "retrainva",
    "filename": "retrainva",
    "headings": [
      "Cause",
      "Solution"
    ],
    "keywords": [
      "doesnt",
      "smart",
      "virtual",
      "agent",
      "doesn",
      "provide",
      "intents",
      "after",
      "suite",
      "upgrade",
      "cause",
      "solution",
      "response.",
      "version",
      "trained",
      "model",
      "too",
      "old",
      "isn",
      "compatible",
      "natural",
      "language",
      "understanding",
      "nlu",
      "pod",
      "current",
      "tenant.",
      "log",
      "interface",
      "navigate",
      "administration",
      "configuration",
      "settings.",
      "click",
      "intent",
      "navigation",
      "bar.",
      "train",
      "retrain",
      "intents."
    ],
    "language": "en",
    "word_count": 54,
    "importance_score": 2.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "smart virtual agent doesn't provide intents after a suite upgrade",
    "contentLower": "after you upgrade the suite, smart virtual agent can't provide intents in the response. cause the version of the trained model is too old and isn't compatible with the natural language understanding (nlu) pod of your current tenant. solution log in to agent interface and navigate to administration > configuration > virtual agent settings. click intent in the navigation bar. click train to retrain the intents.",
    "keywordsLower": [
      "doesnt",
      "smart",
      "virtual",
      "agent",
      "doesn",
      "provide",
      "intents",
      "after",
      "suite",
      "upgrade",
      "cause",
      "solution",
      "response.",
      "version",
      "trained",
      "model",
      "too",
      "old",
      "isn",
      "compatible",
      "natural",
      "language",
      "understanding",
      "nlu",
      "pod",
      "current",
      "tenant.",
      "log",
      "interface",
      "navigate",
      "administration",
      "configuration",
      "settings.",
      "click",
      "intent",
      "navigation",
      "bar.",
      "train",
      "retrain",
      "intents."
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Service Portal custom widgets disappear after a suite upgrade",
    "content": "After you upgrade the suite to 24.4, the custom widgets and size of category tiles configured in Service Portal display theme settings are lost. To work around this issue, you may manually backup your custom widget configurations in Service Portal > Theme Settings: For each customized theme, save the widget configurations and download widget source files. After upgrade, please manually add them back to the corresponding themes. There's also a Theme Recovery Tool provided to re-connect the association between widgets and themes. See solution 1 and solution 2. Cause During the upgrade, an error in the upgrade process breaks the association between widgets and themes in the database. Solution 1 Use the Theme Recovery Tool to backup your custom widget configurations before upgrade and restore the configurations after upgrade. Performed by: System administrator and Database administrator Download theme_backup_restore.zip from the file list of Troubleshoot OCTCR19XW2415291: Service Portal cu",
    "url": "troubleshootcustomwidgets",
    "filename": "troubleshootcustomwidgets",
    "headings": [
      "Cause",
      "Solution 1",
      "Solution 2",
      "Related topics"
    ],
    "keywords": [
      "24.4",
      "1_OCTCR19XW2415291.zip",
      "theme_backup_restore.zip",
      "2_OCTCR19XW2415291.zip",
      "service",
      "portal",
      "custom",
      "widgets",
      "disappear",
      "after",
      "suite",
      "upgrade",
      "cause",
      "solution",
      "related",
      "topics",
      "size",
      "category",
      "tiles",
      "configured",
      "display",
      "theme",
      "settings",
      "lost.",
      "work",
      "around",
      "issue",
      "manually",
      "backup",
      "widget",
      "configurations",
      "customized",
      "save",
      "download",
      "source",
      "files.",
      "please",
      "add",
      "back",
      "corresponding",
      "themes.",
      "there",
      "recovery",
      "tool",
      "provided",
      "re-connect",
      "association",
      "between",
      "see",
      "2.",
      "during",
      "error",
      "process",
      "breaks",
      "themes",
      "database.",
      "before",
      "restore",
      "upgrade.",
      "performed",
      "system",
      "administrator",
      "database",
      "file",
      "list",
      "troubleshoot",
      "octcr19xw2415291",
      "24.4.extract",
      "file.follow",
      "instructions",
      "readme-db",
      "tenant",
      "didn",
      "apply",
      "readme-tenant",
      "managed",
      "kubernetes",
      "managementupgrade",
      "management"
    ],
    "language": "en",
    "word_count": 110,
    "importance_score": 4.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "service portal custom widgets disappear after a suite upgrade",
    "contentLower": "after you upgrade the suite to 24.4, the custom widgets and size of category tiles configured in service portal display theme settings are lost. to work around this issue, you may manually backup your custom widget configurations in service portal > theme settings: for each customized theme, save the widget configurations and download widget source files. after upgrade, please manually add them back to the corresponding themes. there's also a theme recovery tool provided to re-connect the association between widgets and themes. see solution 1 and solution 2. cause during the upgrade, an error in the upgrade process breaks the association between widgets and themes in the database. solution 1 use the theme recovery tool to backup your custom widget configurations before upgrade and restore the configurations after upgrade. performed by: system administrator and database administrator download theme_backup_restore.zip from the file list of troubleshoot octcr19xw2415291: service portal cu",
    "keywordsLower": [
      "24.4",
      "1_octcr19xw2415291.zip",
      "theme_backup_restore.zip",
      "2_octcr19xw2415291.zip",
      "service",
      "portal",
      "custom",
      "widgets",
      "disappear",
      "after",
      "suite",
      "upgrade",
      "cause",
      "solution",
      "related",
      "topics",
      "size",
      "category",
      "tiles",
      "configured",
      "display",
      "theme",
      "settings",
      "lost.",
      "work",
      "around",
      "issue",
      "manually",
      "backup",
      "widget",
      "configurations",
      "customized",
      "save",
      "download",
      "source",
      "files.",
      "please",
      "add",
      "back",
      "corresponding",
      "themes.",
      "there",
      "recovery",
      "tool",
      "provided",
      "re-connect",
      "association",
      "between",
      "see",
      "2.",
      "during",
      "error",
      "process",
      "breaks",
      "themes",
      "database.",
      "before",
      "restore",
      "upgrade.",
      "performed",
      "system",
      "administrator",
      "database",
      "file",
      "list",
      "troubleshoot",
      "octcr19xw2415291",
      "24.4.extract",
      "file.follow",
      "instructions",
      "readme-db",
      "tenant",
      "didn",
      "apply",
      "readme-tenant",
      "managed",
      "kubernetes",
      "managementupgrade",
      "management"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Smart virtual agent fails to perform training because the CPU doesn't support AVX",
    "content": "Smart virtual agent fails to perform the training, and the log of the startup NLU pod resembles the snapshot below: Cause The CPU on the Kubernetes cluster worker node that runs the virtual agent NLU pod doesn't support AVX instructions. The virtual agent relies on the TensorFlow library to provide Natural Language Understanding (NLU) capabilities, and the current version of TensorFlow installed via pip uses the AVX instruction set at compile time. This instruction set is only supported on CPUs from the second generation of Intel Core CPUs (codename: Sandy Bridge) and newer, which means that CPUs before 2011 are not supported. To avoid blocking the entire suite installation or upgrade process, the virtual agent NLU pod checks if your CPU supports AVX instructions during startup and decides whether to start the real NLU engine or a mock server. To determine if your hardware supports AVX instructions, follow these steps: Use kubectl to enter the running NLU pod: kubectl exec -it virtual-",
    "url": "supportavxofcpuinsmartva",
    "filename": "supportavxofcpuinsmartva",
    "headings": [
      "Cause",
      "Solution"
    ],
    "keywords": [
      "doesnt",
      "smart",
      "virtual",
      "agent",
      "fails",
      "perform",
      "training",
      "because",
      "cpu",
      "doesn",
      "support",
      "avx",
      "cause",
      "solution",
      "log",
      "startup",
      "nlu",
      "pod",
      "resembles",
      "snapshot",
      "below",
      "kubernetes",
      "cluster",
      "worker",
      "node",
      "runs",
      "instructions.",
      "relies",
      "tensorflow",
      "library",
      "provide",
      "natural",
      "language",
      "understanding",
      "capabilities",
      "current",
      "version",
      "installed",
      "via",
      "pip",
      "uses",
      "instruction",
      "set",
      "compile",
      "time.",
      "supported",
      "cpus",
      "second",
      "generation",
      "intel",
      "core",
      "codename",
      "sandy",
      "bridge",
      "newer",
      "means",
      "before",
      "2011",
      "supported.",
      "avoid",
      "blocking",
      "entire",
      "suite",
      "installation",
      "upgrade",
      "process",
      "checks",
      "supports",
      "instructions",
      "during",
      "decides",
      "whether",
      "start",
      "real",
      "engine",
      "mock",
      "server.",
      "determine",
      "hardware",
      "follow",
      "steps",
      "kubectl",
      "enter",
      "running",
      "exec",
      "-it",
      "virtual-agent-nlu-xxxxxxxxxx-xxxx",
      "-c",
      "virtual-agent-nlu",
      "-n",
      "bash",
      "shell",
      "run",
      "following",
      "command",
      "check",
      "status",
      "cat",
      "proc",
      "cpuinfo"
    ],
    "language": "en",
    "word_count": 124,
    "importance_score": 2.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "smart virtual agent fails to perform training because the cpu doesn't support avx",
    "contentLower": "smart virtual agent fails to perform the training, and the log of the startup nlu pod resembles the snapshot below: cause the cpu on the kubernetes cluster worker node that runs the virtual agent nlu pod doesn't support avx instructions. the virtual agent relies on the tensorflow library to provide natural language understanding (nlu) capabilities, and the current version of tensorflow installed via pip uses the avx instruction set at compile time. this instruction set is only supported on cpus from the second generation of intel core cpus (codename: sandy bridge) and newer, which means that cpus before 2011 are not supported. to avoid blocking the entire suite installation or upgrade process, the virtual agent nlu pod checks if your cpu supports avx instructions during startup and decides whether to start the real nlu engine or a mock server. to determine if your hardware supports avx instructions, follow these steps: use kubectl to enter the running nlu pod: kubectl exec -it virtual-",
    "keywordsLower": [
      "doesnt",
      "smart",
      "virtual",
      "agent",
      "fails",
      "perform",
      "training",
      "because",
      "cpu",
      "doesn",
      "support",
      "avx",
      "cause",
      "solution",
      "log",
      "startup",
      "nlu",
      "pod",
      "resembles",
      "snapshot",
      "below",
      "kubernetes",
      "cluster",
      "worker",
      "node",
      "runs",
      "instructions.",
      "relies",
      "tensorflow",
      "library",
      "provide",
      "natural",
      "language",
      "understanding",
      "capabilities",
      "current",
      "version",
      "installed",
      "via",
      "pip",
      "uses",
      "instruction",
      "set",
      "compile",
      "time.",
      "supported",
      "cpus",
      "second",
      "generation",
      "intel",
      "core",
      "codename",
      "sandy",
      "bridge",
      "newer",
      "means",
      "before",
      "2011",
      "supported.",
      "avoid",
      "blocking",
      "entire",
      "suite",
      "installation",
      "upgrade",
      "process",
      "checks",
      "supports",
      "instructions",
      "during",
      "decides",
      "whether",
      "start",
      "real",
      "engine",
      "mock",
      "server.",
      "determine",
      "hardware",
      "follow",
      "steps",
      "kubectl",
      "enter",
      "running",
      "exec",
      "-it",
      "virtual-agent-nlu-xxxxxxxxxx-xxxx",
      "-c",
      "virtual-agent-nlu",
      "-n",
      "bash",
      "shell",
      "run",
      "following",
      "command",
      "check",
      "status",
      "cat",
      "proc",
      "cpuinfo"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "The \"503 Service Temporarily Unavailable\" error occurs when clicking Virtual Agent Settings",
    "content": "When you click Virtual Agent Settings in Suite Administration, the \"503 Service Temporarily Unavailable\" error occurs. Cause A possible cause for this issue is that the virtual agent pods aren't up. Solution Check if the following virtual agent pods are running. If not, bring the pods up one by one: virtual-agent-admin-ui virtual-agent-nlu virtual-agent-bot-engine For more information, see Smart virtual agent settings.",
    "url": "vaserviceunavailableissue",
    "filename": "vaserviceunavailableissue",
    "headings": [
      "Cause",
      "Solution"
    ],
    "keywords": [
      "503",
      "service",
      "temporarily",
      "unavailable",
      "error",
      "occurs",
      "clicking",
      "virtual",
      "agent",
      "settings",
      "cause",
      "solution",
      "click",
      "suite",
      "administration",
      "occurs.",
      "possible",
      "issue",
      "pods",
      "aren",
      "up.",
      "check",
      "following",
      "running.",
      "bring",
      "one",
      "virtual-agent-admin-ui",
      "virtual-agent-nlu",
      "virtual-agent-bot-engine",
      "information",
      "see",
      "smart",
      "settings."
    ],
    "language": "en",
    "word_count": 52,
    "importance_score": 1.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "the \"503 service temporarily unavailable\" error occurs when clicking virtual agent settings",
    "contentLower": "when you click virtual agent settings in suite administration, the \"503 service temporarily unavailable\" error occurs. cause a possible cause for this issue is that the virtual agent pods aren't up. solution check if the following virtual agent pods are running. if not, bring the pods up one by one: virtual-agent-admin-ui virtual-agent-nlu virtual-agent-bot-engine for more information, see smart virtual agent settings.",
    "keywordsLower": [
      "503",
      "service",
      "temporarily",
      "unavailable",
      "error",
      "occurs",
      "clicking",
      "virtual",
      "agent",
      "settings",
      "cause",
      "solution",
      "click",
      "suite",
      "administration",
      "occurs.",
      "possible",
      "issue",
      "pods",
      "aren",
      "up.",
      "check",
      "following",
      "running.",
      "bring",
      "one",
      "virtual-agent-admin-ui",
      "virtual-agent-nlu",
      "virtual-agent-bot-engine",
      "information",
      "see",
      "smart",
      "settings."
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Service requests included in bundle stop responding in Log phase",
    "content": "After you submit a request bundle that includes more than 3 requests in Service Portal, some child requests of the request bundle stops responding in the Log phase, instead of proceeding to the Approval or Fulfillment phase as expected. Cause Product limitation. Solution If this issue occurs, follow these steps: In Service Management, select Administration > Configuration > Studio > Processes and Rules. Select the Request record type. Search for two rules with the following IDs, then disable the rules respectively. id: setRequestBundleCommentsOnAssigned id: setRequestBundleCommentsOnCreated These 2 workflow rules are used to generate informational messages. If you still want to enable them, you can create the same rules under After applying changes. Save your changes.",
    "url": "requesthanginglog",
    "filename": "requesthanginglog",
    "headings": [
      "Cause",
      "Solution"
    ],
    "keywords": [
      "service",
      "requests",
      "included",
      "bundle",
      "stop",
      "responding",
      "log",
      "phase",
      "cause",
      "solution",
      "after",
      "submit",
      "request",
      "includes",
      "portal",
      "child",
      "stops",
      "instead",
      "proceeding",
      "approval",
      "fulfillment",
      "expected.",
      "product",
      "limitation.",
      "issue",
      "occurs",
      "follow",
      "steps",
      "management",
      "select",
      "administration",
      "configuration",
      "studio",
      "processes",
      "rules.",
      "record",
      "type.",
      "search",
      "two",
      "rules",
      "following",
      "ids",
      "disable",
      "respectively.",
      "id",
      "setrequestbundlecommentsonassigned",
      "setrequestbundlecommentsoncreated",
      "workflow",
      "generate",
      "informational",
      "messages.",
      "still",
      "want",
      "enable",
      "create",
      "same",
      "under",
      "applying",
      "changes.",
      "save"
    ],
    "language": "en",
    "word_count": 81,
    "importance_score": 3.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "service requests included in bundle stop responding in log phase",
    "contentLower": "after you submit a request bundle that includes more than 3 requests in service portal, some child requests of the request bundle stops responding in the log phase, instead of proceeding to the approval or fulfillment phase as expected. cause product limitation. solution if this issue occurs, follow these steps: in service management, select administration > configuration > studio > processes and rules. select the request record type. search for two rules with the following ids, then disable the rules respectively. id: setrequestbundlecommentsonassigned id: setrequestbundlecommentsoncreated these 2 workflow rules are used to generate informational messages. if you still want to enable them, you can create the same rules under after applying changes. save your changes.",
    "keywordsLower": [
      "service",
      "requests",
      "included",
      "bundle",
      "stop",
      "responding",
      "log",
      "phase",
      "cause",
      "solution",
      "after",
      "submit",
      "request",
      "includes",
      "portal",
      "child",
      "stops",
      "instead",
      "proceeding",
      "approval",
      "fulfillment",
      "expected.",
      "product",
      "limitation.",
      "issue",
      "occurs",
      "follow",
      "steps",
      "management",
      "select",
      "administration",
      "configuration",
      "studio",
      "processes",
      "rules.",
      "record",
      "type.",
      "search",
      "two",
      "rules",
      "following",
      "ids",
      "disable",
      "respectively.",
      "id",
      "setrequestbundlecommentsonassigned",
      "setrequestbundlecommentsoncreated",
      "workflow",
      "generate",
      "informational",
      "messages.",
      "still",
      "want",
      "enable",
      "create",
      "same",
      "under",
      "applying",
      "changes.",
      "save"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Troubleshoot Service Management",
    "content": "This section provides the following troubleshooting topics: Expense lines aren't generated as expected Cannot see module menu with an unauthorized page error Saving PPO currency failed Dev2Prod - One or more customization definitions could not be imported Dev2Prod - An existing import job is still running Dev2Prod - Failed to get the entity link value Dev2Prod - Package size is too large",
    "url": "tsservicemgt",
    "filename": "tsservicemgt",
    "headings": [],
    "keywords": [
      "troubleshoot",
      "service",
      "management",
      "section",
      "provides",
      "following",
      "troubleshooting",
      "topics",
      "expense",
      "lines",
      "aren",
      "generated",
      "expected",
      "cannot",
      "see",
      "module",
      "menu",
      "unauthorized",
      "page",
      "error",
      "saving",
      "ppo",
      "currency",
      "failed",
      "dev2prod",
      "one",
      "customization",
      "definitions",
      "imported",
      "existing",
      "import",
      "job",
      "still",
      "running",
      "get",
      "entity",
      "link",
      "value",
      "package",
      "size",
      "too",
      "large"
    ],
    "language": "en",
    "word_count": 47,
    "importance_score": 2.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "troubleshoot service management",
    "contentLower": "this section provides the following troubleshooting topics: expense lines aren't generated as expected cannot see module menu with an unauthorized page error saving ppo currency failed dev2prod - one or more customization definitions could not be imported dev2prod - an existing import job is still running dev2prod - failed to get the entity link value dev2prod - package size is too large",
    "keywordsLower": [
      "troubleshoot",
      "service",
      "management",
      "section",
      "provides",
      "following",
      "troubleshooting",
      "topics",
      "expense",
      "lines",
      "aren",
      "generated",
      "expected",
      "cannot",
      "see",
      "module",
      "menu",
      "unauthorized",
      "page",
      "error",
      "saving",
      "ppo",
      "currency",
      "failed",
      "dev2prod",
      "one",
      "customization",
      "definitions",
      "imported",
      "existing",
      "import",
      "job",
      "still",
      "running",
      "get",
      "entity",
      "link",
      "value",
      "package",
      "size",
      "too",
      "large"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "The execution order doesn't work correctly when you use the REPLACE function in the Manage Persons API",
    "content": "The execution order doesn't work correctly when you use the REPLACE function in the Manage Persons API. Cause The Manage Persons API works asynchronously and there's no guarantee for the execution order of concurrent jobs. Using the REPLACE function to delete and add people's organizational group data might set the OrganizationalGroup field and other relevant fields to an unexpected value. Solution Update the tenant settings by configuring the waiting time between steps for replacing organizational group data. To do this, follow these steps: Configure the waiting mode Open Postman and click + in the workbench to open a new tab. Change the method to PUT and enter the Tenant Settings API for the request URL in the following format: https://<External Access Host>/rest/<tenant ID>/common-settings/setting/<tenant settings key>?value=<tenant setting value> The tenant settings key REPLACE_ORG_GROUP_TRANSACTION_ISOLATION_MODE configures the waiting mode between steps for replacing persons' org",
    "url": "executionordernotworking",
    "filename": "executionordernotworking",
    "headings": [
      "Cause",
      "Solution",
      "Configure the waiting mode",
      "Configure the waiting timeout value"
    ],
    "keywords": [
      "doesnt",
      "https://<External",
      "execution",
      "order",
      "doesn",
      "work",
      "correctly",
      "replace",
      "function",
      "manage",
      "persons",
      "api",
      "cause",
      "solution",
      "configure",
      "waiting",
      "mode",
      "timeout",
      "value",
      "api.",
      "works",
      "asynchronously",
      "there",
      "guarantee",
      "concurrent",
      "jobs.",
      "delete",
      "add",
      "people",
      "organizational",
      "group",
      "data",
      "set",
      "organizationalgroup",
      "field",
      "relevant",
      "fields",
      "unexpected",
      "value.",
      "update",
      "tenant",
      "settings",
      "configuring",
      "time",
      "between",
      "steps",
      "replacing",
      "data.",
      "follow",
      "open",
      "postman",
      "click",
      "workbench",
      "new",
      "tab.",
      "change",
      "method",
      "put",
      "enter",
      "request",
      "url",
      "following",
      "format",
      "https",
      "rest",
      "common-settings",
      "setting",
      "key",
      "configures",
      "information",
      "four",
      "values",
      "valid",
      "none",
      "skip",
      "mode.",
      "fixed",
      "wait",
      "equal",
      "multiplied",
      "total",
      "amount",
      "relationships",
      "groups",
      "removed",
      "request.",
      "dynamical",
      "until",
      "all",
      "need",
      "replaced",
      "become",
      "empty",
      "reaches",
      "configured",
      "latter",
      "case",
      "manually",
      "identify",
      "records"
    ],
    "language": "en",
    "word_count": 104,
    "importance_score": 3.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "the execution order doesn't work correctly when you use the replace function in the manage persons api",
    "contentLower": "the execution order doesn't work correctly when you use the replace function in the manage persons api. cause the manage persons api works asynchronously and there's no guarantee for the execution order of concurrent jobs. using the replace function to delete and add people's organizational group data might set the organizationalgroup field and other relevant fields to an unexpected value. solution update the tenant settings by configuring the waiting time between steps for replacing organizational group data. to do this, follow these steps: configure the waiting mode open postman and click + in the workbench to open a new tab. change the method to put and enter the tenant settings api for the request url in the following format: https://<external access host>/rest/<tenant id>/common-settings/setting/<tenant settings key>?value=<tenant setting value> the tenant settings key replace_org_group_transaction_isolation_mode configures the waiting mode between steps for replacing persons' org",
    "keywordsLower": [
      "doesnt",
      "https://<external",
      "execution",
      "order",
      "doesn",
      "work",
      "correctly",
      "replace",
      "function",
      "manage",
      "persons",
      "api",
      "cause",
      "solution",
      "configure",
      "waiting",
      "mode",
      "timeout",
      "value",
      "api.",
      "works",
      "asynchronously",
      "there",
      "guarantee",
      "concurrent",
      "jobs.",
      "delete",
      "add",
      "people",
      "organizational",
      "group",
      "data",
      "set",
      "organizationalgroup",
      "field",
      "relevant",
      "fields",
      "unexpected",
      "value.",
      "update",
      "tenant",
      "settings",
      "configuring",
      "time",
      "between",
      "steps",
      "replacing",
      "data.",
      "follow",
      "open",
      "postman",
      "click",
      "workbench",
      "new",
      "tab.",
      "change",
      "method",
      "put",
      "enter",
      "request",
      "url",
      "following",
      "format",
      "https",
      "rest",
      "common-settings",
      "setting",
      "key",
      "configures",
      "information",
      "four",
      "values",
      "valid",
      "none",
      "skip",
      "mode.",
      "fixed",
      "wait",
      "equal",
      "multiplied",
      "total",
      "amount",
      "relationships",
      "groups",
      "removed",
      "request.",
      "dynamical",
      "until",
      "all",
      "need",
      "replaced",
      "become",
      "empty",
      "reaches",
      "configured",
      "latter",
      "case",
      "manually",
      "identify",
      "records"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "The comment does not show up in the email notification if you try to add a comment in the discussion before setting and saving an owner",
    "content": "When updating a record, if you try to add a comment in the discussion before setting and saving an owner, the comment doesn’t show up in the email notification. Instead, a \"Request has been assigned\" comment appears in the email notification. Cause Before setting and saving an owner, the system doesn’t know the recipient of the email notification and therefore can’t add the comment. Instead, the default \"Request has been assigned\" comment is put in the email notification. Solution Make sure an owner has been assigned to the record and click Save. Then, add your comment to the discussion.",
    "url": "tscommentdoesnotshowupwhenownerisnotsaved",
    "filename": "tscommentdoesnotshowupwhenownerisnotsaved",
    "headings": [
      "Cause",
      "Solution"
    ],
    "keywords": [
      "comment",
      "show",
      "email",
      "notification",
      "try",
      "add",
      "discussion",
      "before",
      "setting",
      "saving",
      "owner",
      "cause",
      "solution",
      "updating",
      "record",
      "doesn",
      "notification.",
      "instead",
      "request",
      "assigned",
      "appears",
      "system",
      "know",
      "recipient",
      "therefore",
      "comment.",
      "default",
      "put",
      "make",
      "sure",
      "click",
      "save.",
      "discussion."
    ],
    "language": "en",
    "word_count": 70,
    "importance_score": 1.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "the comment does not show up in the email notification if you try to add a comment in the discussion before setting and saving an owner",
    "contentLower": "when updating a record, if you try to add a comment in the discussion before setting and saving an owner, the comment doesn’t show up in the email notification. instead, a \"request has been assigned\" comment appears in the email notification. cause before setting and saving an owner, the system doesn’t know the recipient of the email notification and therefore can’t add the comment. instead, the default \"request has been assigned\" comment is put in the email notification. solution make sure an owner has been assigned to the record and click save. then, add your comment to the discussion.",
    "keywordsLower": [
      "comment",
      "show",
      "email",
      "notification",
      "try",
      "add",
      "discussion",
      "before",
      "setting",
      "saving",
      "owner",
      "cause",
      "solution",
      "updating",
      "record",
      "doesn",
      "notification.",
      "instead",
      "request",
      "assigned",
      "appears",
      "system",
      "know",
      "recipient",
      "therefore",
      "comment.",
      "default",
      "put",
      "make",
      "sure",
      "click",
      "save.",
      "discussion."
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "The service level agreements and operational level agreements do not appear on the Targets tab",
    "content": "A user can view the agreements on the Targets tab, however, he/she can’t view the target-type-related data. Cause The user doesn't have permission for Service Level Target. Solution Grant permission for Service Level Target to the user's role.",
    "url": "slaoladonotshow",
    "filename": "slaoladonotshow",
    "headings": [
      "Cause",
      "Solution"
    ],
    "keywords": [
      "service",
      "level",
      "agreements",
      "operational",
      "appear",
      "targets",
      "tab",
      "cause",
      "solution",
      "user",
      "view",
      "however",
      "target-type-related",
      "data.",
      "doesn",
      "permission",
      "target.",
      "grant",
      "target",
      "role."
    ],
    "language": "en",
    "word_count": 36,
    "importance_score": 1.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "the service level agreements and operational level agreements do not appear on the targets tab",
    "contentLower": "a user can view the agreements on the targets tab, however, he/she can’t view the target-type-related data. cause the user doesn't have permission for service level target. solution grant permission for service level target to the user's role.",
    "keywordsLower": [
      "service",
      "level",
      "agreements",
      "operational",
      "appear",
      "targets",
      "tab",
      "cause",
      "solution",
      "user",
      "view",
      "however",
      "target-type-related",
      "data.",
      "doesn",
      "permission",
      "target.",
      "grant",
      "target",
      "role."
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Support Request rules trigger email notifications when Service Request is submitted",
    "content": "Service Management has an out-of-the-box business rule in Studio under Request > Support > Log: Sends notification to Requested for and Requested by person using selected template if the request has no parent request and email integration is off. This rule is under Support (not Service), so the system sends notifications when a new support offering ticket is created, which is the expected behavior. However, the system also sends email notifications when a new service offering ticket is created. Cause In the current design, when a request is created, it enters the default process first. The Support process is the default process for the Request record type, as shown in the following figure. As a result, any business rules defined in the Log phase of the Support process will run even when the user selects a service offering when creating a request. Solution Add the following string to the condition of the rule: && (entity.RequestsOffering == null || entity.RequestsOffering.OfferingType =",
    "url": "supportrequestrulestriggeremailnotifications4servicerequest",
    "filename": "supportrequestrulestriggeremailnotifications4servicerequest",
    "headings": [
      "Cause",
      "Solution"
    ],
    "keywords": [
      "support",
      "request",
      "rules",
      "trigger",
      "email",
      "notifications",
      "service",
      "submitted",
      "cause",
      "solution",
      "management",
      "out-of-the-box",
      "business",
      "rule",
      "studio",
      "under",
      "log",
      "sends",
      "notification",
      "requested",
      "person",
      "selected",
      "template",
      "parent",
      "integration",
      "off.",
      "system",
      "new",
      "offering",
      "ticket",
      "created",
      "expected",
      "behavior.",
      "however",
      "created.",
      "current",
      "design",
      "enters",
      "default",
      "process",
      "first.",
      "record",
      "type",
      "shown",
      "following",
      "figure.",
      "result",
      "any",
      "defined",
      "phase",
      "run",
      "even",
      "user",
      "selects",
      "creating",
      "request.",
      "add",
      "string",
      "condition",
      "entity.requestsoffering",
      "null",
      "entity.requestsoffering.offeringtype",
      "supportoffering"
    ],
    "language": "en",
    "word_count": 101,
    "importance_score": 2.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "support request rules trigger email notifications when service request is submitted",
    "contentLower": "service management has an out-of-the-box business rule in studio under request > support > log: sends notification to requested for and requested by person using selected template if the request has no parent request and email integration is off. this rule is under support (not service), so the system sends notifications when a new support offering ticket is created, which is the expected behavior. however, the system also sends email notifications when a new service offering ticket is created. cause in the current design, when a request is created, it enters the default process first. the support process is the default process for the request record type, as shown in the following figure. as a result, any business rules defined in the log phase of the support process will run even when the user selects a service offering when creating a request. solution add the following string to the condition of the rule: && (entity.requestsoffering == null || entity.requestsoffering.offeringtype =",
    "keywordsLower": [
      "support",
      "request",
      "rules",
      "trigger",
      "email",
      "notifications",
      "service",
      "submitted",
      "cause",
      "solution",
      "management",
      "out-of-the-box",
      "business",
      "rule",
      "studio",
      "under",
      "log",
      "sends",
      "notification",
      "requested",
      "person",
      "selected",
      "template",
      "parent",
      "integration",
      "off.",
      "system",
      "new",
      "offering",
      "ticket",
      "created",
      "expected",
      "behavior.",
      "however",
      "created.",
      "current",
      "design",
      "enters",
      "default",
      "process",
      "first.",
      "record",
      "type",
      "shown",
      "following",
      "figure.",
      "result",
      "any",
      "defined",
      "phase",
      "run",
      "even",
      "user",
      "selects",
      "creating",
      "request.",
      "add",
      "string",
      "condition",
      "entity.requestsoffering",
      "null",
      "entity.requestsoffering.offeringtype",
      "supportoffering"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Saving PPO currency failed",
    "content": "You receive a \"Saving PPO currency failed” error message when you save an updated PPO currency value in Application Settings. Cause This issue occurs because the selected currency value isn't supported. Solution Make sure the selected currency value is supported. You can find the supported currency list below. Currency AFA ARS AUD ATS AZM BSD BHD BDT BEF BOB BAM BWP BRL BGN CAD XAF CLP CNY COP HRK DKK DEM EGP EEK EUR FJD FIM FRF GRD GTQ HKD HUF ISK INR IDR IQD IEP ITL JPY JOD KZT KES KWD LAK LVL LBP LTL LUF MKD MGA MGF MYR MXN MNT NPR NLG ILS TWD NZD NGN KPW NOK PKR PAB PGK PEN UYU PHP PLN PTE GBP RON RUB SAR RSD SGD SKK SIT SOS ZAR KRW ESP LKR SEK CHF SYP TZS THB TND TRY UAH AED USD VEB VND ZWD CZK UGX SHP MOP KGS DJF BTN GWP BBD ROL TMM GEL SBD MMK TJS CVE PYG CDF CUP UZS ZMK NAD SZL MXV SDG KYD SDD GHC LYD SCR GHS GIP CLF STD ADP JMD BGL BIF DZD MZN AWG MZM BZD BYR KHR CYP GYD BYB AFN SVC TTD HTG YER FKP MWK XCD RWF VUV MVR AZN WST SRG VEF KMF GNF MDL SRD MUR LRD BMD OMR NIO GMD MTL",
    "url": "savingppocurrency",
    "filename": "savingppocurrency",
    "headings": [
      "Cause",
      "Solution"
    ],
    "keywords": [
      "saving",
      "ppo",
      "currency",
      "failed",
      "cause",
      "solution",
      "receive",
      "error",
      "message",
      "save",
      "updated",
      "value",
      "application",
      "settings.",
      "issue",
      "occurs",
      "because",
      "selected",
      "isn",
      "supported.",
      "make",
      "sure",
      "find",
      "supported",
      "list",
      "below.",
      "afa",
      "ars",
      "aud",
      "ats",
      "azm",
      "bsd",
      "bhd",
      "bdt",
      "bef",
      "bob",
      "bam",
      "bwp",
      "brl",
      "bgn",
      "cad",
      "xaf",
      "clp",
      "cny",
      "cop",
      "hrk",
      "dkk",
      "dem",
      "egp",
      "eek",
      "eur",
      "fjd",
      "fim",
      "frf",
      "grd",
      "gtq",
      "hkd",
      "huf",
      "isk",
      "inr",
      "idr",
      "iqd",
      "iep",
      "itl",
      "jpy",
      "jod",
      "kzt",
      "kes",
      "kwd",
      "lak",
      "lvl",
      "lbp",
      "ltl",
      "luf",
      "mkd",
      "mga",
      "mgf",
      "myr",
      "mxn",
      "mnt",
      "npr",
      "nlg",
      "ils",
      "twd",
      "nzd",
      "ngn",
      "kpw",
      "nok",
      "pkr",
      "pab",
      "pgk",
      "pen",
      "uyu",
      "php",
      "pln",
      "pte",
      "gbp",
      "ron",
      "rub",
      "sar"
    ],
    "language": "en",
    "word_count": 211,
    "importance_score": 4.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "saving ppo currency failed",
    "contentLower": "you receive a \"saving ppo currency failed” error message when you save an updated ppo currency value in application settings. cause this issue occurs because the selected currency value isn't supported. solution make sure the selected currency value is supported. you can find the supported currency list below. currency afa ars aud ats azm bsd bhd bdt bef bob bam bwp brl bgn cad xaf clp cny cop hrk dkk dem egp eek eur fjd fim frf grd gtq hkd huf isk inr idr iqd iep itl jpy jod kzt kes kwd lak lvl lbp ltl luf mkd mga mgf myr mxn mnt npr nlg ils twd nzd ngn kpw nok pkr pab pgk pen uyu php pln pte gbp ron rub sar rsd sgd skk sit sos zar krw esp lkr sek chf syp tzs thb tnd try uah aed usd veb vnd zwd czk ugx shp mop kgs djf btn gwp bbd rol tmm gel sbd mmk tjs cve pyg cdf cup uzs zmk nad szl mxv sdg kyd sdd ghc lyd scr ghs gip clf std adp jmd bgl bif dzd mzn awg mzm bzd byr khr cyp gyd byb afn svc ttd htg yer fkp mwk xcd rwf vuv mvr azn wst srg vef kmf gnf mdl srd mur lrd bmd omr nio gmd mtl",
    "keywordsLower": [
      "saving",
      "ppo",
      "currency",
      "failed",
      "cause",
      "solution",
      "receive",
      "error",
      "message",
      "save",
      "updated",
      "value",
      "application",
      "settings.",
      "issue",
      "occurs",
      "because",
      "selected",
      "isn",
      "supported.",
      "make",
      "sure",
      "find",
      "supported",
      "list",
      "below.",
      "afa",
      "ars",
      "aud",
      "ats",
      "azm",
      "bsd",
      "bhd",
      "bdt",
      "bef",
      "bob",
      "bam",
      "bwp",
      "brl",
      "bgn",
      "cad",
      "xaf",
      "clp",
      "cny",
      "cop",
      "hrk",
      "dkk",
      "dem",
      "egp",
      "eek",
      "eur",
      "fjd",
      "fim",
      "frf",
      "grd",
      "gtq",
      "hkd",
      "huf",
      "isk",
      "inr",
      "idr",
      "iqd",
      "iep",
      "itl",
      "jpy",
      "jod",
      "kzt",
      "kes",
      "kwd",
      "lak",
      "lvl",
      "lbp",
      "ltl",
      "luf",
      "mkd",
      "mga",
      "mgf",
      "myr",
      "mxn",
      "mnt",
      "npr",
      "nlg",
      "ils",
      "twd",
      "nzd",
      "ngn",
      "kpw",
      "nok",
      "pkr",
      "pab",
      "pgk",
      "pen",
      "uyu",
      "php",
      "pln",
      "pte",
      "gbp",
      "ron",
      "rub",
      "sar"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Troubleshoot Dev2Prod issues",
    "content": "This section provides troubleshooting information about using the Dev2Prod process: Dev2Prod - Offering rules aren't imported Dev2Prod - Task plan business rules of an offering bundle are skipped during import Dev2Prod - One or more customization definitions could not be imported Dev2Prod - an existing import job is still running Dev2Prod - Failed to get the entity link value Dev2Prod - Package size is too large",
    "url": "troubleshootdev2prod",
    "filename": "troubleshootdev2prod",
    "headings": [],
    "keywords": [
      "troubleshoot",
      "dev2prod",
      "issues",
      "section",
      "provides",
      "troubleshooting",
      "information",
      "about",
      "process",
      "offering",
      "rules",
      "aren",
      "imported",
      "task",
      "plan",
      "business",
      "bundle",
      "skipped",
      "during",
      "import",
      "one",
      "customization",
      "definitions",
      "existing",
      "job",
      "still",
      "running",
      "failed",
      "get",
      "entity",
      "link",
      "value",
      "package",
      "size",
      "too",
      "large"
    ],
    "language": "en",
    "word_count": 48,
    "importance_score": 2.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "troubleshoot dev2prod issues",
    "contentLower": "this section provides troubleshooting information about using the dev2prod process: dev2prod - offering rules aren't imported dev2prod - task plan business rules of an offering bundle are skipped during import dev2prod - one or more customization definitions could not be imported dev2prod - an existing import job is still running dev2prod - failed to get the entity link value dev2prod - package size is too large",
    "keywordsLower": [
      "troubleshoot",
      "dev2prod",
      "issues",
      "section",
      "provides",
      "troubleshooting",
      "information",
      "about",
      "process",
      "offering",
      "rules",
      "aren",
      "imported",
      "task",
      "plan",
      "business",
      "bundle",
      "skipped",
      "during",
      "import",
      "one",
      "customization",
      "definitions",
      "existing",
      "job",
      "still",
      "running",
      "failed",
      "get",
      "entity",
      "link",
      "value",
      "package",
      "size",
      "too",
      "large"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Troubleshoot OMT",
    "content": "For information about how to troubleshoot OMT, refer to the OMT documentation.",
    "url": "troubleshootcdf",
    "filename": "troubleshootcdf",
    "headings": [],
    "keywords": [
      "troubleshoot",
      "omt",
      "information",
      "about",
      "refer",
      "documentation."
    ],
    "language": "en",
    "word_count": 9,
    "importance_score": 2.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "troubleshoot omt",
    "contentLower": "for information about how to troubleshoot omt, refer to the omt documentation.",
    "keywordsLower": [
      "troubleshoot",
      "omt",
      "information",
      "about",
      "refer",
      "documentation."
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Troubleshoot Native SACM",
    "content": "This section provides the following troubleshooting topics: Some or all child CIs of NodeElement can’t be deleted timely by Native SACMClicking the Back button reloads the standard viewInvalid input for UD/UCMDBErrors occur running ScalableImportTableSeparationUpdateCrawlingStep during upgradeCreation of Device fails due to a ClusterResourceGroup Subtype valueAn error occurs when you try to enable Native SACMThe UCMDB default tenant can't be synchronized to Service Management as a data domainCIs do not appear in Service Management when UCMDB multi-tenancy is enabledError message \"CMS connection Invalid URL or port\"The transcation_context table keeps growingFederation between SMA OS type and UCMDB OsFamilyHow to change log levelSMA loggingNo CIs displayed in a grid in Service ManagementThe list of UCMDB attributes is empty in StudioNewly created attributes in UD/UCMDB aren't exposed to SMA StudioCannot create several services with the same name with Native SACMServices and CIs are no lo",
    "url": "troubleshootnativesacm",
    "filename": "troubleshootnativesacm",
    "headings": [],
    "keywords": [
      "troubleshoot",
      "native",
      "sacm",
      "section",
      "provides",
      "following",
      "troubleshooting",
      "topics",
      "all",
      "child",
      "cis",
      "nodeelement",
      "deleted",
      "timely",
      "sacmclicking",
      "back",
      "button",
      "reloads",
      "standard",
      "viewinvalid",
      "input",
      "ud",
      "ucmdberrors",
      "occur",
      "running",
      "scalableimporttableseparationupdatecrawlingstep",
      "during",
      "upgradecreation",
      "device",
      "fails",
      "due",
      "clusterresourcegroup",
      "subtype",
      "valuean",
      "error",
      "occurs",
      "try",
      "enable",
      "sacmthe",
      "ucmdb",
      "default",
      "tenant",
      "synchronized",
      "service",
      "management",
      "data",
      "domaincis",
      "appear",
      "multi-tenancy",
      "enablederror",
      "message",
      "cms",
      "connection",
      "invalid",
      "url",
      "port",
      "table",
      "keeps",
      "growingfederation",
      "between",
      "sma",
      "os",
      "type",
      "osfamilyhow",
      "change",
      "log",
      "levelsma",
      "loggingno",
      "displayed",
      "grid",
      "managementthe",
      "list",
      "attributes",
      "empty",
      "studionewly",
      "created",
      "aren",
      "exposed",
      "studiocannot",
      "create",
      "several",
      "services",
      "same",
      "name",
      "sacmservices",
      "longer",
      "federatedthe",
      "current",
      "count",
      "total",
      "items",
      "shown",
      "bottom",
      "rows",
      "emptyhaving",
      "multiple",
      "offline",
      "pods",
      "results",
      "duplicated"
    ],
    "language": "en",
    "word_count": 105,
    "importance_score": 3.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "troubleshoot native sacm",
    "contentLower": "this section provides the following troubleshooting topics: some or all child cis of nodeelement can’t be deleted timely by native sacmclicking the back button reloads the standard viewinvalid input for ud/ucmdberrors occur running scalableimporttableseparationupdatecrawlingstep during upgradecreation of device fails due to a clusterresourcegroup subtype valuean error occurs when you try to enable native sacmthe ucmdb default tenant can't be synchronized to service management as a data domaincis do not appear in service management when ucmdb multi-tenancy is enablederror message \"cms connection invalid url or port\"the transcation_context table keeps growingfederation between sma os type and ucmdb osfamilyhow to change log levelsma loggingno cis displayed in a grid in service managementthe list of ucmdb attributes is empty in studionewly created attributes in ud/ucmdb aren't exposed to sma studiocannot create several services with the same name with native sacmservices and cis are no lo",
    "keywordsLower": [
      "troubleshoot",
      "native",
      "sacm",
      "section",
      "provides",
      "following",
      "troubleshooting",
      "topics",
      "all",
      "child",
      "cis",
      "nodeelement",
      "deleted",
      "timely",
      "sacmclicking",
      "back",
      "button",
      "reloads",
      "standard",
      "viewinvalid",
      "input",
      "ud",
      "ucmdberrors",
      "occur",
      "running",
      "scalableimporttableseparationupdatecrawlingstep",
      "during",
      "upgradecreation",
      "device",
      "fails",
      "due",
      "clusterresourcegroup",
      "subtype",
      "valuean",
      "error",
      "occurs",
      "try",
      "enable",
      "sacmthe",
      "ucmdb",
      "default",
      "tenant",
      "synchronized",
      "service",
      "management",
      "data",
      "domaincis",
      "appear",
      "multi-tenancy",
      "enablederror",
      "message",
      "cms",
      "connection",
      "invalid",
      "url",
      "port",
      "table",
      "keeps",
      "growingfederation",
      "between",
      "sma",
      "os",
      "type",
      "osfamilyhow",
      "change",
      "log",
      "levelsma",
      "loggingno",
      "displayed",
      "grid",
      "managementthe",
      "list",
      "attributes",
      "empty",
      "studionewly",
      "created",
      "aren",
      "exposed",
      "studiocannot",
      "create",
      "several",
      "services",
      "same",
      "name",
      "sacmservices",
      "longer",
      "federatedthe",
      "current",
      "count",
      "total",
      "items",
      "shown",
      "bottom",
      "rows",
      "emptyhaving",
      "multiple",
      "offline",
      "pods",
      "results",
      "duplicated"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Some or all child CIs of NodeElement can’t be deleted timely by Native SACM",
    "content": "After you enable the Native SACM CI aging feature, some or all child CIs of NodeElement can’t be deleted timely. Cause If the metaphase default value of NodeElement child CIs other than Cpu, DiskDevice, FileSystem, and Interface have been wrongly configured (they should be left empty), they may not be deleted by Native SACM in a timely manner. Resolution To resolve this issue, exclude these CIs in the enhanced CI lifecycle solution: Go to UCMDB UI > Home > CI type manager > Node Element > QUALIFIERS. Check CIT_NOT_APPLICABLE_TO_LIFECYCLE, toggle Apply qualifier changes to Child Type (s), and then click Save. Wait a few minutes until a green message pops up \"Successfully applied [node_element] qualifier changes to its child types.\" Search for CI type VMware Host Resource, if the CIT_NOT_APPLICABLE_TO_LIFECYCLE box is checked, the process is completed. Search for CI types Cpu, DiskDevice, FileSystem, and Interface, uncheck CIT_NOT_APPLICABLE_TO_LIFECYCLE, and then click Save.",
    "url": "childcisnodeelementcantbedeleted",
    "filename": "childcisnodeelementcantbedeleted",
    "headings": [
      "Cause",
      "Resolution"
    ],
    "keywords": [
      "cant",
      "all",
      "child",
      "cis",
      "nodeelement",
      "deleted",
      "timely",
      "native",
      "sacm",
      "cause",
      "resolution",
      "after",
      "enable",
      "ci",
      "aging",
      "feature",
      "timely.",
      "metaphase",
      "default",
      "value",
      "cpu",
      "diskdevice",
      "filesystem",
      "interface",
      "wrongly",
      "configured",
      "left",
      "empty",
      "manner.",
      "resolve",
      "issue",
      "exclude",
      "enhanced",
      "lifecycle",
      "solution",
      "go",
      "ucmdb",
      "ui",
      "home",
      "type",
      "manager",
      "node",
      "element",
      "qualifiers.",
      "check",
      "toggle",
      "apply",
      "qualifier",
      "changes",
      "click",
      "save.",
      "wait",
      "few",
      "minutes",
      "until",
      "green",
      "message",
      "pops",
      "successfully",
      "applied",
      "types.",
      "search",
      "vmware",
      "host",
      "resource",
      "box",
      "checked",
      "process",
      "completed.",
      "types",
      "uncheck"
    ],
    "language": "en",
    "word_count": 109,
    "importance_score": 2.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "some or all child cis of nodeelement can’t be deleted timely by native sacm",
    "contentLower": "after you enable the native sacm ci aging feature, some or all child cis of nodeelement can’t be deleted timely. cause if the metaphase default value of nodeelement child cis other than cpu, diskdevice, filesystem, and interface have been wrongly configured (they should be left empty), they may not be deleted by native sacm in a timely manner. resolution to resolve this issue, exclude these cis in the enhanced ci lifecycle solution: go to ucmdb ui > home > ci type manager > node element > qualifiers. check cit_not_applicable_to_lifecycle, toggle apply qualifier changes to child type (s), and then click save. wait a few minutes until a green message pops up \"successfully applied [node_element] qualifier changes to its child types.\" search for ci type vmware host resource, if the cit_not_applicable_to_lifecycle box is checked, the process is completed. search for ci types cpu, diskdevice, filesystem, and interface, uncheck cit_not_applicable_to_lifecycle, and then click save.",
    "keywordsLower": [
      "cant",
      "all",
      "child",
      "cis",
      "nodeelement",
      "deleted",
      "timely",
      "native",
      "sacm",
      "cause",
      "resolution",
      "after",
      "enable",
      "ci",
      "aging",
      "feature",
      "timely.",
      "metaphase",
      "default",
      "value",
      "cpu",
      "diskdevice",
      "filesystem",
      "interface",
      "wrongly",
      "configured",
      "left",
      "empty",
      "manner.",
      "resolve",
      "issue",
      "exclude",
      "enhanced",
      "lifecycle",
      "solution",
      "go",
      "ucmdb",
      "ui",
      "home",
      "type",
      "manager",
      "node",
      "element",
      "qualifiers.",
      "check",
      "toggle",
      "apply",
      "qualifier",
      "changes",
      "click",
      "save.",
      "wait",
      "few",
      "minutes",
      "until",
      "green",
      "message",
      "pops",
      "successfully",
      "applied",
      "types.",
      "search",
      "vmware",
      "host",
      "resource",
      "box",
      "checked",
      "process",
      "completed.",
      "types",
      "uncheck"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "The UCMDB default tenant can't be synchronized to Service Management as a data domain",
    "content": "When you enabled UCMDB Multi-Tenancy, if you did not set the default tenant name following the naming convention as described in Enable UCMDB Multi-Tenancy, the default tenant can't be synchronized to Service Management as a data domain. Even if you correct the tenant name through the UCMDB Local Client later, it does not solve the problem. Cause Updating the tenant name through the UCMDB Local Client does not change the internal name which is used for data domain synchronization. Solution Follow these steps to fix the problem: In the UCMDB Local Client, create a new tenant with a name that complies with the Service Management data domain naming convention. Log in to the UCMDB JMX Console of the Consumer customer. Locate the setTenantAsDefault method. This method is used to change the default tenant. Enter the name of the new tenant and invoke the method. Alternatively, you may delete the old default tenant in the UCMDB Local Client.",
    "url": "tsnativesacmdefaulttenantcannotsync",
    "filename": "tsnativesacmdefaulttenantcannotsync",
    "headings": [
      "Cause",
      "Solution"
    ],
    "keywords": [
      "cant",
      "ucmdb",
      "default",
      "tenant",
      "synchronized",
      "service",
      "management",
      "data",
      "domain",
      "cause",
      "solution",
      "enabled",
      "multi-tenancy",
      "set",
      "name",
      "following",
      "naming",
      "convention",
      "described",
      "enable",
      "domain.",
      "even",
      "correct",
      "through",
      "local",
      "client",
      "later",
      "solve",
      "problem.",
      "updating",
      "change",
      "internal",
      "synchronization.",
      "follow",
      "steps",
      "fix",
      "problem",
      "create",
      "new",
      "complies",
      "convention.",
      "log",
      "jmx",
      "console",
      "consumer",
      "customer.",
      "locate",
      "settenantasdefault",
      "method.",
      "method",
      "tenant.",
      "enter",
      "invoke",
      "alternatively",
      "delete",
      "old",
      "client."
    ],
    "language": "en",
    "word_count": 102,
    "importance_score": 2.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "the ucmdb default tenant can't be synchronized to service management as a data domain",
    "contentLower": "when you enabled ucmdb multi-tenancy, if you did not set the default tenant name following the naming convention as described in enable ucmdb multi-tenancy, the default tenant can't be synchronized to service management as a data domain. even if you correct the tenant name through the ucmdb local client later, it does not solve the problem. cause updating the tenant name through the ucmdb local client does not change the internal name which is used for data domain synchronization. solution follow these steps to fix the problem: in the ucmdb local client, create a new tenant with a name that complies with the service management data domain naming convention. log in to the ucmdb jmx console of the consumer customer. locate the settenantasdefault method. this method is used to change the default tenant. enter the name of the new tenant and invoke the method. alternatively, you may delete the old default tenant in the ucmdb local client.",
    "keywordsLower": [
      "cant",
      "ucmdb",
      "default",
      "tenant",
      "synchronized",
      "service",
      "management",
      "data",
      "domain",
      "cause",
      "solution",
      "enabled",
      "multi-tenancy",
      "set",
      "name",
      "following",
      "naming",
      "convention",
      "described",
      "enable",
      "domain.",
      "even",
      "correct",
      "through",
      "local",
      "client",
      "later",
      "solve",
      "problem.",
      "updating",
      "change",
      "internal",
      "synchronization.",
      "follow",
      "steps",
      "fix",
      "problem",
      "create",
      "new",
      "complies",
      "convention.",
      "log",
      "jmx",
      "console",
      "consumer",
      "customer.",
      "locate",
      "settenantasdefault",
      "method.",
      "method",
      "tenant.",
      "enter",
      "invoke",
      "alternatively",
      "delete",
      "old",
      "client."
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "The transaction_context table keeps growing",
    "content": "When Native SACM is enabled, the transaction_context table keeps growing. Cause CMS sends SMA notifications of non-federated fields' changes, which causes a lot of transactions to be recorded in the transaction_context table. Workaround If the transaction_context table grows rapidly, run the following SQL statement to clear the table. delete from transaction_context_<tenantID> where retry_count=2 and (transaction_timestamp + interval '1 days') <= (SELECT min(last_taken) from transaction_etl_job_<tenantID> where job_name not in('History','Analytics')) Note: Make sure to replace the placeholder <tenantID> with the actual tenant ID.",
    "url": "tstransactiontable",
    "filename": "tstransactiontable",
    "headings": [
      "Cause",
      "Workaround"
    ],
    "keywords": [
      "transaction_context",
      "table",
      "keeps",
      "growing",
      "cause",
      "workaround",
      "native",
      "sacm",
      "enabled",
      "growing.",
      "cms",
      "sends",
      "sma",
      "notifications",
      "non-federated",
      "fields",
      "changes",
      "causes",
      "lot",
      "transactions",
      "recorded",
      "table.",
      "grows",
      "rapidly",
      "run",
      "following",
      "sql",
      "statement",
      "clear",
      "delete",
      "interval",
      "days",
      "history",
      "analytics",
      "note",
      "make",
      "sure",
      "replace",
      "placeholder",
      "actual",
      "tenant",
      "id."
    ],
    "language": "en",
    "word_count": 55,
    "importance_score": 3.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "the transaction_context table keeps growing",
    "contentLower": "when native sacm is enabled, the transaction_context table keeps growing. cause cms sends sma notifications of non-federated fields' changes, which causes a lot of transactions to be recorded in the transaction_context table. workaround if the transaction_context table grows rapidly, run the following sql statement to clear the table. delete from transaction_context_<tenantid> where retry_count=2 and (transaction_timestamp + interval '1 days') <= (select min(last_taken) from transaction_etl_job_<tenantid> where job_name not in('history','analytics')) note: make sure to replace the placeholder <tenantid> with the actual tenant id.",
    "keywordsLower": [
      "transaction_context",
      "table",
      "keeps",
      "growing",
      "cause",
      "workaround",
      "native",
      "sacm",
      "enabled",
      "growing.",
      "cms",
      "sends",
      "sma",
      "notifications",
      "non-federated",
      "fields",
      "changes",
      "causes",
      "lot",
      "transactions",
      "recorded",
      "table.",
      "grows",
      "rapidly",
      "run",
      "following",
      "sql",
      "statement",
      "clear",
      "delete",
      "interval",
      "days",
      "history",
      "analytics",
      "note",
      "make",
      "sure",
      "replace",
      "placeholder",
      "actual",
      "tenant",
      "id."
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "SMA logging",
    "content": "To see SMA logging regarding Native SACM, in the global logs directory, go to the folder itom-xruntime-platform-<pod id>. In this folder, there is the maas_cms-x.log file where the details are tracked.",
    "url": "smalogging",
    "filename": "smalogging",
    "headings": [],
    "keywords": [
      "x.log",
      "sma",
      "logging",
      "see",
      "regarding",
      "native",
      "sacm",
      "global",
      "logs",
      "directory",
      "go",
      "folder",
      "itom-xruntime-platform-.",
      "there",
      "file",
      "details",
      "tracked."
    ],
    "language": "en",
    "word_count": 20,
    "importance_score": 2.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "sma logging",
    "contentLower": "to see sma logging regarding native sacm, in the global logs directory, go to the folder itom-xruntime-platform-<pod id>. in this folder, there is the maas_cms-x.log file where the details are tracked.",
    "keywordsLower": [
      "x.log",
      "sma",
      "logging",
      "see",
      "regarding",
      "native",
      "sacm",
      "global",
      "logs",
      "directory",
      "go",
      "folder",
      "itom-xruntime-platform-.",
      "there",
      "file",
      "details",
      "tracked."
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "The list of UCMDB attributes is empty in Studio",
    "content": "The list of UCMDB attributes is empty in Studio. Solution Restart the UCMDB Gateway and refresh the screen in Service Management.",
    "url": "cmsattributesemptyinstudio",
    "filename": "cmsattributesemptyinstudio",
    "headings": [
      "Solution"
    ],
    "keywords": [
      "list",
      "ucmdb",
      "attributes",
      "empty",
      "studio",
      "solution",
      "studio.",
      "restart",
      "gateway",
      "refresh",
      "screen",
      "service",
      "management."
    ],
    "language": "en",
    "word_count": 18,
    "importance_score": 1.5,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "the list of ucmdb attributes is empty in studio",
    "contentLower": "the list of ucmdb attributes is empty in studio. solution restart the ucmdb gateway and refresh the screen in service management.",
    "keywordsLower": [
      "list",
      "ucmdb",
      "attributes",
      "empty",
      "studio",
      "solution",
      "studio.",
      "restart",
      "gateway",
      "refresh",
      "screen",
      "service",
      "management."
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Services and CIs are no longer federated",
    "content": "Services and CIs are no longer federated. Cause When Service Management can't connect to UCMDB for more than 2 hours, the WebSocket connections are closed. Workaround To restart the network connection, reset the UCMDB connection by running the following REST call with a Tenant Admin account. URL: http(s)://<hostname>/rest/<tenantId>/cmsx/reset Method: PUT Body: {} Note: Use your actual Service Management hostname and tenant ID to replace the placeholders.",
    "url": "servicescisnotfederated",
    "filename": "servicescisnotfederated",
    "headings": [
      "Cause",
      "Workaround"
    ],
    "keywords": [
      "services",
      "cis",
      "longer",
      "federated",
      "cause",
      "workaround",
      "federated.",
      "service",
      "management",
      "connect",
      "ucmdb",
      "hours",
      "websocket",
      "connections",
      "closed.",
      "restart",
      "network",
      "connection",
      "reset",
      "running",
      "following",
      "rest",
      "call",
      "tenant",
      "admin",
      "account.",
      "url",
      "http",
      "cmsx",
      "method",
      "put",
      "body",
      "note",
      "actual",
      "hostname",
      "id",
      "replace",
      "placeholders."
    ],
    "language": "en",
    "word_count": 51,
    "importance_score": 2.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "services and cis are no longer federated",
    "contentLower": "services and cis are no longer federated. cause when service management can't connect to ucmdb for more than 2 hours, the websocket connections are closed. workaround to restart the network connection, reset the ucmdb connection by running the following rest call with a tenant admin account. url: http(s)://<hostname>/rest/<tenantid>/cmsx/reset method: put body: {} note: use your actual service management hostname and tenant id to replace the placeholders.",
    "keywordsLower": [
      "services",
      "cis",
      "longer",
      "federated",
      "cause",
      "workaround",
      "federated.",
      "service",
      "management",
      "connect",
      "ucmdb",
      "hours",
      "websocket",
      "connections",
      "closed.",
      "restart",
      "network",
      "connection",
      "reset",
      "running",
      "following",
      "rest",
      "call",
      "tenant",
      "admin",
      "account.",
      "url",
      "http",
      "cmsx",
      "method",
      "put",
      "body",
      "note",
      "actual",
      "hostname",
      "id",
      "replace",
      "placeholders."
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "The current count of total Device items is shown at the bottom but all rows are empty",
    "content": "Symptom In the Devices grid, the current count of total items is shown at the bottom, however, all rows are empty. Cause The HTTP request headers with the Service Management token are removed from load balancers. The error.log of UCMDB Gateway reports the following error: api-gateway.GraphqlController authentication failed due to smax token is missing Error: authentication failed due to smax token is missing Solution Check if the \"underscores_in_headers on\" setting is correctly configured in the load balancers. See Install containerized UD/UCMDB (on-premises).",
    "url": "tsnativesacmdevicesgrid",
    "filename": "tsnativesacmdevicesgrid",
    "headings": [
      "Symptom",
      "Cause",
      "Solution"
    ],
    "keywords": [
      "error.log",
      "current",
      "count",
      "total",
      "device",
      "items",
      "shown",
      "bottom",
      "all",
      "rows",
      "empty",
      "symptom",
      "cause",
      "solution",
      "devices",
      "grid",
      "however",
      "empty.",
      "http",
      "request",
      "headers",
      "service",
      "management",
      "token",
      "removed",
      "load",
      "balancers.",
      "ucmdb",
      "gateway",
      "reports",
      "following",
      "error",
      "api-gateway.graphqlcontroller",
      "authentication",
      "failed",
      "due",
      "smax",
      "missing",
      "check",
      "setting",
      "correctly",
      "configured",
      "see",
      "install",
      "containerized",
      "ud",
      "on-premises"
    ],
    "language": "en",
    "word_count": 67,
    "importance_score": 1.5,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "the current count of total device items is shown at the bottom but all rows are empty",
    "contentLower": "symptom in the devices grid, the current count of total items is shown at the bottom, however, all rows are empty. cause the http request headers with the service management token are removed from load balancers. the error.log of ucmdb gateway reports the following error: api-gateway.graphqlcontroller authentication failed due to smax token is missing error: authentication failed due to smax token is missing solution check if the \"underscores_in_headers on\" setting is correctly configured in the load balancers. see install containerized ud/ucmdb (on-premises).",
    "keywordsLower": [
      "error.log",
      "current",
      "count",
      "total",
      "device",
      "items",
      "shown",
      "bottom",
      "all",
      "rows",
      "empty",
      "symptom",
      "cause",
      "solution",
      "devices",
      "grid",
      "however",
      "empty.",
      "http",
      "request",
      "headers",
      "service",
      "management",
      "token",
      "removed",
      "load",
      "balancers.",
      "ucmdb",
      "gateway",
      "reports",
      "following",
      "error",
      "api-gateway.graphqlcontroller",
      "authentication",
      "failed",
      "due",
      "smax",
      "missing",
      "check",
      "setting",
      "correctly",
      "configured",
      "see",
      "install",
      "containerized",
      "ud",
      "on-premises"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "SACM configuration error",
    "content": "When trying to edit the SACM configuration on Service Management, the following error occurs: \"Cannot invoke \"com.hp.maas.platform.tenantsettings.api.TenantSettingsData.getValue()\" because the return value of \"com.hp.maas.platform.tenantsettings.api.TenantSettingsEtagSupportRWCache.getTenantSetting(String)\" is null. Cause This may be due to the Redis cache that fails. Solution You must restart the Service Management suite. For more details, see the Restart the suite page.",
    "url": "sacmconfigerror",
    "filename": "sacmconfigerror",
    "headings": [
      "Cause",
      "Solution"
    ],
    "keywords": [
      "tenantsettings.api",
      "com.hp",
      "sacm",
      "configuration",
      "error",
      "cause",
      "solution",
      "trying",
      "edit",
      "service",
      "management",
      "following",
      "occurs",
      "cannot",
      "invoke",
      "com.hp.maas.platform.tenantsettings.api.tenantsettingsdata.getvalue",
      "because",
      "return",
      "value",
      "com.hp.maas.platform.tenantsettings.api.tenantsettingsetagsupportrwcache.gettenantsetting",
      "string",
      "null.",
      "due",
      "redis",
      "cache",
      "fails.",
      "restart",
      "suite.",
      "details",
      "see",
      "suite",
      "page."
    ],
    "language": "en",
    "word_count": 36,
    "importance_score": 3.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "sacm configuration error",
    "contentLower": "when trying to edit the sacm configuration on service management, the following error occurs: \"cannot invoke \"com.hp.maas.platform.tenantsettings.api.tenantsettingsdata.getvalue()\" because the return value of \"com.hp.maas.platform.tenantsettings.api.tenantsettingsetagsupportrwcache.gettenantsetting(string)\" is null. cause this may be due to the redis cache that fails. solution you must restart the service management suite. for more details, see the restart the suite page.",
    "keywordsLower": [
      "tenantsettings.api",
      "com.hp",
      "sacm",
      "configuration",
      "error",
      "cause",
      "solution",
      "trying",
      "edit",
      "service",
      "management",
      "following",
      "occurs",
      "cannot",
      "invoke",
      "com.hp.maas.platform.tenantsettings.api.tenantsettingsdata.getvalue",
      "because",
      "return",
      "value",
      "com.hp.maas.platform.tenantsettings.api.tenantsettingsetagsupportrwcache.gettenantsetting",
      "string",
      "null.",
      "due",
      "redis",
      "cache",
      "fails.",
      "restart",
      "suite.",
      "details",
      "see",
      "suite",
      "page."
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Troubleshoot SAM",
    "content": "This section describes the related logs you can use when troubleshooting SAM. On the NFS server, check <logging-volume>/sam/ (for example, /var/vols/itom/itsma/global-volume/logs/sam/). In this location, there’re several folders dependent on the SAM components that are running. You can check the key logs inside these folders to look at when SAM isn’t working properly, as shown in the following table. Folder Log Issue type Backend full_adapter.log Product synchronization issue full_calc.log Compliance calculation issue full.log Database issue; OOTB data import issue UI samui.log System login issue; Permission issue Init full.log System startup issue Upgrade full.log System upgrade issue There’re also a couple of folders to investigate when troubleshooting compliance calculations inside /SAM/Backend/<TenantID>: adapter compliance Inside these folders are the results that SAM produced using the information stored in UCMDB and Service Management based on the license rules applied to the pr",
    "url": "troubleshootsam",
    "filename": "troubleshootsam",
    "headings": [],
    "keywords": [
      "full.log",
      "full_calc.log",
      "full_adapter.log",
      "samui.log",
      "troubleshoot",
      "sam",
      "section",
      "describes",
      "related",
      "logs",
      "troubleshooting",
      "sam.",
      "nfs",
      "server",
      "check",
      "example",
      "var",
      "vols",
      "itom",
      "itsma",
      "global-volume",
      "location",
      "there",
      "re",
      "several",
      "folders",
      "dependent",
      "components",
      "running.",
      "key",
      "inside",
      "look",
      "isn",
      "working",
      "properly",
      "shown",
      "following",
      "table.",
      "folder",
      "log",
      "issue",
      "type",
      "backend",
      "product",
      "synchronization",
      "compliance",
      "calculation",
      "database",
      "ootb",
      "data",
      "import",
      "ui",
      "system",
      "login",
      "permission",
      "init",
      "startup",
      "upgrade",
      "couple",
      "investigate",
      "calculations",
      "adapter",
      "results",
      "produced",
      "information",
      "stored",
      "ucmdb",
      "service",
      "management",
      "based",
      "license",
      "rules",
      "applied",
      "products",
      "report",
      "didn",
      "produce",
      "expected",
      "certain",
      "good",
      "help",
      "understand",
      "why.",
      "specific",
      "topics",
      "include",
      "access",
      "directly",
      "oo",
      "audit",
      "page",
      "view",
      "deployment",
      "vrealize",
      "oracle",
      "fail",
      "design",
      "reports",
      "connection",
      "test"
    ],
    "language": "en",
    "word_count": 108,
    "importance_score": 3.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "troubleshoot sam",
    "contentLower": "this section describes the related logs you can use when troubleshooting sam. on the nfs server, check <logging-volume>/sam/ (for example, /var/vols/itom/itsma/global-volume/logs/sam/). in this location, there’re several folders dependent on the sam components that are running. you can check the key logs inside these folders to look at when sam isn’t working properly, as shown in the following table. folder log issue type backend full_adapter.log product synchronization issue full_calc.log compliance calculation issue full.log database issue; ootb data import issue ui samui.log system login issue; permission issue init full.log system startup issue upgrade full.log system upgrade issue there’re also a couple of folders to investigate when troubleshooting compliance calculations inside /sam/backend/<tenantid>: adapter compliance inside these folders are the results that sam produced using the information stored in ucmdb and service management based on the license rules applied to the pr",
    "keywordsLower": [
      "full.log",
      "full_calc.log",
      "full_adapter.log",
      "samui.log",
      "troubleshoot",
      "sam",
      "section",
      "describes",
      "related",
      "logs",
      "troubleshooting",
      "sam.",
      "nfs",
      "server",
      "check",
      "example",
      "var",
      "vols",
      "itom",
      "itsma",
      "global-volume",
      "location",
      "there",
      "re",
      "several",
      "folders",
      "dependent",
      "components",
      "running.",
      "key",
      "inside",
      "look",
      "isn",
      "working",
      "properly",
      "shown",
      "following",
      "table.",
      "folder",
      "log",
      "issue",
      "type",
      "backend",
      "product",
      "synchronization",
      "compliance",
      "calculation",
      "database",
      "ootb",
      "data",
      "import",
      "ui",
      "system",
      "login",
      "permission",
      "init",
      "startup",
      "upgrade",
      "couple",
      "investigate",
      "calculations",
      "adapter",
      "results",
      "produced",
      "information",
      "stored",
      "ucmdb",
      "service",
      "management",
      "based",
      "license",
      "rules",
      "applied",
      "products",
      "report",
      "didn",
      "produce",
      "expected",
      "certain",
      "good",
      "help",
      "understand",
      "why.",
      "specific",
      "topics",
      "include",
      "access",
      "directly",
      "oo",
      "audit",
      "page",
      "view",
      "deployment",
      "vrealize",
      "oracle",
      "fail",
      "design",
      "reports",
      "connection",
      "test"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "SAM connection test fails on the agent interface",
    "content": "SAM connection test fails on the agent UI. Cause Possible causes for this issue include: The UCMDB Gateway certificate hasn't been imported into Service Management. The firewall setting is wrong and the inbound connection from the Service Management server fails. Solution 1 If the issue occurred due to incorrect certificate import, follow the instructions about certificate import in Install UD/UCMDB for SAM. Solution 2 If the issue occurred due to wrong firewall settings, set a firewall rule that allows inbound connection from the Service Management server for the UCMDB Gateway port on the UCMDB Gateway server.",
    "url": "tsconnectionfails",
    "filename": "tsconnectionfails",
    "headings": [
      "Cause",
      "Solution 1",
      "Solution 2"
    ],
    "keywords": [
      "sam",
      "connection",
      "test",
      "fails",
      "agent",
      "interface",
      "cause",
      "solution",
      "ui.",
      "possible",
      "causes",
      "issue",
      "include",
      "ucmdb",
      "gateway",
      "certificate",
      "hasn",
      "imported",
      "service",
      "management.",
      "firewall",
      "setting",
      "wrong",
      "inbound",
      "management",
      "server",
      "fails.",
      "occurred",
      "due",
      "incorrect",
      "import",
      "follow",
      "instructions",
      "about",
      "install",
      "ud",
      "sam.",
      "settings",
      "set",
      "rule",
      "allows",
      "port",
      "server."
    ],
    "language": "en",
    "word_count": 74,
    "importance_score": 2.5,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "sam connection test fails on the agent interface",
    "contentLower": "sam connection test fails on the agent ui. cause possible causes for this issue include: the ucmdb gateway certificate hasn't been imported into service management. the firewall setting is wrong and the inbound connection from the service management server fails. solution 1 if the issue occurred due to incorrect certificate import, follow the instructions about certificate import in install ud/ucmdb for sam. solution 2 if the issue occurred due to wrong firewall settings, set a firewall rule that allows inbound connection from the service management server for the ucmdb gateway port on the ucmdb gateway server.",
    "keywordsLower": [
      "sam",
      "connection",
      "test",
      "fails",
      "agent",
      "interface",
      "cause",
      "solution",
      "ui.",
      "possible",
      "causes",
      "issue",
      "include",
      "ucmdb",
      "gateway",
      "certificate",
      "hasn",
      "imported",
      "service",
      "management.",
      "firewall",
      "setting",
      "wrong",
      "inbound",
      "management",
      "server",
      "fails.",
      "occurred",
      "due",
      "incorrect",
      "import",
      "follow",
      "instructions",
      "about",
      "install",
      "ud",
      "sam.",
      "settings",
      "set",
      "rule",
      "allows",
      "port",
      "server."
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Troubleshoot UD/UCMDB",
    "content": "This section provides troubleshooting documentation links for classic and containerized UD/UCMDB. Classic UD/UCMDB See the Troubleshooting instructions for classic UD/UCMDB. Containerized UD/UCMDB See the Troubleshooting instructions for containerized UD/UCMDB. Note: To troubleshoot installation issues for containerized UD/UCMDB, see Troubleshoot installation. To find the log files for containerized UD/UCMDB, see Find UD/UCMDB log files.",
    "url": "troubleshootcms",
    "filename": "troubleshootcms",
    "headings": [
      "Classic UD/UCMDB",
      "Containerized UD/UCMDB"
    ],
    "keywords": [
      "uducmdb",
      "troubleshoot",
      "ud",
      "ucmdb",
      "classic",
      "containerized",
      "section",
      "provides",
      "troubleshooting",
      "documentation",
      "links",
      "ucmdb.",
      "see",
      "instructions",
      "note",
      "installation",
      "issues",
      "installation.",
      "find",
      "log",
      "files",
      "files."
    ],
    "language": "en",
    "word_count": 52,
    "importance_score": 3.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "troubleshoot ud/ucmdb",
    "contentLower": "this section provides troubleshooting documentation links for classic and containerized ud/ucmdb. classic ud/ucmdb see the troubleshooting instructions for classic ud/ucmdb. containerized ud/ucmdb see the troubleshooting instructions for containerized ud/ucmdb. note: to troubleshoot installation issues for containerized ud/ucmdb, see troubleshoot installation. to find the log files for containerized ud/ucmdb, see find ud/ucmdb log files.",
    "keywordsLower": [
      "uducmdb",
      "troubleshoot",
      "ud",
      "ucmdb",
      "classic",
      "containerized",
      "section",
      "provides",
      "troubleshooting",
      "documentation",
      "links",
      "ucmdb.",
      "see",
      "instructions",
      "note",
      "installation",
      "issues",
      "installation.",
      "find",
      "log",
      "files",
      "files."
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Troubleshoot Content Store",
    "content": "This section provides the following troubleshooting topics: Resource sync flow fails when DND account password has a special character Selected file is invalid or corrupted Installation aborted, as the content isn't digitally trusted and only digitally trusted contents are allowed to install Fatal error occurred Received a failure response from the server. Please check your permission details and retry Unable to import service design file Failed to import auxiliary file OO content pack import failure AWS Capsule fails to install after enabling DND",
    "url": "troubleshootcontentstore",
    "filename": "troubleshootcontentstore",
    "headings": [],
    "keywords": [
      "troubleshoot",
      "content",
      "store",
      "section",
      "provides",
      "following",
      "troubleshooting",
      "topics",
      "resource",
      "sync",
      "flow",
      "fails",
      "dnd",
      "account",
      "password",
      "special",
      "character",
      "selected",
      "file",
      "invalid",
      "corrupted",
      "installation",
      "aborted",
      "isn",
      "digitally",
      "trusted",
      "contents",
      "allowed",
      "install",
      "fatal",
      "error",
      "occurred",
      "received",
      "failure",
      "response",
      "server.",
      "please",
      "check",
      "permission",
      "details",
      "retry",
      "unable",
      "import",
      "service",
      "design",
      "failed",
      "auxiliary",
      "oo",
      "pack",
      "aws",
      "capsule",
      "after",
      "enabling"
    ],
    "language": "en",
    "word_count": 66,
    "importance_score": 2.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "troubleshoot content store",
    "contentLower": "this section provides the following troubleshooting topics: resource sync flow fails when dnd account password has a special character selected file is invalid or corrupted installation aborted, as the content isn't digitally trusted and only digitally trusted contents are allowed to install fatal error occurred received a failure response from the server. please check your permission details and retry unable to import service design file failed to import auxiliary file oo content pack import failure aws capsule fails to install after enabling dnd",
    "keywordsLower": [
      "troubleshoot",
      "content",
      "store",
      "section",
      "provides",
      "following",
      "troubleshooting",
      "topics",
      "resource",
      "sync",
      "flow",
      "fails",
      "dnd",
      "account",
      "password",
      "special",
      "character",
      "selected",
      "file",
      "invalid",
      "corrupted",
      "installation",
      "aborted",
      "isn",
      "digitally",
      "trusted",
      "contents",
      "allowed",
      "install",
      "fatal",
      "error",
      "occurred",
      "received",
      "failure",
      "response",
      "server.",
      "please",
      "check",
      "permission",
      "details",
      "retry",
      "unable",
      "import",
      "service",
      "design",
      "failed",
      "auxiliary",
      "oo",
      "pack",
      "aws",
      "capsule",
      "after",
      "enabling"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Resource sync flow fails when DND account password has a special character",
    "content": "When you trigger resource sync, the flow fails. Cause This issue occurs when you set the DND account password with a \"/\" in it. During content installation, the OO system account property CSA_REST_CREDENTIALS doesn't get updated if the DND account password has a \"/\". This causes the resource sync flow to fail. Solution Manually update the DND account credentials in OO Central by following these steps: Log in to OO Central. Open the system account property CSA_REST_CREDENTIALS. Enter the DND account username and password. Save the changes. Trigger the resource sync flow.",
    "url": "resourcesyncfail",
    "filename": "resourcesyncfail",
    "headings": [
      "Cause",
      "Solution"
    ],
    "keywords": [
      "resource",
      "sync",
      "flow",
      "fails",
      "dnd",
      "account",
      "password",
      "special",
      "character",
      "cause",
      "solution",
      "trigger",
      "fails.",
      "issue",
      "occurs",
      "set",
      "it.",
      "during",
      "content",
      "installation",
      "oo",
      "system",
      "property",
      "doesn",
      "get",
      "updated",
      "causes",
      "fail.",
      "manually",
      "update",
      "credentials",
      "central",
      "following",
      "steps",
      "log",
      "central.",
      "open",
      "enter",
      "username",
      "password.",
      "save",
      "changes.",
      "flow."
    ],
    "language": "en",
    "word_count": 71,
    "importance_score": 1.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "resource sync flow fails when dnd account password has a special character",
    "contentLower": "when you trigger resource sync, the flow fails. cause this issue occurs when you set the dnd account password with a \"/\" in it. during content installation, the oo system account property csa_rest_credentials doesn't get updated if the dnd account password has a \"/\". this causes the resource sync flow to fail. solution manually update the dnd account credentials in oo central by following these steps: log in to oo central. open the system account property csa_rest_credentials. enter the dnd account username and password. save the changes. trigger the resource sync flow.",
    "keywordsLower": [
      "resource",
      "sync",
      "flow",
      "fails",
      "dnd",
      "account",
      "password",
      "special",
      "character",
      "cause",
      "solution",
      "trigger",
      "fails.",
      "issue",
      "occurs",
      "set",
      "it.",
      "during",
      "content",
      "installation",
      "oo",
      "system",
      "property",
      "doesn",
      "get",
      "updated",
      "causes",
      "fail.",
      "manually",
      "update",
      "credentials",
      "central",
      "following",
      "steps",
      "log",
      "central.",
      "open",
      "enter",
      "username",
      "password.",
      "save",
      "changes.",
      "flow."
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Selected file is invalid or corrupted",
    "content": "The capsule installation fails and you may come across any one of the following error messages: Selected file is invalid or corrupted, please select a valid content to install Selected file doesn't contain a valid content manifest, please select a valid content to install Causes The first error occurs if the selected capsule file isn't a zip file. The second occurs if the manifest file isn't present inside the capsule zip. Solution Select a valid capsule file to install.",
    "url": "invalidfile",
    "filename": "invalidfile",
    "headings": [
      "Causes",
      "Solution"
    ],
    "keywords": [
      "selected",
      "file",
      "invalid",
      "corrupted",
      "causes",
      "solution",
      "capsule",
      "installation",
      "fails",
      "come",
      "across",
      "any",
      "one",
      "following",
      "error",
      "messages",
      "please",
      "select",
      "valid",
      "content",
      "install",
      "doesn",
      "contain",
      "manifest",
      "first",
      "occurs",
      "isn",
      "zip",
      "file.",
      "second",
      "present",
      "inside",
      "zip.",
      "install."
    ],
    "language": "en",
    "word_count": 63,
    "importance_score": 2.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "selected file is invalid or corrupted",
    "contentLower": "the capsule installation fails and you may come across any one of the following error messages: selected file is invalid or corrupted, please select a valid content to install selected file doesn't contain a valid content manifest, please select a valid content to install causes the first error occurs if the selected capsule file isn't a zip file. the second occurs if the manifest file isn't present inside the capsule zip. solution select a valid capsule file to install.",
    "keywordsLower": [
      "selected",
      "file",
      "invalid",
      "corrupted",
      "causes",
      "solution",
      "capsule",
      "installation",
      "fails",
      "come",
      "across",
      "any",
      "one",
      "following",
      "error",
      "messages",
      "please",
      "select",
      "valid",
      "content",
      "install",
      "doesn",
      "contain",
      "manifest",
      "first",
      "occurs",
      "isn",
      "zip",
      "file.",
      "second",
      "present",
      "inside",
      "zip.",
      "install."
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Received a failure response from the server. Please check your permission details and retry",
    "content": "The following error message appears while performing an action. You do not have permission to perform this action Cause This issue occurs when you are logged in as a user that doesn't have permission to perform the action. Solution Log in as a user with the appropriate permission. Or, ask the administrator to give you the permission to perform the action.",
    "url": "nopermission",
    "filename": "nopermission",
    "headings": [
      "Cause",
      "Solution"
    ],
    "keywords": [
      "received",
      "failure",
      "response",
      "server.",
      "please",
      "check",
      "permission",
      "details",
      "retry",
      "cause",
      "solution",
      "following",
      "error",
      "message",
      "appears",
      "while",
      "performing",
      "action.",
      "perform",
      "action",
      "issue",
      "occurs",
      "logged",
      "user",
      "doesn",
      "log",
      "appropriate",
      "permission.",
      "ask",
      "administrator",
      "give"
    ],
    "language": "en",
    "word_count": 40,
    "importance_score": 1.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "received a failure response from the server. please check your permission details and retry",
    "contentLower": "the following error message appears while performing an action. you do not have permission to perform this action cause this issue occurs when you are logged in as a user that doesn't have permission to perform the action. solution log in as a user with the appropriate permission. or, ask the administrator to give you the permission to perform the action.",
    "keywordsLower": [
      "received",
      "failure",
      "response",
      "server.",
      "please",
      "check",
      "permission",
      "details",
      "retry",
      "cause",
      "solution",
      "following",
      "error",
      "message",
      "appears",
      "while",
      "performing",
      "action.",
      "perform",
      "action",
      "issue",
      "occurs",
      "logged",
      "user",
      "doesn",
      "log",
      "appropriate",
      "permission.",
      "ask",
      "administrator",
      "give"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "SMA Support Assistant",
    "content": "The SMA Support Assistant provides a more stable runtime platform for running SMA scripts in both managed Kubernetes and on-premises environments. The runtime platform provided by the Support Assistant is a container named itom-toolkit. The Support Assistant supports SMA maintenance tools available for download from the ITOM Marketplace, including the SMA Doctor and the SMA Operation Toolkit, as well as scripts in customer-signed packages. Additionally, considering some scripts (for example, the fqdn-replace.sh script in the SMA Operation Toolkit package) may require certificate files, the Support Assistant also allows you to upload certificate files. Before using the Support Assistant, be aware of the following: Scripts must be included in packages in tar, tgz, gz, or zip format, and a valid signature file must accompany each package. For example, SMA-nnnnn-nnnnnn.tar.gz and SMA-nnnnn-nnnnn.tar.gz.sig. For customer-signed packages, you must provide their signing key (.pub or .asc). Ce",
    "url": "tookitcontainer",
    "filename": "tookitcontainer",
    "headings": [
      "Install the runtime platform",
      "How to run scripts on the runtime platform",
      "Prepare scripts on the runtime platform",
      "Run scripts on the runtime platform",
      "Related topics"
    ],
    "keywords": [
      "nnnnnn.tar",
      "apply_custom_settings.sh",
      "nnnnn.tar",
      "gz.sig",
      "nnnn.nn",
      "install.sh",
      "action_reindex.py",
      "serviceaccount.yaml",
      "updateLocalRegistryInfo.sh",
      "updateSMAExternalDBInfo.sh",
      "podReScheduler.sh",
      "replace.sh",
      "changeIntegrationUserPwd.sh",
      "tar.gz",
      "sma",
      "support",
      "assistant",
      "install",
      "runtime",
      "platform",
      "run",
      "scripts",
      "prepare",
      "related",
      "topics",
      "provides",
      "stable",
      "running",
      "both",
      "managed",
      "kubernetes",
      "on-premises",
      "environments.",
      "provided",
      "container",
      "named",
      "itom-toolkit.",
      "supports",
      "maintenance",
      "tools",
      "available",
      "download",
      "itom",
      "marketplace",
      "including",
      "doctor",
      "operation",
      "toolkit",
      "well",
      "customer-signed",
      "packages.",
      "additionally",
      "considering",
      "example",
      "fqdn-replace.sh",
      "script",
      "package",
      "require",
      "certificate",
      "files",
      "allows",
      "upload",
      "files.",
      "before",
      "aware",
      "following",
      "included",
      "packages",
      "tar",
      "tgz",
      "gz",
      "zip",
      "format",
      "valid",
      "signature",
      "file",
      "accompany",
      "package.",
      "sma-nnnnn-nnnnnn.tar.gz",
      "sma-nnnnn-nnnnn.tar.gz.sig.",
      "provide",
      "signing",
      "key",
      ".pub",
      ".asc",
      "extension",
      ".cer",
      ".crt",
      ".pem",
      ".key.",
      "any",
      "unsupported",
      "automatically",
      "deleted",
      "tool.",
      "deployed",
      "openshift",
      "instructions",
      "doesn",
      "work"
    ],
    "language": "en",
    "word_count": 94,
    "importance_score": 5.5,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "sma support assistant",
    "contentLower": "the sma support assistant provides a more stable runtime platform for running sma scripts in both managed kubernetes and on-premises environments. the runtime platform provided by the support assistant is a container named itom-toolkit. the support assistant supports sma maintenance tools available for download from the itom marketplace, including the sma doctor and the sma operation toolkit, as well as scripts in customer-signed packages. additionally, considering some scripts (for example, the fqdn-replace.sh script in the sma operation toolkit package) may require certificate files, the support assistant also allows you to upload certificate files. before using the support assistant, be aware of the following: scripts must be included in packages in tar, tgz, gz, or zip format, and a valid signature file must accompany each package. for example, sma-nnnnn-nnnnnn.tar.gz and sma-nnnnn-nnnnn.tar.gz.sig. for customer-signed packages, you must provide their signing key (.pub or .asc). ce",
    "keywordsLower": [
      "nnnnnn.tar",
      "apply_custom_settings.sh",
      "nnnnn.tar",
      "gz.sig",
      "nnnn.nn",
      "install.sh",
      "action_reindex.py",
      "serviceaccount.yaml",
      "updatelocalregistryinfo.sh",
      "updatesmaexternaldbinfo.sh",
      "podrescheduler.sh",
      "replace.sh",
      "changeintegrationuserpwd.sh",
      "tar.gz",
      "sma",
      "support",
      "assistant",
      "install",
      "runtime",
      "platform",
      "run",
      "scripts",
      "prepare",
      "related",
      "topics",
      "provides",
      "stable",
      "running",
      "both",
      "managed",
      "kubernetes",
      "on-premises",
      "environments.",
      "provided",
      "container",
      "named",
      "itom-toolkit.",
      "supports",
      "maintenance",
      "tools",
      "available",
      "download",
      "itom",
      "marketplace",
      "including",
      "doctor",
      "operation",
      "toolkit",
      "well",
      "customer-signed",
      "packages.",
      "additionally",
      "considering",
      "example",
      "fqdn-replace.sh",
      "script",
      "package",
      "require",
      "certificate",
      "files",
      "allows",
      "upload",
      "files.",
      "before",
      "aware",
      "following",
      "included",
      "packages",
      "tar",
      "tgz",
      "gz",
      "zip",
      "format",
      "valid",
      "signature",
      "file",
      "accompany",
      "package.",
      "sma-nnnnn-nnnnnn.tar.gz",
      "sma-nnnnn-nnnnn.tar.gz.sig.",
      "provide",
      "signing",
      "key",
      ".pub",
      ".asc",
      "extension",
      ".cer",
      ".crt",
      ".pem",
      ".key.",
      "any",
      "unsupported",
      "automatically",
      "deleted",
      "tool.",
      "deployed",
      "openshift",
      "instructions",
      "doesn",
      "work"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "SMA Doctor doesn't work on OpenShift",
    "content": "The check_resource.py script in SMA Doctor doesn't work when SMA is deployed on OpenShift. Cause The check_resource.py script isn't compatible with oc (OpenShift commands). Solution Perform the following steps: Copy oc (OpenShift commands) from the VM on which OpenShift is installed to the NFS share folder <data-volume>/toolkit. An example of the folder is: /vols/itom/data-volume>/toolkit/. Change the ownership of this folder: chown -R <SYSTEM_USER_ID>:<SYSTEM_GROUP_ID> * Replace <SYSTEM_USER_ID> and <SYSTEM_GROUP_ID> with the values that you specify when configuring NFS volumes. The two values must be either 1999 (default) or a value between 100000 and 2000000000. Refer to Prepare scripts on the runtime platform to upload SMA Doctor to the SMA Support Assistant. Enter the container with the following command and find the check_resource.py script under the /toolkit/xdoctor/diagnostic-tool/check_resources folder: ​ kubectl exec -it $( kubectl get pods -n $( kubectl get ns |grep itsma | ",
    "url": "smadoctornotworkingonopenshift",
    "filename": "smadoctornotworkingonopenshift",
    "headings": [
      "Cause",
      "Solution"
    ],
    "keywords": [
      "doesnt",
      "check_resource.py",
      "sma",
      "doctor",
      "doesn",
      "work",
      "openshift",
      "cause",
      "solution",
      "script",
      "deployed",
      "openshift.",
      "isn",
      "compatible",
      "oc",
      "commands",
      "perform",
      "following",
      "steps",
      "copy",
      "vm",
      "installed",
      "nfs",
      "share",
      "folder",
      "toolkit.",
      "example",
      "vols",
      "itom",
      "data-volume",
      "toolkit",
      "change",
      "ownership",
      "chown",
      "-r",
      "replace",
      "values",
      "specify",
      "configuring",
      "volumes.",
      "two",
      "either",
      "1999",
      "default",
      "value",
      "between",
      "100000",
      "2000000000.",
      "refer",
      "prepare",
      "scripts",
      "runtime",
      "platform",
      "upload",
      "support",
      "assistant.",
      "enter",
      "container",
      "command",
      "find",
      "under",
      "xdoctor",
      "diagnostic-tool",
      "kubectl",
      "exec",
      "-it",
      "get",
      "pods",
      "-n",
      "ns",
      "grep",
      "itsma",
      "cut",
      "-f1",
      "-d",
      "itom-toolkit",
      "awk",
      "print",
      "head",
      "-1",
      "bash",
      "-c",
      "modify",
      "follows",
      "cache",
      "type",
      "list",
      "cmd",
      "top",
      "nodes",
      "--all-namespaces",
      "logs",
      "adm",
      "save",
      "changes."
    ],
    "language": "en",
    "word_count": 102,
    "importance_score": 3.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "sma doctor doesn't work on openshift",
    "contentLower": "the check_resource.py script in sma doctor doesn't work when sma is deployed on openshift. cause the check_resource.py script isn't compatible with oc (openshift commands). solution perform the following steps: copy oc (openshift commands) from the vm on which openshift is installed to the nfs share folder <data-volume>/toolkit. an example of the folder is: /vols/itom/data-volume>/toolkit/. change the ownership of this folder: chown -r <system_user_id>:<system_group_id> * replace <system_user_id> and <system_group_id> with the values that you specify when configuring nfs volumes. the two values must be either 1999 (default) or a value between 100000 and 2000000000. refer to prepare scripts on the runtime platform to upload sma doctor to the sma support assistant. enter the container with the following command and find the check_resource.py script under the /toolkit/xdoctor/diagnostic-tool/check_resources folder: ​ kubectl exec -it $( kubectl get pods -n $( kubectl get ns |grep itsma | ",
    "keywordsLower": [
      "doesnt",
      "check_resource.py",
      "sma",
      "doctor",
      "doesn",
      "work",
      "openshift",
      "cause",
      "solution",
      "script",
      "deployed",
      "openshift.",
      "isn",
      "compatible",
      "oc",
      "commands",
      "perform",
      "following",
      "steps",
      "copy",
      "vm",
      "installed",
      "nfs",
      "share",
      "folder",
      "toolkit.",
      "example",
      "vols",
      "itom",
      "data-volume",
      "toolkit",
      "change",
      "ownership",
      "chown",
      "-r",
      "replace",
      "values",
      "specify",
      "configuring",
      "volumes.",
      "two",
      "either",
      "1999",
      "default",
      "value",
      "between",
      "100000",
      "2000000000.",
      "refer",
      "prepare",
      "scripts",
      "runtime",
      "platform",
      "upload",
      "support",
      "assistant.",
      "enter",
      "container",
      "command",
      "find",
      "under",
      "xdoctor",
      "diagnostic-tool",
      "kubectl",
      "exec",
      "-it",
      "get",
      "pods",
      "-n",
      "ns",
      "grep",
      "itsma",
      "cut",
      "-f1",
      "-d",
      "itom-toolkit",
      "awk",
      "print",
      "head",
      "-1",
      "bash",
      "-c",
      "modify",
      "follows",
      "cache",
      "type",
      "list",
      "cmd",
      "top",
      "nodes",
      "--all-namespaces",
      "logs",
      "adm",
      "save",
      "changes."
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Troubleshoot Audit service",
    "content": "The section provides the following troubleshooting tips: Create Tenant in Audit API fails Audits related to login events aren't visible in the Audit UI Audit service isn't working for existing tenants",
    "url": "troubleshootaudit",
    "filename": "troubleshootaudit",
    "headings": [],
    "keywords": [
      "troubleshoot",
      "audit",
      "service",
      "section",
      "provides",
      "following",
      "troubleshooting",
      "tips",
      "create",
      "tenant",
      "api",
      "fails",
      "audits",
      "related",
      "login",
      "events",
      "aren",
      "visible",
      "ui",
      "isn",
      "working",
      "existing",
      "tenants"
    ],
    "language": "en",
    "word_count": 29,
    "importance_score": 2.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "troubleshoot audit service",
    "contentLower": "the section provides the following troubleshooting tips: create tenant in audit api fails audits related to login events aren't visible in the audit ui audit service isn't working for existing tenants",
    "keywordsLower": [
      "troubleshoot",
      "audit",
      "service",
      "section",
      "provides",
      "following",
      "troubleshooting",
      "tips",
      "create",
      "tenant",
      "api",
      "fails",
      "audits",
      "related",
      "login",
      "events",
      "aren",
      "visible",
      "ui",
      "isn",
      "working",
      "existing",
      "tenants"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Troubleshoot Aviator",
    "content": "This section helps you identify and resolve some issues that you might come across while using the Aviator capability.",
    "url": "troubleshootaviator",
    "filename": "troubleshootaviator",
    "headings": [],
    "keywords": [
      "troubleshoot",
      "aviator",
      "section",
      "helps",
      "identify",
      "resolve",
      "issues",
      "come",
      "across",
      "while",
      "capability."
    ],
    "language": "en",
    "word_count": 12,
    "importance_score": 2.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "troubleshoot aviator",
    "contentLower": "this section helps you identify and resolve some issues that you might come across while using the aviator capability.",
    "keywordsLower": [
      "troubleshoot",
      "aviator",
      "section",
      "helps",
      "identify",
      "resolve",
      "issues",
      "come",
      "across",
      "while",
      "capability."
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Troubleshoot license management",
    "content": "This section provides the following troubleshooting topic. Usage count for Cloud Management license is missing",
    "url": "troubleshootlicensemgmt",
    "filename": "troubleshootlicensemgmt",
    "headings": [],
    "keywords": [
      "troubleshoot",
      "license",
      "management",
      "section",
      "provides",
      "following",
      "troubleshooting",
      "topic.",
      "usage",
      "count",
      "cloud",
      "missing"
    ],
    "language": "en",
    "word_count": 14,
    "importance_score": 2.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "troubleshoot license management",
    "contentLower": "this section provides the following troubleshooting topic. usage count for cloud management license is missing",
    "keywordsLower": [
      "troubleshoot",
      "license",
      "management",
      "section",
      "provides",
      "following",
      "troubleshooting",
      "topic.",
      "usage",
      "count",
      "cloud",
      "missing"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Troubleshoot Inbox",
    "content": "This section provides the following troubleshooting topic: Inbox custom ENUM field mapping issue",
    "url": "troubleshootinbox",
    "filename": "troubleshootinbox",
    "headings": [],
    "keywords": [
      "troubleshoot",
      "inbox",
      "section",
      "provides",
      "following",
      "troubleshooting",
      "topic",
      "custom",
      "enum",
      "field",
      "mapping",
      "issue"
    ],
    "language": "en",
    "word_count": 13,
    "importance_score": 2.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "troubleshoot inbox",
    "contentLower": "this section provides the following troubleshooting topic: inbox custom enum field mapping issue",
    "keywordsLower": [
      "troubleshoot",
      "inbox",
      "section",
      "provides",
      "following",
      "troubleshooting",
      "topic",
      "custom",
      "enum",
      "field",
      "mapping",
      "issue"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "REST API queries",
    "content": "You can use the Entity Management Service (EMS) REST API to run a variety of queries to retrieve information from the system. For more information about the EMS REST API, see EMS REST API. You can use the REST API in connection with the Query Language. For a reference of Query Language operators and commands, see REST API collection query protocol. Retrieving related record properties The EMS REST API enables you to query for properties defined on related records. Example: Consider the following pseudo meta-model: Entity:Incident { Property: Id Property: Name Property: Owner->IncidentOwner } Entity:User { Property: Id Property: Name Property: Email } Relationship:IncidentOwner { From: Incident To: User } and the following REST call: HTTP GET: /rest/<tenant-id>/ems/Incident?layout=Id,Status,OwnedByPerson,OwnedByPerson.Name,OwnedByPerson.Email where tenant-id represents the tenant ID. To access the tenant ID, right click the Launch button next to the required product on MyAccount, select",
    "url": "queryproperties",
    "filename": "queryproperties",
    "headings": [
      "Retrieving related record properties",
      "Retrieving related records",
      "Retrieving grouped aggregated record data",
      "Filtering based on related record properties",
      "Query language extensions",
      "Related topics"
    ],
    "keywords": [
      "https://<serverAddress>/rest/<tenant-id>/ems/Incident/aggregations?filter=Active+%3D+'true'&group=Priority",
      "microfocus.com",
      "Category.Id",
      "OwnedByPerson.Name",
      "rest",
      "api",
      "queries",
      "retrieving",
      "related",
      "record",
      "properties",
      "records",
      "grouped",
      "aggregated",
      "data",
      "filtering",
      "based",
      "query",
      "language",
      "extensions",
      "topics",
      "entity",
      "management",
      "service",
      "ems",
      "run",
      "variety",
      "retrieve",
      "information",
      "system.",
      "about",
      "see",
      "api.",
      "connection",
      "language.",
      "reference",
      "operators",
      "commands",
      "collection",
      "protocol.",
      "enables",
      "defined",
      "records.",
      "example",
      "consider",
      "following",
      "pseudo",
      "meta-model",
      "incident",
      "property",
      "id",
      "name",
      "owner-",
      "incidentowner",
      "user",
      "email",
      "relationship",
      "call",
      "http",
      "get",
      "layout",
      "status",
      "ownedbyperson",
      "ownedbyperson.email",
      "tenant-id",
      "represents",
      "tenant",
      "id.",
      "access",
      "right",
      "click",
      "launch",
      "button",
      "next",
      "required",
      "product",
      "myaccount",
      "select",
      "copy",
      "link",
      "address",
      "paste",
      "browser.",
      "number",
      "tenantid",
      "result",
      "entities",
      "12226789",
      "open",
      "owner",
      "123651234",
      "jimi",
      "meta",
      "ok",
      "section",
      "refers",
      "querying",
      "relationships",
      "paths",
      "another"
    ],
    "language": "en",
    "word_count": 109,
    "importance_score": 6.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "rest api queries",
    "contentLower": "you can use the entity management service (ems) rest api to run a variety of queries to retrieve information from the system. for more information about the ems rest api, see ems rest api. you can use the rest api in connection with the query language. for a reference of query language operators and commands, see rest api collection query protocol. retrieving related record properties the ems rest api enables you to query for properties defined on related records. example: consider the following pseudo meta-model: entity:incident { property: id property: name property: owner->incidentowner } entity:user { property: id property: name property: email } relationship:incidentowner { from: incident to: user } and the following rest call: http get: /rest/<tenant-id>/ems/incident?layout=id,status,ownedbyperson,ownedbyperson.name,ownedbyperson.email where tenant-id represents the tenant id. to access the tenant id, right click the launch button next to the required product on myaccount, select",
    "keywordsLower": [
      "https://<serveraddress>/rest/<tenant-id>/ems/incident/aggregations?filter=active+%3d+'true'&group=priority",
      "microfocus.com",
      "category.id",
      "ownedbyperson.name",
      "rest",
      "api",
      "queries",
      "retrieving",
      "related",
      "record",
      "properties",
      "records",
      "grouped",
      "aggregated",
      "data",
      "filtering",
      "based",
      "query",
      "language",
      "extensions",
      "topics",
      "entity",
      "management",
      "service",
      "ems",
      "run",
      "variety",
      "retrieve",
      "information",
      "system.",
      "about",
      "see",
      "api.",
      "connection",
      "language.",
      "reference",
      "operators",
      "commands",
      "collection",
      "protocol.",
      "enables",
      "defined",
      "records.",
      "example",
      "consider",
      "following",
      "pseudo",
      "meta-model",
      "incident",
      "property",
      "id",
      "name",
      "owner-",
      "incidentowner",
      "user",
      "email",
      "relationship",
      "call",
      "http",
      "get",
      "layout",
      "status",
      "ownedbyperson",
      "ownedbyperson.email",
      "tenant-id",
      "represents",
      "tenant",
      "id.",
      "access",
      "right",
      "click",
      "launch",
      "button",
      "next",
      "required",
      "product",
      "myaccount",
      "select",
      "copy",
      "link",
      "address",
      "paste",
      "browser.",
      "number",
      "tenantid",
      "result",
      "entities",
      "12226789",
      "open",
      "owner",
      "123651234",
      "jimi",
      "meta",
      "ok",
      "section",
      "refers",
      "querying",
      "relationships",
      "paths",
      "another"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Single record APIs",
    "content": "The only API implemented for single records is the Get record by ID API. The syntax can be in the following formats: The tenant ID is directly in the URL: https://<serverAddress>/rest/<tenant-id>/ems/<entity-type>/<id>?<layout> The tenant ID is in a parameter: https://<serverAddress>/rest/<tenant-id>/ems/<entity-type>/<id>?<layout>&TENANTID=<tenant-id> The customer domain has a domain mapping: https://<customer domain name>/rest/<tenant-id>/ems/<entity-type>/<id>?<layout> where: tenant-id represents the tenant ID. To access the tenant ID, right-click the Launch button next to the required product on MyAccount, select Copy link address and paste it into a browser. The tenant ID is the number following TENANTID=. entity-type represents the logical name of the record to return. Example: Incident. id represents the ID of the record instance. layout represents a part of the REST query specifications. It specifies the record properties to return. Note The layout parameter is mandatory. For m",
    "url": "singleentityops",
    "filename": "singleentityops",
    "headings": [
      "Request structure",
      "Return structure",
      "Related topics"
    ],
    "keywords": [
      "https://<serverAddress>/rest/<tenant-id>/ems/Person/10548?layout=Name,Avatar",
      "https://<serverAddress>/admin/entity-editor/<entity-type>/property-grid-tab?TENANTID=xxxxx",
      "https://<customer",
      "https://<serverAddress>/rest/<tenant-id>/ems/<entity-type>/<id>?<layout",
      "microfocus.com",
      "https://<serverAddress>/rest/1234/ems/Person/10548?layout=Name,Avatar&TENANTID=1234",
      "https://<serverAddress>/rest/<tenant-id>/ems/<entity-type>/<id>?<layout>&TENANTID=<tenant-id",
      "single",
      "record",
      "apis",
      "request",
      "structure",
      "return",
      "related",
      "topics",
      "api",
      "implemented",
      "records",
      "get",
      "id",
      "api.",
      "syntax",
      "following",
      "formats",
      "tenant",
      "directly",
      "url",
      "https",
      "rest",
      "ems",
      "parameter",
      "tenantid",
      "customer",
      "domain",
      "mapping",
      "tenant-id",
      "represents",
      "id.",
      "access",
      "right-click",
      "launch",
      "button",
      "next",
      "required",
      "product",
      "myaccount",
      "select",
      "copy",
      "link",
      "address",
      "paste",
      "browser.",
      "number",
      "entity-type",
      "logical",
      "name",
      "return.",
      "example",
      "incident.",
      "instance.",
      "layout",
      "part",
      "query",
      "specifications.",
      "specifies",
      "properties",
      "note",
      "mandatory.",
      "information",
      "about",
      "see",
      "layout.",
      "types",
      "go",
      "administration",
      "configuration",
      "studio",
      "fields",
      "type",
      "drop-down",
      "list",
      "find",
      "admin",
      "entity-editor",
      "property-grid-tab",
      "xxxxx.",
      "view",
      "available",
      "selecting",
      "going",
      "tab.",
      "ui",
      "field",
      "displays",
      "multilingual",
      "label",
      "however",
      "make",
      "sure",
      "field."
    ],
    "language": "en",
    "word_count": 88,
    "importance_score": 4.5,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "single record apis",
    "contentLower": "the only api implemented for single records is the get record by id api. the syntax can be in the following formats: the tenant id is directly in the url: https://<serveraddress>/rest/<tenant-id>/ems/<entity-type>/<id>?<layout> the tenant id is in a parameter: https://<serveraddress>/rest/<tenant-id>/ems/<entity-type>/<id>?<layout>&tenantid=<tenant-id> the customer domain has a domain mapping: https://<customer domain name>/rest/<tenant-id>/ems/<entity-type>/<id>?<layout> where: tenant-id represents the tenant id. to access the tenant id, right-click the launch button next to the required product on myaccount, select copy link address and paste it into a browser. the tenant id is the number following tenantid=. entity-type represents the logical name of the record to return. example: incident. id represents the id of the record instance. layout represents a part of the rest query specifications. it specifies the record properties to return. note the layout parameter is mandatory. for m",
    "keywordsLower": [
      "https://<serveraddress>/rest/<tenant-id>/ems/person/10548?layout=name,avatar",
      "https://<serveraddress>/admin/entity-editor/<entity-type>/property-grid-tab?tenantid=xxxxx",
      "https://<customer",
      "https://<serveraddress>/rest/<tenant-id>/ems/<entity-type>/<id>?<layout",
      "microfocus.com",
      "https://<serveraddress>/rest/1234/ems/person/10548?layout=name,avatar&tenantid=1234",
      "https://<serveraddress>/rest/<tenant-id>/ems/<entity-type>/<id>?<layout>&tenantid=<tenant-id",
      "single",
      "record",
      "apis",
      "request",
      "structure",
      "return",
      "related",
      "topics",
      "api",
      "implemented",
      "records",
      "get",
      "id",
      "api.",
      "syntax",
      "following",
      "formats",
      "tenant",
      "directly",
      "url",
      "https",
      "rest",
      "ems",
      "parameter",
      "tenantid",
      "customer",
      "domain",
      "mapping",
      "tenant-id",
      "represents",
      "id.",
      "access",
      "right-click",
      "launch",
      "button",
      "next",
      "required",
      "product",
      "myaccount",
      "select",
      "copy",
      "link",
      "address",
      "paste",
      "browser.",
      "number",
      "entity-type",
      "logical",
      "name",
      "return.",
      "example",
      "incident.",
      "instance.",
      "layout",
      "part",
      "query",
      "specifications.",
      "specifies",
      "properties",
      "note",
      "mandatory.",
      "information",
      "about",
      "see",
      "layout.",
      "types",
      "go",
      "administration",
      "configuration",
      "studio",
      "fields",
      "type",
      "drop-down",
      "list",
      "find",
      "admin",
      "entity-editor",
      "property-grid-tab",
      "xxxxx.",
      "view",
      "available",
      "selecting",
      "going",
      "tab.",
      "ui",
      "field",
      "displays",
      "multilingual",
      "label",
      "however",
      "make",
      "sure",
      "field."
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Record bulk update and collection APIs",
    "content": "Bulk update APIs are highly recommended from a performance perspective because they reduce traffic and enable the EMS to optimize interaction with the database and increase its capacity. We don't recommend using the APIs for data deletion, as this is not yet officially supported. If you need to delete any transactional data, we recommend that you use the Purge feature provided by the system to ensure that all associated data is completely removed. Getting a record collection To run an HTTP GET method for a collection, the following syntax is supported: rest/<tenant-id>/ems/<entity-type>?<query-params> Where: tenant-id represents the tenant ID. To access the tenant ID, right-click the Launch button next to the required product on MyAccount, select Copy link address and paste it into a browser. The tenant ID is the number following TENANTID=. entity-type represents the logical name of the record to return. Example: incident. query-params represents query parameters compatible with the qu",
    "url": "bulkupdate",
    "filename": "bulkupdate",
    "headings": [
      "Getting a record collection",
      "Bulk Create/Update",
      "Example: Bulk Create",
      "Example: Bulk Update",
      "Example: Clear the value in a field",
      "Limitations",
      "Related topics"
    ],
    "keywords": [
      "https://<serverAddress>/rest/<tenant-id>/ems/Incident/11704?layout=SolvedTime,RegisteredForActualService,UserOptionsType,EntityModel",
      "https://{serverAddress}/rest/{tenant-id}/ems/bulk",
      "https://{serverAddress}/saw/ess/viewResult/13422\\\">BlackBerry</a><br><br",
      "record",
      "bulk",
      "update",
      "collection",
      "apis",
      "getting",
      "create",
      "example",
      "clear",
      "value",
      "field",
      "limitations",
      "related",
      "topics",
      "highly",
      "recommended",
      "performance",
      "perspective",
      "because",
      "reduce",
      "traffic",
      "enable",
      "ems",
      "optimize",
      "interaction",
      "database",
      "increase",
      "capacity.",
      "don",
      "recommend",
      "data",
      "deletion",
      "yet",
      "officially",
      "supported.",
      "need",
      "delete",
      "any",
      "transactional",
      "purge",
      "feature",
      "provided",
      "system",
      "ensure",
      "all",
      "associated",
      "completely",
      "removed.",
      "run",
      "http",
      "get",
      "method",
      "following",
      "syntax",
      "supported",
      "rest",
      "tenant-id",
      "represents",
      "tenant",
      "id.",
      "access",
      "id",
      "right-click",
      "launch",
      "button",
      "next",
      "required",
      "product",
      "myaccount",
      "select",
      "copy",
      "link",
      "address",
      "paste",
      "browser.",
      "number",
      "tenantid",
      "entity-type",
      "logical",
      "name",
      "return.",
      "incident.",
      "query-params",
      "query",
      "parameters",
      "compatible",
      "language",
      "specifications.",
      "enter",
      "request",
      "uri",
      "https",
      "incident",
      "11704",
      "layout",
      "solvedtime",
      "registeredforactualservice"
    ],
    "language": "en",
    "word_count": 99,
    "importance_score": 5.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "record bulk update and collection apis",
    "contentLower": "bulk update apis are highly recommended from a performance perspective because they reduce traffic and enable the ems to optimize interaction with the database and increase its capacity. we don't recommend using the apis for data deletion, as this is not yet officially supported. if you need to delete any transactional data, we recommend that you use the purge feature provided by the system to ensure that all associated data is completely removed. getting a record collection to run an http get method for a collection, the following syntax is supported: rest/<tenant-id>/ems/<entity-type>?<query-params> where: tenant-id represents the tenant id. to access the tenant id, right-click the launch button next to the required product on myaccount, select copy link address and paste it into a browser. the tenant id is the number following tenantid=. entity-type represents the logical name of the record to return. example: incident. query-params represents query parameters compatible with the qu",
    "keywordsLower": [
      "https://<serveraddress>/rest/<tenant-id>/ems/incident/11704?layout=solvedtime,registeredforactualservice,useroptionstype,entitymodel",
      "https://{serveraddress}/rest/{tenant-id}/ems/bulk",
      "https://{serveraddress}/saw/ess/viewresult/13422\\\">blackberry</a><br><br",
      "record",
      "bulk",
      "update",
      "collection",
      "apis",
      "getting",
      "create",
      "example",
      "clear",
      "value",
      "field",
      "limitations",
      "related",
      "topics",
      "highly",
      "recommended",
      "performance",
      "perspective",
      "because",
      "reduce",
      "traffic",
      "enable",
      "ems",
      "optimize",
      "interaction",
      "database",
      "increase",
      "capacity.",
      "don",
      "recommend",
      "data",
      "deletion",
      "yet",
      "officially",
      "supported.",
      "need",
      "delete",
      "any",
      "transactional",
      "purge",
      "feature",
      "provided",
      "system",
      "ensure",
      "all",
      "associated",
      "completely",
      "removed.",
      "run",
      "http",
      "get",
      "method",
      "following",
      "syntax",
      "supported",
      "rest",
      "tenant-id",
      "represents",
      "tenant",
      "id.",
      "access",
      "id",
      "right-click",
      "launch",
      "button",
      "next",
      "required",
      "product",
      "myaccount",
      "select",
      "copy",
      "link",
      "address",
      "paste",
      "browser.",
      "number",
      "tenantid",
      "entity-type",
      "logical",
      "name",
      "return.",
      "incident.",
      "query-params",
      "query",
      "parameters",
      "compatible",
      "language",
      "specifications.",
      "enter",
      "request",
      "uri",
      "https",
      "incident",
      "11704",
      "layout",
      "solvedtime",
      "registeredforactualservice"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "REST API collection query protocol",
    "content": "This section provides specifications for HTTP GET query parameters designed to be used with REST services APIs. Collection filtering The filter query parameter specifies a filtering condition for a resource collection. The service then returns only resources that meet the specified condition. Logical operators The following logical operators are supported: Name Description Examples Logical And Evaluates to true if both the left and right operands evaluate to true, otherwise evaluates to false. https://<host>/rest/<tenant-id>/ems/<record-type>?filter=Id > 1000 and Name eq 'Jake'&layout=Id,Displaylabel,Priority https://<host>/rest/<tenant-id>/ems/<record-type>?filter=Id > 1000 and Name = 'Jake'&layout=Id,Displaylabel,Priority Logical Or Evaluates to true if at least one of the left and right operands evaluates to true, otherwise evaluates to false. https://<host>/rest/<tenant-id>/ems/<record-type>?filter=Id > 1000 or Name eq 'Jane'&layout=Id,Displaylabel,Priority https://<host>/rest/<ten",
    "url": "collectqueryprotocol",
    "filename": "collectqueryprotocol",
    "headings": [
      "Collection filtering",
      "Layout",
      "Record-type",
      "Ordering",
      "Size",
      "Skip",
      "Paging",
      "Metadata",
      "String literals",
      "Related topics"
    ],
    "keywords": [
      "https://<host>/rest/<tenant-id>/ems/<record-type>?filter=Rank",
      "https://<host>/Person?layout=FirstName,LastName,Email&filter=Age<30&order=Age",
      "https://<host>/rest/<tenant-id>/ems/<record-type>?layout=Id,Name,Description",
      "https://<host>/rest/<tenant-id>/ems/<record-type>?filter=Actual",
      "https://<host>/Person?layout=FirstName,LastName,Email&order=Id&skip=50&size=50",
      "PrimaryAddress.City",
      "https://<host>/Person?layout=FirstName,LastName,Email&order=Id&skip=100&size=50",
      "https://<host>/rest/<tenant-id>/ems/<record-type>?filter=PreviousRank",
      "https://<host>/rest/<tenant-id>/ems/<record-type>?filter=SupportDurationTime",
      "https://<host>/admin/entity-editor/<record-type>/property-grid-tab?TENANTID=xxxxx",
      "https://<host>/Person?layout=FirstName,LastName,Email&skip=50",
      "https://<host>/rest/<tenant-id>/ems/<record-type>?filter=LastUpdate",
      "https://<host>/rest/<tenant-id>/ems/<record-type>?filter=PlannedHours=PlannedDays",
      "https://<host>/Person?layout=FirstName,LastName,Email&order=Id&skip=0&size=50",
      "https://<host>/rest/<tenant-id>/ems/<record-type>?filter=Id",
      "https://<host>/rest/<tenant-id>/ems/Person?layout=PrimaryAddress.City",
      "https://<host>/Person?layout=FirstName,LastName,Email&skip=50&filter=Age>10&meta=totalCount,Count",
      "rest",
      "api",
      "collection",
      "query",
      "protocol",
      "filtering",
      "layout",
      "record-type",
      "ordering",
      "size",
      "skip",
      "paging",
      "metadata",
      "string",
      "literals",
      "related",
      "topics",
      "section",
      "provides",
      "specifications",
      "http",
      "get",
      "parameters",
      "designed",
      "services",
      "apis.",
      "filter",
      "parameter",
      "specifies",
      "condition",
      "resource",
      "collection.",
      "service",
      "returns",
      "resources",
      "meet",
      "specified",
      "condition.",
      "logical",
      "operators",
      "following",
      "supported",
      "name",
      "description",
      "examples",
      "evaluates",
      "true",
      "both",
      "left",
      "right",
      "operands",
      "evaluate",
      "otherwise",
      "false.",
      "https",
      "ems",
      "id",
      "1000",
      "eq",
      "jake",
      "displaylabel",
      "priority",
      "least",
      "one",
      "jane",
      "isn",
      "supported.",
      "specific",
      "own",
      "negation",
      "syntax.",
      "example",
      "comparison",
      "boolean",
      "value",
      "depending",
      "operand",
      "values.",
      "equals",
      "equal",
      "rank",
      "aren",
      "ne"
    ],
    "language": "en",
    "word_count": 107,
    "importance_score": 6.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "rest api collection query protocol",
    "contentLower": "this section provides specifications for http get query parameters designed to be used with rest services apis. collection filtering the filter query parameter specifies a filtering condition for a resource collection. the service then returns only resources that meet the specified condition. logical operators the following logical operators are supported: name description examples logical and evaluates to true if both the left and right operands evaluate to true, otherwise evaluates to false. https://<host>/rest/<tenant-id>/ems/<record-type>?filter=id > 1000 and name eq 'jake'&layout=id,displaylabel,priority https://<host>/rest/<tenant-id>/ems/<record-type>?filter=id > 1000 and name = 'jake'&layout=id,displaylabel,priority logical or evaluates to true if at least one of the left and right operands evaluates to true, otherwise evaluates to false. https://<host>/rest/<tenant-id>/ems/<record-type>?filter=id > 1000 or name eq 'jane'&layout=id,displaylabel,priority https://<host>/rest/<ten",
    "keywordsLower": [
      "https://<host>/rest/<tenant-id>/ems/<record-type>?filter=rank",
      "https://<host>/person?layout=firstname,lastname,email&filter=age<30&order=age",
      "https://<host>/rest/<tenant-id>/ems/<record-type>?layout=id,name,description",
      "https://<host>/rest/<tenant-id>/ems/<record-type>?filter=actual",
      "https://<host>/person?layout=firstname,lastname,email&order=id&skip=50&size=50",
      "primaryaddress.city",
      "https://<host>/person?layout=firstname,lastname,email&order=id&skip=100&size=50",
      "https://<host>/rest/<tenant-id>/ems/<record-type>?filter=previousrank",
      "https://<host>/rest/<tenant-id>/ems/<record-type>?filter=supportdurationtime",
      "https://<host>/admin/entity-editor/<record-type>/property-grid-tab?tenantid=xxxxx",
      "https://<host>/person?layout=firstname,lastname,email&skip=50",
      "https://<host>/rest/<tenant-id>/ems/<record-type>?filter=lastupdate",
      "https://<host>/rest/<tenant-id>/ems/<record-type>?filter=plannedhours=planneddays",
      "https://<host>/person?layout=firstname,lastname,email&order=id&skip=0&size=50",
      "https://<host>/rest/<tenant-id>/ems/<record-type>?filter=id",
      "https://<host>/rest/<tenant-id>/ems/person?layout=primaryaddress.city",
      "https://<host>/person?layout=firstname,lastname,email&skip=50&filter=age>10&meta=totalcount,count",
      "rest",
      "api",
      "collection",
      "query",
      "protocol",
      "filtering",
      "layout",
      "record-type",
      "ordering",
      "size",
      "skip",
      "paging",
      "metadata",
      "string",
      "literals",
      "related",
      "topics",
      "section",
      "provides",
      "specifications",
      "http",
      "get",
      "parameters",
      "designed",
      "services",
      "apis.",
      "filter",
      "parameter",
      "specifies",
      "condition",
      "resource",
      "collection.",
      "service",
      "returns",
      "resources",
      "meet",
      "specified",
      "condition.",
      "logical",
      "operators",
      "following",
      "supported",
      "name",
      "description",
      "examples",
      "evaluates",
      "true",
      "both",
      "left",
      "right",
      "operands",
      "evaluate",
      "otherwise",
      "false.",
      "https",
      "ems",
      "id",
      "1000",
      "eq",
      "jake",
      "displaylabel",
      "priority",
      "least",
      "one",
      "jane",
      "isn",
      "supported.",
      "specific",
      "own",
      "negation",
      "syntax.",
      "example",
      "comparison",
      "boolean",
      "value",
      "depending",
      "operand",
      "values.",
      "equals",
      "equal",
      "rank",
      "aren",
      "ne"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "REST API use case scenario - import REST API",
    "content": "The import service supports importing record data into the EMS in either CSV or XML format. Imported data must comply with system and workflow rules for the import process to be successful. CSV format request body To import data in CSV format, make sure the CSV file follows these guidelines: The first line of the file contains the record property names (headers) as specified in the metadata. The names must be identical to the record field names. The following lines contain the data itself. The following example can be used to create users: FirstName,LastName,Email,Name,IsMaasUser,Upn John,Smith,john.smith@microfocus.com,John Smith,false,john.smith@microfocus.com John,Doe,john.doe@microfocus.com,John Doe,true,john.doe@microfocus.com Click here to view a spreadsheet with sample CSV files for a series of records. The files should be imported sequentially according to their number. Note The import service creates a separate record for each row of data in the CSV file. XML format request bo",
    "url": "usecasesimport",
    "filename": "usecasesimport",
    "headings": [
      "CSV format request body",
      "XML format request body",
      "Access the import service",
      "Related topics"
    ],
    "keywords": [
      "https://<serverAddress>/rest/<tenant-id>/import?entity-type=<entityType>&file-type=XML",
      "https://<serverAddress>/rest/<tenant-id>/import/<job_id",
      "www.hpe",
      "1.0.0",
      "john.doe",
      "microfocus.com",
      "https://<serverAddress>/rest/<tenant-id>/import?entity-type=<entityType>&file-type=CSV",
      "http://www.hpe.com/maas/1.0.0/import",
      "rest",
      "api",
      "case",
      "scenario",
      "import",
      "csv",
      "format",
      "request",
      "body",
      "xml",
      "access",
      "service",
      "related",
      "topics",
      "supports",
      "importing",
      "record",
      "data",
      "ems",
      "either",
      "format.",
      "imported",
      "comply",
      "system",
      "workflow",
      "rules",
      "process",
      "successful.",
      "make",
      "sure",
      "file",
      "follows",
      "guidelines",
      "first",
      "line",
      "contains",
      "property",
      "names",
      "headers",
      "specified",
      "metadata.",
      "identical",
      "field",
      "names.",
      "following",
      "lines",
      "contain",
      "itself.",
      "example",
      "create",
      "users",
      "firstname",
      "lastname",
      "email",
      "name",
      "ismaasuser",
      "upn",
      "john",
      "smith",
      "john.smith",
      "false",
      "doe",
      "true",
      "click",
      "here",
      "view",
      "spreadsheet",
      "sample",
      "files",
      "series",
      "records.",
      "sequentially",
      "according",
      "number.",
      "note",
      "creates",
      "separate",
      "row",
      "file.",
      "element",
      "key",
      "holds",
      "metadata",
      "value",
      "value.",
      "severity",
      "entity",
      "one",
      "urls",
      "https",
      "entity-type",
      "file-type"
    ],
    "language": "en",
    "word_count": 117,
    "importance_score": 4.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "rest api use case scenario - import rest api",
    "contentLower": "the import service supports importing record data into the ems in either csv or xml format. imported data must comply with system and workflow rules for the import process to be successful. csv format request body to import data in csv format, make sure the csv file follows these guidelines: the first line of the file contains the record property names (headers) as specified in the metadata. the names must be identical to the record field names. the following lines contain the data itself. the following example can be used to create users: firstname,lastname,email,name,ismaasuser,upn john,smith,john.smith@microfocus.com,john smith,false,john.smith@microfocus.com john,doe,john.doe@microfocus.com,john doe,true,john.doe@microfocus.com click here to view a spreadsheet with sample csv files for a series of records. the files should be imported sequentially according to their number. note the import service creates a separate record for each row of data in the csv file. xml format request bo",
    "keywordsLower": [
      "https://<serveraddress>/rest/<tenant-id>/import?entity-type=<entitytype>&file-type=xml",
      "https://<serveraddress>/rest/<tenant-id>/import/<job_id",
      "www.hpe",
      "1.0.0",
      "john.doe",
      "microfocus.com",
      "https://<serveraddress>/rest/<tenant-id>/import?entity-type=<entitytype>&file-type=csv",
      "http://www.hpe.com/maas/1.0.0/import",
      "rest",
      "api",
      "case",
      "scenario",
      "import",
      "csv",
      "format",
      "request",
      "body",
      "xml",
      "access",
      "service",
      "related",
      "topics",
      "supports",
      "importing",
      "record",
      "data",
      "ems",
      "either",
      "format.",
      "imported",
      "comply",
      "system",
      "workflow",
      "rules",
      "process",
      "successful.",
      "make",
      "sure",
      "file",
      "follows",
      "guidelines",
      "first",
      "line",
      "contains",
      "property",
      "names",
      "headers",
      "specified",
      "metadata.",
      "identical",
      "field",
      "names.",
      "following",
      "lines",
      "contain",
      "itself.",
      "example",
      "create",
      "users",
      "firstname",
      "lastname",
      "email",
      "name",
      "ismaasuser",
      "upn",
      "john",
      "smith",
      "john.smith",
      "false",
      "doe",
      "true",
      "click",
      "here",
      "view",
      "spreadsheet",
      "sample",
      "files",
      "series",
      "records.",
      "sequentially",
      "according",
      "number.",
      "note",
      "creates",
      "separate",
      "row",
      "file.",
      "element",
      "key",
      "holds",
      "metadata",
      "value",
      "value.",
      "severity",
      "entity",
      "one",
      "urls",
      "https",
      "entity-type",
      "file-type"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "SAM license rule APIs",
    "content": "This section describes how to extend SAM's license rules through programming. SAM supports license rule extension by providing the capability of creating license rules and the corresponding rule scripts. For more information about how to create license rules, see License rules. What's license rule A rule script implements the algorithms of license consumption calculation. It focuses on a particular resource unit and generates one valid result. The resource unit can be a software instance, an OSE, a physical device, or other devices, depending on the license terms of the product. The following example uses the Microsoft license terms. Server licenses (per instance): Customers might use one running software instance in either a physical or virtual OSE deployed on a licensed server for each license. If a license rule is created for products of this metric, the rule must be implemented on an OSE. Script security The license rules provided by SAM are developed using groovy scripts. The scri",
    "url": "samprgmruleextensibility",
    "filename": "samprgmruleextensibility",
    "headings": [
      "What's license rule",
      "Script security",
      "Develop a license rule script",
      "Part 1: Package definition",
      "Part 2: Implement the standard ConsumptionCalculator interface",
      "Part 3: Implement the calculation method",
      "Part 4: Parameter ParamPerUnit",
      "Part 5: Implement the license rule",
      "Part 6: Consumption result",
      "Method related to the consumption result",
      "Part 7: Return result",
      "Return two sets of consumption result in one license rule",
      "Part 1: Calculate two sets of result",
      "Part 2: Save two sets of result",
      "Part 3: Select one result for subsequent compliance calculation",
      "Use logs in a script",
      "Class allowlist for scripting",
      "Classes and APIs for scripting"
    ],
    "keywords": [
      "java.math",
      "2020.11",
      "java.util",
      "java.lang",
      "ci.Node",
      "model.calc",
      "microfocus.sam",
      "ci.Host",
      "model.vo",
      "sam",
      "license",
      "rule",
      "apis",
      "what",
      "script",
      "security",
      "develop",
      "part",
      "package",
      "definition",
      "implement",
      "standard",
      "consumptioncalculator",
      "interface",
      "calculation",
      "method",
      "parameter",
      "paramperunit",
      "consumption",
      "result",
      "related",
      "return",
      "two",
      "sets",
      "one",
      "calculate",
      "save",
      "select",
      "subsequent",
      "compliance",
      "logs",
      "class",
      "allowlist",
      "scripting",
      "classes",
      "section",
      "describes",
      "extend",
      "rules",
      "through",
      "programming.",
      "supports",
      "extension",
      "providing",
      "capability",
      "creating",
      "corresponding",
      "scripts.",
      "information",
      "about",
      "create",
      "see",
      "rules.",
      "implements",
      "algorithms",
      "calculation.",
      "focuses",
      "particular",
      "resource",
      "unit",
      "generates",
      "valid",
      "result.",
      "software",
      "instance",
      "ose",
      "physical",
      "device",
      "devices",
      "depending",
      "terms",
      "product.",
      "following",
      "example",
      "uses",
      "microsoft",
      "terms.",
      "server",
      "licenses",
      "per",
      "customers",
      "running",
      "either",
      "virtual",
      "deployed",
      "licensed",
      "license.",
      "created",
      "products",
      "metric"
    ],
    "language": "en",
    "word_count": 106,
    "importance_score": 6.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "sam license rule apis",
    "contentLower": "this section describes how to extend sam's license rules through programming. sam supports license rule extension by providing the capability of creating license rules and the corresponding rule scripts. for more information about how to create license rules, see license rules. what's license rule a rule script implements the algorithms of license consumption calculation. it focuses on a particular resource unit and generates one valid result. the resource unit can be a software instance, an ose, a physical device, or other devices, depending on the license terms of the product. the following example uses the microsoft license terms. server licenses (per instance): customers might use one running software instance in either a physical or virtual ose deployed on a licensed server for each license. if a license rule is created for products of this metric, the rule must be implemented on an ose. script security the license rules provided by sam are developed using groovy scripts. the scri",
    "keywordsLower": [
      "java.math",
      "2020.11",
      "java.util",
      "java.lang",
      "ci.node",
      "model.calc",
      "microfocus.sam",
      "ci.host",
      "model.vo",
      "sam",
      "license",
      "rule",
      "apis",
      "what",
      "script",
      "security",
      "develop",
      "part",
      "package",
      "definition",
      "implement",
      "standard",
      "consumptioncalculator",
      "interface",
      "calculation",
      "method",
      "parameter",
      "paramperunit",
      "consumption",
      "result",
      "related",
      "return",
      "two",
      "sets",
      "one",
      "calculate",
      "save",
      "select",
      "subsequent",
      "compliance",
      "logs",
      "class",
      "allowlist",
      "scripting",
      "classes",
      "section",
      "describes",
      "extend",
      "rules",
      "through",
      "programming.",
      "supports",
      "extension",
      "providing",
      "capability",
      "creating",
      "corresponding",
      "scripts.",
      "information",
      "about",
      "create",
      "see",
      "rules.",
      "implements",
      "algorithms",
      "calculation.",
      "focuses",
      "particular",
      "resource",
      "unit",
      "generates",
      "valid",
      "result.",
      "software",
      "instance",
      "ose",
      "physical",
      "device",
      "devices",
      "depending",
      "terms",
      "product.",
      "following",
      "example",
      "uses",
      "microsoft",
      "terms.",
      "server",
      "licenses",
      "per",
      "customers",
      "running",
      "either",
      "virtual",
      "deployed",
      "licensed",
      "license.",
      "created",
      "products",
      "metric"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Scriptlets",
    "content": "An OO Scriptlet is a JavaScript (Rhino) script used for manipulating flow data. Coding style Long scriptlets If possible, avoid long scriptlets. When trying to save a flow that contains scriptlets exceeding 64kb, an exception will occur. Usually, scriptlets should not contain complex logic. Use scriptlets for parsing strings as well (the following image shows an example). Validate scriptlets When saving a flow that has a scriptlet, OO Studio automatically performs a scriptlet validation, checking the script for syntax errors. This validation can also be triggered manually by clicking the “Check Script” button from the Scriptlet tab. JavaScript best practices and sriptlets It is recommended that you apply JavaScript best practices to OO scriptlets, as follows: In JavaScript, function or variable names must begin with a letter, an underscore (_), or a dollar sign ($). Subsequent characters can be letters, digits, underscores, or dollar signs. Note If the inputs of flows or steps are refe",
    "url": "scriptlets",
    "filename": "scriptlets",
    "headings": [
      "Coding style",
      "Long scriptlets",
      "Validate scriptlets",
      "JavaScript best practices and sriptlets",
      "Exception handling",
      "Handling scriptlets in OO",
      "OO special objects and methods",
      "Scriptlet capabilities",
      "Reusing scriptlets",
      "Handling variables"
    ],
    "keywords": [
      "java.lang",
      "2.3",
      "scriptletContext.get",
      "Java.lang",
      "scriptletContext.put",
      "scriptlets",
      "coding",
      "style",
      "long",
      "validate",
      "javascript",
      "best",
      "practices",
      "sriptlets",
      "exception",
      "handling",
      "oo",
      "special",
      "objects",
      "methods",
      "scriptlet",
      "capabilities",
      "reusing",
      "variables",
      "rhino",
      "script",
      "manipulating",
      "flow",
      "data.",
      "possible",
      "avoid",
      "scriptlets.",
      "trying",
      "save",
      "contains",
      "exceeding",
      "64kb",
      "occur.",
      "usually",
      "contain",
      "complex",
      "logic.",
      "parsing",
      "strings",
      "well",
      "following",
      "image",
      "shows",
      "example",
      "saving",
      "studio",
      "automatically",
      "performs",
      "validation",
      "checking",
      "syntax",
      "errors.",
      "triggered",
      "manually",
      "clicking",
      "check",
      "button",
      "tab.",
      "recommended",
      "apply",
      "follows",
      "function",
      "variable",
      "names",
      "begin",
      "letter",
      "underscore",
      "dollar",
      "sign",
      "subsequent",
      "characters",
      "letters",
      "digits",
      "underscores",
      "signs.",
      "note",
      "inputs",
      "flows",
      "steps",
      "referenced",
      "follow",
      "guidelines.",
      "input",
      "name",
      "input.1",
      "because",
      "invalid",
      "even",
      "though",
      "valid",
      "input.",
      "always",
      "var",
      "declaring",
      "global"
    ],
    "language": "en",
    "word_count": 96,
    "importance_score": 6.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "scriptlets",
    "contentLower": "an oo scriptlet is a javascript (rhino) script used for manipulating flow data. coding style long scriptlets if possible, avoid long scriptlets. when trying to save a flow that contains scriptlets exceeding 64kb, an exception will occur. usually, scriptlets should not contain complex logic. use scriptlets for parsing strings as well (the following image shows an example). validate scriptlets when saving a flow that has a scriptlet, oo studio automatically performs a scriptlet validation, checking the script for syntax errors. this validation can also be triggered manually by clicking the “check script” button from the scriptlet tab. javascript best practices and sriptlets it is recommended that you apply javascript best practices to oo scriptlets, as follows: in javascript, function or variable names must begin with a letter, an underscore (_), or a dollar sign ($). subsequent characters can be letters, digits, underscores, or dollar signs. note if the inputs of flows or steps are refe",
    "keywordsLower": [
      "java.lang",
      "2.3",
      "scriptletcontext.get",
      "java.lang",
      "scriptletcontext.put",
      "scriptlets",
      "coding",
      "style",
      "long",
      "validate",
      "javascript",
      "best",
      "practices",
      "sriptlets",
      "exception",
      "handling",
      "oo",
      "special",
      "objects",
      "methods",
      "scriptlet",
      "capabilities",
      "reusing",
      "variables",
      "rhino",
      "script",
      "manipulating",
      "flow",
      "data.",
      "possible",
      "avoid",
      "scriptlets.",
      "trying",
      "save",
      "contains",
      "exceeding",
      "64kb",
      "occur.",
      "usually",
      "contain",
      "complex",
      "logic.",
      "parsing",
      "strings",
      "well",
      "following",
      "image",
      "shows",
      "example",
      "saving",
      "studio",
      "automatically",
      "performs",
      "validation",
      "checking",
      "syntax",
      "errors.",
      "triggered",
      "manually",
      "clicking",
      "check",
      "button",
      "tab.",
      "recommended",
      "apply",
      "follows",
      "function",
      "variable",
      "names",
      "begin",
      "letter",
      "underscore",
      "dollar",
      "sign",
      "subsequent",
      "characters",
      "letters",
      "digits",
      "underscores",
      "signs.",
      "note",
      "inputs",
      "flows",
      "steps",
      "referenced",
      "follow",
      "guidelines.",
      "input",
      "name",
      "input.1",
      "because",
      "invalid",
      "even",
      "though",
      "valid",
      "input.",
      "always",
      "var",
      "declaring",
      "global"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "References",
    "content": "Maven Getting Started Guide: https://maven.apache.org/guides/getting-started/index#$filename Installing Apache Maven: https://maven.apache.org/install#$filename Using Mirrors for Repositories: https://maven.apache.org/guides/mini/guide-mirror-settings#$filename CloudSlang Tutorial: http://cloudslang-docs.readthedocs.io/en/v1.0/section_tutorial#$filename",
    "url": "references",
    "filename": "references",
    "headings": [],
    "keywords": [
      "https://maven.apache.org/install#$filename",
      "apache.org",
      "https://maven.apache.org/guides/getting-started/index#$filename",
      "readthedocs.io",
      "https://maven.apache.org/guides/mini/guide-mirror-settings#$filename",
      "http://cloudslang-docs.readthedocs.io/en/v1.0/section_tutorial#$filename",
      "v1.0",
      "references",
      "maven",
      "getting",
      "started",
      "guide",
      "https",
      "maven.apache.org",
      "guides",
      "getting-started",
      "index",
      "filename",
      "installing",
      "apache",
      "install",
      "mirrors",
      "repositories",
      "mini",
      "guide-mirror-settings",
      "cloudslang",
      "tutorial",
      "http",
      "cloudslang-docs.readthedocs.io",
      "en"
    ],
    "language": "en",
    "word_count": 34,
    "importance_score": 2.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "references",
    "contentLower": "maven getting started guide: https://maven.apache.org/guides/getting-started/index#$filename installing apache maven: https://maven.apache.org/install#$filename using mirrors for repositories: https://maven.apache.org/guides/mini/guide-mirror-settings#$filename cloudslang tutorial: http://cloudslang-docs.readthedocs.io/en/v1.0/section_tutorial#$filename",
    "keywordsLower": [
      "https://maven.apache.org/install#$filename",
      "apache.org",
      "https://maven.apache.org/guides/getting-started/index#$filename",
      "readthedocs.io",
      "https://maven.apache.org/guides/mini/guide-mirror-settings#$filename",
      "http://cloudslang-docs.readthedocs.io/en/v1.0/section_tutorial#$filename",
      "v1.0",
      "references",
      "maven",
      "getting",
      "started",
      "guide",
      "https",
      "maven.apache.org",
      "guides",
      "getting-started",
      "index",
      "filename",
      "installing",
      "apache",
      "install",
      "mirrors",
      "repositories",
      "mini",
      "guide-mirror-settings",
      "cloudslang",
      "tutorial",
      "http",
      "cloudslang-docs.readthedocs.io",
      "en"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  }
]