[
  {
    "title": "User authentication overview",
    "content": "User authentication in Service Management validates the identity of a user and then authorizes the user to features that match the user's role. You can use different methods to authenticate users, which fall into two main categories: IdM authentication and external identity provider (IdP) authentication. IdM authentication In IdM authentication, users log in to applications through the IdM login page (the applications utilize the IdM login page), and IdM validates the credentials itself, according to how you have configured the authentication. IdM authentication comprises the following methods: Database User information is stored in the IdM database. You must add users to the IdM database by using User Administration, IdM Admin Portal, a seeded file, or an API. For this authentication method, a user must enter the user name and password to log in to the system. LDAP User information is stored on an external LDAP server. You use the IdM Admin Portal to configure an LDAP server connectio",
    "url": "authtypes",
    "filename": "authtypes",
    "headings": [
      "IdM authentication",
      "IdP authentication",
      "2FA & MFA",
      "SSO",
      "Related topics"
    ],
    "keywords": [
      "user",
      "authentication",
      "overview",
      "idm",
      "idp",
      "2fa",
      "mfa",
      "sso",
      "related",
      "topics",
      "service",
      "management",
      "validates",
      "identity",
      "authorizes",
      "features",
      "match",
      "role.",
      "different",
      "methods",
      "authenticate",
      "users",
      "fall",
      "two",
      "main",
      "categories",
      "external",
      "provider",
      "authentication.",
      "log",
      "applications",
      "through",
      "login",
      "page",
      "utilize",
      "credentials",
      "itself",
      "according",
      "configured",
      "comprises",
      "following",
      "database",
      "information",
      "stored",
      "database.",
      "add",
      "administration",
      "admin",
      "portal",
      "seeded",
      "file",
      "api.",
      "method",
      "enter",
      "name",
      "password",
      "system.",
      "ldap",
      "server.",
      "configure",
      "server",
      "connection",
      "required",
      "administrator",
      "credentials.",
      "logs",
      "application",
      "authenticates",
      "verifying",
      "existing",
      "directory.",
      "integrate",
      "third-party",
      "idp.",
      "request",
      "forwarded",
      "validate",
      "saml",
      "oauth",
      "two-factor",
      "multi-factor",
      "requires",
      "provide",
      "verification",
      "factors",
      "rather",
      "just",
      "username",
      "gain",
      "access",
      "security",
      "suite",
      "supports",
      "it.",
      "delegating",
      "federated",
      "idps",
      "system",
      "redirect",
      "additional"
    ],
    "language": "en",
    "word_count": 101,
    "importance_score": 5.5,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "user authentication overview",
    "contentLower": "user authentication in service management validates the identity of a user and then authorizes the user to features that match the user's role. you can use different methods to authenticate users, which fall into two main categories: idm authentication and external identity provider (idp) authentication. idm authentication in idm authentication, users log in to applications through the idm login page (the applications utilize the idm login page), and idm validates the credentials itself, according to how you have configured the authentication. idm authentication comprises the following methods: database user information is stored in the idm database. you must add users to the idm database by using user administration, idm admin portal, a seeded file, or an api. for this authentication method, a user must enter the user name and password to log in to the system. ldap user information is stored on an external ldap server. you use the idm admin portal to configure an ldap server connectio",
    "keywordsLower": [
      "user",
      "authentication",
      "overview",
      "idm",
      "idp",
      "2fa",
      "mfa",
      "sso",
      "related",
      "topics",
      "service",
      "management",
      "validates",
      "identity",
      "authorizes",
      "features",
      "match",
      "role.",
      "different",
      "methods",
      "authenticate",
      "users",
      "fall",
      "two",
      "main",
      "categories",
      "external",
      "provider",
      "authentication.",
      "log",
      "applications",
      "through",
      "login",
      "page",
      "utilize",
      "credentials",
      "itself",
      "according",
      "configured",
      "comprises",
      "following",
      "database",
      "information",
      "stored",
      "database.",
      "add",
      "administration",
      "admin",
      "portal",
      "seeded",
      "file",
      "api.",
      "method",
      "enter",
      "name",
      "password",
      "system.",
      "ldap",
      "server.",
      "configure",
      "server",
      "connection",
      "required",
      "administrator",
      "credentials.",
      "logs",
      "application",
      "authenticates",
      "verifying",
      "existing",
      "directory.",
      "integrate",
      "third-party",
      "idp.",
      "request",
      "forwarded",
      "validate",
      "saml",
      "oauth",
      "two-factor",
      "multi-factor",
      "requires",
      "provide",
      "verification",
      "factors",
      "rather",
      "just",
      "username",
      "gain",
      "access",
      "security",
      "suite",
      "supports",
      "it.",
      "delegating",
      "federated",
      "idps",
      "system",
      "redirect",
      "additional"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Using Software Asset Management in Service Management",
    "content": "This document aims to assist customers who want to use SAM within Service Management. It provides detailed instructions on how to navigate SAM, generate software licenses, create metrics, and show how to use them to create compliance and analysis reports. The key topics of using SAM in Service Management include products, license models, licenses, compliance, analysis, license metrics, and license rules. For details, see Manage software compliance using SAM.",
    "url": "usingsaminsmax",
    "filename": "usingsaminsmax",
    "headings": [],
    "keywords": [
      "software",
      "asset",
      "management",
      "service",
      "document",
      "aims",
      "assist",
      "customers",
      "want",
      "sam",
      "management.",
      "provides",
      "detailed",
      "instructions",
      "navigate",
      "generate",
      "licenses",
      "create",
      "metrics",
      "show",
      "compliance",
      "analysis",
      "reports.",
      "key",
      "topics",
      "include",
      "products",
      "license",
      "models",
      "rules.",
      "details",
      "see",
      "manage",
      "sam."
    ],
    "language": "en",
    "word_count": 50,
    "importance_score": 1.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "using software asset management in service management",
    "contentLower": "this document aims to assist customers who want to use sam within service management. it provides detailed instructions on how to navigate sam, generate software licenses, create metrics, and show how to use them to create compliance and analysis reports. the key topics of using sam in service management include products, license models, licenses, compliance, analysis, license metrics, and license rules. for details, see manage software compliance using sam.",
    "keywordsLower": [
      "software",
      "asset",
      "management",
      "service",
      "document",
      "aims",
      "assist",
      "customers",
      "want",
      "sam",
      "management.",
      "provides",
      "detailed",
      "instructions",
      "navigate",
      "generate",
      "licenses",
      "create",
      "metrics",
      "show",
      "compliance",
      "analysis",
      "reports.",
      "key",
      "topics",
      "include",
      "products",
      "license",
      "models",
      "rules.",
      "details",
      "see",
      "manage",
      "sam."
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Way of Working",
    "content": "Introduction Service Management is the first application suite for IT and Enterprise Service and Asset Management built on native machine learning, analytics, CMDB, and discovery. The out-of-the-box, extensible, best practices and completely codeless configuration means faster time-to-market for implementations. It can be deployed on-premise, in private or public cloud, or moved from one to the other as business conditions change. Its scalable, multi-tenant, architecture makes it easy to install, configure, and run. Customers (and their administrators) that have worked with other products may find some areas in Service Management different than they are used to -- especially products that aren't ITIL compliant. This document attempts to highlight and explain some of the important concepts and functionality within Service Management that may be new or not intuitive to users not familiar with the product. This document, as well as the related documents linked here, will continue to evolv",
    "url": "wayofworking",
    "filename": "wayofworking",
    "headings": [
      "Introduction",
      "High Level Guidance",
      "Stay close to home",
      "…and out of the box",
      "Don’t create the next buggy whip",
      "…by trying to reimplement an old system inside of Service Management",
      "Processes",
      "Service Request vs. Incident",
      "Request and Incident Together",
      "Do not reopen records",
      "Configuration",
      "Services and Designing the Service Catalog",
      "Workflows",
      "Using and modifying forms"
    ],
    "keywords": [
      "way",
      "working",
      "introduction",
      "high",
      "level",
      "guidance",
      "stay",
      "close",
      "home",
      "out",
      "box",
      "don",
      "create",
      "next",
      "buggy",
      "whip",
      "trying",
      "reimplement",
      "old",
      "system",
      "inside",
      "service",
      "management",
      "processes",
      "request",
      "vs.",
      "incident",
      "together",
      "reopen",
      "records",
      "configuration",
      "services",
      "designing",
      "catalog",
      "workflows",
      "modifying",
      "forms",
      "first",
      "application",
      "suite",
      "enterprise",
      "asset",
      "built",
      "native",
      "machine",
      "learning",
      "analytics",
      "cmdb",
      "discovery.",
      "out-of-the-box",
      "extensible",
      "best",
      "practices",
      "completely",
      "codeless",
      "means",
      "faster",
      "time-to-market",
      "implementations.",
      "deployed",
      "on-premise",
      "private",
      "public",
      "cloud",
      "moved",
      "one",
      "business",
      "conditions",
      "change.",
      "scalable",
      "multi-tenant",
      "architecture",
      "makes",
      "easy",
      "install",
      "configure",
      "run.",
      "customers",
      "administrators",
      "worked",
      "products",
      "find",
      "areas",
      "different",
      "especially",
      "aren",
      "itil",
      "compliant.",
      "document",
      "attempts",
      "highlight",
      "explain",
      "important",
      "concepts",
      "functionality",
      "new",
      "intuitive",
      "users",
      "familiar",
      "product."
    ],
    "language": "en",
    "word_count": 86,
    "importance_score": 6.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "way of working",
    "contentLower": "introduction service management is the first application suite for it and enterprise service and asset management built on native machine learning, analytics, cmdb, and discovery. the out-of-the-box, extensible, best practices and completely codeless configuration means faster time-to-market for implementations. it can be deployed on-premise, in private or public cloud, or moved from one to the other as business conditions change. its scalable, multi-tenant, architecture makes it easy to install, configure, and run. customers (and their administrators) that have worked with other products may find some areas in service management different than they are used to -- especially products that aren't itil compliant. this document attempts to highlight and explain some of the important concepts and functionality within service management that may be new or not intuitive to users not familiar with the product. this document, as well as the related documents linked here, will continue to evolv",
    "keywordsLower": [
      "way",
      "working",
      "introduction",
      "high",
      "level",
      "guidance",
      "stay",
      "close",
      "home",
      "out",
      "box",
      "don",
      "create",
      "next",
      "buggy",
      "whip",
      "trying",
      "reimplement",
      "old",
      "system",
      "inside",
      "service",
      "management",
      "processes",
      "request",
      "vs.",
      "incident",
      "together",
      "reopen",
      "records",
      "configuration",
      "services",
      "designing",
      "catalog",
      "workflows",
      "modifying",
      "forms",
      "first",
      "application",
      "suite",
      "enterprise",
      "asset",
      "built",
      "native",
      "machine",
      "learning",
      "analytics",
      "cmdb",
      "discovery.",
      "out-of-the-box",
      "extensible",
      "best",
      "practices",
      "completely",
      "codeless",
      "means",
      "faster",
      "time-to-market",
      "implementations.",
      "deployed",
      "on-premise",
      "private",
      "public",
      "cloud",
      "moved",
      "one",
      "business",
      "conditions",
      "change.",
      "scalable",
      "multi-tenant",
      "architecture",
      "makes",
      "easy",
      "install",
      "configure",
      "run.",
      "customers",
      "administrators",
      "worked",
      "products",
      "find",
      "areas",
      "different",
      "especially",
      "aren",
      "itil",
      "compliant.",
      "document",
      "attempts",
      "highlight",
      "explain",
      "important",
      "concepts",
      "functionality",
      "new",
      "intuitive",
      "users",
      "familiar",
      "product."
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Using Offerings to Update People",
    "content": "Introduction In Service Management Automation-X it is not possible for an agent to create or modify person information without the having the tenant admin role. In some cases, system administrators do not want agents to have the tenant admin role but they still want the agent to create or modify a Person. By using offerings, it is also possible to allow self-service users themselves to update profile information not otherwise available. Using offerings is an option that would allow a non-tenant admin user to be able to perform these actions. Use Case Company ABC wants to allow agents who do not possess the tenant admin role to create or modify contact information. Company ABC wants self-service users to modify a few fields on their own profiles. The company plans to use two offerings in order to satisfy the requirement. Company ABC will use an audience to limit users who can create accounts, while all self-service users can update their own profile information. Configuration Steps - Su",
    "url": "wowofferingpeople",
    "filename": "wowofferingpeople",
    "headings": [
      "Introduction",
      "Use Case",
      "Configuration Steps - Summary",
      "Configuration Steps - Detail",
      "1. Create an offering to create contacts",
      "2. Create user options to define the fields to be populated",
      "3. Create task plan in the offering to populate the new contact fields with user options",
      "4. Assigning entitlement rules to the offering",
      "5. Create an offering to modify contact\\user information",
      "6. Create user options in the offering",
      "7. Create task plan in the offering to update the fields"
    ],
    "keywords": [
      "RequestForPerson.Id",
      "offerings",
      "update",
      "people",
      "introduction",
      "case",
      "configuration",
      "steps",
      "summary",
      "detail",
      "1.",
      "create",
      "offering",
      "contacts",
      "2.",
      "user",
      "options",
      "define",
      "fields",
      "populated",
      "3.",
      "task",
      "plan",
      "populate",
      "new",
      "contact",
      "4.",
      "assigning",
      "entitlement",
      "rules",
      "5.",
      "modify",
      "information",
      "6.",
      "7.",
      "service",
      "management",
      "automation-x",
      "possible",
      "agent",
      "person",
      "having",
      "tenant",
      "admin",
      "role.",
      "cases",
      "system",
      "administrators",
      "want",
      "agents",
      "role",
      "still",
      "person.",
      "allow",
      "self-service",
      "users",
      "themselves",
      "profile",
      "otherwise",
      "available.",
      "option",
      "non-tenant",
      "able",
      "perform",
      "actions.",
      "company",
      "abc",
      "wants",
      "possess",
      "information.",
      "few",
      "own",
      "profiles.",
      "plans",
      "two",
      "order",
      "satisfy",
      "requirement.",
      "audience",
      "limit",
      "accounts",
      "while",
      "all",
      "assign",
      "offering.",
      "updated",
      "catalog",
      "named",
      "contact.",
      "click",
      "tab",
      "created",
      "previous",
      "step.",
      "need",
      "record.",
      "note",
      "several",
      "required",
      "creating"
    ],
    "language": "en",
    "word_count": 100,
    "importance_score": 6.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "using offerings to update people",
    "contentLower": "introduction in service management automation-x it is not possible for an agent to create or modify person information without the having the tenant admin role. in some cases, system administrators do not want agents to have the tenant admin role but they still want the agent to create or modify a person. by using offerings, it is also possible to allow self-service users themselves to update profile information not otherwise available. using offerings is an option that would allow a non-tenant admin user to be able to perform these actions. use case company abc wants to allow agents who do not possess the tenant admin role to create or modify contact information. company abc wants self-service users to modify a few fields on their own profiles. the company plans to use two offerings in order to satisfy the requirement. company abc will use an audience to limit users who can create accounts, while all self-service users can update their own profile information. configuration steps - su",
    "keywordsLower": [
      "requestforperson.id",
      "offerings",
      "update",
      "people",
      "introduction",
      "case",
      "configuration",
      "steps",
      "summary",
      "detail",
      "1.",
      "create",
      "offering",
      "contacts",
      "2.",
      "user",
      "options",
      "define",
      "fields",
      "populated",
      "3.",
      "task",
      "plan",
      "populate",
      "new",
      "contact",
      "4.",
      "assigning",
      "entitlement",
      "rules",
      "5.",
      "modify",
      "information",
      "6.",
      "7.",
      "service",
      "management",
      "automation-x",
      "possible",
      "agent",
      "person",
      "having",
      "tenant",
      "admin",
      "role.",
      "cases",
      "system",
      "administrators",
      "want",
      "agents",
      "role",
      "still",
      "person.",
      "allow",
      "self-service",
      "users",
      "themselves",
      "profile",
      "otherwise",
      "available.",
      "option",
      "non-tenant",
      "able",
      "perform",
      "actions.",
      "company",
      "abc",
      "wants",
      "possess",
      "information.",
      "few",
      "own",
      "profiles.",
      "plans",
      "two",
      "order",
      "satisfy",
      "requirement.",
      "audience",
      "limit",
      "accounts",
      "while",
      "all",
      "assign",
      "offering.",
      "updated",
      "catalog",
      "named",
      "contact.",
      "click",
      "tab",
      "created",
      "previous",
      "step.",
      "need",
      "record.",
      "note",
      "several",
      "required",
      "creating"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Using Power BI to Create Reports",
    "content": "Introduction Service Management Automation-X includes a BI sync feature that allows users to download entity data and relationships in order to create reports in external tools. Microsoft Power BI is able to use the data exported from Service Management Automation-X to generate customized reports. This document describes how to use the data created by the sync process to create reports in Power BI. Use Case Company ABC wants to create a report that will list Requests with their SLT next target time as well as the target status. The report must allow the ability to filter by offering, service or assignment group. Configuration Steps - Summary Add the record types and fields required to be able to generate the desired reports Execute the REST call to generate data Download the data Import the data into Power BI Add display names for the service, group and offering Refresh the data Load and combine multiple files Configuration Steps - Detail 1. Add the record types and fields required to ",
    "url": "wowrptpowerbi",
    "filename": "wowrptpowerbi",
    "headings": [
      "Introduction",
      "Use Case",
      "Configuration Steps - Summary",
      "Configuration Steps - Detail",
      "1. Add the record types and fields required to be able to generate the desired reports",
      "2. Execute the REST call to generate data",
      "3. Download the data",
      "4. Import the data into Power BI",
      "5. Add display names for the service, group, and offering",
      "6. Refresh the data",
      "7. Load and combine multiple files"
    ],
    "keywords": [
      "https://$testmachineandport/rest/$tenantId/bi/initial",
      "https://$testmachineandport/rest/$tenantId/bi/status/<syncId",
      "https://$testmachineandport/rest/$tenantId/frs/file-list/<FileID",
      "Request_1.csv",
      "Request_2.csv",
      "Request_0.csv",
      "power",
      "bi",
      "create",
      "reports",
      "introduction",
      "case",
      "configuration",
      "steps",
      "summary",
      "detail",
      "1.",
      "add",
      "record",
      "types",
      "fields",
      "required",
      "able",
      "generate",
      "desired",
      "2.",
      "execute",
      "rest",
      "call",
      "data",
      "3.",
      "download",
      "4.",
      "import",
      "5.",
      "display",
      "names",
      "service",
      "group",
      "offering",
      "6.",
      "refresh",
      "7.",
      "load",
      "combine",
      "multiple",
      "files",
      "management",
      "automation-x",
      "includes",
      "sync",
      "feature",
      "allows",
      "users",
      "entity",
      "relationships",
      "order",
      "external",
      "tools.",
      "microsoft",
      "exported",
      "customized",
      "reports.",
      "document",
      "describes",
      "created",
      "process",
      "bi.",
      "company",
      "abc",
      "wants",
      "report",
      "list",
      "requests",
      "slt",
      "next",
      "target",
      "time",
      "well",
      "status.",
      "allow",
      "ability",
      "filter",
      "assignment",
      "group.",
      "export",
      "all",
      "transactional",
      "available",
      "automation-x.",
      "interface",
      "select",
      "actual",
      "agreement",
      "status",
      "request.",
      "include",
      "need",
      "selected.",
      "inside"
    ],
    "language": "en",
    "word_count": 112,
    "importance_score": 5.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "using power bi to create reports",
    "contentLower": "introduction service management automation-x includes a bi sync feature that allows users to download entity data and relationships in order to create reports in external tools. microsoft power bi is able to use the data exported from service management automation-x to generate customized reports. this document describes how to use the data created by the sync process to create reports in power bi. use case company abc wants to create a report that will list requests with their slt next target time as well as the target status. the report must allow the ability to filter by offering, service or assignment group. configuration steps - summary add the record types and fields required to be able to generate the desired reports execute the rest call to generate data download the data import the data into power bi add display names for the service, group and offering refresh the data load and combine multiple files configuration steps - detail 1. add the record types and fields required to ",
    "keywordsLower": [
      "https://$testmachineandport/rest/$tenantid/bi/initial",
      "https://$testmachineandport/rest/$tenantid/bi/status/<syncid",
      "https://$testmachineandport/rest/$tenantid/frs/file-list/<fileid",
      "request_1.csv",
      "request_2.csv",
      "request_0.csv",
      "power",
      "bi",
      "create",
      "reports",
      "introduction",
      "case",
      "configuration",
      "steps",
      "summary",
      "detail",
      "1.",
      "add",
      "record",
      "types",
      "fields",
      "required",
      "able",
      "generate",
      "desired",
      "2.",
      "execute",
      "rest",
      "call",
      "data",
      "3.",
      "download",
      "4.",
      "import",
      "5.",
      "display",
      "names",
      "service",
      "group",
      "offering",
      "6.",
      "refresh",
      "7.",
      "load",
      "combine",
      "multiple",
      "files",
      "management",
      "automation-x",
      "includes",
      "sync",
      "feature",
      "allows",
      "users",
      "entity",
      "relationships",
      "order",
      "external",
      "tools.",
      "microsoft",
      "exported",
      "customized",
      "reports.",
      "document",
      "describes",
      "created",
      "process",
      "bi.",
      "company",
      "abc",
      "wants",
      "report",
      "list",
      "requests",
      "slt",
      "next",
      "target",
      "time",
      "well",
      "status.",
      "allow",
      "ability",
      "filter",
      "assignment",
      "group.",
      "export",
      "all",
      "transactional",
      "available",
      "automation-x.",
      "interface",
      "select",
      "actual",
      "agreement",
      "status",
      "request.",
      "include",
      "need",
      "selected.",
      "inside"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "UCMDB Integration",
    "content": "IntroductionService Management provides an integration with the UCMDB that synchronizes Service Asset & Configuration Management (SACM) information. The UCMDB integration uses the On-Premises Bridge (OPB) to connect to an external UCMDB to synchronize Actual Services, Service Components, System Elements and Assets to the Service Management repository. This document provides detailed information regarding the configuration of this integration.This information includes:Installing the OPB AgentCreating an EndpointConfiguring SSL for OPBConfiguring the UCMDB EndpointVerifying Data SynchronizationTroubleshooting Installing the OPB AgentLogin to the desired tenant within Service Management with a user that has Tenant Admin privileges. If you login to the Service Portal, switch to the Agent Interface.From the main menu, navigate to the Integration area under Administration > Utilities.Ensure the Agents section is selected (from the header menu bar) and click on Download agent to copy the agen",
    "url": "wow_ucmdb_integration",
    "filename": "wow_ucmdb_integration",
    "headings": [
      "Introduction",
      "Installing the OPB Agent",
      "Creating an Endpoint",
      "Configuring SSL for OPB",
      "Export UCMDB Server Certificate",
      "Import UCMDB Server Certificate",
      "Configuring the UCMDB Endpoint",
      "Verifying Data Synchronization",
      "Apply update for using Aviator in cross-domain integration",
      "Aviator limitations in cross-domain integration scenarios",
      "Troubleshooting"
    ],
    "keywords": [
      "integration.This",
      "Interface.From",
      "servers.If",
      "issues.The",
      "Management.The",
      "upgrade.The",
      "10.20",
      "Management.To",
      "Save.If",
      "Endpoint.Open",
      "ucmdbserver.cert",
      "computer.Copy",
      "Management.Once",
      "values.yaml",
      "configuration.Run",
      "Add.This",
      "Integration.Note",
      "OPB.If",
      "keytool.exe",
      "place.On",
      "file.The",
      "ucmdb",
      "integration",
      "introduction",
      "installing",
      "opb",
      "agent",
      "creating",
      "endpoint",
      "configuring",
      "ssl",
      "export",
      "server",
      "certificate",
      "import",
      "verifying",
      "data",
      "synchronization",
      "apply",
      "update",
      "aviator",
      "cross-domain",
      "limitations",
      "scenarios",
      "troubleshooting",
      "introductionservice",
      "management",
      "provides",
      "synchronizes",
      "service",
      "asset",
      "configuration",
      "sacm",
      "information.",
      "uses",
      "on-premises",
      "bridge",
      "connect",
      "external",
      "synchronize",
      "actual",
      "services",
      "components",
      "system",
      "elements",
      "assets",
      "repository.",
      "document",
      "detailed",
      "information",
      "regarding",
      "includes",
      "agentcreating",
      "endpointconfiguring",
      "opbconfiguring",
      "endpointverifying",
      "synchronizationtroubleshooting",
      "agentlogin",
      "desired",
      "tenant",
      "user",
      "admin",
      "privileges.",
      "login",
      "portal",
      "switch",
      "main",
      "menu",
      "navigate",
      "area",
      "under",
      "administration",
      "utilities.ensure",
      "agents",
      "section",
      "selected",
      "header",
      "bar",
      "click",
      "download"
    ],
    "language": "en",
    "word_count": 89,
    "importance_score": 6.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "ucmdb integration",
    "contentLower": "introductionservice management provides an integration with the ucmdb that synchronizes service asset & configuration management (sacm) information. the ucmdb integration uses the on-premises bridge (opb) to connect to an external ucmdb to synchronize actual services, service components, system elements and assets to the service management repository. this document provides detailed information regarding the configuration of this integration.this information includes:installing the opb agentcreating an endpointconfiguring ssl for opbconfiguring the ucmdb endpointverifying data synchronizationtroubleshooting installing the opb agentlogin to the desired tenant within service management with a user that has tenant admin privileges. if you login to the service portal, switch to the agent interface.from the main menu, navigate to the integration area under administration > utilities.ensure the agents section is selected (from the header menu bar) and click on download agent to copy the agen",
    "keywordsLower": [
      "integration.this",
      "interface.from",
      "servers.if",
      "issues.the",
      "management.the",
      "upgrade.the",
      "10.20",
      "management.to",
      "save.if",
      "endpoint.open",
      "ucmdbserver.cert",
      "computer.copy",
      "management.once",
      "values.yaml",
      "configuration.run",
      "add.this",
      "integration.note",
      "opb.if",
      "keytool.exe",
      "place.on",
      "file.the",
      "ucmdb",
      "integration",
      "introduction",
      "installing",
      "opb",
      "agent",
      "creating",
      "endpoint",
      "configuring",
      "ssl",
      "export",
      "server",
      "certificate",
      "import",
      "verifying",
      "data",
      "synchronization",
      "apply",
      "update",
      "aviator",
      "cross-domain",
      "limitations",
      "scenarios",
      "troubleshooting",
      "introductionservice",
      "management",
      "provides",
      "synchronizes",
      "service",
      "asset",
      "configuration",
      "sacm",
      "information.",
      "uses",
      "on-premises",
      "bridge",
      "connect",
      "external",
      "synchronize",
      "actual",
      "services",
      "components",
      "system",
      "elements",
      "assets",
      "repository.",
      "document",
      "detailed",
      "information",
      "regarding",
      "includes",
      "agentcreating",
      "endpointconfiguring",
      "opbconfiguring",
      "endpointverifying",
      "synchronizationtroubleshooting",
      "agentlogin",
      "desired",
      "tenant",
      "user",
      "admin",
      "privileges.",
      "login",
      "portal",
      "switch",
      "main",
      "menu",
      "navigate",
      "area",
      "under",
      "administration",
      "utilities.ensure",
      "agents",
      "section",
      "selected",
      "header",
      "bar",
      "click",
      "download"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Working with Forms",
    "content": "Every record type in Service Management has a pre-defined set of forms for displaying information. The specific form (or sometimes forms) shown to the user may depend on what phase of the workflow the records is currently in or what action the user is taking. It's not possible to create new forms. This restriction ensures a common look and behavior for all records of a certain type, leading to increased productivity for the end user as the fields are always in the same place for each record. While Service Management doesn't allow the creation of new forms, there are several methods available to customize a form based on specific requirements. The two primary methods involve business rules and models. Business Rules There are several business rule templates available that allow modifications to a form based on defined conditions. Which rule to use depends on the type of change you are trying to make. These rules include: Disabling a field Expanding a section Hiding a field Hiding a sect",
    "url": "workingwithforms",
    "filename": "workingwithforms",
    "headings": [
      "Business Rules",
      "Hiding sections based on phase"
    ],
    "keywords": [
      "working",
      "forms",
      "business",
      "rules",
      "hiding",
      "sections",
      "based",
      "phase",
      "every",
      "record",
      "type",
      "service",
      "management",
      "pre-defined",
      "set",
      "displaying",
      "information.",
      "specific",
      "form",
      "sometimes",
      "shown",
      "user",
      "depend",
      "what",
      "workflow",
      "records",
      "currently",
      "action",
      "taking.",
      "possible",
      "create",
      "new",
      "forms.",
      "restriction",
      "ensures",
      "common",
      "look",
      "behavior",
      "all",
      "certain",
      "leading",
      "increased",
      "productivity",
      "end",
      "fields",
      "always",
      "same",
      "place",
      "record.",
      "while",
      "doesn",
      "allow",
      "creation",
      "there",
      "several",
      "methods",
      "available",
      "customize",
      "requirements.",
      "two",
      "primary",
      "involve",
      "models.",
      "rule",
      "templates",
      "modifications",
      "defined",
      "conditions.",
      "depends",
      "change",
      "trying",
      "make.",
      "include",
      "disabling",
      "field",
      "expanding",
      "section",
      "tab",
      "restricting",
      "allowing",
      "editing",
      "modified",
      "criteria",
      "such",
      "current",
      "model",
      "any",
      "information",
      "stored",
      "itself.",
      "too",
      "many",
      "examples",
      "list",
      "here",
      "following",
      "represents",
      "cases.",
      "process",
      "often"
    ],
    "language": "en",
    "word_count": 107,
    "importance_score": 4.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "working with forms",
    "contentLower": "every record type in service management has a pre-defined set of forms for displaying information. the specific form (or sometimes forms) shown to the user may depend on what phase of the workflow the records is currently in or what action the user is taking. it's not possible to create new forms. this restriction ensures a common look and behavior for all records of a certain type, leading to increased productivity for the end user as the fields are always in the same place for each record. while service management doesn't allow the creation of new forms, there are several methods available to customize a form based on specific requirements. the two primary methods involve business rules and models. business rules there are several business rule templates available that allow modifications to a form based on defined conditions. which rule to use depends on the type of change you are trying to make. these rules include: disabling a field expanding a section hiding a field hiding a sect",
    "keywordsLower": [
      "working",
      "forms",
      "business",
      "rules",
      "hiding",
      "sections",
      "based",
      "phase",
      "every",
      "record",
      "type",
      "service",
      "management",
      "pre-defined",
      "set",
      "displaying",
      "information.",
      "specific",
      "form",
      "sometimes",
      "shown",
      "user",
      "depend",
      "what",
      "workflow",
      "records",
      "currently",
      "action",
      "taking.",
      "possible",
      "create",
      "new",
      "forms.",
      "restriction",
      "ensures",
      "common",
      "look",
      "behavior",
      "all",
      "certain",
      "leading",
      "increased",
      "productivity",
      "end",
      "fields",
      "always",
      "same",
      "place",
      "record.",
      "while",
      "doesn",
      "allow",
      "creation",
      "there",
      "several",
      "methods",
      "available",
      "customize",
      "requirements.",
      "two",
      "primary",
      "involve",
      "models.",
      "rule",
      "templates",
      "modifications",
      "defined",
      "conditions.",
      "depends",
      "change",
      "trying",
      "make.",
      "include",
      "disabling",
      "field",
      "expanding",
      "section",
      "tab",
      "restricting",
      "allowing",
      "editing",
      "modified",
      "criteria",
      "such",
      "current",
      "model",
      "any",
      "information",
      "stored",
      "itself.",
      "too",
      "many",
      "examples",
      "list",
      "here",
      "following",
      "represents",
      "cases.",
      "process",
      "often"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Use cases",
    "content": "This section covers the Customer Service Management (CSM) related use cases. We believe these use cases are important to understand the CSM added functionality to use it properly.",
    "url": "csmusecases",
    "filename": "csmusecases",
    "headings": [],
    "keywords": [
      "cases",
      "section",
      "covers",
      "customer",
      "service",
      "management",
      "csm",
      "related",
      "cases.",
      "believe",
      "important",
      "understand",
      "added",
      "functionality",
      "properly."
    ],
    "language": "en",
    "word_count": 17,
    "importance_score": 2.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "use cases",
    "contentLower": "this section covers the customer service management (csm) related use cases. we believe these use cases are important to understand the csm added functionality to use it properly.",
    "keywordsLower": [
      "cases",
      "section",
      "covers",
      "customer",
      "service",
      "management",
      "csm",
      "related",
      "cases.",
      "believe",
      "important",
      "understand",
      "added",
      "functionality",
      "properly."
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Working with Product models and Product instances",
    "content": "Product models Product models represent the products a company is selling. Product models can be a multi-level classification you can use to structure your products to help define how they are managed. A product model can be of type Category: A classification or grouping of similar products. Product: An individual product. Bundle: A collection of multiple products that are packaged together and offered as a single unit to the user. Product models can have versions and modules. Product versions define the available versions of a product, including the maintenance dates. Product modules allow breaking down the product into components, which can be used in the request handling to classify and route the requests. User options can be used to have one product model for several variants of the product. For example, if there is a product available in green, red or blue, you can add an user option color, which is then set when the product model is instantiated. There is no need to have a produc",
    "url": "productmanagement",
    "filename": "productmanagement",
    "headings": [
      "Product models",
      "Product instance",
      "Simple product model structure",
      "Simple product model structure with bundle",
      "Advanced product model structure"
    ],
    "keywords": [
      "forms.Add",
      "working",
      "product",
      "models",
      "instances",
      "instance",
      "simple",
      "model",
      "structure",
      "bundle",
      "advanced",
      "represent",
      "products",
      "company",
      "selling.",
      "multi-level",
      "classification",
      "help",
      "define",
      "managed.",
      "type",
      "category",
      "grouping",
      "similar",
      "products.",
      "individual",
      "product.",
      "collection",
      "multiple",
      "packaged",
      "together",
      "offered",
      "single",
      "unit",
      "user.",
      "versions",
      "modules.",
      "available",
      "including",
      "maintenance",
      "dates.",
      "modules",
      "allow",
      "breaking",
      "components",
      "request",
      "handling",
      "classify",
      "route",
      "requests.",
      "user",
      "options",
      "one",
      "several",
      "variants",
      "example",
      "there",
      "green",
      "red",
      "blue",
      "add",
      "option",
      "color",
      "set",
      "instantiated.",
      "need",
      "color.",
      "often",
      "first",
      "level",
      "software.",
      "next",
      "software",
      "on.",
      "related",
      "offerings",
      "articles.",
      "ensures",
      "users",
      "entitlement",
      "see",
      "article",
      "offering.",
      "case",
      "hierarchical",
      "supported",
      "parent",
      "offering",
      "restrict",
      "access",
      "child",
      "models.",
      "sold",
      "customer.",
      "become",
      "instance.",
      "inherits",
      "all",
      "configured",
      "track"
    ],
    "language": "en",
    "word_count": 93,
    "importance_score": 4.5,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "working with product models and product instances",
    "contentLower": "product models product models represent the products a company is selling. product models can be a multi-level classification you can use to structure your products to help define how they are managed. a product model can be of type category: a classification or grouping of similar products. product: an individual product. bundle: a collection of multiple products that are packaged together and offered as a single unit to the user. product models can have versions and modules. product versions define the available versions of a product, including the maintenance dates. product modules allow breaking down the product into components, which can be used in the request handling to classify and route the requests. user options can be used to have one product model for several variants of the product. for example, if there is a product available in green, red or blue, you can add an user option color, which is then set when the product model is instantiated. there is no need to have a produc",
    "keywordsLower": [
      "forms.add",
      "working",
      "product",
      "models",
      "instances",
      "instance",
      "simple",
      "model",
      "structure",
      "bundle",
      "advanced",
      "represent",
      "products",
      "company",
      "selling.",
      "multi-level",
      "classification",
      "help",
      "define",
      "managed.",
      "type",
      "category",
      "grouping",
      "similar",
      "products.",
      "individual",
      "product.",
      "collection",
      "multiple",
      "packaged",
      "together",
      "offered",
      "single",
      "unit",
      "user.",
      "versions",
      "modules.",
      "available",
      "including",
      "maintenance",
      "dates.",
      "modules",
      "allow",
      "breaking",
      "components",
      "request",
      "handling",
      "classify",
      "route",
      "requests.",
      "user",
      "options",
      "one",
      "several",
      "variants",
      "example",
      "there",
      "green",
      "red",
      "blue",
      "add",
      "option",
      "color",
      "set",
      "instantiated.",
      "need",
      "color.",
      "often",
      "first",
      "level",
      "software.",
      "next",
      "software",
      "on.",
      "related",
      "offerings",
      "articles.",
      "ensures",
      "users",
      "entitlement",
      "see",
      "article",
      "offering.",
      "case",
      "hierarchical",
      "supported",
      "parent",
      "offering",
      "restrict",
      "access",
      "child",
      "models.",
      "sold",
      "customer.",
      "become",
      "instance.",
      "inherits",
      "all",
      "configured",
      "track"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Working with Entitlements",
    "content": "In the context of Customer Service Management (CSM), entitlements refer to the predefined rights, permissions, or services that a customer is entitled to receive as part of their relationship with a company. These entitlements outline what services, support, or benefits a customer can access based on factors such as their service agreement, product purchases, subscription type, or contract. Key aspects Product or Service Coverage: Entitlements can specify which products or services are covered under customer support. For instance, a customer who has purchased an extended warranty may be entitled to free repairs for a certain period or support for additional features.Support Channels: Entitlements may also determine which channels of support the customer can use. For example, some customers may be entitled to support via phone and chat, while others may only have access to email support or a self-service portal.Number of Requests or Cases: Entitlements can also limit the number of cases",
    "url": "entitlementexamples",
    "filename": "entitlementexamples",
    "headings": [
      "Key aspects",
      "How entitlements work",
      "Use case 1 - Customer entitlement",
      "Use case 2 - Customer entitlement delegated to a partner",
      "Use case 3 - Multi service provider entitlements with customer delegation"
    ],
    "keywords": [
      "market.Have",
      "B.Have",
      "working",
      "entitlements",
      "key",
      "aspects",
      "work",
      "case",
      "customer",
      "entitlement",
      "delegated",
      "partner",
      "multi",
      "service",
      "provider",
      "delegation",
      "context",
      "management",
      "csm",
      "refer",
      "predefined",
      "rights",
      "permissions",
      "services",
      "entitled",
      "receive",
      "part",
      "relationship",
      "company.",
      "outline",
      "what",
      "support",
      "benefits",
      "access",
      "based",
      "factors",
      "such",
      "agreement",
      "product",
      "purchases",
      "subscription",
      "type",
      "contract.",
      "coverage",
      "specify",
      "products",
      "covered",
      "under",
      "support.",
      "instance",
      "purchased",
      "extended",
      "warranty",
      "free",
      "repairs",
      "certain",
      "period",
      "additional",
      "features.support",
      "channels",
      "determine",
      "use.",
      "example",
      "customers",
      "via",
      "phone",
      "chat",
      "while",
      "others",
      "email",
      "self-service",
      "portal.number",
      "requests",
      "cases",
      "limit",
      "number",
      "incidents",
      "submit",
      "given",
      "time",
      "period.",
      "plan",
      "entitles",
      "five",
      "per",
      "year",
      "after",
      "charges",
      "apply.",
      "opentext",
      "differentiate",
      "between",
      "rules",
      "records.",
      "records",
      "document",
      "level",
      "users",
      "to.",
      "means"
    ],
    "language": "en",
    "word_count": 90,
    "importance_score": 5.5,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "working with entitlements",
    "contentLower": "in the context of customer service management (csm), entitlements refer to the predefined rights, permissions, or services that a customer is entitled to receive as part of their relationship with a company. these entitlements outline what services, support, or benefits a customer can access based on factors such as their service agreement, product purchases, subscription type, or contract. key aspects product or service coverage: entitlements can specify which products or services are covered under customer support. for instance, a customer who has purchased an extended warranty may be entitled to free repairs for a certain period or support for additional features.support channels: entitlements may also determine which channels of support the customer can use. for example, some customers may be entitled to support via phone and chat, while others may only have access to email support or a self-service portal.number of requests or cases: entitlements can also limit the number of cases",
    "keywordsLower": [
      "market.have",
      "b.have",
      "working",
      "entitlements",
      "key",
      "aspects",
      "work",
      "case",
      "customer",
      "entitlement",
      "delegated",
      "partner",
      "multi",
      "service",
      "provider",
      "delegation",
      "context",
      "management",
      "csm",
      "refer",
      "predefined",
      "rights",
      "permissions",
      "services",
      "entitled",
      "receive",
      "part",
      "relationship",
      "company.",
      "outline",
      "what",
      "support",
      "benefits",
      "access",
      "based",
      "factors",
      "such",
      "agreement",
      "product",
      "purchases",
      "subscription",
      "type",
      "contract.",
      "coverage",
      "specify",
      "products",
      "covered",
      "under",
      "support.",
      "instance",
      "purchased",
      "extended",
      "warranty",
      "free",
      "repairs",
      "certain",
      "period",
      "additional",
      "features.support",
      "channels",
      "determine",
      "use.",
      "example",
      "customers",
      "via",
      "phone",
      "chat",
      "while",
      "others",
      "email",
      "self-service",
      "portal.number",
      "requests",
      "cases",
      "limit",
      "number",
      "incidents",
      "submit",
      "given",
      "time",
      "period.",
      "plan",
      "entitles",
      "five",
      "per",
      "year",
      "after",
      "charges",
      "apply.",
      "opentext",
      "differentiate",
      "between",
      "rules",
      "records.",
      "records",
      "document",
      "level",
      "users",
      "to.",
      "means"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Use case",
    "content": "This section covers the use cases for the different capabilities. Software Asset Management (SAM) Manage software compliance using SAMCustomize service workflows against a license usage record Financial Management Control your budget using the Financial Management module Cloud Management Cloud Management - Design and deploy cloud offeringsCloud Management - Cloud Cost ReportingUse case: OPB endpoints of Design and DeployEnable IaC Gateway in Cloud Management",
    "url": "usecase",
    "filename": "usecase",
    "headings": [
      "Software Asset Management (SAM)",
      "Financial Management",
      "Cloud Management"
    ],
    "keywords": [
      "case",
      "software",
      "asset",
      "management",
      "sam",
      "financial",
      "cloud",
      "section",
      "covers",
      "cases",
      "different",
      "capabilities.",
      "manage",
      "compliance",
      "samcustomize",
      "service",
      "workflows",
      "against",
      "license",
      "usage",
      "record",
      "control",
      "budget",
      "module",
      "design",
      "deploy",
      "offeringscloud",
      "cost",
      "reportinguse",
      "opb",
      "endpoints",
      "deployenable",
      "iac",
      "gateway"
    ],
    "language": "en",
    "word_count": 48,
    "importance_score": 3.5,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "use case",
    "contentLower": "this section covers the use cases for the different capabilities. software asset management (sam) manage software compliance using samcustomize service workflows against a license usage record financial management control your budget using the financial management module cloud management cloud management - design and deploy cloud offeringscloud management - cloud cost reportinguse case: opb endpoints of design and deployenable iac gateway in cloud management",
    "keywordsLower": [
      "case",
      "software",
      "asset",
      "management",
      "sam",
      "financial",
      "cloud",
      "section",
      "covers",
      "cases",
      "different",
      "capabilities.",
      "manage",
      "compliance",
      "samcustomize",
      "service",
      "workflows",
      "against",
      "license",
      "usage",
      "record",
      "control",
      "budget",
      "module",
      "design",
      "deploy",
      "offeringscloud",
      "cost",
      "reportinguse",
      "opb",
      "endpoints",
      "deployenable",
      "iac",
      "gateway"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Use case: Budget control using the Financial Management module",
    "content": "Following a budget or spending plan helps an organization make full use of the buying and investing opportunities. The Financial Management module allows you to plan, execute, monitor, and control your budgets and expenditure in an efficient and effective way. This use case provides step-by-step instructions on how to manage your financial resources by comparing the actual expenditure incurred to the planned budget. With the budget and expense information, you can identify the corrective actions that are required to reach your financial goals. Concepts Here, we list some key concepts for you to get started: Fiscal year: enables you to specify a 12-month period as a fiscal year for your company Accounting period: enables you to specify any period of time within a fiscal year to cover a set of financial statements Budget center: enables you to manage and analyze the budgets and their allocation in an organization Budget: enables you to create, maintain, and track your budgeted costs Budg",
    "url": "budgetcontrolusingfm",
    "filename": "budgetcontrolusingfm",
    "headings": [
      "Concepts",
      "Navigate to Financial Management",
      "Workflow",
      "Create a fiscal year",
      "Create an accounting period",
      "Create a budget center",
      "Create a budget type",
      "Create a budget",
      "Create budget lines",
      "Create a cost center and link it to the budget center",
      "Create a cost type and link it to the budget type",
      "Create expense lines",
      "Compare expenditure with budget",
      "Troubleshoot",
      "Related topics"
    ],
    "keywords": [
      "case",
      "budget",
      "control",
      "financial",
      "management",
      "module",
      "concepts",
      "navigate",
      "workflow",
      "create",
      "fiscal",
      "year",
      "accounting",
      "period",
      "center",
      "type",
      "lines",
      "cost",
      "link",
      "expense",
      "compare",
      "expenditure",
      "troubleshoot",
      "related",
      "topics",
      "following",
      "spending",
      "plan",
      "helps",
      "organization",
      "make",
      "full",
      "buying",
      "investing",
      "opportunities.",
      "allows",
      "execute",
      "monitor",
      "budgets",
      "efficient",
      "effective",
      "way.",
      "provides",
      "step-by-step",
      "instructions",
      "manage",
      "resources",
      "comparing",
      "actual",
      "incurred",
      "planned",
      "budget.",
      "information",
      "identify",
      "corrective",
      "actions",
      "required",
      "reach",
      "goals.",
      "here",
      "list",
      "key",
      "get",
      "started",
      "enables",
      "specify",
      "12-month",
      "company",
      "any",
      "time",
      "cover",
      "set",
      "statements",
      "analyze",
      "allocation",
      "maintain",
      "track",
      "budgeted",
      "costs",
      "defines",
      "different",
      "kinds",
      "based",
      "common",
      "characteristics",
      "aggregates",
      "categorizes",
      "types",
      "perspective",
      "line",
      "amount",
      "given",
      "both",
      "projected",
      "sign",
      "service",
      "management.",
      "main",
      "menu",
      "choose"
    ],
    "language": "en",
    "word_count": 98,
    "importance_score": 5.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "use case: budget control using the financial management module",
    "contentLower": "following a budget or spending plan helps an organization make full use of the buying and investing opportunities. the financial management module allows you to plan, execute, monitor, and control your budgets and expenditure in an efficient and effective way. this use case provides step-by-step instructions on how to manage your financial resources by comparing the actual expenditure incurred to the planned budget. with the budget and expense information, you can identify the corrective actions that are required to reach your financial goals. concepts here, we list some key concepts for you to get started: fiscal year: enables you to specify a 12-month period as a fiscal year for your company accounting period: enables you to specify any period of time within a fiscal year to cover a set of financial statements budget center: enables you to manage and analyze the budgets and their allocation in an organization budget: enables you to create, maintain, and track your budgeted costs budg",
    "keywordsLower": [
      "case",
      "budget",
      "control",
      "financial",
      "management",
      "module",
      "concepts",
      "navigate",
      "workflow",
      "create",
      "fiscal",
      "year",
      "accounting",
      "period",
      "center",
      "type",
      "lines",
      "cost",
      "link",
      "expense",
      "compare",
      "expenditure",
      "troubleshoot",
      "related",
      "topics",
      "following",
      "spending",
      "plan",
      "helps",
      "organization",
      "make",
      "full",
      "buying",
      "investing",
      "opportunities.",
      "allows",
      "execute",
      "monitor",
      "budgets",
      "efficient",
      "effective",
      "way.",
      "provides",
      "step-by-step",
      "instructions",
      "manage",
      "resources",
      "comparing",
      "actual",
      "incurred",
      "planned",
      "budget.",
      "information",
      "identify",
      "corrective",
      "actions",
      "required",
      "reach",
      "goals.",
      "here",
      "list",
      "key",
      "get",
      "started",
      "enables",
      "specify",
      "12-month",
      "company",
      "any",
      "time",
      "cover",
      "set",
      "statements",
      "analyze",
      "allocation",
      "maintain",
      "track",
      "budgeted",
      "costs",
      "defines",
      "different",
      "kinds",
      "based",
      "common",
      "characteristics",
      "aggregates",
      "categorizes",
      "types",
      "perspective",
      "line",
      "amount",
      "given",
      "both",
      "projected",
      "sign",
      "service",
      "management.",
      "main",
      "menu",
      "choose"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Use case - VMware vCenter Capsule",
    "content": "Mark Tyler, a developer, wants to deploy a virtual machine. Mark has to subscribe to a VMware vCenter service offering through the Service Portal. He can go to the Service Portal, browse for the offering, and request it. For the VMware vCenter offering to be available in the Service Portal, the administrator should use the VMware vCenter capsule and make use of the service design, publish and configure it. Personas The following table shows the personas involved in getting the VMware vCenter cloud offering in the Service Portal: Persona Responsibilities Sandra - Suite administrator Configure tenant and enable Design and Deploy (DND) capability Oliver Twist - Tenant Administrator Administer tenant and configure user authorization Add Aggregation Provider Ray Smith - DND Administrator Create and publish a VMware vCenter service design Add the published design to the catalog Approve a service request Mark Tyler - Service Portal User/ Developer Request for a cloud service offering from the",
    "url": "usecasevmwarevcentercapsule",
    "filename": "usecasevmwarevcentercapsule",
    "headings": [
      "Personas",
      "Prerequisites",
      "Use case",
      "Configure Suite Administration",
      "Configure email",
      "Create Customer, Account, and Users",
      "Create a customer",
      "Create Account",
      "Create Users",
      "Mark - Service Portal user",
      "Oliver - Tenant administrator",
      "Ray - DND Administrator",
      "DND_Integration_admin - DND integration user",
      "Configure Cloud Management License",
      "Create a license",
      "Create a license pool",
      "Add the license to the license pool",
      "Go to the license created earlier.",
      "In the License pool field, select the license pool created in the above section from the drop-down menu and save the changes.",
      "Create and configure a tenant"
    ],
    "keywords": [
      "https://<OO_HOST>:<OO_PORT>/autopass",
      "https://<hostname>/bo",
      "https://<OO_HOST>:<OO_PORT",
      "http://www.vmware.com/support/pubs",
      "https://itom-dnd-controller-svc:8444/dnd",
      "vmware.com",
      "https://<vCenter-Server>:443",
      "https://<External",
      "example.com",
      "https://myoohost.example.com:9443",
      "Sync.xml",
      "case",
      "vmware",
      "vcenter",
      "capsule",
      "personas",
      "prerequisites",
      "configure",
      "suite",
      "administration",
      "email",
      "create",
      "customer",
      "account",
      "users",
      "mark",
      "service",
      "portal",
      "user",
      "oliver",
      "tenant",
      "administrator",
      "ray",
      "dnd",
      "integration",
      "cloud",
      "management",
      "license",
      "pool",
      "add",
      "go",
      "created",
      "earlier.",
      "field",
      "select",
      "above",
      "section",
      "drop-down",
      "menu",
      "save",
      "changes.",
      "assign",
      "admin",
      "deploy",
      "oo",
      "capability",
      "authorization",
      "authorize",
      "idm",
      "role",
      "visibility",
      "publish",
      "instance",
      "offering",
      "application",
      "settings",
      "aggregation",
      "provider",
      "install",
      "latest",
      "content",
      "store",
      "resource",
      "system",
      "properties",
      "synchronize",
      "resources",
      "associate",
      "offerings",
      "component",
      "templates",
      "design",
      "catalog",
      "definition",
      "aggregated",
      "subscribe",
      "subscription",
      "approve",
      "request",
      "view",
      "status",
      "deployment",
      "operations",
      "details",
      "accept",
      "solution",
      "related",
      "topics",
      "tyler",
      "developer"
    ],
    "language": "en",
    "word_count": 107,
    "importance_score": 5.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "use case - vmware vcenter capsule",
    "contentLower": "mark tyler, a developer, wants to deploy a virtual machine. mark has to subscribe to a vmware vcenter service offering through the service portal. he can go to the service portal, browse for the offering, and request it. for the vmware vcenter offering to be available in the service portal, the administrator should use the vmware vcenter capsule and make use of the service design, publish and configure it. personas the following table shows the personas involved in getting the vmware vcenter cloud offering in the service portal: persona responsibilities sandra - suite administrator configure tenant and enable design and deploy (dnd) capability oliver twist - tenant administrator administer tenant and configure user authorization add aggregation provider ray smith - dnd administrator create and publish a vmware vcenter service design add the published design to the catalog approve a service request mark tyler - service portal user/ developer request for a cloud service offering from the",
    "keywordsLower": [
      "https://<oo_host>:<oo_port>/autopass",
      "https://<hostname>/bo",
      "https://<oo_host>:<oo_port",
      "http://www.vmware.com/support/pubs",
      "https://itom-dnd-controller-svc:8444/dnd",
      "vmware.com",
      "https://<vcenter-server>:443",
      "https://<external",
      "example.com",
      "https://myoohost.example.com:9443",
      "sync.xml",
      "case",
      "vmware",
      "vcenter",
      "capsule",
      "personas",
      "prerequisites",
      "configure",
      "suite",
      "administration",
      "email",
      "create",
      "customer",
      "account",
      "users",
      "mark",
      "service",
      "portal",
      "user",
      "oliver",
      "tenant",
      "administrator",
      "ray",
      "dnd",
      "integration",
      "cloud",
      "management",
      "license",
      "pool",
      "add",
      "go",
      "created",
      "earlier.",
      "field",
      "select",
      "above",
      "section",
      "drop-down",
      "menu",
      "save",
      "changes.",
      "assign",
      "admin",
      "deploy",
      "oo",
      "capability",
      "authorization",
      "authorize",
      "idm",
      "role",
      "visibility",
      "publish",
      "instance",
      "offering",
      "application",
      "settings",
      "aggregation",
      "provider",
      "install",
      "latest",
      "content",
      "store",
      "resource",
      "system",
      "properties",
      "synchronize",
      "resources",
      "associate",
      "offerings",
      "component",
      "templates",
      "design",
      "catalog",
      "definition",
      "aggregated",
      "subscribe",
      "subscription",
      "approve",
      "request",
      "view",
      "status",
      "deployment",
      "operations",
      "details",
      "accept",
      "solution",
      "related",
      "topics",
      "tyler",
      "developer"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Use case: Enable IaC Gateway in Cloud Management",
    "content": "Support for IaC Gateway is a beta feature and therefore may contain defects. The primary objective of this feature is to obtain feedback on its functionality and quality, and to identify functional enhancement. Customer is advised to safeguard its data, use caution, and not rely in any way on the correct functioning or performance of this feature and its artifacts. Customer assumes all risks and all costs associated with their use of this feature, including, without limitation, any damage to any equipment, software, information, or data. OpenText disclaims any liability for any loss, damage, or inconvenience caused by using or relying on this feature. The services that enable the functionality of IaC Gateway (IaCGw) are shipped with the ESM platform. IaC Gateway gives customers who are developing Infrastructure as Code (IaC) using Terraform the ability to store Terraform state files in ESM’s database. Storing these state files in ESM’s database gives Operation teams and other users of ",
    "url": "cloudmanagementenableiacgateway",
    "filename": "cloudmanagementenableiacgateway",
    "headings": [
      "Enablement of IaC Gateway",
      "Enablement of IaCGw as Terraform state backend",
      "Using the IaCGw \"Request On Behalf\" functionality",
      "Optional step: configure a basic IaCGw subscription report",
      "UD/UCMDB configuration prerequisites",
      "Optional step: enable cost estimation for Terraform Plan",
      "Install Infracost",
      "Set up integration between IaC Gateway and Infracost",
      "Set up additional configuration options within ESM",
      "Known Issues of IaC Gateway",
      "API calls",
      "Optional step"
    ],
    "keywords": [
      "https://<hostName>/iac-controller/v1/<tenantId>/integration/infracost",
      "https://<hostName>/iac-controller/v1/<tenantId",
      "case",
      "enable",
      "iac",
      "gateway",
      "cloud",
      "management",
      "enablement",
      "iacgw",
      "terraform",
      "state",
      "backend",
      "request",
      "behalf",
      "functionality",
      "optional",
      "step",
      "configure",
      "basic",
      "subscription",
      "report",
      "ud",
      "ucmdb",
      "configuration",
      "prerequisites",
      "cost",
      "estimation",
      "plan",
      "install",
      "infracost",
      "set",
      "integration",
      "between",
      "additional",
      "options",
      "esm",
      "known",
      "issues",
      "api",
      "calls",
      "support",
      "beta",
      "feature",
      "therefore",
      "contain",
      "defects.",
      "primary",
      "objective",
      "obtain",
      "feedback",
      "quality",
      "identify",
      "functional",
      "enhancement.",
      "customer",
      "advised",
      "safeguard",
      "data",
      "caution",
      "rely",
      "any",
      "way",
      "correct",
      "functioning",
      "performance",
      "artifacts.",
      "assumes",
      "all",
      "risks",
      "costs",
      "associated",
      "including",
      "limitation",
      "damage",
      "equipment",
      "software",
      "information",
      "data.",
      "opentext",
      "disclaims",
      "liability",
      "loss",
      "inconvenience",
      "caused",
      "relying",
      "feature.",
      "services",
      "shipped",
      "platform.",
      "gives",
      "customers",
      "developing",
      "infrastructure",
      "code",
      "ability",
      "store",
      "files",
      "database.",
      "storing"
    ],
    "language": "en",
    "word_count": 101,
    "importance_score": 5.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "use case: enable iac gateway in cloud management",
    "contentLower": "support for iac gateway is a beta feature and therefore may contain defects. the primary objective of this feature is to obtain feedback on its functionality and quality, and to identify functional enhancement. customer is advised to safeguard its data, use caution, and not rely in any way on the correct functioning or performance of this feature and its artifacts. customer assumes all risks and all costs associated with their use of this feature, including, without limitation, any damage to any equipment, software, information, or data. opentext disclaims any liability for any loss, damage, or inconvenience caused by using or relying on this feature. the services that enable the functionality of iac gateway (iacgw) are shipped with the esm platform. iac gateway gives customers who are developing infrastructure as code (iac) using terraform the ability to store terraform state files in esm’s database. storing these state files in esm’s database gives operation teams and other users of ",
    "keywordsLower": [
      "https://<hostname>/iac-controller/v1/<tenantid>/integration/infracost",
      "https://<hostname>/iac-controller/v1/<tenantid",
      "case",
      "enable",
      "iac",
      "gateway",
      "cloud",
      "management",
      "enablement",
      "iacgw",
      "terraform",
      "state",
      "backend",
      "request",
      "behalf",
      "functionality",
      "optional",
      "step",
      "configure",
      "basic",
      "subscription",
      "report",
      "ud",
      "ucmdb",
      "configuration",
      "prerequisites",
      "cost",
      "estimation",
      "plan",
      "install",
      "infracost",
      "set",
      "integration",
      "between",
      "additional",
      "options",
      "esm",
      "known",
      "issues",
      "api",
      "calls",
      "support",
      "beta",
      "feature",
      "therefore",
      "contain",
      "defects.",
      "primary",
      "objective",
      "obtain",
      "feedback",
      "quality",
      "identify",
      "functional",
      "enhancement.",
      "customer",
      "advised",
      "safeguard",
      "data",
      "caution",
      "rely",
      "any",
      "way",
      "correct",
      "functioning",
      "performance",
      "artifacts.",
      "assumes",
      "all",
      "risks",
      "costs",
      "associated",
      "including",
      "limitation",
      "damage",
      "equipment",
      "software",
      "information",
      "data.",
      "opentext",
      "disclaims",
      "liability",
      "loss",
      "inconvenience",
      "caused",
      "relying",
      "feature.",
      "services",
      "shipped",
      "platform.",
      "gives",
      "customers",
      "developing",
      "infrastructure",
      "code",
      "ability",
      "store",
      "files",
      "database.",
      "storing"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Use case: Monitor cloud costs using Cloud Cost Reporting",
    "content": "Derek wants clear visibility into cloud spending across the organization. He needs consistent, up-to-date cloud cost reports to understand spending trends, identify major cost drivers, and track cloud usage across accounts and cloud providers. Using Cloud Cost Reporting, Derek and his team can collect billing data from supported cloud platforms and analyze it through prebuilt reports in Operations Cloud. When needed, they can also create custom reports. The following personas will be involved in this use case. Persona Role(s) Responsibilities Stephen Suite administrator Configure a Cloud Management tenant to enable the Cloud Cost Reporting capability. Derek Tenant Administrator of Cloud Management tenant, User with the bvd_admin role in Operations Cloud Administer Cloud Management tenant, configure user authorization, and configure cloud cost providers. Upload the Cloud Cost Reports package, view prebuilt Cloud Cost Reports, and create custom reports in Operations Cloud. Johnny User wi",
    "url": "usecasecgro",
    "filename": "usecasecgro",
    "headings": [
      "Prerequisites",
      "Configure suite administration",
      "Configure an email service",
      "Create customer, account, and users",
      "Create a customer",
      "Create an account",
      "Configure users",
      "HCMX_admin_user1 – tenant administrator",
      "HCMX_OO_User1 – Operations Orchestration admin user",
      "HCMX_transport_user1 – Cloud Cost Reporting integration user",
      "Configure the Cloud Management license",
      "Create or upload a license",
      "Create a license pool",
      "Add the license to the license pool",
      "Create and configure a Cloud Management tenant for Cloud Cost Reporting",
      "Create a tenant",
      "Assign a tenant admin",
      "Assign a license to the tenant",
      "Deploy the tenant",
      "Enable the Cloud Cost Reporting capability"
    ],
    "keywords": [
      "insights.AWS",
      "days.Data",
      "compartments.Cost",
      "categories.Cost",
      "Interface.Go",
      "tags.Cost",
      "tags.Tag",
      "context.Cost",
      "months.Cost",
      "Settings.In",
      "On.Save",
      "insights.Cost",
      "trends.Cost",
      "month.Cost",
      "period.Cost",
      "Providers.On",
      "https://<hostname>/bo",
      "options.Cost",
      "days.Cost",
      "months.Data",
      "days.AWS",
      "scope.Cost",
      "report.Cost",
      "Deploy.You",
      "case",
      "monitor",
      "cloud",
      "costs",
      "cost",
      "reporting",
      "prerequisites",
      "configure",
      "suite",
      "administration",
      "email",
      "service",
      "create",
      "customer",
      "account",
      "users",
      "tenant",
      "administrator",
      "operations",
      "orchestration",
      "admin",
      "user",
      "integration",
      "management",
      "license",
      "upload",
      "pool",
      "add",
      "assign",
      "deploy",
      "enable",
      "capability",
      "provider",
      "platform",
      "download",
      "reports",
      "package",
      "view",
      "overview",
      "multi-cloud",
      "spend",
      "summary",
      "aws",
      "billing",
      "executive",
      "compute",
      "s3",
      "data",
      "transfer",
      "database",
      "azure",
      "blob",
      "storage",
      "oci",
      "exploration",
      "tags",
      "custom",
      "derek",
      "wants",
      "clear",
      "visibility",
      "spending",
      "across",
      "organization.",
      "needs",
      "consistent",
      "up-to-date",
      "understand",
      "trends",
      "identify",
      "major",
      "drivers",
      "track",
      "usage",
      "accounts",
      "providers."
    ],
    "language": "en",
    "word_count": 116,
    "importance_score": 5.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "use case: monitor cloud costs using cloud cost reporting",
    "contentLower": "derek wants clear visibility into cloud spending across the organization. he needs consistent, up-to-date cloud cost reports to understand spending trends, identify major cost drivers, and track cloud usage across accounts and cloud providers. using cloud cost reporting, derek and his team can collect billing data from supported cloud platforms and analyze it through prebuilt reports in operations cloud. when needed, they can also create custom reports. the following personas will be involved in this use case. persona role(s) responsibilities stephen suite administrator configure a cloud management tenant to enable the cloud cost reporting capability. derek tenant administrator of cloud management tenant, user with the bvd_admin role in operations cloud administer cloud management tenant, configure user authorization, and configure cloud cost providers. upload the cloud cost reports package, view prebuilt cloud cost reports, and create custom reports in operations cloud. johnny user wi",
    "keywordsLower": [
      "insights.aws",
      "days.data",
      "compartments.cost",
      "categories.cost",
      "interface.go",
      "tags.cost",
      "tags.tag",
      "context.cost",
      "months.cost",
      "settings.in",
      "on.save",
      "insights.cost",
      "trends.cost",
      "month.cost",
      "period.cost",
      "providers.on",
      "https://<hostname>/bo",
      "options.cost",
      "days.cost",
      "months.data",
      "days.aws",
      "scope.cost",
      "report.cost",
      "deploy.you",
      "case",
      "monitor",
      "cloud",
      "costs",
      "cost",
      "reporting",
      "prerequisites",
      "configure",
      "suite",
      "administration",
      "email",
      "service",
      "create",
      "customer",
      "account",
      "users",
      "tenant",
      "administrator",
      "operations",
      "orchestration",
      "admin",
      "user",
      "integration",
      "management",
      "license",
      "upload",
      "pool",
      "add",
      "assign",
      "deploy",
      "enable",
      "capability",
      "provider",
      "platform",
      "download",
      "reports",
      "package",
      "view",
      "overview",
      "multi-cloud",
      "spend",
      "summary",
      "aws",
      "billing",
      "executive",
      "compute",
      "s3",
      "data",
      "transfer",
      "database",
      "azure",
      "blob",
      "storage",
      "oci",
      "exploration",
      "tags",
      "custom",
      "derek",
      "wants",
      "clear",
      "visibility",
      "spending",
      "across",
      "organization.",
      "needs",
      "consistent",
      "up-to-date",
      "understand",
      "trends",
      "identify",
      "major",
      "drivers",
      "track",
      "usage",
      "accounts",
      "providers."
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Use case: OPB endpoints of Design and Deploy",
    "content": "This document covers the use case for the following On-Premises Bridge (OPB) endpoint types of Design and Deploy: LDAP Query: Fetch values from the LDAP server. JDBC Query: Fetch data from a database server. File system: Fetch the content from a file. REST Executor 1.0: Fetch the data made available in a REST API. Note: The response size limit currently is 128 KB. Use case: Eve, as a Service Designer, can make use of the data provided by the above OPB endpoints in a dynamic list property. For this, she needs the OPB endpoints configured in Agent Portal. After configuring an endpoint, she can use the same in dynamically listing the data in the configuration option properties of service design. The following user roles are involved in this use case: User role Responsibilities Tenant Admin Configure OPB endpoints Service Designer Create configuration option dynamic list properties in service design using OPB endpoints Service Portal User Request for a cloud service offering from the Servi",
    "url": "opbendpointsusecase",
    "filename": "opbendpointsusecase",
    "headings": [
      "Prerequisites",
      "Install and add an OPB Agent",
      "Configure OPB endpoints",
      "Specify endpoint credentials using Endpoint Credentials Manager on OPB agent server",
      "Add an endpoint in Agent Portal",
      "Configure an endpoint in Agent Portal",
      "Use the endpoint in Service Design",
      "Sample Javascript of JDBC endpoint",
      "Sample Javascript of LDAP endpoint",
      "Sample Javascript of file system endpoint",
      "Sample Javascript of REST executor 1.0 endpoint",
      "Related topics"
    ],
    "keywords": [
      "sqlserver://<host_name",
      "response.body",
      "https://mydomain:port/<my_context",
      "cloudwars.in",
      "postgresql://<host_name",
      "ldaps://<host_name",
      "1.0",
      "HTTPClient.call",
      "sample.txt",
      "obj.name",
      "client.call",
      "availableValues.push",
      "ldap://<host_name",
      "response.data",
      "OpbAgent.bat",
      "case",
      "opb",
      "endpoints",
      "design",
      "deploy",
      "prerequisites",
      "install",
      "add",
      "agent",
      "configure",
      "specify",
      "endpoint",
      "credentials",
      "manager",
      "server",
      "portal",
      "service",
      "sample",
      "javascript",
      "jdbc",
      "ldap",
      "file",
      "system",
      "rest",
      "executor",
      "related",
      "topics",
      "document",
      "covers",
      "following",
      "on-premises",
      "bridge",
      "types",
      "query",
      "fetch",
      "values",
      "server.",
      "data",
      "database",
      "content",
      "file.",
      "made",
      "available",
      "api.",
      "note",
      "response",
      "size",
      "limit",
      "currently",
      "128",
      "kb.",
      "eve",
      "designer",
      "make",
      "provided",
      "above",
      "dynamic",
      "list",
      "property.",
      "needs",
      "configured",
      "portal.",
      "after",
      "configuring",
      "same",
      "dynamically",
      "listing",
      "configuration",
      "option",
      "properties",
      "design.",
      "user",
      "roles",
      "involved",
      "role",
      "responsibilities",
      "tenant",
      "admin",
      "create",
      "request",
      "cloud",
      "offering",
      "ensure",
      "complete",
      "dnd"
    ],
    "language": "en",
    "word_count": 113,
    "importance_score": 5.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "use case: opb endpoints of design and deploy",
    "contentLower": "this document covers the use case for the following on-premises bridge (opb) endpoint types of design and deploy: ldap query: fetch values from the ldap server. jdbc query: fetch data from a database server. file system: fetch the content from a file. rest executor 1.0: fetch the data made available in a rest api. note: the response size limit currently is 128 kb. use case: eve, as a service designer, can make use of the data provided by the above opb endpoints in a dynamic list property. for this, she needs the opb endpoints configured in agent portal. after configuring an endpoint, she can use the same in dynamically listing the data in the configuration option properties of service design. the following user roles are involved in this use case: user role responsibilities tenant admin configure opb endpoints service designer create configuration option dynamic list properties in service design using opb endpoints service portal user request for a cloud service offering from the servi",
    "keywordsLower": [
      "sqlserver://<host_name",
      "response.body",
      "https://mydomain:port/<my_context",
      "cloudwars.in",
      "postgresql://<host_name",
      "ldaps://<host_name",
      "1.0",
      "httpclient.call",
      "sample.txt",
      "obj.name",
      "client.call",
      "availablevalues.push",
      "ldap://<host_name",
      "response.data",
      "opbagent.bat",
      "case",
      "opb",
      "endpoints",
      "design",
      "deploy",
      "prerequisites",
      "install",
      "add",
      "agent",
      "configure",
      "specify",
      "endpoint",
      "credentials",
      "manager",
      "server",
      "portal",
      "service",
      "sample",
      "javascript",
      "jdbc",
      "ldap",
      "file",
      "system",
      "rest",
      "executor",
      "related",
      "topics",
      "document",
      "covers",
      "following",
      "on-premises",
      "bridge",
      "types",
      "query",
      "fetch",
      "values",
      "server.",
      "data",
      "database",
      "content",
      "file.",
      "made",
      "available",
      "api.",
      "note",
      "response",
      "size",
      "limit",
      "currently",
      "128",
      "kb.",
      "eve",
      "designer",
      "make",
      "provided",
      "above",
      "dynamic",
      "list",
      "property.",
      "needs",
      "configured",
      "portal.",
      "after",
      "configuring",
      "same",
      "dynamically",
      "listing",
      "configuration",
      "option",
      "properties",
      "design.",
      "user",
      "roles",
      "involved",
      "role",
      "responsibilities",
      "tenant",
      "admin",
      "create",
      "request",
      "cloud",
      "offering",
      "ensure",
      "complete",
      "dnd"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Upload images to a registry (Helm)",
    "content": "Before you install the suite, you need to download the images from the official Docker Hub to a registry. Generate the download bundle Use the steps below to generate the download bundle. Log on to the first control plane node, and then navigate to the $CDF_HOME/tools/generate-download directory. Run the generate_download_bundle.sh command together with the options required by your deployment. For a full list of command options, run the command with the -h option. generate_download_bundle.sh -f <image set file> [ -d <output directory>] Where: <image set_file>: The absolute path to the image set file. To locate this file, unzip the esm-1.0.0+2x.x-xxx.zip  and check the scripts folder. <output_directory>: The directory where the script saves the offline-download.zip file. If you don't specify a value, the script saves the file to the default directory, which is the current working directory. Example command: generate_download_bundle.sh -f <ESM_Helm_Chart-2x.x.x>/scripts/image_sets/_image",
    "url": "uploadimagestoexternalregistryhelm",
    "filename": "uploadimagestoexternalregistryhelm",
    "headings": [
      "Generate the download bundle",
      "Download the suite images",
      "(Optional) Transfer the images to the control plane node",
      "Upload the images"
    ],
    "keywords": [
      "downloadimages.sh",
      "https://PROXY_SERVER:PORT",
      "download.zip",
      "1.0.0",
      "set.json",
      "http://image-registry.com",
      "xxx.zip",
      "uploadimages.sh",
      "generate_download_bundle.sh",
      "20240129084204.log",
      "registry.com",
      "https://image-registry.com",
      "http://PROXY_SERVER:PORT",
      "tar.gz",
      "upload",
      "images",
      "registry",
      "helm",
      "generate",
      "download",
      "bundle",
      "suite",
      "optional",
      "transfer",
      "control",
      "plane",
      "node",
      "before",
      "install",
      "need",
      "official",
      "docker",
      "hub",
      "registry.",
      "steps",
      "below",
      "bundle.",
      "log",
      "first",
      "navigate",
      "tools",
      "generate-download",
      "directory.",
      "run",
      "command",
      "together",
      "options",
      "required",
      "deployment.",
      "full",
      "list",
      "-h",
      "option.",
      "-f",
      "-d",
      "absolute",
      "path",
      "image",
      "set",
      "file.",
      "locate",
      "file",
      "unzip",
      "esm-1.0.0",
      "2x.x-xxx.zip",
      "check",
      "scripts",
      "folder.",
      "directory",
      "script",
      "saves",
      "offline-download.zip",
      "don",
      "specify",
      "value",
      "default",
      "current",
      "working",
      "example",
      "tmp",
      "see",
      "similar",
      "message",
      "indicating",
      "successfully",
      "generated",
      "info",
      "under",
      "details",
      "please",
      "refer",
      "opt",
      "cdf",
      "contains",
      "downloads",
      "installation.",
      "node.",
      "access",
      "linux",
      "server"
    ],
    "language": "en",
    "word_count": 87,
    "importance_score": 4.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "upload images to a registry (helm)",
    "contentLower": "before you install the suite, you need to download the images from the official docker hub to a registry. generate the download bundle use the steps below to generate the download bundle. log on to the first control plane node, and then navigate to the $cdf_home/tools/generate-download directory. run the generate_download_bundle.sh command together with the options required by your deployment. for a full list of command options, run the command with the -h option. generate_download_bundle.sh -f <image set file> [ -d <output directory>] where: <image set_file>: the absolute path to the image set file. to locate this file, unzip the esm-1.0.0+2x.x-xxx.zip  and check the scripts folder. <output_directory>: the directory where the script saves the offline-download.zip file. if you don't specify a value, the script saves the file to the default directory, which is the current working directory. example command: generate_download_bundle.sh -f <esm_helm_chart-2x.x.x>/scripts/image_sets/_image",
    "keywordsLower": [
      "downloadimages.sh",
      "https://proxy_server:port",
      "download.zip",
      "1.0.0",
      "set.json",
      "http://image-registry.com",
      "xxx.zip",
      "uploadimages.sh",
      "generate_download_bundle.sh",
      "20240129084204.log",
      "registry.com",
      "https://image-registry.com",
      "http://proxy_server:port",
      "tar.gz",
      "upload",
      "images",
      "registry",
      "helm",
      "generate",
      "download",
      "bundle",
      "suite",
      "optional",
      "transfer",
      "control",
      "plane",
      "node",
      "before",
      "install",
      "need",
      "official",
      "docker",
      "hub",
      "registry.",
      "steps",
      "below",
      "bundle.",
      "log",
      "first",
      "navigate",
      "tools",
      "generate-download",
      "directory.",
      "run",
      "command",
      "together",
      "options",
      "required",
      "deployment.",
      "full",
      "list",
      "-h",
      "option.",
      "-f",
      "-d",
      "absolute",
      "path",
      "image",
      "set",
      "file.",
      "locate",
      "file",
      "unzip",
      "esm-1.0.0",
      "2x.x-xxx.zip",
      "check",
      "scripts",
      "folder.",
      "directory",
      "script",
      "saves",
      "offline-download.zip",
      "don",
      "specify",
      "value",
      "default",
      "current",
      "working",
      "example",
      "tmp",
      "see",
      "similar",
      "message",
      "indicating",
      "successfully",
      "generated",
      "info",
      "under",
      "details",
      "please",
      "refer",
      "opt",
      "cdf",
      "contains",
      "downloads",
      "installation.",
      "node.",
      "access",
      "linux",
      "server"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Upload container images for UD/UCMDB to a registry",
    "content": "Upload the installation images to your image registry. The image registry is a local registry on your cluster nodes or an external registry, such as your enterprise repository. To upload the images: Log on to the control plane node where you downloaded or copied the images. Run the following command to the $CDF_HOME/scripts/ directory: cd $CDF_HOME/scripts Run the following command to upload the suite images to the local registry: ./uploadimages.sh [-r <image repository URL> -u <username> -d <image download directory> -o <org name>] Where: <image repository URL>: Specify the -r option if you want to upload the images to an external registry other than the local registry. Replace <username> with the registry username.  Use the registry-admin user for the local registry. The local registry refers to the default registry or the registry URL that's localhost:5000. If you don't specify the credentials here, the ./uploadimages.sh script prompts you to specify them when you run the command. <",
    "url": "cmswithsmaxuploadinstallationimages",
    "filename": "cmswithsmaxuploadinstallationimages",
    "headings": [],
    "keywords": [
      "uducmdb",
      "downloadimages.sh",
      "uploadimages.sh",
      "updateLocalRegistryInfo.sh",
      "upload",
      "container",
      "images",
      "ud",
      "ucmdb",
      "registry",
      "installation",
      "image",
      "registry.",
      "local",
      "cluster",
      "nodes",
      "external",
      "such",
      "enterprise",
      "repository.",
      "log",
      "control",
      "plane",
      "node",
      "downloaded",
      "copied",
      "images.",
      "run",
      "following",
      "command",
      "scripts",
      "directory",
      "cd",
      "suite",
      "-r",
      "-u",
      "-d",
      "-o",
      "specify",
      "option",
      "want",
      "replace",
      "username.",
      "registry-admin",
      "user",
      "refers",
      "default",
      "url",
      "localhost",
      "5000.",
      "don",
      "credentials",
      "here",
      "script",
      "prompts",
      "command.",
      "downloads",
      "value",
      "var",
      "opt",
      "cdf",
      "offline.",
      "placed",
      "aren",
      "available",
      "offline",
      "directory.",
      "multiple",
      "times",
      "different",
      "directories.",
      "downloadimages.sh.",
      "make",
      "sure",
      "file",
      "type",
      "matches",
      "extension.",
      "organization",
      "contains",
      "installation.",
      "hpeswitom.",
      "mandatory",
      "name.",
      "--cleanup",
      "delete",
      "source",
      "folder",
      "save",
      "disk",
      "space.",
      "works",
      "all",
      "uploaded",
      "successfully.",
      "see",
      "full",
      "list",
      "options",
      "-h"
    ],
    "language": "en",
    "word_count": 91,
    "importance_score": 2.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "upload container images for ud/ucmdb to a registry",
    "contentLower": "upload the installation images to your image registry. the image registry is a local registry on your cluster nodes or an external registry, such as your enterprise repository. to upload the images: log on to the control plane node where you downloaded or copied the images. run the following command to the $cdf_home/scripts/ directory: cd $cdf_home/scripts run the following command to upload the suite images to the local registry: ./uploadimages.sh [-r <image repository url> -u <username> -d <image download directory> -o <org name>] where: <image repository url>: specify the -r option if you want to upload the images to an external registry other than the local registry. replace <username> with the registry username.  use the registry-admin user for the local registry. the local registry refers to the default registry or the registry url that's localhost:5000. if you don't specify the credentials here, the ./uploadimages.sh script prompts you to specify them when you run the command. <",
    "keywordsLower": [
      "uducmdb",
      "downloadimages.sh",
      "uploadimages.sh",
      "updatelocalregistryinfo.sh",
      "upload",
      "container",
      "images",
      "ud",
      "ucmdb",
      "registry",
      "installation",
      "image",
      "registry.",
      "local",
      "cluster",
      "nodes",
      "external",
      "such",
      "enterprise",
      "repository.",
      "log",
      "control",
      "plane",
      "node",
      "downloaded",
      "copied",
      "images.",
      "run",
      "following",
      "command",
      "scripts",
      "directory",
      "cd",
      "suite",
      "-r",
      "-u",
      "-d",
      "-o",
      "specify",
      "option",
      "want",
      "replace",
      "username.",
      "registry-admin",
      "user",
      "refers",
      "default",
      "url",
      "localhost",
      "5000.",
      "don",
      "credentials",
      "here",
      "script",
      "prompts",
      "command.",
      "downloads",
      "value",
      "var",
      "opt",
      "cdf",
      "offline.",
      "placed",
      "aren",
      "available",
      "offline",
      "directory.",
      "multiple",
      "times",
      "different",
      "directories.",
      "downloadimages.sh.",
      "make",
      "sure",
      "file",
      "type",
      "matches",
      "extension.",
      "organization",
      "contains",
      "installation.",
      "hpeswitom.",
      "mandatory",
      "name.",
      "--cleanup",
      "delete",
      "source",
      "folder",
      "save",
      "disk",
      "space.",
      "works",
      "all",
      "uploaded",
      "successfully.",
      "see",
      "full",
      "list",
      "options",
      "-h"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Verify the UD/UCMDB installation",
    "content": "To verify if UD/UCMDB has been installed successfully, do the following: Log in to the control plane node (embedded Kubernetes) or the bastion node (managed Kubernetes). Run the following command to make sure that each of the PVCs is bound to an NFS volume. kubectl get pvc -n <UD/UCMDB NAMESPACE> Example: # kubectl get pvc -n ucmdb-prod NAME STATUS VOLUME CAPACITY ACCESS MODES STORAGECLASS AGE ucmdb-configvolumeclaim Bound ucmdb-prod-config-volume 5Gi RWX 8h ucmdb-datavolumeclaim Bound ucmdb-prod-data-volume 5Gi RWX 8h ucmdb-logvolumeclaim Bound ucmdb-prod-log-volume 5Gi RWX 8h Run the following command to see the pod status in the UD/UCMDB namespace. kubectl get pods -n <UD/UCMDB NAMESPACE> Example: # kubectl get pods -n ucmdb-prod NAME READY STATUS RESTARTS AGE itom-autopass-lms-7bb6c57dbf-ttb4q 2/2 Running 0 8h itom-cms-downloader-687849d8f4-r9bv4 2/2 Running 0 8h itom-cms-gateway-5969db8f5d-26n7z 2/2 Running 0 8h itom-cms-gateway-5969db8f5d-nn4h6 2/2 Running 0 8h itom-idm-7c687c8f4",
    "url": "installcmswithsmaxverify",
    "filename": "installcmswithsmaxverify",
    "headings": [],
    "keywords": [
      "uducmdb",
      "verify",
      "ud",
      "ucmdb",
      "installation",
      "installed",
      "successfully",
      "following",
      "log",
      "control",
      "plane",
      "node",
      "embedded",
      "kubernetes",
      "bastion",
      "managed",
      "run",
      "command",
      "make",
      "sure",
      "pvcs",
      "bound",
      "nfs",
      "volume.",
      "kubectl",
      "get",
      "pvc",
      "-n",
      "example",
      "ucmdb-prod",
      "name",
      "status",
      "volume",
      "capacity",
      "access",
      "modes",
      "storageclass",
      "age",
      "ucmdb-configvolumeclaim",
      "ucmdb-prod-config-volume",
      "5gi",
      "rwx",
      "8h",
      "ucmdb-datavolumeclaim",
      "ucmdb-prod-data-volume",
      "ucmdb-logvolumeclaim",
      "ucmdb-prod-log-volume",
      "see",
      "pod",
      "namespace.",
      "pods",
      "ready",
      "restarts",
      "itom-autopass-lms-7bb6c57dbf-ttb4q",
      "running",
      "itom-cms-downloader-687849d8f4-r9bv4",
      "itom-cms-gateway-5969db8f5d-26n7z",
      "itom-cms-gateway-5969db8f5d-nn4h6",
      "itom-idm-7c687c8f49-kzs9t",
      "itom-idm-7c687c8f49-wl4hs",
      "itom-ingress-controller-58cd796778-d7cn7",
      "itom-ingress-controller-58cd796778-m9znp",
      "itom-ucmdb-0",
      "4h",
      "itom-ucmdb-1",
      "4h10m",
      "itom-ucmdb-browser-6dbcdd9586-dgf94",
      "itom-ucmdb-probe-6c554bc9d-rvxkq",
      "itom-ucmdb-solr-7b44ff67b7-vhhqj",
      "itom-vault-fd98f675b-smv8n",
      "column",
      "indicates",
      "current",
      "lifecycle",
      "state",
      "pod.",
      "pending",
      "completed",
      "init",
      "crashloopbackoff.",
      "many",
      "eventually",
      "becomes",
      "podinitializing",
      "state.",
      "addition",
      "check",
      "fully",
      "started",
      "up.",
      "contains",
      "two",
      "numbers",
      "form",
      "number",
      "containers",
      "running.",
      "means",
      "one",
      "isn"
    ],
    "language": "en",
    "word_count": 114,
    "importance_score": 3.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "verify the ud/ucmdb installation",
    "contentLower": "to verify if ud/ucmdb has been installed successfully, do the following: log in to the control plane node (embedded kubernetes) or the bastion node (managed kubernetes). run the following command to make sure that each of the pvcs is bound to an nfs volume. kubectl get pvc -n <ud/ucmdb namespace> example: # kubectl get pvc -n ucmdb-prod name status volume capacity access modes storageclass age ucmdb-configvolumeclaim bound ucmdb-prod-config-volume 5gi rwx 8h ucmdb-datavolumeclaim bound ucmdb-prod-data-volume 5gi rwx 8h ucmdb-logvolumeclaim bound ucmdb-prod-log-volume 5gi rwx 8h run the following command to see the pod status in the ud/ucmdb namespace. kubectl get pods -n <ud/ucmdb namespace> example: # kubectl get pods -n ucmdb-prod name ready status restarts age itom-autopass-lms-7bb6c57dbf-ttb4q 2/2 running 0 8h itom-cms-downloader-687849d8f4-r9bv4 2/2 running 0 8h itom-cms-gateway-5969db8f5d-26n7z 2/2 running 0 8h itom-cms-gateway-5969db8f5d-nn4h6 2/2 running 0 8h itom-idm-7c687c8f4",
    "keywordsLower": [
      "uducmdb",
      "verify",
      "ud",
      "ucmdb",
      "installation",
      "installed",
      "successfully",
      "following",
      "log",
      "control",
      "plane",
      "node",
      "embedded",
      "kubernetes",
      "bastion",
      "managed",
      "run",
      "command",
      "make",
      "sure",
      "pvcs",
      "bound",
      "nfs",
      "volume.",
      "kubectl",
      "get",
      "pvc",
      "-n",
      "example",
      "ucmdb-prod",
      "name",
      "status",
      "volume",
      "capacity",
      "access",
      "modes",
      "storageclass",
      "age",
      "ucmdb-configvolumeclaim",
      "ucmdb-prod-config-volume",
      "5gi",
      "rwx",
      "8h",
      "ucmdb-datavolumeclaim",
      "ucmdb-prod-data-volume",
      "ucmdb-logvolumeclaim",
      "ucmdb-prod-log-volume",
      "see",
      "pod",
      "namespace.",
      "pods",
      "ready",
      "restarts",
      "itom-autopass-lms-7bb6c57dbf-ttb4q",
      "running",
      "itom-cms-downloader-687849d8f4-r9bv4",
      "itom-cms-gateway-5969db8f5d-26n7z",
      "itom-cms-gateway-5969db8f5d-nn4h6",
      "itom-idm-7c687c8f49-kzs9t",
      "itom-idm-7c687c8f49-wl4hs",
      "itom-ingress-controller-58cd796778-d7cn7",
      "itom-ingress-controller-58cd796778-m9znp",
      "itom-ucmdb-0",
      "4h",
      "itom-ucmdb-1",
      "4h10m",
      "itom-ucmdb-browser-6dbcdd9586-dgf94",
      "itom-ucmdb-probe-6c554bc9d-rvxkq",
      "itom-ucmdb-solr-7b44ff67b7-vhhqj",
      "itom-vault-fd98f675b-smv8n",
      "column",
      "indicates",
      "current",
      "lifecycle",
      "state",
      "pod.",
      "pending",
      "completed",
      "init",
      "crashloopbackoff.",
      "many",
      "eventually",
      "becomes",
      "podinitializing",
      "state.",
      "addition",
      "check",
      "fully",
      "started",
      "up.",
      "contains",
      "two",
      "numbers",
      "form",
      "number",
      "containers",
      "running.",
      "means",
      "one",
      "isn"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Uninstall UD/UCMDB",
    "content": "To uninstall UD/UCMDB, perform the following tasks: Delete the UD/UCMDB deployment Log on to the control plane node as root or a sudo user. Run the following command to remove the UD/UCMDB release: helm uninstall <UD/UCMDB RELEASE NAME> -n <UD/UCMDB NAMESPACE> Where: <UD/UCMDB RELEASE NAME> is the UD/UCMDB release that you want to uninstall <UD/UCMDB NAMESPACE> is the namespace where you installed UD/UCMDB Go to the $CDF_HOME/scripts folder and run the following command: ./cdfctl.sh deployment delete -d <UD/UCMDB DEPLOYMENT NAME> Where: <UD/UCMDB DEPLOYMENT NAME> is the name you specified for the deployment you created to install UD/UCMDB. For example: ./cdfctl.sh deployment delete -d ucmdb-prod Remove persistent volumes If you created PVs based on the ucmdb-pv.yaml sample file as documented in Create persistent volumes, you can run the following command to delete the persistent volumes: kubectl delete -f ucmdb-pv.yaml Clean the NFS volumes Log on to the NFS server host and clear all t",
    "url": "cmswithsmaxuninstallcms",
    "filename": "cmswithsmaxuninstallcms",
    "headings": [
      "Delete the UD/UCMDB deployment",
      "Remove persistent volumes",
      "Clean the NFS volumes",
      "Clean the databases"
    ],
    "keywords": [
      "uducmdb",
      "cdfctl.sh",
      "pv.yaml",
      "uninstall",
      "ud",
      "ucmdb",
      "delete",
      "deployment",
      "remove",
      "persistent",
      "volumes",
      "clean",
      "nfs",
      "databases",
      "perform",
      "following",
      "tasks",
      "log",
      "control",
      "plane",
      "node",
      "root",
      "sudo",
      "user.",
      "run",
      "command",
      "release",
      "helm",
      "-n",
      "want",
      "namespace",
      "installed",
      "go",
      "scripts",
      "folder",
      "-d",
      "name",
      "specified",
      "created",
      "install",
      "ucmdb.",
      "example",
      "ucmdb-prod",
      "pvs",
      "based",
      "ucmdb-pv.yaml",
      "sample",
      "file",
      "documented",
      "create",
      "kubectl",
      "-f",
      "server",
      "host",
      "clear",
      "all",
      "contents",
      "volume",
      "directories",
      "step.",
      "rm",
      "-rf",
      "var",
      "vols",
      "itom",
      "un-installation",
      "process",
      "external",
      "postgresql",
      "server.",
      "need",
      "manually."
    ],
    "language": "en",
    "word_count": 96,
    "importance_score": 5.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "uninstall ud/ucmdb",
    "contentLower": "to uninstall ud/ucmdb, perform the following tasks: delete the ud/ucmdb deployment log on to the control plane node as root or a sudo user. run the following command to remove the ud/ucmdb release: helm uninstall <ud/ucmdb release name> -n <ud/ucmdb namespace> where: <ud/ucmdb release name> is the ud/ucmdb release that you want to uninstall <ud/ucmdb namespace> is the namespace where you installed ud/ucmdb go to the $cdf_home/scripts folder and run the following command: ./cdfctl.sh deployment delete -d <ud/ucmdb deployment name> where: <ud/ucmdb deployment name> is the name you specified for the deployment you created to install ud/ucmdb. for example: ./cdfctl.sh deployment delete -d ucmdb-prod remove persistent volumes if you created pvs based on the ucmdb-pv.yaml sample file as documented in create persistent volumes, you can run the following command to delete the persistent volumes: kubectl delete -f ucmdb-pv.yaml clean the nfs volumes log on to the nfs server host and clear all t",
    "keywordsLower": [
      "uducmdb",
      "cdfctl.sh",
      "pv.yaml",
      "uninstall",
      "ud",
      "ucmdb",
      "delete",
      "deployment",
      "remove",
      "persistent",
      "volumes",
      "clean",
      "nfs",
      "databases",
      "perform",
      "following",
      "tasks",
      "log",
      "control",
      "plane",
      "node",
      "root",
      "sudo",
      "user.",
      "run",
      "command",
      "release",
      "helm",
      "-n",
      "want",
      "namespace",
      "installed",
      "go",
      "scripts",
      "folder",
      "-d",
      "name",
      "specified",
      "created",
      "install",
      "ucmdb.",
      "example",
      "ucmdb-prod",
      "pvs",
      "based",
      "ucmdb-pv.yaml",
      "sample",
      "file",
      "documented",
      "create",
      "kubectl",
      "-f",
      "server",
      "host",
      "clear",
      "all",
      "contents",
      "volume",
      "directories",
      "step.",
      "rm",
      "-rf",
      "var",
      "vols",
      "itom",
      "un-installation",
      "process",
      "external",
      "postgresql",
      "server.",
      "need",
      "manually."
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Uninstall the Audit collector on-premises",
    "content": "To uninstall the Audit collector, perform the following tasks. Delete the Audit collector Log on to the control plane node. Run the following command to remove the Audit collector: helm uninstall <Audit Collector Release Name> -n <Audit Producer Namespace> Where, <Audit Collector Release Name> is the Audit collector release name that you want to uninstall. <Audit Producer Namespace> is the namespace where you installed the Audit producer. Clean the NFS volumes Log on to the NFS server host and clear all the contents in the NFS volume directories that you have created for the Audit collector. For example: rm -rf /var/vols/itom/itsma/global-volume/logs/audit-collector/*",
    "url": "uninstallauditcollector",
    "filename": "uninstallauditcollector",
    "headings": [
      "Delete the Audit collector",
      "Clean the NFS volumes"
    ],
    "keywords": [
      "uninstall",
      "audit",
      "collector",
      "on-premises",
      "delete",
      "clean",
      "nfs",
      "volumes",
      "perform",
      "following",
      "tasks.",
      "log",
      "control",
      "plane",
      "node.",
      "run",
      "command",
      "remove",
      "helm",
      "-n",
      "release",
      "name",
      "want",
      "uninstall.",
      "namespace",
      "installed",
      "producer.",
      "server",
      "host",
      "clear",
      "all",
      "contents",
      "volume",
      "directories",
      "created",
      "collector.",
      "example",
      "rm",
      "-rf",
      "var",
      "vols",
      "itom",
      "itsma",
      "global-volume",
      "logs",
      "audit-collector"
    ],
    "language": "en",
    "word_count": 62,
    "importance_score": 4.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "uninstall the audit collector on-premises",
    "contentLower": "to uninstall the audit collector, perform the following tasks. delete the audit collector log on to the control plane node. run the following command to remove the audit collector: helm uninstall <audit collector release name> -n <audit producer namespace> where, <audit collector release name> is the audit collector release name that you want to uninstall. <audit producer namespace> is the namespace where you installed the audit producer. clean the nfs volumes log on to the nfs server host and clear all the contents in the nfs volume directories that you have created for the audit collector. for example: rm -rf /var/vols/itom/itsma/global-volume/logs/audit-collector/*",
    "keywordsLower": [
      "uninstall",
      "audit",
      "collector",
      "on-premises",
      "delete",
      "clean",
      "nfs",
      "volumes",
      "perform",
      "following",
      "tasks.",
      "log",
      "control",
      "plane",
      "node.",
      "run",
      "command",
      "remove",
      "helm",
      "-n",
      "release",
      "name",
      "want",
      "uninstall.",
      "namespace",
      "installed",
      "producer.",
      "server",
      "host",
      "clear",
      "all",
      "contents",
      "volume",
      "directories",
      "created",
      "collector.",
      "example",
      "rm",
      "-rf",
      "var",
      "vols",
      "itom",
      "itsma",
      "global-volume",
      "logs",
      "audit-collector"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Upload OO container images to a registry",
    "content": "Upload the installation images to your image registry. The image registry is a local registry on your cluster nodes or an external registry, such as your enterprise repository. To upload the images: Log on to the control plane node where you downloaded or copied the images. Run the following command to the $CDF_HOME/scripts/ directory: cd $CDF_HOME/scripts Run the following command to upload the suite images to the local registry: ./uploadimages.sh [-r <image repository URL> -u <username> -d <image download directory> -o <org name>] Where: <image repository URL>: Specify the -r option to upload the images to an external registry other than the local registry. Replace <username> with the registry username. Use the registry-admin user for the local registry. The local registry refers to the default registry or the registry URL that's localhost:5000. If you don't specify the credentials here, the ./uploadimages.sh script prompts you to specify them when you run the command. <image downloa",
    "url": "uploadoocontainerimage",
    "filename": "uploadoocontainerimage",
    "headings": [],
    "keywords": [
      "downloadimages.sh",
      "uploadimages.sh",
      "updateLocalRegistryInfo.sh",
      "upload",
      "oo",
      "container",
      "images",
      "registry",
      "installation",
      "image",
      "registry.",
      "local",
      "cluster",
      "nodes",
      "external",
      "such",
      "enterprise",
      "repository.",
      "log",
      "control",
      "plane",
      "node",
      "downloaded",
      "copied",
      "images.",
      "run",
      "following",
      "command",
      "scripts",
      "directory",
      "cd",
      "suite",
      "-r",
      "-u",
      "-d",
      "-o",
      "specify",
      "option",
      "replace",
      "username.",
      "registry-admin",
      "user",
      "refers",
      "default",
      "url",
      "localhost",
      "5000.",
      "don",
      "credentials",
      "here",
      "script",
      "prompts",
      "command.",
      "downloads",
      "value",
      "var",
      "opt",
      "cdf",
      "offline.",
      "placed",
      "aren",
      "available",
      "offline",
      "directory.",
      "multiple",
      "times",
      "different",
      "directories.",
      "downloadimages.sh.",
      "make",
      "sure",
      "file",
      "type",
      "matches",
      "extension.",
      "organization",
      "contains",
      "installation.",
      "hpeswitom.",
      "mandatory",
      "name.",
      "--cleanup",
      "delete",
      "source",
      "folder",
      "save",
      "disk",
      "space.",
      "works",
      "all",
      "uploaded",
      "successfully.",
      "see",
      "full",
      "list",
      "options",
      "-h",
      "example",
      "-y",
      "-c"
    ],
    "language": "en",
    "word_count": 91,
    "importance_score": 2.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "upload oo container images to a registry",
    "contentLower": "upload the installation images to your image registry. the image registry is a local registry on your cluster nodes or an external registry, such as your enterprise repository. to upload the images: log on to the control plane node where you downloaded or copied the images. run the following command to the $cdf_home/scripts/ directory: cd $cdf_home/scripts run the following command to upload the suite images to the local registry: ./uploadimages.sh [-r <image repository url> -u <username> -d <image download directory> -o <org name>] where: <image repository url>: specify the -r option to upload the images to an external registry other than the local registry. replace <username> with the registry username. use the registry-admin user for the local registry. the local registry refers to the default registry or the registry url that's localhost:5000. if you don't specify the credentials here, the ./uploadimages.sh script prompts you to specify them when you run the command. <image downloa",
    "keywordsLower": [
      "downloadimages.sh",
      "uploadimages.sh",
      "updatelocalregistryinfo.sh",
      "upload",
      "oo",
      "container",
      "images",
      "registry",
      "installation",
      "image",
      "registry.",
      "local",
      "cluster",
      "nodes",
      "external",
      "such",
      "enterprise",
      "repository.",
      "log",
      "control",
      "plane",
      "node",
      "downloaded",
      "copied",
      "images.",
      "run",
      "following",
      "command",
      "scripts",
      "directory",
      "cd",
      "suite",
      "-r",
      "-u",
      "-d",
      "-o",
      "specify",
      "option",
      "replace",
      "username.",
      "registry-admin",
      "user",
      "refers",
      "default",
      "url",
      "localhost",
      "5000.",
      "don",
      "credentials",
      "here",
      "script",
      "prompts",
      "command.",
      "downloads",
      "value",
      "var",
      "opt",
      "cdf",
      "offline.",
      "placed",
      "aren",
      "available",
      "offline",
      "directory.",
      "multiple",
      "times",
      "different",
      "directories.",
      "downloadimages.sh.",
      "make",
      "sure",
      "file",
      "type",
      "matches",
      "extension.",
      "organization",
      "contains",
      "installation.",
      "hpeswitom.",
      "mandatory",
      "name.",
      "--cleanup",
      "delete",
      "source",
      "folder",
      "save",
      "disk",
      "space.",
      "works",
      "all",
      "uploaded",
      "successfully.",
      "see",
      "full",
      "list",
      "options",
      "-h",
      "example",
      "-y",
      "-c"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Verify OO Containerized installation",
    "content": "To verify OO Containerized installation, do the following: Log in to the control plane node. Run the following command to make sure that all OO pods are ready. kubectl get pod -n <OO namespace> |grep -v 1/1|grep -v 2/2|grep -v 3/3|grep -v 4/4|grep -v Completed Where: <OO namespace> is the namespace where you deploy the OO chart. This command returns a list of pending pods. When it returns no results, all OO pods are ready.",
    "url": "verifyoocinstall",
    "filename": "verifyoocinstall",
    "headings": [],
    "keywords": [
      "verify",
      "oo",
      "containerized",
      "installation",
      "following",
      "log",
      "control",
      "plane",
      "node.",
      "run",
      "command",
      "make",
      "sure",
      "all",
      "pods",
      "ready.",
      "kubectl",
      "get",
      "pod",
      "-n",
      "grep",
      "-v",
      "completed",
      "namespace",
      "deploy",
      "chart.",
      "returns",
      "list",
      "pending",
      "pods.",
      "results"
    ],
    "language": "en",
    "word_count": 60,
    "importance_score": 2.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "verify oo containerized installation",
    "contentLower": "to verify oo containerized installation, do the following: log in to the control plane node. run the following command to make sure that all oo pods are ready. kubectl get pod -n <oo namespace> |grep -v 1/1|grep -v 2/2|grep -v 3/3|grep -v 4/4|grep -v completed where: <oo namespace> is the namespace where you deploy the oo chart. this command returns a list of pending pods. when it returns no results, all oo pods are ready.",
    "keywordsLower": [
      "verify",
      "oo",
      "containerized",
      "installation",
      "following",
      "log",
      "control",
      "plane",
      "node.",
      "run",
      "command",
      "make",
      "sure",
      "all",
      "pods",
      "ready.",
      "kubectl",
      "get",
      "pod",
      "-n",
      "grep",
      "-v",
      "completed",
      "namespace",
      "deploy",
      "chart.",
      "returns",
      "list",
      "pending",
      "pods.",
      "results"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Uninstall OO Containerized",
    "content": "To uninstall OO Containerized, perform the following tasks: Delete the OO Containerized deployment Log on to the control plane node as root or a sudo user. Run the following command to remove the OO release: helm uninstall <OO release name> -n <OO namespace> Where: <OO release name> is the OO release that you want to uninstall <OO namespace> is the namespace where you installed OO Go to the $CDF_HOME/scripts folder and run the following command: ./cdfctl.sh deployment delete -d <OO DEPLOYMENT NAME> Where, <OO deployment name> is the name you specified for the deployment you created to install OO. For example: ./cdfctl.sh deployment delete -d oo-prod Remove persistent volumes If you created persistent volumes and persistent volume claims based on the oo-pv.yaml sample files, run the following command to delete the volumes and claims: kubectl delete -f /path/to/oo-pv.yaml kubectl delete -f /path/to/oo-pvc.yaml Clean the /etc/exports file To avoid \"duplicated export entries\" at a later in",
    "url": "uninstallooc",
    "filename": "uninstallooc",
    "headings": [
      "Delete the OO Containerized deployment",
      "Remove persistent volumes",
      "Clean the /etc/exports file",
      "Clean the NFS volumes",
      "Clean the databases"
    ],
    "keywords": [
      "cdfctl.sh",
      "pv.yaml",
      "pvc.yaml",
      "uninstall",
      "oo",
      "containerized",
      "delete",
      "deployment",
      "remove",
      "persistent",
      "volumes",
      "clean",
      "etc",
      "exports",
      "file",
      "nfs",
      "databases",
      "perform",
      "following",
      "tasks",
      "log",
      "control",
      "plane",
      "node",
      "root",
      "sudo",
      "user.",
      "run",
      "command",
      "release",
      "helm",
      "-n",
      "want",
      "namespace",
      "installed",
      "go",
      "scripts",
      "folder",
      "-d",
      "name",
      "specified",
      "created",
      "install",
      "oo.",
      "example",
      "oo-prod",
      "volume",
      "claims",
      "based",
      "oo-pv.yaml",
      "sample",
      "files",
      "kubectl",
      "-f",
      "path",
      "oo-pvc.yaml",
      "avoid",
      "duplicated",
      "export",
      "entries",
      "later",
      "installation",
      "same",
      "environment",
      "make",
      "sure",
      "running",
      "sed",
      "-i",
      "var",
      "vols",
      "itom",
      "server",
      "host",
      "clear",
      "all",
      "contents",
      "directories",
      "create",
      "step.",
      "rm",
      "-rf",
      "external",
      "need",
      "uninstallation",
      "process",
      "doesn",
      "postgresql",
      "server.",
      "manually."
    ],
    "language": "en",
    "word_count": 97,
    "importance_score": 5.5,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "uninstall oo containerized",
    "contentLower": "to uninstall oo containerized, perform the following tasks: delete the oo containerized deployment log on to the control plane node as root or a sudo user. run the following command to remove the oo release: helm uninstall <oo release name> -n <oo namespace> where: <oo release name> is the oo release that you want to uninstall <oo namespace> is the namespace where you installed oo go to the $cdf_home/scripts folder and run the following command: ./cdfctl.sh deployment delete -d <oo deployment name> where, <oo deployment name> is the name you specified for the deployment you created to install oo. for example: ./cdfctl.sh deployment delete -d oo-prod remove persistent volumes if you created persistent volumes and persistent volume claims based on the oo-pv.yaml sample files, run the following command to delete the volumes and claims: kubectl delete -f /path/to/oo-pv.yaml kubectl delete -f /path/to/oo-pvc.yaml clean the /etc/exports file to avoid \"duplicated export entries\" at a later in",
    "keywordsLower": [
      "cdfctl.sh",
      "pv.yaml",
      "pvc.yaml",
      "uninstall",
      "oo",
      "containerized",
      "delete",
      "deployment",
      "remove",
      "persistent",
      "volumes",
      "clean",
      "etc",
      "exports",
      "file",
      "nfs",
      "databases",
      "perform",
      "following",
      "tasks",
      "log",
      "control",
      "plane",
      "node",
      "root",
      "sudo",
      "user.",
      "run",
      "command",
      "release",
      "helm",
      "-n",
      "want",
      "namespace",
      "installed",
      "go",
      "scripts",
      "folder",
      "-d",
      "name",
      "specified",
      "created",
      "install",
      "oo.",
      "example",
      "oo-prod",
      "volume",
      "claims",
      "based",
      "oo-pv.yaml",
      "sample",
      "files",
      "kubectl",
      "-f",
      "path",
      "oo-pvc.yaml",
      "avoid",
      "duplicated",
      "export",
      "entries",
      "later",
      "installation",
      "same",
      "environment",
      "make",
      "sure",
      "running",
      "sed",
      "-i",
      "var",
      "vols",
      "itom",
      "server",
      "host",
      "clear",
      "all",
      "contents",
      "directories",
      "create",
      "step.",
      "rm",
      "-rf",
      "external",
      "need",
      "uninstallation",
      "process",
      "doesn",
      "postgresql",
      "server.",
      "manually."
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Upload container images for Audit to a registry",
    "content": "Upload the installation images to your image registry. The image registry is a local registry on your cluster nodes or an external registry, such as your enterprise repository. To upload the images: Log on to the control plane node where you downloaded or copied the images. Run the following command to the $CDF_HOME/scripts/ directory: cd $CDF_HOME/scripts Run the following command to upload the suite images to the local registry: ./uploadimages.sh [-r <image repository URL> -u <username> -d <image download directory> -o <org name>] Where: <image repository URL>: Specify the -r option if you want to upload the images to an external registry other than the local registry. Replace <username> with the registry username.  Use the registry-admin user for the local registry. The local registry refers to the default registry or the registry URL that's localhost:5000. If you don't specify the credentials here, you can specify when prompted while running the command. <image download directory>:",
    "url": "uploadauditimageshelm",
    "filename": "uploadauditimageshelm",
    "headings": [],
    "keywords": [
      "downloadimages.sh",
      "uploadimages.sh",
      "tar.gz",
      "updateLocalRegistryInfo.sh",
      "upload",
      "container",
      "images",
      "audit",
      "registry",
      "installation",
      "image",
      "registry.",
      "local",
      "cluster",
      "nodes",
      "external",
      "such",
      "enterprise",
      "repository.",
      "log",
      "control",
      "plane",
      "node",
      "downloaded",
      "copied",
      "images.",
      "run",
      "following",
      "command",
      "scripts",
      "directory",
      "cd",
      "suite",
      "-r",
      "-u",
      "-d",
      "-o",
      "specify",
      "option",
      "want",
      "replace",
      "username.",
      "registry-admin",
      "user",
      "refers",
      "default",
      "url",
      "localhost",
      "5000.",
      "don",
      "credentials",
      "here",
      "prompted",
      "while",
      "running",
      "command.",
      "get",
      "downloaded.",
      "value",
      "var",
      "opt",
      "cdf",
      "offline.",
      "placed",
      "aren",
      "available",
      "offline",
      "directory.",
      "multiple",
      "times",
      "different",
      "directories.",
      "however",
      "specified",
      "-l",
      "false",
      "one",
      "download",
      "downloadimages.sh.",
      ".tar",
      ".tgz",
      ".tar.gz",
      "supported.",
      "make",
      "sure",
      "file",
      "type",
      "matches",
      "extension.",
      "organization",
      "contains",
      "installation.",
      "hpeswitom.",
      "mandatory",
      "name.",
      "see",
      "full",
      "list",
      "options",
      "-h"
    ],
    "language": "en",
    "word_count": 89,
    "importance_score": 2.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "upload container images for audit to a registry",
    "contentLower": "upload the installation images to your image registry. the image registry is a local registry on your cluster nodes or an external registry, such as your enterprise repository. to upload the images: log on to the control plane node where you downloaded or copied the images. run the following command to the $cdf_home/scripts/ directory: cd $cdf_home/scripts run the following command to upload the suite images to the local registry: ./uploadimages.sh [-r <image repository url> -u <username> -d <image download directory> -o <org name>] where: <image repository url>: specify the -r option if you want to upload the images to an external registry other than the local registry. replace <username> with the registry username.  use the registry-admin user for the local registry. the local registry refers to the default registry or the registry url that's localhost:5000. if you don't specify the credentials here, you can specify when prompted while running the command. <image download directory>:",
    "keywordsLower": [
      "downloadimages.sh",
      "uploadimages.sh",
      "tar.gz",
      "updatelocalregistryinfo.sh",
      "upload",
      "container",
      "images",
      "audit",
      "registry",
      "installation",
      "image",
      "registry.",
      "local",
      "cluster",
      "nodes",
      "external",
      "such",
      "enterprise",
      "repository.",
      "log",
      "control",
      "plane",
      "node",
      "downloaded",
      "copied",
      "images.",
      "run",
      "following",
      "command",
      "scripts",
      "directory",
      "cd",
      "suite",
      "-r",
      "-u",
      "-d",
      "-o",
      "specify",
      "option",
      "want",
      "replace",
      "username.",
      "registry-admin",
      "user",
      "refers",
      "default",
      "url",
      "localhost",
      "5000.",
      "don",
      "credentials",
      "here",
      "prompted",
      "while",
      "running",
      "command.",
      "get",
      "downloaded.",
      "value",
      "var",
      "opt",
      "cdf",
      "offline.",
      "placed",
      "aren",
      "available",
      "offline",
      "directory.",
      "multiple",
      "times",
      "different",
      "directories.",
      "however",
      "specified",
      "-l",
      "false",
      "one",
      "download",
      "downloadimages.sh.",
      ".tar",
      ".tgz",
      ".tar.gz",
      "supported.",
      "make",
      "sure",
      "file",
      "type",
      "matches",
      "extension.",
      "organization",
      "contains",
      "installation.",
      "hpeswitom.",
      "mandatory",
      "name.",
      "see",
      "full",
      "list",
      "options",
      "-h"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Uninstall the Audit service on-premises",
    "content": "To uninstall Audit service, perform the following tasks: Delete the deployment Log on to the control plane node. Run the following command to remove the Audit release: helm uninstall <Audit Release Name> -n <Audit Namespace> Where, <Audit Release Name> is the Audit release that you want to uninstall, <Audit Namespace> is the namespace where you installed Audit. Go to the $CDF_HOME/scripts folder and run the following command: ./cdfctl.sh deployment delete -d <Audit Deployment Name> Where: <Audit Deployment Name> is the name you specified for the deployment you created to install Audit. For example: ./cdfctl.sh deployment delete -d audit-prod Remove persistent volumes If you created PVs based on the itom-audit-pv.yaml sample file as documented in Create persistent volumes, you can run the following command to delete the persistent volumes: kubectl delete -f itom-audit-pv.yaml Clean the NFS volumes Log on to the NFS server host and clear all the contents in the NFS volume directories tha",
    "url": "uninstallauditonpremises",
    "filename": "uninstallauditonpremises",
    "headings": [
      "Delete the deployment",
      "Remove persistent volumes",
      "Clean the NFS volumes",
      "Clean the databases"
    ],
    "keywords": [
      "cdfctl.sh",
      "pv.yaml",
      "uninstall",
      "audit",
      "service",
      "on-premises",
      "delete",
      "deployment",
      "remove",
      "persistent",
      "volumes",
      "clean",
      "nfs",
      "databases",
      "perform",
      "following",
      "tasks",
      "log",
      "control",
      "plane",
      "node.",
      "run",
      "command",
      "release",
      "helm",
      "-n",
      "want",
      "namespace",
      "installed",
      "audit.",
      "go",
      "scripts",
      "folder",
      "-d",
      "name",
      "specified",
      "created",
      "install",
      "example",
      "audit-prod",
      "pvs",
      "based",
      "itom-audit-pv.yaml",
      "sample",
      "file",
      "documented",
      "create",
      "kubectl",
      "-f",
      "server",
      "host",
      "clear",
      "all",
      "contents",
      "volume",
      "directories",
      "created.",
      "rm",
      "-rf",
      "var",
      "vols",
      "itom",
      "auditns",
      "vault",
      "uninstallation",
      "process",
      "doesn",
      "external",
      "postgresql",
      "server.",
      "need",
      "manually."
    ],
    "language": "en",
    "word_count": 92,
    "importance_score": 5.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "uninstall the audit service on-premises",
    "contentLower": "to uninstall audit service, perform the following tasks: delete the deployment log on to the control plane node. run the following command to remove the audit release: helm uninstall <audit release name> -n <audit namespace> where, <audit release name> is the audit release that you want to uninstall, <audit namespace> is the namespace where you installed audit. go to the $cdf_home/scripts folder and run the following command: ./cdfctl.sh deployment delete -d <audit deployment name> where: <audit deployment name> is the name you specified for the deployment you created to install audit. for example: ./cdfctl.sh deployment delete -d audit-prod remove persistent volumes if you created pvs based on the itom-audit-pv.yaml sample file as documented in create persistent volumes, you can run the following command to delete the persistent volumes: kubectl delete -f itom-audit-pv.yaml clean the nfs volumes log on to the nfs server host and clear all the contents in the nfs volume directories tha",
    "keywordsLower": [
      "cdfctl.sh",
      "pv.yaml",
      "uninstall",
      "audit",
      "service",
      "on-premises",
      "delete",
      "deployment",
      "remove",
      "persistent",
      "volumes",
      "clean",
      "nfs",
      "databases",
      "perform",
      "following",
      "tasks",
      "log",
      "control",
      "plane",
      "node.",
      "run",
      "command",
      "release",
      "helm",
      "-n",
      "want",
      "namespace",
      "installed",
      "audit.",
      "go",
      "scripts",
      "folder",
      "-d",
      "name",
      "specified",
      "created",
      "install",
      "example",
      "audit-prod",
      "pvs",
      "based",
      "itom-audit-pv.yaml",
      "sample",
      "file",
      "documented",
      "create",
      "kubectl",
      "-f",
      "server",
      "host",
      "clear",
      "all",
      "contents",
      "volume",
      "directories",
      "created.",
      "rm",
      "-rf",
      "var",
      "vols",
      "itom",
      "auditns",
      "vault",
      "uninstallation",
      "process",
      "doesn",
      "external",
      "postgresql",
      "server.",
      "need",
      "manually."
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Verify the UD/UCMDB installation (EKS)",
    "content": "To verify if UD/UCMDB has been installed successfully, do the following: Log in to the control plane node (embedded Kubernetes) or the bastion node (managed Kubernetes). Run the following command to make sure that each of the PVCs is bound to an NFS volume. kubectl get pvc -n <UD/UCMDB NAMESPACE> Example: # kubectl get pvc -n ucmdb-prod NAME STATUS VOLUME CAPACITY ACCESS MODES STORAGECLASS AGE ucmdb-configvolumeclaim Bound ucmdb-prod-config-volume 5Gi RWX 8h ucmdb-datavolumeclaim Bound ucmdb-prod-data-volume 5Gi RWX 8h ucmdb-logvolumeclaim Bound ucmdb-prod-log-volume 5Gi RWX 8h Run the following command to see the pod status in the UD/UCMDB namespace. kubectl get pods -n <UD/UCMDB NAMESPACE> Example: # kubectl get pods -n ucmdb-prod NAME READY STATUS RESTARTS AGE itom-autopass-lms-7bb6c57dbf-ttb4q 2/2 Running 0 8h itom-cms-downloader-687849d8f4-r9bv4 2/2 Running 0 8h itom-cms-gateway-5969db8f5d-26n7z 2/2 Running 0 8h itom-cms-gateway-5969db8f5d-nn4h6 2/2 Running 0 8h itom-idm-7c687c8f4",
    "url": "installcmswithsmaxverifyeks",
    "filename": "installcmswithsmaxverifyeks",
    "headings": [],
    "keywords": [
      "uducmdb",
      "verify",
      "ud",
      "ucmdb",
      "installation",
      "eks",
      "installed",
      "successfully",
      "following",
      "log",
      "control",
      "plane",
      "node",
      "embedded",
      "kubernetes",
      "bastion",
      "managed",
      "run",
      "command",
      "make",
      "sure",
      "pvcs",
      "bound",
      "nfs",
      "volume.",
      "kubectl",
      "get",
      "pvc",
      "-n",
      "example",
      "ucmdb-prod",
      "name",
      "status",
      "volume",
      "capacity",
      "access",
      "modes",
      "storageclass",
      "age",
      "ucmdb-configvolumeclaim",
      "ucmdb-prod-config-volume",
      "5gi",
      "rwx",
      "8h",
      "ucmdb-datavolumeclaim",
      "ucmdb-prod-data-volume",
      "ucmdb-logvolumeclaim",
      "ucmdb-prod-log-volume",
      "see",
      "pod",
      "namespace.",
      "pods",
      "ready",
      "restarts",
      "itom-autopass-lms-7bb6c57dbf-ttb4q",
      "running",
      "itom-cms-downloader-687849d8f4-r9bv4",
      "itom-cms-gateway-5969db8f5d-26n7z",
      "itom-cms-gateway-5969db8f5d-nn4h6",
      "itom-idm-7c687c8f49-kzs9t",
      "itom-idm-7c687c8f49-wl4hs",
      "itom-ingress-controller-58cd796778-d7cn7",
      "itom-ingress-controller-58cd796778-m9znp",
      "itom-ucmdb-0",
      "4h",
      "itom-ucmdb-1",
      "4h10m",
      "itom-ucmdb-browser-6dbcdd9586-dgf94",
      "itom-ucmdb-probe-6c554bc9d-rvxkq",
      "itom-ucmdb-solr-7b44ff67b7-vhhqj",
      "itom-vault-fd98f675b-smv8n",
      "column",
      "indicates",
      "current",
      "lifecycle",
      "state",
      "pod.",
      "pending",
      "completed",
      "init",
      "crashloopbackoff.",
      "many",
      "eventually",
      "becomes",
      "podinitializing",
      "state.",
      "addition",
      "check",
      "fully",
      "started",
      "up.",
      "contains",
      "two",
      "numbers",
      "form",
      "number",
      "containers",
      "running.",
      "means",
      "one"
    ],
    "language": "en",
    "word_count": 115,
    "importance_score": 3.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "verify the ud/ucmdb installation (eks)",
    "contentLower": "to verify if ud/ucmdb has been installed successfully, do the following: log in to the control plane node (embedded kubernetes) or the bastion node (managed kubernetes). run the following command to make sure that each of the pvcs is bound to an nfs volume. kubectl get pvc -n <ud/ucmdb namespace> example: # kubectl get pvc -n ucmdb-prod name status volume capacity access modes storageclass age ucmdb-configvolumeclaim bound ucmdb-prod-config-volume 5gi rwx 8h ucmdb-datavolumeclaim bound ucmdb-prod-data-volume 5gi rwx 8h ucmdb-logvolumeclaim bound ucmdb-prod-log-volume 5gi rwx 8h run the following command to see the pod status in the ud/ucmdb namespace. kubectl get pods -n <ud/ucmdb namespace> example: # kubectl get pods -n ucmdb-prod name ready status restarts age itom-autopass-lms-7bb6c57dbf-ttb4q 2/2 running 0 8h itom-cms-downloader-687849d8f4-r9bv4 2/2 running 0 8h itom-cms-gateway-5969db8f5d-26n7z 2/2 running 0 8h itom-cms-gateway-5969db8f5d-nn4h6 2/2 running 0 8h itom-idm-7c687c8f4",
    "keywordsLower": [
      "uducmdb",
      "verify",
      "ud",
      "ucmdb",
      "installation",
      "eks",
      "installed",
      "successfully",
      "following",
      "log",
      "control",
      "plane",
      "node",
      "embedded",
      "kubernetes",
      "bastion",
      "managed",
      "run",
      "command",
      "make",
      "sure",
      "pvcs",
      "bound",
      "nfs",
      "volume.",
      "kubectl",
      "get",
      "pvc",
      "-n",
      "example",
      "ucmdb-prod",
      "name",
      "status",
      "volume",
      "capacity",
      "access",
      "modes",
      "storageclass",
      "age",
      "ucmdb-configvolumeclaim",
      "ucmdb-prod-config-volume",
      "5gi",
      "rwx",
      "8h",
      "ucmdb-datavolumeclaim",
      "ucmdb-prod-data-volume",
      "ucmdb-logvolumeclaim",
      "ucmdb-prod-log-volume",
      "see",
      "pod",
      "namespace.",
      "pods",
      "ready",
      "restarts",
      "itom-autopass-lms-7bb6c57dbf-ttb4q",
      "running",
      "itom-cms-downloader-687849d8f4-r9bv4",
      "itom-cms-gateway-5969db8f5d-26n7z",
      "itom-cms-gateway-5969db8f5d-nn4h6",
      "itom-idm-7c687c8f49-kzs9t",
      "itom-idm-7c687c8f49-wl4hs",
      "itom-ingress-controller-58cd796778-d7cn7",
      "itom-ingress-controller-58cd796778-m9znp",
      "itom-ucmdb-0",
      "4h",
      "itom-ucmdb-1",
      "4h10m",
      "itom-ucmdb-browser-6dbcdd9586-dgf94",
      "itom-ucmdb-probe-6c554bc9d-rvxkq",
      "itom-ucmdb-solr-7b44ff67b7-vhhqj",
      "itom-vault-fd98f675b-smv8n",
      "column",
      "indicates",
      "current",
      "lifecycle",
      "state",
      "pod.",
      "pending",
      "completed",
      "init",
      "crashloopbackoff.",
      "many",
      "eventually",
      "becomes",
      "podinitializing",
      "state.",
      "addition",
      "check",
      "fully",
      "started",
      "up.",
      "contains",
      "two",
      "numbers",
      "form",
      "number",
      "containers",
      "running.",
      "means",
      "one"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Verify the UD/UCMDB installation (EKS) (FIPS mode)",
    "content": "To verify if UD/UCMDB has been installed successfully, do the following: Log in to the control plane node (embedded Kubernetes) or the bastion node (managed Kubernetes). Run the following command to make sure that each of the PVCs is bound to an NFS volume. kubectl get pvc -n <UD/UCMDB NAMESPACE> Example: # kubectl get pvc -n ucmdb-prod NAME STATUS VOLUME CAPACITY ACCESS MODES STORAGECLASS AGE ucmdb-configvolumeclaim Bound ucmdb-prod-config-volume 5Gi RWX 8h ucmdb-datavolumeclaim Bound ucmdb-prod-data-volume 5Gi RWX 8h ucmdb-logvolumeclaim Bound ucmdb-prod-log-volume 5Gi RWX 8h Check whether the UD/UCMDB pods are assigned to your UD/UCMDB worker nodes: kubectl get pods -o wide -n <UD/UCMDB NAMESPACE> Run the following command to see the pod status in the UD/UCMDB namespace. kubectl get pods -n <UD/UCMDB NAMESPACE> Example: # kubectl get pods -n ucmdb-prod NAME READY STATUS RESTARTS AGE itom-autopass-lms-7bb6c57dbf-ttb4q 2/2 Running 0 8h itom-cms-gateway-5969db8f5d-26n7z 2/2 Running 0 8",
    "url": "installcmswithsmaxverifyeksfips",
    "filename": "installcmswithsmaxverifyeksfips",
    "headings": [],
    "keywords": [
      "uducmdb",
      "verify",
      "ud",
      "ucmdb",
      "installation",
      "eks",
      "fips",
      "mode",
      "installed",
      "successfully",
      "following",
      "log",
      "control",
      "plane",
      "node",
      "embedded",
      "kubernetes",
      "bastion",
      "managed",
      "run",
      "command",
      "make",
      "sure",
      "pvcs",
      "bound",
      "nfs",
      "volume.",
      "kubectl",
      "get",
      "pvc",
      "-n",
      "example",
      "ucmdb-prod",
      "name",
      "status",
      "volume",
      "capacity",
      "access",
      "modes",
      "storageclass",
      "age",
      "ucmdb-configvolumeclaim",
      "ucmdb-prod-config-volume",
      "5gi",
      "rwx",
      "8h",
      "ucmdb-datavolumeclaim",
      "ucmdb-prod-data-volume",
      "ucmdb-logvolumeclaim",
      "ucmdb-prod-log-volume",
      "check",
      "whether",
      "pods",
      "assigned",
      "worker",
      "nodes",
      "-o",
      "wide",
      "see",
      "pod",
      "namespace.",
      "ready",
      "restarts",
      "itom-autopass-lms-7bb6c57dbf-ttb4q",
      "running",
      "itom-cms-gateway-5969db8f5d-26n7z",
      "itom-cms-gateway-5969db8f5d-nn4h6",
      "itom-idm-7c687c8f49-kzs9t",
      "itom-idm-7c687c8f49-wl4hs",
      "itom-ingress-controller-58cd796778-d7cn7",
      "itom-ingress-controller-58cd796778-m9znp",
      "itom-ucmdb-0",
      "4h",
      "itom-ucmdb-1",
      "4h10m",
      "itom-ucmdb-browser-6dbcdd9586-dgf94",
      "itom-vault-fd98f675b-smv8n",
      "column",
      "indicates",
      "current",
      "lifecycle",
      "state",
      "pod.",
      "pending",
      "completed",
      "init",
      "crashloopbackoff.",
      "many",
      "eventually",
      "becomes",
      "podinitializing",
      "state.",
      "addition",
      "fully",
      "started",
      "up.",
      "contains",
      "two",
      "numbers",
      "form"
    ],
    "language": "en",
    "word_count": 120,
    "importance_score": 2.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "verify the ud/ucmdb installation (eks) (fips mode)",
    "contentLower": "to verify if ud/ucmdb has been installed successfully, do the following: log in to the control plane node (embedded kubernetes) or the bastion node (managed kubernetes). run the following command to make sure that each of the pvcs is bound to an nfs volume. kubectl get pvc -n <ud/ucmdb namespace> example: # kubectl get pvc -n ucmdb-prod name status volume capacity access modes storageclass age ucmdb-configvolumeclaim bound ucmdb-prod-config-volume 5gi rwx 8h ucmdb-datavolumeclaim bound ucmdb-prod-data-volume 5gi rwx 8h ucmdb-logvolumeclaim bound ucmdb-prod-log-volume 5gi rwx 8h check whether the ud/ucmdb pods are assigned to your ud/ucmdb worker nodes: kubectl get pods -o wide -n <ud/ucmdb namespace> run the following command to see the pod status in the ud/ucmdb namespace. kubectl get pods -n <ud/ucmdb namespace> example: # kubectl get pods -n ucmdb-prod name ready status restarts age itom-autopass-lms-7bb6c57dbf-ttb4q 2/2 running 0 8h itom-cms-gateway-5969db8f5d-26n7z 2/2 running 0 8",
    "keywordsLower": [
      "uducmdb",
      "verify",
      "ud",
      "ucmdb",
      "installation",
      "eks",
      "fips",
      "mode",
      "installed",
      "successfully",
      "following",
      "log",
      "control",
      "plane",
      "node",
      "embedded",
      "kubernetes",
      "bastion",
      "managed",
      "run",
      "command",
      "make",
      "sure",
      "pvcs",
      "bound",
      "nfs",
      "volume.",
      "kubectl",
      "get",
      "pvc",
      "-n",
      "example",
      "ucmdb-prod",
      "name",
      "status",
      "volume",
      "capacity",
      "access",
      "modes",
      "storageclass",
      "age",
      "ucmdb-configvolumeclaim",
      "ucmdb-prod-config-volume",
      "5gi",
      "rwx",
      "8h",
      "ucmdb-datavolumeclaim",
      "ucmdb-prod-data-volume",
      "ucmdb-logvolumeclaim",
      "ucmdb-prod-log-volume",
      "check",
      "whether",
      "pods",
      "assigned",
      "worker",
      "nodes",
      "-o",
      "wide",
      "see",
      "pod",
      "namespace.",
      "ready",
      "restarts",
      "itom-autopass-lms-7bb6c57dbf-ttb4q",
      "running",
      "itom-cms-gateway-5969db8f5d-26n7z",
      "itom-cms-gateway-5969db8f5d-nn4h6",
      "itom-idm-7c687c8f49-kzs9t",
      "itom-idm-7c687c8f49-wl4hs",
      "itom-ingress-controller-58cd796778-d7cn7",
      "itom-ingress-controller-58cd796778-m9znp",
      "itom-ucmdb-0",
      "4h",
      "itom-ucmdb-1",
      "4h10m",
      "itom-ucmdb-browser-6dbcdd9586-dgf94",
      "itom-vault-fd98f675b-smv8n",
      "column",
      "indicates",
      "current",
      "lifecycle",
      "state",
      "pod.",
      "pending",
      "completed",
      "init",
      "crashloopbackoff.",
      "many",
      "eventually",
      "becomes",
      "podinitializing",
      "state.",
      "addition",
      "fully",
      "started",
      "up.",
      "contains",
      "two",
      "numbers",
      "form"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Uninstall UD/UCMDB on AWS",
    "content": "To uninstall UD/UCMDB on AWS with EKS, perform the following tasks: Delete the UD/UCMDB deployment Log on to the bastion node, navigate to the OPTIC Management Toolkit (OMT) installation directory: cd OMT_External_K8s_2x.x-xxx/bin Run the following command to remove the UD/UCMDB release: ./helm uninstall <UD/UCMDB RELEASE NAME> -n <UD/UCMDB NAMESPACE> Where: <UD/UCMDB RELEASE NAME> is the UD/UCMDB release that you want to uninstall, which you can get by running the command ./helm list -n <UD/UCMDB NAMESPACE>. <UD/UCMDB NAMESPACE> is the namespace where you installed UD/UCMDB. Run the following command to remove the OMT deployment: cd OMT_External_K8s_2x.x-xxx/scripts ./cdfctl deployment delete -d <UD/UCMDB DEPLOYMENT NAME> Where <UD/UCMDB DEPLOYMENT NAME> is the name you specified for the deployment you created to install UD/UCMDB. For example: ./cdfctl deployment delete -d ucmdb-prod You will need to enter the password of the administrator that you set during the OMT installation. Rem",
    "url": "uninstallcmswitheks",
    "filename": "uninstallcmswitheks",
    "headings": [
      "Delete the UD/UCMDB deployment",
      "Remove persistent volumes",
      "Clean the NFS volumes",
      "Clean the databases",
      "Related topics"
    ],
    "keywords": [
      "uducmdb",
      "pv.yaml",
      "cleanCMSNFS.sh",
      "uninstall",
      "ud",
      "ucmdb",
      "aws",
      "delete",
      "deployment",
      "remove",
      "persistent",
      "volumes",
      "clean",
      "nfs",
      "databases",
      "related",
      "topics",
      "eks",
      "perform",
      "following",
      "tasks",
      "log",
      "bastion",
      "node",
      "navigate",
      "optic",
      "management",
      "toolkit",
      "omt",
      "installation",
      "directory",
      "cd",
      "bin",
      "run",
      "command",
      "release",
      "helm",
      "-n",
      "want",
      "get",
      "running",
      "list",
      "namespace",
      "installed",
      "ucmdb.",
      "scripts",
      "cdfctl",
      "-d",
      "name",
      "specified",
      "created",
      "install",
      "example",
      "ucmdb-prod",
      "need",
      "enter",
      "password",
      "administrator",
      "set",
      "during",
      "installation.",
      "pvs",
      "based",
      "ucmdb-pv.yaml",
      "sample",
      "file",
      "documented",
      "create",
      "step",
      "kubectl",
      "-f",
      "tmp",
      "ucmdb-helm-charts",
      "samples",
      "copy",
      "save",
      "script",
      "bash",
      "shopt",
      "-s",
      "extglob",
      "edit",
      "needed",
      "mnt",
      "cms",
      "var",
      "vols",
      "itom",
      "rm",
      "-rf",
      "ls",
      "-l",
      "commands",
      "data",
      "storage",
      "chmod",
      "755",
      "sudo",
      "un-installation",
      "process"
    ],
    "language": "en",
    "word_count": 89,
    "importance_score": 5.5,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "uninstall ud/ucmdb on aws",
    "contentLower": "to uninstall ud/ucmdb on aws with eks, perform the following tasks: delete the ud/ucmdb deployment log on to the bastion node, navigate to the optic management toolkit (omt) installation directory: cd omt_external_k8s_2x.x-xxx/bin run the following command to remove the ud/ucmdb release: ./helm uninstall <ud/ucmdb release name> -n <ud/ucmdb namespace> where: <ud/ucmdb release name> is the ud/ucmdb release that you want to uninstall, which you can get by running the command ./helm list -n <ud/ucmdb namespace>. <ud/ucmdb namespace> is the namespace where you installed ud/ucmdb. run the following command to remove the omt deployment: cd omt_external_k8s_2x.x-xxx/scripts ./cdfctl deployment delete -d <ud/ucmdb deployment name> where <ud/ucmdb deployment name> is the name you specified for the deployment you created to install ud/ucmdb. for example: ./cdfctl deployment delete -d ucmdb-prod you will need to enter the password of the administrator that you set during the omt installation. rem",
    "keywordsLower": [
      "uducmdb",
      "pv.yaml",
      "cleancmsnfs.sh",
      "uninstall",
      "ud",
      "ucmdb",
      "aws",
      "delete",
      "deployment",
      "remove",
      "persistent",
      "volumes",
      "clean",
      "nfs",
      "databases",
      "related",
      "topics",
      "eks",
      "perform",
      "following",
      "tasks",
      "log",
      "bastion",
      "node",
      "navigate",
      "optic",
      "management",
      "toolkit",
      "omt",
      "installation",
      "directory",
      "cd",
      "bin",
      "run",
      "command",
      "release",
      "helm",
      "-n",
      "want",
      "get",
      "running",
      "list",
      "namespace",
      "installed",
      "ucmdb.",
      "scripts",
      "cdfctl",
      "-d",
      "name",
      "specified",
      "created",
      "install",
      "example",
      "ucmdb-prod",
      "need",
      "enter",
      "password",
      "administrator",
      "set",
      "during",
      "installation.",
      "pvs",
      "based",
      "ucmdb-pv.yaml",
      "sample",
      "file",
      "documented",
      "create",
      "step",
      "kubectl",
      "-f",
      "tmp",
      "ucmdb-helm-charts",
      "samples",
      "copy",
      "save",
      "script",
      "bash",
      "shopt",
      "-s",
      "extglob",
      "edit",
      "needed",
      "mnt",
      "cms",
      "var",
      "vols",
      "itom",
      "rm",
      "-rf",
      "ls",
      "-l",
      "commands",
      "data",
      "storage",
      "chmod",
      "755",
      "sudo",
      "un-installation",
      "process"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Verify the OO installation in EKS",
    "content": "To verify OO installation, do the following: Log in to the bastion node. Run the following command to make sure that all OO pods are ready. kubectl get pod -n <OO NAMESPACE> |grep -v 1/1|grep -v 2/2|grep -v 3/3|grep -v 4/4|grep -v Completed Where: <OO NAMESPACE> is the namespace where you deploy the OO chart. This command returns a list of abnormal pods. When it returns no results, all OO pods are ready.",
    "url": "installoocwithsmaxverifyeks",
    "filename": "installoocwithsmaxverifyeks",
    "headings": [],
    "keywords": [
      "verify",
      "oo",
      "installation",
      "eks",
      "following",
      "log",
      "bastion",
      "node.",
      "run",
      "command",
      "make",
      "sure",
      "all",
      "pods",
      "ready.",
      "kubectl",
      "get",
      "pod",
      "-n",
      "grep",
      "-v",
      "completed",
      "namespace",
      "deploy",
      "chart.",
      "returns",
      "list",
      "abnormal",
      "pods.",
      "results"
    ],
    "language": "en",
    "word_count": 58,
    "importance_score": 1.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "verify the oo installation in eks",
    "contentLower": "to verify oo installation, do the following: log in to the bastion node. run the following command to make sure that all oo pods are ready. kubectl get pod -n <oo namespace> |grep -v 1/1|grep -v 2/2|grep -v 3/3|grep -v 4/4|grep -v completed where: <oo namespace> is the namespace where you deploy the oo chart. this command returns a list of abnormal pods. when it returns no results, all oo pods are ready.",
    "keywordsLower": [
      "verify",
      "oo",
      "installation",
      "eks",
      "following",
      "log",
      "bastion",
      "node.",
      "run",
      "command",
      "make",
      "sure",
      "all",
      "pods",
      "ready.",
      "kubectl",
      "get",
      "pod",
      "-n",
      "grep",
      "-v",
      "completed",
      "namespace",
      "deploy",
      "chart.",
      "returns",
      "list",
      "abnormal",
      "pods.",
      "results"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Uninstall OO on AWS",
    "content": "To uninstall Operations Orchestration (OO) on AWS with EKS, perform the following tasks: Delete the OO deployment Log on to the bastion node, and navigate to the OPTIC Management Toolkit (OMT) installation directory: cd <OMT_External_K8s_2x.x-xxx>/bin Run the following command to remove the OO release: ./helm uninstall <OO RELEASE NAME> -n <OO NAMESPACE> Where: <OO RELEASE NAME> is the OO release that you want to uninstall, which you can get by running the command ./helm list -n <OO NAMESPACE>. <OO NAMESPACE> is the namespace where you installed OO. Run the following command to remove the OO deployment: cd <OMT_External_K8s_2x.x-xxx>/scripts ./cdfctl.sh deployment delete -d <OO DEPLOYMENT NAME> Where: <OO DEPLOYMENT NAME> is the name you specified for the deployment you created to install OO. For example: ./cdfctl.sh deployment delete -d oo-prod You need to enter the administrator password you set during the OMT installation. Remove persistent volume and claims If you created the oo-pv",
    "url": "399-uninstallooconeks",
    "filename": "399-uninstallooconeks",
    "headings": [
      "Delete the OO deployment",
      "Remove persistent volume and claims",
      "Clean the Amazon Elastic File System volumes",
      "Clean the databases"
    ],
    "keywords": [
      "cdfctl.sh",
      "cleanOONFS.sh",
      "pv.yaml",
      "pvc.yaml",
      "uninstall",
      "oo",
      "aws",
      "delete",
      "deployment",
      "remove",
      "persistent",
      "volume",
      "claims",
      "clean",
      "amazon",
      "elastic",
      "file",
      "system",
      "volumes",
      "databases",
      "operations",
      "orchestration",
      "eks",
      "perform",
      "following",
      "tasks",
      "log",
      "bastion",
      "node",
      "navigate",
      "optic",
      "management",
      "toolkit",
      "omt",
      "installation",
      "directory",
      "cd",
      "bin",
      "run",
      "command",
      "release",
      "helm",
      "-n",
      "want",
      "get",
      "running",
      "list",
      "namespace",
      "installed",
      "oo.",
      "scripts",
      "-d",
      "name",
      "specified",
      "created",
      "install",
      "example",
      "oo-prod",
      "need",
      "enter",
      "administrator",
      "password",
      "set",
      "during",
      "installation.",
      "oo-pv.yaml",
      "sample",
      "documented",
      "prepare",
      "step",
      "kubectl",
      "-f",
      "oo-helm-charts-1.x.x",
      "26.x.x",
      "oo-helm-charts",
      "samples",
      "oo-pvc.yaml",
      "copy",
      "save",
      "script",
      "bash",
      "shopt",
      "-s",
      "extglob",
      "edit",
      "needed",
      "mnt",
      "var",
      "vols",
      "itom",
      "rm",
      "-rf",
      "ls",
      "-l",
      "commands",
      "data",
      "nfs",
      "storage",
      "chmod",
      "755"
    ],
    "language": "en",
    "word_count": 87,
    "importance_score": 5.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "uninstall oo on aws",
    "contentLower": "to uninstall operations orchestration (oo) on aws with eks, perform the following tasks: delete the oo deployment log on to the bastion node, and navigate to the optic management toolkit (omt) installation directory: cd <omt_external_k8s_2x.x-xxx>/bin run the following command to remove the oo release: ./helm uninstall <oo release name> -n <oo namespace> where: <oo release name> is the oo release that you want to uninstall, which you can get by running the command ./helm list -n <oo namespace>. <oo namespace> is the namespace where you installed oo. run the following command to remove the oo deployment: cd <omt_external_k8s_2x.x-xxx>/scripts ./cdfctl.sh deployment delete -d <oo deployment name> where: <oo deployment name> is the name you specified for the deployment you created to install oo. for example: ./cdfctl.sh deployment delete -d oo-prod you need to enter the administrator password you set during the omt installation. remove persistent volume and claims if you created the oo-pv",
    "keywordsLower": [
      "cdfctl.sh",
      "cleanoonfs.sh",
      "pv.yaml",
      "pvc.yaml",
      "uninstall",
      "oo",
      "aws",
      "delete",
      "deployment",
      "remove",
      "persistent",
      "volume",
      "claims",
      "clean",
      "amazon",
      "elastic",
      "file",
      "system",
      "volumes",
      "databases",
      "operations",
      "orchestration",
      "eks",
      "perform",
      "following",
      "tasks",
      "log",
      "bastion",
      "node",
      "navigate",
      "optic",
      "management",
      "toolkit",
      "omt",
      "installation",
      "directory",
      "cd",
      "bin",
      "run",
      "command",
      "release",
      "helm",
      "-n",
      "want",
      "get",
      "running",
      "list",
      "namespace",
      "installed",
      "oo.",
      "scripts",
      "-d",
      "name",
      "specified",
      "created",
      "install",
      "example",
      "oo-prod",
      "need",
      "enter",
      "administrator",
      "password",
      "set",
      "during",
      "installation.",
      "oo-pv.yaml",
      "sample",
      "documented",
      "prepare",
      "step",
      "kubectl",
      "-f",
      "oo-helm-charts-1.x.x",
      "26.x.x",
      "oo-helm-charts",
      "samples",
      "oo-pvc.yaml",
      "copy",
      "save",
      "script",
      "bash",
      "shopt",
      "-s",
      "extglob",
      "edit",
      "needed",
      "mnt",
      "var",
      "vols",
      "itom",
      "rm",
      "-rf",
      "ls",
      "-l",
      "commands",
      "data",
      "nfs",
      "storage",
      "chmod",
      "755"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Uninstall Audit on AWS (EKS)",
    "content": "To uninstall Audit service, perform the following tasks: Delete the Audit deployment Log on to the bastion node. Run the following command to remove the Audit release: helm uninstall <Audit Release Name> -n <Namespace> where, <Audit Release Name> is the Audit release that you want to uninstall <Namespace> is the namespace where you installed Audit Go to the $CDF_HOME/scripts folder and run the following command: ./cdfctl.sh deployment delete -d <Audit Deployment Name> where, <Audit Deployment Name> is the name you specified for the deployment you created to install Audit. For example: ./cdfctl.sh deployment delete -d audit-prod Remove persistent volumes If you created PVs based on the itom-audit-pv.yaml sample file, you can run the following command to delete the persistent volumes: kubectl delete -f itom-audit-pv.yaml Clean the EFS volumes Log on to the Elastic File System (EFS) server host and clear all the contents in the EFS volume directories that you created. For example: rm -rf ",
    "url": "uninstallauditeks",
    "filename": "uninstallauditeks",
    "headings": [
      "Delete the Audit deployment",
      "Remove persistent volumes",
      "Clean the EFS volumes",
      "Clean the databases"
    ],
    "keywords": [
      "cdfctl.sh",
      "pv.yaml",
      "uninstall",
      "audit",
      "aws",
      "eks",
      "delete",
      "deployment",
      "remove",
      "persistent",
      "volumes",
      "clean",
      "efs",
      "databases",
      "service",
      "perform",
      "following",
      "tasks",
      "log",
      "bastion",
      "node.",
      "run",
      "command",
      "release",
      "helm",
      "-n",
      "want",
      "namespace",
      "installed",
      "go",
      "scripts",
      "folder",
      "-d",
      "name",
      "specified",
      "created",
      "install",
      "audit.",
      "example",
      "audit-prod",
      "pvs",
      "based",
      "itom-audit-pv.yaml",
      "sample",
      "file",
      "kubectl",
      "-f",
      "elastic",
      "system",
      "server",
      "host",
      "clear",
      "all",
      "contents",
      "volume",
      "directories",
      "created.",
      "rm",
      "-rf",
      "var",
      "vols",
      "itom",
      "auditns",
      "vault",
      "uninstallation",
      "process",
      "doesn",
      "external",
      "postgresql",
      "server.",
      "need",
      "manually."
    ],
    "language": "en",
    "word_count": 94,
    "importance_score": 5.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "uninstall audit on aws (eks)",
    "contentLower": "to uninstall audit service, perform the following tasks: delete the audit deployment log on to the bastion node. run the following command to remove the audit release: helm uninstall <audit release name> -n <namespace> where, <audit release name> is the audit release that you want to uninstall <namespace> is the namespace where you installed audit go to the $cdf_home/scripts folder and run the following command: ./cdfctl.sh deployment delete -d <audit deployment name> where, <audit deployment name> is the name you specified for the deployment you created to install audit. for example: ./cdfctl.sh deployment delete -d audit-prod remove persistent volumes if you created pvs based on the itom-audit-pv.yaml sample file, you can run the following command to delete the persistent volumes: kubectl delete -f itom-audit-pv.yaml clean the efs volumes log on to the elastic file system (efs) server host and clear all the contents in the efs volume directories that you created. for example: rm -rf ",
    "keywordsLower": [
      "cdfctl.sh",
      "pv.yaml",
      "uninstall",
      "audit",
      "aws",
      "eks",
      "delete",
      "deployment",
      "remove",
      "persistent",
      "volumes",
      "clean",
      "efs",
      "databases",
      "service",
      "perform",
      "following",
      "tasks",
      "log",
      "bastion",
      "node.",
      "run",
      "command",
      "release",
      "helm",
      "-n",
      "want",
      "namespace",
      "installed",
      "go",
      "scripts",
      "folder",
      "-d",
      "name",
      "specified",
      "created",
      "install",
      "audit.",
      "example",
      "audit-prod",
      "pvs",
      "based",
      "itom-audit-pv.yaml",
      "sample",
      "file",
      "kubectl",
      "-f",
      "elastic",
      "system",
      "server",
      "host",
      "clear",
      "all",
      "contents",
      "volume",
      "directories",
      "created.",
      "rm",
      "-rf",
      "var",
      "vols",
      "itom",
      "auditns",
      "vault",
      "uninstallation",
      "process",
      "doesn",
      "external",
      "postgresql",
      "server.",
      "need",
      "manually."
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Uninstall Audit collector on AWS (EKS)",
    "content": "The information in this document applies only to classic deployments where the Audit Collector is installed using its own helm chart rather than the Enterprise Service Management (ESM) helm chart. To uninstall Audit collector, perform the following tasks: Delete the Audit collector Log on to the bastion node. Run the following command to remove the Audit collector: helm uninstall <Audit Collector Release Name> -n <Audit Producer Namespace> where, <Audit Collector Release Name> is the Audit collector release name that you want to uninstall. <Audit Producer Namespace> is the namespace where you installed the Audit producer. Clean the NFS volumes Log on to the NFS server host and clear all the contents in the NFS volume directories that you have created for the Audit collector. For example: rm -rf /var/vols/itom/itsma/global-volume/logs/audit-collector/*",
    "url": "uninstallauditcollectoreks",
    "filename": "uninstallauditcollectoreks",
    "headings": [
      "Delete the Audit collector",
      "Clean the NFS volumes"
    ],
    "keywords": [
      "uninstall",
      "audit",
      "collector",
      "aws",
      "eks",
      "delete",
      "clean",
      "nfs",
      "volumes",
      "information",
      "document",
      "applies",
      "classic",
      "deployments",
      "installed",
      "own",
      "helm",
      "chart",
      "rather",
      "enterprise",
      "service",
      "management",
      "esm",
      "chart.",
      "perform",
      "following",
      "tasks",
      "log",
      "bastion",
      "node.",
      "run",
      "command",
      "remove",
      "-n",
      "release",
      "name",
      "want",
      "uninstall.",
      "namespace",
      "producer.",
      "server",
      "host",
      "clear",
      "all",
      "contents",
      "volume",
      "directories",
      "created",
      "collector.",
      "example",
      "rm",
      "-rf",
      "var",
      "vols",
      "itom",
      "itsma",
      "global-volume",
      "logs",
      "audit-collector"
    ],
    "language": "en",
    "word_count": 80,
    "importance_score": 3.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "uninstall audit collector on aws (eks)",
    "contentLower": "the information in this document applies only to classic deployments where the audit collector is installed using its own helm chart rather than the enterprise service management (esm) helm chart. to uninstall audit collector, perform the following tasks: delete the audit collector log on to the bastion node. run the following command to remove the audit collector: helm uninstall <audit collector release name> -n <audit producer namespace> where, <audit collector release name> is the audit collector release name that you want to uninstall. <audit producer namespace> is the namespace where you installed the audit producer. clean the nfs volumes log on to the nfs server host and clear all the contents in the nfs volume directories that you have created for the audit collector. for example: rm -rf /var/vols/itom/itsma/global-volume/logs/audit-collector/*",
    "keywordsLower": [
      "uninstall",
      "audit",
      "collector",
      "aws",
      "eks",
      "delete",
      "clean",
      "nfs",
      "volumes",
      "information",
      "document",
      "applies",
      "classic",
      "deployments",
      "installed",
      "own",
      "helm",
      "chart",
      "rather",
      "enterprise",
      "service",
      "management",
      "esm",
      "chart.",
      "perform",
      "following",
      "tasks",
      "log",
      "bastion",
      "node.",
      "run",
      "command",
      "remove",
      "-n",
      "release",
      "name",
      "want",
      "uninstall.",
      "namespace",
      "producer.",
      "server",
      "host",
      "clear",
      "all",
      "contents",
      "volume",
      "directories",
      "created",
      "collector.",
      "example",
      "rm",
      "-rf",
      "var",
      "vols",
      "itom",
      "itsma",
      "global-volume",
      "logs",
      "audit-collector"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Verify the UD/UCMDB installation (AKS)",
    "content": "To verify if UD/UCMDB has been installed successfully, do the following: Log in to the control plane node (embedded Kubernetes) or the bastion node (managed Kubernetes). Run the following command to make sure that each of the PVCs is bound to an NFS volume. kubectl get pvc -n <UD/UCMDB NAMESPACE> Example: # kubectl get pvc -n ucmdb-prod NAME STATUS VOLUME CAPACITY ACCESS MODES STORAGECLASS AGE ucmdb-configvolumeclaim Bound ucmdb-prod-config-volume 5Gi RWX 8h ucmdb-datavolumeclaim Bound ucmdb-prod-data-volume 5Gi RWX 8h ucmdb-logvolumeclaim Bound ucmdb-prod-log-volume 5Gi RWX 8h Run the following command to see the pod status in the UD/UCMDB namespace. kubectl get pods -n <UD/UCMDB NAMESPACE> Example: # kubectl get pods -n ucmdb-prod NAME READY STATUS RESTARTS AGE itom-autopass-lms-7bb6c57dbf-ttb4q 2/2 Running 0 8h itom-cms-downloader-687849d8f4-r9bv4 2/2 Running 0 8h itom-cms-gateway-5969db8f5d-26n7z 2/2 Running 0 8h itom-cms-gateway-5969db8f5d-nn4h6 2/2 Running 0 8h itom-idm-7c687c8f4",
    "url": "installcmswithsmaxverifyaks",
    "filename": "installcmswithsmaxverifyaks",
    "headings": [],
    "keywords": [
      "uducmdb",
      "verify",
      "ud",
      "ucmdb",
      "installation",
      "aks",
      "installed",
      "successfully",
      "following",
      "log",
      "control",
      "plane",
      "node",
      "embedded",
      "kubernetes",
      "bastion",
      "managed",
      "run",
      "command",
      "make",
      "sure",
      "pvcs",
      "bound",
      "nfs",
      "volume.",
      "kubectl",
      "get",
      "pvc",
      "-n",
      "example",
      "ucmdb-prod",
      "name",
      "status",
      "volume",
      "capacity",
      "access",
      "modes",
      "storageclass",
      "age",
      "ucmdb-configvolumeclaim",
      "ucmdb-prod-config-volume",
      "5gi",
      "rwx",
      "8h",
      "ucmdb-datavolumeclaim",
      "ucmdb-prod-data-volume",
      "ucmdb-logvolumeclaim",
      "ucmdb-prod-log-volume",
      "see",
      "pod",
      "namespace.",
      "pods",
      "ready",
      "restarts",
      "itom-autopass-lms-7bb6c57dbf-ttb4q",
      "running",
      "itom-cms-downloader-687849d8f4-r9bv4",
      "itom-cms-gateway-5969db8f5d-26n7z",
      "itom-cms-gateway-5969db8f5d-nn4h6",
      "itom-idm-7c687c8f49-kzs9t",
      "itom-idm-7c687c8f49-wl4hs",
      "itom-ingress-controller-58cd796778-d7cn7",
      "itom-ingress-controller-58cd796778-m9znp",
      "itom-ucmdb-0",
      "4h",
      "itom-ucmdb-1",
      "4h10m",
      "itom-ucmdb-browser-6dbcdd9586-dgf94",
      "itom-ucmdb-probe-6c554bc9d-rvxkq",
      "itom-ucmdb-solr-7b44ff67b7-vhhqj",
      "itom-vault-fd98f675b-smv8n",
      "column",
      "indicates",
      "current",
      "lifecycle",
      "state",
      "pod.",
      "pending",
      "completed",
      "init",
      "crashloopbackoff.",
      "many",
      "eventually",
      "becomes",
      "podinitializing",
      "state.",
      "addition",
      "check",
      "fully",
      "started",
      "up.",
      "contains",
      "two",
      "numbers",
      "form",
      "number",
      "containers",
      "running.",
      "means",
      "one"
    ],
    "language": "en",
    "word_count": 115,
    "importance_score": 3.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "verify the ud/ucmdb installation (aks)",
    "contentLower": "to verify if ud/ucmdb has been installed successfully, do the following: log in to the control plane node (embedded kubernetes) or the bastion node (managed kubernetes). run the following command to make sure that each of the pvcs is bound to an nfs volume. kubectl get pvc -n <ud/ucmdb namespace> example: # kubectl get pvc -n ucmdb-prod name status volume capacity access modes storageclass age ucmdb-configvolumeclaim bound ucmdb-prod-config-volume 5gi rwx 8h ucmdb-datavolumeclaim bound ucmdb-prod-data-volume 5gi rwx 8h ucmdb-logvolumeclaim bound ucmdb-prod-log-volume 5gi rwx 8h run the following command to see the pod status in the ud/ucmdb namespace. kubectl get pods -n <ud/ucmdb namespace> example: # kubectl get pods -n ucmdb-prod name ready status restarts age itom-autopass-lms-7bb6c57dbf-ttb4q 2/2 running 0 8h itom-cms-downloader-687849d8f4-r9bv4 2/2 running 0 8h itom-cms-gateway-5969db8f5d-26n7z 2/2 running 0 8h itom-cms-gateway-5969db8f5d-nn4h6 2/2 running 0 8h itom-idm-7c687c8f4",
    "keywordsLower": [
      "uducmdb",
      "verify",
      "ud",
      "ucmdb",
      "installation",
      "aks",
      "installed",
      "successfully",
      "following",
      "log",
      "control",
      "plane",
      "node",
      "embedded",
      "kubernetes",
      "bastion",
      "managed",
      "run",
      "command",
      "make",
      "sure",
      "pvcs",
      "bound",
      "nfs",
      "volume.",
      "kubectl",
      "get",
      "pvc",
      "-n",
      "example",
      "ucmdb-prod",
      "name",
      "status",
      "volume",
      "capacity",
      "access",
      "modes",
      "storageclass",
      "age",
      "ucmdb-configvolumeclaim",
      "ucmdb-prod-config-volume",
      "5gi",
      "rwx",
      "8h",
      "ucmdb-datavolumeclaim",
      "ucmdb-prod-data-volume",
      "ucmdb-logvolumeclaim",
      "ucmdb-prod-log-volume",
      "see",
      "pod",
      "namespace.",
      "pods",
      "ready",
      "restarts",
      "itom-autopass-lms-7bb6c57dbf-ttb4q",
      "running",
      "itom-cms-downloader-687849d8f4-r9bv4",
      "itom-cms-gateway-5969db8f5d-26n7z",
      "itom-cms-gateway-5969db8f5d-nn4h6",
      "itom-idm-7c687c8f49-kzs9t",
      "itom-idm-7c687c8f49-wl4hs",
      "itom-ingress-controller-58cd796778-d7cn7",
      "itom-ingress-controller-58cd796778-m9znp",
      "itom-ucmdb-0",
      "4h",
      "itom-ucmdb-1",
      "4h10m",
      "itom-ucmdb-browser-6dbcdd9586-dgf94",
      "itom-ucmdb-probe-6c554bc9d-rvxkq",
      "itom-ucmdb-solr-7b44ff67b7-vhhqj",
      "itom-vault-fd98f675b-smv8n",
      "column",
      "indicates",
      "current",
      "lifecycle",
      "state",
      "pod.",
      "pending",
      "completed",
      "init",
      "crashloopbackoff.",
      "many",
      "eventually",
      "becomes",
      "podinitializing",
      "state.",
      "addition",
      "check",
      "fully",
      "started",
      "up.",
      "contains",
      "two",
      "numbers",
      "form",
      "number",
      "containers",
      "running.",
      "means",
      "one"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Uninstall UD/UCMDB on Azure",
    "content": "To uninstall UD/UCMDB on Azure, perform the tasks in this section.Delete the UD/UCMDB deployment Log on to the bastion node, navigate to the OPTIC Management Toolkit (OMT) installation directory: cd OMT_External_K8s_2x.x-xxx/bin Run the following command to remove the UD/UCMDB release: ./helm uninstall <UD/UCMDB RELEASE NAME> -n <UD/UCMDB NAMESPACE> Where: <UD/UCMDB RELEASE NAME> is the UD/UCMDB release that you want to uninstall, which you can get by running the command ./helm list -n <UD/UCMDB NAMESPACE>. <UD/UCMDB NAMESPACE> is the namespace where you installed UD/UCMDB. Run the following command to remove the OMT deployment: cd OMT_External_K8s_2x.x-xxx/scripts ./cdfctl deployment delete -d <CMS DEPLOYMENT NAME> Where <CMS DEPLOYMENT NAME> is the name you specified for the deployment you created to install UD/UCMDB. For example: ./cdfctl deployment delete -d ucmdb-prod You will need to enter the password of the administrator that you set during the OMT installation. Remove persiste",
    "url": "uninstallcmswithaks",
    "filename": "uninstallcmswithaks",
    "headings": [
      "Delete the UD/UCMDB deployment",
      "Remove persistent volumes",
      "Clean the NFS volumes",
      "Clean the databases"
    ],
    "keywords": [
      "uducmdb",
      "volume.yaml",
      "cleanCMSNFS.sh",
      "uninstall",
      "ud",
      "ucmdb",
      "azure",
      "delete",
      "deployment",
      "remove",
      "persistent",
      "volumes",
      "clean",
      "nfs",
      "databases",
      "perform",
      "tasks",
      "section.delete",
      "log",
      "bastion",
      "node",
      "navigate",
      "optic",
      "management",
      "toolkit",
      "omt",
      "installation",
      "directory",
      "cd",
      "bin",
      "run",
      "following",
      "command",
      "release",
      "helm",
      "-n",
      "want",
      "get",
      "running",
      "list",
      "namespace",
      "installed",
      "ucmdb.",
      "scripts",
      "cdfctl",
      "-d",
      "name",
      "specified",
      "created",
      "install",
      "example",
      "ucmdb-prod",
      "need",
      "enter",
      "password",
      "administrator",
      "set",
      "during",
      "installation.",
      "volumesif",
      "pvs",
      "instructions",
      "subscribe",
      "premium",
      "files",
      "kubectl",
      "-f",
      "tmp",
      "cmspvyamlsfolder",
      "ucmdb-config-volume.yaml",
      "ucmdb-data-volume.yaml",
      "ucmdb-log-volume.yamlclean",
      "volumescopy",
      "save",
      "script",
      "bash",
      "shopt",
      "-s",
      "extglob",
      "edit",
      "needed",
      "mnt",
      "var",
      "vols",
      "itom",
      "cms",
      "rm",
      "-rf",
      "ls",
      "-l",
      "storage",
      "service",
      "commands",
      "data",
      "chmod",
      "755",
      "sudo",
      "file",
      "share",
      "storing"
    ],
    "language": "en",
    "word_count": 88,
    "importance_score": 5.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "uninstall ud/ucmdb on azure",
    "contentLower": "to uninstall ud/ucmdb on azure, perform the tasks in this section.delete the ud/ucmdb deployment log on to the bastion node, navigate to the optic management toolkit (omt) installation directory: cd omt_external_k8s_2x.x-xxx/bin run the following command to remove the ud/ucmdb release: ./helm uninstall <ud/ucmdb release name> -n <ud/ucmdb namespace> where: <ud/ucmdb release name> is the ud/ucmdb release that you want to uninstall, which you can get by running the command ./helm list -n <ud/ucmdb namespace>. <ud/ucmdb namespace> is the namespace where you installed ud/ucmdb. run the following command to remove the omt deployment: cd omt_external_k8s_2x.x-xxx/scripts ./cdfctl deployment delete -d <cms deployment name> where <cms deployment name> is the name you specified for the deployment you created to install ud/ucmdb. for example: ./cdfctl deployment delete -d ucmdb-prod you will need to enter the password of the administrator that you set during the omt installation. remove persiste",
    "keywordsLower": [
      "uducmdb",
      "volume.yaml",
      "cleancmsnfs.sh",
      "uninstall",
      "ud",
      "ucmdb",
      "azure",
      "delete",
      "deployment",
      "remove",
      "persistent",
      "volumes",
      "clean",
      "nfs",
      "databases",
      "perform",
      "tasks",
      "section.delete",
      "log",
      "bastion",
      "node",
      "navigate",
      "optic",
      "management",
      "toolkit",
      "omt",
      "installation",
      "directory",
      "cd",
      "bin",
      "run",
      "following",
      "command",
      "release",
      "helm",
      "-n",
      "want",
      "get",
      "running",
      "list",
      "namespace",
      "installed",
      "ucmdb.",
      "scripts",
      "cdfctl",
      "-d",
      "name",
      "specified",
      "created",
      "install",
      "example",
      "ucmdb-prod",
      "need",
      "enter",
      "password",
      "administrator",
      "set",
      "during",
      "installation.",
      "volumesif",
      "pvs",
      "instructions",
      "subscribe",
      "premium",
      "files",
      "kubectl",
      "-f",
      "tmp",
      "cmspvyamlsfolder",
      "ucmdb-config-volume.yaml",
      "ucmdb-data-volume.yaml",
      "ucmdb-log-volume.yamlclean",
      "volumescopy",
      "save",
      "script",
      "bash",
      "shopt",
      "-s",
      "extglob",
      "edit",
      "needed",
      "mnt",
      "var",
      "vols",
      "itom",
      "cms",
      "rm",
      "-rf",
      "ls",
      "-l",
      "storage",
      "service",
      "commands",
      "data",
      "chmod",
      "755",
      "sudo",
      "file",
      "share",
      "storing"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Verify the OO installation in AKS",
    "content": "To verify OO installation, do the following: Log in to the bastion node. Run the following command to make sure that all OO pods are ready. kubectl get pod -n <OO NAMESPACE> |grep -v 1/1|grep -v 2/2|grep -v 3/3|grep -v 4/4|grep -v Completed Where: <OO NAMESPACE> is the namespace where you deploy the OO chart. This command returns a list of abnormal pods. When it returns no results, all OO pods are ready.",
    "url": "verifyinstallooaks",
    "filename": "verifyinstallooaks",
    "headings": [],
    "keywords": [
      "verify",
      "oo",
      "installation",
      "aks",
      "following",
      "log",
      "bastion",
      "node.",
      "run",
      "command",
      "make",
      "sure",
      "all",
      "pods",
      "ready.",
      "kubectl",
      "get",
      "pod",
      "-n",
      "grep",
      "-v",
      "completed",
      "namespace",
      "deploy",
      "chart.",
      "returns",
      "list",
      "abnormal",
      "pods.",
      "results"
    ],
    "language": "en",
    "word_count": 58,
    "importance_score": 1.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "verify the oo installation in aks",
    "contentLower": "to verify oo installation, do the following: log in to the bastion node. run the following command to make sure that all oo pods are ready. kubectl get pod -n <oo namespace> |grep -v 1/1|grep -v 2/2|grep -v 3/3|grep -v 4/4|grep -v completed where: <oo namespace> is the namespace where you deploy the oo chart. this command returns a list of abnormal pods. when it returns no results, all oo pods are ready.",
    "keywordsLower": [
      "verify",
      "oo",
      "installation",
      "aks",
      "following",
      "log",
      "bastion",
      "node.",
      "run",
      "command",
      "make",
      "sure",
      "all",
      "pods",
      "ready.",
      "kubectl",
      "get",
      "pod",
      "-n",
      "grep",
      "-v",
      "completed",
      "namespace",
      "deploy",
      "chart.",
      "returns",
      "list",
      "abnormal",
      "pods.",
      "results"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Uninstall OO on Azure",
    "content": "To uninstall Operations Orchestration Containerized (OO Containerized) on Azure with AKS, perform the following tasks: Delete the OO deployment Log on to the bastion node, and navigate to the OPTIC Management Toolkit (OMT) installation directory: cd <OMT_External_K8s_2x.x-xxx>/bin Run the following command to remove the OO release: ./helm uninstall <OO RELEASE NAME> -n <OO NAMESPACE> Where: <OO RELEASE NAME> is the OO release that you want to uninstall, which you can get by running the command ./helm list -n <OO NAMESPACE>. <OO NAMESPACE> is the namespace where you installed OO. Run the following command to remove the OO deployment: cd <OMT_External_K8s_2x.x-xxx>/scripts ./cdfctl.sh deployment delete -d <OO DEPLOYMENT NAME> Where <OO DEPLOYMENT NAME> is the name you specified for the deployment you created to install OO. For example: ./cdfctl.sh deployment delete -d oo-prod You will need to enter the password of the administrator that you set during the OMT installation. Remove persist",
    "url": "399-uninstallooaks",
    "filename": "399-uninstallooaks",
    "headings": [
      "Delete the OO deployment",
      "Remove persistent volume and claims",
      "Clean the file system volumes",
      "Clean the databases"
    ],
    "keywords": [
      "cdfctl.sh",
      "pv.yaml",
      "pvc.yaml",
      "uninstall",
      "oo",
      "azure",
      "delete",
      "deployment",
      "remove",
      "persistent",
      "volume",
      "claims",
      "clean",
      "file",
      "system",
      "volumes",
      "databases",
      "operations",
      "orchestration",
      "containerized",
      "aks",
      "perform",
      "following",
      "tasks",
      "log",
      "bastion",
      "node",
      "navigate",
      "optic",
      "management",
      "toolkit",
      "omt",
      "installation",
      "directory",
      "cd",
      "bin",
      "run",
      "command",
      "release",
      "helm",
      "-n",
      "want",
      "get",
      "running",
      "list",
      "namespace",
      "installed",
      "oo.",
      "scripts",
      "-d",
      "name",
      "specified",
      "created",
      "install",
      "example",
      "oo-prod",
      "need",
      "enter",
      "password",
      "administrator",
      "set",
      "during",
      "installation.",
      "oo-pv.yaml",
      "sample",
      "documented",
      "prepare",
      "kubectl",
      "-f",
      "oo-helm-charts-1.x.x",
      "26.x.x",
      "oo-helm-charts",
      "samples",
      "oo-pvc.yaml",
      "mounted",
      "mnt",
      "nfs",
      "rm",
      "-rf",
      "var",
      "vols",
      "itom",
      "share",
      "configure",
      "premium",
      "files",
      "residing",
      "external",
      "postgresql",
      "aren",
      "removed.",
      "manually.",
      "different",
      "names",
      "creating",
      "database",
      "users",
      "components",
      "replace",
      "default"
    ],
    "language": "en",
    "word_count": 85,
    "importance_score": 5.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "uninstall oo on azure",
    "contentLower": "to uninstall operations orchestration containerized (oo containerized) on azure with aks, perform the following tasks: delete the oo deployment log on to the bastion node, and navigate to the optic management toolkit (omt) installation directory: cd <omt_external_k8s_2x.x-xxx>/bin run the following command to remove the oo release: ./helm uninstall <oo release name> -n <oo namespace> where: <oo release name> is the oo release that you want to uninstall, which you can get by running the command ./helm list -n <oo namespace>. <oo namespace> is the namespace where you installed oo. run the following command to remove the oo deployment: cd <omt_external_k8s_2x.x-xxx>/scripts ./cdfctl.sh deployment delete -d <oo deployment name> where <oo deployment name> is the name you specified for the deployment you created to install oo. for example: ./cdfctl.sh deployment delete -d oo-prod you will need to enter the password of the administrator that you set during the omt installation. remove persist",
    "keywordsLower": [
      "cdfctl.sh",
      "pv.yaml",
      "pvc.yaml",
      "uninstall",
      "oo",
      "azure",
      "delete",
      "deployment",
      "remove",
      "persistent",
      "volume",
      "claims",
      "clean",
      "file",
      "system",
      "volumes",
      "databases",
      "operations",
      "orchestration",
      "containerized",
      "aks",
      "perform",
      "following",
      "tasks",
      "log",
      "bastion",
      "node",
      "navigate",
      "optic",
      "management",
      "toolkit",
      "omt",
      "installation",
      "directory",
      "cd",
      "bin",
      "run",
      "command",
      "release",
      "helm",
      "-n",
      "want",
      "get",
      "running",
      "list",
      "namespace",
      "installed",
      "oo.",
      "scripts",
      "-d",
      "name",
      "specified",
      "created",
      "install",
      "example",
      "oo-prod",
      "need",
      "enter",
      "password",
      "administrator",
      "set",
      "during",
      "installation.",
      "oo-pv.yaml",
      "sample",
      "documented",
      "prepare",
      "kubectl",
      "-f",
      "oo-helm-charts-1.x.x",
      "26.x.x",
      "oo-helm-charts",
      "samples",
      "oo-pvc.yaml",
      "mounted",
      "mnt",
      "nfs",
      "rm",
      "-rf",
      "var",
      "vols",
      "itom",
      "share",
      "configure",
      "premium",
      "files",
      "residing",
      "external",
      "postgresql",
      "aren",
      "removed.",
      "manually.",
      "different",
      "names",
      "creating",
      "database",
      "users",
      "components",
      "replace",
      "default"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Verify the OO installation on GKE",
    "content": "To verify OO installation in GKE, do the following: Log in to the bastion node. Run the following command to ensure that all OO pods are ready. kubectl get pod -n <OO NAMESPACE> |grep -v 1/1|grep -v 2/2|grep -v 3/3|grep -v 4/4|grep -v Completed Where: <OO NAMESPACE> is the namespace where you deploy the OO chart. This command returns a list of abnormal pods. When it returns no results, all OO pods are ready.",
    "url": "399-verifyinstalloocgcp",
    "filename": "399-verifyinstalloocgcp",
    "headings": [],
    "keywords": [
      "verify",
      "oo",
      "installation",
      "gke",
      "following",
      "log",
      "bastion",
      "node.",
      "run",
      "command",
      "ensure",
      "all",
      "pods",
      "ready.",
      "kubectl",
      "get",
      "pod",
      "-n",
      "grep",
      "-v",
      "completed",
      "namespace",
      "deploy",
      "chart.",
      "returns",
      "list",
      "abnormal",
      "pods.",
      "results"
    ],
    "language": "en",
    "word_count": 58,
    "importance_score": 1.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "verify the oo installation on gke",
    "contentLower": "to verify oo installation in gke, do the following: log in to the bastion node. run the following command to ensure that all oo pods are ready. kubectl get pod -n <oo namespace> |grep -v 1/1|grep -v 2/2|grep -v 3/3|grep -v 4/4|grep -v completed where: <oo namespace> is the namespace where you deploy the oo chart. this command returns a list of abnormal pods. when it returns no results, all oo pods are ready.",
    "keywordsLower": [
      "verify",
      "oo",
      "installation",
      "gke",
      "following",
      "log",
      "bastion",
      "node.",
      "run",
      "command",
      "ensure",
      "all",
      "pods",
      "ready.",
      "kubectl",
      "get",
      "pod",
      "-n",
      "grep",
      "-v",
      "completed",
      "namespace",
      "deploy",
      "chart.",
      "returns",
      "list",
      "abnormal",
      "pods.",
      "results"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Uninstall OO on GCP",
    "content": "To uninstall Operations Orchestration (OO) on GCP with GKE, perform the following tasks: Delete the OO deployment Log on to the bastion node, and navigate to the OPTIC Management Toolkit (OMT) installation directory: cd <OMT_External_K8s_2x.x-xxx>/bin Run the following command to remove the OO release: ./helm uninstall <OO RELEASE NAME> -n <OO NAMESPACE> Where: <OO RELEASE NAME> is the OO release that you want to uninstall, which you can get by running the command ./helm list -n <OO NAMESPACE>. <OO NAMESPACE> is the namespace where you installed OO. Run the following command to remove the OO deployment: cd <OMT_External_K8s_2x.x-xxx>/scripts ./cdfctl.sh deployment delete -d <OO DEPLOYMENT NAME> Where: <OO DEPLOYMENT NAME> is the name you specified for the deployment you created to install OO. For example: ./cdfctl.sh deployment delete -d oo-prod You need to enter the administrator password you set during the OMT installation. Remove persistent volume and claims If you created the oo-pv",
    "url": "399-gcpoocuninstall",
    "filename": "399-gcpoocuninstall",
    "headings": [
      "Delete the OO deployment",
      "Remove persistent volume and claims",
      "Clean the databases"
    ],
    "keywords": [
      "cdfctl.sh",
      "pv.yaml",
      "pvc.yaml",
      "uninstall",
      "oo",
      "gcp",
      "delete",
      "deployment",
      "remove",
      "persistent",
      "volume",
      "claims",
      "clean",
      "databases",
      "operations",
      "orchestration",
      "gke",
      "perform",
      "following",
      "tasks",
      "log",
      "bastion",
      "node",
      "navigate",
      "optic",
      "management",
      "toolkit",
      "omt",
      "installation",
      "directory",
      "cd",
      "bin",
      "run",
      "command",
      "release",
      "helm",
      "-n",
      "want",
      "get",
      "running",
      "list",
      "namespace",
      "installed",
      "oo.",
      "scripts",
      "-d",
      "name",
      "specified",
      "created",
      "install",
      "example",
      "oo-prod",
      "need",
      "enter",
      "administrator",
      "password",
      "set",
      "during",
      "installation.",
      "oo-pv.yaml",
      "sample",
      "file",
      "documented",
      "prepare",
      "volumes",
      "step",
      "kubectl",
      "-f",
      "oo-helm-charts-1.x.x",
      "26.x.x",
      "oo-helm-charts",
      "samples",
      "oo-pvc.yaml",
      "residing",
      "external",
      "postgresql",
      "aren",
      "removed.",
      "manually.",
      "different",
      "names",
      "creating",
      "database",
      "users",
      "components",
      "replace",
      "default",
      "below",
      "used.",
      "connect",
      "postgres",
      "server",
      "psql",
      "-h",
      "-u",
      "all",
      "commands",
      "drop",
      "oocentraldb",
      "oouidb"
    ],
    "language": "en",
    "word_count": 87,
    "importance_score": 4.5,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "uninstall oo on gcp",
    "contentLower": "to uninstall operations orchestration (oo) on gcp with gke, perform the following tasks: delete the oo deployment log on to the bastion node, and navigate to the optic management toolkit (omt) installation directory: cd <omt_external_k8s_2x.x-xxx>/bin run the following command to remove the oo release: ./helm uninstall <oo release name> -n <oo namespace> where: <oo release name> is the oo release that you want to uninstall, which you can get by running the command ./helm list -n <oo namespace>. <oo namespace> is the namespace where you installed oo. run the following command to remove the oo deployment: cd <omt_external_k8s_2x.x-xxx>/scripts ./cdfctl.sh deployment delete -d <oo deployment name> where: <oo deployment name> is the name you specified for the deployment you created to install oo. for example: ./cdfctl.sh deployment delete -d oo-prod you need to enter the administrator password you set during the omt installation. remove persistent volume and claims if you created the oo-pv",
    "keywordsLower": [
      "cdfctl.sh",
      "pv.yaml",
      "pvc.yaml",
      "uninstall",
      "oo",
      "gcp",
      "delete",
      "deployment",
      "remove",
      "persistent",
      "volume",
      "claims",
      "clean",
      "databases",
      "operations",
      "orchestration",
      "gke",
      "perform",
      "following",
      "tasks",
      "log",
      "bastion",
      "node",
      "navigate",
      "optic",
      "management",
      "toolkit",
      "omt",
      "installation",
      "directory",
      "cd",
      "bin",
      "run",
      "command",
      "release",
      "helm",
      "-n",
      "want",
      "get",
      "running",
      "list",
      "namespace",
      "installed",
      "oo.",
      "scripts",
      "-d",
      "name",
      "specified",
      "created",
      "install",
      "example",
      "oo-prod",
      "need",
      "enter",
      "administrator",
      "password",
      "set",
      "during",
      "installation.",
      "oo-pv.yaml",
      "sample",
      "file",
      "documented",
      "prepare",
      "volumes",
      "step",
      "kubectl",
      "-f",
      "oo-helm-charts-1.x.x",
      "26.x.x",
      "oo-helm-charts",
      "samples",
      "oo-pvc.yaml",
      "residing",
      "external",
      "postgresql",
      "aren",
      "removed.",
      "manually.",
      "different",
      "names",
      "creating",
      "database",
      "users",
      "components",
      "replace",
      "default",
      "below",
      "used.",
      "connect",
      "postgres",
      "server",
      "psql",
      "-h",
      "-u",
      "all",
      "commands",
      "drop",
      "oocentraldb",
      "oouidb"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Verify the UD/UCMDB installation (GCP)",
    "content": "To verify if UD/UCMDB has been successfully installed, do the following: Log in to the control plane node (embedded Kubernetes) or the bastion node (managed Kubernetes). Run the following command to make sure that each of the PVCs is bound to an NFS volume. kubectl get pvc -n <UD/UCMDB NAMESPACE> Example: # kubectl get pvc -n ucmdb-prod NAME STATUS VOLUME CAPACITY ACCESS MODES STORAGECLASS AGE ucmdb-configvolumeclaim Bound ucmdb-prod-config-volume 5Gi RWX 8h ucmdb-datavolumeclaim Bound ucmdb-prod-data-volume 5Gi RWX 8h ucmdb-logvolumeclaim Bound ucmdb-prod-log-volume 5Gi RWX 8h Run the following command to see the pod status in the UD/UCMDB namespace. kubectl get pods -n <UD/UCMDB NAMESPACE> Example: # kubectl get pods -n ucmdb-prod NAME READY STATUS RESTARTS AGE itom-autopass-lms-7bb6c57dbf-ttb4q 2/2 Running 0 8h itom-uducmdb-downloader-687849d8f4-r9bv4 2/2 Running 0 8h itom-uducmdb-gateway-5969db8f5d-26n7z 2/2 Running 0 8h itom-uducmdb-gateway-5969db8f5d-nn4h6 2/2 Running 0 8h itom-i",
    "url": "403-verifyucmdbinstallgcp",
    "filename": "403-verifyucmdbinstallgcp",
    "headings": [],
    "keywords": [
      "uducmdb",
      "verify",
      "ud",
      "ucmdb",
      "installation",
      "gcp",
      "successfully",
      "installed",
      "following",
      "log",
      "control",
      "plane",
      "node",
      "embedded",
      "kubernetes",
      "bastion",
      "managed",
      "run",
      "command",
      "make",
      "sure",
      "pvcs",
      "bound",
      "nfs",
      "volume.",
      "kubectl",
      "get",
      "pvc",
      "-n",
      "example",
      "ucmdb-prod",
      "name",
      "status",
      "volume",
      "capacity",
      "access",
      "modes",
      "storageclass",
      "age",
      "ucmdb-configvolumeclaim",
      "ucmdb-prod-config-volume",
      "5gi",
      "rwx",
      "8h",
      "ucmdb-datavolumeclaim",
      "ucmdb-prod-data-volume",
      "ucmdb-logvolumeclaim",
      "ucmdb-prod-log-volume",
      "see",
      "pod",
      "namespace.",
      "pods",
      "ready",
      "restarts",
      "itom-autopass-lms-7bb6c57dbf-ttb4q",
      "running",
      "itom-uducmdb-downloader-687849d8f4-r9bv4",
      "itom-uducmdb-gateway-5969db8f5d-26n7z",
      "itom-uducmdb-gateway-5969db8f5d-nn4h6",
      "itom-idm-7c687c8f49-kzs9t",
      "itom-idm-7c687c8f49-wl4hs",
      "itom-ingress-controller-58cd796778-d7cn7",
      "itom-ingress-controller-58cd796778-m9znp",
      "itom-ucmdb-0",
      "4h",
      "itom-ucmdb-1",
      "4h10m",
      "itom-ucmdb-browser-6dbcdd9586-dgf94",
      "itom-ucmdb-probe-6c554bc9d-rvxkq",
      "itom-ucmdb-solr-7b44ff67b7-vhhqj",
      "itom-vault-fd98f675b-smv8n",
      "column",
      "indicates",
      "current",
      "lifecycle",
      "state",
      "pod.",
      "pending",
      "completed",
      "init",
      "crashloopbackoff.",
      "many",
      "eventually",
      "becomes",
      "podinitializing",
      "state.",
      "addition",
      "check",
      "fully",
      "started",
      "up.",
      "contains",
      "two",
      "numbers",
      "form",
      "number",
      "containers",
      "running.",
      "means",
      "one"
    ],
    "language": "en",
    "word_count": 115,
    "importance_score": 3.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "verify the ud/ucmdb installation (gcp)",
    "contentLower": "to verify if ud/ucmdb has been successfully installed, do the following: log in to the control plane node (embedded kubernetes) or the bastion node (managed kubernetes). run the following command to make sure that each of the pvcs is bound to an nfs volume. kubectl get pvc -n <ud/ucmdb namespace> example: # kubectl get pvc -n ucmdb-prod name status volume capacity access modes storageclass age ucmdb-configvolumeclaim bound ucmdb-prod-config-volume 5gi rwx 8h ucmdb-datavolumeclaim bound ucmdb-prod-data-volume 5gi rwx 8h ucmdb-logvolumeclaim bound ucmdb-prod-log-volume 5gi rwx 8h run the following command to see the pod status in the ud/ucmdb namespace. kubectl get pods -n <ud/ucmdb namespace> example: # kubectl get pods -n ucmdb-prod name ready status restarts age itom-autopass-lms-7bb6c57dbf-ttb4q 2/2 running 0 8h itom-uducmdb-downloader-687849d8f4-r9bv4 2/2 running 0 8h itom-uducmdb-gateway-5969db8f5d-26n7z 2/2 running 0 8h itom-uducmdb-gateway-5969db8f5d-nn4h6 2/2 running 0 8h itom-i",
    "keywordsLower": [
      "uducmdb",
      "verify",
      "ud",
      "ucmdb",
      "installation",
      "gcp",
      "successfully",
      "installed",
      "following",
      "log",
      "control",
      "plane",
      "node",
      "embedded",
      "kubernetes",
      "bastion",
      "managed",
      "run",
      "command",
      "make",
      "sure",
      "pvcs",
      "bound",
      "nfs",
      "volume.",
      "kubectl",
      "get",
      "pvc",
      "-n",
      "example",
      "ucmdb-prod",
      "name",
      "status",
      "volume",
      "capacity",
      "access",
      "modes",
      "storageclass",
      "age",
      "ucmdb-configvolumeclaim",
      "ucmdb-prod-config-volume",
      "5gi",
      "rwx",
      "8h",
      "ucmdb-datavolumeclaim",
      "ucmdb-prod-data-volume",
      "ucmdb-logvolumeclaim",
      "ucmdb-prod-log-volume",
      "see",
      "pod",
      "namespace.",
      "pods",
      "ready",
      "restarts",
      "itom-autopass-lms-7bb6c57dbf-ttb4q",
      "running",
      "itom-uducmdb-downloader-687849d8f4-r9bv4",
      "itom-uducmdb-gateway-5969db8f5d-26n7z",
      "itom-uducmdb-gateway-5969db8f5d-nn4h6",
      "itom-idm-7c687c8f49-kzs9t",
      "itom-idm-7c687c8f49-wl4hs",
      "itom-ingress-controller-58cd796778-d7cn7",
      "itom-ingress-controller-58cd796778-m9znp",
      "itom-ucmdb-0",
      "4h",
      "itom-ucmdb-1",
      "4h10m",
      "itom-ucmdb-browser-6dbcdd9586-dgf94",
      "itom-ucmdb-probe-6c554bc9d-rvxkq",
      "itom-ucmdb-solr-7b44ff67b7-vhhqj",
      "itom-vault-fd98f675b-smv8n",
      "column",
      "indicates",
      "current",
      "lifecycle",
      "state",
      "pod.",
      "pending",
      "completed",
      "init",
      "crashloopbackoff.",
      "many",
      "eventually",
      "becomes",
      "podinitializing",
      "state.",
      "addition",
      "check",
      "fully",
      "started",
      "up.",
      "contains",
      "two",
      "numbers",
      "form",
      "number",
      "containers",
      "running.",
      "means",
      "one"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Uninstall UD/UCMDB on GCP",
    "content": "To uninstall UD/UCMDB on GCP with GKE, perform the following tasks: Delete the UD/UCMDB deployment Log on to the bastion node, navigate to the OPTIC Management Toolkit (OMT) installation directory: cd OMT_External_K8s_2x.x-xxx/bin Run the following command to remove the UD/UCMDB release: ./helm uninstall <UD/UCMDB RELEASE NAME> -n <UD/UCMDB NAMESPACE> Where: <UD/UCMDB RELEASE NAME> is the UD/UCMDB release that you want to uninstall, which you can get by running the command ./helm list -n <UD/UCMDB NAMESPACE>. <UD/UCMDB NAMESPACE> is the namespace where you installed UD/UCMDB. Run the following command to remove the OMT deployment: cd OMT_External_K8s_2x.x-xxx/scripts ./cdfctl deployment delete -d <UD/UCMDB DEPLOYMENT NAME> Where <UD/UCMDB DEPLOYMENT NAME> is the name you specified for the deployment you created to install UD/UCMDB. For example: ./cdfctl deployment delete -d ucmdb-prod You will need to enter the password of the administrator that you set during the OMT installation. Rem",
    "url": "403-uninstallucmdbongcp",
    "filename": "403-uninstallucmdbongcp",
    "headings": [
      "Delete the UD/UCMDB deployment",
      "Remove persistent volumes",
      "Clean the NFS volumes",
      "Clean the databases"
    ],
    "keywords": [
      "uducmdb",
      "pv.yaml",
      "cleanCMSNFS.sh",
      "uninstall",
      "ud",
      "ucmdb",
      "gcp",
      "delete",
      "deployment",
      "remove",
      "persistent",
      "volumes",
      "clean",
      "nfs",
      "databases",
      "gke",
      "perform",
      "following",
      "tasks",
      "log",
      "bastion",
      "node",
      "navigate",
      "optic",
      "management",
      "toolkit",
      "omt",
      "installation",
      "directory",
      "cd",
      "bin",
      "run",
      "command",
      "release",
      "helm",
      "-n",
      "want",
      "get",
      "running",
      "list",
      "namespace",
      "installed",
      "ucmdb.",
      "scripts",
      "cdfctl",
      "-d",
      "name",
      "specified",
      "created",
      "install",
      "example",
      "ucmdb-prod",
      "need",
      "enter",
      "password",
      "administrator",
      "set",
      "during",
      "installation.",
      "pvs",
      "based",
      "ucmdb-pv.yaml",
      "sample",
      "file",
      "documented",
      "create",
      "step",
      "kubectl",
      "-f",
      "tmp",
      "ucmdb-helm-charts",
      "samples",
      "copy",
      "save",
      "script",
      "bash",
      "shopt",
      "-s",
      "extglob",
      "edit",
      "needed",
      "mnt",
      "cms",
      "var",
      "vols",
      "itom",
      "rm",
      "-rf",
      "ls",
      "-l",
      "commands",
      "data",
      "storage",
      "chmod",
      "755",
      "sudo",
      "un-installation",
      "process",
      "doesn",
      "residing"
    ],
    "language": "en",
    "word_count": 89,
    "importance_score": 5.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "uninstall ud/ucmdb on gcp",
    "contentLower": "to uninstall ud/ucmdb on gcp with gke, perform the following tasks: delete the ud/ucmdb deployment log on to the bastion node, navigate to the optic management toolkit (omt) installation directory: cd omt_external_k8s_2x.x-xxx/bin run the following command to remove the ud/ucmdb release: ./helm uninstall <ud/ucmdb release name> -n <ud/ucmdb namespace> where: <ud/ucmdb release name> is the ud/ucmdb release that you want to uninstall, which you can get by running the command ./helm list -n <ud/ucmdb namespace>. <ud/ucmdb namespace> is the namespace where you installed ud/ucmdb. run the following command to remove the omt deployment: cd omt_external_k8s_2x.x-xxx/scripts ./cdfctl deployment delete -d <ud/ucmdb deployment name> where <ud/ucmdb deployment name> is the name you specified for the deployment you created to install ud/ucmdb. for example: ./cdfctl deployment delete -d ucmdb-prod you will need to enter the password of the administrator that you set during the omt installation. rem",
    "keywordsLower": [
      "uducmdb",
      "pv.yaml",
      "cleancmsnfs.sh",
      "uninstall",
      "ud",
      "ucmdb",
      "gcp",
      "delete",
      "deployment",
      "remove",
      "persistent",
      "volumes",
      "clean",
      "nfs",
      "databases",
      "gke",
      "perform",
      "following",
      "tasks",
      "log",
      "bastion",
      "node",
      "navigate",
      "optic",
      "management",
      "toolkit",
      "omt",
      "installation",
      "directory",
      "cd",
      "bin",
      "run",
      "command",
      "release",
      "helm",
      "-n",
      "want",
      "get",
      "running",
      "list",
      "namespace",
      "installed",
      "ucmdb.",
      "scripts",
      "cdfctl",
      "-d",
      "name",
      "specified",
      "created",
      "install",
      "example",
      "ucmdb-prod",
      "need",
      "enter",
      "password",
      "administrator",
      "set",
      "during",
      "installation.",
      "pvs",
      "based",
      "ucmdb-pv.yaml",
      "sample",
      "file",
      "documented",
      "create",
      "step",
      "kubectl",
      "-f",
      "tmp",
      "ucmdb-helm-charts",
      "samples",
      "copy",
      "save",
      "script",
      "bash",
      "shopt",
      "-s",
      "extglob",
      "edit",
      "needed",
      "mnt",
      "cms",
      "var",
      "vols",
      "itom",
      "rm",
      "-rf",
      "ls",
      "-l",
      "commands",
      "data",
      "storage",
      "chmod",
      "755",
      "sudo",
      "un-installation",
      "process",
      "doesn",
      "residing"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Uninstall Audit on GCP",
    "content": "To uninstall Audit service, perform the following tasks: Delete Audit deployment Log in to the bastion node. Run the following command to remove the Audit release: helm uninstall <Audit Release Name> -n <Namespace> where, <Audit Release Name> is the Audit release that you want to uninstall <Namespace> is the namespace where you installed Audit Go to the $CDF_HOME/scripts folder and run the following command: ./cdfctl.sh deployment delete -d <Audit Deployment Name> where, <Audit Deployment Name> is the name you specified for the deployment you created to install Audit. For example: ./cdfctl.sh deployment delete -d audit-prod Remove persistent volumes If you created PVs based on the itom-audit-pv.yaml sample file, you can run the following command to delete the persistent volumes: kubectl delete -f itom-audit-pv.yaml Clean EFS volumes Log in to the Elastic File System (EFS) server host and clear all the contents in the EFS volume directories that you created. For example: rm -rf /var/vol",
    "url": "131-uninstallauditgcp",
    "filename": "131-uninstallauditgcp",
    "headings": [
      "Delete Audit deployment",
      "Remove persistent volumes",
      "Clean EFS volumes",
      "Clean databases"
    ],
    "keywords": [
      "cdfctl.sh",
      "pv.yaml",
      "uninstall",
      "audit",
      "gcp",
      "delete",
      "deployment",
      "remove",
      "persistent",
      "volumes",
      "clean",
      "efs",
      "databases",
      "service",
      "perform",
      "following",
      "tasks",
      "log",
      "bastion",
      "node.",
      "run",
      "command",
      "release",
      "helm",
      "-n",
      "want",
      "namespace",
      "installed",
      "go",
      "scripts",
      "folder",
      "-d",
      "name",
      "specified",
      "created",
      "install",
      "audit.",
      "example",
      "audit-prod",
      "pvs",
      "based",
      "itom-audit-pv.yaml",
      "sample",
      "file",
      "kubectl",
      "-f",
      "elastic",
      "system",
      "server",
      "host",
      "clear",
      "all",
      "contents",
      "volume",
      "directories",
      "created.",
      "rm",
      "-rf",
      "var",
      "vols",
      "itom",
      "auditns",
      "vault",
      "uninstallation",
      "process",
      "external",
      "postgresql",
      "server.",
      "need",
      "manually."
    ],
    "language": "en",
    "word_count": 95,
    "importance_score": 5.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "uninstall audit on gcp",
    "contentLower": "to uninstall audit service, perform the following tasks: delete audit deployment log in to the bastion node. run the following command to remove the audit release: helm uninstall <audit release name> -n <namespace> where, <audit release name> is the audit release that you want to uninstall <namespace> is the namespace where you installed audit go to the $cdf_home/scripts folder and run the following command: ./cdfctl.sh deployment delete -d <audit deployment name> where, <audit deployment name> is the name you specified for the deployment you created to install audit. for example: ./cdfctl.sh deployment delete -d audit-prod remove persistent volumes if you created pvs based on the itom-audit-pv.yaml sample file, you can run the following command to delete the persistent volumes: kubectl delete -f itom-audit-pv.yaml clean efs volumes log in to the elastic file system (efs) server host and clear all the contents in the efs volume directories that you created. for example: rm -rf /var/vol",
    "keywordsLower": [
      "cdfctl.sh",
      "pv.yaml",
      "uninstall",
      "audit",
      "gcp",
      "delete",
      "deployment",
      "remove",
      "persistent",
      "volumes",
      "clean",
      "efs",
      "databases",
      "service",
      "perform",
      "following",
      "tasks",
      "log",
      "bastion",
      "node.",
      "run",
      "command",
      "release",
      "helm",
      "-n",
      "want",
      "namespace",
      "installed",
      "go",
      "scripts",
      "folder",
      "-d",
      "name",
      "specified",
      "created",
      "install",
      "audit.",
      "example",
      "audit-prod",
      "pvs",
      "based",
      "itom-audit-pv.yaml",
      "sample",
      "file",
      "kubectl",
      "-f",
      "elastic",
      "system",
      "server",
      "host",
      "clear",
      "all",
      "contents",
      "volume",
      "directories",
      "created.",
      "rm",
      "-rf",
      "var",
      "vols",
      "itom",
      "auditns",
      "vault",
      "uninstallation",
      "process",
      "external",
      "postgresql",
      "server.",
      "need",
      "manually."
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Uninstall Audit collector on GCP",
    "content": "To uninstall the Audit collector, perform the following tasks. Delete Audit collector Log in to the control plane node. Run the following command to remove the Audit collector: helm uninstall <Audit Collector Release Name> -n <Audit Producer Namespace> Where, <Audit Collector Release Name> is the Audit collector release name that you want to uninstall. <Audit Producer Namespace> is the namespace where you installed the Audit producer. Clean NFS volumes Log in to the NFS server host and clear all the contents in the NFS volume directories that you created for the Audit collector. For example: rm -rf /var/vols/itom/itsma/global-volume/logs/audit-collector/*",
    "url": "131-uninstallauditcollectorgcp",
    "filename": "131-uninstallauditcollectorgcp",
    "headings": [
      "Delete Audit collector",
      "Clean NFS volumes"
    ],
    "keywords": [
      "uninstall",
      "audit",
      "collector",
      "gcp",
      "delete",
      "clean",
      "nfs",
      "volumes",
      "perform",
      "following",
      "tasks.",
      "log",
      "control",
      "plane",
      "node.",
      "run",
      "command",
      "remove",
      "helm",
      "-n",
      "release",
      "name",
      "want",
      "uninstall.",
      "namespace",
      "installed",
      "producer.",
      "server",
      "host",
      "clear",
      "all",
      "contents",
      "volume",
      "directories",
      "created",
      "collector.",
      "example",
      "rm",
      "-rf",
      "var",
      "vols",
      "itom",
      "itsma",
      "global-volume",
      "logs",
      "audit-collector"
    ],
    "language": "en",
    "word_count": 62,
    "importance_score": 3.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "uninstall audit collector on gcp",
    "contentLower": "to uninstall the audit collector, perform the following tasks. delete audit collector log in to the control plane node. run the following command to remove the audit collector: helm uninstall <audit collector release name> -n <audit producer namespace> where, <audit collector release name> is the audit collector release name that you want to uninstall. <audit producer namespace> is the namespace where you installed the audit producer. clean nfs volumes log in to the nfs server host and clear all the contents in the nfs volume directories that you created for the audit collector. for example: rm -rf /var/vols/itom/itsma/global-volume/logs/audit-collector/*",
    "keywordsLower": [
      "uninstall",
      "audit",
      "collector",
      "gcp",
      "delete",
      "clean",
      "nfs",
      "volumes",
      "perform",
      "following",
      "tasks.",
      "log",
      "control",
      "plane",
      "node.",
      "run",
      "command",
      "remove",
      "helm",
      "-n",
      "release",
      "name",
      "want",
      "uninstall.",
      "namespace",
      "installed",
      "producer.",
      "server",
      "host",
      "clear",
      "all",
      "contents",
      "volume",
      "directories",
      "created",
      "collector.",
      "example",
      "rm",
      "-rf",
      "var",
      "vols",
      "itom",
      "itsma",
      "global-volume",
      "logs",
      "audit-collector"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Upload container images for UD/UCMDB to a registry (OpenShift)",
    "content": "Upload the installation images to your image registry. The image registry is a local registry on your cluster nodes or an external registry, such as your enterprise repository. To upload the images: Log on to one of the bastion nodes. On the bastion node, go to the $CDF_HOME/scripts/ directory. Run the following command: cd $CDF_HOME/scripts Run the following command to upload the suite images to the local registry: ./uploadimages.sh [-r <image repository URL>] [-u <username>]  [-d <image download directory> Where: <image repository URL>: Specify the -r option if you want to upload the images to an external registry other than the local registry. Replace <username> with the registry username.  Use the \"registry-admin\" user for the local registry. The local registry refers to the default registry or the registry URL that is \"localhost:5000 \". If you do not specify the credentials here, you will be prompted to specify them when you run the command. <image download directory>: The directo",
    "url": "cmswithsmaxuploadinstallationimagesopenshift",
    "filename": "cmswithsmaxuploadinstallationimagesopenshift",
    "headings": [],
    "keywords": [
      "uducmdb",
      "downloadimages.sh",
      "uploadimages.sh",
      "tar.gz",
      "updateLocalRegistryInfo.sh",
      "upload",
      "container",
      "images",
      "ud",
      "ucmdb",
      "registry",
      "openshift",
      "installation",
      "image",
      "registry.",
      "local",
      "cluster",
      "nodes",
      "external",
      "such",
      "enterprise",
      "repository.",
      "log",
      "one",
      "bastion",
      "nodes.",
      "node",
      "go",
      "scripts",
      "directory.",
      "run",
      "following",
      "command",
      "cd",
      "suite",
      "-r",
      "-u",
      "-d",
      "specify",
      "option",
      "want",
      "replace",
      "username.",
      "registry-admin",
      "user",
      "refers",
      "default",
      "url",
      "localhost",
      "5000",
      "credentials",
      "here",
      "prompted",
      "command.",
      "directory",
      "downloaded.",
      "value",
      "var",
      "opt",
      "kubernetes",
      "offline.",
      "placed",
      "available",
      "offline",
      "multiple",
      "times",
      "different",
      "directories.",
      "however",
      "specified",
      "-l",
      "false",
      "either",
      "download",
      "generated",
      "docker",
      "save.",
      "there",
      "both",
      "script",
      ".tar",
      ".tgz",
      ".tar.gz",
      "supported.",
      "make",
      "sure",
      "file",
      "type",
      "matches",
      "extension.",
      "see",
      "full",
      "list",
      "options",
      "-h",
      "example",
      "-y",
      "-c",
      "-p",
      "password"
    ],
    "language": "en",
    "word_count": 87,
    "importance_score": 2.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "upload container images for ud/ucmdb to a registry (openshift)",
    "contentLower": "upload the installation images to your image registry. the image registry is a local registry on your cluster nodes or an external registry, such as your enterprise repository. to upload the images: log on to one of the bastion nodes. on the bastion node, go to the $cdf_home/scripts/ directory. run the following command: cd $cdf_home/scripts run the following command to upload the suite images to the local registry: ./uploadimages.sh [-r <image repository url>] [-u <username>]  [-d <image download directory> where: <image repository url>: specify the -r option if you want to upload the images to an external registry other than the local registry. replace <username> with the registry username.  use the \"registry-admin\" user for the local registry. the local registry refers to the default registry or the registry url that is \"localhost:5000 \". if you do not specify the credentials here, you will be prompted to specify them when you run the command. <image download directory>: the directo",
    "keywordsLower": [
      "uducmdb",
      "downloadimages.sh",
      "uploadimages.sh",
      "tar.gz",
      "updatelocalregistryinfo.sh",
      "upload",
      "container",
      "images",
      "ud",
      "ucmdb",
      "registry",
      "openshift",
      "installation",
      "image",
      "registry.",
      "local",
      "cluster",
      "nodes",
      "external",
      "such",
      "enterprise",
      "repository.",
      "log",
      "one",
      "bastion",
      "nodes.",
      "node",
      "go",
      "scripts",
      "directory.",
      "run",
      "following",
      "command",
      "cd",
      "suite",
      "-r",
      "-u",
      "-d",
      "specify",
      "option",
      "want",
      "replace",
      "username.",
      "registry-admin",
      "user",
      "refers",
      "default",
      "url",
      "localhost",
      "5000",
      "credentials",
      "here",
      "prompted",
      "command.",
      "directory",
      "downloaded.",
      "value",
      "var",
      "opt",
      "kubernetes",
      "offline.",
      "placed",
      "available",
      "offline",
      "multiple",
      "times",
      "different",
      "directories.",
      "however",
      "specified",
      "-l",
      "false",
      "either",
      "download",
      "generated",
      "docker",
      "save.",
      "there",
      "both",
      "script",
      ".tar",
      ".tgz",
      ".tar.gz",
      "supported.",
      "make",
      "sure",
      "file",
      "type",
      "matches",
      "extension.",
      "see",
      "full",
      "list",
      "options",
      "-h",
      "example",
      "-y",
      "-c",
      "-p",
      "password"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Verify the UD/UCMDB installation (OpenShift)",
    "content": "To verify if UD/UCMDB has been installed successfully, do the following: Log in to the control plane node (embedded Kubernetes) or the bastion node (managed Kubernetes). Run the following command to make sure that each of the PVCs is bound to an NFS volume. kubectl get pvc -n <UD/UCMDB NAMESPACE> Example: # kubectl get pvc -n ucmdb-prod NAME STATUS VOLUME CAPACITY ACCESS MODES STORAGECLASS AGE ucmdb-configvolumeclaim Bound ucmdb-prod-config-volume 5Gi RWX 8h ucmdb-datavolumeclaim Bound ucmdb-prod-data-volume 5Gi RWX 8h ucmdb-logvolumeclaim Bound ucmdb-prod-log-volume 5Gi RWX 8h Run the following command to see the pod status in the UD/UCMDB namespace. kubectl get pods -n <UD/UCMDB NAMESPACE> Example: # kubectl get pods -n ucmdb-prod NAME READY STATUS RESTARTS AGE itom-autopass-lms-7bb6c57dbf-ttb4q 2/2 Running 0 8h itom-cms-downloader-687849d8f4-r9bv4 2/2 Running 0 8h itom-cms-gateway-5969db8f5d-26n7z 2/2 Running 0 8h itom-cms-gateway-5969db8f5d-nn4h6 2/2 Running 0 8h itom-idm-7c687c8f4",
    "url": "installcmswithsmaxverifyopenshift",
    "filename": "installcmswithsmaxverifyopenshift",
    "headings": [],
    "keywords": [
      "uducmdb",
      "verify",
      "ud",
      "ucmdb",
      "installation",
      "openshift",
      "installed",
      "successfully",
      "following",
      "log",
      "control",
      "plane",
      "node",
      "embedded",
      "kubernetes",
      "bastion",
      "managed",
      "run",
      "command",
      "make",
      "sure",
      "pvcs",
      "bound",
      "nfs",
      "volume.",
      "kubectl",
      "get",
      "pvc",
      "-n",
      "example",
      "ucmdb-prod",
      "name",
      "status",
      "volume",
      "capacity",
      "access",
      "modes",
      "storageclass",
      "age",
      "ucmdb-configvolumeclaim",
      "ucmdb-prod-config-volume",
      "5gi",
      "rwx",
      "8h",
      "ucmdb-datavolumeclaim",
      "ucmdb-prod-data-volume",
      "ucmdb-logvolumeclaim",
      "ucmdb-prod-log-volume",
      "see",
      "pod",
      "namespace.",
      "pods",
      "ready",
      "restarts",
      "itom-autopass-lms-7bb6c57dbf-ttb4q",
      "running",
      "itom-cms-downloader-687849d8f4-r9bv4",
      "itom-cms-gateway-5969db8f5d-26n7z",
      "itom-cms-gateway-5969db8f5d-nn4h6",
      "itom-idm-7c687c8f49-kzs9t",
      "itom-idm-7c687c8f49-wl4hs",
      "itom-ingress-controller-58cd796778-d7cn7",
      "itom-ingress-controller-58cd796778-m9znp",
      "itom-ucmdb-0",
      "4h",
      "itom-ucmdb-1",
      "4h10m",
      "itom-ucmdb-browser-6dbcdd9586-dgf94",
      "itom-ucmdb-probe-6c554bc9d-rvxkq",
      "itom-ucmdb-solr-7b44ff67b7-vhhqj",
      "itom-vault-fd98f675b-smv8n",
      "column",
      "indicates",
      "current",
      "lifecycle",
      "state",
      "pod.",
      "pending",
      "completed",
      "init",
      "crashloopbackoff.",
      "many",
      "eventually",
      "becomes",
      "podinitializing",
      "state.",
      "addition",
      "check",
      "fully",
      "started",
      "up.",
      "contains",
      "two",
      "numbers",
      "form",
      "number",
      "containers",
      "running.",
      "means",
      "one"
    ],
    "language": "en",
    "word_count": 115,
    "importance_score": 3.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "verify the ud/ucmdb installation (openshift)",
    "contentLower": "to verify if ud/ucmdb has been installed successfully, do the following: log in to the control plane node (embedded kubernetes) or the bastion node (managed kubernetes). run the following command to make sure that each of the pvcs is bound to an nfs volume. kubectl get pvc -n <ud/ucmdb namespace> example: # kubectl get pvc -n ucmdb-prod name status volume capacity access modes storageclass age ucmdb-configvolumeclaim bound ucmdb-prod-config-volume 5gi rwx 8h ucmdb-datavolumeclaim bound ucmdb-prod-data-volume 5gi rwx 8h ucmdb-logvolumeclaim bound ucmdb-prod-log-volume 5gi rwx 8h run the following command to see the pod status in the ud/ucmdb namespace. kubectl get pods -n <ud/ucmdb namespace> example: # kubectl get pods -n ucmdb-prod name ready status restarts age itom-autopass-lms-7bb6c57dbf-ttb4q 2/2 running 0 8h itom-cms-downloader-687849d8f4-r9bv4 2/2 running 0 8h itom-cms-gateway-5969db8f5d-26n7z 2/2 running 0 8h itom-cms-gateway-5969db8f5d-nn4h6 2/2 running 0 8h itom-idm-7c687c8f4",
    "keywordsLower": [
      "uducmdb",
      "verify",
      "ud",
      "ucmdb",
      "installation",
      "openshift",
      "installed",
      "successfully",
      "following",
      "log",
      "control",
      "plane",
      "node",
      "embedded",
      "kubernetes",
      "bastion",
      "managed",
      "run",
      "command",
      "make",
      "sure",
      "pvcs",
      "bound",
      "nfs",
      "volume.",
      "kubectl",
      "get",
      "pvc",
      "-n",
      "example",
      "ucmdb-prod",
      "name",
      "status",
      "volume",
      "capacity",
      "access",
      "modes",
      "storageclass",
      "age",
      "ucmdb-configvolumeclaim",
      "ucmdb-prod-config-volume",
      "5gi",
      "rwx",
      "8h",
      "ucmdb-datavolumeclaim",
      "ucmdb-prod-data-volume",
      "ucmdb-logvolumeclaim",
      "ucmdb-prod-log-volume",
      "see",
      "pod",
      "namespace.",
      "pods",
      "ready",
      "restarts",
      "itom-autopass-lms-7bb6c57dbf-ttb4q",
      "running",
      "itom-cms-downloader-687849d8f4-r9bv4",
      "itom-cms-gateway-5969db8f5d-26n7z",
      "itom-cms-gateway-5969db8f5d-nn4h6",
      "itom-idm-7c687c8f49-kzs9t",
      "itom-idm-7c687c8f49-wl4hs",
      "itom-ingress-controller-58cd796778-d7cn7",
      "itom-ingress-controller-58cd796778-m9znp",
      "itom-ucmdb-0",
      "4h",
      "itom-ucmdb-1",
      "4h10m",
      "itom-ucmdb-browser-6dbcdd9586-dgf94",
      "itom-ucmdb-probe-6c554bc9d-rvxkq",
      "itom-ucmdb-solr-7b44ff67b7-vhhqj",
      "itom-vault-fd98f675b-smv8n",
      "column",
      "indicates",
      "current",
      "lifecycle",
      "state",
      "pod.",
      "pending",
      "completed",
      "init",
      "crashloopbackoff.",
      "many",
      "eventually",
      "becomes",
      "podinitializing",
      "state.",
      "addition",
      "check",
      "fully",
      "started",
      "up.",
      "contains",
      "two",
      "numbers",
      "form",
      "number",
      "containers",
      "running.",
      "means",
      "one"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Uninstall UD/UCMDB (OpenShift)",
    "content": "To uninstall UD/UCMDB, perform the following tasks: Delete the UD/UCMDB deployment Log in to your OpenShift Container Platform. Click Projects, and then click your UD/UCMDB project. For example, ucmdb-prod. From the Action drop-down list, click Delete Project. Remove persistent volumes If you created PVs based on the ucmdb-pv.yaml sample file as documented in Create persistent volumes, you can run the following command to delete the persistent volumes: kubectl delete -f ucmdb-pv.yaml Clean the NFS volumes Log on to the NFS server host and clear all the contents in the NFS volume directories that you created in the Create NFS volumes step. For example: rm -rf /var/vols/itom/ucmdb/data_volume/* rm -rf /var/vols/itom/ucmdb/conf_volume/* rm -rf /var/vols/itom/ucmdb/log_volume/* rm -rf /var/vols/itom/ucmdb/db_volume/* Note: If external databases are used, no need to delete the db_volume. Clean the databases The system doesn't remove the databases from the external database server after unin",
    "url": "cmswithsmaxuninstallcmsopenshift",
    "filename": "cmswithsmaxuninstallcmsopenshift",
    "headings": [
      "Delete the UD/UCMDB deployment",
      "Remove persistent volumes",
      "Clean the NFS volumes",
      "Clean the databases"
    ],
    "keywords": [
      "uducmdb",
      "pv.yaml",
      "uninstall",
      "ud",
      "ucmdb",
      "openshift",
      "delete",
      "deployment",
      "remove",
      "persistent",
      "volumes",
      "clean",
      "nfs",
      "databases",
      "perform",
      "following",
      "tasks",
      "log",
      "container",
      "platform.",
      "click",
      "projects",
      "project.",
      "example",
      "ucmdb-prod.",
      "action",
      "drop-down",
      "list",
      "created",
      "pvs",
      "based",
      "ucmdb-pv.yaml",
      "sample",
      "file",
      "documented",
      "create",
      "run",
      "command",
      "kubectl",
      "-f",
      "server",
      "host",
      "clear",
      "all",
      "contents",
      "volume",
      "directories",
      "step.",
      "rm",
      "-rf",
      "var",
      "vols",
      "itom",
      "note",
      "external",
      "need",
      "system",
      "doesn",
      "database",
      "after",
      "uninstalling",
      "ucmdb.",
      "manually."
    ],
    "language": "en",
    "word_count": 120,
    "importance_score": 5.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "uninstall ud/ucmdb (openshift)",
    "contentLower": "to uninstall ud/ucmdb, perform the following tasks: delete the ud/ucmdb deployment log in to your openshift container platform. click projects, and then click your ud/ucmdb project. for example, ucmdb-prod. from the action drop-down list, click delete project. remove persistent volumes if you created pvs based on the ucmdb-pv.yaml sample file as documented in create persistent volumes, you can run the following command to delete the persistent volumes: kubectl delete -f ucmdb-pv.yaml clean the nfs volumes log on to the nfs server host and clear all the contents in the nfs volume directories that you created in the create nfs volumes step. for example: rm -rf /var/vols/itom/ucmdb/data_volume/* rm -rf /var/vols/itom/ucmdb/conf_volume/* rm -rf /var/vols/itom/ucmdb/log_volume/* rm -rf /var/vols/itom/ucmdb/db_volume/* note: if external databases are used, no need to delete the db_volume. clean the databases the system doesn't remove the databases from the external database server after unin",
    "keywordsLower": [
      "uducmdb",
      "pv.yaml",
      "uninstall",
      "ud",
      "ucmdb",
      "openshift",
      "delete",
      "deployment",
      "remove",
      "persistent",
      "volumes",
      "clean",
      "nfs",
      "databases",
      "perform",
      "following",
      "tasks",
      "log",
      "container",
      "platform.",
      "click",
      "projects",
      "project.",
      "example",
      "ucmdb-prod.",
      "action",
      "drop-down",
      "list",
      "created",
      "pvs",
      "based",
      "ucmdb-pv.yaml",
      "sample",
      "file",
      "documented",
      "create",
      "run",
      "command",
      "kubectl",
      "-f",
      "server",
      "host",
      "clear",
      "all",
      "contents",
      "volume",
      "directories",
      "step.",
      "rm",
      "-rf",
      "var",
      "vols",
      "itom",
      "note",
      "external",
      "need",
      "system",
      "doesn",
      "database",
      "after",
      "uninstalling",
      "ucmdb.",
      "manually."
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Upload container images for OO to a registry on OpenShift",
    "content": "Upload the installation images to your image registry. The image registry is a local registry on your cluster nodes or an external registry, such as your enterprise repository. To upload the images: Log on to one of the bastion nodes. On the bastion node, go to the $CDF_HOME/scripts/ directory. Run the following command: cd $CDF_HOME/scripts Run the following command to upload the suite images to the local registry: ./uploadimages.sh [-r <image repository URL>] [-u <username>]  [-d <image download directory> Where: In <image repository URL>, specify the -r option if you want to upload the images to an external registry other than the local registry. Replace <username> with the Docker Hub username. Use the registry-admin user for the local registry. The local registry refers to the default registry or the registry URL which is localhost:5000. If you don't specify the credentials here, specify them when you run the command, at the prompt. <image download directory>: The directory where t",
    "url": "uploadimagesooocp",
    "filename": "uploadimagesooocp",
    "headings": [],
    "keywords": [
      "downloadimages.sh",
      "uploadimages.sh",
      "tar.gz",
      "upload",
      "container",
      "images",
      "oo",
      "registry",
      "openshift",
      "installation",
      "image",
      "registry.",
      "local",
      "cluster",
      "nodes",
      "external",
      "such",
      "enterprise",
      "repository.",
      "log",
      "one",
      "bastion",
      "nodes.",
      "node",
      "go",
      "scripts",
      "directory.",
      "run",
      "following",
      "command",
      "cd",
      "suite",
      "-r",
      "-u",
      "-d",
      "specify",
      "option",
      "want",
      "replace",
      "docker",
      "hub",
      "username.",
      "registry-admin",
      "user",
      "refers",
      "default",
      "url",
      "localhost",
      "5000.",
      "don",
      "credentials",
      "here",
      "prompt.",
      "directory",
      "downloaded.",
      "value",
      "var",
      "opt",
      "kubernetes",
      "offline.",
      "placed",
      "aren",
      "available",
      "offline",
      "multiple",
      "times",
      "different",
      "directories.",
      "however",
      "specified",
      "-l",
      "false",
      "either",
      "download",
      "generated",
      "save.",
      "there",
      "both",
      "script",
      "won",
      ".tar",
      ".tgz",
      ".tar.gz",
      "supported.",
      "make",
      "sure",
      "file",
      "type",
      "matches",
      "extension.",
      "see",
      "full",
      "list",
      "options",
      "h.",
      "-p",
      "enter",
      "password.",
      "doesn",
      "support"
    ],
    "language": "en",
    "word_count": 90,
    "importance_score": 2.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "upload container images for oo to a registry on openshift",
    "contentLower": "upload the installation images to your image registry. the image registry is a local registry on your cluster nodes or an external registry, such as your enterprise repository. to upload the images: log on to one of the bastion nodes. on the bastion node, go to the $cdf_home/scripts/ directory. run the following command: cd $cdf_home/scripts run the following command to upload the suite images to the local registry: ./uploadimages.sh [-r <image repository url>] [-u <username>]  [-d <image download directory> where: in <image repository url>, specify the -r option if you want to upload the images to an external registry other than the local registry. replace <username> with the docker hub username. use the registry-admin user for the local registry. the local registry refers to the default registry or the registry url which is localhost:5000. if you don't specify the credentials here, specify them when you run the command, at the prompt. <image download directory>: the directory where t",
    "keywordsLower": [
      "downloadimages.sh",
      "uploadimages.sh",
      "tar.gz",
      "upload",
      "container",
      "images",
      "oo",
      "registry",
      "openshift",
      "installation",
      "image",
      "registry.",
      "local",
      "cluster",
      "nodes",
      "external",
      "such",
      "enterprise",
      "repository.",
      "log",
      "one",
      "bastion",
      "nodes.",
      "node",
      "go",
      "scripts",
      "directory.",
      "run",
      "following",
      "command",
      "cd",
      "suite",
      "-r",
      "-u",
      "-d",
      "specify",
      "option",
      "want",
      "replace",
      "docker",
      "hub",
      "username.",
      "registry-admin",
      "user",
      "refers",
      "default",
      "url",
      "localhost",
      "5000.",
      "don",
      "credentials",
      "here",
      "prompt.",
      "directory",
      "downloaded.",
      "value",
      "var",
      "opt",
      "kubernetes",
      "offline.",
      "placed",
      "aren",
      "available",
      "offline",
      "multiple",
      "times",
      "different",
      "directories.",
      "however",
      "specified",
      "-l",
      "false",
      "either",
      "download",
      "generated",
      "save.",
      "there",
      "both",
      "script",
      "won",
      ".tar",
      ".tgz",
      ".tar.gz",
      "supported.",
      "make",
      "sure",
      "file",
      "type",
      "matches",
      "extension.",
      "see",
      "full",
      "list",
      "options",
      "h.",
      "-p",
      "enter",
      "password.",
      "doesn",
      "support"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Verify the OO installation on OpenShift",
    "content": "To verify OO installation, do the following: Log in to the bastion node. Run the following command to make sure that all OO pods are ready. kubectl get pod -n <OO NAMESPACE> |grep -v 1/1|grep -v 2/2|grep -v 3/3|grep -v 4/4|grep -v Completed Where <OO NAMESPACE> is the namespace where you deploy the OO chart. This command returns a list of abnormal pods. When it returns no results, all OO pods are ready.",
    "url": "verifyinstallooocp",
    "filename": "verifyinstallooocp",
    "headings": [],
    "keywords": [
      "verify",
      "oo",
      "installation",
      "openshift",
      "following",
      "log",
      "bastion",
      "node.",
      "run",
      "command",
      "make",
      "sure",
      "all",
      "pods",
      "ready.",
      "kubectl",
      "get",
      "pod",
      "-n",
      "grep",
      "-v",
      "completed",
      "namespace",
      "deploy",
      "chart.",
      "returns",
      "list",
      "abnormal",
      "pods.",
      "results"
    ],
    "language": "en",
    "word_count": 58,
    "importance_score": 1.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "verify the oo installation on openshift",
    "contentLower": "to verify oo installation, do the following: log in to the bastion node. run the following command to make sure that all oo pods are ready. kubectl get pod -n <oo namespace> |grep -v 1/1|grep -v 2/2|grep -v 3/3|grep -v 4/4|grep -v completed where <oo namespace> is the namespace where you deploy the oo chart. this command returns a list of abnormal pods. when it returns no results, all oo pods are ready.",
    "keywordsLower": [
      "verify",
      "oo",
      "installation",
      "openshift",
      "following",
      "log",
      "bastion",
      "node.",
      "run",
      "command",
      "make",
      "sure",
      "all",
      "pods",
      "ready.",
      "kubectl",
      "get",
      "pod",
      "-n",
      "grep",
      "-v",
      "completed",
      "namespace",
      "deploy",
      "chart.",
      "returns",
      "list",
      "abnormal",
      "pods.",
      "results"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Uninstall OO Containerized on OCP",
    "content": "To uninstall OO Containerized on OpenShift, perform the following tasks: Delete the OO deployment Log on to the bastion node, and navigate to the OPTIC Management Toolkit (OMT) installation directory: cd $CDF_HOME/bin Run the following command to remove the OO release: ./helm uninstall <OO RELEASE NAME> -n <OO NAMESPACE> Where: <OO RELEASE NAME> is the OO release that you want to uninstall, which you can get by running the command ./helm list -n <OO NAMESPACE>. <OO NAMESPACE> is the namespace where you installed OO. Run the following command to remove the OO deployment: cd $CDF_HOME/scripts ./cdfctl.sh deployment delete -d <OO DEPLOYMENT NAME> Where: <OO DEPLOYMENT NAME> is the name you specified for the deployment you created to install OO. For example: ./cdfctl.sh deployment delete -d oo-prod You must enter the administrator password you set during the OMT installation. Remove persistent volume and claims If you created the volumes.yaml sample file as documented in the Prepare persis",
    "url": "399-uninstallooocp",
    "filename": "399-uninstallooocp",
    "headings": [
      "Delete the OO deployment",
      "Remove persistent volume and claims",
      "Clean the databases"
    ],
    "keywords": [
      "cdfctl.sh",
      "volumes.yaml",
      "claims.yaml",
      "uninstall",
      "oo",
      "containerized",
      "ocp",
      "delete",
      "deployment",
      "remove",
      "persistent",
      "volume",
      "claims",
      "clean",
      "databases",
      "openshift",
      "perform",
      "following",
      "tasks",
      "log",
      "bastion",
      "node",
      "navigate",
      "optic",
      "management",
      "toolkit",
      "omt",
      "installation",
      "directory",
      "cd",
      "bin",
      "run",
      "command",
      "release",
      "helm",
      "-n",
      "want",
      "get",
      "running",
      "list",
      "namespace",
      "installed",
      "oo.",
      "scripts",
      "-d",
      "name",
      "specified",
      "created",
      "install",
      "example",
      "oo-prod",
      "enter",
      "administrator",
      "password",
      "set",
      "during",
      "installation.",
      "sample",
      "file",
      "documented",
      "prepare",
      "volumes",
      "step",
      "kubectl",
      "-f",
      "oo-helm-charts-1.x.x",
      "26.x.x",
      "oo-helm-charts",
      "samples",
      "residing",
      "external",
      "postgresql",
      "aren",
      "removed.",
      "need",
      "manually.",
      "different",
      "names",
      "creating",
      "database",
      "users",
      "components",
      "replace",
      "default",
      "below",
      "actual",
      "used.",
      "connect",
      "postgres",
      "server",
      "psql",
      "-h",
      "-p",
      "-u",
      "all",
      "commands",
      "drop",
      "oocentraldb",
      "oouidb",
      "oocontrollerdb"
    ],
    "language": "en",
    "word_count": 92,
    "importance_score": 4.5,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "uninstall oo containerized on ocp",
    "contentLower": "to uninstall oo containerized on openshift, perform the following tasks: delete the oo deployment log on to the bastion node, and navigate to the optic management toolkit (omt) installation directory: cd $cdf_home/bin run the following command to remove the oo release: ./helm uninstall <oo release name> -n <oo namespace> where: <oo release name> is the oo release that you want to uninstall, which you can get by running the command ./helm list -n <oo namespace>. <oo namespace> is the namespace where you installed oo. run the following command to remove the oo deployment: cd $cdf_home/scripts ./cdfctl.sh deployment delete -d <oo deployment name> where: <oo deployment name> is the name you specified for the deployment you created to install oo. for example: ./cdfctl.sh deployment delete -d oo-prod you must enter the administrator password you set during the omt installation. remove persistent volume and claims if you created the volumes.yaml sample file as documented in the prepare persis",
    "keywordsLower": [
      "cdfctl.sh",
      "volumes.yaml",
      "claims.yaml",
      "uninstall",
      "oo",
      "containerized",
      "ocp",
      "delete",
      "deployment",
      "remove",
      "persistent",
      "volume",
      "claims",
      "clean",
      "databases",
      "openshift",
      "perform",
      "following",
      "tasks",
      "log",
      "bastion",
      "node",
      "navigate",
      "optic",
      "management",
      "toolkit",
      "omt",
      "installation",
      "directory",
      "cd",
      "bin",
      "run",
      "command",
      "release",
      "helm",
      "-n",
      "want",
      "get",
      "running",
      "list",
      "namespace",
      "installed",
      "oo.",
      "scripts",
      "-d",
      "name",
      "specified",
      "created",
      "install",
      "example",
      "oo-prod",
      "enter",
      "administrator",
      "password",
      "set",
      "during",
      "installation.",
      "sample",
      "file",
      "documented",
      "prepare",
      "volumes",
      "step",
      "kubectl",
      "-f",
      "oo-helm-charts-1.x.x",
      "26.x.x",
      "oo-helm-charts",
      "samples",
      "residing",
      "external",
      "postgresql",
      "aren",
      "removed.",
      "need",
      "manually.",
      "different",
      "names",
      "creating",
      "database",
      "users",
      "components",
      "replace",
      "default",
      "below",
      "actual",
      "used.",
      "connect",
      "postgres",
      "server",
      "psql",
      "-h",
      "-p",
      "-u",
      "all",
      "commands",
      "drop",
      "oocentraldb",
      "oouidb",
      "oocontrollerdb"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Upload container images to a registry (OpenShift)",
    "content": "Upload the installation images to your image registry. The image registry is a local registry on your cluster nodes or an external registry, such as your enterprise repository. To upload the images: Log on to the bastion node where you downloaded or copied the images. Run the following command to the $CDF_HOME/scripts/ directory: cd $CDF_HOME/scripts Run the following command to upload the suite images to the local registry: ./uploadimages.sh [-r <image repository URL> -u <username> -d <image download directory> -o <org name>] Where, <image repository URL>: Specify the -r option if you want to upload the images to an external registry other than the local registry. Replace <username> with the registry username. Use the registry-admin user for the local registry. The local registry refers to the default registry or the registry URL that's localhost:5000. If you don't specify the credentials here, you can specify when prompted while running the command. <image download directory>: The di",
    "url": "uploadinstallationimagesopenshift",
    "filename": "uploadinstallationimagesopenshift",
    "headings": [],
    "keywords": [
      "downloadimages.sh",
      "uploadimages.sh",
      "tar.gz",
      "updateLocalRegistryInfo.sh",
      "upload",
      "container",
      "images",
      "registry",
      "openshift",
      "installation",
      "image",
      "registry.",
      "local",
      "cluster",
      "nodes",
      "external",
      "such",
      "enterprise",
      "repository.",
      "log",
      "bastion",
      "node",
      "downloaded",
      "copied",
      "images.",
      "run",
      "following",
      "command",
      "scripts",
      "directory",
      "cd",
      "suite",
      "-r",
      "-u",
      "-d",
      "-o",
      "specify",
      "option",
      "want",
      "replace",
      "username.",
      "registry-admin",
      "user",
      "refers",
      "default",
      "url",
      "localhost",
      "5000.",
      "don",
      "credentials",
      "here",
      "prompted",
      "while",
      "running",
      "command.",
      "get",
      "downloaded.",
      "value",
      "var",
      "opt",
      "cdf",
      "offline.",
      "placed",
      "aren",
      "available",
      "offline",
      "directory.",
      "multiple",
      "times",
      "different",
      "directories.",
      "however",
      "specified",
      "-l",
      "false",
      "one",
      "download",
      "downloadimages.sh.",
      ".tar",
      ".tgz",
      ".tar.gz",
      "supported.",
      "make",
      "sure",
      "file",
      "type",
      "matches",
      "extension.",
      "organization",
      "contains",
      "installation.",
      "hpeswitom.",
      "mandatory",
      "name.",
      "see",
      "full",
      "list",
      "options",
      "-h",
      "example"
    ],
    "language": "en",
    "word_count": 89,
    "importance_score": 2.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "upload container images to a registry (openshift)",
    "contentLower": "upload the installation images to your image registry. the image registry is a local registry on your cluster nodes or an external registry, such as your enterprise repository. to upload the images: log on to the bastion node where you downloaded or copied the images. run the following command to the $cdf_home/scripts/ directory: cd $cdf_home/scripts run the following command to upload the suite images to the local registry: ./uploadimages.sh [-r <image repository url> -u <username> -d <image download directory> -o <org name>] where, <image repository url>: specify the -r option if you want to upload the images to an external registry other than the local registry. replace <username> with the registry username. use the registry-admin user for the local registry. the local registry refers to the default registry or the registry url that's localhost:5000. if you don't specify the credentials here, you can specify when prompted while running the command. <image download directory>: the di",
    "keywordsLower": [
      "downloadimages.sh",
      "uploadimages.sh",
      "tar.gz",
      "updatelocalregistryinfo.sh",
      "upload",
      "container",
      "images",
      "registry",
      "openshift",
      "installation",
      "image",
      "registry.",
      "local",
      "cluster",
      "nodes",
      "external",
      "such",
      "enterprise",
      "repository.",
      "log",
      "bastion",
      "node",
      "downloaded",
      "copied",
      "images.",
      "run",
      "following",
      "command",
      "scripts",
      "directory",
      "cd",
      "suite",
      "-r",
      "-u",
      "-d",
      "-o",
      "specify",
      "option",
      "want",
      "replace",
      "username.",
      "registry-admin",
      "user",
      "refers",
      "default",
      "url",
      "localhost",
      "5000.",
      "don",
      "credentials",
      "here",
      "prompted",
      "while",
      "running",
      "command.",
      "get",
      "downloaded.",
      "value",
      "var",
      "opt",
      "cdf",
      "offline.",
      "placed",
      "aren",
      "available",
      "offline",
      "directory.",
      "multiple",
      "times",
      "different",
      "directories.",
      "however",
      "specified",
      "-l",
      "false",
      "one",
      "download",
      "downloadimages.sh.",
      ".tar",
      ".tgz",
      ".tar.gz",
      "supported.",
      "make",
      "sure",
      "file",
      "type",
      "matches",
      "extension.",
      "organization",
      "contains",
      "installation.",
      "hpeswitom.",
      "mandatory",
      "name.",
      "see",
      "full",
      "list",
      "options",
      "-h",
      "example"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Uninstall Audit on OpenShift",
    "content": "To uninstall Audit service that you deployed on OpenShift, perform the following tasks: Delete the deployment Log on to the bastion node. To remove the Audit release, run the following command: helm uninstall <Audit Release Name> -n <Audit Namespace> where, <Audit Release Name> is the Audit release that you want to uninstall. <Audit Namespace> is the namespace where you installed Audit. Go to the $CDF_HOME/scripts folder and run the following command: ./cdfctl.sh deployment delete -d <Audit Deployment Name> where, <Audit Deployment Name> is the name you specified for the deployment you created to install Audit. For example: ./cdfctl.sh deployment delete -d audit-prod Remove persistent volumes If you created PVs based on the itom-audit-pv.yaml sample file as documented in Create persistent volumes, you can run the following command to delete the persistent volumes: kubectl delete -f itom-audit-pv.yaml Clean the NFS volumes Log on to the NFS server host and clear all the contents in the ",
    "url": "uninstallauditopenshift",
    "filename": "uninstallauditopenshift",
    "headings": [
      "Delete the deployment",
      "Remove persistent volumes",
      "Clean the NFS volumes",
      "Clean the databases"
    ],
    "keywords": [
      "cdfctl.sh",
      "pv.yaml",
      "uninstall",
      "audit",
      "openshift",
      "delete",
      "deployment",
      "remove",
      "persistent",
      "volumes",
      "clean",
      "nfs",
      "databases",
      "service",
      "deployed",
      "perform",
      "following",
      "tasks",
      "log",
      "bastion",
      "node.",
      "release",
      "run",
      "command",
      "helm",
      "-n",
      "want",
      "uninstall.",
      "namespace",
      "installed",
      "audit.",
      "go",
      "scripts",
      "folder",
      "-d",
      "name",
      "specified",
      "created",
      "install",
      "example",
      "audit-prod",
      "pvs",
      "based",
      "itom-audit-pv.yaml",
      "sample",
      "file",
      "documented",
      "create",
      "kubectl",
      "-f",
      "server",
      "host",
      "clear",
      "all",
      "contents",
      "volume",
      "directories",
      "created.",
      "rm",
      "-rf",
      "var",
      "vols",
      "itom",
      "auditns",
      "vault",
      "uninstallation",
      "process",
      "doesn",
      "external",
      "postgresql",
      "server.",
      "need",
      "manually."
    ],
    "language": "en",
    "word_count": 88,
    "importance_score": 5.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "uninstall audit on openshift",
    "contentLower": "to uninstall audit service that you deployed on openshift, perform the following tasks: delete the deployment log on to the bastion node. to remove the audit release, run the following command: helm uninstall <audit release name> -n <audit namespace> where, <audit release name> is the audit release that you want to uninstall. <audit namespace> is the namespace where you installed audit. go to the $cdf_home/scripts folder and run the following command: ./cdfctl.sh deployment delete -d <audit deployment name> where, <audit deployment name> is the name you specified for the deployment you created to install audit. for example: ./cdfctl.sh deployment delete -d audit-prod remove persistent volumes if you created pvs based on the itom-audit-pv.yaml sample file as documented in create persistent volumes, you can run the following command to delete the persistent volumes: kubectl delete -f itom-audit-pv.yaml clean the nfs volumes log on to the nfs server host and clear all the contents in the ",
    "keywordsLower": [
      "cdfctl.sh",
      "pv.yaml",
      "uninstall",
      "audit",
      "openshift",
      "delete",
      "deployment",
      "remove",
      "persistent",
      "volumes",
      "clean",
      "nfs",
      "databases",
      "service",
      "deployed",
      "perform",
      "following",
      "tasks",
      "log",
      "bastion",
      "node.",
      "release",
      "run",
      "command",
      "helm",
      "-n",
      "want",
      "uninstall.",
      "namespace",
      "installed",
      "audit.",
      "go",
      "scripts",
      "folder",
      "-d",
      "name",
      "specified",
      "created",
      "install",
      "example",
      "audit-prod",
      "pvs",
      "based",
      "itom-audit-pv.yaml",
      "sample",
      "file",
      "documented",
      "create",
      "kubectl",
      "-f",
      "server",
      "host",
      "clear",
      "all",
      "contents",
      "volume",
      "directories",
      "created.",
      "rm",
      "-rf",
      "var",
      "vols",
      "itom",
      "auditns",
      "vault",
      "uninstallation",
      "process",
      "doesn",
      "external",
      "postgresql",
      "server.",
      "need",
      "manually."
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Uninstall Audit collector on OpenShift",
    "content": "To uninstall the Audit collector, perform the following tasks. Delete the Audit collector Log on to the bastion node. Run the following command to remove the Audit collector: helm uninstall <Audit Collector Release Name> -n <Audit Producer Namespace> where, <Audit Collector Release Name> is the Audit collector release name that you want to uninstall. <Audit Producer Namespace> is the namespace where you installed the Audit producer. Clean the NFS volumes Log on to the NFS server host and clear all the contents in the NFS volume directories that you have created for the Audit collector. For example: rm -rf /var/vols/itom/itsma/global-volume/logs/audit-collector/*",
    "url": "uninstallauditcollectoropenshift",
    "filename": "uninstallauditcollectoropenshift",
    "headings": [
      "Delete the Audit collector",
      "Clean the NFS volumes"
    ],
    "keywords": [
      "uninstall",
      "audit",
      "collector",
      "openshift",
      "delete",
      "clean",
      "nfs",
      "volumes",
      "perform",
      "following",
      "tasks.",
      "log",
      "bastion",
      "node.",
      "run",
      "command",
      "remove",
      "helm",
      "-n",
      "release",
      "name",
      "want",
      "uninstall.",
      "namespace",
      "installed",
      "producer.",
      "server",
      "host",
      "clear",
      "all",
      "contents",
      "volume",
      "directories",
      "created",
      "collector.",
      "example",
      "rm",
      "-rf",
      "var",
      "vols",
      "itom",
      "itsma",
      "global-volume",
      "logs",
      "audit-collector"
    ],
    "language": "en",
    "word_count": 61,
    "importance_score": 4.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "uninstall audit collector on openshift",
    "contentLower": "to uninstall the audit collector, perform the following tasks. delete the audit collector log on to the bastion node. run the following command to remove the audit collector: helm uninstall <audit collector release name> -n <audit producer namespace> where, <audit collector release name> is the audit collector release name that you want to uninstall. <audit producer namespace> is the namespace where you installed the audit producer. clean the nfs volumes log on to the nfs server host and clear all the contents in the nfs volume directories that you have created for the audit collector. for example: rm -rf /var/vols/itom/itsma/global-volume/logs/audit-collector/*",
    "keywordsLower": [
      "uninstall",
      "audit",
      "collector",
      "openshift",
      "delete",
      "clean",
      "nfs",
      "volumes",
      "perform",
      "following",
      "tasks.",
      "log",
      "bastion",
      "node.",
      "run",
      "command",
      "remove",
      "helm",
      "-n",
      "release",
      "name",
      "want",
      "uninstall.",
      "namespace",
      "installed",
      "producer.",
      "server",
      "host",
      "clear",
      "all",
      "contents",
      "volume",
      "directories",
      "created",
      "collector.",
      "example",
      "rm",
      "-rf",
      "var",
      "vols",
      "itom",
      "itsma",
      "global-volume",
      "logs",
      "audit-collector"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Verify ESM installation",
    "content": "Verify ESM installation Run the following command to check all required PVs are ready. The status for all PVCs should be in \"Bound\" state. kubectl get pvc -n <ESM_NAMESPACE> If the status is not in 'Bound\" state for all PVCs, run the following command to describe the abnormal PVC or corresponding PV to check the reason: kubectl describe pvc <PVC_NAME> -n <ESM_NAMESPACE> kubectl describe pv <PV_NAME> Check if the configuration in my-values.yaml file is correct, for example,  if persistence is configured correctly. Make sure the steps for preparing the PV is correct. For details, see Prepare PV. Run the following command to make sure all job resources are complete. If all jobs are completed, the command output will contain COMPLETIONS are 1/1. kubectl get job -n <ESM_NAMESPACE> Run the following command to make sure that all required Pods are ready: kubectl get pod -n <ESM_NAMESPACE> |grep -v 1/1|grep -v 2/2|grep -v 3/3|grep -v 4/4|grep -v Complete | grep -v sma-approle-secret| grep -v u",
    "url": "verifyesminstall",
    "filename": "verifyesminstall",
    "headings": [
      "Verify ESM installation"
    ],
    "keywords": [
      "values.yaml",
      "https://<EXTERNAL_ACCESS_HOST>/bo",
      "verify",
      "esm",
      "installation",
      "run",
      "following",
      "command",
      "check",
      "all",
      "required",
      "pvs",
      "ready.",
      "status",
      "pvcs",
      "bound",
      "state.",
      "kubectl",
      "get",
      "pvc",
      "-n",
      "state",
      "describe",
      "abnormal",
      "corresponding",
      "pv",
      "reason",
      "configuration",
      "my-values.yaml",
      "file",
      "correct",
      "example",
      "persistence",
      "configured",
      "correctly.",
      "make",
      "sure",
      "steps",
      "preparing",
      "correct.",
      "details",
      "see",
      "prepare",
      "pv.",
      "job",
      "resources",
      "complete.",
      "jobs",
      "completed",
      "output",
      "contain",
      "completions",
      "1.",
      "pods",
      "ready",
      "pod",
      "grep",
      "-v",
      "complete",
      "sma-approle-secret",
      "upgrade-tenants",
      "url",
      "accessible.",
      "https",
      "bo"
    ],
    "language": "en",
    "word_count": 124,
    "importance_score": 3.5,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "verify esm installation",
    "contentLower": "verify esm installation run the following command to check all required pvs are ready. the status for all pvcs should be in \"bound\" state. kubectl get pvc -n <esm_namespace> if the status is not in 'bound\" state for all pvcs, run the following command to describe the abnormal pvc or corresponding pv to check the reason: kubectl describe pvc <pvc_name> -n <esm_namespace> kubectl describe pv <pv_name> check if the configuration in my-values.yaml file is correct, for example,  if persistence is configured correctly. make sure the steps for preparing the pv is correct. for details, see prepare pv. run the following command to make sure all job resources are complete. if all jobs are completed, the command output will contain completions are 1/1. kubectl get job -n <esm_namespace> run the following command to make sure that all required pods are ready: kubectl get pod -n <esm_namespace> |grep -v 1/1|grep -v 2/2|grep -v 3/3|grep -v 4/4|grep -v complete | grep -v sma-approle-secret| grep -v u",
    "keywordsLower": [
      "values.yaml",
      "https://<external_access_host>/bo",
      "verify",
      "esm",
      "installation",
      "run",
      "following",
      "command",
      "check",
      "all",
      "required",
      "pvs",
      "ready.",
      "status",
      "pvcs",
      "bound",
      "state.",
      "kubectl",
      "get",
      "pvc",
      "-n",
      "state",
      "describe",
      "abnormal",
      "corresponding",
      "pv",
      "reason",
      "configuration",
      "my-values.yaml",
      "file",
      "correct",
      "example",
      "persistence",
      "configured",
      "correctly.",
      "make",
      "sure",
      "steps",
      "preparing",
      "correct.",
      "details",
      "see",
      "prepare",
      "pv.",
      "job",
      "resources",
      "complete.",
      "jobs",
      "completed",
      "output",
      "contain",
      "completions",
      "1.",
      "pods",
      "ready",
      "pod",
      "grep",
      "-v",
      "complete",
      "sma-approle-secret",
      "upgrade-tenants",
      "url",
      "accessible.",
      "https",
      "bo"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Upload the application Helm chart",
    "content": "To install an application, you must upload the application chart to the cluster. If you want to install the application through AppHub UI, you must upload the chart. Upload the application chart using AppHub To do this, follow these steps: Log in to AppHub Copy the installation portal URL to a supported browser. The URL uses the following format: https://<external_access_host>:<apphub-port>/apphub. For example: https://myhost.mycompany.com:5443/apphub Log in using the cluster administrator credentials that you provided when you ran the ./install command: User name: admin Password: Enter the password you provided during OMT installation. Click LOG IN. Upload a Helm chart You can only upload one application (two files) at a time. Otherwise, you'll get a warning and the upload will fail. If you try uploading a chart file without a provenance file, you will get a warning that this isn't recommended. Because AppHub won't be able to verify the integrity of the chart. It's recommended always ",
    "url": "uploadoohelmchart",
    "filename": "uploadoohelmchart",
    "headings": [
      "Upload the application chart using AppHub",
      "Log in to AppHub",
      "Upload a Helm chart",
      "Related topic"
    ],
    "keywords": [
      "https://<external_access_host>:<apphub-port>/apphub",
      "tgz.prov",
      "https://myhost.mycompany.com:5443/apphub",
      "mycompany.com",
      "upload",
      "application",
      "helm",
      "chart",
      "apphub",
      "log",
      "related",
      "topic",
      "install",
      "cluster.",
      "want",
      "through",
      "ui",
      "chart.",
      "follow",
      "steps",
      "copy",
      "installation",
      "portal",
      "url",
      "supported",
      "browser.",
      "uses",
      "following",
      "format",
      "https",
      "apphub.",
      "example",
      "myhost.mycompany.com",
      "5443",
      "cluster",
      "administrator",
      "credentials",
      "provided",
      "ran",
      "command",
      "user",
      "name",
      "admin",
      "password",
      "enter",
      "during",
      "omt",
      "installation.",
      "click",
      "in.",
      "one",
      "two",
      "files",
      "time.",
      "otherwise",
      "ll",
      "get",
      "warning",
      "fail.",
      "try",
      "uploading",
      "file",
      "provenance",
      "isn",
      "recommended.",
      "because",
      "won",
      "able",
      "verify",
      "integrity",
      "recommended",
      "always",
      "file.",
      "applications",
      "page",
      "icon",
      "appears.",
      "screen",
      "prompt",
      ".tgz",
      ".tgz.prov",
      "upload.",
      "wait",
      "few",
      "seconds",
      "until",
      "see",
      "complete.",
      "another",
      "need",
      "exit.",
      "refresh",
      "uploaded",
      "appear",
      "page.",
      "validate",
      "signature",
      "validation."
    ],
    "language": "en",
    "word_count": 101,
    "importance_score": 5.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "upload the application helm chart",
    "contentLower": "to install an application, you must upload the application chart to the cluster. if you want to install the application through apphub ui, you must upload the chart. upload the application chart using apphub to do this, follow these steps: log in to apphub copy the installation portal url to a supported browser. the url uses the following format: https://<external_access_host>:<apphub-port>/apphub. for example: https://myhost.mycompany.com:5443/apphub log in using the cluster administrator credentials that you provided when you ran the ./install command: user name: admin password: enter the password you provided during omt installation. click log in. upload a helm chart you can only upload one application (two files) at a time. otherwise, you'll get a warning and the upload will fail. if you try uploading a chart file without a provenance file, you will get a warning that this isn't recommended. because apphub won't be able to verify the integrity of the chart. it's recommended always ",
    "keywordsLower": [
      "https://<external_access_host>:<apphub-port>/apphub",
      "tgz.prov",
      "https://myhost.mycompany.com:5443/apphub",
      "mycompany.com",
      "upload",
      "application",
      "helm",
      "chart",
      "apphub",
      "log",
      "related",
      "topic",
      "install",
      "cluster.",
      "want",
      "through",
      "ui",
      "chart.",
      "follow",
      "steps",
      "copy",
      "installation",
      "portal",
      "url",
      "supported",
      "browser.",
      "uses",
      "following",
      "format",
      "https",
      "apphub.",
      "example",
      "myhost.mycompany.com",
      "5443",
      "cluster",
      "administrator",
      "credentials",
      "provided",
      "ran",
      "command",
      "user",
      "name",
      "admin",
      "password",
      "enter",
      "during",
      "omt",
      "installation.",
      "click",
      "in.",
      "one",
      "two",
      "files",
      "time.",
      "otherwise",
      "ll",
      "get",
      "warning",
      "fail.",
      "try",
      "uploading",
      "file",
      "provenance",
      "isn",
      "recommended.",
      "because",
      "won",
      "able",
      "verify",
      "integrity",
      "recommended",
      "always",
      "file.",
      "applications",
      "page",
      "icon",
      "appears.",
      "screen",
      "prompt",
      ".tgz",
      ".tgz.prov",
      "upload.",
      "wait",
      "few",
      "seconds",
      "until",
      "see",
      "complete.",
      "another",
      "need",
      "exit.",
      "refresh",
      "uploaded",
      "appear",
      "page.",
      "validate",
      "signature",
      "validation."
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Verify installation",
    "content": "To verify the OO Containerized install completion, run the following command to see the pod status in a namespace: kubectl get pods -n <oo-namespace> The STATUS column indicates the current lifecycle state of the pod.  For example, Pending, Running, Completed, Init, CrashLoopBackoff. You will see many pods in Init state, which eventually becomes PodInitializing state, and then Running state. In addition, if the pod status is Running, check the READY column to see if the pod is fully started up.  The READY column contains two numbers in the form X/Y. X indicates the number of containers running in the pod. Y indicates the number of containers that should be running. For example, 1/2 means that one out of two containers is running, so the pod isn't fully started yet. The lifecycle state may take a long time to change, for example, 45 minutes. Verify the URL access Based on your deployment, you will be able to access the following URLs: Capabilities Applications URL Default Port All User ",
    "url": "verifyinstallooc",
    "filename": "verifyinstallooc",
    "headings": [
      "Verify the URL access"
    ],
    "keywords": [
      "https://<external_access_host_FQDN>:<external_access_port>/autopass",
      "https://<external_access_host_FQDN>:<OMT_external_access_port>/idm-admin",
      "https://<external_access_host_FQDN>:<external_access_port>/oo",
      "verify",
      "installation",
      "url",
      "access",
      "oo",
      "containerized",
      "install",
      "completion",
      "run",
      "following",
      "command",
      "see",
      "pod",
      "status",
      "namespace",
      "kubectl",
      "get",
      "pods",
      "-n",
      "column",
      "indicates",
      "current",
      "lifecycle",
      "state",
      "pod.",
      "example",
      "pending",
      "running",
      "completed",
      "init",
      "crashloopbackoff.",
      "many",
      "eventually",
      "becomes",
      "podinitializing",
      "state.",
      "addition",
      "check",
      "ready",
      "fully",
      "started",
      "up.",
      "contains",
      "two",
      "numbers",
      "form",
      "y.",
      "number",
      "containers",
      "running.",
      "means",
      "one",
      "out",
      "isn",
      "yet.",
      "take",
      "long",
      "time",
      "change",
      "45",
      "minutes.",
      "based",
      "deployment",
      "able",
      "urls",
      "capabilities",
      "applications",
      "default",
      "port",
      "all",
      "user",
      "management",
      "ui",
      "https",
      "idm-admin",
      "5443",
      "license",
      "autopass",
      "9443",
      "operations",
      "orchestration",
      "ui¹",
      "completely",
      "functional",
      "after",
      "configuring",
      "tenant.",
      "tip",
      "secure",
      "message",
      "browsers",
      "service",
      "validate",
      "certificates",
      "establish",
      "connection.",
      "details"
    ],
    "language": "en",
    "word_count": 113,
    "importance_score": 3.5,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "verify installation",
    "contentLower": "to verify the oo containerized install completion, run the following command to see the pod status in a namespace: kubectl get pods -n <oo-namespace> the status column indicates the current lifecycle state of the pod.  for example, pending, running, completed, init, crashloopbackoff. you will see many pods in init state, which eventually becomes podinitializing state, and then running state. in addition, if the pod status is running, check the ready column to see if the pod is fully started up.  the ready column contains two numbers in the form x/y. x indicates the number of containers running in the pod. y indicates the number of containers that should be running. for example, 1/2 means that one out of two containers is running, so the pod isn't fully started yet. the lifecycle state may take a long time to change, for example, 45 minutes. verify the url access based on your deployment, you will be able to access the following urls: capabilities applications url default port all user ",
    "keywordsLower": [
      "https://<external_access_host_fqdn>:<external_access_port>/autopass",
      "https://<external_access_host_fqdn>:<omt_external_access_port>/idm-admin",
      "https://<external_access_host_fqdn>:<external_access_port>/oo",
      "verify",
      "installation",
      "url",
      "access",
      "oo",
      "containerized",
      "install",
      "completion",
      "run",
      "following",
      "command",
      "see",
      "pod",
      "status",
      "namespace",
      "kubectl",
      "get",
      "pods",
      "-n",
      "column",
      "indicates",
      "current",
      "lifecycle",
      "state",
      "pod.",
      "example",
      "pending",
      "running",
      "completed",
      "init",
      "crashloopbackoff.",
      "many",
      "eventually",
      "becomes",
      "podinitializing",
      "state.",
      "addition",
      "check",
      "ready",
      "fully",
      "started",
      "up.",
      "contains",
      "two",
      "numbers",
      "form",
      "y.",
      "number",
      "containers",
      "running.",
      "means",
      "one",
      "out",
      "isn",
      "yet.",
      "take",
      "long",
      "time",
      "change",
      "45",
      "minutes.",
      "based",
      "deployment",
      "able",
      "urls",
      "capabilities",
      "applications",
      "default",
      "port",
      "all",
      "user",
      "management",
      "ui",
      "https",
      "idm-admin",
      "5443",
      "license",
      "autopass",
      "9443",
      "operations",
      "orchestration",
      "ui¹",
      "completely",
      "functional",
      "after",
      "configuring",
      "tenant.",
      "tip",
      "secure",
      "message",
      "browsers",
      "service",
      "validate",
      "certificates",
      "establish",
      "connection.",
      "details"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Uninstall OO RAS",
    "content": "This topic lists steps to uninstall OO Remote Action Server (RAS) on Windows and Linux systems. Uninstall OO RAS on Windows In the OO RAS install directory right click uninstall.exe and select Run as an administrator. This opens the Uninstall Wizard Click Next. In the Options section, select Remote Action Server and click Uninstall. (Optional) Unregister the RAS in OO Central. You can unregister this OO RAS from OO Central as part of uninstall. Doing so, this RAS will no longer display in Topology section in OO Central UI. To unregister the RAS as during uninstall: Select \"Provide credentials of a Central user with permission to unregister a RAS (optional)\" checkbox. To keep the RAS in OO Central's Topology section, don't select this check box and click Next. Give the credentials of an IdM user that has the oo_manageTopology permission. Test the connection to OO Central. Click Next. In the Uninstall Progress section, once the uninstall is complete, click Finish. Uninstall OO RAS on Lin",
    "url": "uninstalloorassilent",
    "filename": "uninstalloorassilent",
    "headings": [
      "Uninstall OO RAS on Windows",
      "Uninstall OO RAS on Linux",
      "Silent uninstallation of OO RAS"
    ],
    "keywords": [
      "uninstall.exe",
      "uninstall",
      "oo",
      "ras",
      "windows",
      "linux",
      "silent",
      "uninstallation",
      "topic",
      "lists",
      "steps",
      "remote",
      "action",
      "server",
      "systems.",
      "install",
      "directory",
      "right",
      "click",
      "select",
      "run",
      "administrator.",
      "opens",
      "wizard",
      "next.",
      "options",
      "section",
      "uninstall.",
      "optional",
      "unregister",
      "central.",
      "central",
      "part",
      "doing",
      "longer",
      "display",
      "topology",
      "ui.",
      "during",
      "provide",
      "credentials",
      "user",
      "permission",
      "checkbox.",
      "keep",
      "don",
      "check",
      "box",
      "give",
      "idm",
      "permission.",
      "test",
      "connection",
      "progress",
      "once",
      "complete",
      "finish.",
      "system",
      "navigate",
      "stop",
      "service",
      "example",
      "opt",
      "microfocus",
      "command",
      "stopping",
      "bin",
      "stop.",
      "delete",
      "directory.",
      "note",
      "worker",
      "remains",
      "manually",
      "removed.",
      "one",
      "started",
      "line",
      "completes",
      "any",
      "input",
      "person",
      "it.",
      "perform",
      "environments.",
      "external",
      "open",
      "type",
      "following",
      "prompt",
      "-s",
      "isn",
      "removed",
      "view.",
      "go",
      "configuration",
      "workers",
      "remove",
      "topology."
    ],
    "language": "en",
    "word_count": 115,
    "importance_score": 4.5,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "uninstall oo ras",
    "contentLower": "this topic lists steps to uninstall oo remote action server (ras) on windows and linux systems. uninstall oo ras on windows in the oo ras install directory right click uninstall.exe and select run as an administrator. this opens the uninstall wizard click next. in the options section, select remote action server and click uninstall. (optional) unregister the ras in oo central. you can unregister this oo ras from oo central as part of uninstall. doing so, this ras will no longer display in topology section in oo central ui. to unregister the ras as during uninstall: select \"provide credentials of a central user with permission to unregister a ras (optional)\" checkbox. to keep the ras in oo central's topology section, don't select this check box and click next. give the credentials of an idm user that has the oo_managetopology permission. test the connection to oo central. click next. in the uninstall progress section, once the uninstall is complete, click finish. uninstall oo ras on lin",
    "keywordsLower": [
      "uninstall.exe",
      "uninstall",
      "oo",
      "ras",
      "windows",
      "linux",
      "silent",
      "uninstallation",
      "topic",
      "lists",
      "steps",
      "remote",
      "action",
      "server",
      "systems.",
      "install",
      "directory",
      "right",
      "click",
      "select",
      "run",
      "administrator.",
      "opens",
      "wizard",
      "next.",
      "options",
      "section",
      "uninstall.",
      "optional",
      "unregister",
      "central.",
      "central",
      "part",
      "doing",
      "longer",
      "display",
      "topology",
      "ui.",
      "during",
      "provide",
      "credentials",
      "user",
      "permission",
      "checkbox.",
      "keep",
      "don",
      "check",
      "box",
      "give",
      "idm",
      "permission.",
      "test",
      "connection",
      "progress",
      "once",
      "complete",
      "finish.",
      "system",
      "navigate",
      "stop",
      "service",
      "example",
      "opt",
      "microfocus",
      "command",
      "stopping",
      "bin",
      "stop.",
      "delete",
      "directory.",
      "note",
      "worker",
      "remains",
      "manually",
      "removed.",
      "one",
      "started",
      "line",
      "completes",
      "any",
      "input",
      "person",
      "it.",
      "perform",
      "environments.",
      "external",
      "open",
      "type",
      "following",
      "prompt",
      "-s",
      "isn",
      "removed",
      "view.",
      "go",
      "configuration",
      "workers",
      "remove",
      "topology."
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Uninstall OO Workflow Designer",
    "content": "Before uninstalling OO Workflow Designer, ensure that you back up the current version. There are two ways to uninstall OO Workflow Designer: Using the uninstall wizard on both Windows and Linux Silent uninstall on both Windows and Linux Uninstall OO Workflow Designer using the wizard Uninstall OO Workflow Designer on Windows Navigate to the installation directory, for example, C:\\Program Files\\Micro Focus\\Operations Orchestration Designer for Windows. Right click uninstall.exe and run as an administrator, and then click Next. Select the OO Workflow Designer, and then click Next. When prompted to continue, click Yes. The Uninstall Progress screen displays the progress of the uninstall process and the items that were deleted or removed. Uninstall OO Workflow Designer on Linux Navigate to the installation directory, for example, /opt/microfocus/oo-designer/ for Linux. Open a Terminal window. Type the following command at the prompt and press Enter. export DISPLAY=<ip address> ./uninstall ",
    "url": "uninstallooworkflowdesigner",
    "filename": "uninstallooworkflowdesigner",
    "headings": [
      "Uninstall OO Workflow Designer using the wizard",
      "Uninstall OO Workflow Designer on Windows",
      "Uninstall OO Workflow Designer on Linux",
      "Uninstall OO Workflow Designer using the silent option"
    ],
    "keywords": [
      "uninstall.exe",
      "uninstall",
      "oo",
      "workflow",
      "designer",
      "wizard",
      "windows",
      "linux",
      "silent",
      "option",
      "before",
      "uninstalling",
      "ensure",
      "back",
      "current",
      "version.",
      "there",
      "two",
      "ways",
      "both",
      "navigate",
      "installation",
      "directory",
      "example",
      "program",
      "files",
      "micro",
      "focus",
      "operations",
      "orchestration",
      "windows.",
      "right",
      "click",
      "run",
      "administrator",
      "next.",
      "select",
      "prompted",
      "continue",
      "yes.",
      "progress",
      "screen",
      "displays",
      "process",
      "items",
      "deleted",
      "removed.",
      "opt",
      "microfocus",
      "oo-designer",
      "linux.",
      "open",
      "terminal",
      "window.",
      "type",
      "following",
      "command",
      "prompt",
      "press",
      "enter.",
      "export",
      "display",
      "uninstallation",
      "one",
      "started",
      "line",
      "completes",
      "any",
      "input",
      "person",
      "it.",
      "silently",
      "components",
      "either",
      "perform",
      "window",
      "-s",
      "placeholder",
      "enter",
      "designer.",
      "tip",
      "after",
      "complete",
      "delete",
      "directory."
    ],
    "language": "en",
    "word_count": 105,
    "importance_score": 5.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "uninstall oo workflow designer",
    "contentLower": "before uninstalling oo workflow designer, ensure that you back up the current version. there are two ways to uninstall oo workflow designer: using the uninstall wizard on both windows and linux silent uninstall on both windows and linux uninstall oo workflow designer using the wizard uninstall oo workflow designer on windows navigate to the installation directory, for example, c:\\program files\\micro focus\\operations orchestration designer for windows. right click uninstall.exe and run as an administrator, and then click next. select the oo workflow designer, and then click next. when prompted to continue, click yes. the uninstall progress screen displays the progress of the uninstall process and the items that were deleted or removed. uninstall oo workflow designer on linux navigate to the installation directory, for example, /opt/microfocus/oo-designer/ for linux. open a terminal window. type the following command at the prompt and press enter. export display=<ip address> ./uninstall ",
    "keywordsLower": [
      "uninstall.exe",
      "uninstall",
      "oo",
      "workflow",
      "designer",
      "wizard",
      "windows",
      "linux",
      "silent",
      "option",
      "before",
      "uninstalling",
      "ensure",
      "back",
      "current",
      "version.",
      "there",
      "two",
      "ways",
      "both",
      "navigate",
      "installation",
      "directory",
      "example",
      "program",
      "files",
      "micro",
      "focus",
      "operations",
      "orchestration",
      "windows.",
      "right",
      "click",
      "run",
      "administrator",
      "next.",
      "select",
      "prompted",
      "continue",
      "yes.",
      "progress",
      "screen",
      "displays",
      "process",
      "items",
      "deleted",
      "removed.",
      "opt",
      "microfocus",
      "oo-designer",
      "linux.",
      "open",
      "terminal",
      "window.",
      "type",
      "following",
      "command",
      "prompt",
      "press",
      "enter.",
      "export",
      "display",
      "uninstallation",
      "one",
      "started",
      "line",
      "completes",
      "any",
      "input",
      "person",
      "it.",
      "silently",
      "components",
      "either",
      "perform",
      "window",
      "-s",
      "placeholder",
      "enter",
      "designer.",
      "tip",
      "after",
      "complete",
      "delete",
      "directory."
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Verify the deployment",
    "content": "This topic describes how to verify an Operations Platform deployment. To verify the deployment by ensuring that all the pods are up and running, perform the following steps: Run the following command on the control plane or bastion node to see the pod status in a namespace: kubectl get pods -n <application namespace> Example: kubectl get pods -n ops-platfom NAME READY STATUS RESTARTS AGE bvd-controller-deployment-785889d944-9dpcx 2/2 Running 0 60m bvd-explore-deployment-846bb7d6b-sv6mb 2/2 Running 0 60m bvd-quexserv-7f4d5b49bb-rms6s 2/2 Running 0 60m bvd-receiver-deployment-686d4f7969-5fgbb 2/2 Running 0 60m bvd-redis-5bdcd87c55-wwknf 3/3 Running 0 60m bvd-www-deployment-8669f8cc79-6cb7k 2/2 Running 0 60m itom-autopass-lms-5b9999c5f7-wxzcm 2/2 Running 0 60m itom-certificate-validator-job-dhbkq 0/1 Completed 0 61m itom-di-administration-8587bd8c6c-766l7 2/2 Running 0 60m itom-di-data-access-dpl-7fcdf56945-ghcwr 2/2 Running 0 60m itom-di-metadata-server-767897cfcc-gsgvt 2/2 Running 0 60m",
    "url": "402-verifyopinstall",
    "filename": "402-verifyopinstall",
    "headings": [
      "Verify the URL access"
    ],
    "keywords": [
      "https://<FQDN_of_the_external_access_host>:<port_number_of_the_external_access_host>/ui",
      "values.yaml",
      "https://<FQDN_of_the_external_access_host>:<port_number_of_the_external_access_host>/idm-admin",
      "https://<FQDN_of_the_external_access_host>:<port_number_of_the_external_access_host>/autopass",
      "verify",
      "deployment",
      "url",
      "access",
      "topic",
      "describes",
      "operations",
      "platform",
      "deployment.",
      "ensuring",
      "all",
      "pods",
      "running",
      "perform",
      "following",
      "steps",
      "run",
      "command",
      "control",
      "plane",
      "bastion",
      "node",
      "see",
      "pod",
      "status",
      "namespace",
      "kubectl",
      "get",
      "-n",
      "example",
      "ops-platfom",
      "name",
      "ready",
      "restarts",
      "age",
      "bvd-controller-deployment-785889d944-9dpcx",
      "60m",
      "bvd-explore-deployment-846bb7d6b-sv6mb",
      "bvd-quexserv-7f4d5b49bb-rms6s",
      "bvd-receiver-deployment-686d4f7969-5fgbb",
      "bvd-redis-5bdcd87c55-wwknf",
      "bvd-www-deployment-8669f8cc79-6cb7k",
      "itom-autopass-lms-5b9999c5f7-wxzcm",
      "itom-certificate-validator-job-dhbkq",
      "completed",
      "61m",
      "itom-di-administration-8587bd8c6c-766l7",
      "itom-di-data-access-dpl-7fcdf56945-ghcwr",
      "itom-di-metadata-server-767897cfcc-gsgvt",
      "itom-di-postload-taskcontroller-768fddd565-wftwd",
      "itom-di-postload-taskexecutor-6c65dc7d5b-xrzg7",
      "itom-di-receiver-dpl-5cb44b4d75-9zrbr",
      "itom-di-receiver-dpl-5cb44b4d75-s4v5f",
      "itom-di-scheduler-udx-54bc5ff8c5-djs8c",
      "itom-di-tenant-management-645964b8f8-x4gl8",
      "itom-di-tenant-management-preinstall-47jcg",
      "itom-idm-776966b9c6-25zp2",
      "itom-idm-776966b9c6-9jg5w",
      "itom-ingress-controller-68f9c6c7d5-5jjjx",
      "itom-ingress-controller-68f9c6c7d5-b5prv",
      "itom-op-db-connection-validator-job-7t7cs",
      "itom-prometheus-cert-exporter-6cfd54ccd9-vfpr2",
      "itom-reloader-66bb86c5b-vnt48",
      "itom-restrict-upgrade-65bf4d4f47-v5bnk",
      "itom-static-resource-provider-768f466988-m7zhw",
      "itom-vault-5b45565b98-k8q47",
      "itomdimonitoring-gen-certs-job-wsilohb-nqgls",
      "itomdipulsar-autorecovery-0",
      "itomdipulsar-bastion-0",
      "itomdipulsar-bookkeeper-0",
      "itomdipulsar-bookkeeper-1",
      "57m",
      "itomdipulsar-bookkeeper-2",
      "itomdipulsar-bookkeeper-init-1jukhp2-tpdd2",
      "itomdipulsar-broker-74f764dc4c-6vpvd",
      "itomdipulsar-broker-74f764dc4c-nxdtq",
      "itomdipulsar-broker-74f764dc4c-xjpml",
      "itomdipulsar-broker-apply-admin-settings-dhp6wsi-tv9sw",
      "itomdipulsar-multiaz-job-kv8uts7-vvzsk",
      "itomdipulsar-proxy-866cd8bdc6-cf794",
      "itomdipulsar-proxy-866cd8bdc6-d2db2",
      "itomdipulsar-zookeeper-0",
      "itomdipulsar-zookeeper-1",
      "58m",
      "itomdipulsar-zookeeper-2",
      "itomdipulsar-zookeeper-metadata-cnfzvwc-cjl87",
      "uif-contentservice-deployment-8698cd66b7-7nh5z",
      "webtopdf-deployment-5744898cfd-dmrf6",
      "column",
      "indicates",
      "current",
      "lifecycle",
      "state",
      "pod.",
      "pending",
      "init"
    ],
    "language": "en",
    "word_count": 109,
    "importance_score": 3.5,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "verify the deployment",
    "contentLower": "this topic describes how to verify an operations platform deployment. to verify the deployment by ensuring that all the pods are up and running, perform the following steps: run the following command on the control plane or bastion node to see the pod status in a namespace: kubectl get pods -n <application namespace> example: kubectl get pods -n ops-platfom name ready status restarts age bvd-controller-deployment-785889d944-9dpcx 2/2 running 0 60m bvd-explore-deployment-846bb7d6b-sv6mb 2/2 running 0 60m bvd-quexserv-7f4d5b49bb-rms6s 2/2 running 0 60m bvd-receiver-deployment-686d4f7969-5fgbb 2/2 running 0 60m bvd-redis-5bdcd87c55-wwknf 3/3 running 0 60m bvd-www-deployment-8669f8cc79-6cb7k 2/2 running 0 60m itom-autopass-lms-5b9999c5f7-wxzcm 2/2 running 0 60m itom-certificate-validator-job-dhbkq 0/1 completed 0 61m itom-di-administration-8587bd8c6c-766l7 2/2 running 0 60m itom-di-data-access-dpl-7fcdf56945-ghcwr 2/2 running 0 60m itom-di-metadata-server-767897cfcc-gsgvt 2/2 running 0 60m",
    "keywordsLower": [
      "https://<fqdn_of_the_external_access_host>:<port_number_of_the_external_access_host>/ui",
      "values.yaml",
      "https://<fqdn_of_the_external_access_host>:<port_number_of_the_external_access_host>/idm-admin",
      "https://<fqdn_of_the_external_access_host>:<port_number_of_the_external_access_host>/autopass",
      "verify",
      "deployment",
      "url",
      "access",
      "topic",
      "describes",
      "operations",
      "platform",
      "deployment.",
      "ensuring",
      "all",
      "pods",
      "running",
      "perform",
      "following",
      "steps",
      "run",
      "command",
      "control",
      "plane",
      "bastion",
      "node",
      "see",
      "pod",
      "status",
      "namespace",
      "kubectl",
      "get",
      "-n",
      "example",
      "ops-platfom",
      "name",
      "ready",
      "restarts",
      "age",
      "bvd-controller-deployment-785889d944-9dpcx",
      "60m",
      "bvd-explore-deployment-846bb7d6b-sv6mb",
      "bvd-quexserv-7f4d5b49bb-rms6s",
      "bvd-receiver-deployment-686d4f7969-5fgbb",
      "bvd-redis-5bdcd87c55-wwknf",
      "bvd-www-deployment-8669f8cc79-6cb7k",
      "itom-autopass-lms-5b9999c5f7-wxzcm",
      "itom-certificate-validator-job-dhbkq",
      "completed",
      "61m",
      "itom-di-administration-8587bd8c6c-766l7",
      "itom-di-data-access-dpl-7fcdf56945-ghcwr",
      "itom-di-metadata-server-767897cfcc-gsgvt",
      "itom-di-postload-taskcontroller-768fddd565-wftwd",
      "itom-di-postload-taskexecutor-6c65dc7d5b-xrzg7",
      "itom-di-receiver-dpl-5cb44b4d75-9zrbr",
      "itom-di-receiver-dpl-5cb44b4d75-s4v5f",
      "itom-di-scheduler-udx-54bc5ff8c5-djs8c",
      "itom-di-tenant-management-645964b8f8-x4gl8",
      "itom-di-tenant-management-preinstall-47jcg",
      "itom-idm-776966b9c6-25zp2",
      "itom-idm-776966b9c6-9jg5w",
      "itom-ingress-controller-68f9c6c7d5-5jjjx",
      "itom-ingress-controller-68f9c6c7d5-b5prv",
      "itom-op-db-connection-validator-job-7t7cs",
      "itom-prometheus-cert-exporter-6cfd54ccd9-vfpr2",
      "itom-reloader-66bb86c5b-vnt48",
      "itom-restrict-upgrade-65bf4d4f47-v5bnk",
      "itom-static-resource-provider-768f466988-m7zhw",
      "itom-vault-5b45565b98-k8q47",
      "itomdimonitoring-gen-certs-job-wsilohb-nqgls",
      "itomdipulsar-autorecovery-0",
      "itomdipulsar-bastion-0",
      "itomdipulsar-bookkeeper-0",
      "itomdipulsar-bookkeeper-1",
      "57m",
      "itomdipulsar-bookkeeper-2",
      "itomdipulsar-bookkeeper-init-1jukhp2-tpdd2",
      "itomdipulsar-broker-74f764dc4c-6vpvd",
      "itomdipulsar-broker-74f764dc4c-nxdtq",
      "itomdipulsar-broker-74f764dc4c-xjpml",
      "itomdipulsar-broker-apply-admin-settings-dhp6wsi-tv9sw",
      "itomdipulsar-multiaz-job-kv8uts7-vvzsk",
      "itomdipulsar-proxy-866cd8bdc6-cf794",
      "itomdipulsar-proxy-866cd8bdc6-d2db2",
      "itomdipulsar-zookeeper-0",
      "itomdipulsar-zookeeper-1",
      "58m",
      "itomdipulsar-zookeeper-2",
      "itomdipulsar-zookeeper-metadata-cnfzvwc-cjl87",
      "uif-contentservice-deployment-8698cd66b7-7nh5z",
      "webtopdf-deployment-5744898cfd-dmrf6",
      "column",
      "indicates",
      "current",
      "lifecycle",
      "state",
      "pod.",
      "pending",
      "init"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Uninstall Operations Platform",
    "content": "You can uninstall the following:​​​​​​ Uninstall only Operations Platform: If you want to retain the cluster setup along with OPTIC Management Toolkit (OMT) and uninstall only the platform, you can follow the steps mentioned in the following sections: Uninstall Operations Platform Delete the application's external Databases Uninstall everything: You may want to uninstall the application and OMT (along with local storage provisioner) and remove the complete cluster. You can follow the steps mentioned in the following sections: Uninstall Operations Platform Delete the application's external Databases Uninstall Local storage provisioner, follow the steps mentioned in Uninstall local storage provisioner. Uninstall OMT after you uninstall the application. To uninstall OMT, see OMT documentation. Uninstall Operations Platform You can uninstall the platform while retaining the OMT install. Run the following commands to look up a helm deployment name. For example: # helm list -n <namespace> NA",
    "url": "402-uninstalloperationsplatform",
    "filename": "402-uninstalloperationsplatform",
    "headings": [
      "Uninstall Operations Platform",
      "​Delete the application external Databases",
      "Delete the application user and databases for PostgreSQL",
      "Clear the Vertica database"
    ],
    "keywords": [
      "1.2.0",
      "25.2.0",
      "dbinit.sh",
      "uninstall.sql",
      "15.28736276",
      "DBSQLGenerator.sh",
      "RemoveSQL.sql",
      "uninstall",
      "operations",
      "platform",
      "delete",
      "application",
      "external",
      "databases",
      "user",
      "postgresql",
      "clear",
      "vertica",
      "database",
      "following",
      "want",
      "retain",
      "cluster",
      "setup",
      "along",
      "optic",
      "management",
      "toolkit",
      "omt",
      "follow",
      "steps",
      "mentioned",
      "sections",
      "everything",
      "local",
      "storage",
      "provisioner",
      "remove",
      "complete",
      "cluster.",
      "provisioner.",
      "after",
      "application.",
      "see",
      "documentation.",
      "while",
      "retaining",
      "install.",
      "run",
      "commands",
      "look",
      "helm",
      "deployment",
      "name.",
      "example",
      "list",
      "-n",
      "name",
      "namespace",
      "revision",
      "updated",
      "status",
      "chart",
      "app",
      "version",
      "deployment01",
      "opsplatform",
      "2025-03-10",
      "18",
      "22",
      "-0700",
      "pdt",
      "deployed",
      "op-chart-1.2.0",
      "25.2.0-71",
      "command",
      "--no-hooks",
      "uninstalls",
      "all",
      "kubernetes",
      "resources",
      "secrets",
      "persistent",
      "volume",
      "claims",
      "config",
      "maps.",
      "pvcs",
      "kubectl",
      "pvc",
      "--all",
      "volumes",
      "pv",
      "deletion",
      "fails",
      "terminating",
      "state",
      "execute",
      "patch",
      "-p"
    ],
    "language": "en",
    "word_count": 100,
    "importance_score": 5.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "uninstall operations platform",
    "contentLower": "you can uninstall the following:​​​​​​ uninstall only operations platform: if you want to retain the cluster setup along with optic management toolkit (omt) and uninstall only the platform, you can follow the steps mentioned in the following sections: uninstall operations platform delete the application's external databases uninstall everything: you may want to uninstall the application and omt (along with local storage provisioner) and remove the complete cluster. you can follow the steps mentioned in the following sections: uninstall operations platform delete the application's external databases uninstall local storage provisioner, follow the steps mentioned in uninstall local storage provisioner. uninstall omt after you uninstall the application. to uninstall omt, see omt documentation. uninstall operations platform you can uninstall the platform while retaining the omt install. run the following commands to look up a helm deployment name. for example: # helm list -n <namespace> na",
    "keywordsLower": [
      "1.2.0",
      "25.2.0",
      "dbinit.sh",
      "uninstall.sql",
      "15.28736276",
      "dbsqlgenerator.sh",
      "removesql.sql",
      "uninstall",
      "operations",
      "platform",
      "delete",
      "application",
      "external",
      "databases",
      "user",
      "postgresql",
      "clear",
      "vertica",
      "database",
      "following",
      "want",
      "retain",
      "cluster",
      "setup",
      "along",
      "optic",
      "management",
      "toolkit",
      "omt",
      "follow",
      "steps",
      "mentioned",
      "sections",
      "everything",
      "local",
      "storage",
      "provisioner",
      "remove",
      "complete",
      "cluster.",
      "provisioner.",
      "after",
      "application.",
      "see",
      "documentation.",
      "while",
      "retaining",
      "install.",
      "run",
      "commands",
      "look",
      "helm",
      "deployment",
      "name.",
      "example",
      "list",
      "-n",
      "name",
      "namespace",
      "revision",
      "updated",
      "status",
      "chart",
      "app",
      "version",
      "deployment01",
      "opsplatform",
      "2025-03-10",
      "18",
      "22",
      "-0700",
      "pdt",
      "deployed",
      "op-chart-1.2.0",
      "25.2.0-71",
      "command",
      "--no-hooks",
      "uninstalls",
      "all",
      "kubernetes",
      "resources",
      "secrets",
      "persistent",
      "volume",
      "claims",
      "config",
      "maps.",
      "pvcs",
      "kubectl",
      "pvc",
      "--all",
      "volumes",
      "pv",
      "deletion",
      "fails",
      "terminating",
      "state",
      "execute",
      "patch",
      "-p"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Uninstall local storage provisioner",
    "content": "As part of the uninstall process, you must uninstall the local storage provisioner and clear the OPTIC DL Message Bus residual files on all cluster nodes where the application namespace is deployed. To uninstall local storage provisioner: Run the following command to uninstall the local storage provisioner: helm uninstall <helm_deployment_name> -n core where: <helm_deployment_name> is the name with which you have deployed the local storage provisioner. Example: helm uninstall lpv -n core Run the following commands to delete the local storage provisioner PVCs: kubectl get pvc -n <application namespace> | grep fast-disks kubectl delete pvc <pvc name of the local storage provisioner> -n <namespace> Example: # kubectl get pvc -n op| grep fast-disk itomdipulsar-bookkeeper-journal-itomdipulsar-bookkeeper-0 Bound local-pv-1bb7a569 97Gi RWO fast-disks <unset> 20h itomdipulsar-bookkeeper-journal-itomdipulsar-bookkeeper-1 Bound local-pv-bc38d41a 97Gi RWO fast-disks <unset> 20h itomdipulsar-bookk",
    "url": "402-oplpvuninstall",
    "filename": "402-oplpvuninstall",
    "headings": [],
    "keywords": [
      "uninstall",
      "local",
      "storage",
      "provisioner",
      "part",
      "process",
      "clear",
      "optic",
      "dl",
      "message",
      "bus",
      "residual",
      "files",
      "all",
      "cluster",
      "nodes",
      "application",
      "namespace",
      "deployed.",
      "run",
      "following",
      "command",
      "helm",
      "-n",
      "core",
      "name",
      "deployed",
      "provisioner.",
      "example",
      "lpv",
      "commands",
      "delete",
      "pvcs",
      "kubectl",
      "get",
      "pvc",
      "grep",
      "fast-disks",
      "op",
      "fast-disk",
      "itomdipulsar-bookkeeper-journal-itomdipulsar-bookkeeper-0",
      "bound",
      "local-pv-1bb7a569",
      "97gi",
      "rwo",
      "20h",
      "itomdipulsar-bookkeeper-journal-itomdipulsar-bookkeeper-1",
      "local-pv-bc38d41a",
      "itomdipulsar-bookkeeper-journal-itomdipulsar-bookkeeper-2",
      "local-pv-8b574552",
      "itomdipulsar-bookkeeper-ledgers-itomdipulsar-bookkeeper-0",
      "local-pv-f43d600f",
      "itomdipulsar-bookkeeper-ledgers-itomdipulsar-bookkeeper-1",
      "local-pv-1d258401",
      "itomdipulsar-bookkeeper-ledgers-itomdipulsar-bookkeeper-2",
      "local-pv-1d7c2f09",
      "itomdipulsar-zookeeper-zookeeper-data-itomdipulsar-zookeeper-0",
      "local-pv-ce021750",
      "itomdipulsar-zookeeper-zookeeper-data-itomdipulsar-zookeeper-1",
      "local-pv-9b21fdb3",
      "itomdipulsar-zookeeper-zookeeper-data-itomdipulsar-zookeeper-2",
      "local-pv-80b73c9a",
      "pv",
      "local-pv-5b1599ea",
      "local-pv-6b090b1b",
      "local-pv-8199a5b1",
      "local-pv-a019bb9c",
      "local-pv-a306c635",
      "local-pv-c61e642",
      "local-pv-e644ca",
      "local-pv-f03deeb",
      "local-pv-faf9cc75",
      "go",
      "location",
      "volumes",
      "mounted",
      "default",
      "mnt",
      "disks",
      "virtual",
      "disk",
      "unmount",
      "directories",
      "mount",
      "path",
      "directory.",
      "perform",
      "worker",
      "nodes.",
      "cd",
      "lpv1",
      "lpv2",
      "lpv3",
      "rm",
      "-rf",
      "done"
    ],
    "language": "en",
    "word_count": 91,
    "importance_score": 3.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "uninstall local storage provisioner",
    "contentLower": "as part of the uninstall process, you must uninstall the local storage provisioner and clear the optic dl message bus residual files on all cluster nodes where the application namespace is deployed. to uninstall local storage provisioner: run the following command to uninstall the local storage provisioner: helm uninstall <helm_deployment_name> -n core where: <helm_deployment_name> is the name with which you have deployed the local storage provisioner. example: helm uninstall lpv -n core run the following commands to delete the local storage provisioner pvcs: kubectl get pvc -n <application namespace> | grep fast-disks kubectl delete pvc <pvc name of the local storage provisioner> -n <namespace> example: # kubectl get pvc -n op| grep fast-disk itomdipulsar-bookkeeper-journal-itomdipulsar-bookkeeper-0 bound local-pv-1bb7a569 97gi rwo fast-disks <unset> 20h itomdipulsar-bookkeeper-journal-itomdipulsar-bookkeeper-1 bound local-pv-bc38d41a 97gi rwo fast-disks <unset> 20h itomdipulsar-bookk",
    "keywordsLower": [
      "uninstall",
      "local",
      "storage",
      "provisioner",
      "part",
      "process",
      "clear",
      "optic",
      "dl",
      "message",
      "bus",
      "residual",
      "files",
      "all",
      "cluster",
      "nodes",
      "application",
      "namespace",
      "deployed.",
      "run",
      "following",
      "command",
      "helm",
      "-n",
      "core",
      "name",
      "deployed",
      "provisioner.",
      "example",
      "lpv",
      "commands",
      "delete",
      "pvcs",
      "kubectl",
      "get",
      "pvc",
      "grep",
      "fast-disks",
      "op",
      "fast-disk",
      "itomdipulsar-bookkeeper-journal-itomdipulsar-bookkeeper-0",
      "bound",
      "local-pv-1bb7a569",
      "97gi",
      "rwo",
      "20h",
      "itomdipulsar-bookkeeper-journal-itomdipulsar-bookkeeper-1",
      "local-pv-bc38d41a",
      "itomdipulsar-bookkeeper-journal-itomdipulsar-bookkeeper-2",
      "local-pv-8b574552",
      "itomdipulsar-bookkeeper-ledgers-itomdipulsar-bookkeeper-0",
      "local-pv-f43d600f",
      "itomdipulsar-bookkeeper-ledgers-itomdipulsar-bookkeeper-1",
      "local-pv-1d258401",
      "itomdipulsar-bookkeeper-ledgers-itomdipulsar-bookkeeper-2",
      "local-pv-1d7c2f09",
      "itomdipulsar-zookeeper-zookeeper-data-itomdipulsar-zookeeper-0",
      "local-pv-ce021750",
      "itomdipulsar-zookeeper-zookeeper-data-itomdipulsar-zookeeper-1",
      "local-pv-9b21fdb3",
      "itomdipulsar-zookeeper-zookeeper-data-itomdipulsar-zookeeper-2",
      "local-pv-80b73c9a",
      "pv",
      "local-pv-5b1599ea",
      "local-pv-6b090b1b",
      "local-pv-8199a5b1",
      "local-pv-a019bb9c",
      "local-pv-a306c635",
      "local-pv-c61e642",
      "local-pv-e644ca",
      "local-pv-f03deeb",
      "local-pv-faf9cc75",
      "go",
      "location",
      "volumes",
      "mounted",
      "default",
      "mnt",
      "disks",
      "virtual",
      "disk",
      "unmount",
      "directories",
      "mount",
      "path",
      "directory.",
      "perform",
      "worker",
      "nodes.",
      "cd",
      "lpv1",
      "lpv2",
      "lpv3",
      "rm",
      "-rf",
      "done"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Uninstall",
    "content": "This topic provides instructions to uninstall OMT and the suite in your deployment. For instructions to uninstall OMT, see the following topics. Refer to the topic relevant to your deployment: Uninstall OMT on embedded Kubernetes. Uninstall OMT on managed Kubernetes. For instructions to uninstall the suite, see the following topics. Refer to the topic relevant to your deployment. Uninstall the suite on embedded Kubernetes Uninstall the suite on AWS Uninstall the suite on Azure Uninstall the suite on GCP Uninstall the suite on OpenShift",
    "url": "uninstall",
    "filename": "uninstall",
    "headings": [],
    "keywords": [
      "uninstall",
      "topic",
      "provides",
      "instructions",
      "omt",
      "suite",
      "deployment.",
      "see",
      "following",
      "topics.",
      "refer",
      "relevant",
      "deployment",
      "embedded",
      "kubernetes.",
      "managed",
      "kubernetes",
      "aws",
      "azure",
      "gcp",
      "openshift"
    ],
    "language": "en",
    "word_count": 52,
    "importance_score": 2.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "uninstall",
    "contentLower": "this topic provides instructions to uninstall omt and the suite in your deployment. for instructions to uninstall omt, see the following topics. refer to the topic relevant to your deployment: uninstall omt on embedded kubernetes. uninstall omt on managed kubernetes. for instructions to uninstall the suite, see the following topics. refer to the topic relevant to your deployment. uninstall the suite on embedded kubernetes uninstall the suite on aws uninstall the suite on azure uninstall the suite on gcp uninstall the suite on openshift",
    "keywordsLower": [
      "uninstall",
      "topic",
      "provides",
      "instructions",
      "omt",
      "suite",
      "deployment.",
      "see",
      "following",
      "topics.",
      "refer",
      "relevant",
      "deployment",
      "embedded",
      "kubernetes.",
      "managed",
      "kubernetes",
      "aws",
      "azure",
      "gcp",
      "openshift"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Uninstall the suite on embedded Kubernetes",
    "content": "Follow the instructions below if you need to uninstall the suite on the embedded Kubernetes. If you have OMT installed, see Uninstall OMT (embedded K8s) for instructions on how to uninstall OMT. Uninstall Kubernetes configurations For details, see Uninstall Kubernetes configurations. Clean up the suite databases For details, see Clean up the suite databases. Clean up NFS folders Empty the NFS folders under the base directory. rm -rf <base directory>/* Note that if your base directory has subfolders used for other applications, you may need to remove those for the suite one by one, instead of using the command above.",
    "url": "uninstallcdfandsuite",
    "filename": "uninstallcdfandsuite",
    "headings": [
      "Uninstall Kubernetes configurations",
      "Clean up the suite databases",
      "Clean up NFS folders"
    ],
    "keywords": [
      "uninstall",
      "suite",
      "embedded",
      "kubernetes",
      "configurations",
      "clean",
      "databases",
      "nfs",
      "folders",
      "follow",
      "instructions",
      "below",
      "need",
      "kubernetes.",
      "omt",
      "installed",
      "see",
      "k8s",
      "omt.",
      "details",
      "configurations.",
      "databases.",
      "empty",
      "under",
      "base",
      "directory.",
      "rm",
      "-rf",
      "note",
      "directory",
      "subfolders",
      "applications",
      "remove",
      "one",
      "instead",
      "command",
      "above."
    ],
    "language": "en",
    "word_count": 62,
    "importance_score": 3.5,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "uninstall the suite on embedded kubernetes",
    "contentLower": "follow the instructions below if you need to uninstall the suite on the embedded kubernetes. if you have omt installed, see uninstall omt (embedded k8s) for instructions on how to uninstall omt. uninstall kubernetes configurations for details, see uninstall kubernetes configurations. clean up the suite databases for details, see clean up the suite databases. clean up nfs folders empty the nfs folders under the base directory. rm -rf <base directory>/* note that if your base directory has subfolders used for other applications, you may need to remove those for the suite one by one, instead of using the command above.",
    "keywordsLower": [
      "uninstall",
      "suite",
      "embedded",
      "kubernetes",
      "configurations",
      "clean",
      "databases",
      "nfs",
      "folders",
      "follow",
      "instructions",
      "below",
      "need",
      "kubernetes.",
      "omt",
      "installed",
      "see",
      "k8s",
      "omt.",
      "details",
      "configurations.",
      "databases.",
      "empty",
      "under",
      "base",
      "directory.",
      "rm",
      "-rf",
      "note",
      "directory",
      "subfolders",
      "applications",
      "remove",
      "one",
      "instead",
      "command",
      "above."
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Uninstall the suite on AWS with EKS",
    "content": "This topic provides instructions to uninstall the Suite on EKS. If you have OMT installed, see Uninstall OMT (external K8s) for instructions to uninstall OMT. Uninstall Kubernetes configurations For details on uninstalling kubernetes configurations, see Uninstall Kubernetes configurations. Clean up the suite volumes The following section provides instructions to clean up the storage volumes for static and dynamic provisioning. Follow the cleanup instructions that is relevant to the type of storage volumes used in your deployment. Complete the following steps to clean up static volumes Copy the following script and save it to cleanSMANFS.sh file on the bastion node: #!/bin/bash shopt -s extglob # Edit as needed MOUNT_POINT=\"/mnt/efs\" NFS_PARENT=\"var/vols/itom/itsma\" rm -rf ${MOUNT_POINT}/${NFS_PARENT}/*/* ls -l ${MOUNT_POINT}/${NFS_PARENT}/*/ Run the following commands to clean up SMA data in the NFS storage: chmod 755 cleanSMANFS.sh sudo ./cleanSMANFS.sh Complete the following steps to",
    "url": "eksuninstall",
    "filename": "eksuninstall",
    "headings": [
      "Uninstall Kubernetes configurations",
      "Clean up the suite volumes",
      "Clean up the Suite databases"
    ],
    "keywords": [
      "cleanSMANFS.sh",
      "uninstall",
      "suite",
      "aws",
      "eks",
      "kubernetes",
      "configurations",
      "clean",
      "volumes",
      "databases",
      "topic",
      "provides",
      "instructions",
      "eks.",
      "omt",
      "installed",
      "see",
      "external",
      "k8s",
      "omt.",
      "details",
      "uninstalling",
      "configurations.",
      "following",
      "section",
      "storage",
      "static",
      "dynamic",
      "provisioning.",
      "follow",
      "cleanup",
      "relevant",
      "type",
      "deployment.",
      "complete",
      "steps",
      "copy",
      "script",
      "save",
      "file",
      "bastion",
      "node",
      "bin",
      "bash",
      "shopt",
      "-s",
      "extglob",
      "edit",
      "needed",
      "mnt",
      "efs",
      "var",
      "vols",
      "itom",
      "itsma",
      "rm",
      "-rf",
      "ls",
      "-l",
      "run",
      "commands",
      "sma",
      "data",
      "nfs",
      "chmod",
      "755",
      "sudo",
      "volume",
      "folders",
      "esm",
      "itsma-xxx",
      "cleaning",
      "databases.",
      "fail",
      "delete",
      "owned",
      "below",
      "command",
      "postgres",
      "user",
      "grant",
      "user."
    ],
    "language": "en",
    "word_count": 105,
    "importance_score": 3.5,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "uninstall the suite on aws with eks",
    "contentLower": "this topic provides instructions to uninstall the suite on eks. if you have omt installed, see uninstall omt (external k8s) for instructions to uninstall omt. uninstall kubernetes configurations for details on uninstalling kubernetes configurations, see uninstall kubernetes configurations. clean up the suite volumes the following section provides instructions to clean up the storage volumes for static and dynamic provisioning. follow the cleanup instructions that is relevant to the type of storage volumes used in your deployment. complete the following steps to clean up static volumes copy the following script and save it to cleansmanfs.sh file on the bastion node: #!/bin/bash shopt -s extglob # edit as needed mount_point=\"/mnt/efs\" nfs_parent=\"var/vols/itom/itsma\" rm -rf ${mount_point}/${nfs_parent}/*/* ls -l ${mount_point}/${nfs_parent}/*/ run the following commands to clean up sma data in the nfs storage: chmod 755 cleansmanfs.sh sudo ./cleansmanfs.sh complete the following steps to",
    "keywordsLower": [
      "cleansmanfs.sh",
      "uninstall",
      "suite",
      "aws",
      "eks",
      "kubernetes",
      "configurations",
      "clean",
      "volumes",
      "databases",
      "topic",
      "provides",
      "instructions",
      "eks.",
      "omt",
      "installed",
      "see",
      "external",
      "k8s",
      "omt.",
      "details",
      "uninstalling",
      "configurations.",
      "following",
      "section",
      "storage",
      "static",
      "dynamic",
      "provisioning.",
      "follow",
      "cleanup",
      "relevant",
      "type",
      "deployment.",
      "complete",
      "steps",
      "copy",
      "script",
      "save",
      "file",
      "bastion",
      "node",
      "bin",
      "bash",
      "shopt",
      "-s",
      "extglob",
      "edit",
      "needed",
      "mnt",
      "efs",
      "var",
      "vols",
      "itom",
      "itsma",
      "rm",
      "-rf",
      "ls",
      "-l",
      "run",
      "commands",
      "sma",
      "data",
      "nfs",
      "chmod",
      "755",
      "sudo",
      "volume",
      "folders",
      "esm",
      "itsma-xxx",
      "cleaning",
      "databases.",
      "fail",
      "delete",
      "owned",
      "below",
      "command",
      "postgres",
      "user",
      "grant",
      "user."
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Uninstall the suite on Azure",
    "content": "Follow the instructions below if you need to uninstall the suite on AKS. If you have OMT installed, see Uninstall OMT (external K8s) for instructions on how to uninstall OMT. Uninstall Kubernetes configurations For details, see Uninstall Kubernetes configurations. Clean up the suite NFS volumes Note: Before you proceed, make sure that the NFS volumes are mounted to the bastion node. (For static storage only) Create cleanSMANFS.sh If you use static storage, copy and save the following script as cleanSMANFS.sh on the bastion node: #!/bin/bash shopt -s extglob # Edit as needed MOUNT_POINT=\"/mnt/nfs\" NFS_PARENT=\"$1/var/vols/itom/itsma\" rm -rf ${MOUNT_POINT}/${NFS_PARENT}/*/* ls -l ${MOUNT_POINT}/${NFS_PARENT}/*/ Clean up the suite data Choose one of the following options to clean up the suite data according to your storage service. If using Azure Files Clean up the storage volumes according to whether you're using static or dynamic storage volumes. To clean up static volumes Run the follow",
    "url": "aksuninstall",
    "filename": "aksuninstall",
    "headings": [
      "Uninstall Kubernetes configurations",
      "Clean up the suite NFS volumes",
      "(For static storage only) Create cleanSMANFS.sh",
      "Clean up the suite data",
      "If using Azure Files",
      "If using Azure Disks",
      "If using Azure NetApp Files",
      "Clean up the suite databases"
    ],
    "keywords": [
      "cleanSMANFS.sh",
      "uninstall",
      "suite",
      "azure",
      "kubernetes",
      "configurations",
      "clean",
      "nfs",
      "volumes",
      "static",
      "storage",
      "create",
      "data",
      "files",
      "disks",
      "netapp",
      "databases",
      "follow",
      "instructions",
      "below",
      "need",
      "aks.",
      "omt",
      "installed",
      "see",
      "external",
      "k8s",
      "omt.",
      "details",
      "configurations.",
      "note",
      "before",
      "proceed",
      "make",
      "sure",
      "mounted",
      "bastion",
      "node.",
      "copy",
      "save",
      "following",
      "script",
      "node",
      "bin",
      "bash",
      "shopt",
      "-s",
      "extglob",
      "edit",
      "needed",
      "mnt",
      "var",
      "vols",
      "itom",
      "itsma",
      "rm",
      "-rf",
      "ls",
      "-l",
      "choose",
      "one",
      "options",
      "according",
      "service.",
      "whether",
      "re",
      "dynamic",
      "volumes.",
      "run",
      "commands",
      "chmod",
      "755",
      "sudo",
      "name",
      "file",
      "shares",
      "storing",
      "generic",
      "data.",
      "find",
      "navigating",
      "portal",
      "accounts",
      "account",
      "share",
      "name.",
      "manually",
      "delete",
      "log",
      "accounts.",
      "locate",
      "created",
      "esm.",
      "esm-pvc-xxx-xx-xxx-xxxx",
      "format.",
      "disks.",
      "search",
      "all",
      "under",
      "cluster"
    ],
    "language": "en",
    "word_count": 109,
    "importance_score": 6.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "uninstall the suite on azure",
    "contentLower": "follow the instructions below if you need to uninstall the suite on aks. if you have omt installed, see uninstall omt (external k8s) for instructions on how to uninstall omt. uninstall kubernetes configurations for details, see uninstall kubernetes configurations. clean up the suite nfs volumes note: before you proceed, make sure that the nfs volumes are mounted to the bastion node. (for static storage only) create cleansmanfs.sh if you use static storage, copy and save the following script as cleansmanfs.sh on the bastion node: #!/bin/bash shopt -s extglob # edit as needed mount_point=\"/mnt/nfs\" nfs_parent=\"$1/var/vols/itom/itsma\" rm -rf ${mount_point}/${nfs_parent}/*/* ls -l ${mount_point}/${nfs_parent}/*/ clean up the suite data choose one of the following options to clean up the suite data according to your storage service. if using azure files clean up the storage volumes according to whether you're using static or dynamic storage volumes. to clean up static volumes run the follow",
    "keywordsLower": [
      "cleansmanfs.sh",
      "uninstall",
      "suite",
      "azure",
      "kubernetes",
      "configurations",
      "clean",
      "nfs",
      "volumes",
      "static",
      "storage",
      "create",
      "data",
      "files",
      "disks",
      "netapp",
      "databases",
      "follow",
      "instructions",
      "below",
      "need",
      "aks.",
      "omt",
      "installed",
      "see",
      "external",
      "k8s",
      "omt.",
      "details",
      "configurations.",
      "note",
      "before",
      "proceed",
      "make",
      "sure",
      "mounted",
      "bastion",
      "node.",
      "copy",
      "save",
      "following",
      "script",
      "node",
      "bin",
      "bash",
      "shopt",
      "-s",
      "extglob",
      "edit",
      "needed",
      "mnt",
      "var",
      "vols",
      "itom",
      "itsma",
      "rm",
      "-rf",
      "ls",
      "-l",
      "choose",
      "one",
      "options",
      "according",
      "service.",
      "whether",
      "re",
      "dynamic",
      "volumes.",
      "run",
      "commands",
      "chmod",
      "755",
      "sudo",
      "name",
      "file",
      "shares",
      "storing",
      "generic",
      "data.",
      "find",
      "navigating",
      "portal",
      "accounts",
      "account",
      "share",
      "name.",
      "manually",
      "delete",
      "log",
      "accounts.",
      "locate",
      "created",
      "esm.",
      "esm-pvc-xxx-xx-xxx-xxxx",
      "format.",
      "disks.",
      "search",
      "all",
      "under",
      "cluster"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Uninstall the suite on GCP",
    "content": "This topic explains how to remove the external Kubernetes (K8s) configurations and uninstall the suite on GCP. RoleLocationSuite administratorBastion nodeUninstall OMTSkip this section if you have not installed OMT for external K8s in your GCP environment. To uninstall OMT from your GCP environment, see  Uninstall OMT (external K8s).Remove K8s configurationsRemove external K8s configuraiton for your suite. For details, see Uninstall Kubernetes configurations in How to uninstall suite Kubernetes configurations and databases. Cleanup PVsClean up suite data on persistent volumes (PV). Refer to the instructions relevant to your PV type - Cloud Filestore or Persistent Disk.Cleanup PV on Cloud FilestoreIf you do not use Cloud Filestore for PV provisioning, skip this section.To clean up suite data on Cloud Filestore, you must first make sure make sure that the NFS volumes are mounted to the bastion node.Check mount pointsMake a note of the mount points used for the classic deployment in your ",
    "url": "gcpuninstall",
    "filename": "gcpuninstall",
    "headings": [
      "Uninstall OMT",
      "Remove K8s configurations",
      "Cleanup PVs",
      "Cleanup PV on Cloud Filestore",
      "Cleanup PV on Peristent Disk",
      "Cleanup suite databases"
    ],
    "keywords": [
      "section.To",
      "Filestore.Copy",
      "Disk.Run",
      "8.0E",
      "cleanSMANFS.sh",
      "uninstall",
      "suite",
      "gcp",
      "omt",
      "remove",
      "k8s",
      "configurations",
      "cleanup",
      "pvs",
      "pv",
      "cloud",
      "filestore",
      "peristent",
      "disk",
      "databases",
      "topic",
      "explains",
      "external",
      "kubernetes",
      "gcp.",
      "rolelocationsuite",
      "administratorbastion",
      "nodeuninstall",
      "omtskip",
      "section",
      "installed",
      "environment.",
      "environment",
      "see",
      ".remove",
      "configurationsremove",
      "configuraiton",
      "suite.",
      "details",
      "databases.",
      "pvsclean",
      "data",
      "persistent",
      "volumes",
      "refer",
      "instructions",
      "relevant",
      "type",
      "disk.cleanup",
      "filestoreif",
      "provisioning",
      "skip",
      "clean",
      "first",
      "make",
      "sure",
      "nfs",
      "mounted",
      "bastion",
      "node.check",
      "mount",
      "pointsmake",
      "note",
      "points",
      "classic",
      "deployment",
      "need",
      "later",
      "syncing",
      "helm",
      "deployment.",
      "different",
      "shown",
      "examples",
      "document",
      "update",
      "sample",
      "commands",
      "know",
      "run",
      "command",
      "df-h.",
      "output",
      "lists",
      "all",
      "filesystems",
      "points.",
      "following",
      "azure",
      "uses",
      "netapp",
      "files",
      "storage",
      "generic",
      "smarta",
      "mnt",
      "efs",
      "respectively.",
      "listed",
      "under"
    ],
    "language": "en",
    "word_count": 97,
    "importance_score": 6.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "uninstall the suite on gcp",
    "contentLower": "this topic explains how to remove the external kubernetes (k8s) configurations and uninstall the suite on gcp. rolelocationsuite administratorbastion nodeuninstall omtskip this section if you have not installed omt for external k8s in your gcp environment. to uninstall omt from your gcp environment, see  uninstall omt (external k8s).remove k8s configurationsremove external k8s configuraiton for your suite. for details, see uninstall kubernetes configurations in how to uninstall suite kubernetes configurations and databases. cleanup pvsclean up suite data on persistent volumes (pv). refer to the instructions relevant to your pv type - cloud filestore or persistent disk.cleanup pv on cloud filestoreif you do not use cloud filestore for pv provisioning, skip this section.to clean up suite data on cloud filestore, you must first make sure make sure that the nfs volumes are mounted to the bastion node.check mount pointsmake a note of the mount points used for the classic deployment in your ",
    "keywordsLower": [
      "section.to",
      "filestore.copy",
      "disk.run",
      "8.0e",
      "cleansmanfs.sh",
      "uninstall",
      "suite",
      "gcp",
      "omt",
      "remove",
      "k8s",
      "configurations",
      "cleanup",
      "pvs",
      "pv",
      "cloud",
      "filestore",
      "peristent",
      "disk",
      "databases",
      "topic",
      "explains",
      "external",
      "kubernetes",
      "gcp.",
      "rolelocationsuite",
      "administratorbastion",
      "nodeuninstall",
      "omtskip",
      "section",
      "installed",
      "environment.",
      "environment",
      "see",
      ".remove",
      "configurationsremove",
      "configuraiton",
      "suite.",
      "details",
      "databases.",
      "pvsclean",
      "data",
      "persistent",
      "volumes",
      "refer",
      "instructions",
      "relevant",
      "type",
      "disk.cleanup",
      "filestoreif",
      "provisioning",
      "skip",
      "clean",
      "first",
      "make",
      "sure",
      "nfs",
      "mounted",
      "bastion",
      "node.check",
      "mount",
      "pointsmake",
      "note",
      "points",
      "classic",
      "deployment",
      "need",
      "later",
      "syncing",
      "helm",
      "deployment.",
      "different",
      "shown",
      "examples",
      "document",
      "update",
      "sample",
      "commands",
      "know",
      "run",
      "command",
      "df-h.",
      "output",
      "lists",
      "all",
      "filesystems",
      "points.",
      "following",
      "azure",
      "uses",
      "netapp",
      "files",
      "storage",
      "generic",
      "smarta",
      "mnt",
      "efs",
      "respectively.",
      "listed",
      "under"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Uninstall the suite on OpenShift",
    "content": "Follow the instructions below if you need to uninstall the suite on OpenShift. If you have OMT installed, see Uninstall OMT (external K8s) for instructions on how to uninstall OMT. Uninstall Kubernetes configurations For details, see Uninstall Kubernetes configurations. Clean up the suite databases For details, see Clean up the suite databases. Delete the suite NFS folders Delete the NFS folders under the base directory. rm -rf <base directory>/* Note that if your base directory has subfolders used for other applications, you may need to remove those for the suite one by one, instead of using the command above.",
    "url": "uninstallonopenshift",
    "filename": "uninstallonopenshift",
    "headings": [
      "Uninstall Kubernetes configurations",
      "Clean up the suite databases",
      "Delete the suite NFS folders"
    ],
    "keywords": [
      "uninstall",
      "suite",
      "openshift",
      "kubernetes",
      "configurations",
      "clean",
      "databases",
      "delete",
      "nfs",
      "folders",
      "follow",
      "instructions",
      "below",
      "need",
      "openshift.",
      "omt",
      "installed",
      "see",
      "external",
      "k8s",
      "omt.",
      "details",
      "configurations.",
      "databases.",
      "under",
      "base",
      "directory.",
      "rm",
      "-rf",
      "note",
      "directory",
      "subfolders",
      "applications",
      "remove",
      "one",
      "instead",
      "command",
      "above."
    ],
    "language": "en",
    "word_count": 61,
    "importance_score": 3.5,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "uninstall the suite on openshift",
    "contentLower": "follow the instructions below if you need to uninstall the suite on openshift. if you have omt installed, see uninstall omt (external k8s) for instructions on how to uninstall omt. uninstall kubernetes configurations for details, see uninstall kubernetes configurations. clean up the suite databases for details, see clean up the suite databases. delete the suite nfs folders delete the nfs folders under the base directory. rm -rf <base directory>/* note that if your base directory has subfolders used for other applications, you may need to remove those for the suite one by one, instead of using the command above.",
    "keywordsLower": [
      "uninstall",
      "suite",
      "openshift",
      "kubernetes",
      "configurations",
      "clean",
      "databases",
      "delete",
      "nfs",
      "folders",
      "follow",
      "instructions",
      "below",
      "need",
      "openshift.",
      "omt",
      "installed",
      "see",
      "external",
      "k8s",
      "omt.",
      "details",
      "configurations.",
      "databases.",
      "under",
      "base",
      "directory.",
      "rm",
      "-rf",
      "note",
      "directory",
      "subfolders",
      "applications",
      "remove",
      "one",
      "instead",
      "command",
      "above."
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Upgrade",
    "content": "This section describes how to upgrade your environment to version 26.1. Supported upgrade paths To bring value to customers more frequently, we’ve shortened the product release cycle from half-yearly to quarterly. Meanwhile, we also want to minimize your maintenance window and service interruptions. Therefore, we've adjusted our release and update strategy as follows: Odd version number releases such as, 25.3 typically contain defect fixing and fewer enhancements.  The upgrade process is simpler than the standard version update process, and is comparable to a patch deployment.Even version number releases such as 25.4 provide more features and enhancements and use the standard version update process. The 26.1 release supports the following upgrade paths: Supported upgrade path Upgrade process 25.4 (and patches) → 26.1 Normal version upgrade Version update best practice As a best practice, test the version update process in a test environment before you apply an update in your production",
    "url": "upgrade",
    "filename": "upgrade",
    "headings": [
      "Supported upgrade paths",
      "Version update best practice",
      "Version update process",
      "Backup and restore methods",
      "Upgrade steps"
    ],
    "keywords": [
      "deployment.Even",
      "25.4",
      "26.1",
      "25.3",
      "upgrade",
      "supported",
      "paths",
      "version",
      "update",
      "best",
      "practice",
      "process",
      "backup",
      "restore",
      "methods",
      "steps",
      "section",
      "describes",
      "environment",
      "26.1.",
      "bring",
      "value",
      "customers",
      "frequently",
      "ve",
      "shortened",
      "product",
      "release",
      "cycle",
      "half-yearly",
      "quarterly.",
      "meanwhile",
      "want",
      "minimize",
      "maintenance",
      "window",
      "service",
      "interruptions.",
      "therefore",
      "adjusted",
      "strategy",
      "follows",
      "odd",
      "number",
      "releases",
      "such",
      "typically",
      "contain",
      "defect",
      "fixing",
      "fewer",
      "enhancements.",
      "simpler",
      "standard",
      "comparable",
      "patch",
      "provide",
      "features",
      "enhancements",
      "process.",
      "supports",
      "following",
      "path",
      "patches",
      "normal",
      "test",
      "before",
      "apply",
      "production",
      "environment.",
      "verify",
      "everything",
      "working",
      "expected.",
      "diagram",
      "illustrates",
      "recommended",
      "entire",
      "applying",
      "follows.",
      "already",
      "set",
      "skip",
      "step",
      "existing",
      "additionally",
      "imported",
      "tenants",
      "during",
      "previous",
      "2.",
      "install",
      "suite",
      "import",
      "all",
      "starting",
      "otherwise",
      "reveal",
      "problems",
      "meet"
    ],
    "language": "en",
    "word_count": 102,
    "importance_score": 5.5,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "upgrade",
    "contentLower": "this section describes how to upgrade your environment to version 26.1. supported upgrade paths to bring value to customers more frequently, we’ve shortened the product release cycle from half-yearly to quarterly. meanwhile, we also want to minimize your maintenance window and service interruptions. therefore, we've adjusted our release and update strategy as follows: odd version number releases such as, 25.3 typically contain defect fixing and fewer enhancements.  the upgrade process is simpler than the standard version update process, and is comparable to a patch deployment.even version number releases such as 25.4 provide more features and enhancements and use the standard version update process. the 26.1 release supports the following upgrade paths: supported upgrade path upgrade process 25.4 (and patches) → 26.1 normal version upgrade version update best practice as a best practice, test the version update process in a test environment before you apply an update in your production",
    "keywordsLower": [
      "deployment.even",
      "25.4",
      "26.1",
      "25.3",
      "upgrade",
      "supported",
      "paths",
      "version",
      "update",
      "best",
      "practice",
      "process",
      "backup",
      "restore",
      "methods",
      "steps",
      "section",
      "describes",
      "environment",
      "26.1.",
      "bring",
      "value",
      "customers",
      "frequently",
      "ve",
      "shortened",
      "product",
      "release",
      "cycle",
      "half-yearly",
      "quarterly.",
      "meanwhile",
      "want",
      "minimize",
      "maintenance",
      "window",
      "service",
      "interruptions.",
      "therefore",
      "adjusted",
      "strategy",
      "follows",
      "odd",
      "number",
      "releases",
      "such",
      "typically",
      "contain",
      "defect",
      "fixing",
      "fewer",
      "enhancements.",
      "simpler",
      "standard",
      "comparable",
      "patch",
      "provide",
      "features",
      "enhancements",
      "process.",
      "supports",
      "following",
      "path",
      "patches",
      "normal",
      "test",
      "before",
      "apply",
      "production",
      "environment.",
      "verify",
      "everything",
      "working",
      "expected.",
      "diagram",
      "illustrates",
      "recommended",
      "entire",
      "applying",
      "follows.",
      "already",
      "set",
      "skip",
      "step",
      "existing",
      "additionally",
      "imported",
      "tenants",
      "during",
      "previous",
      "2.",
      "install",
      "suite",
      "import",
      "all",
      "starting",
      "otherwise",
      "reveal",
      "problems",
      "meet"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Upgrade (embedded Kubernetes)",
    "content": "This section provides version update instructions only for deployments using the embedded Kubernetes in OMT (embedded Kubernetes). If you have deployed the suite in a managed Kubernetes environment (on EKS, AKS, GCP, or OpenShift), refer to the Upgrade (managed Kubernetes) section instead. For an overview of the version upgrade process and upgrade best practices, see the Upgrade landing page. Plan suite upgrade Before you start the upgrade process, make sure you have planned for the following dependencies. Check base version dependency Make sure that upgrade is supported for the suite version installed in your environment. For the list of supported upgrade versions, see Supported upgrade paths. Plan OMT upgrade For seamless operations, OMT version must match the suite version. To ensure this, we recommend that you upgrade OMT and the suite in the same maintenance window. If this is not possible, make sure that you complete the suite upgrade within one week after upgrading OMT. Upgrade ",
    "url": "upgradeembeddedk8s",
    "filename": "upgradeembeddedk8s",
    "headings": [
      "Plan suite upgrade",
      "Check base version dependency",
      "Plan OMT upgrade",
      "Upgrade to 26.1"
    ],
    "keywords": [
      "26.1",
      "upgrade.Back",
      "data.Back",
      "upgrade",
      "embedded",
      "kubernetes",
      "plan",
      "suite",
      "check",
      "base",
      "version",
      "dependency",
      "omt",
      "section",
      "provides",
      "update",
      "instructions",
      "deployments",
      "deployed",
      "managed",
      "environment",
      "eks",
      "aks",
      "gcp",
      "openshift",
      "refer",
      "instead.",
      "overview",
      "process",
      "best",
      "practices",
      "see",
      "landing",
      "page.",
      "before",
      "start",
      "make",
      "sure",
      "planned",
      "following",
      "dependencies.",
      "supported",
      "installed",
      "environment.",
      "list",
      "versions",
      "paths.",
      "seamless",
      "operations",
      "match",
      "version.",
      "ensure",
      "recommend",
      "same",
      "maintenance",
      "window.",
      "possible",
      "complete",
      "one",
      "week",
      "after",
      "upgrading",
      "omt.",
      "table",
      "sequence",
      "upgrade.",
      "steps",
      "order.",
      "interchange",
      "order",
      "between",
      "ud",
      "ucmdb",
      "oo",
      "containerized",
      "audit.",
      "step",
      "no.",
      "description",
      "back",
      "details",
      "data.",
      "ucmdb.",
      "udmdb",
      "deployment",
      ".back",
      "containerized.",
      "backup",
      "audit",
      "note",
      "fails",
      "restore",
      "old",
      "suite.",
      "udmdb.",
      "service",
      "collector."
    ],
    "language": "en",
    "word_count": 102,
    "importance_score": 5.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "upgrade (embedded kubernetes)",
    "contentLower": "this section provides version update instructions only for deployments using the embedded kubernetes in omt (embedded kubernetes). if you have deployed the suite in a managed kubernetes environment (on eks, aks, gcp, or openshift), refer to the upgrade (managed kubernetes) section instead. for an overview of the version upgrade process and upgrade best practices, see the upgrade landing page. plan suite upgrade before you start the upgrade process, make sure you have planned for the following dependencies. check base version dependency make sure that upgrade is supported for the suite version installed in your environment. for the list of supported upgrade versions, see supported upgrade paths. plan omt upgrade for seamless operations, omt version must match the suite version. to ensure this, we recommend that you upgrade omt and the suite in the same maintenance window. if this is not possible, make sure that you complete the suite upgrade within one week after upgrading omt. upgrade ",
    "keywordsLower": [
      "26.1",
      "upgrade.back",
      "data.back",
      "upgrade",
      "embedded",
      "kubernetes",
      "plan",
      "suite",
      "check",
      "base",
      "version",
      "dependency",
      "omt",
      "section",
      "provides",
      "update",
      "instructions",
      "deployments",
      "deployed",
      "managed",
      "environment",
      "eks",
      "aks",
      "gcp",
      "openshift",
      "refer",
      "instead.",
      "overview",
      "process",
      "best",
      "practices",
      "see",
      "landing",
      "page.",
      "before",
      "start",
      "make",
      "sure",
      "planned",
      "following",
      "dependencies.",
      "supported",
      "installed",
      "environment.",
      "list",
      "versions",
      "paths.",
      "seamless",
      "operations",
      "match",
      "version.",
      "ensure",
      "recommend",
      "same",
      "maintenance",
      "window.",
      "possible",
      "complete",
      "one",
      "week",
      "after",
      "upgrading",
      "omt.",
      "table",
      "sequence",
      "upgrade.",
      "steps",
      "order.",
      "interchange",
      "order",
      "between",
      "ud",
      "ucmdb",
      "oo",
      "containerized",
      "audit.",
      "step",
      "no.",
      "description",
      "back",
      "details",
      "data.",
      "ucmdb.",
      "udmdb",
      "deployment",
      ".back",
      "containerized.",
      "backup",
      "audit",
      "note",
      "fails",
      "restore",
      "old",
      "suite.",
      "udmdb.",
      "service",
      "collector."
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Upgrade OMT (embedded Kubernetes)",
    "content": "You can upgrade ITOM OPTIC Management Toolkit (OMT) either by using an autoUpgrade script or manually. The autoUpgrade script requires passwordless SSH connections between cluster nodes. If you can't configure passwordless SSH, you can still perform a manual upgrade.  Plan To create an upgrade plan, review the following information.Select an upgrade methodYou can upgrade OMT manually or use the autoUpgrade script to do the upgrade. The autoUpgrade script requires passwordless SSH connections between cluster nodes. If you cannot configure passwordless SSH, you can still perform a manual upgrade.Additionally, you can upgrade OMT in one of the following modes according to your business requirements:Hot upgrade: In this mode, OMT is upgraded with no downtime. This requires you to run a shell script (podReScheduler.sh) before upgrading each worker node to reschedule those singleton pods of deployments or StatefulSets on the worker node to other worker nodes in advance. You can find the podR",
    "url": "upgradecdf",
    "filename": "upgradecdf",
    "headings": [
      "Plan",
      "Select an upgrade method",
      "Select an upgrade point",
      "Required disk space and available memory",
      "Upgrade system requirements",
      "Free up disk space for control plane nodes and worker nodes",
      "Prerequisite tasks",
      "Add one worker node",
      "Check that the hostname has not changed",
      "Confirm the Subject Alternative Name certificate contains the hostname",
      "Make sure you have backed up data",
      "Download, unzip, and verify the upgrade package",
      "Disable on-access security scans",
      "Upload the images if you use an external registry",
      "Use sudo to enable a regular user to upgrade OMT on the embedded K8s",
      "Configure SSH connections",
      "Make sure that all control plane nodes and worker nodes are running",
      "Clean up unused images",
      "Upgrade procedure",
      "Upgrade OMT by using the autoUpgrade script"
    ],
    "keywords": [
      "restart.sh",
      "directory.You",
      "23.4",
      "12.34.56.78",
      "now.The",
      "directory.Make",
      "sequence.When",
      "unavailable.The",
      "sudo.For",
      "192.168.0.2",
      "192.168",
      "192.0.2.0",
      "2021.11",
      "192.100.0",
      "directory.For",
      "script.When",
      "0.1If",
      "directory.If",
      "packages.The",
      "2022.05",
      "Marketplace.Non",
      "security.To",
      "upgrade.Copy",
      "empty.Don",
      "id_rsa.pub",
      "mismatch.To",
      "https://image-registry.com.Replace",
      "podReScheduler.sh",
      "data.If",
      "env.sh",
      "same.We",
      "script.If",
      "nodes.To",
      "status.sh",
      "sequentially.To",
      "images.tgz",
      "again.The",
      "subdirectories.The",
      "node.Run",
      "upgradeLog.If",
      "completed.Use",
      "user.Run",
      "methods.Auto",
      "registry.com",
      "12.34.56",
      "option.To",
      "192.100.0.1",
      "192.100",
      "24.4",
      "below.The",
      "optional.To",
      "node.To",
      "uploadimages.sh",
      "successfully.When",
      "mycompany.net",
      "192.100.0.3",
      "fail.On",
      "xxx-15001",
      "name.Use",
      "192.168.0",
      "sign.pub",
      "192.0.2",
      "machine.You",
      "http://image-registry.com",
      "node.For",
      "package.If",
      "exist.Run",
      "cluster.If",
      "upgradeLog.To",
      "environment.This",
      "zip.sig",
      "zip.Run",
      "12.34",
      "claimRef.name",
      "scripts.The",
      "node.Non",
      "sequence.Run",
      "https://<External",
      "upgrade.sh",
      "images.For",
      "K8s.zip",
      "2022.11",
      "56.78",
      "192.168.0.3",
      "upgrade.Run",
      "upgrade",
      "omt",
      "embedded",
      "kubernetes",
      "plan",
      "select",
      "method",
      "point",
      "required",
      "disk",
      "space",
      "available",
      "memory",
      "system",
      "requirements"
    ],
    "language": "en",
    "word_count": 98,
    "importance_score": 6.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "upgrade omt (embedded kubernetes)",
    "contentLower": "you can upgrade itom optic management toolkit (omt) either by using an autoupgrade script or manually. the autoupgrade script requires passwordless ssh connections between cluster nodes. if you can't configure passwordless ssh, you can still perform a manual upgrade.  plan to create an upgrade plan, review the following information.select an upgrade methodyou can upgrade omt manually or use the autoupgrade script to do the upgrade. the autoupgrade script requires passwordless ssh connections between cluster nodes. if you cannot configure passwordless ssh, you can still perform a manual upgrade.additionally, you can upgrade omt in one of the following modes according to your business requirements:hot upgrade: in this mode, omt is upgraded with no downtime. this requires you to run a shell script (podrescheduler.sh) before upgrading each worker node to reschedule those singleton pods of deployments or statefulsets on the worker node to other worker nodes in advance. you can find the podr",
    "keywordsLower": [
      "restart.sh",
      "directory.you",
      "23.4",
      "12.34.56.78",
      "now.the",
      "directory.make",
      "sequence.when",
      "unavailable.the",
      "sudo.for",
      "192.168.0.2",
      "192.168",
      "192.0.2.0",
      "2021.11",
      "192.100.0",
      "directory.for",
      "script.when",
      "0.1if",
      "directory.if",
      "packages.the",
      "2022.05",
      "marketplace.non",
      "security.to",
      "upgrade.copy",
      "empty.don",
      "id_rsa.pub",
      "mismatch.to",
      "https://image-registry.com.replace",
      "podrescheduler.sh",
      "data.if",
      "env.sh",
      "same.we",
      "script.if",
      "nodes.to",
      "status.sh",
      "sequentially.to",
      "images.tgz",
      "again.the",
      "subdirectories.the",
      "node.run",
      "upgradelog.if",
      "completed.use",
      "user.run",
      "methods.auto",
      "registry.com",
      "12.34.56",
      "option.to",
      "192.100.0.1",
      "192.100",
      "24.4",
      "below.the",
      "optional.to",
      "node.to",
      "uploadimages.sh",
      "successfully.when",
      "mycompany.net",
      "192.100.0.3",
      "fail.on",
      "xxx-15001",
      "name.use",
      "192.168.0",
      "sign.pub",
      "192.0.2",
      "machine.you",
      "http://image-registry.com",
      "node.for",
      "package.if",
      "exist.run",
      "cluster.if",
      "upgradelog.to",
      "environment.this",
      "zip.sig",
      "zip.run",
      "12.34",
      "claimref.name",
      "scripts.the",
      "node.non",
      "sequence.run",
      "https://<external",
      "upgrade.sh",
      "images.for",
      "k8s.zip",
      "2022.11",
      "56.78",
      "192.168.0.3",
      "upgrade.run",
      "upgrade",
      "omt",
      "embedded",
      "kubernetes",
      "plan",
      "select",
      "method",
      "point",
      "required",
      "disk",
      "space",
      "available",
      "memory",
      "system",
      "requirements"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Upgrade the Suite",
    "content": "This topic describes how to upgrade the Suite. Follow these instructions to prepare your environment, run the required Helm commands, and verify that the upgrade completes successfully.The instructions in this topic apply to all supported Kubernetes environments - embedded Kubernetes provided by OMT or  managed Kubernetes from your cloud provider.PrepareFollow these steps to prepare for the upgrade:Extract the downloaded package, like ESM_Helm_Chart-2x.x.x.zip.Run the following command to unzip the downloaded package: unzip ESM_Helm_Chart-2x.x.x.zip -d ESM_Helm_Chart-2x.x.x The unzipped file contains the following files: esm-2.x.x+2x.x.x.zip: Contains the upgrade package.esm-2.x.x+2x.x.x.zip.sig: The signature file required to verify the package.(Optional) Verify the ESM helm package. Skip this step if you don't want to verify the package. Download the RS_public_keys.tar.gz package from KM000003948 and extract it.Go to the MF_public_keys-Updated folder in the extracted package and loca",
    "url": "upgradesuitehelm",
    "filename": "upgradesuitehelm",
    "headings": [
      "Prepare",
      "Perform pre-update tasks",
      "Check the previous upgrade status",
      "Check the system status",
      "Check the pod readiness",
      "Check the cluster worker node resource usage",
      "Check the database status",
      "Validate the content (tenant data)",
      "Check certificate validity across services",
      "Scale down the Support Assistant",
      "Check and fix the Smart Analytics content group scaling",
      "Check if content pods needs scaling",
      "Check if smarta-saw-dah StatefulSet needs scaling",
      "Scale the content pods and smarta-saw-dah StatefulSet",
      "[AKS only] Configure TLS for Suite ingress",
      "Upgrade",
      "Upgrade using CLI",
      "Upgrade using AppHub",
      "Verify upgrade",
      "Perform post-upgrade tasks"
    ],
    "keywords": [
      "rpm.Run",
      "sign.pub",
      "directory.Run",
      "output.cat",
      "https://<EXTERNAL_ACCESS_HOST>/bo.Perform",
      "x.tgz",
      "precheck.If",
      "beforehand.For",
      "package.esm",
      "complete.For",
      "replicas.yaml",
      "securityContext.user",
      "25.3",
      "precheck.log",
      "values.yaml",
      "needed.Copy",
      "checkPG.sh",
      "kubernetes.io",
      "spec.tls",
      "warning.Go",
      "successfully.The",
      "25.4",
      "RS_public_keys.tar",
      "aligned.Get",
      "plane.Run",
      "images.For",
      "26.1",
      "node.Run",
      "OK.You",
      "x.zip",
      "checkContent.sh",
      "it.Go",
      "SAVE.Once",
      "metadata.name",
      "example.test",
      "upgrade",
      "suite",
      "prepare",
      "perform",
      "pre-update",
      "tasks",
      "check",
      "previous",
      "status",
      "system",
      "pod",
      "readiness",
      "cluster",
      "worker",
      "node",
      "resource",
      "usage",
      "database",
      "validate",
      "content",
      "tenant",
      "data",
      "certificate",
      "validity",
      "across",
      "services",
      "scale",
      "support",
      "assistant",
      "fix",
      "smart",
      "analytics",
      "group",
      "scaling",
      "pods",
      "needs",
      "smarta-saw-dah",
      "statefulset",
      "aks",
      "configure",
      "tls",
      "ingress",
      "cli",
      "apphub",
      "verify",
      "post-upgrade",
      "topic",
      "describes",
      "suite.",
      "follow",
      "instructions",
      "environment",
      "run",
      "required",
      "helm",
      "commands",
      "completes",
      "apply",
      "all",
      "supported",
      "kubernetes",
      "environments",
      "embedded",
      "provided",
      "omt"
    ],
    "language": "en",
    "word_count": 89,
    "importance_score": 6.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "upgrade the suite",
    "contentLower": "this topic describes how to upgrade the suite. follow these instructions to prepare your environment, run the required helm commands, and verify that the upgrade completes successfully.the instructions in this topic apply to all supported kubernetes environments - embedded kubernetes provided by omt or  managed kubernetes from your cloud provider.preparefollow these steps to prepare for the upgrade:extract the downloaded package, like esm_helm_chart-2x.x.x.zip.run the following command to unzip the downloaded package: unzip esm_helm_chart-2x.x.x.zip -d esm_helm_chart-2x.x.x the unzipped file contains the following files: esm-2.x.x+2x.x.x.zip: contains the upgrade package.esm-2.x.x+2x.x.x.zip.sig: the signature file required to verify the package.(optional) verify the esm helm package. skip this step if you don't want to verify the package. download the rs_public_keys.tar.gz package from km000003948 and extract it.go to the mf_public_keys-updated folder in the extracted package and loca",
    "keywordsLower": [
      "rpm.run",
      "sign.pub",
      "directory.run",
      "output.cat",
      "https://<external_access_host>/bo.perform",
      "x.tgz",
      "precheck.if",
      "beforehand.for",
      "package.esm",
      "complete.for",
      "replicas.yaml",
      "securitycontext.user",
      "25.3",
      "precheck.log",
      "values.yaml",
      "needed.copy",
      "checkpg.sh",
      "kubernetes.io",
      "spec.tls",
      "warning.go",
      "successfully.the",
      "25.4",
      "rs_public_keys.tar",
      "aligned.get",
      "plane.run",
      "images.for",
      "26.1",
      "node.run",
      "ok.you",
      "x.zip",
      "checkcontent.sh",
      "it.go",
      "save.once",
      "metadata.name",
      "example.test",
      "upgrade",
      "suite",
      "prepare",
      "perform",
      "pre-update",
      "tasks",
      "check",
      "previous",
      "status",
      "system",
      "pod",
      "readiness",
      "cluster",
      "worker",
      "node",
      "resource",
      "usage",
      "database",
      "validate",
      "content",
      "tenant",
      "data",
      "certificate",
      "validity",
      "across",
      "services",
      "scale",
      "support",
      "assistant",
      "fix",
      "smart",
      "analytics",
      "group",
      "scaling",
      "pods",
      "needs",
      "smarta-saw-dah",
      "statefulset",
      "aks",
      "configure",
      "tls",
      "ingress",
      "cli",
      "apphub",
      "verify",
      "post-upgrade",
      "topic",
      "describes",
      "suite.",
      "follow",
      "instructions",
      "environment",
      "run",
      "required",
      "helm",
      "commands",
      "completes",
      "apply",
      "all",
      "supported",
      "kubernetes",
      "environments",
      "embedded",
      "provided",
      "omt"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Upgrade OO Containerized on-premises using embedded Kubernetes",
    "content": "This section includes topics with information to upgrade OO Containerized that uses embedded Kubernetes on-premises: Back up the OO Containerized deployment on premises before upgrade Upgrade OO Containerized on-premises Restore OO Containerized on-premises",
    "url": "upgradecontainerizedoo",
    "filename": "upgradecontainerizedoo",
    "headings": [],
    "keywords": [
      "upgrade",
      "oo",
      "containerized",
      "on-premises",
      "embedded",
      "kubernetes",
      "section",
      "includes",
      "topics",
      "information",
      "uses",
      "back",
      "deployment",
      "premises",
      "before",
      "restore"
    ],
    "language": "en",
    "word_count": 32,
    "importance_score": 1.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "upgrade oo containerized on-premises using embedded kubernetes",
    "contentLower": "this section includes topics with information to upgrade oo containerized that uses embedded kubernetes on-premises: back up the oo containerized deployment on premises before upgrade upgrade oo containerized on-premises restore oo containerized on-premises",
    "keywordsLower": [
      "upgrade",
      "oo",
      "containerized",
      "on-premises",
      "embedded",
      "kubernetes",
      "section",
      "includes",
      "topics",
      "information",
      "uses",
      "back",
      "deployment",
      "premises",
      "before",
      "restore"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Upgrade OO Containerized on-premises",
    "content": "This topic outlines steps to upgrade OO Containerized on-premises using embedded Kubernetes from 25.1 to 25.2. The upgrade process may take 20-30 minutes based on the number of tenants, which may impact flow execution. Perform the following tasks to upgrade OO Containerized deployment. Download the new charts package You must download the tar file from the Software Licenses and Downloads website to a control plane node. Do the following: Download the oo-helm-charts-1.x.x+26.x.x.zip file from the Software Licenses and Downloads (SLD) website. Copy the file to a temporary directory on a control plane node. Unzip the package: cd /path/to/oo_package_zip unzip oo-helm-charts-1.x.x+26.x.x.zip The following table describes the essential files inside the OO Containerized chart package: Name File OO Helm chart file oo-helm-charts-1.x.x+26.x.x/oo-helm-charts/charts/oo-1.x.x+26.x.x.tgz Example Persistent Volume (PV) and Persistent Volume Claims (PVC) yaml files PV templates: oo-helm-charts-1.x.x+",
    "url": "399-upgradeooembeddedk8s",
    "filename": "399-upgradeooembeddedk8s",
    "headings": [
      "Download the new charts package",
      "Download and upload new OO images",
      "Get values.yaml file and update",
      "Upgrade OO Containerized",
      "Related topic"
    ],
    "keywords": [
      "previous_deployment_values.yaml",
      "4.6.1",
      "claims.yaml",
      "25.1",
      "25.2",
      "database.user",
      "volumes.yaml",
      "x.zip",
      "https://<EXTERNAL_ACCESS_HOST>:<EXTERNAL_ACCESS_PORT>/oo",
      "x.tgz",
      "values.yaml",
      "upgrade",
      "oo",
      "containerized",
      "on-premises",
      "download",
      "new",
      "charts",
      "package",
      "upload",
      "images",
      "get",
      "file",
      "update",
      "related",
      "topic",
      "outlines",
      "steps",
      "embedded",
      "kubernetes",
      "25.2.",
      "process",
      "take",
      "20-30",
      "minutes",
      "based",
      "number",
      "tenants",
      "impact",
      "flow",
      "execution.",
      "perform",
      "following",
      "tasks",
      "deployment.",
      "tar",
      "software",
      "licenses",
      "downloads",
      "website",
      "control",
      "plane",
      "node.",
      "oo-helm-charts-1.x.x",
      "26.x.x.zip",
      "sld",
      "website.",
      "copy",
      "temporary",
      "directory",
      "unzip",
      "cd",
      "path",
      "table",
      "describes",
      "essential",
      "files",
      "inside",
      "chart",
      "name",
      "helm",
      "26.x.x",
      "oo-helm-charts",
      "oo-1.x.x",
      "26.x.x.tgz",
      "example",
      "persistent",
      "volume",
      "pv",
      "claims",
      "pvc",
      "yaml",
      "templates",
      "samples",
      "readme",
      "details",
      "see",
      "container",
      "images.",
      "commands",
      "command",
      "line",
      "tool",
      "yq",
      "part",
      "optic",
      "management",
      "toolkit",
      "omt",
      "available"
    ],
    "language": "en",
    "word_count": 107,
    "importance_score": 5.5,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "upgrade oo containerized on-premises",
    "contentLower": "this topic outlines steps to upgrade oo containerized on-premises using embedded kubernetes from 25.1 to 25.2. the upgrade process may take 20-30 minutes based on the number of tenants, which may impact flow execution. perform the following tasks to upgrade oo containerized deployment. download the new charts package you must download the tar file from the software licenses and downloads website to a control plane node. do the following: download the oo-helm-charts-1.x.x+26.x.x.zip file from the software licenses and downloads (sld) website. copy the file to a temporary directory on a control plane node. unzip the package: cd /path/to/oo_package_zip unzip oo-helm-charts-1.x.x+26.x.x.zip the following table describes the essential files inside the oo containerized chart package: name file oo helm chart file oo-helm-charts-1.x.x+26.x.x/oo-helm-charts/charts/oo-1.x.x+26.x.x.tgz example persistent volume (pv) and persistent volume claims (pvc) yaml files pv templates: oo-helm-charts-1.x.x+",
    "keywordsLower": [
      "previous_deployment_values.yaml",
      "4.6.1",
      "claims.yaml",
      "25.1",
      "25.2",
      "database.user",
      "volumes.yaml",
      "x.zip",
      "https://<external_access_host>:<external_access_port>/oo",
      "x.tgz",
      "values.yaml",
      "upgrade",
      "oo",
      "containerized",
      "on-premises",
      "download",
      "new",
      "charts",
      "package",
      "upload",
      "images",
      "get",
      "file",
      "update",
      "related",
      "topic",
      "outlines",
      "steps",
      "embedded",
      "kubernetes",
      "25.2.",
      "process",
      "take",
      "20-30",
      "minutes",
      "based",
      "number",
      "tenants",
      "impact",
      "flow",
      "execution.",
      "perform",
      "following",
      "tasks",
      "deployment.",
      "tar",
      "software",
      "licenses",
      "downloads",
      "website",
      "control",
      "plane",
      "node.",
      "oo-helm-charts-1.x.x",
      "26.x.x.zip",
      "sld",
      "website.",
      "copy",
      "temporary",
      "directory",
      "unzip",
      "cd",
      "path",
      "table",
      "describes",
      "essential",
      "files",
      "inside",
      "chart",
      "name",
      "helm",
      "26.x.x",
      "oo-helm-charts",
      "oo-1.x.x",
      "26.x.x.tgz",
      "example",
      "persistent",
      "volume",
      "pv",
      "claims",
      "pvc",
      "yaml",
      "templates",
      "samples",
      "readme",
      "details",
      "see",
      "container",
      "images.",
      "commands",
      "command",
      "line",
      "tool",
      "yq",
      "part",
      "optic",
      "management",
      "toolkit",
      "omt",
      "available"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Upgrade external UD/UCMDB (embedded Kubernetes)",
    "content": "If the suite is integrated with UD/UCMDB, follow the instructions below to upgrade UD/UCMDB. Supported UD/UCMDB versions Find the supported UD/UCMDB versions in one of the following sections on the Integration Central: Service Management integration with classic Universal Discovery and CMDB (UCMDB) via Native SACM solution Service Management integration with containerized Universal Discovery and CMDB (UCMDB) via Native SACM solution Service Management integration with classic Universal Discovery and CMDB (UCMDB) via OPB You must perform the before-and-after upgrade tasks only when you upgrade from version 25.3 to 25.4. If you are upgrading from 25.2 or 25.2.2 to 25.3.1 or 25.3.2, you can skip these tasks. Before upgrading to UD/UCMDB 25.4 Perform the following tasks only when you upgrade from version 25.3 to 25.4. Otherwise, proceed with the next section. Set the number of replicas for the itom-cms-gateway deployment in the UCMDB namespace to 0. Go to the NFS server and navigate to the",
    "url": "upgradecms",
    "filename": "upgradecms",
    "headings": [
      "Supported UD/UCMDB versions",
      "Before upgrading to UD/UCMDB 25.4",
      "Upgrade UD/UCMDB",
      "Classic UD/UCMDB",
      "Containerized UD/UCMDB",
      "After upgrading to UD/UCMDB 25.4"
    ],
    "keywords": [
      "uducmdb",
      "25.3.2",
      "25.1",
      "25.2",
      "25.3",
      "25.2.2",
      "25.4",
      "24.4",
      "https://<smax-external-access-host>:<external-access-port>/sap/rest-client?TENANTID=<tenantId",
      "25.3.1",
      "upgrade",
      "external",
      "ud",
      "ucmdb",
      "embedded",
      "kubernetes",
      "supported",
      "versions",
      "before",
      "upgrading",
      "classic",
      "containerized",
      "after",
      "suite",
      "integrated",
      "follow",
      "instructions",
      "below",
      "ucmdb.",
      "find",
      "one",
      "following",
      "sections",
      "integration",
      "central",
      "service",
      "management",
      "universal",
      "discovery",
      "cmdb",
      "via",
      "native",
      "sacm",
      "solution",
      "opb",
      "perform",
      "before-and-after",
      "tasks",
      "version",
      "25.4.",
      "skip",
      "tasks.",
      "otherwise",
      "proceed",
      "next",
      "section.",
      "set",
      "number",
      "replicas",
      "itom-cms-gateway",
      "deployment",
      "namespace",
      "0.",
      "go",
      "nfs",
      "server",
      "navigate",
      "data",
      "volume",
      "delete",
      "all",
      "folders",
      "named",
      "model-",
      "folder",
      "cms-gateway",
      "example",
      "rm",
      "-rf",
      "var",
      "vols",
      "itom",
      "model-1.",
      "separately",
      "dependency",
      "components",
      "see",
      "update",
      "steps",
      "sequence",
      "requirements",
      "any.",
      "release",
      "doesn",
      "include",
      "new",
      "gateway.",
      "continue",
      "gateway",
      "release."
    ],
    "language": "en",
    "word_count": 107,
    "importance_score": 6.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "upgrade external ud/ucmdb (embedded kubernetes)",
    "contentLower": "if the suite is integrated with ud/ucmdb, follow the instructions below to upgrade ud/ucmdb. supported ud/ucmdb versions find the supported ud/ucmdb versions in one of the following sections on the integration central: service management integration with classic universal discovery and cmdb (ucmdb) via native sacm solution service management integration with containerized universal discovery and cmdb (ucmdb) via native sacm solution service management integration with classic universal discovery and cmdb (ucmdb) via opb you must perform the before-and-after upgrade tasks only when you upgrade from version 25.3 to 25.4. if you are upgrading from 25.2 or 25.2.2 to 25.3.1 or 25.3.2, you can skip these tasks. before upgrading to ud/ucmdb 25.4 perform the following tasks only when you upgrade from version 25.3 to 25.4. otherwise, proceed with the next section. set the number of replicas for the itom-cms-gateway deployment in the ucmdb namespace to 0. go to the nfs server and navigate to the",
    "keywordsLower": [
      "uducmdb",
      "25.3.2",
      "25.1",
      "25.2",
      "25.3",
      "25.2.2",
      "25.4",
      "24.4",
      "https://<smax-external-access-host>:<external-access-port>/sap/rest-client?tenantid=<tenantid",
      "25.3.1",
      "upgrade",
      "external",
      "ud",
      "ucmdb",
      "embedded",
      "kubernetes",
      "supported",
      "versions",
      "before",
      "upgrading",
      "classic",
      "containerized",
      "after",
      "suite",
      "integrated",
      "follow",
      "instructions",
      "below",
      "ucmdb.",
      "find",
      "one",
      "following",
      "sections",
      "integration",
      "central",
      "service",
      "management",
      "universal",
      "discovery",
      "cmdb",
      "via",
      "native",
      "sacm",
      "solution",
      "opb",
      "perform",
      "before-and-after",
      "tasks",
      "version",
      "25.4.",
      "skip",
      "tasks.",
      "otherwise",
      "proceed",
      "next",
      "section.",
      "set",
      "number",
      "replicas",
      "itom-cms-gateway",
      "deployment",
      "namespace",
      "0.",
      "go",
      "nfs",
      "server",
      "navigate",
      "data",
      "volume",
      "delete",
      "all",
      "folders",
      "named",
      "model-",
      "folder",
      "cms-gateway",
      "example",
      "rm",
      "-rf",
      "var",
      "vols",
      "itom",
      "model-1.",
      "separately",
      "dependency",
      "components",
      "see",
      "update",
      "steps",
      "sequence",
      "requirements",
      "any.",
      "release",
      "doesn",
      "include",
      "new",
      "gateway.",
      "continue",
      "gateway",
      "release."
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Upgrade the UD/UCMDB deployment (containerized UD/UCMDB)",
    "content": "Perform the following tasks to upgrade Containerized UD/UCMDB deployment.When you upgrade the containerized UD/UCMDB, the system will have downtime for over 10 minutes based on the number of customers and the CI volume of these customers.Download the new UD/UCMDB chart package You need to download the chart package from the Software website to a control plane node (embedded Kubernetes) or the bastion node (managed Kubernetes). To do this, follow these steps: Download the UCMDB_Helm_Chart-25.4.zip file from the Software Licenses and Downloads website. Copy the file to a temporary directory. Unzip the UD/UCMDB installation package: unzip UCMDB_Helm_Chart-25.4.zip The unzipped files are as follows: ucmdb-helm-charts-25.4.tgz ucmdb-helm-charts-25.4.tgz.sig Read_Me.pdf (Optional) Verify the UD/UCMDB installation package. Skip this step if you don't want to verify the package. For detailed instructions, see (Optional) Verify the UD/UCMDB installation package. Untar the chart package: cd UCMD",
    "url": "cmsupgrade",
    "filename": "cmsupgrade",
    "headings": [
      "Download the new UD/UCMDB chart package",
      "(Optional) Verify the UD/UCMDB installation package",
      "Download and upload new UD/UCMDB images",
      "Perform UD/UCMDB version update"
    ],
    "keywords": [
      "uducmdb",
      "deployment.For",
      "4.zip",
      "sign.pub",
      "https://<EXTERNAL_ACCESS_HOST>:<EXTERNAL_ACCESS_PORT>/status",
      "pv.yaml",
      "smax.yaml",
      "Read_Me.pdf",
      "25.4",
      "x.tgz",
      "4.tgz",
      "deployment.When",
      "1.xx",
      "values.yaml",
      "upgrade",
      "ud",
      "ucmdb",
      "deployment",
      "containerized",
      "download",
      "new",
      "chart",
      "package",
      "optional",
      "verify",
      "installation",
      "upload",
      "images",
      "perform",
      "version",
      "update",
      "following",
      "tasks",
      "system",
      "downtime",
      "over",
      "10",
      "minutes",
      "based",
      "number",
      "customers",
      "ci",
      "volume",
      "customers.download",
      "need",
      "software",
      "website",
      "control",
      "plane",
      "node",
      "embedded",
      "kubernetes",
      "bastion",
      "managed",
      "follow",
      "steps",
      "file",
      "licenses",
      "downloads",
      "website.",
      "copy",
      "temporary",
      "directory.",
      "unzip",
      "unzipped",
      "files",
      "follows",
      "ucmdb-helm-charts-25.4.tgz",
      "ucmdb-helm-charts-25.4.tgz.sig",
      "package.",
      "skip",
      "step",
      "don",
      "want",
      "detailed",
      "instructions",
      "see",
      "untar",
      "cd",
      "tar",
      "-xvzf",
      "table",
      "describes",
      "essential",
      "inside",
      "name",
      "helm",
      "ucmdb-helm-charts",
      "charts",
      "ucmdb-1.xx.x-xxx",
      "2x.x.x.tgz",
      "example",
      "pv",
      "yaml",
      "samples",
      "ucmdb-pv.yaml",
      "standalone",
      "environment",
      "shared",
      "idm"
    ],
    "language": "en",
    "word_count": 103,
    "importance_score": 4.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "upgrade the ud/ucmdb deployment (containerized ud/ucmdb)",
    "contentLower": "perform the following tasks to upgrade containerized ud/ucmdb deployment.when you upgrade the containerized ud/ucmdb, the system will have downtime for over 10 minutes based on the number of customers and the ci volume of these customers.download the new ud/ucmdb chart package you need to download the chart package from the software website to a control plane node (embedded kubernetes) or the bastion node (managed kubernetes). to do this, follow these steps: download the ucmdb_helm_chart-25.4.zip file from the software licenses and downloads website. copy the file to a temporary directory. unzip the ud/ucmdb installation package: unzip ucmdb_helm_chart-25.4.zip the unzipped files are as follows: ucmdb-helm-charts-25.4.tgz ucmdb-helm-charts-25.4.tgz.sig read_me.pdf (optional) verify the ud/ucmdb installation package. skip this step if you don't want to verify the package. for detailed instructions, see (optional) verify the ud/ucmdb installation package. untar the chart package: cd ucmd",
    "keywordsLower": [
      "uducmdb",
      "deployment.for",
      "4.zip",
      "sign.pub",
      "https://<external_access_host>:<external_access_port>/status",
      "pv.yaml",
      "smax.yaml",
      "read_me.pdf",
      "25.4",
      "x.tgz",
      "4.tgz",
      "deployment.when",
      "1.xx",
      "values.yaml",
      "upgrade",
      "ud",
      "ucmdb",
      "deployment",
      "containerized",
      "download",
      "new",
      "chart",
      "package",
      "optional",
      "verify",
      "installation",
      "upload",
      "images",
      "perform",
      "version",
      "update",
      "following",
      "tasks",
      "system",
      "downtime",
      "over",
      "10",
      "minutes",
      "based",
      "number",
      "customers",
      "ci",
      "volume",
      "customers.download",
      "need",
      "software",
      "website",
      "control",
      "plane",
      "node",
      "embedded",
      "kubernetes",
      "bastion",
      "managed",
      "follow",
      "steps",
      "file",
      "licenses",
      "downloads",
      "website.",
      "copy",
      "temporary",
      "directory.",
      "unzip",
      "unzipped",
      "files",
      "follows",
      "ucmdb-helm-charts-25.4.tgz",
      "ucmdb-helm-charts-25.4.tgz.sig",
      "package.",
      "skip",
      "step",
      "don",
      "want",
      "detailed",
      "instructions",
      "see",
      "untar",
      "cd",
      "tar",
      "-xvzf",
      "table",
      "describes",
      "essential",
      "inside",
      "name",
      "helm",
      "ucmdb-helm-charts",
      "charts",
      "ucmdb-1.xx.x-xxx",
      "2x.x.x.tgz",
      "example",
      "pv",
      "yaml",
      "samples",
      "ucmdb-pv.yaml",
      "standalone",
      "environment",
      "shared",
      "idm"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Upgrade the content pack (containerized UD/UCMDB)",
    "content": "After UD/UCMDB deployment binary upgrade, perform either of the following to deploy the latest Content Pack for each UCMDB customer manually: Deploy Content Pack from UCMDB Local Client. For detailed instructions, see Install a Discovery and Integration Content Pack. Deploy Content Pack from UCMDB UI. For detailed instructions, see Install/deploy a Content Pack from UCMDB UI. Activate UCMDB enrichment rules If you have enabled Native SACM and activated enrichment rules in the SMAX folder (UCMDB Local Client > Modeling > Enrichment Manager > Root\\SMAX), applying the CP upgrade will reset their status to Inactive. Therefore, you need to manually activate these enrichment rules after the CP upgrade. In addition, enrichment rule customizations, if any, will also be reset by the CP upgrade, please manually back up and restore them after the CP upgrade.",
    "url": "cmscontentpackupgrade",
    "filename": "cmscontentpackupgrade",
    "headings": [
      "Activate UCMDB enrichment rules"
    ],
    "keywords": [
      "uducmdb",
      "upgrade",
      "content",
      "pack",
      "containerized",
      "ud",
      "ucmdb",
      "activate",
      "enrichment",
      "rules",
      "after",
      "deployment",
      "binary",
      "perform",
      "either",
      "following",
      "deploy",
      "latest",
      "customer",
      "manually",
      "local",
      "client.",
      "detailed",
      "instructions",
      "see",
      "install",
      "discovery",
      "integration",
      "pack.",
      "ui.",
      "enabled",
      "native",
      "sacm",
      "activated",
      "smax",
      "folder",
      "client",
      "modeling",
      "manager",
      "root",
      "applying",
      "cp",
      "reset",
      "status",
      "inactive.",
      "therefore",
      "need",
      "upgrade.",
      "addition",
      "rule",
      "customizations",
      "any",
      "please",
      "back",
      "restore"
    ],
    "language": "en",
    "word_count": 100,
    "importance_score": 2.5,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "upgrade the content pack (containerized ud/ucmdb)",
    "contentLower": "after ud/ucmdb deployment binary upgrade, perform either of the following to deploy the latest content pack for each ucmdb customer manually: deploy content pack from ucmdb local client. for detailed instructions, see install a discovery and integration content pack. deploy content pack from ucmdb ui. for detailed instructions, see install/deploy a content pack from ucmdb ui. activate ucmdb enrichment rules if you have enabled native sacm and activated enrichment rules in the smax folder (ucmdb local client > modeling > enrichment manager > root\\smax), applying the cp upgrade will reset their status to inactive. therefore, you need to manually activate these enrichment rules after the cp upgrade. in addition, enrichment rule customizations, if any, will also be reset by the cp upgrade, please manually back up and restore them after the cp upgrade.",
    "keywordsLower": [
      "uducmdb",
      "upgrade",
      "content",
      "pack",
      "containerized",
      "ud",
      "ucmdb",
      "activate",
      "enrichment",
      "rules",
      "after",
      "deployment",
      "binary",
      "perform",
      "either",
      "following",
      "deploy",
      "latest",
      "customer",
      "manually",
      "local",
      "client.",
      "detailed",
      "instructions",
      "see",
      "install",
      "discovery",
      "integration",
      "pack.",
      "ui.",
      "enabled",
      "native",
      "sacm",
      "activated",
      "smax",
      "folder",
      "client",
      "modeling",
      "manager",
      "root",
      "applying",
      "cp",
      "reset",
      "status",
      "inactive.",
      "therefore",
      "need",
      "upgrade.",
      "addition",
      "rule",
      "customizations",
      "any",
      "please",
      "back",
      "restore"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Upgrade Audit (embedded Kubernetes)",
    "content": "This page contains the steps to upgrade Audit service and Audit collector in an on-premises environment. You must upgrade both Audit service and Audit collector. If the suite deployment is Helm-based, the Audit Collector is upgraded during the suite upgrade. In this case, skip the Audit Collector upgrade steps described below. Back up Audit service This section gives the steps to back up Audit files and data: Back up audit database. Back up all the configuration files that you are using. For example, values.yaml file, audit-secret.yaml, chart tar file, and certificates. Back up the itom-audit-pv.yaml file. Back up the following data on the NFS volumes for the Audit deployment: Component NFS volume name Description Example directory path Audit as-vault-volume-<Audit Namespace> Stores Audit configuration files. /var/vols/itom/audit/auditns/vault Audit as-log-volume-<Audit Namespace> Stores logs generated by Audit. /var/vols/itom/audit/auditns/log Download new Audit service Helm chart To ",
    "url": "upgradeauditembeddedk8s",
    "filename": "upgradeauditembeddedk8s",
    "headings": [
      "Back up Audit service",
      "Download new Audit service Helm chart",
      "Download and upload new Audit service images",
      "Upgrade Audit service",
      "Restore Audit service to previous version when upgrade fails",
      "Back up Audit collector",
      "Download new Audit collector Helm chart",
      "Download and upload new Audit collector images",
      "Upgrade Audit collector",
      "Restore Audit collector",
      "Enable indexing for existing tenants",
      "Related topics"
    ],
    "keywords": [
      "1.2.0",
      "cert_two.crt",
      "idm.crt",
      "RE_ca_db.crt",
      "cert_one.crt",
      "backup.yaml",
      "pv.yaml",
      "RE_ca_idm.crt",
      "ase.crt",
      "caCertificates.idm",
      "x.zip",
      "dd.yaml",
      "secret.yaml",
      "value.yaml",
      "xx.tgz",
      "values.yaml",
      "gen_secrets.sh",
      "upgrade",
      "audit",
      "embedded",
      "kubernetes",
      "back",
      "service",
      "download",
      "new",
      "helm",
      "chart",
      "upload",
      "images",
      "restore",
      "previous",
      "version",
      "fails",
      "collector",
      "enable",
      "indexing",
      "existing",
      "tenants",
      "related",
      "topics",
      "page",
      "contains",
      "steps",
      "on-premises",
      "environment.",
      "both",
      "collector.",
      "suite",
      "deployment",
      "helm-based",
      "upgraded",
      "during",
      "upgrade.",
      "case",
      "skip",
      "described",
      "below.",
      "section",
      "gives",
      "files",
      "data",
      "database.",
      "all",
      "configuration",
      "using.",
      "example",
      "file",
      "audit-secret.yaml",
      "tar",
      "certificates.",
      "itom-audit-pv.yaml",
      "file.",
      "following",
      "nfs",
      "volumes",
      "component",
      "volume",
      "name",
      "description",
      "directory",
      "path",
      "as-vault-volume-",
      "stores",
      "files.",
      "var",
      "vols",
      "itom",
      "auditns",
      "vault",
      "as-log-volume-",
      "logs",
      "generated",
      "audit.",
      "log",
      "control",
      "plane",
      "node",
      "follow",
      "navigate",
      "want"
    ],
    "language": "en",
    "word_count": 111,
    "importance_score": 6.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "upgrade audit (embedded kubernetes)",
    "contentLower": "this page contains the steps to upgrade audit service and audit collector in an on-premises environment. you must upgrade both audit service and audit collector. if the suite deployment is helm-based, the audit collector is upgraded during the suite upgrade. in this case, skip the audit collector upgrade steps described below. back up audit service this section gives the steps to back up audit files and data: back up audit database. back up all the configuration files that you are using. for example, values.yaml file, audit-secret.yaml, chart tar file, and certificates. back up the itom-audit-pv.yaml file. back up the following data on the nfs volumes for the audit deployment: component nfs volume name description example directory path audit as-vault-volume-<audit namespace> stores audit configuration files. /var/vols/itom/audit/auditns/vault audit as-log-volume-<audit namespace> stores logs generated by audit. /var/vols/itom/audit/auditns/log download new audit service helm chart to ",
    "keywordsLower": [
      "1.2.0",
      "cert_two.crt",
      "idm.crt",
      "re_ca_db.crt",
      "cert_one.crt",
      "backup.yaml",
      "pv.yaml",
      "re_ca_idm.crt",
      "ase.crt",
      "cacertificates.idm",
      "x.zip",
      "dd.yaml",
      "secret.yaml",
      "value.yaml",
      "xx.tgz",
      "values.yaml",
      "gen_secrets.sh",
      "upgrade",
      "audit",
      "embedded",
      "kubernetes",
      "back",
      "service",
      "download",
      "new",
      "helm",
      "chart",
      "upload",
      "images",
      "restore",
      "previous",
      "version",
      "fails",
      "collector",
      "enable",
      "indexing",
      "existing",
      "tenants",
      "related",
      "topics",
      "page",
      "contains",
      "steps",
      "on-premises",
      "environment.",
      "both",
      "collector.",
      "suite",
      "deployment",
      "helm-based",
      "upgraded",
      "during",
      "upgrade.",
      "case",
      "skip",
      "described",
      "below.",
      "section",
      "gives",
      "files",
      "data",
      "database.",
      "all",
      "configuration",
      "using.",
      "example",
      "file",
      "audit-secret.yaml",
      "tar",
      "certificates.",
      "itom-audit-pv.yaml",
      "file.",
      "following",
      "nfs",
      "volumes",
      "component",
      "volume",
      "name",
      "description",
      "directory",
      "path",
      "as-vault-volume-",
      "stores",
      "files.",
      "var",
      "vols",
      "itom",
      "auditns",
      "vault",
      "as-log-volume-",
      "logs",
      "generated",
      "audit.",
      "log",
      "control",
      "plane",
      "node",
      "follow",
      "navigate",
      "want"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Upgrade (managed Kubernetes)",
    "content": "This section introduces procedures to upgrade OPTIC Management Toolkit (OMT) and the suite deployed on the following platforms: Azure with AKS, AWS with EKS, GCP with GKE, and OpenShift. For an overview of the version upgrade process and upgrade best practices, see the Upgrade landing page.  For the list of base versions from which you can upgrade to the current version, see Supported upgrade paths. Plan for upgrade Before you start the upgrade process, make sure you have planned for the following dependencies. Check base version dependency Make sure that upgrade is supported for the suite version installed in your environment. For the list of supported upgrade versions, see Supported upgrade paths. Plan OMT upgrade For seamless operations, OMT version must match the suite version. To ensure this, we recommend that you upgrade OMT and the suite in the same maintenance window. If this is not possible, make sure that you complete the suite upgrade within one week after upgrading OMT. Upg",
    "url": "upgrademanagedk8s",
    "filename": "upgrademanagedk8s",
    "headings": [
      "Plan for upgrade",
      "Check base version dependency",
      "Plan OMT upgrade",
      "Upgrade to 26.1"
    ],
    "keywords": [
      "26.1",
      "upgrade.Back",
      "data.Back",
      "upgrade",
      "managed",
      "kubernetes",
      "plan",
      "check",
      "base",
      "version",
      "dependency",
      "omt",
      "section",
      "introduces",
      "procedures",
      "optic",
      "management",
      "toolkit",
      "suite",
      "deployed",
      "following",
      "platforms",
      "azure",
      "aks",
      "aws",
      "eks",
      "gcp",
      "gke",
      "openshift.",
      "overview",
      "process",
      "best",
      "practices",
      "see",
      "landing",
      "page.",
      "list",
      "versions",
      "current",
      "supported",
      "paths.",
      "before",
      "start",
      "make",
      "sure",
      "planned",
      "dependencies.",
      "installed",
      "environment.",
      "seamless",
      "operations",
      "match",
      "version.",
      "ensure",
      "recommend",
      "same",
      "maintenance",
      "window.",
      "possible",
      "complete",
      "one",
      "week",
      "after",
      "upgrading",
      "omt.",
      "table",
      "provides",
      "sequence",
      "upgrade.",
      "steps",
      "order.",
      "interchange",
      "order",
      "between",
      "ud",
      "ucmdb",
      "oo",
      "containerized",
      "audit.",
      "step",
      "no.",
      "description",
      "back",
      "data.",
      "details",
      "ucmdb.",
      ".back",
      "containerized.",
      "deployment",
      "audit",
      "service",
      "collector",
      "deployments.",
      "backup",
      "update",
      "suite.",
      "note",
      "fails",
      "restore",
      "old"
    ],
    "language": "en",
    "word_count": 104,
    "importance_score": 5.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "upgrade (managed kubernetes)",
    "contentLower": "this section introduces procedures to upgrade optic management toolkit (omt) and the suite deployed on the following platforms: azure with aks, aws with eks, gcp with gke, and openshift. for an overview of the version upgrade process and upgrade best practices, see the upgrade landing page.  for the list of base versions from which you can upgrade to the current version, see supported upgrade paths. plan for upgrade before you start the upgrade process, make sure you have planned for the following dependencies. check base version dependency make sure that upgrade is supported for the suite version installed in your environment. for the list of supported upgrade versions, see supported upgrade paths. plan omt upgrade for seamless operations, omt version must match the suite version. to ensure this, we recommend that you upgrade omt and the suite in the same maintenance window. if this is not possible, make sure that you complete the suite upgrade within one week after upgrading omt. upg",
    "keywordsLower": [
      "26.1",
      "upgrade.back",
      "data.back",
      "upgrade",
      "managed",
      "kubernetes",
      "plan",
      "check",
      "base",
      "version",
      "dependency",
      "omt",
      "section",
      "introduces",
      "procedures",
      "optic",
      "management",
      "toolkit",
      "suite",
      "deployed",
      "following",
      "platforms",
      "azure",
      "aks",
      "aws",
      "eks",
      "gcp",
      "gke",
      "openshift.",
      "overview",
      "process",
      "best",
      "practices",
      "see",
      "landing",
      "page.",
      "list",
      "versions",
      "current",
      "supported",
      "paths.",
      "before",
      "start",
      "make",
      "sure",
      "planned",
      "dependencies.",
      "installed",
      "environment.",
      "seamless",
      "operations",
      "match",
      "version.",
      "ensure",
      "recommend",
      "same",
      "maintenance",
      "window.",
      "possible",
      "complete",
      "one",
      "week",
      "after",
      "upgrading",
      "omt.",
      "table",
      "provides",
      "sequence",
      "upgrade.",
      "steps",
      "order.",
      "interchange",
      "order",
      "between",
      "ud",
      "ucmdb",
      "oo",
      "containerized",
      "audit.",
      "step",
      "no.",
      "description",
      "back",
      "data.",
      "details",
      "ucmdb.",
      ".back",
      "containerized.",
      "deployment",
      "audit",
      "service",
      "collector",
      "deployments.",
      "backup",
      "update",
      "suite.",
      "note",
      "fails",
      "restore",
      "old"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Upgrade OMT (managed Kubernetes)",
    "content": "This topic describes the steps to upgrade OMT for deployments that use managed Kubernetes. Before upgrading OMT and the suite (and any other applications if any), do not upgrade the Kubernetes cluster. Upgrade the Kubernetes cluster as the last step of the upgrade process.Prerequisite tasks Download, unzip, and verify the upgrade packageRoleLocationSuite adminBastion nodeVisit Software Licenses and Downloads Portal and download the OMT upgrade package (OMT2xx-xxx-15001-External-K8s.zip) to a temporary directory on the bastion node.Run the unzip command to unzip the upgrade package. For example, you run the following command: unzip OMT2xx-xxx-15001-External-K8s.zipTo verify you have a genuine, signed OMT package, use a web browser and visit the public key download portal. Download the MF_public_keys-Updated.tar.gz package to a local directory and extract the public keys, ot-package-sign.pub, using gzip. Refer to the steps on the page and verify the package either using RPM or GnuPG.Run ",
    "url": "upgdmanagedk8scdf",
    "filename": "upgdmanagedk8scdf",
    "headings": [
      "Prerequisite tasks",
      "Download, unzip, and verify the upgrade package",
      "Check the platform version",
      "(OpenShift) Create new security context constraints for OMT",
      "Download and upload the images",
      "Ensure that all the pods are running",
      "Upgrade procedure",
      "Post-upgrade tasks",
      "Clear the browser cache",
      "(AKS only) Reconfigure the load balancer for port 5443",
      "Reapply your Alertmanager rules"
    ],
    "keywords": [
      "package.cd",
      "sign.pub",
      "OMT.For",
      "GnuPG.Run",
      "5443.Make",
      "x.tgz",
      "downloadimages.sh",
      "upload.The",
      "Updated.tar",
      "set.json",
      "registry.The",
      "docker.io",
      "uploadimages.sh",
      "images.The",
      "gcr.io",
      "repository.The",
      "kubernetes.io",
      "option.When",
      "xxx.zip",
      "fail.On",
      "xxx-15001",
      "openshift.io",
      "upgrade.sh",
      "K8s.zip",
      "business.The",
      "hpeswitom.The",
      "node.Run",
      "process.To",
      "meta.helm",
      "cdf.sh",
      "upgrade",
      "omt",
      "managed",
      "kubernetes",
      "prerequisite",
      "tasks",
      "download",
      "unzip",
      "verify",
      "package",
      "check",
      "platform",
      "version",
      "openshift",
      "create",
      "new",
      "security",
      "context",
      "constraints",
      "upload",
      "images",
      "ensure",
      "all",
      "pods",
      "running",
      "procedure",
      "post-upgrade",
      "clear",
      "browser",
      "cache",
      "aks",
      "reconfigure",
      "load",
      "balancer",
      "port",
      "5443",
      "reapply",
      "alertmanager",
      "rules",
      "topic",
      "describes",
      "steps",
      "deployments",
      "kubernetes.",
      "before",
      "upgrading",
      "suite",
      "any",
      "applications",
      "cluster.",
      "cluster",
      "last",
      "step",
      "process.prerequisite",
      "packagerolelocationsuite",
      "adminbastion",
      "nodevisit",
      "software",
      "licenses",
      "downloads",
      "portal",
      "omt2xx-xxx-15001-external-k8s.zip",
      "temporary",
      "directory",
      "bastion",
      "command",
      "package.",
      "example",
      "run",
      "following"
    ],
    "language": "en",
    "word_count": 91,
    "importance_score": 6.6,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "upgrade omt (managed kubernetes)",
    "contentLower": "this topic describes the steps to upgrade omt for deployments that use managed kubernetes. before upgrading omt and the suite (and any other applications if any), do not upgrade the kubernetes cluster. upgrade the kubernetes cluster as the last step of the upgrade process.prerequisite tasks download, unzip, and verify the upgrade packagerolelocationsuite adminbastion nodevisit software licenses and downloads portal and download the omt upgrade package (omt2xx-xxx-15001-external-k8s.zip) to a temporary directory on the bastion node.run the unzip command to unzip the upgrade package. for example, you run the following command: unzip omt2xx-xxx-15001-external-k8s.zipto verify you have a genuine, signed omt package, use a web browser and visit the public key download portal. download the mf_public_keys-updated.tar.gz package to a local directory and extract the public keys, ot-package-sign.pub, using gzip. refer to the steps on the page and verify the package either using rpm or gnupg.run ",
    "keywordsLower": [
      "package.cd",
      "sign.pub",
      "omt.for",
      "gnupg.run",
      "5443.make",
      "x.tgz",
      "downloadimages.sh",
      "upload.the",
      "updated.tar",
      "set.json",
      "registry.the",
      "docker.io",
      "uploadimages.sh",
      "images.the",
      "gcr.io",
      "repository.the",
      "kubernetes.io",
      "option.when",
      "xxx.zip",
      "fail.on",
      "xxx-15001",
      "openshift.io",
      "upgrade.sh",
      "k8s.zip",
      "business.the",
      "hpeswitom.the",
      "node.run",
      "process.to",
      "meta.helm",
      "cdf.sh",
      "upgrade",
      "omt",
      "managed",
      "kubernetes",
      "prerequisite",
      "tasks",
      "download",
      "unzip",
      "verify",
      "package",
      "check",
      "platform",
      "version",
      "openshift",
      "create",
      "new",
      "security",
      "context",
      "constraints",
      "upload",
      "images",
      "ensure",
      "all",
      "pods",
      "running",
      "procedure",
      "post-upgrade",
      "clear",
      "browser",
      "cache",
      "aks",
      "reconfigure",
      "load",
      "balancer",
      "port",
      "5443",
      "reapply",
      "alertmanager",
      "rules",
      "topic",
      "describes",
      "steps",
      "deployments",
      "kubernetes.",
      "before",
      "upgrading",
      "suite",
      "any",
      "applications",
      "cluster.",
      "cluster",
      "last",
      "step",
      "process.prerequisite",
      "packagerolelocationsuite",
      "adminbastion",
      "nodevisit",
      "software",
      "licenses",
      "downloads",
      "portal",
      "omt2xx-xxx-15001-external-k8s.zip",
      "temporary",
      "directory",
      "bastion",
      "command",
      "package.",
      "example",
      "run",
      "following"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Upgrade OO Containerized on EKS and AKS",
    "content": "This topic outlines steps to upgrade OO Containerized on Amazon EKS and Microsoft AKS using managed Kubernetes from 25.2 to 25.3. The upgrade process may take 20 to 30 minutes based on the number of tenants, which may impact flow execution. Prerequisites for upgrade The following sections list the prerequisite steps to upgrade OO Containerized. Download OO chart You can download the OO chart from the Software Licenses and Downloads (SLD) website. After downloading the OO Containerized package from either location, copy and unzip the downloaded file to a temporary directory on the Bastion host. If you downloaded from the Software Licenses and Downloads portal: Unzip the OO Containerized package: cd /path/to/oo_package_zip unzip oo-helm-charts-1.x.x+26.x.x.zip The OO chart contains the following files: Name File OO Helm chart file oo-helm-charts-1.x.x+26.x.x/oo-helm-charts/charts/oo-1.x.x+26.x.x.tgz Example Persistent Volume (PV) and Persistent Volume Claims (PVC) yaml files PV templates",
    "url": "399-upgradecontainerizedoomanagedk8s",
    "filename": "399-upgradecontainerizedoomanagedk8s",
    "headings": [
      "Prerequisites for upgrade",
      "Download OO chart",
      "Download and upload new OO images",
      "Get values.yaml file and update",
      "Create temporary cluster nodes for OO",
      "Upgrade OO Containerized",
      "Related topic"
    ],
    "keywords": [
      "previous_deployment_values.yaml",
      "service.beta",
      "4.6.1",
      "claims.yaml",
      "kubernetes.io",
      "https://<int_lb_fqdn>:<sma_ingress_listener_port>/idm-service",
      "https://int.example.com:2443/idm-service",
      "25.2",
      "25.3",
      "database.user",
      "volumes.yaml",
      "x.zip",
      "https://<EXTERNAL_ACCESS_HOST>:<EXTERNAL_ACCESS_PORT>/oo",
      "global.idm",
      "x.tgz",
      "values.yaml",
      "example.com",
      "upgrade",
      "oo",
      "containerized",
      "eks",
      "aks",
      "prerequisites",
      "download",
      "chart",
      "upload",
      "new",
      "images",
      "get",
      "file",
      "update",
      "create",
      "temporary",
      "cluster",
      "nodes",
      "related",
      "topic",
      "outlines",
      "steps",
      "amazon",
      "microsoft",
      "managed",
      "kubernetes",
      "25.3.",
      "process",
      "take",
      "20",
      "30",
      "minutes",
      "based",
      "number",
      "tenants",
      "impact",
      "flow",
      "execution.",
      "following",
      "sections",
      "list",
      "prerequisite",
      "containerized.",
      "software",
      "licenses",
      "downloads",
      "sld",
      "website.",
      "after",
      "downloading",
      "package",
      "either",
      "location",
      "copy",
      "unzip",
      "downloaded",
      "directory",
      "bastion",
      "host.",
      "portal",
      "cd",
      "path",
      "oo-helm-charts-1.x.x",
      "26.x.x.zip",
      "contains",
      "files",
      "name",
      "helm",
      "26.x.x",
      "oo-helm-charts",
      "charts",
      "oo-1.x.x",
      "26.x.x.tgz",
      "example",
      "persistent",
      "volume",
      "pv",
      "claims",
      "pvc",
      "yaml",
      "templates",
      "samples",
      "readme"
    ],
    "language": "en",
    "word_count": 111,
    "importance_score": 5.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "upgrade oo containerized on eks and aks",
    "contentLower": "this topic outlines steps to upgrade oo containerized on amazon eks and microsoft aks using managed kubernetes from 25.2 to 25.3. the upgrade process may take 20 to 30 minutes based on the number of tenants, which may impact flow execution. prerequisites for upgrade the following sections list the prerequisite steps to upgrade oo containerized. download oo chart you can download the oo chart from the software licenses and downloads (sld) website. after downloading the oo containerized package from either location, copy and unzip the downloaded file to a temporary directory on the bastion host. if you downloaded from the software licenses and downloads portal: unzip the oo containerized package: cd /path/to/oo_package_zip unzip oo-helm-charts-1.x.x+26.x.x.zip the oo chart contains the following files: name file oo helm chart file oo-helm-charts-1.x.x+26.x.x/oo-helm-charts/charts/oo-1.x.x+26.x.x.tgz example persistent volume (pv) and persistent volume claims (pvc) yaml files pv templates",
    "keywordsLower": [
      "previous_deployment_values.yaml",
      "service.beta",
      "4.6.1",
      "claims.yaml",
      "kubernetes.io",
      "https://<int_lb_fqdn>:<sma_ingress_listener_port>/idm-service",
      "https://int.example.com:2443/idm-service",
      "25.2",
      "25.3",
      "database.user",
      "volumes.yaml",
      "x.zip",
      "https://<external_access_host>:<external_access_port>/oo",
      "global.idm",
      "x.tgz",
      "values.yaml",
      "example.com",
      "upgrade",
      "oo",
      "containerized",
      "eks",
      "aks",
      "prerequisites",
      "download",
      "chart",
      "upload",
      "new",
      "images",
      "get",
      "file",
      "update",
      "create",
      "temporary",
      "cluster",
      "nodes",
      "related",
      "topic",
      "outlines",
      "steps",
      "amazon",
      "microsoft",
      "managed",
      "kubernetes",
      "25.3.",
      "process",
      "take",
      "20",
      "30",
      "minutes",
      "based",
      "number",
      "tenants",
      "impact",
      "flow",
      "execution.",
      "following",
      "sections",
      "list",
      "prerequisite",
      "containerized.",
      "software",
      "licenses",
      "downloads",
      "sld",
      "website.",
      "after",
      "downloading",
      "package",
      "either",
      "location",
      "copy",
      "unzip",
      "downloaded",
      "directory",
      "bastion",
      "host.",
      "portal",
      "cd",
      "path",
      "oo-helm-charts-1.x.x",
      "26.x.x.zip",
      "contains",
      "files",
      "name",
      "helm",
      "26.x.x",
      "oo-helm-charts",
      "charts",
      "oo-1.x.x",
      "26.x.x.tgz",
      "example",
      "persistent",
      "volume",
      "pv",
      "claims",
      "pvc",
      "yaml",
      "templates",
      "samples",
      "readme"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Upgrade OO Containerized on OpenShift",
    "content": "This topic outlines steps to upgrade OO Containerized on Red Hat OpenShift. The upgrade process may take 20 to 30 minutes based on the number of tenants, which may impact flow execution. Perform the following tasks to upgrade OO Containerized deployment. Download the new charts package You need to download the tar file from the Software Licenses and Downloads website to a bastion host. Do the following: Download the oo-helm-charts-1.x.x+26.x.x.zip file from the Software Licenses and Downloads (SLD) website. Copy the file to a temporary directory on a bastion host. Unzip the package: cd /path/to/oo_package_zip unzip oo-helm-charts-1.x.x+26.x.x.zip The following table describes the essential files inside the OO Containerized chart package: Name File OO Helm chart file oo-helm-charts-1.x.x+26.x.x/oo-helm-charts/charts/oo-1.x.x+26.x.x.tgz Example Persistent Volume (PV) and Persistent Volume Claims (PVC) yaml files PV templates: oo-helm-charts-1.x.x+26.x.x/oo-helm-charts/samples/persistent_",
    "url": "399-upgradecontainerizedooopenshift",
    "filename": "399-upgradecontainerizedooopenshift",
    "headings": [
      "Download the new charts package",
      "Download and upload new OO images",
      "Get values.yaml file and update",
      "Upgrade OO Containerized",
      "Related topic"
    ],
    "keywords": [
      "previous_deployment_values.yaml",
      "4.6.1",
      "claims.yaml",
      "2023.05",
      "database.user",
      "volumes.yaml",
      "x.zip",
      "https://<EXTERNAL_ACCESS_HOST>:<EXTERNAL_ACCESS_PORT>/oo",
      "x.tgz",
      "values.yaml",
      "upgrade",
      "oo",
      "containerized",
      "openshift",
      "download",
      "new",
      "charts",
      "package",
      "upload",
      "images",
      "get",
      "file",
      "update",
      "related",
      "topic",
      "outlines",
      "steps",
      "red",
      "hat",
      "openshift.",
      "process",
      "take",
      "20",
      "30",
      "minutes",
      "based",
      "number",
      "tenants",
      "impact",
      "flow",
      "execution.",
      "perform",
      "following",
      "tasks",
      "deployment.",
      "need",
      "tar",
      "software",
      "licenses",
      "downloads",
      "website",
      "bastion",
      "host.",
      "oo-helm-charts-1.x.x",
      "26.x.x.zip",
      "sld",
      "website.",
      "copy",
      "temporary",
      "directory",
      "unzip",
      "cd",
      "path",
      "table",
      "describes",
      "essential",
      "files",
      "inside",
      "chart",
      "name",
      "helm",
      "26.x.x",
      "oo-helm-charts",
      "oo-1.x.x",
      "26.x.x.tgz",
      "example",
      "persistent",
      "volume",
      "pv",
      "claims",
      "pvc",
      "yaml",
      "templates",
      "samples",
      "readme",
      "details",
      "see",
      "container",
      "images.",
      "commands",
      "command",
      "line",
      "tool",
      "yq",
      "part",
      "optic",
      "management",
      "toolkit",
      "omt",
      "available"
    ],
    "language": "en",
    "word_count": 109,
    "importance_score": 5.5,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "upgrade oo containerized on openshift",
    "contentLower": "this topic outlines steps to upgrade oo containerized on red hat openshift. the upgrade process may take 20 to 30 minutes based on the number of tenants, which may impact flow execution. perform the following tasks to upgrade oo containerized deployment. download the new charts package you need to download the tar file from the software licenses and downloads website to a bastion host. do the following: download the oo-helm-charts-1.x.x+26.x.x.zip file from the software licenses and downloads (sld) website. copy the file to a temporary directory on a bastion host. unzip the package: cd /path/to/oo_package_zip unzip oo-helm-charts-1.x.x+26.x.x.zip the following table describes the essential files inside the oo containerized chart package: name file oo helm chart file oo-helm-charts-1.x.x+26.x.x/oo-helm-charts/charts/oo-1.x.x+26.x.x.tgz example persistent volume (pv) and persistent volume claims (pvc) yaml files pv templates: oo-helm-charts-1.x.x+26.x.x/oo-helm-charts/samples/persistent_",
    "keywordsLower": [
      "previous_deployment_values.yaml",
      "4.6.1",
      "claims.yaml",
      "2023.05",
      "database.user",
      "volumes.yaml",
      "x.zip",
      "https://<external_access_host>:<external_access_port>/oo",
      "x.tgz",
      "values.yaml",
      "upgrade",
      "oo",
      "containerized",
      "openshift",
      "download",
      "new",
      "charts",
      "package",
      "upload",
      "images",
      "get",
      "file",
      "update",
      "related",
      "topic",
      "outlines",
      "steps",
      "red",
      "hat",
      "openshift.",
      "process",
      "take",
      "20",
      "30",
      "minutes",
      "based",
      "number",
      "tenants",
      "impact",
      "flow",
      "execution.",
      "perform",
      "following",
      "tasks",
      "deployment.",
      "need",
      "tar",
      "software",
      "licenses",
      "downloads",
      "website",
      "bastion",
      "host.",
      "oo-helm-charts-1.x.x",
      "26.x.x.zip",
      "sld",
      "website.",
      "copy",
      "temporary",
      "directory",
      "unzip",
      "cd",
      "path",
      "table",
      "describes",
      "essential",
      "files",
      "inside",
      "chart",
      "name",
      "helm",
      "26.x.x",
      "oo-helm-charts",
      "oo-1.x.x",
      "26.x.x.tgz",
      "example",
      "persistent",
      "volume",
      "pv",
      "claims",
      "pvc",
      "yaml",
      "templates",
      "samples",
      "readme",
      "details",
      "see",
      "container",
      "images.",
      "commands",
      "command",
      "line",
      "tool",
      "yq",
      "part",
      "optic",
      "management",
      "toolkit",
      "omt",
      "available"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Upgrade external UD/UCMDB (managed Kubernetes)",
    "content": "If the suite is integrated with UD/UCMDB, follow the instructions below to upgrade UD/UCMDB. Supported UD/UCMDB versions Find the supported UD/UCMDB versions in one of the following sections on the Integration Central: Service Management integration with classic Universal Discovery and CMDB (UCMDB) via Native SACM solutionService Management integration with containerized Universal Discovery and CMDB (UCMDB) via Native SACM solutionService Management integration with classic Universal Discovery and CMDB (UCMDB) via OPB You must perform the before-and-after upgrade tasks only when you upgrade from version 25.3 to 25.4. If you are upgrading from 25.2 or 25.2.2 to 25.3.1 or 25.3.2, you can skip these tasks. Before upgrading to UD/UCMDB 25.4 Perform the following tasks only when you upgrade from version 25.3 to 25.4. Otherwise, proceed with the next section. Set the number of replicas for the itom-cms-gateway deployment in the UCMDB namespace to 0.Go to the NFS server and navigate to the da",
    "url": "upgdcmsmanagedk8s",
    "filename": "upgdcmsmanagedk8s",
    "headings": [
      "Supported UD/UCMDB versions",
      "Before upgrading to UD/UCMDB 25.4",
      "Upgrade UD/UCMDB",
      "Upgrade Classic UD/UCMDB",
      "Upgrade containerized UD/UCMDB",
      "After upgrading to UD/UCMDB 25.4"
    ],
    "keywords": [
      "uducmdb",
      "25.3.2",
      "https://<smax-external-access-host>:<external-access-port>/sap/rest-client?TENANTID=<tenantId>.Set",
      "25.1",
      "0.Go",
      "25.2",
      "25.3",
      "25.2.2",
      "25.4",
      "24.4",
      "user.Go",
      "25.3.1",
      "upgrade",
      "external",
      "ud",
      "ucmdb",
      "managed",
      "kubernetes",
      "supported",
      "versions",
      "before",
      "upgrading",
      "classic",
      "containerized",
      "after",
      "suite",
      "integrated",
      "follow",
      "instructions",
      "below",
      "ucmdb.",
      "find",
      "one",
      "following",
      "sections",
      "integration",
      "central",
      "service",
      "management",
      "universal",
      "discovery",
      "cmdb",
      "via",
      "native",
      "sacm",
      "solutionservice",
      "opb",
      "perform",
      "before-and-after",
      "tasks",
      "version",
      "25.4.",
      "skip",
      "tasks.",
      "otherwise",
      "proceed",
      "next",
      "section.",
      "set",
      "number",
      "replicas",
      "itom-cms-gateway",
      "deployment",
      "namespace",
      "nfs",
      "server",
      "navigate",
      "data",
      "volume",
      "ucmdb.delete",
      "all",
      "folders",
      "named",
      "model-",
      "folder",
      "cms-gateway",
      "example",
      "rm",
      "-rf",
      "var",
      "vols",
      "itom",
      "model-1.",
      "separately",
      "dependency",
      "components",
      "see",
      "update",
      "steps",
      "sequence",
      "requirements",
      "any.",
      "release",
      "doesn",
      "include",
      "new",
      "gateway.",
      "continue",
      "gateway",
      "release."
    ],
    "language": "en",
    "word_count": 105,
    "importance_score": 6.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "upgrade external ud/ucmdb (managed kubernetes)",
    "contentLower": "if the suite is integrated with ud/ucmdb, follow the instructions below to upgrade ud/ucmdb. supported ud/ucmdb versions find the supported ud/ucmdb versions in one of the following sections on the integration central: service management integration with classic universal discovery and cmdb (ucmdb) via native sacm solutionservice management integration with containerized universal discovery and cmdb (ucmdb) via native sacm solutionservice management integration with classic universal discovery and cmdb (ucmdb) via opb you must perform the before-and-after upgrade tasks only when you upgrade from version 25.3 to 25.4. if you are upgrading from 25.2 or 25.2.2 to 25.3.1 or 25.3.2, you can skip these tasks. before upgrading to ud/ucmdb 25.4 perform the following tasks only when you upgrade from version 25.3 to 25.4. otherwise, proceed with the next section. set the number of replicas for the itom-cms-gateway deployment in the ucmdb namespace to 0.go to the nfs server and navigate to the da",
    "keywordsLower": [
      "uducmdb",
      "25.3.2",
      "https://<smax-external-access-host>:<external-access-port>/sap/rest-client?tenantid=<tenantid>.set",
      "25.1",
      "0.go",
      "25.2",
      "25.3",
      "25.2.2",
      "25.4",
      "24.4",
      "user.go",
      "25.3.1",
      "upgrade",
      "external",
      "ud",
      "ucmdb",
      "managed",
      "kubernetes",
      "supported",
      "versions",
      "before",
      "upgrading",
      "classic",
      "containerized",
      "after",
      "suite",
      "integrated",
      "follow",
      "instructions",
      "below",
      "ucmdb.",
      "find",
      "one",
      "following",
      "sections",
      "integration",
      "central",
      "service",
      "management",
      "universal",
      "discovery",
      "cmdb",
      "via",
      "native",
      "sacm",
      "solutionservice",
      "opb",
      "perform",
      "before-and-after",
      "tasks",
      "version",
      "25.4.",
      "skip",
      "tasks.",
      "otherwise",
      "proceed",
      "next",
      "section.",
      "set",
      "number",
      "replicas",
      "itom-cms-gateway",
      "deployment",
      "namespace",
      "nfs",
      "server",
      "navigate",
      "data",
      "volume",
      "ucmdb.delete",
      "all",
      "folders",
      "named",
      "model-",
      "folder",
      "cms-gateway",
      "example",
      "rm",
      "-rf",
      "var",
      "vols",
      "itom",
      "model-1.",
      "separately",
      "dependency",
      "components",
      "see",
      "update",
      "steps",
      "sequence",
      "requirements",
      "any.",
      "release",
      "doesn",
      "include",
      "new",
      "gateway.",
      "continue",
      "gateway",
      "release."
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Upgrade UD/UCMDB (managed Kubernetes)",
    "content": "Perform the following tasks to upgrade UD/UCMDB deployment.When you upgrade the containerized UD/UCMDB, the system will have downtime for over 10 minutes based on the number of customers and the CI volume of these customers.Download the new UD/UCMDB chart package You need to download the UD/UCMDB chart package from the Software website to a control plane node (embedded Kubernetes) or the bastion node (managed Kubernetes). The The product version is 25.3 on this page; <nn.n > is used to indicate the version number. For example, UCMDB_Helm_Chart-<nn.n> .zip To do this, follow these steps: Download the UCMDB_Helm_Chart- nn.n.zip file from the Software Licenses and Downloads website. Copy the file to a temporary directory. Unzip the UD/UCMDB installation package: unzip UCMDB_Helm_Chart-<nn.n>.zip The unzipped files are as follows: ucmdb-helm-charts-<nn.n>.tgz ucmdb-helm-charts-<nn.n>.tgz.sig Read_Me.pdf (Optional) Verify the UD/UCMDB installation package. Skip this step if you don't want t",
    "url": "cmsupgrademanagedk8s",
    "filename": "cmsupgrademanagedk8s",
    "headings": [
      "Download the new UD/UCMDB chart package",
      "Download and upload new UD/UCMDB images",
      "Perform UD/UCMDB version update"
    ],
    "keywords": [
      "uducmdb",
      "n.zip",
      "25.1",
      "sign.pub",
      "https://<EXTERNAL_ACCESS_HOST>:<EXTERNAL_ACCESS_PORT>/status",
      "pv.yaml",
      "tgz.sig",
      "25.3",
      "Read_Me.pdf",
      "n.tgz",
      "smax.yaml",
      "1.nn",
      "registry.For",
      "deployment.When",
      "values.yaml",
      "upgrade",
      "ud",
      "ucmdb",
      "managed",
      "kubernetes",
      "download",
      "new",
      "chart",
      "package",
      "upload",
      "images",
      "perform",
      "version",
      "update",
      "following",
      "tasks",
      "containerized",
      "system",
      "downtime",
      "over",
      "10",
      "minutes",
      "based",
      "number",
      "customers",
      "ci",
      "volume",
      "customers.download",
      "need",
      "software",
      "website",
      "control",
      "plane",
      "node",
      "embedded",
      "bastion",
      "product",
      "page",
      "indicate",
      "number.",
      "example",
      ".zip",
      "follow",
      "steps",
      "nn.n.zip",
      "file",
      "licenses",
      "downloads",
      "website.",
      "copy",
      "temporary",
      "directory.",
      "unzip",
      "installation",
      "unzipped",
      "files",
      "follows",
      "ucmdb-helm-charts-.tgz",
      "ucmdb-helm-charts-.tgz.sig",
      "optional",
      "verify",
      "package.",
      "skip",
      "step",
      "don",
      "want",
      "visit",
      "km000003948",
      "attached",
      "compressed",
      "tar",
      "get",
      "detailed",
      "signatures.",
      "downloaded",
      "locate",
      "ot-package-sign.pub",
      "key",
      "untar",
      "cd",
      "-xvzf",
      "ucmdb-helm-charts-nn.n.tgz",
      "table",
      "describes",
      "essential"
    ],
    "language": "en",
    "word_count": 101,
    "importance_score": 4.5,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "upgrade ud/ucmdb (managed kubernetes)",
    "contentLower": "perform the following tasks to upgrade ud/ucmdb deployment.when you upgrade the containerized ud/ucmdb, the system will have downtime for over 10 minutes based on the number of customers and the ci volume of these customers.download the new ud/ucmdb chart package you need to download the ud/ucmdb chart package from the software website to a control plane node (embedded kubernetes) or the bastion node (managed kubernetes). the the product version is 25.3 on this page; <nn.n > is used to indicate the version number. for example, ucmdb_helm_chart-<nn.n> .zip to do this, follow these steps: download the ucmdb_helm_chart- nn.n.zip file from the software licenses and downloads website. copy the file to a temporary directory. unzip the ud/ucmdb installation package: unzip ucmdb_helm_chart-<nn.n>.zip the unzipped files are as follows: ucmdb-helm-charts-<nn.n>.tgz ucmdb-helm-charts-<nn.n>.tgz.sig read_me.pdf (optional) verify the ud/ucmdb installation package. skip this step if you don't want t",
    "keywordsLower": [
      "uducmdb",
      "n.zip",
      "25.1",
      "sign.pub",
      "https://<external_access_host>:<external_access_port>/status",
      "pv.yaml",
      "tgz.sig",
      "25.3",
      "read_me.pdf",
      "n.tgz",
      "smax.yaml",
      "1.nn",
      "registry.for",
      "deployment.when",
      "values.yaml",
      "upgrade",
      "ud",
      "ucmdb",
      "managed",
      "kubernetes",
      "download",
      "new",
      "chart",
      "package",
      "upload",
      "images",
      "perform",
      "version",
      "update",
      "following",
      "tasks",
      "containerized",
      "system",
      "downtime",
      "over",
      "10",
      "minutes",
      "based",
      "number",
      "customers",
      "ci",
      "volume",
      "customers.download",
      "need",
      "software",
      "website",
      "control",
      "plane",
      "node",
      "embedded",
      "bastion",
      "product",
      "page",
      "indicate",
      "number.",
      "example",
      ".zip",
      "follow",
      "steps",
      "nn.n.zip",
      "file",
      "licenses",
      "downloads",
      "website.",
      "copy",
      "temporary",
      "directory.",
      "unzip",
      "installation",
      "unzipped",
      "files",
      "follows",
      "ucmdb-helm-charts-.tgz",
      "ucmdb-helm-charts-.tgz.sig",
      "optional",
      "verify",
      "package.",
      "skip",
      "step",
      "don",
      "want",
      "visit",
      "km000003948",
      "attached",
      "compressed",
      "tar",
      "get",
      "detailed",
      "signatures.",
      "downloaded",
      "locate",
      "ot-package-sign.pub",
      "key",
      "untar",
      "cd",
      "-xvzf",
      "ucmdb-helm-charts-nn.n.tgz",
      "table",
      "describes",
      "essential"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Upgrade Content Pack (managed Kubernetes)",
    "content": "Following the UD/UCMDB version upgrade, manually deploy the latest Content Pack for each customer using one of these methods: Deploy Content Pack from UCMDB UI. For details, see Install/Deploy a Content Pack from UCMDB UI. Deploy Content Pack from Local Client. For details, see How to Install a Discovery and Integration Content Pack. Activate UCMDB enrichment rules If you have enabled Native SACM and activated enrichment rules in the SMAX folder (UCMDB Local Client > Modeling > Enrichment Manager > Root\\SMAX), applying the CP upgrade will reset their status to Inactive. Therefore, you need to manually activate these enrichment rules after the CP upgrade. In addition, enrichment rule customizations, if any, will also be reset by the CP upgrade, please manually back up and restore them after the CP upgrade.",
    "url": "cmscontentpackupgrademanagedk8s",
    "filename": "cmscontentpackupgrademanagedk8s",
    "headings": [
      "Activate UCMDB enrichment rules"
    ],
    "keywords": [
      "upgrade",
      "content",
      "pack",
      "managed",
      "kubernetes",
      "activate",
      "ucmdb",
      "enrichment",
      "rules",
      "following",
      "ud",
      "version",
      "manually",
      "deploy",
      "latest",
      "customer",
      "one",
      "methods",
      "ui.",
      "details",
      "see",
      "install",
      "local",
      "client.",
      "discovery",
      "integration",
      "pack.",
      "enabled",
      "native",
      "sacm",
      "activated",
      "smax",
      "folder",
      "client",
      "modeling",
      "manager",
      "root",
      "applying",
      "cp",
      "reset",
      "status",
      "inactive.",
      "therefore",
      "need",
      "after",
      "upgrade.",
      "addition",
      "rule",
      "customizations",
      "any",
      "please",
      "back",
      "restore"
    ],
    "language": "en",
    "word_count": 93,
    "importance_score": 3.5,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "upgrade content pack (managed kubernetes)",
    "contentLower": "following the ud/ucmdb version upgrade, manually deploy the latest content pack for each customer using one of these methods: deploy content pack from ucmdb ui. for details, see install/deploy a content pack from ucmdb ui. deploy content pack from local client. for details, see how to install a discovery and integration content pack. activate ucmdb enrichment rules if you have enabled native sacm and activated enrichment rules in the smax folder (ucmdb local client > modeling > enrichment manager > root\\smax), applying the cp upgrade will reset their status to inactive. therefore, you need to manually activate these enrichment rules after the cp upgrade. in addition, enrichment rule customizations, if any, will also be reset by the cp upgrade, please manually back up and restore them after the cp upgrade.",
    "keywordsLower": [
      "upgrade",
      "content",
      "pack",
      "managed",
      "kubernetes",
      "activate",
      "ucmdb",
      "enrichment",
      "rules",
      "following",
      "ud",
      "version",
      "manually",
      "deploy",
      "latest",
      "customer",
      "one",
      "methods",
      "ui.",
      "details",
      "see",
      "install",
      "local",
      "client.",
      "discovery",
      "integration",
      "pack.",
      "enabled",
      "native",
      "sacm",
      "activated",
      "smax",
      "folder",
      "client",
      "modeling",
      "manager",
      "root",
      "applying",
      "cp",
      "reset",
      "status",
      "inactive.",
      "therefore",
      "need",
      "after",
      "upgrade.",
      "addition",
      "rule",
      "customizations",
      "any",
      "please",
      "back",
      "restore"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Upgrade Audit (managed Kubernetes)",
    "content": "This page contains the steps to upgrade Audit service and Audit collector in a managed (AWS with EKS or OpenShift) environment. You need to upgrade both Audit service and Audit collector. Back up Audit service This section gives the steps to back up Audit files and data: Back up audit database. Back up all the configuration files that you are using. For example, values.yaml file, audit-secret.yaml, chart tar file, and certificates. Back up the itom-audit-pv.yaml file. Back up the following data on the Amazon Elastic File System (EFS) or Network File System (NFS) volumes for the Audit deployment: Component EFS/NFS volume name Description Example directory path Audit as-vault-volume-<Audit Namespace> Stores Audit configuration files. /var/vols/itom/audit/auditns/vault Audit as-log-volume-<Audit Namespace> Stores logs generated by Audit. /var/vols/itom/audit/auditns/log Download the new Audit service Helm chart To download the Audit Helm chart to the bastion node, follow these steps: Log ",
    "url": "131-upgradeauditmanagedk8s",
    "filename": "131-upgradeauditmanagedk8s",
    "headings": [
      "Back up Audit service",
      "Download the new Audit service Helm chart",
      "Download and upload new Audit service images",
      "Upgrade Audit service",
      "Back up Audit collector",
      "Download the new Audit collector Helm chart",
      "Download and upload new Audit collector images",
      "Upgrade Audit collector",
      "Restore Audit collector",
      "Enable indexing for existing tenants"
    ],
    "keywords": [
      "1.2.0",
      "cert_two.crt",
      "RE_ca_intAlb.crt",
      "RE_ca_db.crt",
      "cert_one.crt",
      "backup.yaml",
      "pv.yaml",
      "RE_ca_idm.crt",
      "x.zip",
      "dd.yaml",
      "secret.yaml",
      "value.yaml",
      "xx.tgz",
      "values.yaml",
      "gen_secrets.sh",
      "upgrade",
      "audit",
      "managed",
      "kubernetes",
      "back",
      "service",
      "download",
      "new",
      "helm",
      "chart",
      "upload",
      "images",
      "collector",
      "restore",
      "enable",
      "indexing",
      "existing",
      "tenants",
      "page",
      "contains",
      "steps",
      "aws",
      "eks",
      "openshift",
      "environment.",
      "need",
      "both",
      "collector.",
      "section",
      "gives",
      "files",
      "data",
      "database.",
      "all",
      "configuration",
      "using.",
      "example",
      "file",
      "audit-secret.yaml",
      "tar",
      "certificates.",
      "itom-audit-pv.yaml",
      "file.",
      "following",
      "amazon",
      "elastic",
      "system",
      "efs",
      "network",
      "nfs",
      "volumes",
      "deployment",
      "component",
      "volume",
      "name",
      "description",
      "directory",
      "path",
      "as-vault-volume-",
      "stores",
      "files.",
      "var",
      "vols",
      "itom",
      "auditns",
      "vault",
      "as-log-volume-",
      "logs",
      "generated",
      "audit.",
      "log",
      "bastion",
      "node",
      "follow",
      "navigate",
      "want",
      "install",
      "service.",
      "create",
      "folder",
      "audit-2x.x.",
      "mkdir",
      "audit-2x.x",
      "cd",
      "software"
    ],
    "language": "en",
    "word_count": 116,
    "importance_score": 6.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "upgrade audit (managed kubernetes)",
    "contentLower": "this page contains the steps to upgrade audit service and audit collector in a managed (aws with eks or openshift) environment. you need to upgrade both audit service and audit collector. back up audit service this section gives the steps to back up audit files and data: back up audit database. back up all the configuration files that you are using. for example, values.yaml file, audit-secret.yaml, chart tar file, and certificates. back up the itom-audit-pv.yaml file. back up the following data on the amazon elastic file system (efs) or network file system (nfs) volumes for the audit deployment: component efs/nfs volume name description example directory path audit as-vault-volume-<audit namespace> stores audit configuration files. /var/vols/itom/audit/auditns/vault audit as-log-volume-<audit namespace> stores logs generated by audit. /var/vols/itom/audit/auditns/log download the new audit service helm chart to download the audit helm chart to the bastion node, follow these steps: log ",
    "keywordsLower": [
      "1.2.0",
      "cert_two.crt",
      "re_ca_intalb.crt",
      "re_ca_db.crt",
      "cert_one.crt",
      "backup.yaml",
      "pv.yaml",
      "re_ca_idm.crt",
      "x.zip",
      "dd.yaml",
      "secret.yaml",
      "value.yaml",
      "xx.tgz",
      "values.yaml",
      "gen_secrets.sh",
      "upgrade",
      "audit",
      "managed",
      "kubernetes",
      "back",
      "service",
      "download",
      "new",
      "helm",
      "chart",
      "upload",
      "images",
      "collector",
      "restore",
      "enable",
      "indexing",
      "existing",
      "tenants",
      "page",
      "contains",
      "steps",
      "aws",
      "eks",
      "openshift",
      "environment.",
      "need",
      "both",
      "collector.",
      "section",
      "gives",
      "files",
      "data",
      "database.",
      "all",
      "configuration",
      "using.",
      "example",
      "file",
      "audit-secret.yaml",
      "tar",
      "certificates.",
      "itom-audit-pv.yaml",
      "file.",
      "following",
      "amazon",
      "elastic",
      "system",
      "efs",
      "network",
      "nfs",
      "volumes",
      "deployment",
      "component",
      "volume",
      "name",
      "description",
      "directory",
      "path",
      "as-vault-volume-",
      "stores",
      "files.",
      "var",
      "vols",
      "itom",
      "auditns",
      "vault",
      "as-log-volume-",
      "logs",
      "generated",
      "audit.",
      "log",
      "bastion",
      "node",
      "follow",
      "navigate",
      "want",
      "install",
      "service.",
      "create",
      "folder",
      "audit-2x.x.",
      "mkdir",
      "audit-2x.x",
      "cd",
      "software"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Upgrade the Kubernetes cluster (managed Kubernetes)",
    "content": "After you have upgraded OMT and the suite (and other applications such as UD/UCMDB), the last step of the upgrade process is to upgrade the Kubernetes cluster to a supported version for this release. To avoid upgrade issues, it is recommended you follow the tested support matrix for your platform (EKS, AKS, OpenShift, and GCP) and use the managed Kubernetes version supported for this release. Validate the support matrix before you perform any Kubernetes upgrade on your provider side. In case the Kubernetes version listed in the support matrix for the current release is not longer supported by the provider, contact OpenText support for guidance. For example, if GCP supports GKE v1.29 and above, but the current release you plan to upgrade to only supports GKE v1.27 and v1.28, you should seek support. The Kubernetes upgrade will cause system downtime. Perform the upgrade in a planned maintenance window. For EKS only, make sure you use Force update as the update strategy, and it takes over",
    "url": "upgradek8s",
    "filename": "upgradek8s",
    "headings": [],
    "keywords": [
      "v1.28",
      "v1.27",
      "v1.29",
      "upgrade",
      "kubernetes",
      "cluster",
      "managed",
      "after",
      "upgraded",
      "omt",
      "suite",
      "applications",
      "such",
      "ud",
      "ucmdb",
      "last",
      "step",
      "process",
      "supported",
      "version",
      "release.",
      "avoid",
      "issues",
      "recommended",
      "follow",
      "tested",
      "support",
      "matrix",
      "platform",
      "eks",
      "aks",
      "openshift",
      "gcp",
      "validate",
      "before",
      "perform",
      "any",
      "provider",
      "side.",
      "case",
      "listed",
      "current",
      "release",
      "longer",
      "contact",
      "opentext",
      "guidance.",
      "example",
      "supports",
      "gke",
      "above",
      "plan",
      "seek",
      "support.",
      "cause",
      "system",
      "downtime.",
      "planned",
      "maintenance",
      "window.",
      "make",
      "sure",
      "force",
      "update",
      "strategy",
      "takes",
      "over",
      "hour",
      "time",
      "there",
      "about",
      "15",
      "minutes",
      "downtime",
      "during",
      "update.",
      "deployment",
      "following",
      "steps",
      "official",
      "documentation",
      "cloud",
      "eks.",
      "upgrading",
      "all",
      "pods",
      "running.",
      "infra-rabbitmq-",
      "pod",
      "isn",
      "ready",
      "see",
      "rabbitmq",
      "solution."
    ],
    "language": "en",
    "word_count": 101,
    "importance_score": 2.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "upgrade the kubernetes cluster (managed kubernetes)",
    "contentLower": "after you have upgraded omt and the suite (and other applications such as ud/ucmdb), the last step of the upgrade process is to upgrade the kubernetes cluster to a supported version for this release. to avoid upgrade issues, it is recommended you follow the tested support matrix for your platform (eks, aks, openshift, and gcp) and use the managed kubernetes version supported for this release. validate the support matrix before you perform any kubernetes upgrade on your provider side. in case the kubernetes version listed in the support matrix for the current release is not longer supported by the provider, contact opentext support for guidance. for example, if gcp supports gke v1.29 and above, but the current release you plan to upgrade to only supports gke v1.27 and v1.28, you should seek support. the kubernetes upgrade will cause system downtime. perform the upgrade in a planned maintenance window. for eks only, make sure you use force update as the update strategy, and it takes over",
    "keywordsLower": [
      "v1.28",
      "v1.27",
      "v1.29",
      "upgrade",
      "kubernetes",
      "cluster",
      "managed",
      "after",
      "upgraded",
      "omt",
      "suite",
      "applications",
      "such",
      "ud",
      "ucmdb",
      "last",
      "step",
      "process",
      "supported",
      "version",
      "release.",
      "avoid",
      "issues",
      "recommended",
      "follow",
      "tested",
      "support",
      "matrix",
      "platform",
      "eks",
      "aks",
      "openshift",
      "gcp",
      "validate",
      "before",
      "perform",
      "any",
      "provider",
      "side.",
      "case",
      "listed",
      "current",
      "release",
      "longer",
      "contact",
      "opentext",
      "guidance.",
      "example",
      "supports",
      "gke",
      "above",
      "plan",
      "seek",
      "support.",
      "cause",
      "system",
      "downtime.",
      "planned",
      "maintenance",
      "window.",
      "make",
      "sure",
      "force",
      "update",
      "strategy",
      "takes",
      "over",
      "hour",
      "time",
      "there",
      "about",
      "15",
      "minutes",
      "downtime",
      "during",
      "update.",
      "deployment",
      "following",
      "steps",
      "official",
      "documentation",
      "cloud",
      "eks.",
      "upgrading",
      "all",
      "pods",
      "running.",
      "infra-rabbitmq-",
      "pod",
      "isn",
      "ready",
      "see",
      "rabbitmq",
      "solution."
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Upgrade OO components",
    "content": "This section provides the instructions to help you upgrade OO Workflow Designer and OO External RAS. Upgrade OO Workflow Designer Upgrade OO External RAS",
    "url": "upgradeoocomponents",
    "filename": "upgradeoocomponents",
    "headings": [],
    "keywords": [
      "upgrade",
      "oo",
      "components",
      "section",
      "provides",
      "instructions",
      "help",
      "workflow",
      "designer",
      "external",
      "ras.",
      "ras"
    ],
    "language": "en",
    "word_count": 22,
    "importance_score": 2.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "upgrade oo components",
    "contentLower": "this section provides the instructions to help you upgrade oo workflow designer and oo external ras. upgrade oo workflow designer upgrade oo external ras",
    "keywordsLower": [
      "upgrade",
      "oo",
      "components",
      "section",
      "provides",
      "instructions",
      "help",
      "workflow",
      "designer",
      "external",
      "ras.",
      "ras"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Upgrade OO Workflow Designer",
    "content": "This topic contains the instructions to upgrade an OO Workflow Designer on Windows and Linux environments. Plan Before you start the upgrade process, make sure you meet the System requirements. Prerequisite tasks Review flow statuses Cancel or finish all paused or running flows and disable existing schedules before you apply the upgrade. If there are flows running or paused when you perform the upgrade, it won't be possible to resume them. Their status will appear “Canceled” and the duration will be “0 seconds.” Stop the OO Workflow Designer service It's recommended to stop the OO Workflow Designer service. To stop the OO Workflow Designer service in Windows: Navigate to Windows>Task Manager>Services. Right-click to select an OO Workflow Designer, and then select Stop. To stop the OO Workflow Designer service in Linux: Navigate to <Install Location>/<oo Workflow Designer>/bin. Open the terminal and type the command: ./<oo Workflow Designer> stop Make sure to close the OO Workflow Desig",
    "url": "upgradeooworkflowdesigner",
    "filename": "upgradeooworkflowdesigner",
    "headings": [
      "Plan",
      "Prerequisite tasks",
      "Review flow statuses",
      "Stop the OO Workflow Designer service",
      "Steps to upgrade when OO Workflow Designer database uses Windows Authentication towards an SQL Server",
      "Download OO Workflow Designer upgrade package",
      "Verify the integrity of the OO upgrade packages",
      "Extract the upgrade packages",
      "Upgrade procedure",
      "Upgrade OO using an interactive mode",
      "Upgrade in Windows",
      "Upgrade in Linux",
      "Upgrade OO Workflow Designer in silent mode",
      "Silent upgrade in Windows",
      "Silent upgrade in Linux",
      "Post upgrade tasks",
      "Download and install drivers",
      "Oracle drivers",
      "Clean up after upgrade",
      "Review the log files post-upgrade"
    ],
    "keywords": [
      "12.1.0",
      "upgrade.bat",
      "upgrade.log",
      "10.02",
      "11.2.3",
      "sqljdbc_auth.dll",
      "12.1.0.2",
      "19.3.0.0",
      "19.3.0",
      "upgrade",
      "oo",
      "workflow",
      "designer",
      "plan",
      "prerequisite",
      "tasks",
      "review",
      "flow",
      "statuses",
      "stop",
      "service",
      "steps",
      "database",
      "uses",
      "windows",
      "authentication",
      "towards",
      "sql",
      "server",
      "download",
      "package",
      "verify",
      "integrity",
      "packages",
      "extract",
      "procedure",
      "interactive",
      "mode",
      "linux",
      "silent",
      "post",
      "install",
      "drivers",
      "oracle",
      "clean",
      "after",
      "log",
      "files",
      "post-upgrade",
      "related",
      "topics",
      "topic",
      "contains",
      "instructions",
      "environments.",
      "before",
      "start",
      "process",
      "make",
      "sure",
      "meet",
      "system",
      "requirements.",
      "cancel",
      "finish",
      "all",
      "paused",
      "running",
      "flows",
      "disable",
      "existing",
      "schedules",
      "apply",
      "upgrade.",
      "there",
      "perform",
      "won",
      "possible",
      "resume",
      "them.",
      "status",
      "appear",
      "canceled",
      "duration",
      "seconds.",
      "recommended",
      "service.",
      "navigate",
      "task",
      "manager",
      "services.",
      "right-click",
      "select",
      "stop.",
      "bin.",
      "open",
      "terminal",
      "type",
      "command",
      "close"
    ],
    "language": "en",
    "word_count": 107,
    "importance_score": 6.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "upgrade oo workflow designer",
    "contentLower": "this topic contains the instructions to upgrade an oo workflow designer on windows and linux environments. plan before you start the upgrade process, make sure you meet the system requirements. prerequisite tasks review flow statuses cancel or finish all paused or running flows and disable existing schedules before you apply the upgrade. if there are flows running or paused when you perform the upgrade, it won't be possible to resume them. their status will appear “canceled” and the duration will be “0 seconds.” stop the oo workflow designer service it's recommended to stop the oo workflow designer service. to stop the oo workflow designer service in windows: navigate to windows>task manager>services. right-click to select an oo workflow designer, and then select stop. to stop the oo workflow designer service in linux: navigate to <install location>/<oo workflow designer>/bin. open the terminal and type the command: ./<oo workflow designer> stop make sure to close the oo workflow desig",
    "keywordsLower": [
      "12.1.0",
      "upgrade.bat",
      "upgrade.log",
      "10.02",
      "11.2.3",
      "sqljdbc_auth.dll",
      "12.1.0.2",
      "19.3.0.0",
      "19.3.0",
      "upgrade",
      "oo",
      "workflow",
      "designer",
      "plan",
      "prerequisite",
      "tasks",
      "review",
      "flow",
      "statuses",
      "stop",
      "service",
      "steps",
      "database",
      "uses",
      "windows",
      "authentication",
      "towards",
      "sql",
      "server",
      "download",
      "package",
      "verify",
      "integrity",
      "packages",
      "extract",
      "procedure",
      "interactive",
      "mode",
      "linux",
      "silent",
      "post",
      "install",
      "drivers",
      "oracle",
      "clean",
      "after",
      "log",
      "files",
      "post-upgrade",
      "related",
      "topics",
      "topic",
      "contains",
      "instructions",
      "environments.",
      "before",
      "start",
      "process",
      "make",
      "sure",
      "meet",
      "system",
      "requirements.",
      "cancel",
      "finish",
      "all",
      "paused",
      "running",
      "flows",
      "disable",
      "existing",
      "schedules",
      "apply",
      "upgrade.",
      "there",
      "perform",
      "won",
      "possible",
      "resume",
      "them.",
      "status",
      "appear",
      "canceled",
      "duration",
      "seconds.",
      "recommended",
      "service.",
      "navigate",
      "task",
      "manager",
      "services.",
      "right-click",
      "select",
      "stop.",
      "bin.",
      "open",
      "terminal",
      "type",
      "command",
      "close"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Upgrade External OO RAS",
    "content": "This topic contains the instructions to upgrade External Operations Orchestration RAS (OO RAS). Prerequisites Before you upgrade External OO RAS, make sure you have: Downloaded the upgrade package (upgrader-ras-<latest_version>.zip) onto your local file system. Contact your administrator for the upgrade package, or Download the upgrade package from the user interface of the product. For product-specific details, see the related topics given below. Verified the integrity of the External OO RAS upgrade package. Verify the integrity of the External OO RAS upgrade package To verify the integrity of the upgrade zip and the embedded digital signature certificates: Download the latest JDK from the Oracle site. Install it in a suitable location on your local file system and locate your jarsigner utility under: <JDK_INSTALLATION>/bin Run the following command from the command line: jarsigner -verify -keystore <oo_installation>/ras/var/security/internal.truststore -strict -verbose -certs <zip_fi",
    "url": "upgradeonpremras",
    "filename": "upgradeonpremras",
    "headings": [
      "Prerequisites",
      "Verify the integrity of the External OO RAS upgrade package",
      "Upgrade steps for an External OO RAS",
      "Upgrade in Windows",
      "Upgrade in Linux",
      "Related topics"
    ],
    "keywords": [
      "upgrade",
      "external",
      "oo",
      "ras",
      "prerequisites",
      "verify",
      "integrity",
      "package",
      "steps",
      "windows",
      "linux",
      "related",
      "topics",
      "topic",
      "contains",
      "instructions",
      "operations",
      "orchestration",
      "before",
      "make",
      "sure",
      "downloaded",
      "upgrader-ras-.zip",
      "onto",
      "local",
      "file",
      "system.",
      "contact",
      "administrator",
      "download",
      "user",
      "interface",
      "product.",
      "product-specific",
      "details",
      "see",
      "given",
      "below.",
      "verified",
      "package.",
      "zip",
      "embedded",
      "digital",
      "signature",
      "certificates",
      "latest",
      "jdk",
      "oracle",
      "site.",
      "install",
      "suitable",
      "location",
      "system",
      "locate",
      "jarsigner",
      "utility",
      "under",
      "bin",
      "run",
      "following",
      "command",
      "line",
      "-verify",
      "-keystore",
      "var",
      "security",
      "internal.truststore",
      "-strict",
      "-verbose",
      "-certs",
      "output",
      "messages",
      "jar",
      "secure.",
      "unsigned",
      "isn",
      "all",
      "entries",
      "listed",
      "smk",
      "label.",
      "extract",
      "temp",
      "folder",
      "already",
      "installed",
      "ras.",
      "copy",
      "upgrader-ras-",
      "paste",
      "folder.",
      "navigate",
      "press",
      "shift",
      "right-click",
      "level",
      "select",
      "open",
      "prompt",
      "here."
    ],
    "language": "en",
    "word_count": 102,
    "importance_score": 6.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "upgrade external oo ras",
    "contentLower": "this topic contains the instructions to upgrade external operations orchestration ras (oo ras). prerequisites before you upgrade external oo ras, make sure you have: downloaded the upgrade package (upgrader-ras-<latest_version>.zip) onto your local file system. contact your administrator for the upgrade package, or download the upgrade package from the user interface of the product. for product-specific details, see the related topics given below. verified the integrity of the external oo ras upgrade package. verify the integrity of the external oo ras upgrade package to verify the integrity of the upgrade zip and the embedded digital signature certificates: download the latest jdk from the oracle site. install it in a suitable location on your local file system and locate your jarsigner utility under: <jdk_installation>/bin run the following command from the command line: jarsigner -verify -keystore <oo_installation>/ras/var/security/internal.truststore -strict -verbose -certs <zip_fi",
    "keywordsLower": [
      "upgrade",
      "external",
      "oo",
      "ras",
      "prerequisites",
      "verify",
      "integrity",
      "package",
      "steps",
      "windows",
      "linux",
      "related",
      "topics",
      "topic",
      "contains",
      "instructions",
      "operations",
      "orchestration",
      "before",
      "make",
      "sure",
      "downloaded",
      "upgrader-ras-.zip",
      "onto",
      "local",
      "file",
      "system.",
      "contact",
      "administrator",
      "download",
      "user",
      "interface",
      "product.",
      "product-specific",
      "details",
      "see",
      "given",
      "below.",
      "verified",
      "package.",
      "zip",
      "embedded",
      "digital",
      "signature",
      "certificates",
      "latest",
      "jdk",
      "oracle",
      "site.",
      "install",
      "suitable",
      "location",
      "system",
      "locate",
      "jarsigner",
      "utility",
      "under",
      "bin",
      "run",
      "following",
      "command",
      "line",
      "-verify",
      "-keystore",
      "var",
      "security",
      "internal.truststore",
      "-strict",
      "-verbose",
      "-certs",
      "output",
      "messages",
      "jar",
      "secure.",
      "unsigned",
      "isn",
      "all",
      "entries",
      "listed",
      "smk",
      "label.",
      "extract",
      "temp",
      "folder",
      "already",
      "installed",
      "ras.",
      "copy",
      "upgrader-ras-",
      "paste",
      "folder.",
      "navigate",
      "press",
      "shift",
      "right-click",
      "level",
      "select",
      "open",
      "prompt",
      "here."
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Use endpoints",
    "content": "To set up an integration with an on-premises application through the On-Premises Bridge (OPB) agent, you must add an endpoint. Additionally, if you want to run REST calls without using the OPB agent or to set up an integration based on the Integration Studio, you also must add an endpoint. The following endpoint types are available: UCMDB 10.20 and later: used to set up an integration with classic UCMDB for Configuration Item (CI) synchronization Knowledge Indexing: used to set up an integration to index knowledge articles from other applications such as SharePoint and Confluence into Service Management so that agent users and Service Portal users can access them through search Email Integration: used to set up an integration with an inbox on an external mail server so that users can request appropriate knowledge articles, create requests, and add comments or accept solutions to existing requests without the need to log in REST Executor 1.0: used to run REST calls through the OPB agent",
    "url": "opbuseendpoints",
    "filename": "opbuseendpoints",
    "headings": [
      "Add an endpoint",
      "Configure an endpoint",
      "Endpoint details",
      "UCMDB 10.20 and later",
      "Knowledge Indexing",
      "Email Integration",
      "Rest Executor 1.0",
      "Rest Executor 2.0",
      "Agentless Rest Executor 1.0",
      "Operations Orchestration",
      "Operations Orchestration Containerized",
      "PPM Outbound Integration",
      "PPM Optimization Solver",
      "LDAP Integration",
      "JDBC Query",
      "LDAP Query",
      "File System",
      "Configure a proxy for an endpoint type if necessary",
      "Configure a proxy for the Rest Executor 1.0 domain",
      "Configure a proxy for the Rest Executor 2.0 domain"
    ],
    "keywords": [
      "ldaps://<host_name",
      "https://myhost.mycompany.net:443/246687036",
      "1.8.0",
      "wrapper.java",
      "10.20",
      "additional.210",
      "postgresql://<host_name",
      "opb.all",
      "custom.conf",
      "additional.211",
      "mycompany.net",
      "Dopb.all",
      "1.0",
      "2.0",
      "example.com",
      "https://myhost.mycompany.net:8444",
      "Exchange.asmx",
      "sqlserver:////<host_name",
      "ldap://<host_name",
      "cbc.exe",
      "endpoints",
      "add",
      "endpoint",
      "configure",
      "details",
      "ucmdb",
      "later",
      "knowledge",
      "indexing",
      "email",
      "integration",
      "rest",
      "executor",
      "agentless",
      "operations",
      "orchestration",
      "containerized",
      "ppm",
      "outbound",
      "optimization",
      "solver",
      "ldap",
      "jdbc",
      "query",
      "file",
      "system",
      "proxy",
      "type",
      "necessary",
      "domain",
      "related",
      "topics",
      "set",
      "on-premises",
      "application",
      "through",
      "bridge",
      "opb",
      "agent",
      "endpoint.",
      "additionally",
      "want",
      "run",
      "calls",
      "based",
      "studio",
      "following",
      "types",
      "available",
      "classic",
      "configuration",
      "item",
      "ci",
      "synchronization",
      "index",
      "articles",
      "applications",
      "such",
      "sharepoint",
      "confluence",
      "service",
      "management",
      "users",
      "portal",
      "access",
      "search",
      "inbox",
      "external",
      "mail",
      "server",
      "request",
      "appropriate",
      "create",
      "requests",
      "comments",
      "accept",
      "solutions",
      "existing",
      "need",
      "log"
    ],
    "language": "en",
    "word_count": 94,
    "importance_score": 6.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "use endpoints",
    "contentLower": "to set up an integration with an on-premises application through the on-premises bridge (opb) agent, you must add an endpoint. additionally, if you want to run rest calls without using the opb agent or to set up an integration based on the integration studio, you also must add an endpoint. the following endpoint types are available: ucmdb 10.20 and later: used to set up an integration with classic ucmdb for configuration item (ci) synchronization knowledge indexing: used to set up an integration to index knowledge articles from other applications such as sharepoint and confluence into service management so that agent users and service portal users can access them through search email integration: used to set up an integration with an inbox on an external mail server so that users can request appropriate knowledge articles, create requests, and add comments or accept solutions to existing requests without the need to log in rest executor 1.0: used to run rest calls through the opb agent",
    "keywordsLower": [
      "ldaps://<host_name",
      "https://myhost.mycompany.net:443/246687036",
      "1.8.0",
      "wrapper.java",
      "10.20",
      "additional.210",
      "postgresql://<host_name",
      "opb.all",
      "custom.conf",
      "additional.211",
      "mycompany.net",
      "dopb.all",
      "1.0",
      "2.0",
      "example.com",
      "https://myhost.mycompany.net:8444",
      "exchange.asmx",
      "sqlserver:////<host_name",
      "ldap://<host_name",
      "cbc.exe",
      "endpoints",
      "add",
      "endpoint",
      "configure",
      "details",
      "ucmdb",
      "later",
      "knowledge",
      "indexing",
      "email",
      "integration",
      "rest",
      "executor",
      "agentless",
      "operations",
      "orchestration",
      "containerized",
      "ppm",
      "outbound",
      "optimization",
      "solver",
      "ldap",
      "jdbc",
      "query",
      "file",
      "system",
      "proxy",
      "type",
      "necessary",
      "domain",
      "related",
      "topics",
      "set",
      "on-premises",
      "application",
      "through",
      "bridge",
      "opb",
      "agent",
      "endpoint.",
      "additionally",
      "want",
      "run",
      "calls",
      "based",
      "studio",
      "following",
      "types",
      "available",
      "classic",
      "configuration",
      "item",
      "ci",
      "synchronization",
      "index",
      "articles",
      "applications",
      "such",
      "sharepoint",
      "confluence",
      "service",
      "management",
      "users",
      "portal",
      "access",
      "search",
      "inbox",
      "external",
      "mail",
      "server",
      "request",
      "appropriate",
      "create",
      "requests",
      "comments",
      "accept",
      "solutions",
      "existing",
      "need",
      "log"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Working with external systems",
    "content": "To perform an integration with an external system, follow these steps: Add an external system. For more information, see the How to add an external system section. Assign the external system to a group, using the External system field on the Groups page. This makes the group an external group. For more information, see Groups. Select an incident in Incident Management, a request in Service Request Management, or a change in Change Management. In the General tab, under Assignment, select an external group from the drop-down list for the Service desk group or Expert group field, according to the option selected for the Current assignment field. A new section, External Assignment, is added to the incident, change, or request page. The data in this section is populated automatically by the external system. How to add an external system From the main menu, select Administration > Utilities > Integration > External systems. Click New to open the New External system dialog box. Enter a System",
    "url": "workwithexternalsys",
    "filename": "workwithexternalsys",
    "headings": [
      "How to add an external system",
      "How to edit an external system",
      "Supported operations",
      "Related topics"
    ],
    "keywords": [
      "1.0",
      "RegisteredForActualService.Id",
      "working",
      "external",
      "systems",
      "add",
      "system",
      "edit",
      "supported",
      "operations",
      "related",
      "topics",
      "perform",
      "integration",
      "follow",
      "steps",
      "system.",
      "information",
      "see",
      "section.",
      "assign",
      "group",
      "field",
      "groups",
      "page.",
      "makes",
      "group.",
      "groups.",
      "select",
      "incident",
      "management",
      "request",
      "service",
      "change",
      "management.",
      "general",
      "tab",
      "under",
      "assignment",
      "drop-down",
      "list",
      "desk",
      "expert",
      "according",
      "option",
      "selected",
      "current",
      "field.",
      "new",
      "section",
      "added",
      "data",
      "populated",
      "automatically",
      "main",
      "menu",
      "administration",
      "utilities",
      "systems.",
      "click",
      "open",
      "dialog",
      "box.",
      "enter",
      "id",
      "identify",
      "included",
      "payloads",
      "sent",
      "description",
      "describe",
      "tool",
      "connected",
      "used.",
      "authorized",
      "user",
      "list.",
      "access",
      "optionally",
      "default",
      "actual",
      "value.",
      "value",
      "case",
      "exchange",
      "api",
      "creating",
      "record.",
      "assigns",
      "record",
      "based",
      "following",
      "fields",
      "listed",
      "highest",
      "lowest",
      "priority",
      "json",
      "body",
      "rest"
    ],
    "language": "en",
    "word_count": 102,
    "importance_score": 5.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "working with external systems",
    "contentLower": "to perform an integration with an external system, follow these steps: add an external system. for more information, see the how to add an external system section. assign the external system to a group, using the external system field on the groups page. this makes the group an external group. for more information, see groups. select an incident in incident management, a request in service request management, or a change in change management. in the general tab, under assignment, select an external group from the drop-down list for the service desk group or expert group field, according to the option selected for the current assignment field. a new section, external assignment, is added to the incident, change, or request page. the data in this section is populated automatically by the external system. how to add an external system from the main menu, select administration > utilities > integration > external systems. click new to open the new external system dialog box. enter a system",
    "keywordsLower": [
      "1.0",
      "registeredforactualservice.id",
      "working",
      "external",
      "systems",
      "add",
      "system",
      "edit",
      "supported",
      "operations",
      "related",
      "topics",
      "perform",
      "integration",
      "follow",
      "steps",
      "system.",
      "information",
      "see",
      "section.",
      "assign",
      "group",
      "field",
      "groups",
      "page.",
      "makes",
      "group.",
      "groups.",
      "select",
      "incident",
      "management",
      "request",
      "service",
      "change",
      "management.",
      "general",
      "tab",
      "under",
      "assignment",
      "drop-down",
      "list",
      "desk",
      "expert",
      "according",
      "option",
      "selected",
      "current",
      "field.",
      "new",
      "section",
      "added",
      "data",
      "populated",
      "automatically",
      "main",
      "menu",
      "administration",
      "utilities",
      "systems.",
      "click",
      "open",
      "dialog",
      "box.",
      "enter",
      "id",
      "identify",
      "included",
      "payloads",
      "sent",
      "description",
      "describe",
      "tool",
      "connected",
      "used.",
      "authorized",
      "user",
      "list.",
      "access",
      "optionally",
      "default",
      "actual",
      "value.",
      "value",
      "case",
      "exchange",
      "api",
      "creating",
      "record.",
      "assigns",
      "record",
      "based",
      "following",
      "fields",
      "listed",
      "highest",
      "lowest",
      "priority",
      "json",
      "body",
      "rest"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Use the Integration Studio",
    "content": "This section provides guidelines on how to configure the Integration Studio. It's a best practice to create, configure, and test integrations in the development tenant before you deploy them in the production tenant. The Integration Studio provides an import/export functionality that makes it easier for you to follow this best practice. For details, see Export and import integrations.To use the Integration Studio, including creating or configuring Integration Studio-related endpoints, integrations, and scenarios, you must have the Integration Administrator role. Step 1. Install and configure the OPB agent (optional) If the source Service Management system can directly connect to the target system, there's no need to use the On-Premises Bridge (OPB) agent and you can skip this step. If there's a web application firewall deployed in front of the target system, the source Service Management system needs to use the OPB agent to connect to the target system. For instance, if the source Serv",
    "url": "xieconfiguration",
    "filename": "xieconfiguration",
    "headings": [
      "Step 1. Install and configure the OPB agent (optional)",
      "Step 2. Create an endpoint",
      "Step 3. Create an integration",
      "Step 4. Add and configure scenarios",
      "Step 5. Trigger an integration",
      "Trigger integration by business rule",
      "Trigger integration by task plan",
      "Trigger integration by listener",
      "Trigger integration by scheduler",
      "Trigger integration manually",
      "Step 6. Monitor integration execution status",
      "View execution history on the Execution history page",
      "View execution history on the Endpoints page",
      "Important history fields",
      "Execution history retention period",
      "Related topics"
    ],
    "keywords": [
      "integrations.To",
      "integration.In",
      "keystore.In",
      "current_user.Upn",
      "Integration.Go",
      "satisfied.Save",
      "endpoint.If",
      "Studio.In",
      "endpoint.See",
      "plans.Open",
      "plan.Go",
      "2.0",
      "rule.In",
      "opens.In",
      "integration",
      "studio",
      "step",
      "1.",
      "install",
      "configure",
      "opb",
      "agent",
      "optional",
      "2.",
      "create",
      "endpoint",
      "3.",
      "4.",
      "add",
      "scenarios",
      "5.",
      "trigger",
      "business",
      "rule",
      "task",
      "plan",
      "listener",
      "scheduler",
      "manually",
      "6.",
      "monitor",
      "execution",
      "status",
      "view",
      "history",
      "page",
      "endpoints",
      "important",
      "fields",
      "retention",
      "period",
      "related",
      "topics",
      "section",
      "provides",
      "guidelines",
      "studio.",
      "best",
      "practice",
      "test",
      "integrations",
      "development",
      "tenant",
      "before",
      "deploy",
      "production",
      "tenant.",
      "import",
      "export",
      "functionality",
      "makes",
      "easier",
      "follow",
      "practice.",
      "details",
      "see",
      "including",
      "creating",
      "configuring",
      "studio-related",
      "administrator",
      "role.",
      "source",
      "service",
      "management",
      "system",
      "directly",
      "connect",
      "target",
      "there",
      "need",
      "on-premises",
      "bridge",
      "skip",
      "step.",
      "web",
      "application",
      "firewall",
      "deployed",
      "front"
    ],
    "language": "en",
    "word_count": 96,
    "importance_score": 6.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "use the integration studio",
    "contentLower": "this section provides guidelines on how to configure the integration studio. it's a best practice to create, configure, and test integrations in the development tenant before you deploy them in the production tenant. the integration studio provides an import/export functionality that makes it easier for you to follow this best practice. for details, see export and import integrations.to use the integration studio, including creating or configuring integration studio-related endpoints, integrations, and scenarios, you must have the integration administrator role. step 1. install and configure the opb agent (optional) if the source service management system can directly connect to the target system, there's no need to use the on-premises bridge (opb) agent and you can skip this step. if there's a web application firewall deployed in front of the target system, the source service management system needs to use the opb agent to connect to the target system. for instance, if the source serv",
    "keywordsLower": [
      "integrations.to",
      "integration.in",
      "keystore.in",
      "current_user.upn",
      "integration.go",
      "satisfied.save",
      "endpoint.if",
      "studio.in",
      "endpoint.see",
      "plans.open",
      "plan.go",
      "2.0",
      "rule.in",
      "opens.in",
      "integration",
      "studio",
      "step",
      "1.",
      "install",
      "configure",
      "opb",
      "agent",
      "optional",
      "2.",
      "create",
      "endpoint",
      "3.",
      "4.",
      "add",
      "scenarios",
      "5.",
      "trigger",
      "business",
      "rule",
      "task",
      "plan",
      "listener",
      "scheduler",
      "manually",
      "6.",
      "monitor",
      "execution",
      "status",
      "view",
      "history",
      "page",
      "endpoints",
      "important",
      "fields",
      "retention",
      "period",
      "related",
      "topics",
      "section",
      "provides",
      "guidelines",
      "studio.",
      "best",
      "practice",
      "test",
      "integrations",
      "development",
      "tenant",
      "before",
      "deploy",
      "production",
      "tenant.",
      "import",
      "export",
      "functionality",
      "makes",
      "easier",
      "follow",
      "practice.",
      "details",
      "see",
      "including",
      "creating",
      "configuring",
      "studio-related",
      "administrator",
      "role.",
      "source",
      "service",
      "management",
      "system",
      "directly",
      "connect",
      "target",
      "there",
      "need",
      "on-premises",
      "bridge",
      "skip",
      "step.",
      "web",
      "application",
      "firewall",
      "deployed",
      "front"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Work with scenario rules",
    "content": "This page describes different types of scenario rules and how to use them to build the scenario logic. Understand scenario rules Scenario rules are the building blocks of a scenario. You build the scenario logic by adding scenario rules sequentially. When the Integration Studio runs a scenario, it runs the scenario rules from top to bottom (except for the loop action rules). Conceptually, rules and actions are different. Rules are the building blocks of scenarios, and actions serve as the blueprint from which different instances of rules can be created. But other than this, they are very similar. For simplicity, we use the terms rule and action interchangeably in many places throughout the Integration Studio documentation. Categorization Scenario rules can be categorized into these types, according to the action performed when the system runs the rule: Target system rules (rules that are based on actions associated with a connector): execute an action against the target system endpoint",
    "url": "workwithscenariorules",
    "filename": "workwithscenariorules",
    "headings": [
      "Understand scenario rules",
      "Categorization",
      "Structure",
      "Add scenario rules",
      "Enter parameter values",
      "Identify and work with fields that support the expression language",
      "Use the Expression Editor and Data pane to work with this type of fields",
      "Identify fields that support the JSON payload expression",
      "Navigate scenario rules",
      "Manage scenario rules"
    ],
    "keywords": [
      "work",
      "scenario",
      "rules",
      "understand",
      "categorization",
      "structure",
      "add",
      "enter",
      "parameter",
      "values",
      "identify",
      "fields",
      "support",
      "expression",
      "language",
      "editor",
      "data",
      "pane",
      "type",
      "json",
      "payload",
      "navigate",
      "manage",
      "page",
      "describes",
      "different",
      "types",
      "build",
      "logic.",
      "building",
      "blocks",
      "scenario.",
      "logic",
      "adding",
      "sequentially.",
      "integration",
      "studio",
      "runs",
      "top",
      "bottom",
      "except",
      "loop",
      "action",
      "conceptually",
      "actions",
      "different.",
      "scenarios",
      "serve",
      "blueprint",
      "instances",
      "created.",
      "very",
      "similar.",
      "simplicity",
      "terms",
      "rule",
      "interchangeably",
      "many",
      "places",
      "throughout",
      "documentation.",
      "categorized",
      "according",
      "performed",
      "system",
      "target",
      "based",
      "associated",
      "connector",
      "execute",
      "against",
      "endpoint",
      "specified",
      "configuration.",
      "local",
      "current",
      "service",
      "management",
      "system.",
      "common",
      "manipulate",
      "perform",
      "control",
      "operations",
      "see",
      "connectors",
      "list",
      "available",
      "built-in",
      "actions.",
      "same",
      "standard",
      "structure.",
      "consist",
      "following",
      "sections",
      "condition",
      "allows",
      "specify",
      "conditions"
    ],
    "language": "en",
    "word_count": 93,
    "importance_score": 6.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "work with scenario rules",
    "contentLower": "this page describes different types of scenario rules and how to use them to build the scenario logic. understand scenario rules scenario rules are the building blocks of a scenario. you build the scenario logic by adding scenario rules sequentially. when the integration studio runs a scenario, it runs the scenario rules from top to bottom (except for the loop action rules). conceptually, rules and actions are different. rules are the building blocks of scenarios, and actions serve as the blueprint from which different instances of rules can be created. but other than this, they are very similar. for simplicity, we use the terms rule and action interchangeably in many places throughout the integration studio documentation. categorization scenario rules can be categorized into these types, according to the action performed when the system runs the rule: target system rules (rules that are based on actions associated with a connector): execute an action against the target system endpoint",
    "keywordsLower": [
      "work",
      "scenario",
      "rules",
      "understand",
      "categorization",
      "structure",
      "add",
      "enter",
      "parameter",
      "values",
      "identify",
      "fields",
      "support",
      "expression",
      "language",
      "editor",
      "data",
      "pane",
      "type",
      "json",
      "payload",
      "navigate",
      "manage",
      "page",
      "describes",
      "different",
      "types",
      "build",
      "logic.",
      "building",
      "blocks",
      "scenario.",
      "logic",
      "adding",
      "sequentially.",
      "integration",
      "studio",
      "runs",
      "top",
      "bottom",
      "except",
      "loop",
      "action",
      "conceptually",
      "actions",
      "different.",
      "scenarios",
      "serve",
      "blueprint",
      "instances",
      "created.",
      "very",
      "similar.",
      "simplicity",
      "terms",
      "rule",
      "interchangeably",
      "many",
      "places",
      "throughout",
      "documentation.",
      "categorized",
      "according",
      "performed",
      "system",
      "target",
      "based",
      "associated",
      "connector",
      "execute",
      "against",
      "endpoint",
      "specified",
      "configuration.",
      "local",
      "current",
      "service",
      "management",
      "system.",
      "common",
      "manipulate",
      "perform",
      "control",
      "operations",
      "see",
      "connectors",
      "list",
      "available",
      "built-in",
      "actions.",
      "same",
      "standard",
      "structure.",
      "consist",
      "following",
      "sections",
      "condition",
      "allows",
      "specify",
      "conditions"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "View synchronization results",
    "content": "Service Management's On-Premises Bridge in the Integration Management module allows you to view the results of synchronization. To view synchronization results: From the main menu, select Administration > Utilities > Integration > Endpoints. Service Management displays a list of endpoints in the left pane. Select the endpoint. Service Management displays a list of synchronizations for the endpoint. Click the record identifier in the ID column for the synchronization you want to view. Service Management displays: A summary of the synchronization, including a graphical representation of the success and failure for each synchronization action type. The selected synchronization details in a list. Field Description Label CI label. Record type Whether the CI is a device or system element. Action type The action attempted in synchronization. Status Whether the synchronization of the CI was successful. Failure type If the synchronization of the CI wasn't successful, this displays a summary of ",
    "url": "viewsync",
    "filename": "viewsync",
    "headings": [
      "Related topics"
    ],
    "keywords": [
      "view",
      "synchronization",
      "results",
      "related",
      "topics",
      "service",
      "management",
      "on-premises",
      "bridge",
      "integration",
      "module",
      "allows",
      "synchronization.",
      "main",
      "menu",
      "select",
      "administration",
      "utilities",
      "endpoints.",
      "displays",
      "list",
      "endpoints",
      "left",
      "pane.",
      "endpoint.",
      "synchronizations",
      "click",
      "record",
      "identifier",
      "id",
      "column",
      "want",
      "view.",
      "summary",
      "including",
      "graphical",
      "representation",
      "success",
      "failure",
      "action",
      "type.",
      "selected",
      "details",
      "list.",
      "field",
      "description",
      "label",
      "ci",
      "label.",
      "type",
      "whether",
      "device",
      "system",
      "element.",
      "attempted",
      "status",
      "successful.",
      "wasn",
      "successful",
      "details.",
      "information",
      "show",
      "note",
      "deleted",
      "ucmdb",
      "runs",
      "automatically",
      "updates",
      "missing",
      "parallel",
      "management.",
      "supported",
      "topologies",
      "data",
      "flow",
      "synchronized",
      "configuration",
      "items",
      "cis"
    ],
    "language": "en",
    "word_count": 96,
    "importance_score": 3.5,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "view synchronization results",
    "contentLower": "service management's on-premises bridge in the integration management module allows you to view the results of synchronization. to view synchronization results: from the main menu, select administration > utilities > integration > endpoints. service management displays a list of endpoints in the left pane. select the endpoint. service management displays a list of synchronizations for the endpoint. click the record identifier in the id column for the synchronization you want to view. service management displays: a summary of the synchronization, including a graphical representation of the success and failure for each synchronization action type. the selected synchronization details in a list. field description label ci label. record type whether the ci is a device or system element. action type the action attempted in synchronization. status whether the synchronization of the ci was successful. failure type if the synchronization of the ci wasn't successful, this displays a summary of ",
    "keywordsLower": [
      "view",
      "synchronization",
      "results",
      "related",
      "topics",
      "service",
      "management",
      "on-premises",
      "bridge",
      "integration",
      "module",
      "allows",
      "synchronization.",
      "main",
      "menu",
      "select",
      "administration",
      "utilities",
      "endpoints.",
      "displays",
      "list",
      "endpoints",
      "left",
      "pane.",
      "endpoint.",
      "synchronizations",
      "click",
      "record",
      "identifier",
      "id",
      "column",
      "want",
      "view.",
      "summary",
      "including",
      "graphical",
      "representation",
      "success",
      "failure",
      "action",
      "type.",
      "selected",
      "details",
      "list.",
      "field",
      "description",
      "label",
      "ci",
      "label.",
      "type",
      "whether",
      "device",
      "system",
      "element.",
      "attempted",
      "status",
      "successful.",
      "wasn",
      "successful",
      "details.",
      "information",
      "show",
      "note",
      "deleted",
      "ucmdb",
      "runs",
      "automatically",
      "updates",
      "missing",
      "parallel",
      "management.",
      "supported",
      "topologies",
      "data",
      "flow",
      "synchronized",
      "configuration",
      "items",
      "cis"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Use OData for BI integration",
    "content": "The Business Intelligence (BI) integration module enables you to define the fields and relationships that are synced for a record type when integrating with an external business intelligence system. This can help you export your data to a third-party system with different reporting tools. Alternatively, it's useful for aggregating your data with data from other parts of your organization. In addition to performing the integration using the BI integration API or PostgreSQL Views, you can now use OData as an alternative method for BI integration. What is OData OData (Open Data Protocol) is a standard REST-based protocol used for data exchange between different systems. The current OData version is 4.0, which is approved by ISO/IEC and standardized at OASIS. When used for BI reporting, OData can: Support metadata and data exchange, including relationships Provide all Create, Retrieve, Update, and Delete (CRUD) operations, from which you can use the Retrieve option for reporting purposes A",
    "url": "useodataforbiintegration",
    "filename": "useodataforbiintegration",
    "headings": [
      "What is OData",
      "Advantages of OData",
      "Use OData for BI reporting",
      "Metadata",
      "Authentication method",
      "Generate personal access tokens from Service Portal",
      "Generate the personal access token from Service Management",
      "Generate the personal access token for an integration user",
      "Generate the token by using the SMAX_AUTH_TOKEN cookie",
      "Throttling configurations",
      "Farm level",
      "Tenant level",
      "Supported OData query options",
      "$select",
      "$filter",
      "$top",
      "$skip",
      "$count",
      "$skiptoken",
      "History data retrieval"
    ],
    "keywords": [
      "https://host.example.net:443/datahub/123456789/odata/History?$filter=EntityId",
      "example.net",
      "kubernetes.io",
      "35.301Z",
      "https://host.example.net:443/datahub/123456789/odata/History?$filter=EntityType",
      "4.0",
      "00.000Z",
      "35.301",
      "https://host.example.net:443/datahub/123456789/odata/Request?$filter=Id",
      "https://host.example.net:443/datahub/123456789/odata",
      "postgresql.org",
      "https://www.postgresql.org/docs/current/sql-createindex.html#SQL-CREATEINDEX-CONCURRENTLY",
      "https://<Service",
      "https://<host",
      "2.0",
      "OData.Feed",
      "createindex.html",
      "odata",
      "bi",
      "integration",
      "what",
      "advantages",
      "reporting",
      "metadata",
      "authentication",
      "method",
      "generate",
      "personal",
      "access",
      "tokens",
      "service",
      "portal",
      "token",
      "management",
      "user",
      "cookie",
      "throttling",
      "configurations",
      "farm",
      "level",
      "tenant",
      "supported",
      "query",
      "options",
      "select",
      "filter",
      "top",
      "skip",
      "count",
      "skiptoken",
      "history",
      "data",
      "retrieval",
      "add",
      "indexes",
      "pg",
      "database",
      "l10n",
      "support",
      "limitations",
      "additional",
      "information",
      "connect",
      "source",
      "ssl",
      "optimize",
      "performance",
      "sizing",
      "guide",
      "create",
      "replicas",
      "get",
      "connected",
      "business",
      "intelligence",
      "module",
      "enables",
      "define",
      "fields",
      "relationships",
      "synced",
      "record",
      "type",
      "integrating",
      "external",
      "system.",
      "help",
      "export",
      "third-party",
      "system",
      "different",
      "tools.",
      "alternatively",
      "useful",
      "aggregating",
      "parts",
      "organization.",
      "addition",
      "performing",
      "api"
    ],
    "language": "en",
    "word_count": 94,
    "importance_score": 6.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "use odata for bi integration",
    "contentLower": "the business intelligence (bi) integration module enables you to define the fields and relationships that are synced for a record type when integrating with an external business intelligence system. this can help you export your data to a third-party system with different reporting tools. alternatively, it's useful for aggregating your data with data from other parts of your organization. in addition to performing the integration using the bi integration api or postgresql views, you can now use odata as an alternative method for bi integration. what is odata odata (open data protocol) is a standard rest-based protocol used for data exchange between different systems. the current odata version is 4.0, which is approved by iso/iec and standardized at oasis. when used for bi reporting, odata can: support metadata and data exchange, including relationships provide all create, retrieve, update, and delete (crud) operations, from which you can use the retrieve option for reporting purposes a",
    "keywordsLower": [
      "https://host.example.net:443/datahub/123456789/odata/history?$filter=entityid",
      "example.net",
      "kubernetes.io",
      "35.301z",
      "https://host.example.net:443/datahub/123456789/odata/history?$filter=entitytype",
      "4.0",
      "00.000z",
      "35.301",
      "https://host.example.net:443/datahub/123456789/odata/request?$filter=id",
      "https://host.example.net:443/datahub/123456789/odata",
      "postgresql.org",
      "https://www.postgresql.org/docs/current/sql-createindex.html#sql-createindex-concurrently",
      "https://<service",
      "https://<host",
      "2.0",
      "odata.feed",
      "createindex.html",
      "odata",
      "bi",
      "integration",
      "what",
      "advantages",
      "reporting",
      "metadata",
      "authentication",
      "method",
      "generate",
      "personal",
      "access",
      "tokens",
      "service",
      "portal",
      "token",
      "management",
      "user",
      "cookie",
      "throttling",
      "configurations",
      "farm",
      "level",
      "tenant",
      "supported",
      "query",
      "options",
      "select",
      "filter",
      "top",
      "skip",
      "count",
      "skiptoken",
      "history",
      "data",
      "retrieval",
      "add",
      "indexes",
      "pg",
      "database",
      "l10n",
      "support",
      "limitations",
      "additional",
      "information",
      "connect",
      "source",
      "ssl",
      "optimize",
      "performance",
      "sizing",
      "guide",
      "create",
      "replicas",
      "get",
      "connected",
      "business",
      "intelligence",
      "module",
      "enables",
      "define",
      "fields",
      "relationships",
      "synced",
      "record",
      "type",
      "integrating",
      "external",
      "system.",
      "help",
      "export",
      "third-party",
      "system",
      "different",
      "tools.",
      "alternatively",
      "useful",
      "aggregating",
      "parts",
      "organization.",
      "addition",
      "performing",
      "api"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Use integration user and SMAX_AUTH_TOKEN cookie to access OData",
    "content": "The following example shows how to use an integration user and the SMAX_AUTH_TOKEN cookie to access OData. Before you start, make sure you have met the prerequisites and created the integration user. See Generate a token by using the SMAX_AUTH_TOKEN cookie. Create a query in Power BI To create a blank query in Power BI Desktop, select Home > Get data > Blank query. Run the query in Power Query editor Click the Advanced Editor option. In the Microsoft Power Query editor, paste the following example query. Be sure to replace the placeholders with valid Service Management values. let AuthToken = Text.FromBinary(Web.Contents(\"https://<Service Management host name>/auth/authentication-endpoint/authenticate/token?TENANTID=<tenant ID>\", [Headers = [#\"Content-Type\" = \"application/json\"], Content = Text.ToBinary(\"{\"\"login\"\":\"\"<integration user name>\"\",\"\"password\"\":\"\"<integration user password>\"\"}\")])), Source = OData.Feed(\"https://<Service Management host name>/datahub/<tenant ID>/odata/\", null",
    "url": "intusersmaxauthtokenaccessodata",
    "filename": "intusersmaxauthtokenaccessodata",
    "headings": [
      "Create a query in Power BI",
      "Run the query in Power Query editor",
      "Rename the query",
      "Set the authentication method to Anonymous",
      "Configure privacy settings"
    ],
    "keywords": [
      "smax_auth_token",
      "https://learn.microsoft.com/en-us/power-bi/enterprise/desktop-privacy-levels",
      "microsoft.com",
      "https://<Service",
      "2.0",
      "OData.Feed",
      "integration",
      "user",
      "cookie",
      "access",
      "odata",
      "create",
      "query",
      "power",
      "bi",
      "run",
      "editor",
      "rename",
      "set",
      "authentication",
      "method",
      "anonymous",
      "configure",
      "privacy",
      "settings",
      "following",
      "example",
      "shows",
      "odata.",
      "before",
      "start",
      "make",
      "sure",
      "met",
      "prerequisites",
      "created",
      "user.",
      "see",
      "generate",
      "token",
      "cookie.",
      "blank",
      "desktop",
      "select",
      "home",
      "get",
      "data",
      "query.",
      "click",
      "advanced",
      "option.",
      "microsoft",
      "paste",
      "replace",
      "placeholders",
      "valid",
      "service",
      "management",
      "values.",
      "let",
      "authtoken",
      "text.frombinary",
      "web.contents",
      "https",
      "auth",
      "authentication-endpoint",
      "authenticate",
      "tenantid",
      "headers",
      "content-type",
      "application",
      "json",
      "content",
      "text.tobinary",
      "login",
      "password",
      "source",
      "datahub",
      "null",
      "implementation",
      "note",
      "extra",
      "double",
      "quotes",
      "such",
      "required",
      "syntax",
      "parsing.",
      "don",
      "remove",
      "quotes.",
      "done.",
      "default",
      "name",
      "query1",
      "purpose",
      "clear.",
      "edit",
      "credentials",
      "anonymous."
    ],
    "language": "en",
    "word_count": 93,
    "importance_score": 4.5,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "use integration user and smax_auth_token cookie to access odata",
    "contentLower": "the following example shows how to use an integration user and the smax_auth_token cookie to access odata. before you start, make sure you have met the prerequisites and created the integration user. see generate a token by using the smax_auth_token cookie. create a query in power bi to create a blank query in power bi desktop, select home > get data > blank query. run the query in power query editor click the advanced editor option. in the microsoft power query editor, paste the following example query. be sure to replace the placeholders with valid service management values. let authtoken = text.frombinary(web.contents(\"https://<service management host name>/auth/authentication-endpoint/authenticate/token?tenantid=<tenant id>\", [headers = [#\"content-type\" = \"application/json\"], content = text.tobinary(\"{\"\"login\"\":\"\"<integration user name>\"\",\"\"password\"\":\"\"<integration user password>\"\"}\")])), source = odata.feed(\"https://<service management host name>/datahub/<tenant id>/odata/\", null",
    "keywordsLower": [
      "smax_auth_token",
      "https://learn.microsoft.com/en-us/power-bi/enterprise/desktop-privacy-levels",
      "microsoft.com",
      "https://<service",
      "2.0",
      "odata.feed",
      "integration",
      "user",
      "cookie",
      "access",
      "odata",
      "create",
      "query",
      "power",
      "bi",
      "run",
      "editor",
      "rename",
      "set",
      "authentication",
      "method",
      "anonymous",
      "configure",
      "privacy",
      "settings",
      "following",
      "example",
      "shows",
      "odata.",
      "before",
      "start",
      "make",
      "sure",
      "met",
      "prerequisites",
      "created",
      "user.",
      "see",
      "generate",
      "token",
      "cookie.",
      "blank",
      "desktop",
      "select",
      "home",
      "get",
      "data",
      "query.",
      "click",
      "advanced",
      "option.",
      "microsoft",
      "paste",
      "replace",
      "placeholders",
      "valid",
      "service",
      "management",
      "values.",
      "let",
      "authtoken",
      "text.frombinary",
      "web.contents",
      "https",
      "auth",
      "authentication-endpoint",
      "authenticate",
      "tenantid",
      "headers",
      "content-type",
      "application",
      "json",
      "content",
      "text.tobinary",
      "login",
      "password",
      "source",
      "datahub",
      "null",
      "implementation",
      "note",
      "extra",
      "double",
      "quotes",
      "such",
      "required",
      "syntax",
      "parsing.",
      "don",
      "remove",
      "quotes.",
      "done.",
      "default",
      "name",
      "query1",
      "purpose",
      "clear.",
      "edit",
      "credentials",
      "anonymous."
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Use Power BI to create reports via OData",
    "content": "Use case Your organization wants to create a report that reflects the number of articles distributed in various services. To create the report in Power BI, take the following steps: Connect to the OData feed Open Power BI Desktop. In the Home page, select Get data > OData feed. In the OData feed window, input your OData feed URL in the URL field, and click OK. https://<Service Management host name>:<port number>/datahub/<tenant ID>/odata/ or https://<Service Management host name>:<port number>/datahub/<tenant ID>/odata Power BI Desktop prompts you to enter your credentials. Select Basic and input your user name and password, and then click Save. See Authentication method for detailed information. Now you can connect to the Service Management data. Power BI Desktop displays the available tables and other data elements in the Navigator window. Sort out the data To create a report that reflects the number of articles distributed in various services, you need to import and sort out the dat",
    "url": "powerbireportsviaodata",
    "filename": "powerbireportsviaodata",
    "headings": [
      "Use case",
      "Connect to the OData feed",
      "Sort out the data",
      "Create the report",
      "Refresh the data"
    ],
    "keywords": [
      "https://<Service",
      "power",
      "bi",
      "create",
      "reports",
      "via",
      "odata",
      "case",
      "connect",
      "feed",
      "sort",
      "out",
      "data",
      "report",
      "refresh",
      "organization",
      "wants",
      "reflects",
      "number",
      "articles",
      "distributed",
      "various",
      "services.",
      "take",
      "following",
      "steps",
      "open",
      "desktop.",
      "home",
      "page",
      "select",
      "get",
      "feed.",
      "window",
      "input",
      "url",
      "field",
      "click",
      "ok.",
      "https",
      "datahub",
      "desktop",
      "prompts",
      "enter",
      "credentials.",
      "basic",
      "user",
      "name",
      "password",
      "save.",
      "see",
      "authentication",
      "method",
      "detailed",
      "information.",
      "now",
      "service",
      "management",
      "data.",
      "displays",
      "available",
      "tables",
      "elements",
      "navigator",
      "window.",
      "services",
      "need",
      "import",
      "article",
      "servicedefinition.",
      "servicedefinition",
      "list",
      "load.",
      "after",
      "load",
      "imports",
      "display",
      "progress.",
      "once",
      "complete",
      "fields",
      "side",
      "panel.",
      "expand",
      "file",
      "id",
      "required",
      "creating",
      "report.",
      "table",
      "displayed",
      "ui",
      "because",
      "type",
      "selected",
      "default",
      "visualizations",
      "go",
      "modeling",
      "manage"
    ],
    "language": "en",
    "word_count": 105,
    "importance_score": 4.5,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "use power bi to create reports via odata",
    "contentLower": "use case your organization wants to create a report that reflects the number of articles distributed in various services. to create the report in power bi, take the following steps: connect to the odata feed open power bi desktop. in the home page, select get data > odata feed. in the odata feed window, input your odata feed url in the url field, and click ok. https://<service management host name>:<port number>/datahub/<tenant id>/odata/ or https://<service management host name>:<port number>/datahub/<tenant id>/odata power bi desktop prompts you to enter your credentials. select basic and input your user name and password, and then click save. see authentication method for detailed information. now you can connect to the service management data. power bi desktop displays the available tables and other data elements in the navigator window. sort out the data to create a report that reflects the number of articles distributed in various services, you need to import and sort out the dat",
    "keywordsLower": [
      "https://<service",
      "power",
      "bi",
      "create",
      "reports",
      "via",
      "odata",
      "case",
      "connect",
      "feed",
      "sort",
      "out",
      "data",
      "report",
      "refresh",
      "organization",
      "wants",
      "reflects",
      "number",
      "articles",
      "distributed",
      "various",
      "services.",
      "take",
      "following",
      "steps",
      "open",
      "desktop.",
      "home",
      "page",
      "select",
      "get",
      "feed.",
      "window",
      "input",
      "url",
      "field",
      "click",
      "ok.",
      "https",
      "datahub",
      "desktop",
      "prompts",
      "enter",
      "credentials.",
      "basic",
      "user",
      "name",
      "password",
      "save.",
      "see",
      "authentication",
      "method",
      "detailed",
      "information.",
      "now",
      "service",
      "management",
      "data.",
      "displays",
      "available",
      "tables",
      "elements",
      "navigator",
      "window.",
      "services",
      "need",
      "import",
      "article",
      "servicedefinition.",
      "servicedefinition",
      "list",
      "load.",
      "after",
      "load",
      "imports",
      "display",
      "progress.",
      "once",
      "complete",
      "fields",
      "side",
      "panel.",
      "expand",
      "file",
      "id",
      "required",
      "creating",
      "report.",
      "table",
      "displayed",
      "ui",
      "because",
      "type",
      "selected",
      "default",
      "visualizations",
      "go",
      "modeling",
      "manage"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Use the BI integration API (deprecated)",
    "content": "The Business Intelligence (BI) integration module enables you to define the fields and relationships that are synced for a record type when integrating with an external business intelligence system. This can help you export your data to a third-party system with different reporting tools. Alternatively, it's useful for aggregating your data with data from other parts of your organization. You can define multiple sync configurations, the configurations are used for all selected record types and fields. You perform the integration using the BI integration API. For more information on the API, see Business Intelligence integration API. Service Management only supports direct access to the database for the PostgreSQL views. Unless directed by the Support as part of a case investigation or resolution, any other database access is not supported. Use case This use case will generate an excel report of users and their groups. Your organization wants a report in Excel format that lists all the ",
    "url": "usebiintegrationapi",
    "filename": "usebiintegrationapi",
    "headings": [
      "Use case",
      "Set up the integration",
      "Define a synchronization configuration",
      "Configure a synchronization",
      "Best practices",
      "Use the integration",
      "Load the data into Excel",
      "Native SACM limitation",
      "Related topics"
    ],
    "keywords": [
      "Person_group_0.xlsx",
      "Person_0.xlsx",
      "https://<host>/auth/authentication-endpoint/authenticate/token?tenantId={{TENANTID",
      "bi",
      "integration",
      "api",
      "deprecated",
      "case",
      "set",
      "define",
      "synchronization",
      "configuration",
      "configure",
      "best",
      "practices",
      "load",
      "data",
      "excel",
      "native",
      "sacm",
      "limitation",
      "related",
      "topics",
      "business",
      "intelligence",
      "module",
      "enables",
      "fields",
      "relationships",
      "synced",
      "record",
      "type",
      "integrating",
      "external",
      "system.",
      "help",
      "export",
      "third-party",
      "system",
      "different",
      "reporting",
      "tools.",
      "alternatively",
      "useful",
      "aggregating",
      "parts",
      "organization.",
      "multiple",
      "sync",
      "configurations",
      "all",
      "selected",
      "types",
      "fields.",
      "perform",
      "api.",
      "information",
      "see",
      "service",
      "management",
      "supports",
      "direct",
      "access",
      "database",
      "postgresql",
      "views.",
      "unless",
      "directed",
      "support",
      "part",
      "investigation",
      "resolution",
      "any",
      "supported.",
      "generate",
      "report",
      "users",
      "groups.",
      "organization",
      "wants",
      "format",
      "lists",
      "groups",
      "belong",
      "to.",
      "need",
      "include",
      "group",
      "memberships",
      "person",
      "id",
      "name",
      "members",
      "following",
      "steps",
      "integration.",
      "add",
      "new",
      "main",
      "menu"
    ],
    "language": "en",
    "word_count": 92,
    "importance_score": 5.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "use the bi integration api (deprecated)",
    "contentLower": "the business intelligence (bi) integration module enables you to define the fields and relationships that are synced for a record type when integrating with an external business intelligence system. this can help you export your data to a third-party system with different reporting tools. alternatively, it's useful for aggregating your data with data from other parts of your organization. you can define multiple sync configurations, the configurations are used for all selected record types and fields. you perform the integration using the bi integration api. for more information on the api, see business intelligence integration api. service management only supports direct access to the database for the postgresql views. unless directed by the support as part of a case investigation or resolution, any other database access is not supported. use case this use case will generate an excel report of users and their groups. your organization wants a report in excel format that lists all the ",
    "keywordsLower": [
      "person_group_0.xlsx",
      "person_0.xlsx",
      "https://<host>/auth/authentication-endpoint/authenticate/token?tenantid={{tenantid",
      "bi",
      "integration",
      "api",
      "deprecated",
      "case",
      "set",
      "define",
      "synchronization",
      "configuration",
      "configure",
      "best",
      "practices",
      "load",
      "data",
      "excel",
      "native",
      "sacm",
      "limitation",
      "related",
      "topics",
      "business",
      "intelligence",
      "module",
      "enables",
      "fields",
      "relationships",
      "synced",
      "record",
      "type",
      "integrating",
      "external",
      "system.",
      "help",
      "export",
      "third-party",
      "system",
      "different",
      "reporting",
      "tools.",
      "alternatively",
      "useful",
      "aggregating",
      "parts",
      "organization.",
      "multiple",
      "sync",
      "configurations",
      "all",
      "selected",
      "types",
      "fields.",
      "perform",
      "api.",
      "information",
      "see",
      "service",
      "management",
      "supports",
      "direct",
      "access",
      "database",
      "postgresql",
      "views.",
      "unless",
      "directed",
      "support",
      "part",
      "investigation",
      "resolution",
      "any",
      "supported.",
      "generate",
      "report",
      "users",
      "groups.",
      "organization",
      "wants",
      "format",
      "lists",
      "groups",
      "belong",
      "to.",
      "need",
      "include",
      "group",
      "memberships",
      "person",
      "id",
      "name",
      "members",
      "following",
      "steps",
      "integration.",
      "add",
      "new",
      "main",
      "menu"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Use the BI integration API to create reports (deprecated)",
    "content": "Use case Your organization wants a report in Excel format that lists all the users and all of the groups they belong to. The data you need to include in the BI sync, to report on groups and group memberships, is: Person - ID, Name, Group members Group - ID, Name You need to take the following steps: If not already done, enable BI sync on the tenant From the Main menu, select Administration > Utilities > Integration, and then select BI Integration. Add the required record types and fields In BI integration: Select the following record types: Group Person For the record type Group, add the following fields: ID Name For the record type Person, add the following fields: ID Name Group members (from the Person many to many relationships section) Save your changes. Run the REST call While logged in to Service Management Automation: Launch a REST client such as Postman. Run the REST call to run the BI sync job. Using the SyncId from the call, run the REST call to retrieve the status and file n",
    "url": "biintegusecase",
    "filename": "biintegusecase",
    "headings": [
      "Use case",
      "If not already done, enable BI sync on the tenant",
      "Add the required record types and fields",
      "Run the REST call",
      "Load the data into Excel"
    ],
    "keywords": [
      "Person_group_0.xlsx",
      "Person_0.xlsx",
      "bi",
      "integration",
      "api",
      "create",
      "reports",
      "deprecated",
      "case",
      "already",
      "done",
      "enable",
      "sync",
      "tenant",
      "add",
      "required",
      "record",
      "types",
      "fields",
      "run",
      "rest",
      "call",
      "load",
      "data",
      "excel",
      "organization",
      "wants",
      "report",
      "format",
      "lists",
      "all",
      "users",
      "groups",
      "belong",
      "to.",
      "need",
      "include",
      "group",
      "memberships",
      "person",
      "id",
      "name",
      "members",
      "take",
      "following",
      "steps",
      "main",
      "menu",
      "select",
      "administration",
      "utilities",
      "integration.",
      "type",
      "many",
      "relationships",
      "section",
      "save",
      "changes.",
      "while",
      "logged",
      "service",
      "management",
      "automation",
      "launch",
      "client",
      "such",
      "postman.",
      "job.",
      "syncid",
      "retrieve",
      "status",
      "file",
      "names",
      "created",
      "there",
      "several",
      "files.",
      "open",
      "another",
      "tab",
      "browser.",
      "enter",
      "url",
      "frs",
      "file-list",
      "download",
      "starts.",
      ".zip.",
      "repeat",
      "fileid",
      "values",
      "obtained",
      "call.",
      "navigate",
      "downloaded",
      "files",
      "unzip",
      "them.",
      "completion",
      "preceding"
    ],
    "language": "en",
    "word_count": 122,
    "importance_score": 4.5,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "use the bi integration api to create reports (deprecated)",
    "contentLower": "use case your organization wants a report in excel format that lists all the users and all of the groups they belong to. the data you need to include in the bi sync, to report on groups and group memberships, is: person - id, name, group members group - id, name you need to take the following steps: if not already done, enable bi sync on the tenant from the main menu, select administration > utilities > integration, and then select bi integration. add the required record types and fields in bi integration: select the following record types: group person for the record type group, add the following fields: id name for the record type person, add the following fields: id name group members (from the person many to many relationships section) save your changes. run the rest call while logged in to service management automation: launch a rest client such as postman. run the rest call to run the bi sync job. using the syncid from the call, run the rest call to retrieve the status and file n",
    "keywordsLower": [
      "person_group_0.xlsx",
      "person_0.xlsx",
      "bi",
      "integration",
      "api",
      "create",
      "reports",
      "deprecated",
      "case",
      "already",
      "done",
      "enable",
      "sync",
      "tenant",
      "add",
      "required",
      "record",
      "types",
      "fields",
      "run",
      "rest",
      "call",
      "load",
      "data",
      "excel",
      "organization",
      "wants",
      "report",
      "format",
      "lists",
      "all",
      "users",
      "groups",
      "belong",
      "to.",
      "need",
      "include",
      "group",
      "memberships",
      "person",
      "id",
      "name",
      "members",
      "take",
      "following",
      "steps",
      "main",
      "menu",
      "select",
      "administration",
      "utilities",
      "integration.",
      "type",
      "many",
      "relationships",
      "section",
      "save",
      "changes.",
      "while",
      "logged",
      "service",
      "management",
      "automation",
      "launch",
      "client",
      "such",
      "postman.",
      "job.",
      "syncid",
      "retrieve",
      "status",
      "file",
      "names",
      "created",
      "there",
      "several",
      "files.",
      "open",
      "another",
      "tab",
      "browser.",
      "enter",
      "url",
      "frs",
      "file-list",
      "download",
      "starts.",
      ".zip.",
      "repeat",
      "fileid",
      "values",
      "obtained",
      "call.",
      "navigate",
      "downloaded",
      "files",
      "unzip",
      "them.",
      "completion",
      "preceding"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "User onboarding",
    "content": "The process for importing person records into Service Management is a multi-step process. It involves adding people to both Suite Administration (https://<External Access Host>/bo) and Service Management (the agent interface). The following outlines the methods for importing users into the suite. Types of Person records in Service Management There are two types of Person records in Service Management: Users: persons who are able to log in to the Service Portal or the agent interface. Contacts: persons who are not able to log in but may be referenced as people using phones or third-party vendors, etc. Person records are automatically set to be users if there is an account in Suite Administration that matches the UPN of the person in Service Management. The person is set as a contact if there is not a matching account. Removing the user account from Suite Administration changes the Person record from a user to a contact. In Service Management > People, you can easily convert a user to a ",
    "url": "importusersintosuite",
    "filename": "importusersintosuite",
    "headings": [
      "Types of Person records in Service Management",
      "Determining how to create users and contacts",
      "Adding users manually through My Account in Suite Administration",
      "Adding users manually in Service Management",
      "Using the Manage Persons API",
      "Importing data from a CSV file",
      "Automatic user synchronization by LDAP or SAML authentication",
      "OPB-based LDAP integration",
      "Connect-It integration",
      "Best practice",
      "Person avatar colors",
      "Related Topics"
    ],
    "keywords": [
      "https://<External",
      "Location.Name",
      "microfocus.com",
      "user",
      "onboarding",
      "types",
      "person",
      "records",
      "service",
      "management",
      "determining",
      "create",
      "users",
      "contacts",
      "adding",
      "manually",
      "through",
      "account",
      "suite",
      "administration",
      "manage",
      "persons",
      "api",
      "importing",
      "data",
      "csv",
      "file",
      "automatic",
      "synchronization",
      "ldap",
      "saml",
      "authentication",
      "opb-based",
      "integration",
      "connect-it",
      "best",
      "practice",
      "avatar",
      "colors",
      "related",
      "topics",
      "process",
      "multi-step",
      "process.",
      "involves",
      "people",
      "both",
      "https",
      "bo",
      "agent",
      "interface",
      "following",
      "outlines",
      "methods",
      "suite.",
      "there",
      "two",
      "able",
      "log",
      "portal",
      "interface.",
      "referenced",
      "phones",
      "third-party",
      "vendors",
      "etc.",
      "automatically",
      "set",
      "matches",
      "upn",
      "management.",
      "contact",
      "matching",
      "account.",
      "removing",
      "changes",
      "record",
      "contact.",
      "easily",
      "convert",
      "way",
      "around.",
      "important",
      "concept",
      "understand",
      "need",
      "places",
      "one",
      "another",
      "duplicates",
      "all",
      "exist",
      "makes",
      "user.",
      "creating",
      "outlined",
      "below.",
      "table",
      "provides",
      "comparison"
    ],
    "language": "en",
    "word_count": 94,
    "importance_score": 6.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "user onboarding",
    "contentLower": "the process for importing person records into service management is a multi-step process. it involves adding people to both suite administration (https://<external access host>/bo) and service management (the agent interface). the following outlines the methods for importing users into the suite. types of person records in service management there are two types of person records in service management: users: persons who are able to log in to the service portal or the agent interface. contacts: persons who are not able to log in but may be referenced as people using phones or third-party vendors, etc. person records are automatically set to be users if there is an account in suite administration that matches the upn of the person in service management. the person is set as a contact if there is not a matching account. removing the user account from suite administration changes the person record from a user to a contact. in service management > people, you can easily convert a user to a ",
    "keywordsLower": [
      "https://<external",
      "location.name",
      "microfocus.com",
      "user",
      "onboarding",
      "types",
      "person",
      "records",
      "service",
      "management",
      "determining",
      "create",
      "users",
      "contacts",
      "adding",
      "manually",
      "through",
      "account",
      "suite",
      "administration",
      "manage",
      "persons",
      "api",
      "importing",
      "data",
      "csv",
      "file",
      "automatic",
      "synchronization",
      "ldap",
      "saml",
      "authentication",
      "opb-based",
      "integration",
      "connect-it",
      "best",
      "practice",
      "avatar",
      "colors",
      "related",
      "topics",
      "process",
      "multi-step",
      "process.",
      "involves",
      "people",
      "both",
      "https",
      "bo",
      "agent",
      "interface",
      "following",
      "outlines",
      "methods",
      "suite.",
      "there",
      "two",
      "able",
      "log",
      "portal",
      "interface.",
      "referenced",
      "phones",
      "third-party",
      "vendors",
      "etc.",
      "automatically",
      "set",
      "matches",
      "upn",
      "management.",
      "contact",
      "matching",
      "account.",
      "removing",
      "changes",
      "record",
      "contact.",
      "easily",
      "convert",
      "way",
      "around.",
      "important",
      "concept",
      "understand",
      "need",
      "places",
      "one",
      "another",
      "duplicates",
      "all",
      "exist",
      "makes",
      "user.",
      "creating",
      "outlined",
      "below.",
      "table",
      "provides",
      "comparison"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Use case: back up and restore",
    "content": "The backup and restore solution for all deployments provides the details to create your Disaster Recovery Plan (DRP), including the procedures to back up data and handle specific disaster scenarios. This use case describes how a fictional company (Example Corp.) creates its DRP from scratch, performs the first and routine backup tasks, and successfully restores the suite in the event of service interruption. The chart below gives an overview of how Example Corp executes its DRP flow. Personas The following personas are involved in creating and implementing DRP. Name Role Responsibilities Steve Suite administrator Investigate and create DRP. Get informed when disaster happens. Eve Cloud administrator Set up Velero (Only applicable for managed kubernetes) Coordinate with other administrators in backup and restoration tasks. Monica Kubernetes administrator Perform and manage backups of Kubernetes configurations. Restore Kubernetes configurations when disaster happens. Peter Database admin",
    "url": "drpusecase",
    "filename": "drpusecase",
    "headings": [
      "Personas",
      "Prerequisites",
      "Create Disaster Recovery Plan",
      "Set up Velero",
      "First backup",
      "Routine backup",
      "Test and adjust Disaster Recovery Plan",
      "When a disaster happens"
    ],
    "keywords": [
      "amazon.com",
      "console.aws",
      "https://console.aws.amazon.com/backup",
      "case",
      "back",
      "restore",
      "personas",
      "prerequisites",
      "create",
      "disaster",
      "recovery",
      "plan",
      "set",
      "velero",
      "first",
      "backup",
      "routine",
      "test",
      "adjust",
      "happens",
      "solution",
      "all",
      "deployments",
      "provides",
      "details",
      "drp",
      "including",
      "procedures",
      "data",
      "handle",
      "specific",
      "scenarios.",
      "describes",
      "fictional",
      "company",
      "example",
      "corp.",
      "creates",
      "scratch",
      "performs",
      "tasks",
      "successfully",
      "restores",
      "suite",
      "event",
      "service",
      "interruption.",
      "chart",
      "below",
      "gives",
      "overview",
      "corp",
      "executes",
      "flow.",
      "following",
      "involved",
      "creating",
      "implementing",
      "drp.",
      "name",
      "role",
      "responsibilities",
      "steve",
      "administrator",
      "investigate",
      "get",
      "informed",
      "happens.",
      "eve",
      "cloud",
      "applicable",
      "managed",
      "kubernetes",
      "coordinate",
      "administrators",
      "restoration",
      "tasks.",
      "monica",
      "perform",
      "manage",
      "backups",
      "configurations.",
      "configurations",
      "peter",
      "database",
      "data.",
      "sam",
      "storage",
      "file",
      "running",
      "environment.",
      "steps",
      "need",
      "make",
      "sure",
      "source",
      "target",
      "environments",
      "hosted",
      "same"
    ],
    "language": "en",
    "word_count": 101,
    "importance_score": 5.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "use case: back up and restore",
    "contentLower": "the backup and restore solution for all deployments provides the details to create your disaster recovery plan (drp), including the procedures to back up data and handle specific disaster scenarios. this use case describes how a fictional company (example corp.) creates its drp from scratch, performs the first and routine backup tasks, and successfully restores the suite in the event of service interruption. the chart below gives an overview of how example corp executes its drp flow. personas the following personas are involved in creating and implementing drp. name role responsibilities steve suite administrator investigate and create drp. get informed when disaster happens. eve cloud administrator set up velero (only applicable for managed kubernetes) coordinate with other administrators in backup and restoration tasks. monica kubernetes administrator perform and manage backups of kubernetes configurations. restore kubernetes configurations when disaster happens. peter database admin",
    "keywordsLower": [
      "amazon.com",
      "console.aws",
      "https://console.aws.amazon.com/backup",
      "case",
      "back",
      "restore",
      "personas",
      "prerequisites",
      "create",
      "disaster",
      "recovery",
      "plan",
      "set",
      "velero",
      "first",
      "backup",
      "routine",
      "test",
      "adjust",
      "happens",
      "solution",
      "all",
      "deployments",
      "provides",
      "details",
      "drp",
      "including",
      "procedures",
      "data",
      "handle",
      "specific",
      "scenarios.",
      "describes",
      "fictional",
      "company",
      "example",
      "corp.",
      "creates",
      "scratch",
      "performs",
      "tasks",
      "successfully",
      "restores",
      "suite",
      "event",
      "service",
      "interruption.",
      "chart",
      "below",
      "gives",
      "overview",
      "corp",
      "executes",
      "flow.",
      "following",
      "involved",
      "creating",
      "implementing",
      "drp.",
      "name",
      "role",
      "responsibilities",
      "steve",
      "administrator",
      "investigate",
      "get",
      "informed",
      "happens.",
      "eve",
      "cloud",
      "applicable",
      "managed",
      "kubernetes",
      "coordinate",
      "administrators",
      "restoration",
      "tasks.",
      "monica",
      "perform",
      "manage",
      "backups",
      "configurations.",
      "configurations",
      "peter",
      "database",
      "data.",
      "sam",
      "storage",
      "file",
      "running",
      "environment.",
      "steps",
      "need",
      "make",
      "sure",
      "source",
      "target",
      "environments",
      "hosted",
      "same"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Use the PostgreSQL exporter to monitor the external database",
    "content": "A PostgreSQL exporter image is available in the ITOM Marketplace, which can be used to collect PostgreSQL metrics such as queries per second (QPS) and rows fetched/returned/inserted/updated/deleted per second. These metrics are then exposed in the Prometheus style. Prepare a database user for the PostgreSQL exporter Run the following commands with the database administrator account to create a new database user with the pg_monitor role for the PostgreSQL exporter: create user <test_monitor> with password '<password>'; grant pg_monitor to <test_monitor>; You will need the name and password of this user when running the install.sh command later. Install the PostgreSQL exporter Download the itom-postgres-monitor-2X.X.tar.gz image from the ITOM Marketplace. Run the following command: tar zxvf <itom-postgres-monitor-2X.X.tar.gz> chmod 755 install.sh ./install.sh The script will prompt you to enter credentials. Enter the requested username and password. Note that for an on-premises deploymen",
    "url": "usepgexportermonitorexternaldb",
    "filename": "usepgexportermonitorexternaldb",
    "headings": [
      "Prepare a database user for the PostgreSQL exporter",
      "Install the PostgreSQL exporter",
      "Related topics"
    ],
    "keywords": [
      "X.tar",
      "disable.yaml",
      "exporter.yaml",
      "install.sh",
      "postgresql",
      "exporter",
      "monitor",
      "external",
      "database",
      "prepare",
      "user",
      "install",
      "related",
      "topics",
      "image",
      "available",
      "itom",
      "marketplace",
      "collect",
      "metrics",
      "such",
      "queries",
      "per",
      "second",
      "qps",
      "rows",
      "fetched",
      "returned",
      "inserted",
      "updated",
      "deleted",
      "second.",
      "exposed",
      "prometheus",
      "style.",
      "run",
      "following",
      "commands",
      "administrator",
      "account",
      "create",
      "new",
      "role",
      "password",
      "grant",
      "need",
      "name",
      "running",
      "command",
      "later.",
      "download",
      "itom-postgres-monitor-2x.x.tar.gz",
      "marketplace.",
      "tar",
      "zxvf",
      "chmod",
      "755",
      "script",
      "prompt",
      "enter",
      "credentials.",
      "requested",
      "username",
      "password.",
      "note",
      "on-premises",
      "deployment",
      "registry",
      "repository",
      "registry-admin",
      "installation",
      "take",
      "time",
      "wait",
      "until",
      "see",
      "message",
      "itom-postgres-exporter",
      "up.",
      "press",
      "ctl",
      "exit..",
      "want",
      "exit",
      "ctrl",
      "c.",
      "make",
      "sure",
      "itom-postgres-exporter-xxxxxxxx-xxxxx",
      "pod",
      "status",
      "2.",
      "kubectl",
      "get",
      "pods",
      "-n",
      "ns",
      "grep",
      "itsma",
      "cut"
    ],
    "language": "en",
    "word_count": 91,
    "importance_score": 3.5,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "use the postgresql exporter to monitor the external database",
    "contentLower": "a postgresql exporter image is available in the itom marketplace, which can be used to collect postgresql metrics such as queries per second (qps) and rows fetched/returned/inserted/updated/deleted per second. these metrics are then exposed in the prometheus style. prepare a database user for the postgresql exporter run the following commands with the database administrator account to create a new database user with the pg_monitor role for the postgresql exporter: create user <test_monitor> with password '<password>'; grant pg_monitor to <test_monitor>; you will need the name and password of this user when running the install.sh command later. install the postgresql exporter download the itom-postgres-monitor-2x.x.tar.gz image from the itom marketplace. run the following command: tar zxvf <itom-postgres-monitor-2x.x.tar.gz> chmod 755 install.sh ./install.sh the script will prompt you to enter credentials. enter the requested username and password. note that for an on-premises deploymen",
    "keywordsLower": [
      "x.tar",
      "disable.yaml",
      "exporter.yaml",
      "install.sh",
      "postgresql",
      "exporter",
      "monitor",
      "external",
      "database",
      "prepare",
      "user",
      "install",
      "related",
      "topics",
      "image",
      "available",
      "itom",
      "marketplace",
      "collect",
      "metrics",
      "such",
      "queries",
      "per",
      "second",
      "qps",
      "rows",
      "fetched",
      "returned",
      "inserted",
      "updated",
      "deleted",
      "second.",
      "exposed",
      "prometheus",
      "style.",
      "run",
      "following",
      "commands",
      "administrator",
      "account",
      "create",
      "new",
      "role",
      "password",
      "grant",
      "need",
      "name",
      "running",
      "command",
      "later.",
      "download",
      "itom-postgres-monitor-2x.x.tar.gz",
      "marketplace.",
      "tar",
      "zxvf",
      "chmod",
      "755",
      "script",
      "prompt",
      "enter",
      "credentials.",
      "requested",
      "username",
      "password.",
      "note",
      "on-premises",
      "deployment",
      "registry",
      "repository",
      "registry-admin",
      "installation",
      "take",
      "time",
      "wait",
      "until",
      "see",
      "message",
      "itom-postgres-exporter",
      "up.",
      "press",
      "ctl",
      "exit..",
      "want",
      "exit",
      "ctrl",
      "c.",
      "make",
      "sure",
      "itom-postgres-exporter-xxxxxxxx-xxxxx",
      "pod",
      "status",
      "2.",
      "kubectl",
      "get",
      "pods",
      "-n",
      "ns",
      "grep",
      "itsma",
      "cut"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "UD/UCMDB user management overview",
    "content": "The converged authorization solution enables the Service Management tenant admin to manage UD/UCMDB users, roles, and groups from one single user interface (the Service Management agent portal) when UD/UCMDB is deployed together with Service Management. While UD/UCMDB permissions are still managed in UCMDB Local Client, the solution removes the need for the suite admin to access the IdM Admin Portal for managing UD/UCMDB roles, groups, and users, and therefore streamlines the tenant admin's user administration workflow and reduces the maintenance cost. The UD/UCMDB user management flow under the converged authorization solution is as follows: When the system provisions a UCMDB customer, the UD/UCMDB out-of-the-box (OOTB) roles with built-in permissions are automatically seeded in IdM. The application field of these seeded UD/UCMDB roles is \"CMDB\".  The suite admin can do UD/UCMDB pre-authorization for the Service Management tenant admin in IdM by creating a UD/UCMDB admin group and ass",
    "url": "sharedidmoverview",
    "filename": "sharedidmoverview",
    "headings": [],
    "keywords": [
      "uducmdb",
      "ud",
      "ucmdb",
      "user",
      "management",
      "overview",
      "converged",
      "authorization",
      "solution",
      "enables",
      "service",
      "tenant",
      "admin",
      "manage",
      "users",
      "roles",
      "groups",
      "one",
      "single",
      "interface",
      "agent",
      "portal",
      "deployed",
      "together",
      "management.",
      "while",
      "permissions",
      "still",
      "managed",
      "local",
      "client",
      "removes",
      "need",
      "suite",
      "access",
      "idm",
      "managing",
      "therefore",
      "streamlines",
      "administration",
      "workflow",
      "reduces",
      "maintenance",
      "cost.",
      "flow",
      "under",
      "follows",
      "system",
      "provisions",
      "customer",
      "out-of-the-box",
      "ootb",
      "built-in",
      "automatically",
      "seeded",
      "idm.",
      "application",
      "field",
      "cmdb",
      "pre-authorization",
      "creating",
      "group",
      "associating",
      "superadmin",
      "role",
      "highest",
      "privilege",
      "customer.",
      "after",
      "native",
      "sacm",
      "replicates",
      "interface.",
      "having",
      "meet",
      "requirements",
      "create",
      "custom",
      "replicated",
      "synchronized",
      "same",
      "time.",
      "go",
      "grant",
      "following",
      "table",
      "describes",
      "tasks",
      "location",
      "persona",
      "responsibility",
      "associate",
      "configure",
      "authentication",
      "types",
      "like",
      "saml",
      "update",
      "db",
      "synced"
    ],
    "language": "en",
    "word_count": 115,
    "importance_score": 3.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "ud/ucmdb user management overview",
    "contentLower": "the converged authorization solution enables the service management tenant admin to manage ud/ucmdb users, roles, and groups from one single user interface (the service management agent portal) when ud/ucmdb is deployed together with service management. while ud/ucmdb permissions are still managed in ucmdb local client, the solution removes the need for the suite admin to access the idm admin portal for managing ud/ucmdb roles, groups, and users, and therefore streamlines the tenant admin's user administration workflow and reduces the maintenance cost. the ud/ucmdb user management flow under the converged authorization solution is as follows: when the system provisions a ucmdb customer, the ud/ucmdb out-of-the-box (ootb) roles with built-in permissions are automatically seeded in idm. the application field of these seeded ud/ucmdb roles is \"cmdb\".  the suite admin can do ud/ucmdb pre-authorization for the service management tenant admin in idm by creating a ud/ucmdb admin group and ass",
    "keywordsLower": [
      "uducmdb",
      "ud",
      "ucmdb",
      "user",
      "management",
      "overview",
      "converged",
      "authorization",
      "solution",
      "enables",
      "service",
      "tenant",
      "admin",
      "manage",
      "users",
      "roles",
      "groups",
      "one",
      "single",
      "interface",
      "agent",
      "portal",
      "deployed",
      "together",
      "management.",
      "while",
      "permissions",
      "still",
      "managed",
      "local",
      "client",
      "removes",
      "need",
      "suite",
      "access",
      "idm",
      "managing",
      "therefore",
      "streamlines",
      "administration",
      "workflow",
      "reduces",
      "maintenance",
      "cost.",
      "flow",
      "under",
      "follows",
      "system",
      "provisions",
      "customer",
      "out-of-the-box",
      "ootb",
      "built-in",
      "automatically",
      "seeded",
      "idm.",
      "application",
      "field",
      "cmdb",
      "pre-authorization",
      "creating",
      "group",
      "associating",
      "superadmin",
      "role",
      "highest",
      "privilege",
      "customer.",
      "after",
      "native",
      "sacm",
      "replicates",
      "interface.",
      "having",
      "meet",
      "requirements",
      "create",
      "custom",
      "replicated",
      "synchronized",
      "same",
      "time.",
      "go",
      "grant",
      "following",
      "table",
      "describes",
      "tasks",
      "location",
      "persona",
      "responsibility",
      "associate",
      "configure",
      "authentication",
      "types",
      "like",
      "saml",
      "update",
      "db",
      "synced"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Use the original UD/UCMDB admin or sysadmin instead of suite-admin",
    "content": "It's highly recommended to use the shared administration user (suite-admin) to manage UD/UCMDB and Service Management. If you insist on using the original UD/UCMDB OOTB admin users (admin or sysadmin) to manage UD/UCMDB, perform the steps in this section. To use the original UD/UCMDB admin or sysadmin instead of suite-admin to manage UD/UCMDB, follow these steps: Log in to the shared IdM (https://<External_Access_Host>/idm-admin) as suite-admin. Navigate to the SYSBO organization, and then click it. Go to Users in the navigation pane, and then click in the toolbar. The ADD USER page appears. Provide values as described in the following table for the admin user, and then click SAVE. Field (*required) Description Name * Name of the UD/UCMDB OOTB user. Enter the user name as admin. Display Name * Display name of the new user. Use admin in this case. Password * Specify a password for the UD/UCMDB OOTB user. Type * Select SYSTEM. Password Policy Leave the field empty. User Attributes Leave ",
    "url": "usecmsadminorsysadmin",
    "filename": "usecmsadminorsysadmin",
    "headings": [],
    "keywords": [
      "uducmdb",
      "https://<External_Access_Host>/idm-admin",
      "original",
      "ud",
      "ucmdb",
      "admin",
      "sysadmin",
      "instead",
      "suite-admin",
      "highly",
      "recommended",
      "shared",
      "administration",
      "user",
      "manage",
      "service",
      "management.",
      "insist",
      "ootb",
      "users",
      "perform",
      "steps",
      "section.",
      "follow",
      "log",
      "idm",
      "https",
      "idm-admin",
      "suite-admin.",
      "navigate",
      "sysbo",
      "organization",
      "click",
      "it.",
      "go",
      "navigation",
      "pane",
      "toolbar.",
      "add",
      "page",
      "appears.",
      "provide",
      "values",
      "described",
      "following",
      "table",
      "save.",
      "field",
      "required",
      "description",
      "name",
      "user.",
      "enter",
      "admin.",
      "display",
      "new",
      "case.",
      "password",
      "specify",
      "type",
      "select",
      "system.",
      "policy",
      "leave",
      "empty.",
      "attributes",
      "repeat",
      "above",
      "create",
      "groups",
      "administrators",
      "group",
      "action",
      "button",
      "settings",
      "make",
      "sure",
      "associated",
      "role",
      "superadmin",
      "cmdb",
      "application",
      "field.",
      "scroll",
      "section",
      "search",
      "associate",
      "group.",
      "now",
      "super",
      "permissions.",
      "note",
      "newly",
      "added",
      "same",
      "privilege",
      "difference",
      "between",
      "two",
      "users."
    ],
    "language": "en",
    "word_count": 115,
    "importance_score": 2.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "use the original ud/ucmdb admin or sysadmin instead of suite-admin",
    "contentLower": "it's highly recommended to use the shared administration user (suite-admin) to manage ud/ucmdb and service management. if you insist on using the original ud/ucmdb ootb admin users (admin or sysadmin) to manage ud/ucmdb, perform the steps in this section. to use the original ud/ucmdb admin or sysadmin instead of suite-admin to manage ud/ucmdb, follow these steps: log in to the shared idm (https://<external_access_host>/idm-admin) as suite-admin. navigate to the sysbo organization, and then click it. go to users in the navigation pane, and then click in the toolbar. the add user page appears. provide values as described in the following table for the admin user, and then click save. field (*required) description name * name of the ud/ucmdb ootb user. enter the user name as admin. display name * display name of the new user. use admin in this case. password * specify a password for the ud/ucmdb ootb user. type * select system. password policy leave the field empty. user attributes leave ",
    "keywordsLower": [
      "uducmdb",
      "https://<external_access_host>/idm-admin",
      "original",
      "ud",
      "ucmdb",
      "admin",
      "sysadmin",
      "instead",
      "suite-admin",
      "highly",
      "recommended",
      "shared",
      "administration",
      "user",
      "manage",
      "service",
      "management.",
      "insist",
      "ootb",
      "users",
      "perform",
      "steps",
      "section.",
      "follow",
      "log",
      "idm",
      "https",
      "idm-admin",
      "suite-admin.",
      "navigate",
      "sysbo",
      "organization",
      "click",
      "it.",
      "go",
      "navigation",
      "pane",
      "toolbar.",
      "add",
      "page",
      "appears.",
      "provide",
      "values",
      "described",
      "following",
      "table",
      "save.",
      "field",
      "required",
      "description",
      "name",
      "user.",
      "enter",
      "admin.",
      "display",
      "new",
      "case.",
      "password",
      "specify",
      "type",
      "select",
      "system.",
      "policy",
      "leave",
      "empty.",
      "attributes",
      "repeat",
      "above",
      "create",
      "groups",
      "administrators",
      "group",
      "action",
      "button",
      "settings",
      "make",
      "sure",
      "associated",
      "role",
      "superadmin",
      "cmdb",
      "application",
      "field.",
      "scroll",
      "section",
      "search",
      "associate",
      "group.",
      "now",
      "super",
      "permissions.",
      "note",
      "newly",
      "added",
      "same",
      "privilege",
      "difference",
      "between",
      "two",
      "users."
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Where to find suite logs (Helm)",
    "content": "This section provides information about where to find the suite logs for troubleshooting or administration purposes based on your actual scenarios. In the tables below, <logging-volume> refers to the suite's log NFS volume (for example: /var/vols/itom/itsma/logging-volume). Upgrade Scenario Log file location The upgrade precheck fails <logging-volume>/xservices/platform/<itom-xruntime-content-validation pod>/maas/maas_upg_framework.log <logging-volume>/xservices/platform/<itom-xruntime-content-validation pod>/maas/maas_upg_step_audit.log <logging-volume>/xservices/platform/<itom-xruntime-content-validation-pod>/maas/maas_upg_verification.log Fail to upgrade the suite <logging-volume>/xservices/upgradetenant/<itom-xruntime-upgrade-tenants pod>/upgradeTenant.log <logging-volume>/xservices/lcm/<itom-xruntime-lcm-pod>/lifecycle.log <logging-volume>/xservices/platform/<itom-xruntime-platform-pod>/maas/maas_upg_framework.log <logging-volume>/xservices/platform/<itom-xruntime-platform-pod>/ma",
    "url": "suitelogshelm",
    "filename": "suitelogshelm",
    "headings": [
      "Upgrade",
      "Integration",
      "Authentication and license issues in a tenant",
      "Certificate",
      "Ingress service",
      "Suite Administration",
      "Service Portal",
      "Service Management and platform services",
      "Smart Analytics",
      "Service Management Chat",
      "Virtual Agent",
      "Software Asset Management (SAM)",
      "Cloud Management Platform (CMP) FinOps",
      "Design and Deploy (DND)"
    ],
    "keywords": [
      "gateway_error.log",
      "maas_lifecycle.log",
      "maas_worker_audit.log",
      "maas_worker.log",
      "postgresql.conf",
      "index.log",
      "maas_user_options_package_management.log",
      "maas_upg_step_audit.log",
      "maas_opb.log",
      "maas_slm.log",
      "maas_rms_cache.log",
      "maas_tasks.log",
      "maas_metadata_error.log",
      "maas_cloud_service_scheduler.log",
      "gateway_info.log",
      "insights.log",
      "maas_upg_verification.log",
      "maas_metadata.log",
      "catalina.out",
      "maas_rms.log",
      "maas_tenantSettings.log",
      "access.log",
      "maas_ucmdb_sync.log",
      "northstarapi.log",
      "maas_ums.log",
      "maas_lms.log",
      "service.log",
      "yyyy.mm",
      "scheduler.log",
      "maas_worker_master_audit.log",
      "error.log",
      "maas_filerepository_package_management.log",
      "maas_error.log",
      "proxy.log",
      "web.log",
      "maas_audit.log",
      "showback.log",
      "maas_unhandled_service_exceptions.log",
      "maas_worker_slave_audit.log",
      "maas_dev2prod.log",
      "catalina.log",
      "maas_tenantManagent.log",
      "costpolicy.log",
      "maas_upg_framework.log",
      "catalog.log",
      "maas_unhandled_exceptions.log",
      "maas_tasksGenerateExecutionPlanUpgrader.log",
      "maas_workflow.log",
      "maas_ems_asynch_update.log",
      "ess_error.log",
      "maas_schedulerAudit.log",
      "maas_binder.log",
      "http.log",
      "rsyslog.conf",
      "maas_rms_audit.log",
      "maas_rabbit_client.log",
      "lifecycle.log",
      "maas_scheduler.log",
      "action.log",
      "maas_cloud_service.log",
      "maas_cost_allocation.log",
      "management_access_log.xxx",
      "maas_ems_cache.log",
      "maas_notification.log",
      "query.log",
      "access_log.xxxx",
      "csa.log",
      "maas_ems_transaction_manager.log",
      "export.log",
      "upgradeTenant.log",
      "maas_mail.log",
      "schedule.log",
      "integration.log",
      "maas_metrics.log",
      "maas_ems_upgrade.log",
      "maas_reports.log",
      "job.log",
      "maas_tasksUpg.log",
      "maas_slm_audit.log",
      "search.log",
      "maas_search.log",
      "maas_ems.log",
      "maas_messaging.log",
      "maas_workflow_mng.log",
      "maas_ems_package_management.log",
      "controller.log",
      "management.log",
      "application.log",
      "gateway.log",
      "datahub.log",
      "maas_metadata_customization.log",
      "access_log.xxx",
      "access_log.log",
      "maas_lookup.log",
      "full.log",
      "maas_ems_msp.log",
      "store.log",
      "upgrade.log",
      "ucmdb.log",
      "maas_emsAudit.log"
    ],
    "language": "en",
    "word_count": 67,
    "importance_score": 4.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "where to find suite logs (helm)",
    "contentLower": "this section provides information about where to find the suite logs for troubleshooting or administration purposes based on your actual scenarios. in the tables below, <logging-volume> refers to the suite's log nfs volume (for example: /var/vols/itom/itsma/logging-volume). upgrade scenario log file location the upgrade precheck fails <logging-volume>/xservices/platform/<itom-xruntime-content-validation pod>/maas/maas_upg_framework.log <logging-volume>/xservices/platform/<itom-xruntime-content-validation pod>/maas/maas_upg_step_audit.log <logging-volume>/xservices/platform/<itom-xruntime-content-validation-pod>/maas/maas_upg_verification.log fail to upgrade the suite <logging-volume>/xservices/upgradetenant/<itom-xruntime-upgrade-tenants pod>/upgradetenant.log <logging-volume>/xservices/lcm/<itom-xruntime-lcm-pod>/lifecycle.log <logging-volume>/xservices/platform/<itom-xruntime-platform-pod>/maas/maas_upg_framework.log <logging-volume>/xservices/platform/<itom-xruntime-platform-pod>/ma",
    "keywordsLower": [
      "gateway_error.log",
      "maas_lifecycle.log",
      "maas_worker_audit.log",
      "maas_worker.log",
      "postgresql.conf",
      "index.log",
      "maas_user_options_package_management.log",
      "maas_upg_step_audit.log",
      "maas_opb.log",
      "maas_slm.log",
      "maas_rms_cache.log",
      "maas_tasks.log",
      "maas_metadata_error.log",
      "maas_cloud_service_scheduler.log",
      "gateway_info.log",
      "insights.log",
      "maas_upg_verification.log",
      "maas_metadata.log",
      "catalina.out",
      "maas_rms.log",
      "maas_tenantsettings.log",
      "access.log",
      "maas_ucmdb_sync.log",
      "northstarapi.log",
      "maas_ums.log",
      "maas_lms.log",
      "service.log",
      "yyyy.mm",
      "scheduler.log",
      "maas_worker_master_audit.log",
      "error.log",
      "maas_filerepository_package_management.log",
      "maas_error.log",
      "proxy.log",
      "web.log",
      "maas_audit.log",
      "showback.log",
      "maas_unhandled_service_exceptions.log",
      "maas_worker_slave_audit.log",
      "maas_dev2prod.log",
      "catalina.log",
      "maas_tenantmanagent.log",
      "costpolicy.log",
      "maas_upg_framework.log",
      "catalog.log",
      "maas_unhandled_exceptions.log",
      "maas_tasksgenerateexecutionplanupgrader.log",
      "maas_workflow.log",
      "maas_ems_asynch_update.log",
      "ess_error.log",
      "maas_scheduleraudit.log",
      "maas_binder.log",
      "http.log",
      "rsyslog.conf",
      "maas_rms_audit.log",
      "maas_rabbit_client.log",
      "lifecycle.log",
      "maas_scheduler.log",
      "action.log",
      "maas_cloud_service.log",
      "maas_cost_allocation.log",
      "management_access_log.xxx",
      "maas_ems_cache.log",
      "maas_notification.log",
      "query.log",
      "access_log.xxxx",
      "csa.log",
      "maas_ems_transaction_manager.log",
      "export.log",
      "upgradetenant.log",
      "maas_mail.log",
      "schedule.log",
      "integration.log",
      "maas_metrics.log",
      "maas_ems_upgrade.log",
      "maas_reports.log",
      "job.log",
      "maas_tasksupg.log",
      "maas_slm_audit.log",
      "search.log",
      "maas_search.log",
      "maas_ems.log",
      "maas_messaging.log",
      "maas_workflow_mng.log",
      "maas_ems_package_management.log",
      "controller.log",
      "management.log",
      "application.log",
      "gateway.log",
      "datahub.log",
      "maas_metadata_customization.log",
      "access_log.xxx",
      "access_log.log",
      "maas_lookup.log",
      "full.log",
      "maas_ems_msp.log",
      "store.log",
      "upgrade.log",
      "ucmdb.log",
      "maas_emsaudit.log"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Where to find suite logs",
    "content": "This section provides information about where to find the suite logs for troubleshooting or administration purposes based on your actual scenarios. In the tables below, <itom-vol-claim> refers to the OPTIC Management Toolkit (OMT) core NFS volume (for example: /var/vols/itom/itsma/core) <global-volume> refers to the SMA suite's global NFS volume (for example: /var/vols/itom/itsma/global-volume) <smartanalytics-volume> refers to the SMA suite's Smart Analytics NFS volume (for example: /var/vols/itom/itsma/smartanalytics-volume) <base-directory> refers to the parent folder of the SMA suite's global NFS volume (for example: /var/vols/itom/itsma) Installation and upgrade Scenario Log file location Fail to install the suite <itom-vol-claim>/suite-install/itsma/output/deployer.log <itom-vol-claim>/suite-install/itsma/output/status.log <itom-vol-claim>/suite-install/logs/cdf-apiserver.*.log Log files under folder <global-volume>/logs/services/<yyyy.mm>/<service-name>/deploy-controller The upg",
    "url": "suitelogs",
    "filename": "suitelogs",
    "headings": [
      "Installation and upgrade",
      "Integration",
      "Authentication and license issues in a tenant",
      "Certificate",
      "Ingress Service",
      "Suite Administration",
      "Self Service Portal",
      "Service Management and platform services",
      "Startup Throttling Service",
      "Smart Analytics Service",
      "Service Management Chat Service",
      "Software Asset Management Service (SAM)",
      "Cloud Management Platform (CMP) FinOps",
      "Design and Deploy Service (DND)"
    ],
    "keywords": [
      "gateway_error.log",
      "maas_lifecycle.log",
      "maas_worker_audit.log",
      "maas_worker.log",
      "postgresql.conf",
      "index.log",
      "maas_user_options_package_management.log",
      "maas_upg_step_audit.log",
      "maas_opb.log",
      "maas_slm.log",
      "maas_rms_cache.log",
      "maas_tasks.log",
      "maas_metadata_error.log",
      "maas_cloud_service_scheduler.log",
      "gateway_info.log",
      "insights.log",
      "maas_upg_verification.log",
      "maas_metadata.log",
      "catalina.out",
      "maas_rms.log",
      "maas_tenantSettings.log",
      "access.log",
      "maas_ucmdb_sync.log",
      "northstarapi.log",
      "maas_ums.log",
      "maas_lms.log",
      "service.log",
      "yyyy.mm",
      "scheduler.log",
      "status.log",
      "maas_worker_master_audit.log",
      "error.log",
      "maas_filerepository_package_management.log",
      "maas_error.log",
      "proxy.log",
      "web.log",
      "maas_audit.log",
      "showback.log",
      "maas_unhandled_service_exceptions.log",
      "maas_worker_slave_audit.log",
      "maas_dev2prod.log",
      "catalina.log",
      "wrapper.log",
      "maas_tenantManagent.log",
      "costpolicy.log",
      "maas_upg_framework.log",
      "catalog.log",
      "maas_unhandled_exceptions.log",
      "maas_tasksGenerateExecutionPlanUpgrader.log",
      "maas_workflow.log",
      "maas_ems_asynch_update.log",
      "ess_error.log",
      "maas_schedulerAudit.log",
      "maas_binder.log",
      "http.log",
      "rsyslog.conf",
      "maas_rms_audit.log",
      "maas_rabbit_client.log",
      "lifecycle.log",
      "maas_scheduler.log",
      "action.log",
      "maas_cloud_service.log",
      "maas_cost_allocation.log",
      "management_access_log.xxx",
      "maas_ems_cache.log",
      "maas_notification.log",
      "query.log",
      "access_log.xxxx",
      "csa.log",
      "deployer.log",
      "maas_ems_transaction_manager.log",
      "export.log",
      "upgradeTenant.log",
      "maas_mail.log",
      "schedule.log",
      "integration.log",
      "maas_metrics.log",
      "maas_ems_upgrade.log",
      "maas_reports.log",
      "job.log",
      "maas_tasksUpg.log",
      "maas_slm_audit.log",
      "search.log",
      "maas_search.log",
      "maas_ems.log",
      "maas_messaging.log",
      "maas_workflow_mng.log",
      "maas_ems_package_management.log",
      "controller.log",
      "management.log",
      "application.log",
      "gateway.log",
      "datahub.log",
      "maas_metadata_customization.log",
      "access_log.xxx",
      "access_log.log",
      "maas_lookup.log",
      "full.log",
      "maas_ems_msp.log",
      "execution.log"
    ],
    "language": "en",
    "word_count": 102,
    "importance_score": 6.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "where to find suite logs",
    "contentLower": "this section provides information about where to find the suite logs for troubleshooting or administration purposes based on your actual scenarios. in the tables below, <itom-vol-claim> refers to the optic management toolkit (omt) core nfs volume (for example: /var/vols/itom/itsma/core) <global-volume> refers to the sma suite's global nfs volume (for example: /var/vols/itom/itsma/global-volume) <smartanalytics-volume> refers to the sma suite's smart analytics nfs volume (for example: /var/vols/itom/itsma/smartanalytics-volume) <base-directory> refers to the parent folder of the sma suite's global nfs volume (for example: /var/vols/itom/itsma) installation and upgrade scenario log file location fail to install the suite <itom-vol-claim>/suite-install/itsma/output/deployer.log <itom-vol-claim>/suite-install/itsma/output/status.log <itom-vol-claim>/suite-install/logs/cdf-apiserver.*.log log files under folder <global-volume>/logs/services/<yyyy.mm>/<service-name>/deploy-controller the upg",
    "keywordsLower": [
      "gateway_error.log",
      "maas_lifecycle.log",
      "maas_worker_audit.log",
      "maas_worker.log",
      "postgresql.conf",
      "index.log",
      "maas_user_options_package_management.log",
      "maas_upg_step_audit.log",
      "maas_opb.log",
      "maas_slm.log",
      "maas_rms_cache.log",
      "maas_tasks.log",
      "maas_metadata_error.log",
      "maas_cloud_service_scheduler.log",
      "gateway_info.log",
      "insights.log",
      "maas_upg_verification.log",
      "maas_metadata.log",
      "catalina.out",
      "maas_rms.log",
      "maas_tenantsettings.log",
      "access.log",
      "maas_ucmdb_sync.log",
      "northstarapi.log",
      "maas_ums.log",
      "maas_lms.log",
      "service.log",
      "yyyy.mm",
      "scheduler.log",
      "status.log",
      "maas_worker_master_audit.log",
      "error.log",
      "maas_filerepository_package_management.log",
      "maas_error.log",
      "proxy.log",
      "web.log",
      "maas_audit.log",
      "showback.log",
      "maas_unhandled_service_exceptions.log",
      "maas_worker_slave_audit.log",
      "maas_dev2prod.log",
      "catalina.log",
      "wrapper.log",
      "maas_tenantmanagent.log",
      "costpolicy.log",
      "maas_upg_framework.log",
      "catalog.log",
      "maas_unhandled_exceptions.log",
      "maas_tasksgenerateexecutionplanupgrader.log",
      "maas_workflow.log",
      "maas_ems_asynch_update.log",
      "ess_error.log",
      "maas_scheduleraudit.log",
      "maas_binder.log",
      "http.log",
      "rsyslog.conf",
      "maas_rms_audit.log",
      "maas_rabbit_client.log",
      "lifecycle.log",
      "maas_scheduler.log",
      "action.log",
      "maas_cloud_service.log",
      "maas_cost_allocation.log",
      "management_access_log.xxx",
      "maas_ems_cache.log",
      "maas_notification.log",
      "query.log",
      "access_log.xxxx",
      "csa.log",
      "deployer.log",
      "maas_ems_transaction_manager.log",
      "export.log",
      "upgradetenant.log",
      "maas_mail.log",
      "schedule.log",
      "integration.log",
      "maas_metrics.log",
      "maas_ems_upgrade.log",
      "maas_reports.log",
      "job.log",
      "maas_tasksupg.log",
      "maas_slm_audit.log",
      "search.log",
      "maas_search.log",
      "maas_ems.log",
      "maas_messaging.log",
      "maas_workflow_mng.log",
      "maas_ems_package_management.log",
      "controller.log",
      "management.log",
      "application.log",
      "gateway.log",
      "datahub.log",
      "maas_metadata_customization.log",
      "access_log.xxx",
      "access_log.log",
      "maas_lookup.log",
      "full.log",
      "maas_ems_msp.log",
      "execution.log"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Users",
    "content": "Service Management Automation uses an embedded Identity Manager (IdM) instance for user authentication. The users' authentication types include: DB: User credentials are stored in the IdM database. SAML or OAuth: User credentials are stored in federation IdPs. LDAP: User credentials are stored in LDAP servers. Users management enables you to create users, sync users from IdM, and manage authorizations. Users added or modified in IdM are updated in Suite Administration automatically by the synchronization job that runs once every 2 hours. You can also synchronize the users from IdM manually. Users deleted from IdM aren't synchronized to Suite Administration, but users deleted from Suite Administration are deleted from IdM at the same time. Users created or modified in the LDAP server are updated in IdM automatically by a synchronization job that runs every 12 hours. There's no synchronization job to synchronize federated users (SAML or OAuth) from the IdP to IdM. Related topics How to c",
    "url": "usersmanagement",
    "filename": "usersmanagement",
    "headings": [
      "Related topics"
    ],
    "keywords": [
      "users",
      "related",
      "topics",
      "service",
      "management",
      "automation",
      "uses",
      "embedded",
      "identity",
      "manager",
      "idm",
      "instance",
      "user",
      "authentication.",
      "authentication",
      "types",
      "include",
      "db",
      "credentials",
      "stored",
      "database.",
      "saml",
      "oauth",
      "federation",
      "idps.",
      "ldap",
      "servers.",
      "enables",
      "create",
      "sync",
      "manage",
      "authorizations.",
      "added",
      "modified",
      "updated",
      "suite",
      "administration",
      "automatically",
      "synchronization",
      "job",
      "runs",
      "once",
      "every",
      "hours.",
      "synchronize",
      "manually.",
      "deleted",
      "aren",
      "synchronized",
      "same",
      "time.",
      "created",
      "server",
      "12",
      "there",
      "federated",
      "idp",
      "idm.",
      "edit",
      "delete",
      "accounts"
    ],
    "language": "en",
    "word_count": 108,
    "importance_score": 3.5,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "users",
    "contentLower": "service management automation uses an embedded identity manager (idm) instance for user authentication. the users' authentication types include: db: user credentials are stored in the idm database. saml or oauth: user credentials are stored in federation idps. ldap: user credentials are stored in ldap servers. users management enables you to create users, sync users from idm, and manage authorizations. users added or modified in idm are updated in suite administration automatically by the synchronization job that runs once every 2 hours. you can also synchronize the users from idm manually. users deleted from idm aren't synchronized to suite administration, but users deleted from suite administration are deleted from idm at the same time. users created or modified in the ldap server are updated in idm automatically by a synchronization job that runs every 12 hours. there's no synchronization job to synchronize federated users (saml or oauth) from the idp to idm. related topics how to c",
    "keywordsLower": [
      "users",
      "related",
      "topics",
      "service",
      "management",
      "automation",
      "uses",
      "embedded",
      "identity",
      "manager",
      "idm",
      "instance",
      "user",
      "authentication.",
      "authentication",
      "types",
      "include",
      "db",
      "credentials",
      "stored",
      "database.",
      "saml",
      "oauth",
      "federation",
      "idps.",
      "ldap",
      "servers.",
      "enables",
      "create",
      "sync",
      "manage",
      "authorizations.",
      "added",
      "modified",
      "updated",
      "suite",
      "administration",
      "automatically",
      "synchronization",
      "job",
      "runs",
      "once",
      "every",
      "hours.",
      "synchronize",
      "manually.",
      "deleted",
      "aren",
      "synchronized",
      "same",
      "time.",
      "created",
      "server",
      "12",
      "there",
      "federated",
      "idp",
      "idm.",
      "edit",
      "delete",
      "accounts"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Update Smart Analytics stop words and synonyms",
    "content": "A stop-word list is a list of terms that can be ignored when the search engine is searching or indexing. Typically, stop-word lists include short and common words or prepositions, such as \"a,\" \"the,\" or \"with\" in English. However, they may also include longer words, such as long number strings, or words that are too common to be useful as search targets, such as the term \"internet.\" Stop words are removed from words entered in the \"Search for\" box. They aren't removed during indexing to allow for phrase searching. To update Smart Analytics stop words, follow these steps: Log in to the control plane node as root or a sudo user. Run the cd <Smart Analytics NFS folder>/data/idol/langfiles command to access the <Smart Analytics NFS folder>/data/idol/langfiles folder: The stop words lists are saved as the <language name>.dat file in this folder. Run the chmod 600 <language>.dat command to change the permissions of a language file. Run the vim <language name>.dat command to add a new word or",
    "url": "stopwordssynonyms",
    "filename": "stopwordssynonyms",
    "headings": [],
    "keywords": [
      "update",
      "smart",
      "analytics",
      "stop",
      "words",
      "synonyms",
      "stop-word",
      "list",
      "terms",
      "ignored",
      "search",
      "engine",
      "searching",
      "indexing.",
      "typically",
      "lists",
      "include",
      "short",
      "common",
      "prepositions",
      "such",
      "english.",
      "however",
      "longer",
      "long",
      "number",
      "strings",
      "too",
      "useful",
      "targets",
      "term",
      "internet.",
      "removed",
      "entered",
      "box.",
      "aren",
      "during",
      "indexing",
      "allow",
      "phrase",
      "searching.",
      "follow",
      "steps",
      "log",
      "control",
      "plane",
      "node",
      "root",
      "sudo",
      "user.",
      "run",
      "cd",
      "data",
      "idol",
      "langfiles",
      "command",
      "access",
      "folder",
      "saved",
      ".dat",
      "file",
      "folder.",
      "chmod",
      "600",
      "change",
      "permissions",
      "language",
      "file.",
      "vim",
      "add",
      "new",
      "word",
      "modify",
      "existing",
      "press",
      "esc",
      "enter",
      "wq",
      "save",
      "changes",
      "exit.",
      "restart",
      "all",
      "services",
      "container",
      "kubectl",
      "get",
      "pod",
      "--all-namespaces",
      "grep",
      "smarta",
      "status.",
      "delete",
      "-n",
      "services.",
      "perform",
      "full",
      "reindex",
      "following",
      "instructions"
    ],
    "language": "en",
    "word_count": 105,
    "importance_score": 2.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "update smart analytics stop words and synonyms",
    "contentLower": "a stop-word list is a list of terms that can be ignored when the search engine is searching or indexing. typically, stop-word lists include short and common words or prepositions, such as \"a,\" \"the,\" or \"with\" in english. however, they may also include longer words, such as long number strings, or words that are too common to be useful as search targets, such as the term \"internet.\" stop words are removed from words entered in the \"search for\" box. they aren't removed during indexing to allow for phrase searching. to update smart analytics stop words, follow these steps: log in to the control plane node as root or a sudo user. run the cd <smart analytics nfs folder>/data/idol/langfiles command to access the <smart analytics nfs folder>/data/idol/langfiles folder: the stop words lists are saved as the <language name>.dat file in this folder. run the chmod 600 <language>.dat command to change the permissions of a language file. run the vim <language name>.dat command to add a new word or",
    "keywordsLower": [
      "update",
      "smart",
      "analytics",
      "stop",
      "words",
      "synonyms",
      "stop-word",
      "list",
      "terms",
      "ignored",
      "search",
      "engine",
      "searching",
      "indexing.",
      "typically",
      "lists",
      "include",
      "short",
      "common",
      "prepositions",
      "such",
      "english.",
      "however",
      "longer",
      "long",
      "number",
      "strings",
      "too",
      "useful",
      "targets",
      "term",
      "internet.",
      "removed",
      "entered",
      "box.",
      "aren",
      "during",
      "indexing",
      "allow",
      "phrase",
      "searching.",
      "follow",
      "steps",
      "log",
      "control",
      "plane",
      "node",
      "root",
      "sudo",
      "user.",
      "run",
      "cd",
      "data",
      "idol",
      "langfiles",
      "command",
      "access",
      "folder",
      "saved",
      ".dat",
      "file",
      "folder.",
      "chmod",
      "600",
      "change",
      "permissions",
      "language",
      "file.",
      "vim",
      "add",
      "new",
      "word",
      "modify",
      "existing",
      "press",
      "esc",
      "enter",
      "wq",
      "save",
      "changes",
      "exit.",
      "restart",
      "all",
      "services",
      "container",
      "kubectl",
      "get",
      "pod",
      "--all-namespaces",
      "grep",
      "smarta",
      "status.",
      "delete",
      "-n",
      "services.",
      "perform",
      "full",
      "reindex",
      "following",
      "instructions"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Working with processes",
    "content": "Each record has at least one out-of-the-box process. You can edit a process by adding or deleting phases and transitions. However, the number of metaphases is fixed for each record. Phases and Metaphases Every process is made up of phases and metaphases that reflect the stages of the workflow. The phases are connected by transitions. You can add, move, and delete phases and transitions, and change the direction of a transition. There must be a transition leading to every phase, except the phase at the start of the process. You can define one or more transitions between two phases (see Add a transition in a process for more information). However, a process may contain branches, where multiple transitions from a phase lead to different phases. A process must have exactly one Start phase, which indicates the beginning of the process. You can designate a phase as a Start phase by selecting the Start phase check box in the Properties tab for that phase. The Start phase can't be deleted from",
    "url": "workingwithprocesses",
    "filename": "workingwithprocesses",
    "headings": [
      "Phases and Metaphases",
      "Automatic and manual transitions",
      "Process properties",
      "Metaphase properties",
      "Phase properties",
      "Workflow performance",
      "Related topics"
    ],
    "keywords": [
      "working",
      "processes",
      "phases",
      "metaphases",
      "automatic",
      "manual",
      "transitions",
      "process",
      "properties",
      "metaphase",
      "phase",
      "workflow",
      "performance",
      "related",
      "topics",
      "record",
      "least",
      "one",
      "out-of-the-box",
      "process.",
      "edit",
      "adding",
      "deleting",
      "transitions.",
      "however",
      "number",
      "fixed",
      "record.",
      "every",
      "made",
      "reflect",
      "stages",
      "workflow.",
      "connected",
      "add",
      "move",
      "delete",
      "change",
      "direction",
      "transition.",
      "there",
      "transition",
      "leading",
      "except",
      "start",
      "define",
      "between",
      "two",
      "see",
      "information",
      "contain",
      "branches",
      "multiple",
      "lead",
      "different",
      "phases.",
      "exactly",
      "indicates",
      "beginning",
      "designate",
      "selecting",
      "check",
      "box",
      "tab",
      "phase.",
      "deleted",
      "first",
      "about",
      "note",
      "doesn",
      "located",
      "metaphase.",
      "any",
      "selected",
      "all",
      "last",
      "designated",
      "end",
      "types",
      "manual.",
      "occurs",
      "user",
      "updates",
      "system",
      "automatic.",
      "controlled",
      "condition.",
      "condition",
      "satisfied",
      "advances",
      "next",
      "aborted.",
      "work",
      "concurrently.",
      "automatically",
      "branch.",
      "manually",
      "advance",
      "same",
      "evaluated"
    ],
    "language": "en",
    "word_count": 93,
    "importance_score": 6.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "working with processes",
    "contentLower": "each record has at least one out-of-the-box process. you can edit a process by adding or deleting phases and transitions. however, the number of metaphases is fixed for each record. phases and metaphases every process is made up of phases and metaphases that reflect the stages of the workflow. the phases are connected by transitions. you can add, move, and delete phases and transitions, and change the direction of a transition. there must be a transition leading to every phase, except the phase at the start of the process. you can define one or more transitions between two phases (see add a transition in a process for more information). however, a process may contain branches, where multiple transitions from a phase lead to different phases. a process must have exactly one start phase, which indicates the beginning of the process. you can designate a phase as a start phase by selecting the start phase check box in the properties tab for that phase. the start phase can't be deleted from",
    "keywordsLower": [
      "working",
      "processes",
      "phases",
      "metaphases",
      "automatic",
      "manual",
      "transitions",
      "process",
      "properties",
      "metaphase",
      "phase",
      "workflow",
      "performance",
      "related",
      "topics",
      "record",
      "least",
      "one",
      "out-of-the-box",
      "process.",
      "edit",
      "adding",
      "deleting",
      "transitions.",
      "however",
      "number",
      "fixed",
      "record.",
      "every",
      "made",
      "reflect",
      "stages",
      "workflow.",
      "connected",
      "add",
      "move",
      "delete",
      "change",
      "direction",
      "transition.",
      "there",
      "transition",
      "leading",
      "except",
      "start",
      "define",
      "between",
      "two",
      "see",
      "information",
      "contain",
      "branches",
      "multiple",
      "lead",
      "different",
      "phases.",
      "exactly",
      "indicates",
      "beginning",
      "designate",
      "selecting",
      "check",
      "box",
      "tab",
      "phase.",
      "deleted",
      "first",
      "about",
      "note",
      "doesn",
      "located",
      "metaphase.",
      "any",
      "selected",
      "all",
      "last",
      "designated",
      "end",
      "types",
      "manual.",
      "occurs",
      "user",
      "updates",
      "system",
      "automatic.",
      "controlled",
      "condition.",
      "condition",
      "satisfied",
      "advances",
      "next",
      "aborted.",
      "work",
      "concurrently.",
      "automatically",
      "branch.",
      "manually",
      "advance",
      "same",
      "evaluated"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Validation rule examples",
    "content": "The following examples demonstrate how to formulate rules for each of the validation rule templates. By design: Validation rules do not take effect if they are placed in Leaving/Entering process events. We recommend that you either manually perform the validation or place the validation rules in After change process events. The only exception is the object current_update used in Expression Language, if only current_update is used in your validation rules, you can keep them in Leaving/Entering process events. Starting version 2023.05, validation rules can no longer be added in the Before Change process event. Instead, we recommend that you configure validation rules in the After Change process event. Define fields as mandatory The only parameter in this rule template is fields. Click the link and select the required fields. When the rule runs, the fields become mandatory fields and they are indicated with a red asterisk on any forms on which they appear. Define fields as read-only The o",
    "url": "dslvalidationrules",
    "filename": "dslvalidationrules",
    "headings": [
      "Define fields as mandatory",
      "Define fields as read-only",
      "Validate expression",
      "Validate if field matches pattern",
      "The Input Validation Pattern list",
      "Validate no collisions",
      "Validate that field is in list",
      "Validate that field is in range",
      "Related topics"
    ],
    "keywords": [
      "2023.05",
      "validation",
      "rule",
      "examples",
      "define",
      "fields",
      "mandatory",
      "read-only",
      "validate",
      "expression",
      "field",
      "matches",
      "pattern",
      "input",
      "list",
      "collisions",
      "range",
      "related",
      "topics",
      "following",
      "demonstrate",
      "formulate",
      "rules",
      "templates.",
      "design",
      "take",
      "effect",
      "placed",
      "leaving",
      "entering",
      "process",
      "events.",
      "recommend",
      "either",
      "manually",
      "perform",
      "place",
      "after",
      "change",
      "exception",
      "object",
      "language",
      "keep",
      "starting",
      "version",
      "longer",
      "added",
      "before",
      "event.",
      "instead",
      "configure",
      "parameter",
      "template",
      "fields.",
      "click",
      "link",
      "select",
      "required",
      "runs",
      "become",
      "indicated",
      "red",
      "asterisk",
      "any",
      "forms",
      "appear.",
      "read",
      "property",
      "marked",
      "selected",
      "example",
      "management",
      "set",
      "impactscope",
      "read-only.",
      "impact",
      "form",
      "isn",
      "editable.",
      "enter",
      "phrase",
      "returns",
      "boolean",
      "value.",
      "full",
      "functions",
      "see",
      "syntax.",
      "error",
      "message",
      "relevant",
      "languages.",
      "there",
      "called",
      "cancreateemergencychange",
      "evaluates",
      "can-create-emergency-change",
      "value",
      "based",
      "whether"
    ],
    "language": "en",
    "word_count": 94,
    "importance_score": 6.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "validation rule examples",
    "contentLower": "the following examples demonstrate how to formulate rules for each of the validation rule templates. by design: validation rules do not take effect if they are placed in leaving/entering process events. we recommend that you either manually perform the validation or place the validation rules in after change process events. the only exception is the object current_update used in expression language, if only current_update is used in your validation rules, you can keep them in leaving/entering process events. starting version 2023.05, validation rules can no longer be added in the before change process event. instead, we recommend that you configure validation rules in the after change process event. define fields as mandatory the only parameter in this rule template is fields. click the link and select the required fields. when the rule runs, the fields become mandatory fields and they are indicated with a red asterisk on any forms on which they appear. define fields as read-only the o",
    "keywordsLower": [
      "2023.05",
      "validation",
      "rule",
      "examples",
      "define",
      "fields",
      "mandatory",
      "read-only",
      "validate",
      "expression",
      "field",
      "matches",
      "pattern",
      "input",
      "list",
      "collisions",
      "range",
      "related",
      "topics",
      "following",
      "demonstrate",
      "formulate",
      "rules",
      "templates.",
      "design",
      "take",
      "effect",
      "placed",
      "leaving",
      "entering",
      "process",
      "events.",
      "recommend",
      "either",
      "manually",
      "perform",
      "place",
      "after",
      "change",
      "exception",
      "object",
      "language",
      "keep",
      "starting",
      "version",
      "longer",
      "added",
      "before",
      "event.",
      "instead",
      "configure",
      "parameter",
      "template",
      "fields.",
      "click",
      "link",
      "select",
      "required",
      "runs",
      "become",
      "indicated",
      "red",
      "asterisk",
      "any",
      "forms",
      "appear.",
      "read",
      "property",
      "marked",
      "selected",
      "example",
      "management",
      "set",
      "impactscope",
      "read-only.",
      "impact",
      "form",
      "isn",
      "editable.",
      "enter",
      "phrase",
      "returns",
      "boolean",
      "value.",
      "full",
      "functions",
      "see",
      "syntax.",
      "error",
      "message",
      "relevant",
      "languages.",
      "there",
      "called",
      "cancreateemergencychange",
      "evaluates",
      "can-create-emergency-change",
      "value",
      "based",
      "whether"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Work with notification templates",
    "content": "The following describes how you can work with notification templates. If you customize default templates or create new templates, and your community uses different languages, you must localize any new notification content. You must choose the languages and provide the translated message text that appears in the revised or new template. When a notification template uses the ${:entity.Type} variable, the entity type is localized to the correct language when the notification is sent. Use the ${:entity.Type} variable where the entity type needs to be localized and use ${entity.type} where the entity type must not be localized (for example, in a record link URL). How to view a notification template From the main menu, select Administration > Configuration > Studio. Select a record type. For example, select Incident. Select the Notifications tab. The left pane of the tab displays a list of all existing templates for the record type. The list shows the title that appears as a heading for the ",
    "url": "workwithnotificationtemplates",
    "filename": "workwithnotificationtemplates",
    "headings": [
      "How to view a notification template",
      "How to create a notification template",
      "How to delete a notification template",
      "How to update a notification template",
      "How to edit a system notification template",
      "How to customize the date/time format in notification templates according to language",
      "Related topics"
    ],
    "keywords": [
      "entity.Id",
      "entity.Type",
      "opentext.com",
      "work",
      "notification",
      "templates",
      "view",
      "template",
      "create",
      "delete",
      "update",
      "edit",
      "system",
      "customize",
      "date",
      "time",
      "format",
      "according",
      "language",
      "related",
      "topics",
      "following",
      "describes",
      "templates.",
      "default",
      "new",
      "community",
      "uses",
      "different",
      "languages",
      "localize",
      "any",
      "content.",
      "choose",
      "provide",
      "translated",
      "message",
      "text",
      "appears",
      "revised",
      "template.",
      "variable",
      "entity",
      "type",
      "localized",
      "correct",
      "sent.",
      "needs",
      "example",
      "record",
      "link",
      "url",
      "main",
      "menu",
      "select",
      "administration",
      "configuration",
      "studio.",
      "type.",
      "incident.",
      "notifications",
      "tab.",
      "left",
      "pane",
      "tab",
      "displays",
      "list",
      "all",
      "existing",
      "shows",
      "title",
      "heading",
      "email",
      "notification.",
      "entire",
      "right",
      "pane.",
      "see",
      "appear",
      "sent",
      "click",
      "preview",
      "toolbar.",
      "change",
      "order",
      "side",
      "bar.",
      "move",
      "it.",
      "scroll",
      "through",
      "languages.",
      "permission",
      "add",
      "solution",
      "provides",
      "rich",
      "editor",
      "formatted",
      "insert"
    ],
    "language": "en",
    "word_count": 92,
    "importance_score": 6.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "work with notification templates",
    "contentLower": "the following describes how you can work with notification templates. if you customize default templates or create new templates, and your community uses different languages, you must localize any new notification content. you must choose the languages and provide the translated message text that appears in the revised or new template. when a notification template uses the ${:entity.type} variable, the entity type is localized to the correct language when the notification is sent. use the ${:entity.type} variable where the entity type needs to be localized and use ${entity.type} where the entity type must not be localized (for example, in a record link url). how to view a notification template from the main menu, select administration > configuration > studio. select a record type. for example, select incident. select the notifications tab. the left pane of the tab displays a list of all existing templates for the record type. the list shows the title that appears as a heading for the ",
    "keywordsLower": [
      "entity.id",
      "entity.type",
      "opentext.com",
      "work",
      "notification",
      "templates",
      "view",
      "template",
      "create",
      "delete",
      "update",
      "edit",
      "system",
      "customize",
      "date",
      "time",
      "format",
      "according",
      "language",
      "related",
      "topics",
      "following",
      "describes",
      "templates.",
      "default",
      "new",
      "community",
      "uses",
      "different",
      "languages",
      "localize",
      "any",
      "content.",
      "choose",
      "provide",
      "translated",
      "message",
      "text",
      "appears",
      "revised",
      "template.",
      "variable",
      "entity",
      "type",
      "localized",
      "correct",
      "sent.",
      "needs",
      "example",
      "record",
      "link",
      "url",
      "main",
      "menu",
      "select",
      "administration",
      "configuration",
      "studio.",
      "type.",
      "incident.",
      "notifications",
      "tab.",
      "left",
      "pane",
      "tab",
      "displays",
      "list",
      "all",
      "existing",
      "shows",
      "title",
      "heading",
      "email",
      "notification.",
      "entire",
      "right",
      "pane.",
      "see",
      "appear",
      "sent",
      "click",
      "preview",
      "toolbar.",
      "change",
      "order",
      "side",
      "bar.",
      "move",
      "it.",
      "scroll",
      "through",
      "languages.",
      "permission",
      "add",
      "solution",
      "provides",
      "rich",
      "editor",
      "formatted",
      "insert"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "UI components",
    "content": "The UI components tab enables you to configure UI elements to improve both usability and visual appeal. You can use UI components to customize UI elements for all record types except Model. To access this tab: From the main menu, select Administration > Configuration > Studio. This automatically opens the UI components tab. From the drop-down in the upper left corner of the page, select a record type. Record dropdown You can use the Record dropdown setting to configure a dropdown list by providing additional context to a record. This helps distinguish between items with similar names. For example, adding status and email information to a person record makes it easier for agents to select the correct value. To do this, follow these steps: In the Agent Interface section, click Add columns. In the dialog box that opens, type the field name and click Add. You can continue adding multiple fields and click Done when finished. You can add up to three fields of these data types: SMALL_TEXT, EN",
    "url": "uicomponents",
    "filename": "uicomponents",
    "headings": [
      "Record dropdown"
    ],
    "keywords": [
      "ui",
      "components",
      "record",
      "dropdown",
      "tab",
      "enables",
      "configure",
      "elements",
      "improve",
      "both",
      "usability",
      "visual",
      "appeal.",
      "customize",
      "all",
      "types",
      "except",
      "model.",
      "access",
      "main",
      "menu",
      "select",
      "administration",
      "configuration",
      "studio.",
      "automatically",
      "opens",
      "tab.",
      "drop-down",
      "upper",
      "left",
      "corner",
      "page",
      "type.",
      "setting",
      "list",
      "providing",
      "additional",
      "context",
      "record.",
      "helps",
      "distinguish",
      "between",
      "items",
      "similar",
      "names.",
      "example",
      "adding",
      "status",
      "email",
      "information",
      "person",
      "makes",
      "easier",
      "agents",
      "correct",
      "value.",
      "follow",
      "steps",
      "agent",
      "interface",
      "section",
      "click",
      "add",
      "columns.",
      "dialog",
      "box",
      "type",
      "field",
      "name",
      "add.",
      "continue",
      "multiple",
      "fields",
      "done",
      "finished.",
      "three",
      "data",
      "enum",
      "email.",
      "settings",
      "separator",
      "divides",
      "custom",
      "displayed",
      "contain",
      "five",
      "characters.",
      "default",
      "hyphen",
      "move",
      "change",
      "order",
      "out-of-the-box",
      "ootb",
      "always",
      "before",
      "ones",
      "customize.",
      "save."
    ],
    "language": "en",
    "word_count": 106,
    "importance_score": 3.5,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "ui components",
    "contentLower": "the ui components tab enables you to configure ui elements to improve both usability and visual appeal. you can use ui components to customize ui elements for all record types except model. to access this tab: from the main menu, select administration > configuration > studio. this automatically opens the ui components tab. from the drop-down in the upper left corner of the page, select a record type. record dropdown you can use the record dropdown setting to configure a dropdown list by providing additional context to a record. this helps distinguish between items with similar names. for example, adding status and email information to a person record makes it easier for agents to select the correct value. to do this, follow these steps: in the agent interface section, click add columns. in the dialog box that opens, type the field name and click add. you can continue adding multiple fields and click done when finished. you can add up to three fields of these data types: small_text, en",
    "keywordsLower": [
      "ui",
      "components",
      "record",
      "dropdown",
      "tab",
      "enables",
      "configure",
      "elements",
      "improve",
      "both",
      "usability",
      "visual",
      "appeal.",
      "customize",
      "all",
      "types",
      "except",
      "model.",
      "access",
      "main",
      "menu",
      "select",
      "administration",
      "configuration",
      "studio.",
      "automatically",
      "opens",
      "tab.",
      "drop-down",
      "upper",
      "left",
      "corner",
      "page",
      "type.",
      "setting",
      "list",
      "providing",
      "additional",
      "context",
      "record.",
      "helps",
      "distinguish",
      "between",
      "items",
      "similar",
      "names.",
      "example",
      "adding",
      "status",
      "email",
      "information",
      "person",
      "makes",
      "easier",
      "agents",
      "correct",
      "value.",
      "follow",
      "steps",
      "agent",
      "interface",
      "section",
      "click",
      "add",
      "columns.",
      "dialog",
      "box",
      "type",
      "field",
      "name",
      "add.",
      "continue",
      "multiple",
      "fields",
      "done",
      "finished.",
      "three",
      "data",
      "enum",
      "email.",
      "settings",
      "separator",
      "divides",
      "custom",
      "displayed",
      "contain",
      "five",
      "characters.",
      "default",
      "hyphen",
      "move",
      "change",
      "order",
      "out-of-the-box",
      "ootb",
      "always",
      "before",
      "ones",
      "customize.",
      "save."
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "User-based license assignment and consumption",
    "content": "This topic is applicable to Service Management Express, Service Management Premium, and Asset Management licenses. Agent users can consume one of the following types of licenses: named licenses, and concurrent licenses. Each named license or concurrent license has a capacity value, which indicates how many users (named users or concurrent users) can consume the license: The capacity of a named license is in a one-to-one ratio to the number of users. Concurrent licenses are also known as group licenses. They're floating licenses for all agent users. Once a concurrent license is released, another user can consume it. The number of users that are entitled to use a concurrent license can be more than its capacity. License assignment In the agent interface, the Administration > People page displays all licenses assigned to the tenant. When assigning licenses to a user, the tenant admin can select from all licenses assigned to the tenant. This means the tenant admin can assign multiple licen",
    "url": "userlicenseconsumption",
    "filename": "userlicenseconsumption",
    "headings": [
      "License assignment",
      "License consumption",
      "License release",
      "Inactivity",
      "Logout",
      "Related topics"
    ],
    "keywords": [
      "user-based",
      "license",
      "assignment",
      "consumption",
      "release",
      "inactivity",
      "logout",
      "related",
      "topics",
      "topic",
      "applicable",
      "service",
      "management",
      "express",
      "premium",
      "asset",
      "licenses.",
      "agent",
      "users",
      "consume",
      "one",
      "following",
      "types",
      "licenses",
      "named",
      "concurrent",
      "capacity",
      "value",
      "indicates",
      "many",
      "one-to-one",
      "ratio",
      "number",
      "users.",
      "known",
      "group",
      "re",
      "floating",
      "all",
      "once",
      "released",
      "another",
      "user",
      "it.",
      "entitled",
      "capacity.",
      "interface",
      "administration",
      "people",
      "page",
      "displays",
      "assigned",
      "tenant.",
      "assigning",
      "tenant",
      "admin",
      "select",
      "means",
      "assign",
      "multiple",
      "user.",
      "manually",
      "case",
      "system",
      "doesn",
      "automatically",
      "any",
      "logs",
      "interface.",
      "assigns",
      "both",
      "consumes",
      "after",
      "login.",
      "license.",
      "since",
      "runs",
      "out",
      "next",
      "releases",
      "logged-in",
      "idle",
      "period",
      "time",
      "clicks",
      "button.",
      "30",
      "minutes.",
      "inactive",
      "minutes",
      "example",
      "starts",
      "00",
      "pm",
      "ready",
      "pm.",
      "meantime",
      "there",
      "background",
      "cron"
    ],
    "language": "en",
    "word_count": 101,
    "importance_score": 6.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "user-based license assignment and consumption",
    "contentLower": "this topic is applicable to service management express, service management premium, and asset management licenses. agent users can consume one of the following types of licenses: named licenses, and concurrent licenses. each named license or concurrent license has a capacity value, which indicates how many users (named users or concurrent users) can consume the license: the capacity of a named license is in a one-to-one ratio to the number of users. concurrent licenses are also known as group licenses. they're floating licenses for all agent users. once a concurrent license is released, another user can consume it. the number of users that are entitled to use a concurrent license can be more than its capacity. license assignment in the agent interface, the administration > people page displays all licenses assigned to the tenant. when assigning licenses to a user, the tenant admin can select from all licenses assigned to the tenant. this means the tenant admin can assign multiple licen",
    "keywordsLower": [
      "user-based",
      "license",
      "assignment",
      "consumption",
      "release",
      "inactivity",
      "logout",
      "related",
      "topics",
      "topic",
      "applicable",
      "service",
      "management",
      "express",
      "premium",
      "asset",
      "licenses.",
      "agent",
      "users",
      "consume",
      "one",
      "following",
      "types",
      "licenses",
      "named",
      "concurrent",
      "capacity",
      "value",
      "indicates",
      "many",
      "one-to-one",
      "ratio",
      "number",
      "users.",
      "known",
      "group",
      "re",
      "floating",
      "all",
      "once",
      "released",
      "another",
      "user",
      "it.",
      "entitled",
      "capacity.",
      "interface",
      "administration",
      "people",
      "page",
      "displays",
      "assigned",
      "tenant.",
      "assigning",
      "tenant",
      "admin",
      "select",
      "means",
      "assign",
      "multiple",
      "user.",
      "manually",
      "case",
      "system",
      "doesn",
      "automatically",
      "any",
      "logs",
      "interface.",
      "assigns",
      "both",
      "consumes",
      "after",
      "login.",
      "license.",
      "since",
      "runs",
      "out",
      "next",
      "releases",
      "logged-in",
      "idle",
      "period",
      "time",
      "clicks",
      "button.",
      "30",
      "minutes.",
      "inactive",
      "minutes",
      "example",
      "starts",
      "00",
      "pm",
      "ready",
      "pm.",
      "meantime",
      "there",
      "background",
      "cron"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Users and contacts",
    "content": "There are two types of person records: users and contacts. Users can log in to Service Management; contacts can't. Users and contacts have the same fields, except that users also have license, role, and group membership information. A badge in the upper right corner of the page indicates whether a person is a user or contact. You can import and delete users from Suite Administration; or, if the suite admin has enabled the \"Manage users in tenant\" feature, you as a tenant admin can also create users in Service Management manually. Service Management users must have a user record and an assigned role before they can log in to the application. If you are a tenant admin, part of your responsibilities include managing user records, creating user groups, lists of contacts, and managing user roles. You can create contact records with information about internal or external users. How to view users and contacts The People page displays both users and contacts. From the main menu, select Adminis",
    "url": "userscontacts",
    "filename": "userscontacts",
    "headings": [
      "How to view users and contacts",
      "How to add, edit, or delete users in Suite Administration",
      "How to manage users in the tenant",
      "Unlock users",
      "Reset password",
      "Change person type",
      "How to create and delete users or contacts",
      "How to edit a user or contact record",
      "User and contact details",
      "Enable non-tenant admins to manage user lifecycle",
      "Best practices",
      "Related topics"
    ],
    "keywords": [
      "USERS.To",
      "default.Any",
      "users.When",
      "Discussions.To",
      "rules.When",
      "CONTACTS.To",
      "users",
      "contacts",
      "view",
      "add",
      "edit",
      "delete",
      "suite",
      "administration",
      "manage",
      "tenant",
      "unlock",
      "reset",
      "password",
      "change",
      "person",
      "type",
      "create",
      "user",
      "contact",
      "record",
      "details",
      "enable",
      "non-tenant",
      "admins",
      "lifecycle",
      "best",
      "practices",
      "related",
      "topics",
      "there",
      "two",
      "types",
      "records",
      "contacts.",
      "log",
      "service",
      "management",
      "t.",
      "same",
      "fields",
      "except",
      "license",
      "role",
      "group",
      "membership",
      "information.",
      "badge",
      "upper",
      "right",
      "corner",
      "page",
      "indicates",
      "whether",
      "contact.",
      "import",
      "admin",
      "enabled",
      "feature",
      "manually.",
      "assigned",
      "before",
      "application.",
      "part",
      "responsibilities",
      "include",
      "managing",
      "creating",
      "groups",
      "lists",
      "roles.",
      "information",
      "about",
      "internal",
      "external",
      "users.",
      "people",
      "displays",
      "both",
      "main",
      "menu",
      "select",
      "master",
      "data",
      "people.select",
      "required",
      "display",
      "active",
      "click",
      "all",
      "people.",
      "views",
      "deleted.",
      "new",
      "administration."
    ],
    "language": "en",
    "word_count": 102,
    "importance_score": 6.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "users and contacts",
    "contentLower": "there are two types of person records: users and contacts. users can log in to service management; contacts can't. users and contacts have the same fields, except that users also have license, role, and group membership information. a badge in the upper right corner of the page indicates whether a person is a user or contact. you can import and delete users from suite administration; or, if the suite admin has enabled the \"manage users in tenant\" feature, you as a tenant admin can also create users in service management manually. service management users must have a user record and an assigned role before they can log in to the application. if you are a tenant admin, part of your responsibilities include managing user records, creating user groups, lists of contacts, and managing user roles. you can create contact records with information about internal or external users. how to view users and contacts the people page displays both users and contacts. from the main menu, select adminis",
    "keywordsLower": [
      "users.to",
      "default.any",
      "users.when",
      "discussions.to",
      "rules.when",
      "contacts.to",
      "users",
      "contacts",
      "view",
      "add",
      "edit",
      "delete",
      "suite",
      "administration",
      "manage",
      "tenant",
      "unlock",
      "reset",
      "password",
      "change",
      "person",
      "type",
      "create",
      "user",
      "contact",
      "record",
      "details",
      "enable",
      "non-tenant",
      "admins",
      "lifecycle",
      "best",
      "practices",
      "related",
      "topics",
      "there",
      "two",
      "types",
      "records",
      "contacts.",
      "log",
      "service",
      "management",
      "t.",
      "same",
      "fields",
      "except",
      "license",
      "role",
      "group",
      "membership",
      "information.",
      "badge",
      "upper",
      "right",
      "corner",
      "page",
      "indicates",
      "whether",
      "contact.",
      "import",
      "admin",
      "enabled",
      "feature",
      "manually.",
      "assigned",
      "before",
      "application.",
      "part",
      "responsibilities",
      "include",
      "managing",
      "creating",
      "groups",
      "lists",
      "roles.",
      "information",
      "about",
      "internal",
      "external",
      "users.",
      "people",
      "displays",
      "both",
      "main",
      "menu",
      "select",
      "master",
      "data",
      "people.select",
      "required",
      "display",
      "active",
      "click",
      "all",
      "people.",
      "views",
      "deleted.",
      "new",
      "administration."
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "User management reports",
    "content": "User Management Reports (UMR) can provide administrators with detailed reports of user role assignments and license usage. To enable this feature, go to Administration > Configuration > Application Settings, then set the Enable User Management Reports setting to On. When this feature is enabled, you can select Administration > People > User Management Reports to view the following information: The people and the groups assigned with a particular role The roles assigned to a particular person (either directly assigned or inherited from groups) The list of licenses with usage information, start date, and expiration date The list of users allocated with a particular license and the list of logged-in users The permissions to view the information in the PEOPLE, GROUPS, and ROLES tabs depend on whether you are assigned with corresponding role permissions. See Enable User Management Reports. The information in the LICENSES tab is only available for users with tenant admin role. Currently, Use",
    "url": "usermanagementreports",
    "filename": "usermanagementreports",
    "headings": [
      "People",
      "Group",
      "Roles",
      "License"
    ],
    "keywords": [
      "user",
      "management",
      "reports",
      "people",
      "group",
      "roles",
      "license",
      "umr",
      "provide",
      "administrators",
      "detailed",
      "role",
      "assignments",
      "usage.",
      "enable",
      "feature",
      "go",
      "administration",
      "configuration",
      "application",
      "settings",
      "set",
      "setting",
      "on.",
      "enabled",
      "select",
      "view",
      "following",
      "information",
      "groups",
      "assigned",
      "particular",
      "person",
      "either",
      "directly",
      "inherited",
      "list",
      "licenses",
      "usage",
      "start",
      "date",
      "expiration",
      "users",
      "allocated",
      "logged-in",
      "permissions",
      "tabs",
      "depend",
      "whether",
      "corresponding",
      "permissions.",
      "see",
      "reports.",
      "tab",
      "available",
      "tenant",
      "admin",
      "role.",
      "currently",
      "supports",
      "english",
      "language.",
      "openl10n",
      "localization",
      "isn",
      "supported",
      "person.",
      "possible",
      "actions",
      "filter",
      "bar",
      "search",
      "click",
      "record",
      "results",
      "including",
      "back",
      "exit",
      "details",
      "service",
      "management.",
      "export",
      "excel",
      "contents",
      "current",
      "page",
      "file.",
      "collapse",
      "expand",
      "included",
      "group.",
      "further",
      "users.",
      "id",
      "activated",
      "model",
      "edition",
      "express",
      "premium",
      "access"
    ],
    "language": "en",
    "word_count": 98,
    "importance_score": 5.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "user management reports",
    "contentLower": "user management reports (umr) can provide administrators with detailed reports of user role assignments and license usage. to enable this feature, go to administration > configuration > application settings, then set the enable user management reports setting to on. when this feature is enabled, you can select administration > people > user management reports to view the following information: the people and the groups assigned with a particular role the roles assigned to a particular person (either directly assigned or inherited from groups) the list of licenses with usage information, start date, and expiration date the list of users allocated with a particular license and the list of logged-in users the permissions to view the information in the people, groups, and roles tabs depend on whether you are assigned with corresponding role permissions. see enable user management reports. the information in the licenses tab is only available for users with tenant admin role. currently, use",
    "keywordsLower": [
      "user",
      "management",
      "reports",
      "people",
      "group",
      "roles",
      "license",
      "umr",
      "provide",
      "administrators",
      "detailed",
      "role",
      "assignments",
      "usage.",
      "enable",
      "feature",
      "go",
      "administration",
      "configuration",
      "application",
      "settings",
      "set",
      "setting",
      "on.",
      "enabled",
      "select",
      "view",
      "following",
      "information",
      "groups",
      "assigned",
      "particular",
      "person",
      "either",
      "directly",
      "inherited",
      "list",
      "licenses",
      "usage",
      "start",
      "date",
      "expiration",
      "users",
      "allocated",
      "logged-in",
      "permissions",
      "tabs",
      "depend",
      "whether",
      "corresponding",
      "permissions.",
      "see",
      "reports.",
      "tab",
      "available",
      "tenant",
      "admin",
      "role.",
      "currently",
      "supports",
      "english",
      "language.",
      "openl10n",
      "localization",
      "isn",
      "supported",
      "person.",
      "possible",
      "actions",
      "filter",
      "bar",
      "search",
      "click",
      "record",
      "results",
      "including",
      "back",
      "exit",
      "details",
      "service",
      "management.",
      "export",
      "excel",
      "contents",
      "current",
      "page",
      "file.",
      "collapse",
      "expand",
      "included",
      "group.",
      "further",
      "users.",
      "id",
      "activated",
      "model",
      "edition",
      "express",
      "premium",
      "access"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Vendor (Company) process - Business rules",
    "content": "In the out-of-the-box Vendor (Company) workflow, the following business rules apply to the indicated metaphase or phase. Normal process - all phases Event Condition Service Management action Rendering forms Id = Active Caution note = hidden Caution phase Event Condition Action After change None Caution note = mandatory Related topics Company Management Company workflow How to create a company record How to edit a company record",
    "url": "processvendor",
    "filename": "processvendor",
    "headings": [
      "Normal process - all phases",
      "Caution phase",
      "Related topics"
    ],
    "keywords": [
      "vendor",
      "company",
      "process",
      "business",
      "rules",
      "normal",
      "all",
      "phases",
      "caution",
      "phase",
      "related",
      "topics",
      "out-of-the-box",
      "workflow",
      "following",
      "apply",
      "indicated",
      "metaphase",
      "phase.",
      "event",
      "condition",
      "service",
      "management",
      "action",
      "rendering",
      "forms",
      "id",
      "active",
      "note",
      "hidden",
      "after",
      "change",
      "none",
      "mandatory",
      "create",
      "record",
      "edit"
    ],
    "language": "en",
    "word_count": 55,
    "importance_score": 2.5,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "vendor (company) process - business rules",
    "contentLower": "in the out-of-the-box vendor (company) workflow, the following business rules apply to the indicated metaphase or phase. normal process - all phases event condition service management action rendering forms id = active caution note = hidden caution phase event condition action after change none caution note = mandatory related topics company management company workflow how to create a company record how to edit a company record",
    "keywordsLower": [
      "vendor",
      "company",
      "process",
      "business",
      "rules",
      "normal",
      "all",
      "phases",
      "caution",
      "phase",
      "related",
      "topics",
      "out-of-the-box",
      "workflow",
      "following",
      "apply",
      "indicated",
      "metaphase",
      "phase.",
      "event",
      "condition",
      "service",
      "management",
      "action",
      "rendering",
      "forms",
      "id",
      "active",
      "note",
      "hidden",
      "after",
      "change",
      "none",
      "mandatory",
      "create",
      "record",
      "edit"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Use case scenarios - customizing with business rules",
    "content": "Creating a record from a record: How to add a new field Delegating permissions for service catalog creation and editing Using rules to filter a drop-down selection Using rules to concatenate multiple text into one field Using a rule to display only third level categories for incident, request, or change records Using rules for automatic assignment and suggestions for groups Using a rule to add the date and time (in a readable format) to a comment Using a rule to remove a value from a list Setting a closed record to read-only",
    "url": "ucscenarios",
    "filename": "ucscenarios",
    "headings": [],
    "keywords": [
      "case",
      "scenarios",
      "customizing",
      "business",
      "rules",
      "creating",
      "record",
      "add",
      "new",
      "field",
      "delegating",
      "permissions",
      "service",
      "catalog",
      "creation",
      "editing",
      "filter",
      "drop-down",
      "selection",
      "concatenate",
      "multiple",
      "text",
      "one",
      "rule",
      "display",
      "third",
      "level",
      "categories",
      "incident",
      "request",
      "change",
      "records",
      "automatic",
      "assignment",
      "suggestions",
      "groups",
      "date",
      "time",
      "readable",
      "format",
      "comment",
      "remove",
      "value",
      "list",
      "setting",
      "closed",
      "read-only"
    ],
    "language": "en",
    "word_count": 56,
    "importance_score": 1.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "use case scenarios - customizing with business rules",
    "contentLower": "creating a record from a record: how to add a new field delegating permissions for service catalog creation and editing using rules to filter a drop-down selection using rules to concatenate multiple text into one field using a rule to display only third level categories for incident, request, or change records using rules for automatic assignment and suggestions for groups using a rule to add the date and time (in a readable format) to a comment using a rule to remove a value from a list setting a closed record to read-only",
    "keywordsLower": [
      "case",
      "scenarios",
      "customizing",
      "business",
      "rules",
      "creating",
      "record",
      "add",
      "new",
      "field",
      "delegating",
      "permissions",
      "service",
      "catalog",
      "creation",
      "editing",
      "filter",
      "drop-down",
      "selection",
      "concatenate",
      "multiple",
      "text",
      "one",
      "rule",
      "display",
      "third",
      "level",
      "categories",
      "incident",
      "request",
      "change",
      "records",
      "automatic",
      "assignment",
      "suggestions",
      "groups",
      "date",
      "time",
      "readable",
      "format",
      "comment",
      "remove",
      "value",
      "list",
      "setting",
      "closed",
      "read-only"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Using rules to filter drop-down selection",
    "content": "The following use case scenario demonstrates how you can customize the form for incidents to display all three support groups in a single drop-down. The aim was to help users select an assignment group for an incident, based on the three support groups of the associated service. The first idea was to create three separate rules, one for each group. However, this presented each group with its own header, and took up too much screen real estate. A better approach was to create a single rule that displayed all three fields under a single header. This was achieved by using the union function to combine three different fields from the service record into a single filter. The implementation (shown below) saves screen real estate, and puts key information in front of the user in a way that may be more suitable. Although the use case is specific, the techniques involved can easily be adapted. Create the rule From the main menu, select Administration > Configuration > Studio > Processes and Rul",
    "url": "rulesfilterselection",
    "filename": "rulesfilterselection",
    "headings": [
      "Variation",
      "Create the rule",
      "Edit the rule",
      "Implementation"
    ],
    "keywords": [
      "OrganizationalGroup.Id",
      "SupportLevel1Group.Id",
      "SupportLevel3Group.Id",
      "SupportLevel2Group.Id",
      "rules",
      "filter",
      "drop-down",
      "selection",
      "variation",
      "create",
      "rule",
      "edit",
      "implementation",
      "following",
      "case",
      "scenario",
      "demonstrates",
      "customize",
      "form",
      "incidents",
      "display",
      "all",
      "three",
      "support",
      "groups",
      "single",
      "drop-down.",
      "aim",
      "help",
      "users",
      "select",
      "assignment",
      "group",
      "incident",
      "based",
      "associated",
      "service.",
      "first",
      "idea",
      "separate",
      "one",
      "group.",
      "however",
      "presented",
      "own",
      "header",
      "took",
      "too",
      "much",
      "screen",
      "real",
      "estate.",
      "better",
      "approach",
      "displayed",
      "fields",
      "under",
      "header.",
      "achieved",
      "union",
      "function",
      "combine",
      "different",
      "service",
      "record",
      "filter.",
      "shown",
      "below",
      "saves",
      "estate",
      "puts",
      "key",
      "information",
      "front",
      "user",
      "way",
      "suitable.",
      "although",
      "specific",
      "techniques",
      "involved",
      "easily",
      "adapted.",
      "main",
      "menu",
      "administration",
      "configuration",
      "studio",
      "processes",
      "rules.",
      "type.",
      "tree",
      "left",
      "top",
      "level",
      "rendering",
      "forms",
      "click",
      "add",
      "if...then"
    ],
    "language": "en",
    "word_count": 104,
    "importance_score": 4.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "using rules to filter drop-down selection",
    "contentLower": "the following use case scenario demonstrates how you can customize the form for incidents to display all three support groups in a single drop-down. the aim was to help users select an assignment group for an incident, based on the three support groups of the associated service. the first idea was to create three separate rules, one for each group. however, this presented each group with its own header, and took up too much screen real estate. a better approach was to create a single rule that displayed all three fields under a single header. this was achieved by using the union function to combine three different fields from the service record into a single filter. the implementation (shown below) saves screen real estate, and puts key information in front of the user in a way that may be more suitable. although the use case is specific, the techniques involved can easily be adapted. create the rule from the main menu, select administration > configuration > studio > processes and rul",
    "keywordsLower": [
      "organizationalgroup.id",
      "supportlevel1group.id",
      "supportlevel3group.id",
      "supportlevel2group.id",
      "rules",
      "filter",
      "drop-down",
      "selection",
      "variation",
      "create",
      "rule",
      "edit",
      "implementation",
      "following",
      "case",
      "scenario",
      "demonstrates",
      "customize",
      "form",
      "incidents",
      "display",
      "all",
      "three",
      "support",
      "groups",
      "single",
      "drop-down.",
      "aim",
      "help",
      "users",
      "select",
      "assignment",
      "group",
      "incident",
      "based",
      "associated",
      "service.",
      "first",
      "idea",
      "separate",
      "one",
      "group.",
      "however",
      "presented",
      "own",
      "header",
      "took",
      "too",
      "much",
      "screen",
      "real",
      "estate.",
      "better",
      "approach",
      "displayed",
      "fields",
      "under",
      "header.",
      "achieved",
      "union",
      "function",
      "combine",
      "different",
      "service",
      "record",
      "filter.",
      "shown",
      "below",
      "saves",
      "estate",
      "puts",
      "key",
      "information",
      "front",
      "user",
      "way",
      "suitable.",
      "although",
      "specific",
      "techniques",
      "involved",
      "easily",
      "adapted.",
      "main",
      "menu",
      "administration",
      "configuration",
      "studio",
      "processes",
      "rules.",
      "type.",
      "tree",
      "left",
      "top",
      "level",
      "rendering",
      "forms",
      "click",
      "add",
      "if...then"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Using rules to concatenate multiple text into one field",
    "content": "The following use case demonstrates how to use the concat function to concatenate text. Assume you want to have the Title for requests conform to a standard pattern of a prefix and the Display label of the related offering. Create the rule From the main menu, select Administration > Configuration > Studio > Processes and Rules. Select the Request record type. In the tree on the left, select Request (the top level of the tree). In After change, click Add, then select Simple rule. In Actions, select Set field. Click OK. Edit the rule Click field, and select Title. Then click OK. Click value, and paste in the following expression: ${concat('Your Added Prefix ', entity.RequestsOffering.DisplayLabel)} Then click OK. Click Save. Implementation Using the preceding rule, when there is a change to a request, the title becomes Your Added Prefix and the Display Label of the related offering. The following shows the effect on the request title when the display label of the offering is Laptop repla",
    "url": "concattext",
    "filename": "concattext",
    "headings": [
      "Create the rule",
      "Edit the rule",
      "Implementation"
    ],
    "keywords": [
      "rules",
      "concatenate",
      "multiple",
      "text",
      "one",
      "field",
      "create",
      "rule",
      "edit",
      "implementation",
      "following",
      "case",
      "demonstrates",
      "concat",
      "function",
      "text.",
      "assume",
      "want",
      "title",
      "requests",
      "conform",
      "standard",
      "pattern",
      "prefix",
      "display",
      "label",
      "related",
      "offering.",
      "main",
      "menu",
      "select",
      "administration",
      "configuration",
      "studio",
      "processes",
      "rules.",
      "request",
      "record",
      "type.",
      "tree",
      "left",
      "top",
      "level",
      "after",
      "change",
      "click",
      "add",
      "simple",
      "rule.",
      "actions",
      "set",
      "field.",
      "ok.",
      "title.",
      "value",
      "paste",
      "expression",
      "added",
      "entity.requestsoffering.displaylabel",
      "save.",
      "preceding",
      "there",
      "becomes",
      "shows",
      "effect",
      "offering",
      "laptop",
      "replacement.",
      "tip",
      "depending",
      "particular",
      "best",
      "practice",
      "typically",
      "run",
      "once.",
      "achieve",
      "adding",
      "transition",
      "condition."
    ],
    "language": "en",
    "word_count": 104,
    "importance_score": 3.5,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "using rules to concatenate multiple text into one field",
    "contentLower": "the following use case demonstrates how to use the concat function to concatenate text. assume you want to have the title for requests conform to a standard pattern of a prefix and the display label of the related offering. create the rule from the main menu, select administration > configuration > studio > processes and rules. select the request record type. in the tree on the left, select request (the top level of the tree). in after change, click add, then select simple rule. in actions, select set field. click ok. edit the rule click field, and select title. then click ok. click value, and paste in the following expression: ${concat('your added prefix ', entity.requestsoffering.displaylabel)} then click ok. click save. implementation using the preceding rule, when there is a change to a request, the title becomes your added prefix and the display label of the related offering. the following shows the effect on the request title when the display label of the offering is laptop repla",
    "keywordsLower": [
      "rules",
      "concatenate",
      "multiple",
      "text",
      "one",
      "field",
      "create",
      "rule",
      "edit",
      "implementation",
      "following",
      "case",
      "demonstrates",
      "concat",
      "function",
      "text.",
      "assume",
      "want",
      "title",
      "requests",
      "conform",
      "standard",
      "pattern",
      "prefix",
      "display",
      "label",
      "related",
      "offering.",
      "main",
      "menu",
      "select",
      "administration",
      "configuration",
      "studio",
      "processes",
      "rules.",
      "request",
      "record",
      "type.",
      "tree",
      "left",
      "top",
      "level",
      "after",
      "change",
      "click",
      "add",
      "simple",
      "rule.",
      "actions",
      "set",
      "field.",
      "ok.",
      "title.",
      "value",
      "paste",
      "expression",
      "added",
      "entity.requestsoffering.displaylabel",
      "save.",
      "preceding",
      "there",
      "becomes",
      "shows",
      "effect",
      "offering",
      "laptop",
      "replacement.",
      "tip",
      "depending",
      "particular",
      "best",
      "practice",
      "typically",
      "run",
      "once.",
      "achieve",
      "adding",
      "transition",
      "condition."
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Using a rule to display only third level categories",
    "content": "In Change, Incident, and Request Management in Service Management, users can select a category for a record. These are the categories found at Administration > Master Data > Categories. For example, Network Access might be a category, appearing as the subcategory of Accounts & Identity which is itself the subcategory of Access (Accounts & Passwords): You may want to restrict what categories users can use for change, incident, and request records to third level categories such as Network Access. You can achieve this using the following: From the main menu, select Administration > Configuration > Studio > Processes and Rules. Select the Change record type. In the tree on the left, select Change (the top level of the tree). In Rendering forms, click Add, then select Simple rule. In Field selection rules, select Define suggested values for entity link based on filter. Click OK. Click field, and select Category. Then click OK. Click title, and type Available Categories. Then click OK. Click",
    "url": "3rdlevelcategories",
    "filename": "3rdlevelcategories",
    "headings": [],
    "keywords": [
      "rule",
      "display",
      "third",
      "level",
      "categories",
      "change",
      "incident",
      "request",
      "management",
      "service",
      "users",
      "select",
      "category",
      "record.",
      "found",
      "administration",
      "master",
      "data",
      "categories.",
      "example",
      "network",
      "access",
      "appearing",
      "subcategory",
      "accounts",
      "identity",
      "itself",
      "passwords",
      "want",
      "restrict",
      "what",
      "records",
      "such",
      "access.",
      "achieve",
      "following",
      "main",
      "menu",
      "configuration",
      "studio",
      "processes",
      "rules.",
      "record",
      "type.",
      "tree",
      "left",
      "top",
      "rendering",
      "forms",
      "click",
      "add",
      "simple",
      "rule.",
      "field",
      "selection",
      "rules",
      "define",
      "suggested",
      "values",
      "entity",
      "link",
      "based",
      "filter.",
      "ok.",
      "category.",
      "title",
      "type",
      "available",
      "all",
      "item.",
      "first",
      "box",
      "level2parent.",
      "second",
      "drop-down.",
      "union",
      "empty",
      "save.",
      "implementation",
      "displayed",
      "along",
      "full",
      "path"
    ],
    "language": "en",
    "word_count": 104,
    "importance_score": 2.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "using a rule to display only third level categories",
    "contentLower": "in change, incident, and request management in service management, users can select a category for a record. these are the categories found at administration > master data > categories. for example, network access might be a category, appearing as the subcategory of accounts & identity which is itself the subcategory of access (accounts & passwords): you may want to restrict what categories users can use for change, incident, and request records to third level categories such as network access. you can achieve this using the following: from the main menu, select administration > configuration > studio > processes and rules. select the change record type. in the tree on the left, select change (the top level of the tree). in rendering forms, click add, then select simple rule. in field selection rules, select define suggested values for entity link based on filter. click ok. click field, and select category. then click ok. click title, and type available categories. then click ok. click",
    "keywordsLower": [
      "rule",
      "display",
      "third",
      "level",
      "categories",
      "change",
      "incident",
      "request",
      "management",
      "service",
      "users",
      "select",
      "category",
      "record.",
      "found",
      "administration",
      "master",
      "data",
      "categories.",
      "example",
      "network",
      "access",
      "appearing",
      "subcategory",
      "accounts",
      "identity",
      "itself",
      "passwords",
      "want",
      "restrict",
      "what",
      "records",
      "such",
      "access.",
      "achieve",
      "following",
      "main",
      "menu",
      "configuration",
      "studio",
      "processes",
      "rules.",
      "record",
      "type.",
      "tree",
      "left",
      "top",
      "rendering",
      "forms",
      "click",
      "add",
      "simple",
      "rule.",
      "field",
      "selection",
      "rules",
      "define",
      "suggested",
      "values",
      "entity",
      "link",
      "based",
      "filter.",
      "ok.",
      "category.",
      "title",
      "type",
      "available",
      "all",
      "item.",
      "first",
      "box",
      "level2parent.",
      "second",
      "drop-down.",
      "union",
      "empty",
      "save.",
      "implementation",
      "displayed",
      "along",
      "full",
      "path"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Using rules for automatic assignment and suggestions for groups",
    "content": "When you create process driven records - such as requests or incidents - in Service Management, it's often desirable to assign them automatically to a specific group, based on information in the record. In other cases, it may not be possible to assign the record to a specific group, but instead the system can provide the agent with a list of suggestions, again based on information in the record. You can achieve both using business rules. Two rule types are commonly used to automatically set the initial group in a record: Set field Set field based on routing definition Both are used in the After change section of the rules. The most common groups seen in automatic assignment cases are Service Desk Group and Expert Group (for requests and incidents). However, you can use the examples here for any group field in a record; simply specify the field name when defining the rule. Use case number 1 When creating a new IT Service Request, automatically set the service desk group to the 1st level",
    "url": "autoassignment",
    "filename": "autoassignment",
    "headings": [
      "Use case number 1",
      "Use case number 2",
      "Routing definition",
      "Business rule",
      "Use case number 3",
      "Business rules for offerings",
      "Business rules for the Request record type",
      "Use case number 4",
      "Define suggested values for entity link based on filter",
      "Define suggested values based on routing definition",
      "Use case number 5"
    ],
    "keywords": [
      "CurrentLocation.Id",
      "RegisteredForActualService.Id",
      "rules",
      "automatic",
      "assignment",
      "suggestions",
      "groups",
      "case",
      "number",
      "routing",
      "definition",
      "business",
      "rule",
      "offerings",
      "request",
      "record",
      "type",
      "define",
      "suggested",
      "values",
      "entity",
      "link",
      "based",
      "filter",
      "create",
      "process",
      "driven",
      "records",
      "such",
      "requests",
      "incidents",
      "service",
      "management",
      "often",
      "desirable",
      "assign",
      "automatically",
      "specific",
      "group",
      "information",
      "record.",
      "cases",
      "possible",
      "instead",
      "system",
      "provide",
      "agent",
      "list",
      "again",
      "achieve",
      "both",
      "rules.",
      "two",
      "types",
      "commonly",
      "set",
      "initial",
      "field",
      "after",
      "change",
      "section",
      "most",
      "common",
      "seen",
      "desk",
      "expert",
      "however",
      "examples",
      "here",
      "any",
      "simply",
      "specify",
      "name",
      "defining",
      "rule.",
      "creating",
      "new",
      "1st",
      "level",
      "support",
      "specified",
      "actual",
      "service.",
      "implement",
      "workflow.",
      "value",
      "result",
      "expression.",
      "example",
      "desired",
      "determined",
      "expression",
      "another",
      "following",
      "classification",
      "metaphase",
      "entity.servicedeskgroup",
      "null",
      "entity.registeredforactualservice.supportlevel1group",
      "condition"
    ],
    "language": "en",
    "word_count": 106,
    "importance_score": 5.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "using rules for automatic assignment and suggestions for groups",
    "contentLower": "when you create process driven records - such as requests or incidents - in service management, it's often desirable to assign them automatically to a specific group, based on information in the record. in other cases, it may not be possible to assign the record to a specific group, but instead the system can provide the agent with a list of suggestions, again based on information in the record. you can achieve both using business rules. two rule types are commonly used to automatically set the initial group in a record: set field set field based on routing definition both are used in the after change section of the rules. the most common groups seen in automatic assignment cases are service desk group and expert group (for requests and incidents). however, you can use the examples here for any group field in a record; simply specify the field name when defining the rule. use case number 1 when creating a new it service request, automatically set the service desk group to the 1st level",
    "keywordsLower": [
      "currentlocation.id",
      "registeredforactualservice.id",
      "rules",
      "automatic",
      "assignment",
      "suggestions",
      "groups",
      "case",
      "number",
      "routing",
      "definition",
      "business",
      "rule",
      "offerings",
      "request",
      "record",
      "type",
      "define",
      "suggested",
      "values",
      "entity",
      "link",
      "based",
      "filter",
      "create",
      "process",
      "driven",
      "records",
      "such",
      "requests",
      "incidents",
      "service",
      "management",
      "often",
      "desirable",
      "assign",
      "automatically",
      "specific",
      "group",
      "information",
      "record.",
      "cases",
      "possible",
      "instead",
      "system",
      "provide",
      "agent",
      "list",
      "again",
      "achieve",
      "both",
      "rules.",
      "two",
      "types",
      "commonly",
      "set",
      "initial",
      "field",
      "after",
      "change",
      "section",
      "most",
      "common",
      "seen",
      "desk",
      "expert",
      "however",
      "examples",
      "here",
      "any",
      "simply",
      "specify",
      "name",
      "defining",
      "rule.",
      "creating",
      "new",
      "1st",
      "level",
      "support",
      "specified",
      "actual",
      "service.",
      "implement",
      "workflow.",
      "value",
      "result",
      "expression.",
      "example",
      "desired",
      "determined",
      "expression",
      "another",
      "following",
      "classification",
      "metaphase",
      "entity.servicedeskgroup",
      "null",
      "entity.registeredforactualservice.supportlevel1group",
      "condition"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Using a rule to add the date and time (in a readable format) to a comment",
    "content": "In Service Management, dates and times are stored using a Unix timestamp. You can use the format command to display these values in a more user friendly manner. For example, to add the date and time in a readable format to requests: From the main menu, select Administration > Configuration > Studio > Processes and Rules. Select the Request record type. In the tree on the left, select Request (the top level of the tree). In After change, click Add, then select Simple rule. In Actions, select Add comment. Click OK. Click comment, and add the following expression: ${format(now(),'long')} Click Save. The date and time appears as follows: Offset for time zone differences Date and time values are stored according to the server time. If the server time is different from your local time, you need to use the appropriate offset to display values in local time. For example, if the server location is in London, England and your local time is that of Paris, France, the offset is one hour. To displa",
    "url": "adddatetimecomment",
    "filename": "adddatetimecomment",
    "headings": [],
    "keywords": [
      "rule",
      "add",
      "date",
      "time",
      "readable",
      "format",
      "comment",
      "service",
      "management",
      "dates",
      "times",
      "stored",
      "unix",
      "timestamp.",
      "command",
      "display",
      "values",
      "user",
      "friendly",
      "manner.",
      "example",
      "requests",
      "main",
      "menu",
      "select",
      "administration",
      "configuration",
      "studio",
      "processes",
      "rules.",
      "request",
      "record",
      "type.",
      "tree",
      "left",
      "top",
      "level",
      "after",
      "change",
      "click",
      "simple",
      "rule.",
      "actions",
      "comment.",
      "ok.",
      "following",
      "expression",
      "now",
      "long",
      "save.",
      "appears",
      "follows",
      "offset",
      "zone",
      "differences",
      "according",
      "server",
      "time.",
      "different",
      "local",
      "need",
      "appropriate",
      "location",
      "london",
      "england",
      "paris",
      "france",
      "one",
      "hour.",
      "adding",
      "number",
      "milliseconds",
      "3600000",
      "parameter",
      "adds",
      "previous",
      "image",
      "displays",
      "pdt.",
      "don",
      "want",
      "replace",
      "short."
    ],
    "language": "en",
    "word_count": 110,
    "importance_score": 1.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "using a rule to add the date and time (in a readable format) to a comment",
    "contentLower": "in service management, dates and times are stored using a unix timestamp. you can use the format command to display these values in a more user friendly manner. for example, to add the date and time in a readable format to requests: from the main menu, select administration > configuration > studio > processes and rules. select the request record type. in the tree on the left, select request (the top level of the tree). in after change, click add, then select simple rule. in actions, select add comment. click ok. click comment, and add the following expression: ${format(now(),'long')} click save. the date and time appears as follows: offset for time zone differences date and time values are stored according to the server time. if the server time is different from your local time, you need to use the appropriate offset to display values in local time. for example, if the server location is in london, england and your local time is that of paris, france, the offset is one hour. to displa",
    "keywordsLower": [
      "rule",
      "add",
      "date",
      "time",
      "readable",
      "format",
      "comment",
      "service",
      "management",
      "dates",
      "times",
      "stored",
      "unix",
      "timestamp.",
      "command",
      "display",
      "values",
      "user",
      "friendly",
      "manner.",
      "example",
      "requests",
      "main",
      "menu",
      "select",
      "administration",
      "configuration",
      "studio",
      "processes",
      "rules.",
      "request",
      "record",
      "type.",
      "tree",
      "left",
      "top",
      "level",
      "after",
      "change",
      "click",
      "simple",
      "rule.",
      "actions",
      "comment.",
      "ok.",
      "following",
      "expression",
      "now",
      "long",
      "save.",
      "appears",
      "follows",
      "offset",
      "zone",
      "differences",
      "according",
      "server",
      "time.",
      "different",
      "local",
      "need",
      "appropriate",
      "location",
      "london",
      "england",
      "paris",
      "france",
      "one",
      "hour.",
      "adding",
      "number",
      "milliseconds",
      "3600000",
      "parameter",
      "adds",
      "previous",
      "image",
      "displays",
      "pdt.",
      "don",
      "want",
      "replace",
      "short."
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Using a rule to remove a value from a list",
    "content": "It's notpossible to manually remove a value from a list defined in List Management. To remove a list value, you can define a business rule with a list mapping including only the required list values. You can define the rule as follows: From the main menu, select Administration > Configuration > Studio > Processes and Rules. Select the Request record type. In the tree on the left, select Request (the top level of the tree). In Rendering forms, click Add, then select Simple rule. In Field selection rules, select Define suggested values by a list to list mapping. Click OK. Click field1, and select Completion code. Then click OK. Click field2, and type Completion code. Then click OK. Click mapping definition. For each value from the list on the left that should remain in the list, click the box on the right to open a list of secondary values and select the same value. Do not select the value you want to remove from the list. Click default values, and select all of the values selected in th",
    "url": "removelistvalue",
    "filename": "removelistvalue",
    "headings": [],
    "keywords": [
      "rule",
      "remove",
      "value",
      "list",
      "notpossible",
      "manually",
      "defined",
      "management.",
      "define",
      "business",
      "mapping",
      "including",
      "required",
      "values.",
      "follows",
      "main",
      "menu",
      "select",
      "administration",
      "configuration",
      "studio",
      "processes",
      "rules.",
      "request",
      "record",
      "type.",
      "tree",
      "left",
      "top",
      "level",
      "rendering",
      "forms",
      "click",
      "add",
      "simple",
      "rule.",
      "field",
      "selection",
      "rules",
      "suggested",
      "values",
      "mapping.",
      "ok.",
      "field1",
      "completion",
      "code.",
      "field2",
      "type",
      "definition.",
      "remain",
      "box",
      "right",
      "open",
      "secondary",
      "same",
      "value.",
      "want",
      "list.",
      "default",
      "all",
      "selected",
      "save.",
      "saved",
      "only."
    ],
    "language": "en",
    "word_count": 111,
    "importance_score": 2.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "using a rule to remove a value from a list",
    "contentLower": "it's notpossible to manually remove a value from a list defined in list management. to remove a list value, you can define a business rule with a list mapping including only the required list values. you can define the rule as follows: from the main menu, select administration > configuration > studio > processes and rules. select the request record type. in the tree on the left, select request (the top level of the tree). in rendering forms, click add, then select simple rule. in field selection rules, select define suggested values by a list to list mapping. click ok. click field1, and select completion code. then click ok. click field2, and type completion code. then click ok. click mapping definition. for each value from the list on the left that should remain in the list, click the box on the right to open a list of secondary values and select the same value. do not select the value you want to remove from the list. click default values, and select all of the values selected in th",
    "keywordsLower": [
      "rule",
      "remove",
      "value",
      "list",
      "notpossible",
      "manually",
      "defined",
      "management.",
      "define",
      "business",
      "mapping",
      "including",
      "required",
      "values.",
      "follows",
      "main",
      "menu",
      "select",
      "administration",
      "configuration",
      "studio",
      "processes",
      "rules.",
      "request",
      "record",
      "type.",
      "tree",
      "left",
      "top",
      "level",
      "rendering",
      "forms",
      "click",
      "add",
      "simple",
      "rule.",
      "field",
      "selection",
      "rules",
      "suggested",
      "values",
      "mapping.",
      "ok.",
      "field1",
      "completion",
      "code.",
      "field2",
      "type",
      "definition.",
      "remain",
      "box",
      "right",
      "open",
      "secondary",
      "same",
      "value.",
      "want",
      "list.",
      "default",
      "all",
      "selected",
      "save.",
      "saved",
      "only."
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "User selections in the Service Portal",
    "content": "Out-of-the-box, Service Management is configured so that when submitting requests, users in the portal are restricted as to the devices, infrastructure and peripheral assets, and subscriptions they can select, as follows: Item Those available for selection Devices User owns, uses, or has a subscription for. Subordinates of the user own, use, or have a subscription for. Infrastructure & peripheral assets User owns, uses, or has a subscription for. Subordinates of the user own, use, or have a subscription for. Subscriptions Of the user. Of the subordinates of the user. Note Subordinates of a user are those people for whom the user is specified as a manager. The preceding behavior is fixed as the maximum available selection of assets. You can further refine the selection available to users using the appropriate business rule, but in no case can you configure Service Management so that users can see more than the range specified in the preceding table. Out-of-the box, in Service Management",
    "url": "userselections",
    "filename": "userselections",
    "headings": [
      "Request and user selections",
      "Method 1",
      "Method 2",
      "Method 3",
      "Related topics"
    ],
    "keywords": [
      "user",
      "selections",
      "service",
      "portal",
      "request",
      "method",
      "related",
      "topics",
      "out-of-the-box",
      "management",
      "configured",
      "submitting",
      "requests",
      "users",
      "restricted",
      "devices",
      "infrastructure",
      "peripheral",
      "assets",
      "subscriptions",
      "select",
      "follows",
      "item",
      "available",
      "selection",
      "owns",
      "uses",
      "subscription",
      "for.",
      "subordinates",
      "own",
      "user.",
      "note",
      "people",
      "whom",
      "specified",
      "manager.",
      "preceding",
      "behavior",
      "fixed",
      "maximum",
      "assets.",
      "further",
      "refine",
      "appropriate",
      "business",
      "rule",
      "case",
      "configure",
      "see",
      "range",
      "table.",
      "out-of-the",
      "box",
      "there",
      "rules",
      "refining",
      "further.",
      "example",
      "view",
      "main",
      "menu",
      "go",
      "administration",
      "configuration",
      "studio.",
      "drop-down",
      "top",
      "page",
      "request.",
      "click",
      "processes",
      "tab.",
      "close",
      "workflow",
      "map.",
      "left",
      "pane.",
      "open",
      "rendering",
      "forms",
      "section.",
      "relevant",
      "tag",
      "define",
      "suggested",
      "values",
      "services",
      "subscriptions.",
      "information",
      "studio",
      "rules.",
      "update",
      "renew",
      "cancel",
      "having",
      "fulfilled.",
      "making",
      "behalf",
      "another"
    ],
    "language": "en",
    "word_count": 88,
    "importance_score": 4.5,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "user selections in the service portal",
    "contentLower": "out-of-the-box, service management is configured so that when submitting requests, users in the portal are restricted as to the devices, infrastructure and peripheral assets, and subscriptions they can select, as follows: item those available for selection devices user owns, uses, or has a subscription for. subordinates of the user own, use, or have a subscription for. infrastructure & peripheral assets user owns, uses, or has a subscription for. subordinates of the user own, use, or have a subscription for. subscriptions of the user. of the subordinates of the user. note subordinates of a user are those people for whom the user is specified as a manager. the preceding behavior is fixed as the maximum available selection of assets. you can further refine the selection available to users using the appropriate business rule, but in no case can you configure service management so that users can see more than the range specified in the preceding table. out-of-the box, in service management",
    "keywordsLower": [
      "user",
      "selections",
      "service",
      "portal",
      "request",
      "method",
      "related",
      "topics",
      "out-of-the-box",
      "management",
      "configured",
      "submitting",
      "requests",
      "users",
      "restricted",
      "devices",
      "infrastructure",
      "peripheral",
      "assets",
      "subscriptions",
      "select",
      "follows",
      "item",
      "available",
      "selection",
      "owns",
      "uses",
      "subscription",
      "for.",
      "subordinates",
      "own",
      "user.",
      "note",
      "people",
      "whom",
      "specified",
      "manager.",
      "preceding",
      "behavior",
      "fixed",
      "maximum",
      "assets.",
      "further",
      "refine",
      "appropriate",
      "business",
      "rule",
      "case",
      "configure",
      "see",
      "range",
      "table.",
      "out-of-the",
      "box",
      "there",
      "rules",
      "refining",
      "further.",
      "example",
      "view",
      "main",
      "menu",
      "go",
      "administration",
      "configuration",
      "studio.",
      "drop-down",
      "top",
      "page",
      "request.",
      "click",
      "processes",
      "tab.",
      "close",
      "workflow",
      "map.",
      "left",
      "pane.",
      "open",
      "rendering",
      "forms",
      "section.",
      "relevant",
      "tag",
      "define",
      "suggested",
      "values",
      "services",
      "subscriptions.",
      "information",
      "studio",
      "rules.",
      "update",
      "renew",
      "cancel",
      "having",
      "fulfilled.",
      "making",
      "behalf",
      "another"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "View categories",
    "content": "The Category page shows all categories. Follow these steps to view the Category page: From the main menu, click Administration > Master Data > Categories. The Category page lists all categories arranged in column format. You may search for a category by entering a text string in the search box at the top of the column. As you select an individual category, Service Management displays any existing subcategories on the right side. Limitation The Category page can display up to 2000 Category records. Related topics How to create a category How to edit categories",
    "url": "viewcategory",
    "filename": "viewcategory",
    "headings": [
      "Limitation",
      "Related topics"
    ],
    "keywords": [
      "view",
      "categories",
      "limitation",
      "related",
      "topics",
      "category",
      "page",
      "shows",
      "all",
      "categories.",
      "follow",
      "steps",
      "main",
      "menu",
      "click",
      "administration",
      "master",
      "data",
      "lists",
      "arranged",
      "column",
      "format.",
      "search",
      "entering",
      "text",
      "string",
      "box",
      "top",
      "column.",
      "select",
      "individual",
      "service",
      "management",
      "displays",
      "any",
      "existing",
      "subcategories",
      "right",
      "side.",
      "display",
      "2000",
      "records.",
      "create",
      "edit"
    ],
    "language": "en",
    "word_count": 60,
    "importance_score": 3.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "view categories",
    "contentLower": "the category page shows all categories. follow these steps to view the category page: from the main menu, click administration > master data > categories. the category page lists all categories arranged in column format. you may search for a category by entering a text string in the search box at the top of the column. as you select an individual category, service management displays any existing subcategories on the right side. limitation the category page can display up to 2000 category records. related topics how to create a category how to edit categories",
    "keywordsLower": [
      "view",
      "categories",
      "limitation",
      "related",
      "topics",
      "category",
      "page",
      "shows",
      "all",
      "categories.",
      "follow",
      "steps",
      "main",
      "menu",
      "click",
      "administration",
      "master",
      "data",
      "lists",
      "arranged",
      "column",
      "format.",
      "search",
      "entering",
      "text",
      "string",
      "box",
      "top",
      "column.",
      "select",
      "individual",
      "service",
      "management",
      "displays",
      "any",
      "existing",
      "subcategories",
      "right",
      "side.",
      "display",
      "2000",
      "records.",
      "create",
      "edit"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "View permissions in OO Workflow Designer",
    "content": "This topic describes the permissions you can grant for Operations Orchestration (OO) Workflow Designer users. Access and view the permissions To access and view the permissions on IdM administration console: Click ORGANIZATION and select the Permissions section. The list of all the permissions currently set appears with the following parameters: NAME (DISPLAY NAME): Name of the set permission. DESCRIPTION: Description of the set permission. APPLICATION: The name of the application to which the permission is configured. Note the following default permissions that are non-editable: IDM_ADMIN: Performs IdM administration for consumer organization. ORG_ADMIN: Performs IdM administration for provider organization and its subordinate organizations. SUPER_IDM_ADMIN: Performs IdM administration for all organizations. Search the permissions To search existing permission: In the upper-right corner, enter the permission name into the search bar, then click search to perform the search.",
    "url": "viewoodpermissionsidm",
    "filename": "viewoodpermissionsidm",
    "headings": [
      "Access and view the permissions",
      "Search the permissions"
    ],
    "keywords": [
      "view",
      "permissions",
      "oo",
      "workflow",
      "designer",
      "access",
      "search",
      "topic",
      "describes",
      "grant",
      "operations",
      "orchestration",
      "users.",
      "idm",
      "administration",
      "console",
      "click",
      "organization",
      "select",
      "section.",
      "list",
      "all",
      "currently",
      "set",
      "appears",
      "following",
      "parameters",
      "name",
      "display",
      "permission.",
      "description",
      "application",
      "permission",
      "configured.",
      "note",
      "default",
      "non-editable",
      "performs",
      "consumer",
      "organization.",
      "provider",
      "subordinate",
      "organizations.",
      "existing",
      "upper-right",
      "corner",
      "enter",
      "bar",
      "perform",
      "search."
    ],
    "language": "en",
    "word_count": 93,
    "importance_score": 3.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "view permissions in oo workflow designer",
    "contentLower": "this topic describes the permissions you can grant for operations orchestration (oo) workflow designer users. access and view the permissions to access and view the permissions on idm administration console: click organization and select the permissions section. the list of all the permissions currently set appears with the following parameters: name (display name): name of the set permission. description: description of the set permission. application: the name of the application to which the permission is configured. note the following default permissions that are non-editable: idm_admin: performs idm administration for consumer organization. org_admin: performs idm administration for provider organization and its subordinate organizations. super_idm_admin: performs idm administration for all organizations. search the permissions to search existing permission: in the upper-right corner, enter the permission name into the search bar, then click search to perform the search.",
    "keywordsLower": [
      "view",
      "permissions",
      "oo",
      "workflow",
      "designer",
      "access",
      "search",
      "topic",
      "describes",
      "grant",
      "operations",
      "orchestration",
      "users.",
      "idm",
      "administration",
      "console",
      "click",
      "organization",
      "select",
      "section.",
      "list",
      "all",
      "currently",
      "set",
      "appears",
      "following",
      "parameters",
      "name",
      "display",
      "permission.",
      "description",
      "application",
      "permission",
      "configured.",
      "note",
      "default",
      "non-editable",
      "performs",
      "consumer",
      "organization.",
      "provider",
      "subordinate",
      "organizations.",
      "existing",
      "upper-right",
      "corner",
      "enter",
      "bar",
      "perform",
      "search."
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "User management and authentication in OO Workflow Designer",
    "content": "Database authentication OO Workflow Designer supports the following databases: Oracle, MS SQL, and PostgreSQL. It's recommended to use a strong database password for database authentication and using a strong password policy. For example, blocking after a number of failed attempts. When using MS SQL, it's possible to work with either database authentication or with OS authentication. It's recommended to work with OS authentication, where this is possible. For example, it's possible to use Windows authentication to access Microsoft SQL Server databases.",
    "url": "usersecuritydesigner",
    "filename": "usersecuritydesigner",
    "headings": [
      "Database authentication"
    ],
    "keywords": [
      "user",
      "management",
      "authentication",
      "oo",
      "workflow",
      "designer",
      "database",
      "supports",
      "following",
      "databases",
      "oracle",
      "ms",
      "sql",
      "postgresql.",
      "recommended",
      "strong",
      "password",
      "policy.",
      "example",
      "blocking",
      "after",
      "number",
      "failed",
      "attempts.",
      "possible",
      "work",
      "either",
      "os",
      "authentication.",
      "possible.",
      "windows",
      "access",
      "microsoft",
      "server",
      "databases."
    ],
    "language": "en",
    "word_count": 60,
    "importance_score": 1.5,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "user management and authentication in oo workflow designer",
    "contentLower": "database authentication oo workflow designer supports the following databases: oracle, ms sql, and postgresql. it's recommended to use a strong database password for database authentication and using a strong password policy. for example, blocking after a number of failed attempts. when using ms sql, it's possible to work with either database authentication or with os authentication. it's recommended to work with os authentication, where this is possible. for example, it's possible to use windows authentication to access microsoft sql server databases.",
    "keywordsLower": [
      "user",
      "management",
      "authentication",
      "oo",
      "workflow",
      "designer",
      "database",
      "supports",
      "following",
      "databases",
      "oracle",
      "ms",
      "sql",
      "postgresql.",
      "recommended",
      "strong",
      "password",
      "policy.",
      "example",
      "blocking",
      "after",
      "number",
      "failed",
      "attempts.",
      "possible",
      "work",
      "either",
      "os",
      "authentication.",
      "possible.",
      "windows",
      "access",
      "microsoft",
      "server",
      "databases."
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Working with server certificates",
    "content": "Transport Layer Security (TLS) certificates digitally bind a cryptographic key to the details of an organization, enabling secure and encrypted connections from a web server to a browser. OO Workflow Designer uses the Keytool utility to manage cryptographic keys and trusted certificates. This utility is included in the OO Workflow Designer installation folder, in <installation dir>/java/bin/keytool. For more information about the Keytool utility, see http://docs.oracle.com/javase/7/docs/technotes/tools/solaris/keytool.html. Note: Keytool is an open source utility. Installations of OO Workflow Designer include two files for the management of certificates: <installation dir>/designer/var/security/client.truststore: Contains the list of trusted certificates. <installation dir>/designer/var/security/key.store: Contains the OO Workflow Designer certificate (private key). It's recommended to: Replace the OO Workflow Designer self-signed certificate after a new installation of OO Workflow Des",
    "url": "replacesslcertdesigner",
    "filename": "replacesslcertdesigner",
    "headings": [
      "Related topics"
    ],
    "keywords": [
      "oracle.com",
      "http://docs.oracle.com/javase/7/docs/technotes/tools/solaris/keytool.html",
      "keytool.html",
      "working",
      "server",
      "certificates",
      "related",
      "topics",
      "transport",
      "layer",
      "security",
      "tls",
      "digitally",
      "bind",
      "cryptographic",
      "key",
      "details",
      "organization",
      "enabling",
      "secure",
      "encrypted",
      "connections",
      "web",
      "browser.",
      "oo",
      "workflow",
      "designer",
      "uses",
      "keytool",
      "utility",
      "manage",
      "keys",
      "trusted",
      "certificates.",
      "included",
      "installation",
      "folder",
      "java",
      "bin",
      "keytool.",
      "information",
      "about",
      "see",
      "http",
      "docs.oracle.com",
      "javase",
      "docs",
      "technotes",
      "tools",
      "solaris",
      "keytool.html.",
      "note",
      "open",
      "source",
      "utility.",
      "installations",
      "include",
      "two",
      "files",
      "management",
      "var",
      "client.truststore",
      "contains",
      "list",
      "key.store",
      "certificate",
      "private",
      "recommended",
      "replace",
      "self-signed",
      "after",
      "new",
      "current",
      "expired.",
      "store",
      "truststore",
      "keystore",
      "read",
      "permissions",
      "user",
      "runs",
      "service.",
      "clear",
      "console",
      "prompt",
      "password",
      "inputs.",
      "encrypt",
      "communication",
      "designer."
    ],
    "language": "en",
    "word_count": 103,
    "importance_score": 3.5,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "working with server certificates",
    "contentLower": "transport layer security (tls) certificates digitally bind a cryptographic key to the details of an organization, enabling secure and encrypted connections from a web server to a browser. oo workflow designer uses the keytool utility to manage cryptographic keys and trusted certificates. this utility is included in the oo workflow designer installation folder, in <installation dir>/java/bin/keytool. for more information about the keytool utility, see http://docs.oracle.com/javase/7/docs/technotes/tools/solaris/keytool.html. note: keytool is an open source utility. installations of oo workflow designer include two files for the management of certificates: <installation dir>/designer/var/security/client.truststore: contains the list of trusted certificates. <installation dir>/designer/var/security/key.store: contains the oo workflow designer certificate (private key). it's recommended to: replace the oo workflow designer self-signed certificate after a new installation of oo workflow des",
    "keywordsLower": [
      "oracle.com",
      "http://docs.oracle.com/javase/7/docs/technotes/tools/solaris/keytool.html",
      "keytool.html",
      "working",
      "server",
      "certificates",
      "related",
      "topics",
      "transport",
      "layer",
      "security",
      "tls",
      "digitally",
      "bind",
      "cryptographic",
      "key",
      "details",
      "organization",
      "enabling",
      "secure",
      "encrypted",
      "connections",
      "web",
      "browser.",
      "oo",
      "workflow",
      "designer",
      "uses",
      "keytool",
      "utility",
      "manage",
      "keys",
      "trusted",
      "certificates.",
      "included",
      "installation",
      "folder",
      "java",
      "bin",
      "keytool.",
      "information",
      "about",
      "see",
      "http",
      "docs.oracle.com",
      "javase",
      "docs",
      "technotes",
      "tools",
      "solaris",
      "keytool.html.",
      "note",
      "open",
      "source",
      "utility.",
      "installations",
      "include",
      "two",
      "files",
      "management",
      "var",
      "client.truststore",
      "contains",
      "list",
      "key.store",
      "certificate",
      "private",
      "recommended",
      "replace",
      "self-signed",
      "after",
      "new",
      "current",
      "expired.",
      "store",
      "truststore",
      "keystore",
      "read",
      "permissions",
      "user",
      "runs",
      "service.",
      "clear",
      "console",
      "prompt",
      "password",
      "inputs.",
      "encrypt",
      "communication",
      "designer."
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Use",
    "content": "This section describes how to use the Service Management Automation suite capabilities. Log in to the suite Service Portal Service Portal mobile app Use IT Service Management Use Extended Service Management HR Service Management Use Asset Management Use Cloud Management Use OO Containerized",
    "url": "use",
    "filename": "use",
    "headings": [],
    "keywords": [
      "section",
      "describes",
      "service",
      "management",
      "automation",
      "suite",
      "capabilities.",
      "log",
      "portal",
      "mobile",
      "app",
      "extended",
      "hr",
      "asset",
      "cloud",
      "oo",
      "containerized"
    ],
    "language": "en",
    "word_count": 29,
    "importance_score": 2.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "use",
    "contentLower": "this section describes how to use the service management automation suite capabilities. log in to the suite service portal service portal mobile app use it service management use extended service management hr service management use asset management use cloud management use oo containerized",
    "keywordsLower": [
      "section",
      "describes",
      "service",
      "management",
      "automation",
      "suite",
      "capabilities.",
      "log",
      "portal",
      "mobile",
      "app",
      "extended",
      "hr",
      "asset",
      "cloud",
      "oo",
      "containerized"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Use IT Service Management",
    "content": "Your tenant can work in one or more of the following experience modes depending on the license assigned to the tenant: IT Service Management, Extended Service Management, Asset Management, and Cloud Management. Each experience mode enables user access to specific modules in the system. For information about the licenses required for each experience mode and the modules available in each experience mode, see Experience mode. The following gives a brief introduction to the IT Service Management mode and gives insights into what you can achieve with this experience mode. About IT Service Management IT Service Management is supporting customers to do service management for IT use cases. The following is a summary of what you can achieve with IT Service Management. Unburden service desk agents Increase employee and IT productivity by creating and fulfilling services faster, and reduce the time to resolve with embedded machine learning and automation. Simplify service desk use Increase end u",
    "url": "useitservicemanagement",
    "filename": "useitservicemanagement",
    "headings": [
      "About IT Service Management",
      "Unburden service desk agents",
      "Simplify service desk use",
      "Decrease cost of ITSM on SaaS",
      "Manage IT assets",
      "Embrace feature-rich ITSM",
      "Run enterprise service management",
      "IT Service Management concepts and tasks"
    ],
    "keywords": [
      "service",
      "management",
      "about",
      "unburden",
      "desk",
      "agents",
      "simplify",
      "decrease",
      "cost",
      "itsm",
      "saas",
      "manage",
      "assets",
      "embrace",
      "feature-rich",
      "run",
      "enterprise",
      "concepts",
      "tasks",
      "tenant",
      "work",
      "one",
      "following",
      "experience",
      "modes",
      "depending",
      "license",
      "assigned",
      "extended",
      "asset",
      "cloud",
      "management.",
      "mode",
      "enables",
      "user",
      "access",
      "specific",
      "modules",
      "system.",
      "information",
      "licenses",
      "required",
      "available",
      "see",
      "mode.",
      "gives",
      "brief",
      "introduction",
      "insights",
      "what",
      "achieve",
      "supporting",
      "customers",
      "cases.",
      "summary",
      "increase",
      "employee",
      "productivity",
      "creating",
      "fulfilling",
      "services",
      "faster",
      "reduce",
      "time",
      "resolve",
      "embedded",
      "machine",
      "learning",
      "automation.",
      "end",
      "satisfaction",
      "let",
      "get",
      "back",
      "easily",
      "consumer-like",
      "expect",
      "go.",
      "automate",
      "processes",
      "workflows",
      "allows",
      "avoid",
      "customizations",
      "deploy",
      "update",
      "drive",
      "tco.",
      "grip",
      "throughout",
      "lifecycle",
      "additional",
      "cost.",
      "benefit",
      "smax",
      "modern",
      "ensure",
      "investment",
      "optimization",
      "compliance."
    ],
    "language": "en",
    "word_count": 95,
    "importance_score": 6.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "use it service management",
    "contentLower": "your tenant can work in one or more of the following experience modes depending on the license assigned to the tenant: it service management, extended service management, asset management, and cloud management. each experience mode enables user access to specific modules in the system. for information about the licenses required for each experience mode and the modules available in each experience mode, see experience mode. the following gives a brief introduction to the it service management mode and gives insights into what you can achieve with this experience mode. about it service management it service management is supporting customers to do service management for it use cases. the following is a summary of what you can achieve with it service management. unburden service desk agents increase employee and it productivity by creating and fulfilling services faster, and reduce the time to resolve with embedded machine learning and automation. simplify service desk use increase end u",
    "keywordsLower": [
      "service",
      "management",
      "about",
      "unburden",
      "desk",
      "agents",
      "simplify",
      "decrease",
      "cost",
      "itsm",
      "saas",
      "manage",
      "assets",
      "embrace",
      "feature-rich",
      "run",
      "enterprise",
      "concepts",
      "tasks",
      "tenant",
      "work",
      "one",
      "following",
      "experience",
      "modes",
      "depending",
      "license",
      "assigned",
      "extended",
      "asset",
      "cloud",
      "management.",
      "mode",
      "enables",
      "user",
      "access",
      "specific",
      "modules",
      "system.",
      "information",
      "licenses",
      "required",
      "available",
      "see",
      "mode.",
      "gives",
      "brief",
      "introduction",
      "insights",
      "what",
      "achieve",
      "supporting",
      "customers",
      "cases.",
      "summary",
      "increase",
      "employee",
      "productivity",
      "creating",
      "fulfilling",
      "services",
      "faster",
      "reduce",
      "time",
      "resolve",
      "embedded",
      "machine",
      "learning",
      "automation.",
      "end",
      "satisfaction",
      "let",
      "get",
      "back",
      "easily",
      "consumer-like",
      "expect",
      "go.",
      "automate",
      "processes",
      "workflows",
      "allows",
      "avoid",
      "customizations",
      "deploy",
      "update",
      "drive",
      "tco.",
      "grip",
      "throughout",
      "lifecycle",
      "additional",
      "cost.",
      "benefit",
      "smax",
      "modern",
      "ensure",
      "investment",
      "optimization",
      "compliance."
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Use Extended Service Management",
    "content": "Your tenant can work in one or more of the following experience modes depending on the license assigned to the tenant: IT Service Management, Extended Service Management, Asset Management, and Cloud Management. Each experience mode enables user access to specific modules in the system. For information about the licenses required for each experience mode and the modules available in each experience mode, see Experience mode. The following gives a brief introduction to the Extended Service Management mode and gives insights into what you can achieve with this experience mode. About Extended Service Management Extended Service Management is supporting customers to do service management for non-IT use cases. Commonly that is done in lines of business and departments like HR, Facilities, or Legal. The experience and execution is very similar to what the IT Service Management experience mode is offering. The following is a summary of what you can achieve with Extended Service Management. Unb",
    "url": "usexservicemanagement",
    "filename": "usexservicemanagement",
    "headings": [
      "About Extended Service Management",
      "Simplify use",
      "Decrease cost on SaaS",
      "Manage your assets",
      "Embrace feature-rich Service Management",
      "Run enterprise service management",
      "Extended Service Management concepts and tasks"
    ],
    "keywords": [
      "extended",
      "service",
      "management",
      "about",
      "simplify",
      "decrease",
      "cost",
      "saas",
      "manage",
      "assets",
      "embrace",
      "feature-rich",
      "run",
      "enterprise",
      "concepts",
      "tasks",
      "tenant",
      "work",
      "one",
      "following",
      "experience",
      "modes",
      "depending",
      "license",
      "assigned",
      "asset",
      "cloud",
      "management.",
      "mode",
      "enables",
      "user",
      "access",
      "specific",
      "modules",
      "system.",
      "information",
      "licenses",
      "required",
      "available",
      "see",
      "mode.",
      "gives",
      "brief",
      "introduction",
      "insights",
      "what",
      "achieve",
      "supporting",
      "customers",
      "non-it",
      "cases.",
      "commonly",
      "done",
      "lines",
      "business",
      "departments",
      "like",
      "hr",
      "facilities",
      "legal.",
      "execution",
      "very",
      "similar",
      "offering.",
      "summary",
      "unburden",
      "agents",
      "increase",
      "employee",
      "agent",
      "productivity",
      "creating",
      "fulfilling",
      "services",
      "faster",
      "reduce",
      "time",
      "resolve",
      "embedded",
      "machine",
      "learning",
      "automation.",
      "end",
      "satisfaction",
      "let",
      "get",
      "back",
      "easily",
      "consumer-like",
      "expect",
      "desk",
      "go.",
      "automate",
      "processes",
      "workflows",
      "avoid",
      "customizations",
      "deploy",
      "update",
      "drive"
    ],
    "language": "en",
    "word_count": 97,
    "importance_score": 6.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "use extended service management",
    "contentLower": "your tenant can work in one or more of the following experience modes depending on the license assigned to the tenant: it service management, extended service management, asset management, and cloud management. each experience mode enables user access to specific modules in the system. for information about the licenses required for each experience mode and the modules available in each experience mode, see experience mode. the following gives a brief introduction to the extended service management mode and gives insights into what you can achieve with this experience mode. about extended service management extended service management is supporting customers to do service management for non-it use cases. commonly that is done in lines of business and departments like hr, facilities, or legal. the experience and execution is very similar to what the it service management experience mode is offering. the following is a summary of what you can achieve with extended service management. unb",
    "keywordsLower": [
      "extended",
      "service",
      "management",
      "about",
      "simplify",
      "decrease",
      "cost",
      "saas",
      "manage",
      "assets",
      "embrace",
      "feature-rich",
      "run",
      "enterprise",
      "concepts",
      "tasks",
      "tenant",
      "work",
      "one",
      "following",
      "experience",
      "modes",
      "depending",
      "license",
      "assigned",
      "asset",
      "cloud",
      "management.",
      "mode",
      "enables",
      "user",
      "access",
      "specific",
      "modules",
      "system.",
      "information",
      "licenses",
      "required",
      "available",
      "see",
      "mode.",
      "gives",
      "brief",
      "introduction",
      "insights",
      "what",
      "achieve",
      "supporting",
      "customers",
      "non-it",
      "cases.",
      "commonly",
      "done",
      "lines",
      "business",
      "departments",
      "like",
      "hr",
      "facilities",
      "legal.",
      "execution",
      "very",
      "similar",
      "offering.",
      "summary",
      "unburden",
      "agents",
      "increase",
      "employee",
      "agent",
      "productivity",
      "creating",
      "fulfilling",
      "services",
      "faster",
      "reduce",
      "time",
      "resolve",
      "embedded",
      "machine",
      "learning",
      "automation.",
      "end",
      "satisfaction",
      "let",
      "get",
      "back",
      "easily",
      "consumer-like",
      "expect",
      "desk",
      "go.",
      "automate",
      "processes",
      "workflows",
      "avoid",
      "customizations",
      "deploy",
      "update",
      "drive"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Use HR Service Management",
    "content": "This section provides a brief introduction to Human Resources (HR) service delivery and illustrates the core functions that can be achieved by HR Service Management. HR service delivery is a core function of an organization that allows its human resources department to offer services and interact with employees thus giving access to various levels of HR expertise and prioritizing HR management. Delivering HR services from a unified platform optimizes business costs and processes like monitoring and compliance, improves HR productivity, and meets employee expectations more accurately and efficiently. Remote and hybrid work has become the norm for many organizations, making the traditional model of HR service delivery less feasible. The multi-tier HR service delivery model provides the flexibility needed by employees in the modern workplace, which leads to the success of the hybrid work mode. Typical multi-tier HR service delivery model A multi-tier HR service delivery model is often use",
    "url": "usehrsm",
    "filename": "usehrsm",
    "headings": [
      "Typical multi-tier HR service delivery model",
      "HR Service Management",
      "Key capabilities of HR Service Management",
      "Employee self-service portal",
      "Knowledge base and hot news",
      "Case management",
      "Privacy controls",
      "Catalog entitlement",
      "Aviator user assistance and automation",
      "Out-of-the-box HR content",
      "Integrated content management",
      "Integration with HR systems",
      "Use cases",
      "New hire onboarding with the onboarding bundle",
      "Request for remote country work",
      "Request eLetter for business visa"
    ],
    "keywords": [
      "24.4",
      "hr",
      "service",
      "management",
      "typical",
      "multi-tier",
      "delivery",
      "model",
      "key",
      "capabilities",
      "employee",
      "self-service",
      "portal",
      "knowledge",
      "base",
      "hot",
      "news",
      "case",
      "privacy",
      "controls",
      "catalog",
      "entitlement",
      "aviator",
      "user",
      "assistance",
      "automation",
      "out-of-the-box",
      "content",
      "integrated",
      "integration",
      "systems",
      "cases",
      "new",
      "hire",
      "onboarding",
      "bundle",
      "request",
      "remote",
      "country",
      "work",
      "eletter",
      "business",
      "visa",
      "section",
      "provides",
      "brief",
      "introduction",
      "human",
      "resources",
      "illustrates",
      "core",
      "functions",
      "achieved",
      "management.",
      "function",
      "organization",
      "allows",
      "department",
      "offer",
      "services",
      "interact",
      "employees",
      "thus",
      "giving",
      "access",
      "various",
      "levels",
      "expertise",
      "prioritizing",
      "delivering",
      "unified",
      "platform",
      "optimizes",
      "costs",
      "processes",
      "like",
      "monitoring",
      "compliance",
      "improves",
      "productivity",
      "meets",
      "expectations",
      "accurately",
      "efficiently.",
      "hybrid",
      "become",
      "norm",
      "many",
      "organizations",
      "making",
      "traditional",
      "less",
      "feasible.",
      "flexibility",
      "needed",
      "modern",
      "workplace",
      "leads",
      "success",
      "mode."
    ],
    "language": "en",
    "word_count": 106,
    "importance_score": 6.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "use hr service management",
    "contentLower": "this section provides a brief introduction to human resources (hr) service delivery and illustrates the core functions that can be achieved by hr service management. hr service delivery is a core function of an organization that allows its human resources department to offer services and interact with employees thus giving access to various levels of hr expertise and prioritizing hr management. delivering hr services from a unified platform optimizes business costs and processes like monitoring and compliance, improves hr productivity, and meets employee expectations more accurately and efficiently. remote and hybrid work has become the norm for many organizations, making the traditional model of hr service delivery less feasible. the multi-tier hr service delivery model provides the flexibility needed by employees in the modern workplace, which leads to the success of the hybrid work mode. typical multi-tier hr service delivery model a multi-tier hr service delivery model is often use",
    "keywordsLower": [
      "24.4",
      "hr",
      "service",
      "management",
      "typical",
      "multi-tier",
      "delivery",
      "model",
      "key",
      "capabilities",
      "employee",
      "self-service",
      "portal",
      "knowledge",
      "base",
      "hot",
      "news",
      "case",
      "privacy",
      "controls",
      "catalog",
      "entitlement",
      "aviator",
      "user",
      "assistance",
      "automation",
      "out-of-the-box",
      "content",
      "integrated",
      "integration",
      "systems",
      "cases",
      "new",
      "hire",
      "onboarding",
      "bundle",
      "request",
      "remote",
      "country",
      "work",
      "eletter",
      "business",
      "visa",
      "section",
      "provides",
      "brief",
      "introduction",
      "human",
      "resources",
      "illustrates",
      "core",
      "functions",
      "achieved",
      "management.",
      "function",
      "organization",
      "allows",
      "department",
      "offer",
      "services",
      "interact",
      "employees",
      "thus",
      "giving",
      "access",
      "various",
      "levels",
      "expertise",
      "prioritizing",
      "delivering",
      "unified",
      "platform",
      "optimizes",
      "costs",
      "processes",
      "like",
      "monitoring",
      "compliance",
      "improves",
      "productivity",
      "meets",
      "expectations",
      "accurately",
      "efficiently.",
      "hybrid",
      "become",
      "norm",
      "many",
      "organizations",
      "making",
      "traditional",
      "less",
      "feasible.",
      "flexibility",
      "needed",
      "modern",
      "workplace",
      "leads",
      "success",
      "mode."
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Use Asset Management",
    "content": "Your tenant can work in one or more of the following experience modes depending on the license assigned to the tenant: IT Service Management, Extended Service Management, Asset Management, and Cloud Management. Each experience mode enables user access to specific modules in the system. For information about the licenses required for each experience mode and the modules available in each experience mode, see Experience mode. This topic gives a brief introduction to the Asset Management experience mode and gives insights into what you can achieve with this experience mode. About Asset Management The Asset Management solution helps you to manage your hardware and software assets, optimize spend, ensure compliance, and consolidate Asset Management for projects. Asset Management offers the following benefits: Provide increased visibility with centralized IT asset management capabilities for software, hardware management Automate asset lifecycle processes, and track contractual, financial, a",
    "url": "useassetmanagement",
    "filename": "useassetmanagement",
    "headings": [
      "About Asset Management",
      "Asset Management modules"
    ],
    "keywords": [
      "asset",
      "management",
      "about",
      "modules",
      "tenant",
      "work",
      "one",
      "following",
      "experience",
      "modes",
      "depending",
      "license",
      "assigned",
      "service",
      "extended",
      "cloud",
      "management.",
      "mode",
      "enables",
      "user",
      "access",
      "specific",
      "system.",
      "information",
      "licenses",
      "required",
      "available",
      "see",
      "mode.",
      "topic",
      "gives",
      "brief",
      "introduction",
      "insights",
      "what",
      "achieve",
      "solution",
      "helps",
      "manage",
      "hardware",
      "software",
      "assets",
      "optimize",
      "spend",
      "ensure",
      "compliance",
      "consolidate",
      "projects.",
      "offers",
      "benefits",
      "provide",
      "increased",
      "visibility",
      "centralized",
      "capabilities",
      "automate",
      "lifecycle",
      "processes",
      "track",
      "contractual",
      "financial",
      "inventory",
      "both",
      "native",
      "integration",
      "universal",
      "discovery",
      "retrieve",
      "most",
      "up-to-date",
      "data",
      "leverage",
      "out-of-the-box",
      "vendor",
      "reports",
      "efficiently",
      "titles",
      "stay",
      "top",
      "audits",
      "includes",
      "catalog",
      "company",
      "knowledge",
      "configuration",
      "sacm",
      "sam",
      "request",
      "contract",
      "idea",
      "proposal",
      "application",
      "portfolio",
      "project",
      "program",
      "procurement"
    ],
    "language": "en",
    "word_count": 97,
    "importance_score": 4.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "use asset management",
    "contentLower": "your tenant can work in one or more of the following experience modes depending on the license assigned to the tenant: it service management, extended service management, asset management, and cloud management. each experience mode enables user access to specific modules in the system. for information about the licenses required for each experience mode and the modules available in each experience mode, see experience mode. this topic gives a brief introduction to the asset management experience mode and gives insights into what you can achieve with this experience mode. about asset management the asset management solution helps you to manage your hardware and software assets, optimize spend, ensure compliance, and consolidate asset management for projects. asset management offers the following benefits: provide increased visibility with centralized it asset management capabilities for software, hardware management automate asset lifecycle processes, and track contractual, financial, a",
    "keywordsLower": [
      "asset",
      "management",
      "about",
      "modules",
      "tenant",
      "work",
      "one",
      "following",
      "experience",
      "modes",
      "depending",
      "license",
      "assigned",
      "service",
      "extended",
      "cloud",
      "management.",
      "mode",
      "enables",
      "user",
      "access",
      "specific",
      "system.",
      "information",
      "licenses",
      "required",
      "available",
      "see",
      "mode.",
      "topic",
      "gives",
      "brief",
      "introduction",
      "insights",
      "what",
      "achieve",
      "solution",
      "helps",
      "manage",
      "hardware",
      "software",
      "assets",
      "optimize",
      "spend",
      "ensure",
      "compliance",
      "consolidate",
      "projects.",
      "offers",
      "benefits",
      "provide",
      "increased",
      "visibility",
      "centralized",
      "capabilities",
      "automate",
      "lifecycle",
      "processes",
      "track",
      "contractual",
      "financial",
      "inventory",
      "both",
      "native",
      "integration",
      "universal",
      "discovery",
      "retrieve",
      "most",
      "up-to-date",
      "data",
      "leverage",
      "out-of-the-box",
      "vendor",
      "reports",
      "efficiently",
      "titles",
      "stay",
      "top",
      "audits",
      "includes",
      "catalog",
      "company",
      "knowledge",
      "configuration",
      "sacm",
      "sam",
      "request",
      "contract",
      "idea",
      "proposal",
      "application",
      "portfolio",
      "project",
      "program",
      "procurement"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Use Cloud Management",
    "content": "Your tenant can work in one or more of the following experience modes depending on the tenant's Application Settings: IT Service Management, Extended Service Management, Asset Management, and Cloud Management. Each of the experience modes controls access to specific modules. For more information, see Experience mode. The following gives a brief introduction to the Cloud Management mode and gives insights into what you can achieve by using the Cloud Management mode. About Cloud Management Cloud management offers the following functionalities: Design and Deploy (DND) - With DND capability, new cloud service offerings based on published service designs can be made available to consumers, which facilitates your organization's cloud infrastructure management. Before enabling and using the Design and Deploy functionality, you should install and enable Operations Orchestration(OO) Containerized capability. For more information, see Install OO on-premises, Install OO on EKS, Install OO on AKS ",
    "url": "usecloudmanagement",
    "filename": "usecloudmanagement",
    "headings": [
      "About Cloud Management",
      "Cloud Management concepts and tasks"
    ],
    "keywords": [
      "cloud",
      "management",
      "about",
      "concepts",
      "tasks",
      "tenant",
      "work",
      "one",
      "following",
      "experience",
      "modes",
      "depending",
      "application",
      "settings",
      "service",
      "extended",
      "asset",
      "management.",
      "controls",
      "access",
      "specific",
      "modules.",
      "information",
      "see",
      "mode.",
      "gives",
      "brief",
      "introduction",
      "mode",
      "insights",
      "what",
      "achieve",
      "offers",
      "functionalities",
      "design",
      "deploy",
      "dnd",
      "capability",
      "new",
      "offerings",
      "based",
      "published",
      "designs",
      "made",
      "available",
      "consumers",
      "facilitates",
      "organization",
      "infrastructure",
      "before",
      "enabling",
      "functionality",
      "install",
      "enable",
      "operations",
      "orchestration",
      "oo",
      "containerized",
      "capability.",
      "on-premises",
      "eks",
      "aks",
      "containerized.cloud",
      "cost",
      "reporting",
      "enables",
      "monitor",
      "spending",
      "simplify",
      "configuration",
      "various",
      "providers.image",
      "aggregation",
      "ia",
      "showcases",
      "templates",
      "marketplace",
      "portals",
      "aws",
      "microsoft",
      "azure",
      "vcenter.",
      "business",
      "manager",
      "aggregator",
      "instantly",
      "create",
      "offer",
      "services",
      "having",
      "automation",
      "asset.",
      "content",
      "store",
      "part",
      "web-based",
      "managing",
      "capsules.",
      "users",
      "download"
    ],
    "language": "en",
    "word_count": 99,
    "importance_score": 4.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "use cloud management",
    "contentLower": "your tenant can work in one or more of the following experience modes depending on the tenant's application settings: it service management, extended service management, asset management, and cloud management. each of the experience modes controls access to specific modules. for more information, see experience mode. the following gives a brief introduction to the cloud management mode and gives insights into what you can achieve by using the cloud management mode. about cloud management cloud management offers the following functionalities: design and deploy (dnd) - with dnd capability, new cloud service offerings based on published service designs can be made available to consumers, which facilitates your organization's cloud infrastructure management. before enabling and using the design and deploy functionality, you should install and enable operations orchestration(oo) containerized capability. for more information, see install oo on-premises, install oo on eks, install oo on aks ",
    "keywordsLower": [
      "cloud",
      "management",
      "about",
      "concepts",
      "tasks",
      "tenant",
      "work",
      "one",
      "following",
      "experience",
      "modes",
      "depending",
      "application",
      "settings",
      "service",
      "extended",
      "asset",
      "management.",
      "controls",
      "access",
      "specific",
      "modules.",
      "information",
      "see",
      "mode.",
      "gives",
      "brief",
      "introduction",
      "mode",
      "insights",
      "what",
      "achieve",
      "offers",
      "functionalities",
      "design",
      "deploy",
      "dnd",
      "capability",
      "new",
      "offerings",
      "based",
      "published",
      "designs",
      "made",
      "available",
      "consumers",
      "facilitates",
      "organization",
      "infrastructure",
      "before",
      "enabling",
      "functionality",
      "install",
      "enable",
      "operations",
      "orchestration",
      "oo",
      "containerized",
      "capability.",
      "on-premises",
      "eks",
      "aks",
      "containerized.cloud",
      "cost",
      "reporting",
      "enables",
      "monitor",
      "spending",
      "simplify",
      "configuration",
      "various",
      "providers.image",
      "aggregation",
      "ia",
      "showcases",
      "templates",
      "marketplace",
      "portals",
      "aws",
      "microsoft",
      "azure",
      "vcenter.",
      "business",
      "manager",
      "aggregator",
      "instantly",
      "create",
      "offer",
      "services",
      "having",
      "automation",
      "asset.",
      "content",
      "store",
      "part",
      "web-based",
      "managing",
      "capsules.",
      "users",
      "download"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Use Operations Orchestration Containerized",
    "content": "Navigate through the following topics to comprehend the usage of OO Central and OO Workflow Designer. Use OO Central - In the agent interface, navigate to Run > Automation Operations. You can access OO Central only if you have set up Operations Orchestration as given in Configure OO Containerized menu visibility Use OO Workflow Designer - You need to install an on-premises OO Workflow Designer separately as it's not available out of the box. For more information, see Install OO Workflow Designer.",
    "url": "useoperationsorchestration",
    "filename": "useoperationsorchestration",
    "headings": [],
    "keywords": [
      "operations",
      "orchestration",
      "containerized",
      "navigate",
      "through",
      "following",
      "topics",
      "comprehend",
      "usage",
      "oo",
      "central",
      "workflow",
      "designer.",
      "agent",
      "interface",
      "run",
      "automation",
      "operations.",
      "access",
      "set",
      "given",
      "configure",
      "menu",
      "visibility",
      "designer",
      "need",
      "install",
      "on-premises",
      "separately",
      "available",
      "out",
      "box.",
      "information",
      "see"
    ],
    "language": "en",
    "word_count": 54,
    "importance_score": 2.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "use operations orchestration containerized",
    "contentLower": "navigate through the following topics to comprehend the usage of oo central and oo workflow designer. use oo central - in the agent interface, navigate to run > automation operations. you can access oo central only if you have set up operations orchestration as given in configure oo containerized menu visibility use oo workflow designer - you need to install an on-premises oo workflow designer separately as it's not available out of the box. for more information, see install oo workflow designer.",
    "keywordsLower": [
      "operations",
      "orchestration",
      "containerized",
      "navigate",
      "through",
      "following",
      "topics",
      "comprehend",
      "usage",
      "oo",
      "central",
      "workflow",
      "designer.",
      "agent",
      "interface",
      "run",
      "automation",
      "operations.",
      "access",
      "set",
      "given",
      "configure",
      "menu",
      "visibility",
      "designer",
      "need",
      "install",
      "on-premises",
      "separately",
      "available",
      "out",
      "box.",
      "information",
      "see"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Use Vulnerability and Remediation",
    "content": "The Vulnerability & Remediation capability gives a comprehensive solution to manage risks associated with vulnerabilities across server operating systems. It offers vulnerability assessment, risk scoring to prioritize orchestrated patching, and to resolve vulnerabilities. A security vulnerability is a software code flaw or when a system fails through which attackers can directly gain unauthorized access to a system or a network. When you integrate Qualys with Automation Center and import vulnerability scan results, you can view all the vulnerabilities associated with the devices managed in Automation Center. Enable Vulnerability & Remediation To enable the Vulnerability & Remediation capability in ESM, perform the following steps: From the Mega Menu, go to Administration > Configuration > Application Settings. Set Enable Vulnerability and Remediation to On. Click Save. Refresh the page. You can access the Vulnerability and Remediation pages through the Mega Menu > Build > Vulnerability",
    "url": "usevulnerabilityandremediationac",
    "filename": "usevulnerabilityandremediationac",
    "headings": [
      "Enable Vulnerability & Remediation"
    ],
    "keywords": [
      "vulnerability",
      "remediation",
      "enable",
      "capability",
      "gives",
      "comprehensive",
      "solution",
      "manage",
      "risks",
      "associated",
      "vulnerabilities",
      "across",
      "server",
      "operating",
      "systems.",
      "offers",
      "assessment",
      "risk",
      "scoring",
      "prioritize",
      "orchestrated",
      "patching",
      "resolve",
      "vulnerabilities.",
      "security",
      "software",
      "code",
      "flaw",
      "system",
      "fails",
      "through",
      "attackers",
      "directly",
      "gain",
      "unauthorized",
      "access",
      "network.",
      "integrate",
      "qualys",
      "automation",
      "center",
      "import",
      "scan",
      "results",
      "view",
      "all",
      "devices",
      "managed",
      "center.",
      "esm",
      "perform",
      "following",
      "steps",
      "mega",
      "menu",
      "go",
      "administration",
      "configuration",
      "application",
      "settings.",
      "set",
      "on.",
      "click",
      "save.",
      "refresh",
      "page.",
      "pages",
      "build",
      "remediation."
    ],
    "language": "en",
    "word_count": 93,
    "importance_score": 3.5,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "use vulnerability and remediation",
    "contentLower": "the vulnerability & remediation capability gives a comprehensive solution to manage risks associated with vulnerabilities across server operating systems. it offers vulnerability assessment, risk scoring to prioritize orchestrated patching, and to resolve vulnerabilities. a security vulnerability is a software code flaw or when a system fails through which attackers can directly gain unauthorized access to a system or a network. when you integrate qualys with automation center and import vulnerability scan results, you can view all the vulnerabilities associated with the devices managed in automation center. enable vulnerability & remediation to enable the vulnerability & remediation capability in esm, perform the following steps: from the mega menu, go to administration > configuration > application settings. set enable vulnerability and remediation to on. click save. refresh the page. you can access the vulnerability and remediation pages through the mega menu > build > vulnerability",
    "keywordsLower": [
      "vulnerability",
      "remediation",
      "enable",
      "capability",
      "gives",
      "comprehensive",
      "solution",
      "manage",
      "risks",
      "associated",
      "vulnerabilities",
      "across",
      "server",
      "operating",
      "systems.",
      "offers",
      "assessment",
      "risk",
      "scoring",
      "prioritize",
      "orchestrated",
      "patching",
      "resolve",
      "vulnerabilities.",
      "security",
      "software",
      "code",
      "flaw",
      "system",
      "fails",
      "through",
      "attackers",
      "directly",
      "gain",
      "unauthorized",
      "access",
      "network.",
      "integrate",
      "qualys",
      "automation",
      "center",
      "import",
      "scan",
      "results",
      "view",
      "all",
      "devices",
      "managed",
      "center.",
      "esm",
      "perform",
      "following",
      "steps",
      "mega",
      "menu",
      "go",
      "administration",
      "configuration",
      "application",
      "settings.",
      "set",
      "on.",
      "click",
      "save.",
      "refresh",
      "page.",
      "pages",
      "build",
      "remediation."
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Vulnerabilities",
    "content": "This page gives information on vulnerabilities and how to view them. Overview A security vulnerability is a software code flaw or when a system stops responding through which attackers can directly gain unauthorized access to a system or a network. When you import Qualys vulnerability scan results, you can view all vulnerabilities associated with the devices managed in Automation Center. Lifecycle of vulnerabilities Vulnerabilities have a pre-defined workflow representing the lifecycle of every instance within Automation Center. Vulnerability has the following metaphases: DraftActiveInactive The lifecycle of a vulnerability has the following transition phases: Vulnerability Transitions Transition phase Transition type Description New > Define Automatic When you fill in the name, the phase moves from New to Define. Define > Approve Manual This identifies that there is no default approval plan and moves a policy automatically from Define to Active phase. Approve > Active Manual/ Automati",
    "url": "vulnerabilitiesac",
    "filename": "vulnerabilitiesac",
    "headings": [
      "Overview",
      "Lifecycle of vulnerabilities",
      "Draft",
      "Active",
      "Inactive",
      "View vulnerabilities",
      "Filters",
      "Vulnerability details",
      "General tab",
      "CVE details",
      "Vulnerable Configuration Items tab",
      "Available Patches tab",
      "Discussions tab",
      "History tab",
      "View device vulnerability status"
    ],
    "keywords": [
      "24.3",
      "Vulnerabilities.To",
      "vulnerabilities",
      "overview",
      "lifecycle",
      "draft",
      "active",
      "inactive",
      "view",
      "filters",
      "vulnerability",
      "details",
      "general",
      "tab",
      "cve",
      "vulnerable",
      "configuration",
      "items",
      "available",
      "patches",
      "discussions",
      "history",
      "device",
      "status",
      "page",
      "gives",
      "information",
      "them.",
      "security",
      "software",
      "code",
      "flaw",
      "system",
      "stops",
      "responding",
      "through",
      "attackers",
      "directly",
      "gain",
      "unauthorized",
      "access",
      "network.",
      "import",
      "qualys",
      "scan",
      "results",
      "all",
      "associated",
      "devices",
      "managed",
      "automation",
      "center.",
      "pre-defined",
      "workflow",
      "representing",
      "every",
      "instance",
      "following",
      "metaphases",
      "draftactiveinactive",
      "transition",
      "phases",
      "transitions",
      "phase",
      "type",
      "description",
      "new",
      "define",
      "automatic",
      "fill",
      "name",
      "moves",
      "define.",
      "approve",
      "manual",
      "identifies",
      "there",
      "default",
      "approval",
      "plan",
      "policy",
      "automatically",
      "phase.",
      "definition",
      "approved.",
      "suspend",
      "until",
      "changes",
      "rules.",
      "retire",
      "implementations",
      "reference",
      "it.",
      "metaphase",
      "contains",
      "initial",
      "newly",
      "created",
      "required",
      "information."
    ],
    "language": "en",
    "word_count": 91,
    "importance_score": 6.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "vulnerabilities",
    "contentLower": "this page gives information on vulnerabilities and how to view them. overview a security vulnerability is a software code flaw or when a system stops responding through which attackers can directly gain unauthorized access to a system or a network. when you import qualys vulnerability scan results, you can view all vulnerabilities associated with the devices managed in automation center. lifecycle of vulnerabilities vulnerabilities have a pre-defined workflow representing the lifecycle of every instance within automation center. vulnerability has the following metaphases: draftactiveinactive the lifecycle of a vulnerability has the following transition phases: vulnerability transitions transition phase transition type description new > define automatic when you fill in the name, the phase moves from new to define. define > approve manual this identifies that there is no default approval plan and moves a policy automatically from define to active phase. approve > active manual/ automati",
    "keywordsLower": [
      "24.3",
      "vulnerabilities.to",
      "vulnerabilities",
      "overview",
      "lifecycle",
      "draft",
      "active",
      "inactive",
      "view",
      "filters",
      "vulnerability",
      "details",
      "general",
      "tab",
      "cve",
      "vulnerable",
      "configuration",
      "items",
      "available",
      "patches",
      "discussions",
      "history",
      "device",
      "status",
      "page",
      "gives",
      "information",
      "them.",
      "security",
      "software",
      "code",
      "flaw",
      "system",
      "stops",
      "responding",
      "through",
      "attackers",
      "directly",
      "gain",
      "unauthorized",
      "access",
      "network.",
      "import",
      "qualys",
      "scan",
      "results",
      "all",
      "associated",
      "devices",
      "managed",
      "automation",
      "center.",
      "pre-defined",
      "workflow",
      "representing",
      "every",
      "instance",
      "following",
      "metaphases",
      "draftactiveinactive",
      "transition",
      "phases",
      "transitions",
      "phase",
      "type",
      "description",
      "new",
      "define",
      "automatic",
      "fill",
      "name",
      "moves",
      "define.",
      "approve",
      "manual",
      "identifies",
      "there",
      "default",
      "approval",
      "plan",
      "policy",
      "automatically",
      "phase.",
      "definition",
      "approved.",
      "suspend",
      "until",
      "changes",
      "rules.",
      "retire",
      "implementations",
      "reference",
      "it.",
      "metaphase",
      "contains",
      "initial",
      "newly",
      "created",
      "required",
      "information."
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Use Aviator",
    "content": "In Service Portal and Agent Interface, you can chat with Aviator in natural language. Aviator generates responses based on the input you provide. The response can vary in length and detail depending on the complexity of the query. You can ask follow-up questions to get more accurate and relevant answers or start a new chat to explore different topics. When using Aviator, be aware of the following: Don't share any personal, sensitive, or confidential information. Harmful or toxicity prevention is in place to identify and block content that may be harmful, offensive, or inappropriate. It's advisable to cross-reference the information given by Aviator with reliable sources. If you’re instructed to use a specific language when interacting with Aviator, ensure you do so to enhance the accuracy of Aviator’s responses. See Aviator language. Related topics Use Aviator in Service Portal Use Aviator in Agent Interface",
    "url": "useaviator",
    "filename": "useaviator",
    "headings": [
      "Related topics"
    ],
    "keywords": [
      "aviator",
      "related",
      "topics",
      "service",
      "portal",
      "agent",
      "interface",
      "chat",
      "natural",
      "language.",
      "generates",
      "responses",
      "based",
      "input",
      "provide.",
      "response",
      "vary",
      "length",
      "detail",
      "depending",
      "complexity",
      "query.",
      "ask",
      "follow-up",
      "questions",
      "get",
      "accurate",
      "relevant",
      "answers",
      "start",
      "new",
      "explore",
      "different",
      "topics.",
      "aware",
      "following",
      "don",
      "share",
      "any",
      "personal",
      "sensitive",
      "confidential",
      "information.",
      "harmful",
      "toxicity",
      "prevention",
      "place",
      "identify",
      "block",
      "content",
      "offensive",
      "inappropriate.",
      "advisable",
      "cross-reference",
      "information",
      "given",
      "reliable",
      "sources.",
      "re",
      "instructed",
      "specific",
      "language",
      "interacting",
      "ensure",
      "enhance",
      "accuracy",
      "responses.",
      "see"
    ],
    "language": "en",
    "word_count": 87,
    "importance_score": 3.5,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "use aviator",
    "contentLower": "in service portal and agent interface, you can chat with aviator in natural language. aviator generates responses based on the input you provide. the response can vary in length and detail depending on the complexity of the query. you can ask follow-up questions to get more accurate and relevant answers or start a new chat to explore different topics. when using aviator, be aware of the following: don't share any personal, sensitive, or confidential information. harmful or toxicity prevention is in place to identify and block content that may be harmful, offensive, or inappropriate. it's advisable to cross-reference the information given by aviator with reliable sources. if you’re instructed to use a specific language when interacting with aviator, ensure you do so to enhance the accuracy of aviator’s responses. see aviator language. related topics use aviator in service portal use aviator in agent interface",
    "keywordsLower": [
      "aviator",
      "related",
      "topics",
      "service",
      "portal",
      "agent",
      "interface",
      "chat",
      "natural",
      "language.",
      "generates",
      "responses",
      "based",
      "input",
      "provide.",
      "response",
      "vary",
      "length",
      "detail",
      "depending",
      "complexity",
      "query.",
      "ask",
      "follow-up",
      "questions",
      "get",
      "accurate",
      "relevant",
      "answers",
      "start",
      "new",
      "explore",
      "different",
      "topics.",
      "aware",
      "following",
      "don",
      "share",
      "any",
      "personal",
      "sensitive",
      "confidential",
      "information.",
      "harmful",
      "toxicity",
      "prevention",
      "place",
      "identify",
      "block",
      "content",
      "offensive",
      "inappropriate.",
      "advisable",
      "cross-reference",
      "information",
      "given",
      "reliable",
      "sources.",
      "re",
      "instructed",
      "specific",
      "language",
      "interacting",
      "ensure",
      "enhance",
      "accuracy",
      "responses.",
      "see"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Use Aviator in Service Portal",
    "content": "You can chat with Aviator by clicking the Aviator icon in Service Portal. Aviator disclaimer acceptance An Aviator disclaimer popup will appear upon your first interaction with Aviator, prompting for user acceptance. To engage in conversations with Aviator, click Accept. If you click Cancel, you'll be using the basic Virtual Agent capability. To alter your choice, go to the Preferences page of your Service Portal profile and reset the Aviator disclaimer acceptance option. Ask a question Type your question (for example, how to connect to a printer) in the message bar and click Post. Then, Aviator will generate an answer to your question. When the Aviator service connection fails, responses will be generated using IDOL search. If the answer isn't complete, click Continue generating to view the full text. This button allows for only two clicks and it's not available for open topics. If a Suggested next steps section is present with some suggestions (including offerings and conversational ",
    "url": "useaviatorinserviceportal",
    "filename": "useaviatorinserviceportal",
    "headings": [
      "Aviator disclaimer acceptance",
      "Ask a question",
      "Create a new topic",
      "Create a support request"
    ],
    "keywords": [
      "aviator",
      "service",
      "portal",
      "disclaimer",
      "acceptance",
      "ask",
      "question",
      "create",
      "new",
      "topic",
      "support",
      "request",
      "chat",
      "clicking",
      "icon",
      "portal.",
      "popup",
      "appear",
      "upon",
      "first",
      "interaction",
      "prompting",
      "user",
      "acceptance.",
      "engage",
      "conversations",
      "click",
      "accept.",
      "cancel",
      "ll",
      "basic",
      "virtual",
      "agent",
      "capability.",
      "alter",
      "choice",
      "go",
      "preferences",
      "page",
      "profile",
      "reset",
      "option.",
      "type",
      "example",
      "connect",
      "printer",
      "message",
      "bar",
      "post.",
      "generate",
      "answer",
      "question.",
      "connection",
      "fails",
      "responses",
      "generated",
      "idol",
      "search.",
      "isn",
      "complete",
      "continue",
      "generating",
      "view",
      "full",
      "text.",
      "button",
      "allows",
      "two",
      "clicks",
      "available",
      "open",
      "topics.",
      "suggested",
      "next",
      "steps",
      "section",
      "present",
      "suggestions",
      "including",
      "offerings",
      "conversational",
      "intents",
      "intent",
      "offering",
      "submit",
      "request.",
      "displayed",
      "according",
      "relevant",
      "scores.",
      "any",
      "follow-up",
      "questions",
      "detailed",
      "result",
      "accurate",
      "reference",
      "resources.",
      "whenever",
      "answers"
    ],
    "language": "en",
    "word_count": 99,
    "importance_score": 5.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "use aviator in service portal",
    "contentLower": "you can chat with aviator by clicking the aviator icon in service portal. aviator disclaimer acceptance an aviator disclaimer popup will appear upon your first interaction with aviator, prompting for user acceptance. to engage in conversations with aviator, click accept. if you click cancel, you'll be using the basic virtual agent capability. to alter your choice, go to the preferences page of your service portal profile and reset the aviator disclaimer acceptance option. ask a question type your question (for example, how to connect to a printer) in the message bar and click post. then, aviator will generate an answer to your question. when the aviator service connection fails, responses will be generated using idol search. if the answer isn't complete, click continue generating to view the full text. this button allows for only two clicks and it's not available for open topics. if a suggested next steps section is present with some suggestions (including offerings and conversational ",
    "keywordsLower": [
      "aviator",
      "service",
      "portal",
      "disclaimer",
      "acceptance",
      "ask",
      "question",
      "create",
      "new",
      "topic",
      "support",
      "request",
      "chat",
      "clicking",
      "icon",
      "portal.",
      "popup",
      "appear",
      "upon",
      "first",
      "interaction",
      "prompting",
      "user",
      "acceptance.",
      "engage",
      "conversations",
      "click",
      "accept.",
      "cancel",
      "ll",
      "basic",
      "virtual",
      "agent",
      "capability.",
      "alter",
      "choice",
      "go",
      "preferences",
      "page",
      "profile",
      "reset",
      "option.",
      "type",
      "example",
      "connect",
      "printer",
      "message",
      "bar",
      "post.",
      "generate",
      "answer",
      "question.",
      "connection",
      "fails",
      "responses",
      "generated",
      "idol",
      "search.",
      "isn",
      "complete",
      "continue",
      "generating",
      "view",
      "full",
      "text.",
      "button",
      "allows",
      "two",
      "clicks",
      "available",
      "open",
      "topics.",
      "suggested",
      "next",
      "steps",
      "section",
      "present",
      "suggestions",
      "including",
      "offerings",
      "conversational",
      "intents",
      "intent",
      "offering",
      "submit",
      "request.",
      "displayed",
      "according",
      "relevant",
      "scores.",
      "any",
      "follow-up",
      "questions",
      "detailed",
      "result",
      "accurate",
      "reference",
      "resources.",
      "whenever",
      "answers"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Use Aviator in Agent Interface",
    "content": "Chat with Aviator You can chat with Aviator by clicking the Aviator icon in Agent Interface. Aviator disclaimer acceptance An Aviator disclaimer popup will appear upon your first interaction with Aviator, prompting for user acceptance. To engage in conversations with Aviator, click I understand. Ask a question Type your question (for example, how to connect to a printer) in the message bar and click the Post icon . Then, Aviator will generate an answer to your question. If the answer isn't complete, click Continue generating to view the full text. For any follow-up questions, type them in the message bar and click the Post icon . More detailed questions will result in more accurate responses. If there's no reference resource found in the previous question, Aviator may search and provide reference resources in the follow-up question. Click the References icon to view the detailed information about the reference materials relevant to your question. See Use Aviator in Service Portal for m",
    "url": "useaviatoragentinterface",
    "filename": "useaviatoragentinterface",
    "headings": [
      "Chat with Aviator",
      "Aviator disclaimer acceptance",
      "Ask a question",
      "Summarize a record",
      "Summarize ticket / Suggest a solution for Request and Incident",
      "Create a new topic",
      "Manage conversations",
      "Other action icons",
      "Analyze the sentiment of Requests",
      "Generate and send escalation notifications for Requests",
      "Analyze the risk of Changes",
      "Create Knowledge articles",
      "Resolve Incidents",
      "Privacy analysis for Requests",
      "View records updated by Aviator business rules"
    ],
    "keywords": [
      "aviator",
      "agent",
      "interface",
      "chat",
      "disclaimer",
      "acceptance",
      "ask",
      "question",
      "summarize",
      "record",
      "ticket",
      "suggest",
      "solution",
      "request",
      "incident",
      "create",
      "new",
      "topic",
      "manage",
      "conversations",
      "action",
      "icons",
      "analyze",
      "sentiment",
      "requests",
      "generate",
      "send",
      "escalation",
      "notifications",
      "risk",
      "changes",
      "knowledge",
      "articles",
      "resolve",
      "incidents",
      "privacy",
      "analysis",
      "view",
      "records",
      "updated",
      "business",
      "rules",
      "clicking",
      "icon",
      "interface.",
      "popup",
      "appear",
      "upon",
      "first",
      "interaction",
      "prompting",
      "user",
      "acceptance.",
      "engage",
      "click",
      "understand.",
      "type",
      "example",
      "connect",
      "printer",
      "message",
      "bar",
      "post",
      "answer",
      "question.",
      "isn",
      "complete",
      "continue",
      "generating",
      "full",
      "text.",
      "any",
      "follow-up",
      "questions",
      "detailed",
      "result",
      "accurate",
      "responses.",
      "there",
      "reference",
      "resource",
      "found",
      "previous",
      "search",
      "provide",
      "resources",
      "references",
      "information",
      "about",
      "materials",
      "relevant",
      "see",
      "service",
      "portal",
      "section.",
      "select",
      "open",
      "all",
      "oob",
      "custom"
    ],
    "language": "en",
    "word_count": 101,
    "importance_score": 6.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "use aviator in agent interface",
    "contentLower": "chat with aviator you can chat with aviator by clicking the aviator icon in agent interface. aviator disclaimer acceptance an aviator disclaimer popup will appear upon your first interaction with aviator, prompting for user acceptance. to engage in conversations with aviator, click i understand. ask a question type your question (for example, how to connect to a printer) in the message bar and click the post icon . then, aviator will generate an answer to your question. if the answer isn't complete, click continue generating to view the full text. for any follow-up questions, type them in the message bar and click the post icon . more detailed questions will result in more accurate responses. if there's no reference resource found in the previous question, aviator may search and provide reference resources in the follow-up question. click the references icon to view the detailed information about the reference materials relevant to your question. see use aviator in service portal for m",
    "keywordsLower": [
      "aviator",
      "agent",
      "interface",
      "chat",
      "disclaimer",
      "acceptance",
      "ask",
      "question",
      "summarize",
      "record",
      "ticket",
      "suggest",
      "solution",
      "request",
      "incident",
      "create",
      "new",
      "topic",
      "manage",
      "conversations",
      "action",
      "icons",
      "analyze",
      "sentiment",
      "requests",
      "generate",
      "send",
      "escalation",
      "notifications",
      "risk",
      "changes",
      "knowledge",
      "articles",
      "resolve",
      "incidents",
      "privacy",
      "analysis",
      "view",
      "records",
      "updated",
      "business",
      "rules",
      "clicking",
      "icon",
      "interface.",
      "popup",
      "appear",
      "upon",
      "first",
      "interaction",
      "prompting",
      "user",
      "acceptance.",
      "engage",
      "click",
      "understand.",
      "type",
      "example",
      "connect",
      "printer",
      "message",
      "bar",
      "post",
      "answer",
      "question.",
      "isn",
      "complete",
      "continue",
      "generating",
      "full",
      "text.",
      "any",
      "follow-up",
      "questions",
      "detailed",
      "result",
      "accurate",
      "responses.",
      "there",
      "reference",
      "resource",
      "found",
      "previous",
      "search",
      "provide",
      "resources",
      "references",
      "information",
      "about",
      "materials",
      "relevant",
      "see",
      "service",
      "portal",
      "section.",
      "select",
      "open",
      "all",
      "oob",
      "custom"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Use Customer Service Management (CSM)",
    "content": "This page provides links to functional areas leveraged and enhanced by CSM. Company management for CSMService catalog managementContract managementKnowledge managementService level managementTime period managementService request management",
    "url": "usecsm",
    "filename": "usecsm",
    "headings": [],
    "keywords": [
      "customer",
      "service",
      "management",
      "csm",
      "page",
      "provides",
      "links",
      "functional",
      "areas",
      "leveraged",
      "enhanced",
      "csm.",
      "company",
      "csmservice",
      "catalog",
      "managementcontract",
      "managementknowledge",
      "managementservice",
      "level",
      "managementtime",
      "period",
      "request"
    ],
    "language": "en",
    "word_count": 25,
    "importance_score": 2.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "use customer service management (csm)",
    "contentLower": "this page provides links to functional areas leveraged and enhanced by csm. company management for csmservice catalog managementcontract managementknowledge managementservice level managementtime period managementservice request management",
    "keywordsLower": [
      "customer",
      "service",
      "management",
      "csm",
      "page",
      "provides",
      "links",
      "functional",
      "areas",
      "leveraged",
      "enhanced",
      "csm.",
      "company",
      "csmservice",
      "catalog",
      "managementcontract",
      "managementknowledge",
      "managementservice",
      "level",
      "managementtime",
      "period",
      "request"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Use inbox",
    "content": "Use inbox If the tenant administrator has enabled the Inbox functionality, agent users can view and use the inbox. View the Inbox queue Log in to the Agent Interface. On the main menu, select Inbox. Inbox has the following out-of-the-box views: MY INBOX to view the list of records assigned to you, owned by you or your group. ASSIGNED TO ME to view the work assigned to you. OWNED BY ME to view the work owned by you. MY GROUP INBOX to view the work owned to or by your group. By default, My Inbox is selected. To sort the grid, select the heading of the column by which you want to sort the grid. By default, the records are sorted by SLT.Next target time. To filter the records, select the Add filter button. To view the updated records, refresh the grid as inbox does not refresh automatically. You can only view and edit the records for which you have the edit permission. Manage your inbox On the main menu, select Inbox. A grid view of the inbox is displayed. Select the record identifier in t",
    "url": "accessinbox",
    "filename": "accessinbox",
    "headings": [
      "Use inbox",
      "Manage your inbox",
      "Related topics"
    ],
    "keywords": [
      "SLT.Next",
      "inbox",
      "manage",
      "related",
      "topics",
      "tenant",
      "administrator",
      "enabled",
      "functionality",
      "agent",
      "users",
      "view",
      "inbox.",
      "queue",
      "log",
      "interface.",
      "main",
      "menu",
      "select",
      "following",
      "out-of-the-box",
      "views",
      "list",
      "records",
      "assigned",
      "owned",
      "group.",
      "work",
      "you.",
      "group",
      "default",
      "selected.",
      "sort",
      "grid",
      "heading",
      "column",
      "want",
      "grid.",
      "sorted",
      "target",
      "time.",
      "filter",
      "add",
      "button.",
      "updated",
      "refresh",
      "automatically.",
      "edit",
      "permission.",
      "displayed.",
      "record",
      "identifier",
      "id",
      "dispaly",
      "details",
      "new",
      "tab",
      "preview",
      "record.",
      "pane",
      "fields",
      "simliar",
      "parent",
      "update",
      "automatically",
      "after",
      "edits.",
      "filter.",
      "information",
      "see",
      "filters.",
      "necessary",
      "columns",
      "wish",
      "appear",
      "maximum",
      "250",
      "page.",
      "get",
      "started",
      "configure"
    ],
    "language": "en",
    "word_count": 98,
    "importance_score": 4.5,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "use inbox",
    "contentLower": "use inbox if the tenant administrator has enabled the inbox functionality, agent users can view and use the inbox. view the inbox queue log in to the agent interface. on the main menu, select inbox. inbox has the following out-of-the-box views: my inbox to view the list of records assigned to you, owned by you or your group. assigned to me to view the work assigned to you. owned by me to view the work owned by you. my group inbox to view the work owned to or by your group. by default, my inbox is selected. to sort the grid, select the heading of the column by which you want to sort the grid. by default, the records are sorted by slt.next target time. to filter the records, select the add filter button. to view the updated records, refresh the grid as inbox does not refresh automatically. you can only view and edit the records for which you have the edit permission. manage your inbox on the main menu, select inbox. a grid view of the inbox is displayed. select the record identifier in t",
    "keywordsLower": [
      "slt.next",
      "inbox",
      "manage",
      "related",
      "topics",
      "tenant",
      "administrator",
      "enabled",
      "functionality",
      "agent",
      "users",
      "view",
      "inbox.",
      "queue",
      "log",
      "interface.",
      "main",
      "menu",
      "select",
      "following",
      "out-of-the-box",
      "views",
      "list",
      "records",
      "assigned",
      "owned",
      "group.",
      "work",
      "you.",
      "group",
      "default",
      "selected.",
      "sort",
      "grid",
      "heading",
      "column",
      "want",
      "grid.",
      "sorted",
      "target",
      "time.",
      "filter",
      "add",
      "button.",
      "updated",
      "refresh",
      "automatically.",
      "edit",
      "permission.",
      "displayed.",
      "record",
      "identifier",
      "id",
      "dispaly",
      "details",
      "new",
      "tab",
      "preview",
      "record.",
      "pane",
      "fields",
      "simliar",
      "parent",
      "update",
      "automatically",
      "after",
      "edits.",
      "filter.",
      "information",
      "see",
      "filters.",
      "necessary",
      "columns",
      "wish",
      "appear",
      "maximum",
      "250",
      "page.",
      "get",
      "started",
      "configure"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Views",
    "content": "A view displays a list of records generated through a search or filter operation. Records can be filtered based on criteria such as: Incident records where you are the assigned owner.Change records with a common category.Devices with the Windows 8 SP1 operating system. If you frequently work with similar record sets, it is helpful to create a view that automatically searches, filters, and displays all matching records. There are the following types of views: Public Views that are useful for everyone. Users with the Create public favorite views role permission can create public views and further update and delete these views. Private Views that serve as shortcuts to lists of records that you work with regularly. All users have permission to create private views. Group Views that are useful for and accessible only to certain user groups. Users with the Create group favorite views role permission can create group views, and further update and delete these group views. Users with Administe",
    "url": "views",
    "filename": "views",
    "headings": [
      "Create views",
      "Other view options"
    ],
    "keywords": [
      "appears.Add",
      "views",
      "create",
      "view",
      "options",
      "displays",
      "list",
      "records",
      "generated",
      "through",
      "search",
      "filter",
      "operation.",
      "filtered",
      "based",
      "criteria",
      "such",
      "incident",
      "assigned",
      "owner.change",
      "common",
      "category.devices",
      "windows",
      "sp1",
      "operating",
      "system.",
      "frequently",
      "work",
      "similar",
      "record",
      "sets",
      "helpful",
      "automatically",
      "searches",
      "filters",
      "all",
      "matching",
      "records.",
      "there",
      "following",
      "types",
      "public",
      "useful",
      "everyone.",
      "users",
      "favorite",
      "role",
      "permission",
      "further",
      "update",
      "delete",
      "views.",
      "private",
      "serve",
      "shortcuts",
      "lists",
      "regularly.",
      "group",
      "accessible",
      "certain",
      "user",
      "groups.",
      "administer",
      "created",
      "users.",
      "most",
      "service",
      "management",
      "modules",
      "request",
      "knowledge",
      "problem.",
      "system",
      "provides",
      "two",
      "out-of-the-box",
      "pre-defined",
      "provided",
      "default.",
      "cannot",
      "modify",
      "remove",
      "custom",
      "allow",
      "preferences.",
      "asterisk",
      "appears",
      "next",
      "name",
      "indicate",
      "unsaved",
      "changes.",
      "save",
      "edit",
      "option",
      "disappears",
      "indicating",
      "modifications",
      "pending.",
      "select"
    ],
    "language": "en",
    "word_count": 102,
    "importance_score": 4.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "views",
    "contentLower": "a view displays a list of records generated through a search or filter operation. records can be filtered based on criteria such as: incident records where you are the assigned owner.change records with a common category.devices with the windows 8 sp1 operating system. if you frequently work with similar record sets, it is helpful to create a view that automatically searches, filters, and displays all matching records. there are the following types of views: public views that are useful for everyone. users with the create public favorite views role permission can create public views and further update and delete these views. private views that serve as shortcuts to lists of records that you work with regularly. all users have permission to create private views. group views that are useful for and accessible only to certain user groups. users with the create group favorite views role permission can create group views, and further update and delete these group views. users with administe",
    "keywordsLower": [
      "appears.add",
      "views",
      "create",
      "view",
      "options",
      "displays",
      "list",
      "records",
      "generated",
      "through",
      "search",
      "filter",
      "operation.",
      "filtered",
      "based",
      "criteria",
      "such",
      "incident",
      "assigned",
      "owner.change",
      "common",
      "category.devices",
      "windows",
      "sp1",
      "operating",
      "system.",
      "frequently",
      "work",
      "similar",
      "record",
      "sets",
      "helpful",
      "automatically",
      "searches",
      "filters",
      "all",
      "matching",
      "records.",
      "there",
      "following",
      "types",
      "public",
      "useful",
      "everyone.",
      "users",
      "favorite",
      "role",
      "permission",
      "further",
      "update",
      "delete",
      "views.",
      "private",
      "serve",
      "shortcuts",
      "lists",
      "regularly.",
      "group",
      "accessible",
      "certain",
      "user",
      "groups.",
      "administer",
      "created",
      "users.",
      "most",
      "service",
      "management",
      "modules",
      "request",
      "knowledge",
      "problem.",
      "system",
      "provides",
      "two",
      "out-of-the-box",
      "pre-defined",
      "provided",
      "default.",
      "cannot",
      "modify",
      "remove",
      "custom",
      "allow",
      "preferences.",
      "asterisk",
      "appears",
      "next",
      "name",
      "indicate",
      "unsaved",
      "changes.",
      "save",
      "edit",
      "option",
      "disappears",
      "indicating",
      "modifications",
      "pending.",
      "select"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Update multiple records using the Preview pane",
    "content": "When a record is selected in the grid, the Preview pane on the right displays some details of the record. You can click Edit to update the details of the record directly in the Preview pane, without opening the record in the main pane. You can also move the record to a different phase, using the manual transition button at the top of the pane. When you are finished editing the record, click Save to save your changes. Note Click Discard to discard changes before saving. For Devices, Licenses, and Infrastructure & Peripheral assets, the update functionality is available in the Details tab of the Preview pane. When you edit records, you might make a change that results in an update to the data domain assignment and removes your authorization to view the records (for example, changing the owner of a record assigns the owner's data domains to the record, or changing the location assigns a different group due to a business rule running in the background). This can occur in the following situ",
    "url": "editrecpreview",
    "filename": "editrecpreview",
    "headings": [
      "Mass update",
      "Related topics"
    ],
    "keywords": [
      "update",
      "multiple",
      "records",
      "preview",
      "pane",
      "mass",
      "related",
      "topics",
      "record",
      "selected",
      "grid",
      "right",
      "displays",
      "details",
      "record.",
      "click",
      "edit",
      "directly",
      "opening",
      "main",
      "pane.",
      "move",
      "different",
      "phase",
      "manual",
      "transition",
      "button",
      "top",
      "finished",
      "editing",
      "save",
      "changes.",
      "note",
      "discard",
      "changes",
      "before",
      "saving.",
      "devices",
      "licenses",
      "infrastructure",
      "peripheral",
      "assets",
      "functionality",
      "available",
      "tab",
      "make",
      "change",
      "results",
      "data",
      "domain",
      "assignment",
      "removes",
      "authorization",
      "view",
      "example",
      "changing",
      "owner",
      "assigns",
      "domains",
      "location",
      "group",
      "due",
      "business",
      "rule",
      "running",
      "background",
      "occur",
      "following",
      "situations",
      "updating",
      "single",
      "field",
      "affects",
      "health",
      "indicator",
      "light",
      "bulb",
      "icon",
      "number",
      "increments",
      "existing",
      "indicating",
      "there",
      "new",
      "message--in",
      "case",
      "information",
      "message.",
      "occurs",
      "both",
      "page",
      "itself",
      "relevant",
      "message",
      "action",
      "indicates",
      "saving",
      "remove",
      "changed",
      "messages"
    ],
    "language": "en",
    "word_count": 97,
    "importance_score": 3.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "update multiple records using the preview pane",
    "contentLower": "when a record is selected in the grid, the preview pane on the right displays some details of the record. you can click edit to update the details of the record directly in the preview pane, without opening the record in the main pane. you can also move the record to a different phase, using the manual transition button at the top of the pane. when you are finished editing the record, click save to save your changes. note click discard to discard changes before saving. for devices, licenses, and infrastructure & peripheral assets, the update functionality is available in the details tab of the preview pane. when you edit records, you might make a change that results in an update to the data domain assignment and removes your authorization to view the records (for example, changing the owner of a record assigns the owner's data domains to the record, or changing the location assigns a different group due to a business rule running in the background). this can occur in the following situ",
    "keywordsLower": [
      "update",
      "multiple",
      "records",
      "preview",
      "pane",
      "mass",
      "related",
      "topics",
      "record",
      "selected",
      "grid",
      "right",
      "displays",
      "details",
      "record.",
      "click",
      "edit",
      "directly",
      "opening",
      "main",
      "pane.",
      "move",
      "different",
      "phase",
      "manual",
      "transition",
      "button",
      "top",
      "finished",
      "editing",
      "save",
      "changes.",
      "note",
      "discard",
      "changes",
      "before",
      "saving.",
      "devices",
      "licenses",
      "infrastructure",
      "peripheral",
      "assets",
      "functionality",
      "available",
      "tab",
      "make",
      "change",
      "results",
      "data",
      "domain",
      "assignment",
      "removes",
      "authorization",
      "view",
      "example",
      "changing",
      "owner",
      "assigns",
      "domains",
      "location",
      "group",
      "due",
      "business",
      "rule",
      "running",
      "background",
      "occur",
      "following",
      "situations",
      "updating",
      "single",
      "field",
      "affects",
      "health",
      "indicator",
      "light",
      "bulb",
      "icon",
      "number",
      "increments",
      "existing",
      "indicating",
      "there",
      "new",
      "message--in",
      "case",
      "information",
      "message.",
      "occurs",
      "both",
      "page",
      "itself",
      "relevant",
      "message",
      "action",
      "indicates",
      "saving",
      "remove",
      "changed",
      "messages"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Work with reports",
    "content": "You can create reports and view them as tables or column/pie/bar charts. Users who have access to the report can select and view each of these options dynamically. Users can also change reports viewed in the dashboard dynamically. View or edit an existing report From the main menu, click Reports to open the Reports page. In the left pane, select a report from the list. Service Management displays the report in the middle pane. Edit the report properties in the right panel, as described in Report properties. To preview your changes to the report, click the Preview button at the bottom of the right panel. Click Save at the bottom of the right panel to save your changes. For information on view and edit permission for reports, see Reports list pane. Create a report From the main menu, click Reports to open the Reports page. In the left pane, click New. Select the report type from the drop-down list. The available options are: Analytic report Operational report Operational raw data report ",
    "url": "wokwithreport",
    "filename": "wokwithreport",
    "headings": [
      "View or edit an existing report",
      "Create a report",
      "Delete a report",
      "Limitations",
      "Related topics"
    ],
    "keywords": [
      "work",
      "reports",
      "view",
      "edit",
      "existing",
      "report",
      "create",
      "delete",
      "limitations",
      "related",
      "topics",
      "tables",
      "column",
      "pie",
      "bar",
      "charts.",
      "users",
      "access",
      "select",
      "options",
      "dynamically.",
      "change",
      "viewed",
      "dashboard",
      "main",
      "menu",
      "click",
      "open",
      "page.",
      "left",
      "pane",
      "list.",
      "service",
      "management",
      "displays",
      "middle",
      "pane.",
      "properties",
      "right",
      "panel",
      "described",
      "properties.",
      "preview",
      "changes",
      "button",
      "bottom",
      "panel.",
      "save",
      "changes.",
      "information",
      "permission",
      "see",
      "list",
      "new.",
      "type",
      "drop-down",
      "available",
      "analytic",
      "operational",
      "raw",
      "data",
      "survey",
      "new",
      "defined",
      "active",
      "default.",
      "want",
      "based",
      "duplicate",
      "toolbar.",
      "dialog",
      "box",
      "opens.",
      "enter",
      "required",
      "button.",
      "report.",
      "directly",
      "record",
      "grid",
      "opens",
      "relevant",
      "already",
      "selected.",
      "generate",
      "sam",
      "two",
      "values",
      "same",
      "name",
      "license",
      "metric",
      "box.",
      "one",
      "check",
      "whether",
      "filter",
      "field",
      "lists",
      "following"
    ],
    "language": "en",
    "word_count": 106,
    "importance_score": 5.5,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "work with reports",
    "contentLower": "you can create reports and view them as tables or column/pie/bar charts. users who have access to the report can select and view each of these options dynamically. users can also change reports viewed in the dashboard dynamically. view or edit an existing report from the main menu, click reports to open the reports page. in the left pane, select a report from the list. service management displays the report in the middle pane. edit the report properties in the right panel, as described in report properties. to preview your changes to the report, click the preview button at the bottom of the right panel. click save at the bottom of the right panel to save your changes. for information on view and edit permission for reports, see reports list pane. create a report from the main menu, click reports to open the reports page. in the left pane, click new. select the report type from the drop-down list. the available options are: analytic report operational report operational raw data report ",
    "keywordsLower": [
      "work",
      "reports",
      "view",
      "edit",
      "existing",
      "report",
      "create",
      "delete",
      "limitations",
      "related",
      "topics",
      "tables",
      "column",
      "pie",
      "bar",
      "charts.",
      "users",
      "access",
      "select",
      "options",
      "dynamically.",
      "change",
      "viewed",
      "dashboard",
      "main",
      "menu",
      "click",
      "open",
      "page.",
      "left",
      "pane",
      "list.",
      "service",
      "management",
      "displays",
      "middle",
      "pane.",
      "properties",
      "right",
      "panel",
      "described",
      "properties.",
      "preview",
      "changes",
      "button",
      "bottom",
      "panel.",
      "save",
      "changes.",
      "information",
      "permission",
      "see",
      "list",
      "new.",
      "type",
      "drop-down",
      "available",
      "analytic",
      "operational",
      "raw",
      "data",
      "survey",
      "new",
      "defined",
      "active",
      "default.",
      "want",
      "based",
      "duplicate",
      "toolbar.",
      "dialog",
      "box",
      "opens.",
      "enter",
      "required",
      "button.",
      "report.",
      "directly",
      "record",
      "grid",
      "opens",
      "relevant",
      "already",
      "selected.",
      "generate",
      "sam",
      "two",
      "values",
      "same",
      "name",
      "license",
      "metric",
      "box.",
      "one",
      "check",
      "whether",
      "filter",
      "field",
      "lists",
      "following"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Update the Service Catalog",
    "content": "You edit the Service Catalog in the Service Catalog Management module. Service categories From the main menu, select Plan > Service Catalog > Catalog. To edit a catalog category, select the category, click the down arrow, and select Edit. The General tab displays the following sections: Section Description Category details Includes the following fields: Display label Description Audience Used to specify the appropriate audiences. This entitles users in the selected audiences, defined by location and user group, to access the category in the Service Portal. Audiences are defined in Administration > Master Data > People > Entitlement Rules. For more information, see How to manage entitlement rules. Category display settings Fields used to design category tiles for the Service Portal. For more information, see How to design category tiles for the Service Portal. Preview Displays a preview of the category tile. To delete a category, select the category, click the down arrow, and select Del",
    "url": "updatecatalog",
    "filename": "updatecatalog",
    "headings": [
      "Service categories",
      "Service Definitions",
      "Offerings",
      "Related topics"
    ],
    "keywords": [
      "update",
      "service",
      "catalog",
      "categories",
      "definitions",
      "offerings",
      "related",
      "topics",
      "edit",
      "management",
      "module.",
      "main",
      "menu",
      "select",
      "plan",
      "catalog.",
      "category",
      "click",
      "arrow",
      "edit.",
      "general",
      "tab",
      "displays",
      "following",
      "sections",
      "section",
      "description",
      "details",
      "includes",
      "fields",
      "display",
      "label",
      "audience",
      "specify",
      "appropriate",
      "audiences.",
      "entitles",
      "users",
      "selected",
      "audiences",
      "defined",
      "location",
      "user",
      "group",
      "access",
      "portal.",
      "administration",
      "master",
      "data",
      "people",
      "entitlement",
      "rules.",
      "information",
      "see",
      "manage",
      "settings",
      "design",
      "tiles",
      "preview",
      "tile.",
      "delete",
      "delete.",
      "contains",
      "services.",
      "before",
      "deleting",
      "transfer",
      "any",
      "services",
      "under",
      "categories.",
      "displayed",
      "definition.",
      "tip",
      "enter",
      "text",
      "string",
      "filter",
      "box",
      "narrow",
      "list",
      "definition",
      "pane.",
      "about",
      "create",
      "record.",
      "category.",
      "move",
      "another",
      "decommission",
      "decommissioned",
      "both",
      "aren",
      "available",
      "portal",
      "none",
      "request",
      "workflow",
      "component",
      "workflow."
    ],
    "language": "en",
    "word_count": 101,
    "importance_score": 5.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "update the service catalog",
    "contentLower": "you edit the service catalog in the service catalog management module. service categories from the main menu, select plan > service catalog > catalog. to edit a catalog category, select the category, click the down arrow, and select edit. the general tab displays the following sections: section description category details includes the following fields: display label description audience used to specify the appropriate audiences. this entitles users in the selected audiences, defined by location and user group, to access the category in the service portal. audiences are defined in administration > master data > people > entitlement rules. for more information, see how to manage entitlement rules. category display settings fields used to design category tiles for the service portal. for more information, see how to design category tiles for the service portal. preview displays a preview of the category tile. to delete a category, select the category, click the down arrow, and select del",
    "keywordsLower": [
      "update",
      "service",
      "catalog",
      "categories",
      "definitions",
      "offerings",
      "related",
      "topics",
      "edit",
      "management",
      "module.",
      "main",
      "menu",
      "select",
      "plan",
      "catalog.",
      "category",
      "click",
      "arrow",
      "edit.",
      "general",
      "tab",
      "displays",
      "following",
      "sections",
      "section",
      "description",
      "details",
      "includes",
      "fields",
      "display",
      "label",
      "audience",
      "specify",
      "appropriate",
      "audiences.",
      "entitles",
      "users",
      "selected",
      "audiences",
      "defined",
      "location",
      "user",
      "group",
      "access",
      "portal.",
      "administration",
      "master",
      "data",
      "people",
      "entitlement",
      "rules.",
      "information",
      "see",
      "manage",
      "settings",
      "design",
      "tiles",
      "preview",
      "tile.",
      "delete",
      "delete.",
      "contains",
      "services.",
      "before",
      "deleting",
      "transfer",
      "any",
      "services",
      "under",
      "categories.",
      "displayed",
      "definition.",
      "tip",
      "enter",
      "text",
      "string",
      "filter",
      "box",
      "narrow",
      "list",
      "definition",
      "pane.",
      "about",
      "create",
      "record.",
      "category.",
      "move",
      "another",
      "decommission",
      "decommissioned",
      "both",
      "aren",
      "available",
      "portal",
      "none",
      "request",
      "workflow",
      "component",
      "workflow."
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Use external data in user options",
    "content": "External data dynamic options allow you to populate dropdown fields with real-time data from external systems. It enables you to view and select current values from third-party systems when creating or updating records in Service Management. The key benefits of external data user options are: Real-time data: access up-to-date values from external systems at the moment of selectionSeamless integration: leverage Integration Studio to connect to any external data sourceEnhanced user experience: fast, searchable dropdowns with up to 1,000 displayed items Use cases Select organizations stored in external CRM systemsChoose devices or assets from external inventory management toolsPick values from external configuration management databases (CMDBs)Reference data from any third-party system accessible via Integration Studio Configuration steps Prerequisites Before configuring external data fields, ensure you have: administrator access: permissions to configure User Optionsan Integration Studio",
    "url": "fieldswithexternaldata",
    "filename": "fieldswithexternaldata",
    "headings": [
      "Use cases",
      "Configuration steps",
      "Prerequisites",
      "User Options configuration",
      "Usage: how fields work at runtime",
      "User experience",
      "Display format",
      "Error handling",
      "Advanced: field dependencies with parameters",
      "Integration Studio: scenario requirements",
      "Timeout",
      "Input parameters (optional)",
      "Required output format",
      "Field definitions",
      "Display rules",
      "Sample scenario logic",
      "Best practices",
      "Supported interfaces",
      "Interface-specific features",
      "Searching within dropdowns"
    ],
    "keywords": [
      "cleared.Use",
      "dropdown.The",
      "Field.Set",
      "needed.Use",
      "dropdown.User",
      "Executions.Find",
      "execution.You",
      "external",
      "data",
      "user",
      "options",
      "cases",
      "configuration",
      "steps",
      "prerequisites",
      "usage",
      "fields",
      "work",
      "runtime",
      "experience",
      "display",
      "format",
      "error",
      "handling",
      "advanced",
      "field",
      "dependencies",
      "parameters",
      "integration",
      "studio",
      "scenario",
      "requirements",
      "timeout",
      "input",
      "optional",
      "required",
      "output",
      "definitions",
      "rules",
      "sample",
      "logic",
      "best",
      "practices",
      "supported",
      "interfaces",
      "interface-specific",
      "features",
      "searching",
      "dropdowns",
      "key",
      "information",
      "troubleshooting",
      "common",
      "issues",
      "debugging",
      "dynamic",
      "allow",
      "populate",
      "dropdown",
      "real-time",
      "systems.",
      "enables",
      "view",
      "select",
      "current",
      "values",
      "third-party",
      "systems",
      "creating",
      "updating",
      "records",
      "service",
      "management.",
      "benefits",
      "access",
      "up-to-date",
      "moment",
      "selectionseamless",
      "leverage",
      "connect",
      "any",
      "sourceenhanced",
      "fast",
      "searchable",
      "000",
      "displayed",
      "items",
      "organizations",
      "stored",
      "crm",
      "systemschoose",
      "devices",
      "assets",
      "inventory",
      "management",
      "toolspick",
      "databases",
      "cmdbs",
      "reference",
      "system"
    ],
    "language": "en",
    "word_count": 106,
    "importance_score": 5.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "use external data in user options",
    "contentLower": "external data dynamic options allow you to populate dropdown fields with real-time data from external systems. it enables you to view and select current values from third-party systems when creating or updating records in service management. the key benefits of external data user options are: real-time data: access up-to-date values from external systems at the moment of selectionseamless integration: leverage integration studio to connect to any external data sourceenhanced user experience: fast, searchable dropdowns with up to 1,000 displayed items use cases select organizations stored in external crm systemschoose devices or assets from external inventory management toolspick values from external configuration management databases (cmdbs)reference data from any third-party system accessible via integration studio configuration steps prerequisites before configuring external data fields, ensure you have: administrator access: permissions to configure user optionsan integration studio",
    "keywordsLower": [
      "cleared.use",
      "dropdown.the",
      "field.set",
      "needed.use",
      "dropdown.user",
      "executions.find",
      "execution.you",
      "external",
      "data",
      "user",
      "options",
      "cases",
      "configuration",
      "steps",
      "prerequisites",
      "usage",
      "fields",
      "work",
      "runtime",
      "experience",
      "display",
      "format",
      "error",
      "handling",
      "advanced",
      "field",
      "dependencies",
      "parameters",
      "integration",
      "studio",
      "scenario",
      "requirements",
      "timeout",
      "input",
      "optional",
      "required",
      "output",
      "definitions",
      "rules",
      "sample",
      "logic",
      "best",
      "practices",
      "supported",
      "interfaces",
      "interface-specific",
      "features",
      "searching",
      "dropdowns",
      "key",
      "information",
      "troubleshooting",
      "common",
      "issues",
      "debugging",
      "dynamic",
      "allow",
      "populate",
      "dropdown",
      "real-time",
      "systems.",
      "enables",
      "view",
      "select",
      "current",
      "values",
      "third-party",
      "systems",
      "creating",
      "updating",
      "records",
      "service",
      "management.",
      "benefits",
      "access",
      "up-to-date",
      "moment",
      "selectionseamless",
      "leverage",
      "connect",
      "any",
      "sourceenhanced",
      "fast",
      "searchable",
      "000",
      "displayed",
      "items",
      "organizations",
      "stored",
      "crm",
      "systemschoose",
      "devices",
      "assets",
      "inventory",
      "management",
      "toolspick",
      "databases",
      "cmdbs",
      "reference",
      "system"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Use entity links in user options",
    "content": "A tenant admin can create user options that act as entity links in the following record types: Offering, Fulfillment Plan, Incident Model, Change Model, and Release Model. This feature enables portal users and agent users to access data from Service Management tables when submitting requests and handling incident, change, and release records. You can use this feature to do the following: Define Entity Link user options: In offerings, fulfillment plans, incident models, change models, and release models, a new field type Entity Link is available on their User options tab. The tenant admin or an agent user with Create and Update permissions in Offering, Change Model, Incident Model, and Release Model can create entity link user options. Define suggested values for entity links: The tenant admin or an agent user with Create and Update permissions in Offering, Change Model, Incident Model, and Release Model can use the \"Define suggested values for entity link based on filter\" rule template",
    "url": "useentitylinksinuseroptions",
    "filename": "useentitylinksinuseroptions",
    "headings": [
      "Configure application settings",
      "Create an entity link user option",
      "Define suggested values for the entity link user option",
      "Submit requests in Service Portal",
      "View entity link values in request records",
      "Work with entity link values in reports",
      "Add a custom ESS role in the Person workflow",
      "Related topics"
    ],
    "keywords": [
      "entity",
      "links",
      "user",
      "options",
      "configure",
      "application",
      "settings",
      "create",
      "link",
      "option",
      "define",
      "suggested",
      "values",
      "submit",
      "requests",
      "service",
      "portal",
      "view",
      "request",
      "records",
      "work",
      "reports",
      "add",
      "custom",
      "ess",
      "role",
      "person",
      "workflow",
      "related",
      "topics",
      "tenant",
      "admin",
      "act",
      "following",
      "record",
      "types",
      "offering",
      "fulfillment",
      "plan",
      "incident",
      "model",
      "change",
      "release",
      "model.",
      "feature",
      "enables",
      "users",
      "agent",
      "access",
      "data",
      "management",
      "tables",
      "submitting",
      "handling",
      "records.",
      "offerings",
      "plans",
      "models",
      "new",
      "field",
      "type",
      "available",
      "tab.",
      "update",
      "permissions",
      "options.",
      "based",
      "filter",
      "rule",
      "template",
      "control",
      "what",
      "selection",
      "users.",
      "role-based",
      "receive",
      "message",
      "indicating",
      "aren",
      "authorized",
      "roles",
      "don",
      "permission.",
      "want",
      "allow",
      "specific",
      "permission",
      "described",
      "topic.",
      "group",
      "grid",
      "views",
      "value",
      "note",
      "doesn",
      "support",
      "filtering",
      "grouping",
      "value.",
      "example"
    ],
    "language": "en",
    "word_count": 114,
    "importance_score": 5.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "use entity links in user options",
    "contentLower": "a tenant admin can create user options that act as entity links in the following record types: offering, fulfillment plan, incident model, change model, and release model. this feature enables portal users and agent users to access data from service management tables when submitting requests and handling incident, change, and release records. you can use this feature to do the following: define entity link user options: in offerings, fulfillment plans, incident models, change models, and release models, a new field type entity link is available on their user options tab. the tenant admin or an agent user with create and update permissions in offering, change model, incident model, and release model can create entity link user options. define suggested values for entity links: the tenant admin or an agent user with create and update permissions in offering, change model, incident model, and release model can use the \"define suggested values for entity link based on filter\" rule template",
    "keywordsLower": [
      "entity",
      "links",
      "user",
      "options",
      "configure",
      "application",
      "settings",
      "create",
      "link",
      "option",
      "define",
      "suggested",
      "values",
      "submit",
      "requests",
      "service",
      "portal",
      "view",
      "request",
      "records",
      "work",
      "reports",
      "add",
      "custom",
      "ess",
      "role",
      "person",
      "workflow",
      "related",
      "topics",
      "tenant",
      "admin",
      "act",
      "following",
      "record",
      "types",
      "offering",
      "fulfillment",
      "plan",
      "incident",
      "model",
      "change",
      "release",
      "model.",
      "feature",
      "enables",
      "users",
      "agent",
      "access",
      "data",
      "management",
      "tables",
      "submitting",
      "handling",
      "records.",
      "offerings",
      "plans",
      "models",
      "new",
      "field",
      "type",
      "available",
      "tab.",
      "update",
      "permissions",
      "options.",
      "based",
      "filter",
      "rule",
      "template",
      "control",
      "what",
      "selection",
      "users.",
      "role-based",
      "receive",
      "message",
      "indicating",
      "aren",
      "authorized",
      "roles",
      "don",
      "permission.",
      "want",
      "allow",
      "specific",
      "permission",
      "described",
      "topic.",
      "group",
      "grid",
      "views",
      "value",
      "note",
      "doesn",
      "support",
      "filtering",
      "grouping",
      "value.",
      "example"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Use entity link user options in DSL expressions",
    "content": "You can use entity link user options in DSL expressions so that related entity attributes can be easily used in DSL to improve the effectiveness of Service Management. Notes: This feature supports user options of both out-of-the-box (OOB) and custom entities. You can use DSL expressions with entity link user options in the following areas: task plans in offerings and in change / incident / release models. business rules in offerings and in change / incident / release models. business rules in workflows. You can use this feature as follows: Use entity link user options directly in DSL. For example: entity.UserOptions.MyOption (return ID). Use entity related OOB fields in DSL. For example: entity.UserOptions.MyOption.OOBField. Use entity related custom fields in DSL. For example: entity.UserOptions.MyOption.CustomField. The following sections describe some example use cases. Use case 1: Use an entity link user option in the task plan of an offering A user submits a support request for a ",
    "url": "useentitylinksuseroptionsindsl",
    "filename": "useentitylinksuseroptionsindsl",
    "headings": [
      "Use case 1: Use an entity link user option in the task plan of an offering",
      "Step 1: Enable a custom entity link between two out-of-the-box record types",
      "Step 2: Create an entity link user option in an offering",
      "Step 3: Create a task plan for the offering",
      "Step 4: Submit a request in Service Portal",
      "Step 5: Assign the request to an agent",
      "Use case 2: Use an entity link user option in a workflow",
      "Step 1: Create a rule in the Request workflow",
      "Step 2: Submit a request for the offering",
      "Step 3: Assign the request in the agent interface",
      "Related topics"
    ],
    "keywords": [
      "entity",
      "link",
      "user",
      "options",
      "dsl",
      "expressions",
      "case",
      "option",
      "task",
      "plan",
      "offering",
      "step",
      "enable",
      "custom",
      "between",
      "two",
      "out-of-the-box",
      "record",
      "types",
      "create",
      "submit",
      "request",
      "service",
      "portal",
      "assign",
      "agent",
      "workflow",
      "rule",
      "interface",
      "related",
      "topics",
      "attributes",
      "easily",
      "improve",
      "effectiveness",
      "management.",
      "notes",
      "feature",
      "supports",
      "both",
      "oob",
      "entities.",
      "following",
      "areas",
      "plans",
      "offerings",
      "change",
      "incident",
      "release",
      "models.",
      "business",
      "rules",
      "workflows.",
      "follows",
      "directly",
      "dsl.",
      "example",
      "entity.useroptions.myoption",
      "return",
      "id",
      "fields",
      "entity.useroptions.myoption.oobfield.",
      "entity.useroptions.myoption.customfield.",
      "sections",
      "describe",
      "cases.",
      "submits",
      "support",
      "reboot",
      "one",
      "vm.",
      "relevant",
      "automated",
      "defined.",
      "once",
      "completed",
      "triggers",
      "action",
      "captures",
      "displays",
      "physical",
      "information",
      "specified",
      "device",
      "vm",
      "request.",
      "process",
      "involves",
      "steps.",
      "open",
      "existing",
      "record.",
      "sample",
      "named",
      "pc",
      "laptop",
      "used.",
      "tab",
      "add",
      "click"
    ],
    "language": "en",
    "word_count": 100,
    "importance_score": 5.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "use entity link user options in dsl expressions",
    "contentLower": "you can use entity link user options in dsl expressions so that related entity attributes can be easily used in dsl to improve the effectiveness of service management. notes: this feature supports user options of both out-of-the-box (oob) and custom entities. you can use dsl expressions with entity link user options in the following areas: task plans in offerings and in change / incident / release models. business rules in offerings and in change / incident / release models. business rules in workflows. you can use this feature as follows: use entity link user options directly in dsl. for example: entity.useroptions.myoption (return id). use entity related oob fields in dsl. for example: entity.useroptions.myoption.oobfield. use entity related custom fields in dsl. for example: entity.useroptions.myoption.customfield. the following sections describe some example use cases. use case 1: use an entity link user option in the task plan of an offering a user submits a support request for a ",
    "keywordsLower": [
      "entity",
      "link",
      "user",
      "options",
      "dsl",
      "expressions",
      "case",
      "option",
      "task",
      "plan",
      "offering",
      "step",
      "enable",
      "custom",
      "between",
      "two",
      "out-of-the-box",
      "record",
      "types",
      "create",
      "submit",
      "request",
      "service",
      "portal",
      "assign",
      "agent",
      "workflow",
      "rule",
      "interface",
      "related",
      "topics",
      "attributes",
      "easily",
      "improve",
      "effectiveness",
      "management.",
      "notes",
      "feature",
      "supports",
      "both",
      "oob",
      "entities.",
      "following",
      "areas",
      "plans",
      "offerings",
      "change",
      "incident",
      "release",
      "models.",
      "business",
      "rules",
      "workflows.",
      "follows",
      "directly",
      "dsl.",
      "example",
      "entity.useroptions.myoption",
      "return",
      "id",
      "fields",
      "entity.useroptions.myoption.oobfield.",
      "entity.useroptions.myoption.customfield.",
      "sections",
      "describe",
      "cases.",
      "submits",
      "support",
      "reboot",
      "one",
      "vm.",
      "relevant",
      "automated",
      "defined.",
      "once",
      "completed",
      "triggers",
      "action",
      "captures",
      "displays",
      "physical",
      "information",
      "specified",
      "device",
      "vm",
      "request.",
      "process",
      "involves",
      "steps.",
      "open",
      "existing",
      "record.",
      "sample",
      "named",
      "pc",
      "laptop",
      "used.",
      "tab",
      "add",
      "click"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Work with Service Level Requirements",
    "content": "Service Level Requirements are records that are produced by documenting the customer's requirements. They serve as the basis for future Service Level Agreements. Service Level Requirements should be SMART, and are usually based on key performance indicators. In Service Management, Service Level Requirements are defined in Service Level Agreement records that are in the New phase of the Service Level Agreement workflow. Once both parties (the service provider and the customer) agree on the requirements, the record can be moved to the Approve phase. View Service Level Requirements From the main menu, select Plan > Service Level > Service Level Requirements to display the Service Level Requirements grid. That is, all agreements currently in the New phase of the Service Level Agreement workflow. To filter the list, click the Add filter button. For more information, see Filters. Click a record identifier in the ID column to display that record. Create, edit, and delete Service Level Require",
    "url": "servicelevelrequirements",
    "filename": "servicelevelrequirements",
    "headings": [
      "View Service Level Requirements",
      "Create, edit, and delete Service Level Requirements",
      "Related topics"
    ],
    "keywords": [
      "work",
      "service",
      "level",
      "requirements",
      "view",
      "create",
      "edit",
      "delete",
      "related",
      "topics",
      "records",
      "produced",
      "documenting",
      "customer",
      "requirements.",
      "serve",
      "basis",
      "future",
      "agreements.",
      "smart",
      "usually",
      "based",
      "key",
      "performance",
      "indicators.",
      "management",
      "defined",
      "agreement",
      "new",
      "phase",
      "workflow.",
      "once",
      "both",
      "parties",
      "provider",
      "agree",
      "record",
      "moved",
      "approve",
      "phase.",
      "main",
      "menu",
      "select",
      "plan",
      "display",
      "grid.",
      "all",
      "agreements",
      "currently",
      "filter",
      "list",
      "click",
      "add",
      "button.",
      "information",
      "see",
      "filters.",
      "identifier",
      "id",
      "column",
      "record.",
      "because",
      "process",
      "identical",
      "requirement",
      "directly",
      "page",
      "first",
      "subtype",
      "want",
      "flavor",
      "field.",
      "follow",
      "steps",
      "workflow",
      "procedures"
    ],
    "language": "en",
    "word_count": 105,
    "importance_score": 4.5,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "work with service level requirements",
    "contentLower": "service level requirements are records that are produced by documenting the customer's requirements. they serve as the basis for future service level agreements. service level requirements should be smart, and are usually based on key performance indicators. in service management, service level requirements are defined in service level agreement records that are in the new phase of the service level agreement workflow. once both parties (the service provider and the customer) agree on the requirements, the record can be moved to the approve phase. view service level requirements from the main menu, select plan > service level > service level requirements to display the service level requirements grid. that is, all agreements currently in the new phase of the service level agreement workflow. to filter the list, click the add filter button. for more information, see filters. click a record identifier in the id column to display that record. create, edit, and delete service level require",
    "keywordsLower": [
      "work",
      "service",
      "level",
      "requirements",
      "view",
      "create",
      "edit",
      "delete",
      "related",
      "topics",
      "records",
      "produced",
      "documenting",
      "customer",
      "requirements.",
      "serve",
      "basis",
      "future",
      "agreements.",
      "smart",
      "usually",
      "based",
      "key",
      "performance",
      "indicators.",
      "management",
      "defined",
      "agreement",
      "new",
      "phase",
      "workflow.",
      "once",
      "both",
      "parties",
      "provider",
      "agree",
      "record",
      "moved",
      "approve",
      "phase.",
      "main",
      "menu",
      "select",
      "plan",
      "display",
      "grid.",
      "all",
      "agreements",
      "currently",
      "filter",
      "list",
      "click",
      "add",
      "button.",
      "information",
      "see",
      "filters.",
      "identifier",
      "id",
      "column",
      "record.",
      "because",
      "process",
      "identical",
      "requirement",
      "directly",
      "page",
      "first",
      "subtype",
      "want",
      "flavor",
      "field.",
      "follow",
      "steps",
      "workflow",
      "procedures"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "View or edit company",
    "content": "This page explains how to view or edit a company record. View or edit company Click > Plan > Company.Click the name of the company you want to view or edit. The company record contains the following tabs. Tab Description General View and edit company details, account admins, sites, and attachments. For more information, see the \"General tab\" section. Workflow View the workflow and current phase of the company. For information on the company workflow and the procedure to change the phase, see the Company workflow page. Related contracts View and add contracts associated with the company. For more information, see the \"Related contracts tab\" section. Related parties View the users of the company. View, add, and remove related companies. View, add, and remove users of the related companies. For more information, see the \"Related parties tab\" section. Entitlements View and add entitlements. For information about entitlements, see the \"Entitlements tab\" section . Purchased products View and",
    "url": "vieworeditcompanydetails",
    "filename": "vieworeditcompanydetails",
    "headings": [
      "View or edit company",
      "General tab",
      "Company details",
      "Account admins",
      "Who is an account admin?",
      "Add account admin",
      "Remove account admin",
      "Sites",
      "What is a site",
      "Add site",
      "Remove site",
      "Designate site as headquarters",
      "Remove headquarters designation",
      "Attachments",
      "Add attachment",
      "Delete attachment",
      "Workflow tab",
      "Related contracts tab",
      "Add contract",
      "View or edit details of contract"
    ],
    "keywords": [
      "edit.Edit",
      "companies.MSP",
      "view",
      "edit",
      "company",
      "general",
      "tab",
      "details",
      "account",
      "admins",
      "admin",
      "add",
      "remove",
      "sites",
      "what",
      "site",
      "designate",
      "headquarters",
      "designation",
      "attachments",
      "attachment",
      "delete",
      "workflow",
      "related",
      "contracts",
      "contract",
      "parties",
      "companies",
      "relation",
      "users",
      "user",
      "entitlements",
      "entitlement",
      "purchased",
      "products",
      "product",
      "instance",
      "licenses",
      "license",
      "consumed",
      "environments",
      "environment",
      "owned",
      "requests",
      "raise",
      "request",
      "agent",
      "interface",
      "page",
      "explains",
      "record.",
      "click",
      "plan",
      "company.click",
      "name",
      "want",
      "edit.",
      "record",
      "contains",
      "following",
      "tabs.",
      "description",
      "attachments.",
      "information",
      "see",
      "section.",
      "current",
      "phase",
      "company.",
      "procedure",
      "change",
      "page.",
      "associated",
      "companies.",
      "entitlements.",
      "about",
      "section",
      "instances.",
      "instances",
      "environments.",
      "raised",
      "discussions",
      "any",
      "relevant",
      "conversations",
      "history",
      "changes",
      "required.click",
      "save",
      "toolbar",
      "changes.",
      "sections",
      "detailsaccount",
      "adminscontactssitesattachments",
      "field",
      "duns",
      "number",
      "provided",
      "code",
      "identification"
    ],
    "language": "en",
    "word_count": 106,
    "importance_score": 6.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "view or edit company",
    "contentLower": "this page explains how to view or edit a company record. view or edit company click > plan > company.click the name of the company you want to view or edit. the company record contains the following tabs. tab description general view and edit company details, account admins, sites, and attachments. for more information, see the \"general tab\" section. workflow view the workflow and current phase of the company. for information on the company workflow and the procedure to change the phase, see the company workflow page. related contracts view and add contracts associated with the company. for more information, see the \"related contracts tab\" section. related parties view the users of the company. view, add, and remove related companies. view, add, and remove users of the related companies. for more information, see the \"related parties tab\" section. entitlements view and add entitlements. for information about entitlements, see the \"entitlements tab\" section . purchased products view and",
    "keywordsLower": [
      "edit.edit",
      "companies.msp",
      "view",
      "edit",
      "company",
      "general",
      "tab",
      "details",
      "account",
      "admins",
      "admin",
      "add",
      "remove",
      "sites",
      "what",
      "site",
      "designate",
      "headquarters",
      "designation",
      "attachments",
      "attachment",
      "delete",
      "workflow",
      "related",
      "contracts",
      "contract",
      "parties",
      "companies",
      "relation",
      "users",
      "user",
      "entitlements",
      "entitlement",
      "purchased",
      "products",
      "product",
      "instance",
      "licenses",
      "license",
      "consumed",
      "environments",
      "environment",
      "owned",
      "requests",
      "raise",
      "request",
      "agent",
      "interface",
      "page",
      "explains",
      "record.",
      "click",
      "plan",
      "company.click",
      "name",
      "want",
      "edit.",
      "record",
      "contains",
      "following",
      "tabs.",
      "description",
      "attachments.",
      "information",
      "see",
      "section.",
      "current",
      "phase",
      "company.",
      "procedure",
      "change",
      "page.",
      "associated",
      "companies.",
      "entitlements.",
      "about",
      "section",
      "instances.",
      "instances",
      "environments.",
      "raised",
      "discussions",
      "any",
      "relevant",
      "conversations",
      "history",
      "changes",
      "required.click",
      "save",
      "toolbar",
      "changes.",
      "sections",
      "detailsaccount",
      "adminscontactssitesattachments",
      "field",
      "duns",
      "number",
      "provided",
      "code",
      "identification"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "View or edit product model",
    "content": "This page explains how to view or edit a product model record. View or edit product model Click > Plan > Company. In the Companies dropdown, click Product Models. Click the name of the product model you want to view or edit. The product model record contains the following tabs. Tab Description General View and edit product model details. For more information, see the \"General tab\" section. Workflow View the workflow and current phase of the product model. The current phase of the product model is highlighted in blue in the workflow. For information on the product model workflow and the procedure to change the phase, see the Product model workflow page. User options View, add, and delete user options for the product model. For more information, see the \"User options tab\" section. Default values Define default values for all the custom fields in the User options tab. For more information, see the \"Default values\" section. Rules Define business rules for the product model. For more inform",
    "url": "vieworeditproductmodel",
    "filename": "vieworeditproductmodel",
    "headings": [
      "View or edit product model",
      "General tab",
      "Product model details",
      "Identifiers",
      "Sustainability",
      "Attachments",
      "Add attachment",
      "Delete attachment",
      "Workflow tab",
      "User options tab",
      "User options",
      "Add section",
      "Add group",
      "Add field",
      "Delete section, group, or field",
      "Default values tab",
      "Define default value",
      "Rules tab",
      "Add business rule",
      "Edit, remove, or disable business rule"
    ],
    "keywords": [
      "MyURL.com",
      "view",
      "edit",
      "product",
      "model",
      "general",
      "tab",
      "details",
      "identifiers",
      "sustainability",
      "attachments",
      "add",
      "attachment",
      "delete",
      "workflow",
      "user",
      "options",
      "section",
      "group",
      "field",
      "default",
      "values",
      "define",
      "value",
      "rules",
      "business",
      "rule",
      "remove",
      "disable",
      "modules",
      "module",
      "versions",
      "version",
      "bundled",
      "products",
      "bundle",
      "item",
      "current",
      "phase",
      "change",
      "page",
      "explains",
      "record.",
      "click",
      "plan",
      "company.",
      "companies",
      "dropdown",
      "models.",
      "name",
      "want",
      "edit.",
      "record",
      "contains",
      "following",
      "tabs.",
      "description",
      "details.",
      "information",
      "see",
      "section.",
      "model.",
      "highlighted",
      "blue",
      "workflow.",
      "procedure",
      "page.",
      "all",
      "custom",
      "fields",
      "tab.",
      "related",
      "knowledge",
      "news",
      "articles",
      "available",
      "models",
      "type",
      "category.",
      "environments",
      "instances",
      "deployed.",
      "sub",
      "sub-product",
      "products.",
      "discussions",
      "conversations",
      "relevant",
      "history",
      "changes",
      "required.",
      "save",
      "toolbar.",
      "sections",
      "display",
      "label",
      "product.",
      "collection",
      "multiple",
      "packaged"
    ],
    "language": "en",
    "word_count": 113,
    "importance_score": 6.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "view or edit product model",
    "contentLower": "this page explains how to view or edit a product model record. view or edit product model click > plan > company. in the companies dropdown, click product models. click the name of the product model you want to view or edit. the product model record contains the following tabs. tab description general view and edit product model details. for more information, see the \"general tab\" section. workflow view the workflow and current phase of the product model. the current phase of the product model is highlighted in blue in the workflow. for information on the product model workflow and the procedure to change the phase, see the product model workflow page. user options view, add, and delete user options for the product model. for more information, see the \"user options tab\" section. default values define default values for all the custom fields in the user options tab. for more information, see the \"default values\" section. rules define business rules for the product model. for more inform",
    "keywordsLower": [
      "myurl.com",
      "view",
      "edit",
      "product",
      "model",
      "general",
      "tab",
      "details",
      "identifiers",
      "sustainability",
      "attachments",
      "add",
      "attachment",
      "delete",
      "workflow",
      "user",
      "options",
      "section",
      "group",
      "field",
      "default",
      "values",
      "define",
      "value",
      "rules",
      "business",
      "rule",
      "remove",
      "disable",
      "modules",
      "module",
      "versions",
      "version",
      "bundled",
      "products",
      "bundle",
      "item",
      "current",
      "phase",
      "change",
      "page",
      "explains",
      "record.",
      "click",
      "plan",
      "company.",
      "companies",
      "dropdown",
      "models.",
      "name",
      "want",
      "edit.",
      "record",
      "contains",
      "following",
      "tabs.",
      "description",
      "details.",
      "information",
      "see",
      "section.",
      "model.",
      "highlighted",
      "blue",
      "workflow.",
      "procedure",
      "page.",
      "all",
      "custom",
      "fields",
      "tab.",
      "related",
      "knowledge",
      "news",
      "articles",
      "available",
      "models",
      "type",
      "category.",
      "environments",
      "instances",
      "deployed.",
      "sub",
      "sub-product",
      "products.",
      "discussions",
      "conversations",
      "relevant",
      "history",
      "changes",
      "required.",
      "save",
      "toolbar.",
      "sections",
      "display",
      "label",
      "product.",
      "collection",
      "multiple",
      "packaged"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "View or edit product module",
    "content": "This page explains how to view or edit a product module record. View or edit product module Click > Plan > Company. In the Companies dropdown, click Product Modules. Click the ID of the product module you want to view or edit. The product module record contains the following tabs. Tab Description General View and edit product module details. For more information, see the \"General tab\" section. Workflow View the workflow and current phase of the product module. The current phase of the product model is highlighted in blue in the workflow. For information on the product module workflow and the procedure to change the phase, see the Product module workflow page. Discussions View conversations relevant to the product module. For more information, see the Discussions page. History View changes to the product module record. For more information, see the History page Click the tab you want to view or edit. Edit as required. Click Save on the toolbar. General tab This tab displays the followin",
    "url": "vieworeditproductmodule",
    "filename": "vieworeditproductmodule",
    "headings": [
      "View or edit product module",
      "General tab"
    ],
    "keywords": [
      "view",
      "edit",
      "product",
      "module",
      "general",
      "tab",
      "page",
      "explains",
      "record.",
      "click",
      "plan",
      "company.",
      "companies",
      "dropdown",
      "modules.",
      "id",
      "want",
      "edit.",
      "record",
      "contains",
      "following",
      "tabs.",
      "description",
      "details.",
      "information",
      "see",
      "section.",
      "workflow",
      "current",
      "phase",
      "module.",
      "model",
      "highlighted",
      "blue",
      "workflow.",
      "procedure",
      "change",
      "page.",
      "discussions",
      "conversations",
      "relevant",
      "history",
      "changes",
      "required.",
      "save",
      "toolbar.",
      "displays",
      "details",
      "field",
      "display",
      "label",
      "belongs."
    ],
    "language": "en",
    "word_count": 110,
    "importance_score": 4.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "view or edit product module",
    "contentLower": "this page explains how to view or edit a product module record. view or edit product module click > plan > company. in the companies dropdown, click product modules. click the id of the product module you want to view or edit. the product module record contains the following tabs. tab description general view and edit product module details. for more information, see the \"general tab\" section. workflow view the workflow and current phase of the product module. the current phase of the product model is highlighted in blue in the workflow. for information on the product module workflow and the procedure to change the phase, see the product module workflow page. discussions view conversations relevant to the product module. for more information, see the discussions page. history view changes to the product module record. for more information, see the history page click the tab you want to view or edit. edit as required. click save on the toolbar. general tab this tab displays the followin",
    "keywordsLower": [
      "view",
      "edit",
      "product",
      "module",
      "general",
      "tab",
      "page",
      "explains",
      "record.",
      "click",
      "plan",
      "company.",
      "companies",
      "dropdown",
      "modules.",
      "id",
      "want",
      "edit.",
      "record",
      "contains",
      "following",
      "tabs.",
      "description",
      "details.",
      "information",
      "see",
      "section.",
      "workflow",
      "current",
      "phase",
      "module.",
      "model",
      "highlighted",
      "blue",
      "workflow.",
      "procedure",
      "change",
      "page.",
      "discussions",
      "conversations",
      "relevant",
      "history",
      "changes",
      "required.",
      "save",
      "toolbar.",
      "displays",
      "details",
      "field",
      "display",
      "label",
      "belongs."
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Version workflow",
    "content": "This page explains the version workflow and the steps to perform the following tasks: View workflow and current phase of version Change phase of version Version workflow The version workflow describes the different metaphases and phases in the lifecycle of a version. Metaphases represent broad stages in the lifecycle, while phases are the specific steps within each stage. The version lifecycle consists of the following metaphases: Planning Consumable Retired (End) The following figure shows the version workflow. The following table describes the phases within each metaphase. Metaphase Phase Description Allowed transitions Transition type Planning Draft After creating the version, it is in the Draft phase by default. Keep the version in the Draft phase until it is ready to use. Draft to Active, Draft to Inactive Manual Consumable Active Move the version to the Active phase when it is ready for use or has active customers Active to Inactive Manual Retired (End) Inactive Move the version ",
    "url": "manageversionworkflow",
    "filename": "manageversionworkflow",
    "headings": [
      "Version workflow",
      "View workflow and current phase of version",
      "Change phase of version"
    ],
    "keywords": [
      "version",
      "workflow",
      "view",
      "current",
      "phase",
      "change",
      "page",
      "explains",
      "steps",
      "perform",
      "following",
      "tasks",
      "describes",
      "different",
      "metaphases",
      "phases",
      "lifecycle",
      "version.",
      "represent",
      "broad",
      "stages",
      "while",
      "specific",
      "stage.",
      "consists",
      "planning",
      "consumable",
      "retired",
      "end",
      "figure",
      "shows",
      "workflow.",
      "table",
      "metaphase.",
      "metaphase",
      "description",
      "allowed",
      "transitions",
      "transition",
      "type",
      "draft",
      "after",
      "creating",
      "default.",
      "keep",
      "until",
      "ready",
      "use.",
      "active",
      "inactive",
      "manual",
      "move",
      "customers",
      "longer",
      "support",
      "ended.",
      "click",
      "plan",
      "company.",
      "companies",
      "dropdown",
      "product",
      "versions.",
      "id",
      "tab.",
      "displays",
      "highlighted",
      "blue.",
      "directs",
      "general",
      "tab",
      "button",
      "upper-right",
      "side",
      "next",
      "select",
      "appropriate",
      "dropdown.",
      "save."
    ],
    "language": "en",
    "word_count": 101,
    "importance_score": 4.5,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "version workflow",
    "contentLower": "this page explains the version workflow and the steps to perform the following tasks: view workflow and current phase of version change phase of version version workflow the version workflow describes the different metaphases and phases in the lifecycle of a version. metaphases represent broad stages in the lifecycle, while phases are the specific steps within each stage. the version lifecycle consists of the following metaphases: planning consumable retired (end) the following figure shows the version workflow. the following table describes the phases within each metaphase. metaphase phase description allowed transitions transition type planning draft after creating the version, it is in the draft phase by default. keep the version in the draft phase until it is ready to use. draft to active, draft to inactive manual consumable active move the version to the active phase when it is ready for use or has active customers active to inactive manual retired (end) inactive move the version ",
    "keywordsLower": [
      "version",
      "workflow",
      "view",
      "current",
      "phase",
      "change",
      "page",
      "explains",
      "steps",
      "perform",
      "following",
      "tasks",
      "describes",
      "different",
      "metaphases",
      "phases",
      "lifecycle",
      "version.",
      "represent",
      "broad",
      "stages",
      "while",
      "specific",
      "stage.",
      "consists",
      "planning",
      "consumable",
      "retired",
      "end",
      "figure",
      "shows",
      "workflow.",
      "table",
      "metaphase.",
      "metaphase",
      "description",
      "allowed",
      "transitions",
      "transition",
      "type",
      "draft",
      "after",
      "creating",
      "default.",
      "keep",
      "until",
      "ready",
      "use.",
      "active",
      "inactive",
      "manual",
      "move",
      "customers",
      "longer",
      "support",
      "ended.",
      "click",
      "plan",
      "company.",
      "companies",
      "dropdown",
      "product",
      "versions.",
      "id",
      "tab.",
      "displays",
      "highlighted",
      "blue.",
      "directs",
      "general",
      "tab",
      "button",
      "upper-right",
      "side",
      "next",
      "select",
      "appropriate",
      "dropdown.",
      "save."
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "View or edit version",
    "content": "This page explains how to view or edit a version record. View or edit version Click > Plan > Company. In the Companies dropdown, click Product Versions. Click the ID of the version you want to view or edit. The version record contains the following tabs. Field Description General View and edit version details. For more information, see the \"General tab\" section. Workflow View the workflow and current phase of the version. The current phase of the product model is highlighted in blue in the workflow. For information on the version workflow and the procedure to change the phase, see the Version workflow page. Discussions View conversations relevant to the version. For more information, see the Discussions page. History View changes to the version record. For more information, see the History page Click the tab you want to view or edit. Edit as required. Click Save on the toolbar. General tab This tab displays the following details of the version. Field Description Version name The name o",
    "url": "vieworeditversion",
    "filename": "vieworeditversion",
    "headings": [
      "View or edit version",
      "General tab"
    ],
    "keywords": [
      "view",
      "edit",
      "version",
      "general",
      "tab",
      "page",
      "explains",
      "record.",
      "click",
      "plan",
      "company.",
      "companies",
      "dropdown",
      "product",
      "versions.",
      "id",
      "want",
      "edit.",
      "record",
      "contains",
      "following",
      "tabs.",
      "field",
      "description",
      "details.",
      "information",
      "see",
      "section.",
      "workflow",
      "current",
      "phase",
      "version.",
      "model",
      "highlighted",
      "blue",
      "workflow.",
      "procedure",
      "change",
      "page.",
      "discussions",
      "conversations",
      "relevant",
      "history",
      "changes",
      "required.",
      "save",
      "toolbar.",
      "displays",
      "details",
      "name",
      "number",
      "number.",
      "display",
      "label",
      "auto-populated",
      "combining",
      "format",
      "belongs.",
      "type",
      "available",
      "options",
      "major",
      "minor",
      "patch.",
      "parent",
      "applicable",
      "maintenance",
      "start",
      "date",
      "begins.",
      "end",
      "ends."
    ],
    "language": "en",
    "word_count": 107,
    "importance_score": 4.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "view or edit version",
    "contentLower": "this page explains how to view or edit a version record. view or edit version click > plan > company. in the companies dropdown, click product versions. click the id of the version you want to view or edit. the version record contains the following tabs. field description general view and edit version details. for more information, see the \"general tab\" section. workflow view the workflow and current phase of the version. the current phase of the product model is highlighted in blue in the workflow. for information on the version workflow and the procedure to change the phase, see the version workflow page. discussions view conversations relevant to the version. for more information, see the discussions page. history view changes to the version record. for more information, see the history page click the tab you want to view or edit. edit as required. click save on the toolbar. general tab this tab displays the following details of the version. field description version name the name o",
    "keywordsLower": [
      "view",
      "edit",
      "version",
      "general",
      "tab",
      "page",
      "explains",
      "record.",
      "click",
      "plan",
      "company.",
      "companies",
      "dropdown",
      "product",
      "versions.",
      "id",
      "want",
      "edit.",
      "record",
      "contains",
      "following",
      "tabs.",
      "field",
      "description",
      "details.",
      "information",
      "see",
      "section.",
      "workflow",
      "current",
      "phase",
      "version.",
      "model",
      "highlighted",
      "blue",
      "workflow.",
      "procedure",
      "change",
      "page.",
      "discussions",
      "conversations",
      "relevant",
      "history",
      "changes",
      "required.",
      "save",
      "toolbar.",
      "displays",
      "details",
      "name",
      "number",
      "number.",
      "display",
      "label",
      "auto-populated",
      "combining",
      "format",
      "belongs.",
      "type",
      "available",
      "options",
      "major",
      "minor",
      "patch.",
      "parent",
      "applicable",
      "maintenance",
      "start",
      "date",
      "begins.",
      "end",
      "ends."
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "View or edit environment",
    "content": "This page explains how to view or edit an environment record. View or edit environment Click > Plan > Company. In the Companies dropdown, click Environments. Click the ID of the environment you want to view or edit. The environment record contains the following tabs: Tab Description General View and edit environment details. View the product instances deployed in the environment and update their verisons. For more information, see the \"General tab\" section. Workflow View the workflow and current phase of the environment. The current phase of the environment is highlighted in blue in the workflow. For information on the environment workflow and the procedure to change the phase, see the Environment workflow page. Discussions View conversations relevant to the environment. For more information, see the Discussions page. History View changes to the environment record. For more information, see the History page Click the tab you want to view or edit. Edit as required. Click Save on the too",
    "url": "vieworeditenvironment",
    "filename": "vieworeditenvironment",
    "headings": [
      "View or edit environment",
      "General tab",
      "Environment details",
      "Product Instances"
    ],
    "keywords": [
      "view",
      "edit",
      "environment",
      "general",
      "tab",
      "details",
      "product",
      "instances",
      "page",
      "explains",
      "record.",
      "click",
      "plan",
      "company.",
      "companies",
      "dropdown",
      "environments.",
      "id",
      "want",
      "edit.",
      "record",
      "contains",
      "following",
      "tabs",
      "description",
      "details.",
      "deployed",
      "update",
      "verisons.",
      "information",
      "see",
      "section.",
      "workflow",
      "current",
      "phase",
      "environment.",
      "highlighted",
      "blue",
      "workflow.",
      "procedure",
      "change",
      "page.",
      "discussions",
      "conversations",
      "relevant",
      "history",
      "changes",
      "required.",
      "save",
      "toolbar.",
      "sections",
      "field",
      "display",
      "label",
      "company",
      "owns",
      "service",
      "ignore",
      "functional",
      "release.",
      "type",
      "available",
      "options",
      "development",
      "non",
      "production",
      "staging",
      "test",
      "trial.",
      "deployment",
      "model",
      "premise",
      "public",
      "cloud",
      "private",
      "cloud.",
      "thise",
      "section",
      "displays",
      "version",
      "instance",
      "select",
      "instance.",
      "version.",
      "versions.",
      "clicking",
      "anwhere",
      "except",
      "gray.",
      "ok.",
      "ok",
      "dialog",
      "box.",
      "updated",
      "selected"
    ],
    "language": "en",
    "word_count": 99,
    "importance_score": 5.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "view or edit environment",
    "contentLower": "this page explains how to view or edit an environment record. view or edit environment click > plan > company. in the companies dropdown, click environments. click the id of the environment you want to view or edit. the environment record contains the following tabs: tab description general view and edit environment details. view the product instances deployed in the environment and update their verisons. for more information, see the \"general tab\" section. workflow view the workflow and current phase of the environment. the current phase of the environment is highlighted in blue in the workflow. for information on the environment workflow and the procedure to change the phase, see the environment workflow page. discussions view conversations relevant to the environment. for more information, see the discussions page. history view changes to the environment record. for more information, see the history page click the tab you want to view or edit. edit as required. click save on the too",
    "keywordsLower": [
      "view",
      "edit",
      "environment",
      "general",
      "tab",
      "details",
      "product",
      "instances",
      "page",
      "explains",
      "record.",
      "click",
      "plan",
      "company.",
      "companies",
      "dropdown",
      "environments.",
      "id",
      "want",
      "edit.",
      "record",
      "contains",
      "following",
      "tabs",
      "description",
      "details.",
      "deployed",
      "update",
      "verisons.",
      "information",
      "see",
      "section.",
      "workflow",
      "current",
      "phase",
      "environment.",
      "highlighted",
      "blue",
      "workflow.",
      "procedure",
      "change",
      "page.",
      "discussions",
      "conversations",
      "relevant",
      "history",
      "changes",
      "required.",
      "save",
      "toolbar.",
      "sections",
      "field",
      "display",
      "label",
      "company",
      "owns",
      "service",
      "ignore",
      "functional",
      "release.",
      "type",
      "available",
      "options",
      "development",
      "non",
      "production",
      "staging",
      "test",
      "trial.",
      "deployment",
      "model",
      "premise",
      "public",
      "cloud",
      "private",
      "cloud.",
      "thise",
      "section",
      "displays",
      "version",
      "instance",
      "select",
      "instance.",
      "version.",
      "versions.",
      "clicking",
      "anwhere",
      "except",
      "gray.",
      "ok.",
      "ok",
      "dialog",
      "box.",
      "updated",
      "selected"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "View or edit product instance",
    "content": "This page explains how to view or edit a product instance record. View or edit product instance Click > Plan > Company.In the Companies dropdown, click Product Instances.Click the ID of the product instance. The product instance record contains the following tabs: Tab Description General View product instance details. For more information, see the \"General tab\" section. Workflow View the workflow and current phase of the product instance. The current phase of the product instance is highlighted in blue in the workflow. For information on the product instance workflow and the procedure to change the phase, see the Product instance workflow page. Related records This tab is available only for instances where the product model is of type Bundle. When you create an instance record for a Bundle, a product instance is also created for each product included in the bundle. The Related records tab displays all product instances related to the bundle instance. Discussions View conversations rele",
    "url": "vieworeditproductinstance",
    "filename": "vieworeditproductinstance",
    "headings": [
      "View or edit product instance",
      "General tab",
      "Product instance details",
      "User options"
    ],
    "keywords": [
      "Company.In",
      "edit.Edit",
      "view",
      "edit",
      "product",
      "instance",
      "general",
      "tab",
      "details",
      "user",
      "options",
      "page",
      "explains",
      "record.",
      "click",
      "plan",
      "companies",
      "dropdown",
      "instances.click",
      "id",
      "instance.",
      "record",
      "contains",
      "following",
      "tabs",
      "description",
      "details.",
      "information",
      "see",
      "section.",
      "workflow",
      "current",
      "phase",
      "highlighted",
      "blue",
      "workflow.",
      "procedure",
      "change",
      "page.",
      "related",
      "records",
      "available",
      "instances",
      "model",
      "type",
      "bundle.",
      "create",
      "bundle",
      "created",
      "included",
      "displays",
      "all",
      "discussions",
      "conversations",
      "relevant",
      "history",
      "changes",
      "want",
      "required.click",
      "save",
      "toolbar.",
      "sections",
      "detailsuser",
      "field",
      "display",
      "label",
      "models",
      "active",
      "appear",
      "dropdown.",
      "section",
      "version",
      "versions",
      "company",
      "purchased",
      "name",
      "name.",
      "auto-filled",
      "based",
      "model.",
      "environment",
      "deployed.",
      "start",
      "date",
      "started",
      "end",
      "stopped",
      "quantity",
      "number",
      "instances.",
      "serial",
      "contract",
      "associated",
      "appears",
      "there",
      "any",
      "custom",
      "fields",
      "defined",
      "specified"
    ],
    "language": "en",
    "word_count": 103,
    "importance_score": 5.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "view or edit product instance",
    "contentLower": "this page explains how to view or edit a product instance record. view or edit product instance click > plan > company.in the companies dropdown, click product instances.click the id of the product instance. the product instance record contains the following tabs: tab description general view product instance details. for more information, see the \"general tab\" section. workflow view the workflow and current phase of the product instance. the current phase of the product instance is highlighted in blue in the workflow. for information on the product instance workflow and the procedure to change the phase, see the product instance workflow page. related records this tab is available only for instances where the product model is of type bundle. when you create an instance record for a bundle, a product instance is also created for each product included in the bundle. the related records tab displays all product instances related to the bundle instance. discussions view conversations rele",
    "keywordsLower": [
      "company.in",
      "edit.edit",
      "view",
      "edit",
      "product",
      "instance",
      "general",
      "tab",
      "details",
      "user",
      "options",
      "page",
      "explains",
      "record.",
      "click",
      "plan",
      "companies",
      "dropdown",
      "instances.click",
      "id",
      "instance.",
      "record",
      "contains",
      "following",
      "tabs",
      "description",
      "details.",
      "information",
      "see",
      "section.",
      "workflow",
      "current",
      "phase",
      "highlighted",
      "blue",
      "workflow.",
      "procedure",
      "change",
      "page.",
      "related",
      "records",
      "available",
      "instances",
      "model",
      "type",
      "bundle.",
      "create",
      "bundle",
      "created",
      "included",
      "displays",
      "all",
      "discussions",
      "conversations",
      "relevant",
      "history",
      "changes",
      "want",
      "required.click",
      "save",
      "toolbar.",
      "sections",
      "detailsuser",
      "field",
      "display",
      "label",
      "models",
      "active",
      "appear",
      "dropdown.",
      "section",
      "version",
      "versions",
      "company",
      "purchased",
      "name",
      "name.",
      "auto-filled",
      "based",
      "model.",
      "environment",
      "deployed.",
      "start",
      "date",
      "started",
      "end",
      "stopped",
      "quantity",
      "number",
      "instances.",
      "serial",
      "contract",
      "associated",
      "appears",
      "there",
      "any",
      "custom",
      "fields",
      "defined",
      "specified"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "View or edit entitlement",
    "content": "This page explains how to view or edit an entitlement record. View or edit entitlement Click > Plan > Company. In the Companies dropdown, click Entitlements.Click the ID of the entitlement you want to view or edit. The entitlement record contains the following tabs: Tab Description General View and edit entitlement details, manage product instances covered under the entitlement, and add or remove delegated companies. For more information, see the \"General tab\" section. Workflow View the workflow and current phase of the entitlement. The current phase of the product model is highlighted in blue in the workflow. For information on the entitlement workflow and the procedure to change the phase, see the Entitlement workflow page. Entitled users Grant or remove user permissions for viewing or creating requests and viewing knowledge articles. For more information, see the \"Entitled users tab\" section. Discussions View conversations relevant to the entitlement. For more information, see the D",
    "url": "vieworeditentitlement",
    "filename": "vieworeditentitlement",
    "headings": [
      "View or edit entitlement",
      "General tab",
      "Entitlement details",
      "Product instances",
      "Add product instance to entitlement",
      "Remove product instance from entitlement",
      "Delegated companies",
      "Add delegated company to entitlement",
      "Remove delegated company from entitlement",
      "Entitled users tab",
      "Grant users from owner company permission to view requests and knowledge articles",
      "Grant users from delegated company permission to view requests and knowledge articles",
      "Grant users from owner company permission to create and update requests",
      "Grant users from delegated company permission to create and update requests",
      "Remove permission for user to view requests and knowledge articles",
      "Remove permission for user to create and update requests",
      "Configure how owner and delegated users interact with requests"
    ],
    "keywords": [
      "edit.Edit",
      "view",
      "edit",
      "entitlement",
      "general",
      "tab",
      "details",
      "product",
      "instances",
      "add",
      "instance",
      "remove",
      "delegated",
      "companies",
      "company",
      "entitled",
      "users",
      "grant",
      "owner",
      "permission",
      "requests",
      "knowledge",
      "articles",
      "create",
      "update",
      "user",
      "configure",
      "interact",
      "page",
      "explains",
      "record.",
      "click",
      "plan",
      "company.",
      "dropdown",
      "entitlements.click",
      "id",
      "want",
      "edit.",
      "record",
      "contains",
      "following",
      "tabs",
      "description",
      "manage",
      "covered",
      "under",
      "companies.",
      "information",
      "see",
      "section.",
      "workflow",
      "current",
      "phase",
      "entitlement.",
      "model",
      "highlighted",
      "blue",
      "workflow.",
      "procedure",
      "change",
      "page.",
      "permissions",
      "viewing",
      "creating",
      "articles.",
      "discussions",
      "conversations",
      "relevant",
      "history",
      "changes",
      "required.click",
      "save",
      "toolbar.",
      "sections",
      "detailsproduct",
      "instancesdelegated",
      "field",
      "display",
      "label",
      "type",
      "type.",
      "currently",
      "one",
      "option",
      "product.",
      "grants",
      "raise",
      "owns",
      "contract",
      "associated",
      "section",
      "add.",
      "displays",
      "all",
      "purchased",
      "entitlement.select",
      "entitlement.click",
      "ok.click",
      "adds"
    ],
    "language": "en",
    "word_count": 100,
    "importance_score": 6.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "view or edit entitlement",
    "contentLower": "this page explains how to view or edit an entitlement record. view or edit entitlement click > plan > company. in the companies dropdown, click entitlements.click the id of the entitlement you want to view or edit. the entitlement record contains the following tabs: tab description general view and edit entitlement details, manage product instances covered under the entitlement, and add or remove delegated companies. for more information, see the \"general tab\" section. workflow view the workflow and current phase of the entitlement. the current phase of the product model is highlighted in blue in the workflow. for information on the entitlement workflow and the procedure to change the phase, see the entitlement workflow page. entitled users grant or remove user permissions for viewing or creating requests and viewing knowledge articles. for more information, see the \"entitled users tab\" section. discussions view conversations relevant to the entitlement. for more information, see the d",
    "keywordsLower": [
      "edit.edit",
      "view",
      "edit",
      "entitlement",
      "general",
      "tab",
      "details",
      "product",
      "instances",
      "add",
      "instance",
      "remove",
      "delegated",
      "companies",
      "company",
      "entitled",
      "users",
      "grant",
      "owner",
      "permission",
      "requests",
      "knowledge",
      "articles",
      "create",
      "update",
      "user",
      "configure",
      "interact",
      "page",
      "explains",
      "record.",
      "click",
      "plan",
      "company.",
      "dropdown",
      "entitlements.click",
      "id",
      "want",
      "edit.",
      "record",
      "contains",
      "following",
      "tabs",
      "description",
      "manage",
      "covered",
      "under",
      "companies.",
      "information",
      "see",
      "section.",
      "workflow",
      "current",
      "phase",
      "entitlement.",
      "model",
      "highlighted",
      "blue",
      "workflow.",
      "procedure",
      "change",
      "page.",
      "permissions",
      "viewing",
      "creating",
      "articles.",
      "discussions",
      "conversations",
      "relevant",
      "history",
      "changes",
      "required.click",
      "save",
      "toolbar.",
      "sections",
      "detailsproduct",
      "instancesdelegated",
      "field",
      "display",
      "label",
      "type",
      "type.",
      "currently",
      "one",
      "option",
      "product.",
      "grants",
      "raise",
      "owns",
      "contract",
      "associated",
      "section",
      "add.",
      "displays",
      "all",
      "purchased",
      "entitlement.select",
      "entitlement.click",
      "ok.click",
      "adds"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "View or edit sold license",
    "content": "This page explains how to view or edit a sold license record. View or edit sold license Click > Plan > Company. In the Companies dropdown, click Licenses. Locate the license you want to view or edit.  To filter the record list, click the Add filter button. For more information, see Filters. Click the ID of the license. The license record has the following tabs. Tab Description General Displays overview and details of the license. For more information, see the General section on this page. Workflow Displays the workflow metaphase and phase of the license. For more information, see the License workflow page. License Keys Displays details of any software keys which validates or activates the use of the software. For more information, see the License Keys section on this page. Finance Displays information about acquisition and connection to fixed assets, as well as expense lines. For more information, see the Finance section on this page. Discussions Displays any relevant conversations abo",
    "url": "vieworeditlicense",
    "filename": "vieworeditlicense",
    "headings": [
      "View or edit sold license",
      "General",
      "Overview",
      "Details",
      "Maintenance",
      "User list",
      "Machine details",
      "Covered product models",
      "Attachments",
      "License keys",
      "Finance",
      "Acquisition",
      "Expense lines"
    ],
    "keywords": [
      "view",
      "edit",
      "sold",
      "license",
      "general",
      "overview",
      "details",
      "maintenance",
      "user",
      "list",
      "machine",
      "covered",
      "product",
      "models",
      "attachments",
      "keys",
      "finance",
      "acquisition",
      "expense",
      "lines",
      "page",
      "explains",
      "record.",
      "click",
      "plan",
      "company.",
      "companies",
      "dropdown",
      "licenses.",
      "locate",
      "want",
      "edit.",
      "filter",
      "record",
      "add",
      "button.",
      "information",
      "see",
      "filters.",
      "id",
      "license.",
      "following",
      "tabs.",
      "tab",
      "description",
      "displays",
      "section",
      "page.",
      "workflow",
      "metaphase",
      "phase",
      "any",
      "software",
      "validates",
      "activates",
      "software.",
      "about",
      "connection",
      "fixed",
      "assets",
      "well",
      "lines.",
      "discussions",
      "relevant",
      "conversations",
      "history",
      "changes",
      "view.",
      "required.",
      "save",
      "toolbar",
      "changes.",
      "sections",
      "field",
      "display",
      "label",
      "class",
      "classification",
      "set",
      "default",
      "licenses",
      "added",
      "company",
      "management",
      "module.",
      "consumer",
      "purchased",
      "publisher",
      "publisher.",
      "owner",
      "person",
      "manages",
      "monitors",
      "quantity",
      "number",
      "unit",
      "rights",
      "authorized",
      "included",
      "one"
    ],
    "language": "en",
    "word_count": 105,
    "importance_score": 6.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "view or edit sold license",
    "contentLower": "this page explains how to view or edit a sold license record. view or edit sold license click > plan > company. in the companies dropdown, click licenses. locate the license you want to view or edit.  to filter the record list, click the add filter button. for more information, see filters. click the id of the license. the license record has the following tabs. tab description general displays overview and details of the license. for more information, see the general section on this page. workflow displays the workflow metaphase and phase of the license. for more information, see the license workflow page. license keys displays details of any software keys which validates or activates the use of the software. for more information, see the license keys section on this page. finance displays information about acquisition and connection to fixed assets, as well as expense lines. for more information, see the finance section on this page. discussions displays any relevant conversations abo",
    "keywordsLower": [
      "view",
      "edit",
      "sold",
      "license",
      "general",
      "overview",
      "details",
      "maintenance",
      "user",
      "list",
      "machine",
      "covered",
      "product",
      "models",
      "attachments",
      "keys",
      "finance",
      "acquisition",
      "expense",
      "lines",
      "page",
      "explains",
      "record.",
      "click",
      "plan",
      "company.",
      "companies",
      "dropdown",
      "licenses.",
      "locate",
      "want",
      "edit.",
      "filter",
      "record",
      "add",
      "button.",
      "information",
      "see",
      "filters.",
      "id",
      "license.",
      "following",
      "tabs.",
      "tab",
      "description",
      "displays",
      "section",
      "page.",
      "workflow",
      "metaphase",
      "phase",
      "any",
      "software",
      "validates",
      "activates",
      "software.",
      "about",
      "connection",
      "fixed",
      "assets",
      "well",
      "lines.",
      "discussions",
      "relevant",
      "conversations",
      "history",
      "changes",
      "view.",
      "required.",
      "save",
      "toolbar",
      "changes.",
      "sections",
      "field",
      "display",
      "label",
      "class",
      "classification",
      "set",
      "default",
      "licenses",
      "added",
      "company",
      "management",
      "module.",
      "consumer",
      "purchased",
      "publisher",
      "publisher.",
      "owner",
      "person",
      "manages",
      "monitors",
      "quantity",
      "number",
      "unit",
      "rights",
      "authorized",
      "included",
      "one"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "View the Change Calendar",
    "content": "From the main menu, select Build > Change > Calendar. The Change Calendar is displayed. The calendar can display a maximum of 100 change records. If the filter selection is 100 or more change records, a warning icon is displayed, with an informative tooltip message. The default display is 30 change records. To display more change records, click Show more at the bottom of the records list. This displays up to 60 change records, and if clicked again, shows up to 100 change records. To return to the default display, click F5, or reset the filter selection. To maximize calendar performance, refine the filter selection to display fewer change records. The default display is in order of scheduled start, with the first at the top. For information about filtering changes in the calendar, see How to filter records in the Change Calendar. Change Calendar User Interface (UI) The Change Calendar has the following UI elements: Left pane The left pane displays a list of changes, each showing a risk ",
    "url": "cmviewchangecalendar",
    "filename": "cmviewchangecalendar",
    "headings": [
      "Change Calendar User Interface (UI)",
      "Left pane",
      "Main pane",
      "Right pane",
      "Footer",
      "Leaving the Change Calendar",
      "Related topics"
    ],
    "keywords": [
      "view",
      "change",
      "calendar",
      "user",
      "interface",
      "ui",
      "left",
      "pane",
      "main",
      "right",
      "footer",
      "leaving",
      "related",
      "topics",
      "menu",
      "select",
      "build",
      "calendar.",
      "displayed.",
      "display",
      "maximum",
      "100",
      "records.",
      "filter",
      "selection",
      "records",
      "warning",
      "icon",
      "displayed",
      "informative",
      "tooltip",
      "message.",
      "default",
      "30",
      "click",
      "show",
      "bottom",
      "list.",
      "displays",
      "60",
      "clicked",
      "again",
      "shows",
      "return",
      "f5",
      "reset",
      "selection.",
      "maximize",
      "performance",
      "refine",
      "fewer",
      "order",
      "scheduled",
      "start",
      "first",
      "top.",
      "information",
      "about",
      "filtering",
      "changes",
      "see",
      "following",
      "elements",
      "list",
      "showing",
      "risk",
      "record",
      "id",
      "title.",
      "there",
      "icons",
      "reflect",
      "various",
      "statuses.",
      "sort",
      "drop-down",
      "button",
      "toolbar",
      "choose",
      "appear.",
      "point",
      "explaining",
      "meaning.",
      "example",
      "schedule",
      "occur",
      "outside",
      "maintenance",
      "time",
      "period",
      "window",
      "inside",
      "blackout",
      "isn",
      "yet",
      "approved.",
      "deal",
      "breaches",
      "scheduling",
      "standards."
    ],
    "language": "en",
    "word_count": 106,
    "importance_score": 6.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "view the change calendar",
    "contentLower": "from the main menu, select build > change > calendar. the change calendar is displayed. the calendar can display a maximum of 100 change records. if the filter selection is 100 or more change records, a warning icon is displayed, with an informative tooltip message. the default display is 30 change records. to display more change records, click show more at the bottom of the records list. this displays up to 60 change records, and if clicked again, shows up to 100 change records. to return to the default display, click f5, or reset the filter selection. to maximize calendar performance, refine the filter selection to display fewer change records. the default display is in order of scheduled start, with the first at the top. for information about filtering changes in the calendar, see how to filter records in the change calendar. change calendar user interface (ui) the change calendar has the following ui elements: left pane the left pane displays a list of changes, each showing a risk ",
    "keywordsLower": [
      "view",
      "change",
      "calendar",
      "user",
      "interface",
      "ui",
      "left",
      "pane",
      "main",
      "right",
      "footer",
      "leaving",
      "related",
      "topics",
      "menu",
      "select",
      "build",
      "calendar.",
      "displayed.",
      "display",
      "maximum",
      "100",
      "records.",
      "filter",
      "selection",
      "records",
      "warning",
      "icon",
      "displayed",
      "informative",
      "tooltip",
      "message.",
      "default",
      "30",
      "click",
      "show",
      "bottom",
      "list.",
      "displays",
      "60",
      "clicked",
      "again",
      "shows",
      "return",
      "f5",
      "reset",
      "selection.",
      "maximize",
      "performance",
      "refine",
      "fewer",
      "order",
      "scheduled",
      "start",
      "first",
      "top.",
      "information",
      "about",
      "filtering",
      "changes",
      "see",
      "following",
      "elements",
      "list",
      "showing",
      "risk",
      "record",
      "id",
      "title.",
      "there",
      "icons",
      "reflect",
      "various",
      "statuses.",
      "sort",
      "drop-down",
      "button",
      "toolbar",
      "choose",
      "appear.",
      "point",
      "explaining",
      "meaning.",
      "example",
      "schedule",
      "occur",
      "outside",
      "maintenance",
      "time",
      "period",
      "window",
      "inside",
      "blackout",
      "isn",
      "yet",
      "approved.",
      "deal",
      "breaches",
      "scheduling",
      "standards."
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "UCMDB Gateway",
    "content": "UCMDB Gateway consists of new high-performance APIs based on the GraphQL technology, see https://graphql.org/learn/. It allows dynamic, high-performance, and highly-backward-compatible API calls into more than one system to merge the responses in one JSON payload. UCMDB Gateway exposes APIs per CI type which are then used by Service Management to federate CI data from UCMDB into the Service Management UI. The following APIs are currently exposed: Node API: for all Node CIs from UCMDB Service API: for Service CI Type Services from UCMDB BusinessApplication API: for CIs of type business application from UCMDB InfrastructureElement API: for CIs of type Infrastructure Element from UCMDB The UCMDB Gateway is also responsible for notifying Service Management about CI changes in UD/UCMDB. Every attribute change in UCMDB is validated against a list of attributes Service Management is federating. When one of these attributes changes on the UCMDB side, Service Management gets notified to trigger",
    "url": "cmsapigateway",
    "filename": "cmsapigateway",
    "headings": [
      "Architecture",
      "Related topics"
    ],
    "keywords": [
      "graphql.org",
      "https://graphql.org/learn",
      "ucmdb",
      "gateway",
      "architecture",
      "related",
      "topics",
      "consists",
      "new",
      "high-performance",
      "apis",
      "based",
      "graphql",
      "technology",
      "see",
      "https",
      "learn",
      "allows",
      "dynamic",
      "highly-backward-compatible",
      "api",
      "calls",
      "one",
      "system",
      "merge",
      "responses",
      "json",
      "payload.",
      "exposes",
      "per",
      "ci",
      "type",
      "service",
      "management",
      "federate",
      "data",
      "ui.",
      "following",
      "currently",
      "exposed",
      "node",
      "all",
      "cis",
      "services",
      "businessapplication",
      "business",
      "application",
      "infrastructureelement",
      "infrastructure",
      "element",
      "responsible",
      "notifying",
      "about",
      "changes",
      "ud",
      "ucmdb.",
      "every",
      "attribute",
      "change",
      "validated",
      "against",
      "list",
      "attributes",
      "federating.",
      "side",
      "gets",
      "notified",
      "trigger",
      "configured",
      "actions",
      "like",
      "workflow",
      "rules",
      "document",
      "history.",
      "high-level",
      "federation",
      "follows",
      "placed",
      "between",
      "server.",
      "ui",
      "requests",
      "such",
      "showing",
      "filtering",
      "grouping",
      "sorting",
      "result",
      "corresponding",
      "fetch",
      "simultaneously.",
      "whenever",
      "modified",
      "directly",
      "subscription",
      "feature",
      "knows",
      "federated",
      "management."
    ],
    "language": "en",
    "word_count": 107,
    "importance_score": 4.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "ucmdb gateway",
    "contentLower": "ucmdb gateway consists of new high-performance apis based on the graphql technology, see https://graphql.org/learn/. it allows dynamic, high-performance, and highly-backward-compatible api calls into more than one system to merge the responses in one json payload. ucmdb gateway exposes apis per ci type which are then used by service management to federate ci data from ucmdb into the service management ui. the following apis are currently exposed: node api: for all node cis from ucmdb service api: for service ci type services from ucmdb businessapplication api: for cis of type business application from ucmdb infrastructureelement api: for cis of type infrastructure element from ucmdb the ucmdb gateway is also responsible for notifying service management about ci changes in ud/ucmdb. every attribute change in ucmdb is validated against a list of attributes service management is federating. when one of these attributes changes on the ucmdb side, service management gets notified to trigger",
    "keywordsLower": [
      "graphql.org",
      "https://graphql.org/learn",
      "ucmdb",
      "gateway",
      "architecture",
      "related",
      "topics",
      "consists",
      "new",
      "high-performance",
      "apis",
      "based",
      "graphql",
      "technology",
      "see",
      "https",
      "learn",
      "allows",
      "dynamic",
      "highly-backward-compatible",
      "api",
      "calls",
      "one",
      "system",
      "merge",
      "responses",
      "json",
      "payload.",
      "exposes",
      "per",
      "ci",
      "type",
      "service",
      "management",
      "federate",
      "data",
      "ui.",
      "following",
      "currently",
      "exposed",
      "node",
      "all",
      "cis",
      "services",
      "businessapplication",
      "business",
      "application",
      "infrastructureelement",
      "infrastructure",
      "element",
      "responsible",
      "notifying",
      "about",
      "changes",
      "ud",
      "ucmdb.",
      "every",
      "attribute",
      "change",
      "validated",
      "against",
      "list",
      "attributes",
      "federating.",
      "side",
      "gets",
      "notified",
      "trigger",
      "configured",
      "actions",
      "like",
      "workflow",
      "rules",
      "document",
      "history.",
      "high-level",
      "federation",
      "follows",
      "placed",
      "between",
      "server.",
      "ui",
      "requests",
      "such",
      "showing",
      "filtering",
      "grouping",
      "sorting",
      "result",
      "corresponding",
      "fetch",
      "simultaneously.",
      "whenever",
      "modified",
      "directly",
      "subscription",
      "feature",
      "knows",
      "federated",
      "management."
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "View the impact map of a device",
    "content": "From the main menu, select Build > Service Asset & Configuration. From SACM Home, select Devices. Select the device. To filter the record list, click the Add filter button. For more information, see Filters. Click Show Impact . An impact map of the device is displayed. You can zoom in and out of the impact map by using the mouse wheel button. Note: Data domain segmentation also applies to the impact map. That is, if the currently logged-in user doesn't have access to some impacted records' data domains, these records aren't available on the impact map. If Native SACM is disabled If Native SACM is disabled, the Show Impact widget displays the traditional view of the records impacted by the selected record, as defined in SMA. If a text string is too long to be displayed, an ellipsis (…) appears. You can hover over the ellipsis to display the full text string. You can hover over the following icons in the impact map: Owner avatar – a window is displayed with the owner’s details. Business ",
    "url": "viewdevicetplgy",
    "filename": "viewdevicetplgy",
    "headings": [
      "If Native SACM is disabled",
      "If Native SACM is enabled",
      "Related topics"
    ],
    "keywords": [
      "view",
      "impact",
      "map",
      "device",
      "native",
      "sacm",
      "disabled",
      "enabled",
      "related",
      "topics",
      "main",
      "menu",
      "select",
      "build",
      "service",
      "asset",
      "configuration.",
      "home",
      "devices.",
      "device.",
      "filter",
      "record",
      "list",
      "click",
      "add",
      "button.",
      "information",
      "see",
      "filters.",
      "show",
      "displayed.",
      "zoom",
      "out",
      "mouse",
      "wheel",
      "note",
      "data",
      "domain",
      "segmentation",
      "applies",
      "map.",
      "currently",
      "logged-in",
      "user",
      "doesn",
      "access",
      "impacted",
      "records",
      "domains",
      "aren",
      "available",
      "widget",
      "displays",
      "traditional",
      "selected",
      "defined",
      "sma.",
      "text",
      "string",
      "too",
      "long",
      "displayed",
      "ellipsis",
      "appears.",
      "hover",
      "over",
      "display",
      "full",
      "string.",
      "following",
      "icons",
      "owner",
      "avatar",
      "window",
      "details.",
      "business",
      "criticality",
      "tooltip",
      "criticality.",
      "location",
      "name",
      "location.",
      "depending",
      "size",
      "browser",
      "management",
      "subtype",
      "system",
      "element.",
      "graphic",
      "information.",
      "shows",
      "cis",
      "record.",
      "topology",
      "federated",
      "ucmdb",
      "similar",
      "one",
      "described"
    ],
    "language": "en",
    "word_count": 110,
    "importance_score": 3.5,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "view the impact map of a device",
    "contentLower": "from the main menu, select build > service asset & configuration. from sacm home, select devices. select the device. to filter the record list, click the add filter button. for more information, see filters. click show impact . an impact map of the device is displayed. you can zoom in and out of the impact map by using the mouse wheel button. note: data domain segmentation also applies to the impact map. that is, if the currently logged-in user doesn't have access to some impacted records' data domains, these records aren't available on the impact map. if native sacm is disabled if native sacm is disabled, the show impact widget displays the traditional view of the records impacted by the selected record, as defined in sma. if a text string is too long to be displayed, an ellipsis (…) appears. you can hover over the ellipsis to display the full text string. you can hover over the following icons in the impact map: owner avatar – a window is displayed with the owner’s details. business ",
    "keywordsLower": [
      "view",
      "impact",
      "map",
      "device",
      "native",
      "sacm",
      "disabled",
      "enabled",
      "related",
      "topics",
      "main",
      "menu",
      "select",
      "build",
      "service",
      "asset",
      "configuration.",
      "home",
      "devices.",
      "device.",
      "filter",
      "record",
      "list",
      "click",
      "add",
      "button.",
      "information",
      "see",
      "filters.",
      "show",
      "displayed.",
      "zoom",
      "out",
      "mouse",
      "wheel",
      "note",
      "data",
      "domain",
      "segmentation",
      "applies",
      "map.",
      "currently",
      "logged-in",
      "user",
      "doesn",
      "access",
      "impacted",
      "records",
      "domains",
      "aren",
      "available",
      "widget",
      "displays",
      "traditional",
      "selected",
      "defined",
      "sma.",
      "text",
      "string",
      "too",
      "long",
      "displayed",
      "ellipsis",
      "appears.",
      "hover",
      "over",
      "display",
      "full",
      "string.",
      "following",
      "icons",
      "owner",
      "avatar",
      "window",
      "details.",
      "business",
      "criticality",
      "tooltip",
      "criticality.",
      "location",
      "name",
      "location.",
      "depending",
      "size",
      "browser",
      "management",
      "subtype",
      "system",
      "element.",
      "graphic",
      "information.",
      "shows",
      "cis",
      "record.",
      "topology",
      "federated",
      "ucmdb",
      "similar",
      "one",
      "described"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "View the impact map of a system element",
    "content": "From the main menu, select Build > Service Asset & Configuration. From SACM Home, select System Elements. Select the system element. To filter the record list, click the Add filter button. For more information, see Filters. Click Show Impact . An impact map of the system element is displayed. Note: Data domain segmentation also applies to the impact map. That is, if the currently logged-in user doesn't have access to some impacted records' data domains, these records aren't available on the impact map. If Native SACM is disabled If Native SACM is disabled, the Show Impact widget displays the traditional view of the records impacted by the selected record, as defined in SMA. If a text string is too long to be displayed, an ellipsis (…) appears. You can hover over the ellipsis to display the full text string. You can hover over the following icons in the impact map: Owner avatar – a window is displayed with the owner’s details. Business criticality – a tooltip is displayed with the criti",
    "url": "viewsyselementtplgy",
    "filename": "viewsyselementtplgy",
    "headings": [
      "If Native SACM is disabled",
      "If Native SACM is enabled",
      "Related topics"
    ],
    "keywords": [
      "view",
      "impact",
      "map",
      "system",
      "element",
      "native",
      "sacm",
      "disabled",
      "enabled",
      "related",
      "topics",
      "main",
      "menu",
      "select",
      "build",
      "service",
      "asset",
      "configuration.",
      "home",
      "elements.",
      "element.",
      "filter",
      "record",
      "list",
      "click",
      "add",
      "button.",
      "information",
      "see",
      "filters.",
      "show",
      "displayed.",
      "note",
      "data",
      "domain",
      "segmentation",
      "applies",
      "map.",
      "currently",
      "logged-in",
      "user",
      "doesn",
      "access",
      "impacted",
      "records",
      "domains",
      "aren",
      "available",
      "widget",
      "displays",
      "traditional",
      "selected",
      "defined",
      "sma.",
      "text",
      "string",
      "too",
      "long",
      "displayed",
      "ellipsis",
      "appears.",
      "hover",
      "over",
      "display",
      "full",
      "string.",
      "following",
      "icons",
      "owner",
      "avatar",
      "window",
      "details.",
      "business",
      "criticality",
      "tooltip",
      "criticality.",
      "location",
      "name",
      "location.",
      "depending",
      "size",
      "browser",
      "management",
      "subtype",
      "device",
      "graphic",
      "information.",
      "shows",
      "cis",
      "record.",
      "topology",
      "federated",
      "ucmdb",
      "similar",
      "one",
      "described",
      "ci",
      "relationship",
      "federation.",
      "create"
    ],
    "language": "en",
    "word_count": 111,
    "importance_score": 3.5,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "view the impact map of a system element",
    "contentLower": "from the main menu, select build > service asset & configuration. from sacm home, select system elements. select the system element. to filter the record list, click the add filter button. for more information, see filters. click show impact . an impact map of the system element is displayed. note: data domain segmentation also applies to the impact map. that is, if the currently logged-in user doesn't have access to some impacted records' data domains, these records aren't available on the impact map. if native sacm is disabled if native sacm is disabled, the show impact widget displays the traditional view of the records impacted by the selected record, as defined in sma. if a text string is too long to be displayed, an ellipsis (…) appears. you can hover over the ellipsis to display the full text string. you can hover over the following icons in the impact map: owner avatar – a window is displayed with the owner’s details. business criticality – a tooltip is displayed with the criti",
    "keywordsLower": [
      "view",
      "impact",
      "map",
      "system",
      "element",
      "native",
      "sacm",
      "disabled",
      "enabled",
      "related",
      "topics",
      "main",
      "menu",
      "select",
      "build",
      "service",
      "asset",
      "configuration.",
      "home",
      "elements.",
      "element.",
      "filter",
      "record",
      "list",
      "click",
      "add",
      "button.",
      "information",
      "see",
      "filters.",
      "show",
      "displayed.",
      "note",
      "data",
      "domain",
      "segmentation",
      "applies",
      "map.",
      "currently",
      "logged-in",
      "user",
      "doesn",
      "access",
      "impacted",
      "records",
      "domains",
      "aren",
      "available",
      "widget",
      "displays",
      "traditional",
      "selected",
      "defined",
      "sma.",
      "text",
      "string",
      "too",
      "long",
      "displayed",
      "ellipsis",
      "appears.",
      "hover",
      "over",
      "display",
      "full",
      "string.",
      "following",
      "icons",
      "owner",
      "avatar",
      "window",
      "details.",
      "business",
      "criticality",
      "tooltip",
      "criticality.",
      "location",
      "name",
      "location.",
      "depending",
      "size",
      "browser",
      "management",
      "subtype",
      "device",
      "graphic",
      "information.",
      "shows",
      "cis",
      "record.",
      "topology",
      "federated",
      "ucmdb",
      "similar",
      "one",
      "described",
      "ci",
      "relationship",
      "federation.",
      "create"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "View asset model records",
    "content": "From the main menu, select Build > Service Asset and Configuration. From SACM Home, select Asset Models. There are two ways to view the SACM asset model records: tree view and table view. In the tree view: Click an asset model record to display the connected next lower level of asset model records. Continue to click each lower level of asset model record to drill down the levels of asset model. As you drill down, Service Management displays a navigation bar with a set of links. Click the appropriate link to go to the required asset model level. As you click an asset model record, Service Management displays a summary in the right pane. To go to the table view, click Table view. In the table view: As you click an asset model record, Service Management displays a summary in the right pane. To go to the tree view, click Tree view. For more information about views, see Views. Related topics Asset models How to create an asset model record How to edit an asset model record How to retire an ",
    "url": "viewassetmodels",
    "filename": "viewassetmodels",
    "headings": [
      "Related topics"
    ],
    "keywords": [
      "view",
      "asset",
      "model",
      "records",
      "related",
      "topics",
      "main",
      "menu",
      "select",
      "build",
      "service",
      "configuration.",
      "sacm",
      "home",
      "models.",
      "there",
      "two",
      "ways",
      "tree",
      "table",
      "view.",
      "click",
      "record",
      "display",
      "connected",
      "next",
      "lower",
      "level",
      "records.",
      "continue",
      "drill",
      "levels",
      "model.",
      "management",
      "displays",
      "navigation",
      "bar",
      "set",
      "links.",
      "appropriate",
      "link",
      "go",
      "required",
      "level.",
      "summary",
      "right",
      "pane.",
      "information",
      "about",
      "views",
      "see",
      "views.",
      "models",
      "create",
      "edit",
      "retire"
    ],
    "language": "en",
    "word_count": 121,
    "importance_score": 3.5,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "view asset model records",
    "contentLower": "from the main menu, select build > service asset and configuration. from sacm home, select asset models. there are two ways to view the sacm asset model records: tree view and table view. in the tree view: click an asset model record to display the connected next lower level of asset model records. continue to click each lower level of asset model record to drill down the levels of asset model. as you drill down, service management displays a navigation bar with a set of links. click the appropriate link to go to the required asset model level. as you click an asset model record, service management displays a summary in the right pane. to go to the table view, click table view. in the table view: as you click an asset model record, service management displays a summary in the right pane. to go to the tree view, click tree view. for more information about views, see views. related topics asset models how to create an asset model record how to edit an asset model record how to retire an ",
    "keywordsLower": [
      "view",
      "asset",
      "model",
      "records",
      "related",
      "topics",
      "main",
      "menu",
      "select",
      "build",
      "service",
      "configuration.",
      "sacm",
      "home",
      "models.",
      "there",
      "two",
      "ways",
      "tree",
      "table",
      "view.",
      "click",
      "record",
      "display",
      "connected",
      "next",
      "lower",
      "level",
      "records.",
      "continue",
      "drill",
      "levels",
      "model.",
      "management",
      "displays",
      "navigation",
      "bar",
      "set",
      "links.",
      "appropriate",
      "link",
      "go",
      "required",
      "level.",
      "summary",
      "right",
      "pane.",
      "information",
      "about",
      "views",
      "see",
      "views.",
      "models",
      "create",
      "edit",
      "retire"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Vendor catalogs",
    "content": "A vendor catalog is a list that consists of goods available from a supplier. You can add items to the vendor catalog. The catalog items can be published as an offering. You can create and manage a vendor catalog given that the right permission is granted. This section includes the following: Create and manage vendor catalogs Create and manage vendor catalog items Publish a vendor catalog item as offering",
    "url": "vendorcatalogshead",
    "filename": "vendorcatalogshead",
    "headings": [],
    "keywords": [
      "vendor",
      "catalogs",
      "catalog",
      "list",
      "consists",
      "goods",
      "available",
      "supplier.",
      "add",
      "items",
      "catalog.",
      "published",
      "offering.",
      "create",
      "manage",
      "given",
      "right",
      "permission",
      "granted.",
      "section",
      "includes",
      "following",
      "publish",
      "item",
      "offering"
    ],
    "language": "en",
    "word_count": 42,
    "importance_score": 2.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "vendor catalogs",
    "contentLower": "a vendor catalog is a list that consists of goods available from a supplier. you can add items to the vendor catalog. the catalog items can be published as an offering. you can create and manage a vendor catalog given that the right permission is granted. this section includes the following: create and manage vendor catalogs create and manage vendor catalog items publish a vendor catalog item as offering",
    "keywordsLower": [
      "vendor",
      "catalogs",
      "catalog",
      "list",
      "consists",
      "goods",
      "available",
      "supplier.",
      "add",
      "items",
      "catalog.",
      "published",
      "offering.",
      "create",
      "manage",
      "given",
      "right",
      "permission",
      "granted.",
      "section",
      "includes",
      "following",
      "publish",
      "item",
      "offering"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "View the caller's details in Live Support",
    "content": "Live Support can display details about a caller. To go to the Live Support page, select Run > Service Request > Live Support. To display caller's details: If the caller's name isn't automatically displayed in the PERSON box, you can find it in one of the following ways: Click the list icon to display a simple list of eligible values. When the list of values is long, you can type a few characters from the start of the caller's name into the search field to limit the results. Click the expanded list icon to display a list of eligible values in a record list format. Other field values appear in this view that are useful information. After finding the caller's name, select it to display the caller's location and contact details in MORE INFO. Related topics How to create a request in Live Support How to open an existing request in Live Support Keyboard shortcuts Live Support How to use the chat capability",
    "url": "viewcallerdetails",
    "filename": "viewcallerdetails",
    "headings": [
      "Related topics"
    ],
    "keywords": [
      "callers",
      "view",
      "caller",
      "details",
      "live",
      "support",
      "related",
      "topics",
      "display",
      "about",
      "caller.",
      "go",
      "page",
      "select",
      "run",
      "service",
      "request",
      "support.",
      "name",
      "isn",
      "automatically",
      "displayed",
      "person",
      "box",
      "find",
      "one",
      "following",
      "ways",
      "click",
      "list",
      "icon",
      "simple",
      "eligible",
      "values.",
      "values",
      "long",
      "type",
      "few",
      "characters",
      "start",
      "search",
      "field",
      "limit",
      "results.",
      "expanded",
      "record",
      "format.",
      "appear",
      "useful",
      "information.",
      "after",
      "finding",
      "location",
      "contact",
      "info.",
      "create",
      "open",
      "existing",
      "keyboard",
      "shortcuts",
      "chat",
      "capability"
    ],
    "language": "en",
    "word_count": 108,
    "importance_score": 2.5,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "view the caller's details in live support",
    "contentLower": "live support can display details about a caller. to go to the live support page, select run > service request > live support. to display caller's details: if the caller's name isn't automatically displayed in the person box, you can find it in one of the following ways: click the list icon to display a simple list of eligible values. when the list of values is long, you can type a few characters from the start of the caller's name into the search field to limit the results. click the expanded list icon to display a list of eligible values in a record list format. other field values appear in this view that are useful information. after finding the caller's name, select it to display the caller's location and contact details in more info. related topics how to create a request in live support how to open an existing request in live support keyboard shortcuts live support how to use the chat capability",
    "keywordsLower": [
      "callers",
      "view",
      "caller",
      "details",
      "live",
      "support",
      "related",
      "topics",
      "display",
      "about",
      "caller.",
      "go",
      "page",
      "select",
      "run",
      "service",
      "request",
      "support.",
      "name",
      "isn",
      "automatically",
      "displayed",
      "person",
      "box",
      "find",
      "one",
      "following",
      "ways",
      "click",
      "list",
      "icon",
      "simple",
      "eligible",
      "values.",
      "values",
      "long",
      "type",
      "few",
      "characters",
      "start",
      "search",
      "field",
      "limit",
      "results.",
      "expanded",
      "record",
      "format.",
      "appear",
      "useful",
      "information.",
      "after",
      "finding",
      "location",
      "contact",
      "info.",
      "create",
      "open",
      "existing",
      "keyboard",
      "shortcuts",
      "chat",
      "capability"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Use the chat capability",
    "content": "Service Request Management allows you to view and deal with chat requests from users. Note To view requests, from the main menu, select Run > Service Request > Requests. In the list view columns for requests, the following fields related to chat requests are available: Chat status Displays the current chat status. Chat last request time Displays the time of the last chat request, if any. To display a field in the record list, click Columns and then click the field and OK. For more information, see List view in Service Management user interface. To view chat requests: From the main menu, select Run > Service Request > Requests. Select the My Chat Requests view to display your pending chat requests. On selection, the Chat last request field is automatically added to the list view, and requests are sorted by this field, older requests first. If a Request is assigned to you or your group, when the requester starts a chat request or cancels a chat request from the Service Portal, the system",
    "url": "usechat",
    "filename": "usechat",
    "headings": [
      "Related topics"
    ],
    "keywords": [
      "chat",
      "capability",
      "related",
      "topics",
      "service",
      "request",
      "management",
      "allows",
      "view",
      "deal",
      "requests",
      "users.",
      "note",
      "main",
      "menu",
      "select",
      "run",
      "requests.",
      "list",
      "columns",
      "following",
      "fields",
      "available",
      "status",
      "displays",
      "current",
      "status.",
      "last",
      "time",
      "any.",
      "display",
      "field",
      "record",
      "click",
      "ok.",
      "information",
      "see",
      "user",
      "interface.",
      "pending",
      "selection",
      "automatically",
      "added",
      "sorted",
      "older",
      "first.",
      "assigned",
      "group",
      "requester",
      "starts",
      "cancels",
      "portal",
      "system",
      "refresh",
      "view.",
      "desk",
      "group.",
      "answer",
      "request.",
      "right",
      "panel",
      "open",
      "preview",
      "displayed",
      "there.",
      "necessary",
      "panel.",
      "toolbar",
      "live",
      "chat.",
      "support",
      "section.",
      "call.",
      "abandons",
      "example",
      "logging",
      "out",
      "closing",
      "browser",
      "before",
      "agent",
      "answers",
      "abandoned.",
      "dialog",
      "appears.",
      "type",
      "message",
      "press",
      "enter.",
      "doesn",
      "responded",
      "until",
      "send",
      "message.",
      "once",
      "sent",
      "changes",
      "none",
      "till",
      "end"
    ],
    "language": "en",
    "word_count": 110,
    "importance_score": 3.5,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "use the chat capability",
    "contentLower": "service request management allows you to view and deal with chat requests from users. note to view requests, from the main menu, select run > service request > requests. in the list view columns for requests, the following fields related to chat requests are available: chat status displays the current chat status. chat last request time displays the time of the last chat request, if any. to display a field in the record list, click columns and then click the field and ok. for more information, see list view in service management user interface. to view chat requests: from the main menu, select run > service request > requests. select the my chat requests view to display your pending chat requests. on selection, the chat last request field is automatically added to the list view, and requests are sorted by this field, older requests first. if a request is assigned to you or your group, when the requester starts a chat request or cancels a chat request from the service portal, the system",
    "keywordsLower": [
      "chat",
      "capability",
      "related",
      "topics",
      "service",
      "request",
      "management",
      "allows",
      "view",
      "deal",
      "requests",
      "users.",
      "note",
      "main",
      "menu",
      "select",
      "run",
      "requests.",
      "list",
      "columns",
      "following",
      "fields",
      "available",
      "status",
      "displays",
      "current",
      "status.",
      "last",
      "time",
      "any.",
      "display",
      "field",
      "record",
      "click",
      "ok.",
      "information",
      "see",
      "user",
      "interface.",
      "pending",
      "selection",
      "automatically",
      "added",
      "sorted",
      "older",
      "first.",
      "assigned",
      "group",
      "requester",
      "starts",
      "cancels",
      "portal",
      "system",
      "refresh",
      "view.",
      "desk",
      "group.",
      "answer",
      "request.",
      "right",
      "panel",
      "open",
      "preview",
      "displayed",
      "there.",
      "necessary",
      "panel.",
      "toolbar",
      "live",
      "chat.",
      "support",
      "section.",
      "call.",
      "abandons",
      "example",
      "logging",
      "out",
      "closing",
      "browser",
      "before",
      "agent",
      "answers",
      "abandoned.",
      "dialog",
      "appears.",
      "type",
      "message",
      "press",
      "enter.",
      "doesn",
      "responded",
      "until",
      "send",
      "message.",
      "once",
      "sent",
      "changes",
      "none",
      "till",
      "end"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "View and follow a public request",
    "content": "This section describes the different methods to view and follow a public request in the Service Portal. Note Public requests are visible for thirty days from the time they're closed. Request list Click the portal menu at the top right of the page Click Requests. Click Public to display public requests. Click Following to display requests you are following. Search Enter the details in the search box, and press Return. Select the appropriate item from the results, and click the link. The details are displayed. Click the Follow button to follow the request. You can see this button only on public requests. Virtual agent support Click Request Support. Enter the details, and click Post. When the system finds a relevant public request, it's displayed as a possible solution. Related topics How to create a public request in the Service Portal How public requests interact with other Service Management features How to set up public requests",
    "url": "publicrequestsview",
    "filename": "publicrequestsview",
    "headings": [
      "Request list",
      "Search",
      "Virtual agent support",
      "Related topics"
    ],
    "keywords": [
      "view",
      "follow",
      "public",
      "request",
      "list",
      "search",
      "virtual",
      "agent",
      "support",
      "related",
      "topics",
      "section",
      "describes",
      "different",
      "methods",
      "service",
      "portal.",
      "note",
      "requests",
      "visible",
      "thirty",
      "days",
      "time",
      "re",
      "closed.",
      "click",
      "portal",
      "menu",
      "top",
      "right",
      "page",
      "requests.",
      "display",
      "following",
      "following.",
      "enter",
      "details",
      "box",
      "press",
      "return.",
      "select",
      "appropriate",
      "item",
      "results",
      "link.",
      "displayed.",
      "button",
      "request.",
      "see",
      "support.",
      "post.",
      "system",
      "finds",
      "relevant",
      "displayed",
      "possible",
      "solution.",
      "create",
      "interact",
      "management",
      "features",
      "set"
    ],
    "language": "en",
    "word_count": 102,
    "importance_score": 4.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "view and follow a public request",
    "contentLower": "this section describes the different methods to view and follow a public request in the service portal. note public requests are visible for thirty days from the time they're closed. request list click the portal menu at the top right of the page click requests. click public to display public requests. click following to display requests you are following. search enter the details in the search box, and press return. select the appropriate item from the results, and click the link. the details are displayed. click the follow button to follow the request. you can see this button only on public requests. virtual agent support click request support. enter the details, and click post. when the system finds a relevant public request, it's displayed as a possible solution. related topics how to create a public request in the service portal how public requests interact with other service management features how to set up public requests",
    "keywordsLower": [
      "view",
      "follow",
      "public",
      "request",
      "list",
      "search",
      "virtual",
      "agent",
      "support",
      "related",
      "topics",
      "section",
      "describes",
      "different",
      "methods",
      "service",
      "portal.",
      "note",
      "requests",
      "visible",
      "thirty",
      "days",
      "time",
      "re",
      "closed.",
      "click",
      "portal",
      "menu",
      "top",
      "right",
      "page",
      "requests.",
      "display",
      "following",
      "following.",
      "enter",
      "details",
      "box",
      "press",
      "return.",
      "select",
      "appropriate",
      "item",
      "results",
      "link.",
      "displayed.",
      "button",
      "request.",
      "see",
      "support.",
      "post.",
      "system",
      "finds",
      "relevant",
      "displayed",
      "possible",
      "solution.",
      "create",
      "interact",
      "management",
      "features",
      "set"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "View current on-call status",
    "content": "The On-Call Schedule Management feature allows you to easily view the on-call shifts, working hours, and vacations of you, and any employees you manage. In addition, you can view the current on-call assignment of any group. To view the current on-call assignment of any group: From the Main menu, select Run > On-Call Schedule.Select the group. The right panel displays these sections: Current members who are on call. Note that if a member is on vacation, they still appear under On-call right now during the shift. This is a known limitation.Group members. To view your current on-call status: Click the avatar in the menu bar and then select User profile. The Profile & Preferences page is displayed. Do one of the following: Click Schedule in the main menu bar. Click View calendar at the top left of the page. Your schedule is displayed. To view the current on-call status of a group of which you are a member: Click the avatar in the menu bar and then select User profile. The Profile & Prefere",
    "url": "viewoncallstatus",
    "filename": "viewoncallstatus",
    "headings": [
      "To view the current on-call assignment of any group:",
      "To view your current on-call status:",
      "To view the current on-call status of a group of which you are a member:",
      "To view the current on-call status of an employee:",
      "Related topics"
    ],
    "keywords": [
      "view",
      "current",
      "on-call",
      "status",
      "assignment",
      "any",
      "group",
      "member",
      "employee",
      "related",
      "topics",
      "schedule",
      "management",
      "feature",
      "allows",
      "easily",
      "shifts",
      "working",
      "hours",
      "vacations",
      "employees",
      "manage.",
      "addition",
      "group.",
      "main",
      "menu",
      "select",
      "run",
      "schedule.select",
      "right",
      "panel",
      "displays",
      "sections",
      "members",
      "call.",
      "note",
      "vacation",
      "still",
      "appear",
      "under",
      "now",
      "during",
      "shift.",
      "known",
      "limitation.group",
      "members.",
      "click",
      "avatar",
      "bar",
      "user",
      "profile.",
      "profile",
      "preferences",
      "page",
      "displayed.",
      "one",
      "following",
      "bar.",
      "calendar",
      "top",
      "left",
      "page.",
      "displayed.select",
      "group.click",
      "icon.",
      "displayed.click",
      "icon",
      "employee.",
      "different",
      "link",
      "displayed",
      "viewing",
      "own",
      "schedule.",
      "display",
      "drop-down",
      "managementon-call",
      "interface"
    ],
    "language": "en",
    "word_count": 105,
    "importance_score": 5.5,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "view current on-call status",
    "contentLower": "the on-call schedule management feature allows you to easily view the on-call shifts, working hours, and vacations of you, and any employees you manage. in addition, you can view the current on-call assignment of any group. to view the current on-call assignment of any group: from the main menu, select run > on-call schedule.select the group. the right panel displays these sections: current members who are on call. note that if a member is on vacation, they still appear under on-call right now during the shift. this is a known limitation.group members. to view your current on-call status: click the avatar in the menu bar and then select user profile. the profile & preferences page is displayed. do one of the following: click schedule in the main menu bar. click view calendar at the top left of the page. your schedule is displayed. to view the current on-call status of a group of which you are a member: click the avatar in the menu bar and then select user profile. the profile & prefere",
    "keywordsLower": [
      "view",
      "current",
      "on-call",
      "status",
      "assignment",
      "any",
      "group",
      "member",
      "employee",
      "related",
      "topics",
      "schedule",
      "management",
      "feature",
      "allows",
      "easily",
      "shifts",
      "working",
      "hours",
      "vacations",
      "employees",
      "manage.",
      "addition",
      "group.",
      "main",
      "menu",
      "select",
      "run",
      "schedule.select",
      "right",
      "panel",
      "displays",
      "sections",
      "members",
      "call.",
      "note",
      "vacation",
      "still",
      "appear",
      "under",
      "now",
      "during",
      "shift.",
      "known",
      "limitation.group",
      "members.",
      "click",
      "avatar",
      "bar",
      "user",
      "profile.",
      "profile",
      "preferences",
      "page",
      "displayed.",
      "one",
      "following",
      "bar.",
      "calendar",
      "top",
      "left",
      "page.",
      "displayed.select",
      "group.click",
      "icon.",
      "displayed.click",
      "icon",
      "employee.",
      "different",
      "link",
      "displayed",
      "viewing",
      "own",
      "schedule.",
      "display",
      "drop-down",
      "managementon-call",
      "interface"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Use the SCCM Installed Software Integration job for SAM",
    "content": "This section describes how to use the SCCM Installed Software Integration job to create compliance reports based on the license consumption data managed by Microsoft System Center Configuration Manager (SCCM). Overview If you have deployed both SCCM and Universal Discovery (UD), you can use SCCM to collect data of desktops and installed software and UD to discover servers. SAM considers UCMDB as a trusted central inventory. The SCCM Installed Software Integration job can help import SCCM's inventory data into UCMDB. Then SAM generates compliance reports based on the data collected from the UCMDB database through UCMDB Gateway. Software Application Library (SAI) will normalize all the software applications discovered by SCCM. Workflow Run the SCCM Installed Software Integration job. For more information, see SCCM Installed Software Integration. Synchronize the product family. Note Because SCCM doesn't collect Oracle License Management Services (LMS) data from the managed devices, retrie",
    "url": "sccm4sam",
    "filename": "sccm4sam",
    "headings": [
      "Overview",
      "Workflow",
      "Related topics"
    ],
    "keywords": [
      "sccm",
      "installed",
      "software",
      "integration",
      "job",
      "sam",
      "overview",
      "workflow",
      "related",
      "topics",
      "section",
      "describes",
      "create",
      "compliance",
      "reports",
      "based",
      "license",
      "consumption",
      "data",
      "managed",
      "microsoft",
      "system",
      "center",
      "configuration",
      "manager",
      "deployed",
      "both",
      "universal",
      "discovery",
      "ud",
      "collect",
      "desktops",
      "discover",
      "servers.",
      "considers",
      "ucmdb",
      "trusted",
      "central",
      "inventory.",
      "help",
      "import",
      "inventory",
      "ucmdb.",
      "generates",
      "collected",
      "database",
      "through",
      "gateway.",
      "application",
      "library",
      "sai",
      "normalize",
      "all",
      "applications",
      "discovered",
      "sccm.",
      "run",
      "job.",
      "information",
      "see",
      "integration.",
      "synchronize",
      "product",
      "family.",
      "note",
      "because",
      "doesn",
      "oracle",
      "management",
      "services",
      "lms",
      "devices",
      "retrieve",
      "required",
      "capability",
      "sam.",
      "implementation",
      "content",
      "pack",
      "online",
      "documentation.",
      "configure",
      "rules.",
      "models",
      "build",
      "pool",
      "information.",
      "coverage.",
      "calculate",
      "consumption.",
      "view",
      "status.",
      "analyze",
      "report.",
      "products"
    ],
    "language": "en",
    "word_count": 114,
    "importance_score": 3.5,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "use the sccm installed software integration job for sam",
    "contentLower": "this section describes how to use the sccm installed software integration job to create compliance reports based on the license consumption data managed by microsoft system center configuration manager (sccm). overview if you have deployed both sccm and universal discovery (ud), you can use sccm to collect data of desktops and installed software and ud to discover servers. sam considers ucmdb as a trusted central inventory. the sccm installed software integration job can help import sccm's inventory data into ucmdb. then sam generates compliance reports based on the data collected from the ucmdb database through ucmdb gateway. software application library (sai) will normalize all the software applications discovered by sccm. workflow run the sccm installed software integration job. for more information, see sccm installed software integration. synchronize the product family. note because sccm doesn't collect oracle license management services (lms) data from the managed devices, retrie",
    "keywordsLower": [
      "sccm",
      "installed",
      "software",
      "integration",
      "job",
      "sam",
      "overview",
      "workflow",
      "related",
      "topics",
      "section",
      "describes",
      "create",
      "compliance",
      "reports",
      "based",
      "license",
      "consumption",
      "data",
      "managed",
      "microsoft",
      "system",
      "center",
      "configuration",
      "manager",
      "deployed",
      "both",
      "universal",
      "discovery",
      "ud",
      "collect",
      "desktops",
      "discover",
      "servers.",
      "considers",
      "ucmdb",
      "trusted",
      "central",
      "inventory.",
      "help",
      "import",
      "inventory",
      "ucmdb.",
      "generates",
      "collected",
      "database",
      "through",
      "gateway.",
      "application",
      "library",
      "sai",
      "normalize",
      "all",
      "applications",
      "discovered",
      "sccm.",
      "run",
      "job.",
      "information",
      "see",
      "integration.",
      "synchronize",
      "product",
      "family.",
      "note",
      "because",
      "doesn",
      "oracle",
      "management",
      "services",
      "lms",
      "devices",
      "retrieve",
      "required",
      "capability",
      "sam.",
      "implementation",
      "content",
      "pack",
      "online",
      "documentation.",
      "configure",
      "rules.",
      "models",
      "build",
      "pool",
      "information.",
      "coverage.",
      "calculate",
      "consumption.",
      "view",
      "status.",
      "analyze",
      "report.",
      "products"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Use OData for SAM reports",
    "content": "You can use data visualization software (such as Power BI) to create SAM reports by using the Service Management OData service. The Service Management OData data model includes SAM record types. See SAM data model for details of the SAM-related record types. This page describes the prerequisites for using OData for SAM-related reports. In addition, it describes how to import some OData-based sample SAM reports to Power BI. You can import the sample reports and review the report details in Power BI. Prerequisites To use OData for SAM reports, you must meet the following prerequisites: You have read the Service Management OData service documentation and understood how it works and how to use it. When you enter authentication details for connecting to the OData service, you must use the credentials of a user with the Access OData API permission and the View permission for these record types: License, License metric, Product, Product compliance, Product version, Product version compliance,",
    "url": "samodatareport",
    "filename": "samodatareport",
    "headings": [
      "Prerequisites",
      "Import sample report to Power BI"
    ],
    "keywords": [
      "deployment.sam",
      "values.yaml",
      "https://<FQDN>:<port>/rest/<tenant",
      "odata",
      "sam",
      "reports",
      "prerequisites",
      "import",
      "sample",
      "report",
      "power",
      "bi",
      "data",
      "visualization",
      "software",
      "such",
      "create",
      "service",
      "management",
      "service.",
      "model",
      "includes",
      "record",
      "types.",
      "see",
      "details",
      "sam-related",
      "page",
      "describes",
      "reports.",
      "addition",
      "odata-based",
      "bi.",
      "review",
      "meet",
      "following",
      "read",
      "documentation",
      "understood",
      "works",
      "it.",
      "enter",
      "authentication",
      "connecting",
      "credentials",
      "user",
      "access",
      "api",
      "permission",
      "view",
      "types",
      "license",
      "metric",
      "product",
      "compliance",
      "version",
      "publisher.",
      "certain",
      "federated",
      "via",
      "ucmdb",
      "gateway.",
      "need",
      "establish",
      "connection",
      "gateway",
      "odata.",
      "configure",
      "parameters",
      "ud",
      "ucmdb.",
      "topics",
      "depending",
      "installed",
      "containerized",
      "my-values.yaml",
      "file",
      "cmsgateway.deployment.sam.host",
      "cmsgateway.deployment.sam.port",
      "cmsgateway.deployment.sam.context.",
      "integration",
      "parameters.",
      "classic",
      "section",
      "config.properties",
      "file.",
      "install",
      "windows",
      "linux.",
      "enable",
      "tenant",
      "already",
      "enabled",
      "load",
      "metadata",
      "send",
      "get",
      "request",
      "endpoint",
      "credential"
    ],
    "language": "en",
    "word_count": 99,
    "importance_score": 4.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "use odata for sam reports",
    "contentLower": "you can use data visualization software (such as power bi) to create sam reports by using the service management odata service. the service management odata data model includes sam record types. see sam data model for details of the sam-related record types. this page describes the prerequisites for using odata for sam-related reports. in addition, it describes how to import some odata-based sample sam reports to power bi. you can import the sample reports and review the report details in power bi. prerequisites to use odata for sam reports, you must meet the following prerequisites: you have read the service management odata service documentation and understood how it works and how to use it. when you enter authentication details for connecting to the odata service, you must use the credentials of a user with the access odata api permission and the view permission for these record types: license, license metric, product, product compliance, product version, product version compliance,",
    "keywordsLower": [
      "deployment.sam",
      "values.yaml",
      "https://<fqdn>:<port>/rest/<tenant",
      "odata",
      "sam",
      "reports",
      "prerequisites",
      "import",
      "sample",
      "report",
      "power",
      "bi",
      "data",
      "visualization",
      "software",
      "such",
      "create",
      "service",
      "management",
      "service.",
      "model",
      "includes",
      "record",
      "types.",
      "see",
      "details",
      "sam-related",
      "page",
      "describes",
      "reports.",
      "addition",
      "odata-based",
      "bi.",
      "review",
      "meet",
      "following",
      "read",
      "documentation",
      "understood",
      "works",
      "it.",
      "enter",
      "authentication",
      "connecting",
      "credentials",
      "user",
      "access",
      "api",
      "permission",
      "view",
      "types",
      "license",
      "metric",
      "product",
      "compliance",
      "version",
      "publisher.",
      "certain",
      "federated",
      "via",
      "ucmdb",
      "gateway.",
      "need",
      "establish",
      "connection",
      "gateway",
      "odata.",
      "configure",
      "parameters",
      "ud",
      "ucmdb.",
      "topics",
      "depending",
      "installed",
      "containerized",
      "my-values.yaml",
      "file",
      "cmsgateway.deployment.sam.host",
      "cmsgateway.deployment.sam.port",
      "cmsgateway.deployment.sam.context.",
      "integration",
      "parameters.",
      "classic",
      "section",
      "config.properties",
      "file.",
      "install",
      "windows",
      "linux.",
      "enable",
      "tenant",
      "already",
      "enabled",
      "load",
      "metadata",
      "send",
      "get",
      "request",
      "endpoint",
      "credential"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "View an expense line",
    "content": "Besides viewing the expense lines associated with a certain record on the record's detail page, you can also view all expense lines generated or created in Expense Lines page. From the main menu, select Run > Financials > Expense Lines. Click the record identifier in the ID column to display the selected record. The General tab includes the following sections: Overview Field Description Display label External (common) name of the expense line. Amount Amount of the expense line. Currency The currency used for this expense line. Cost center The business unit to which the expense line belongs. Cost type The type of cost. For example, hardware maintenance or software. Credit/Debit Entry for the expense line. Expense date Date when the expense is incurred. Accounting period Accounting period for the expense line, generated automatically according to the expense date. Status Status of the expense line. The status is Incurred if the expense date is equal to the current date. The status is Pro",
    "url": "viewexpenseline",
    "filename": "viewexpenseline",
    "headings": [
      "Overview",
      "Source"
    ],
    "keywords": [
      "view",
      "expense",
      "line",
      "overview",
      "source",
      "besides",
      "viewing",
      "lines",
      "associated",
      "certain",
      "record",
      "detail",
      "page",
      "all",
      "generated",
      "created",
      "page.",
      "main",
      "menu",
      "select",
      "run",
      "financials",
      "lines.",
      "click",
      "identifier",
      "id",
      "column",
      "display",
      "selected",
      "record.",
      "general",
      "tab",
      "includes",
      "following",
      "sections",
      "field",
      "description",
      "label",
      "external",
      "common",
      "name",
      "line.",
      "amount",
      "currency",
      "cost",
      "center",
      "business",
      "unit",
      "belongs.",
      "type",
      "cost.",
      "example",
      "hardware",
      "maintenance",
      "software.",
      "credit",
      "debit",
      "entry",
      "date",
      "incurred.",
      "accounting",
      "period",
      "automatically",
      "according",
      "date.",
      "status",
      "incurred",
      "equal",
      "current",
      "projected",
      "greater",
      "creation",
      "time",
      "created.",
      "last",
      "update",
      "updated.",
      "parent",
      "displays",
      "applicable.",
      "allocation",
      "rule",
      "rule.",
      "recurring",
      "indicates",
      "changes",
      "updates",
      "made",
      "history",
      "tab.",
      "information",
      "see",
      "history."
    ],
    "language": "en",
    "word_count": 110,
    "importance_score": 4.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "view an expense line",
    "contentLower": "besides viewing the expense lines associated with a certain record on the record's detail page, you can also view all expense lines generated or created in expense lines page. from the main menu, select run > financials > expense lines. click the record identifier in the id column to display the selected record. the general tab includes the following sections: overview field description display label external (common) name of the expense line. amount amount of the expense line. currency the currency used for this expense line. cost center the business unit to which the expense line belongs. cost type the type of cost. for example, hardware maintenance or software. credit/debit entry for the expense line. expense date date when the expense is incurred. accounting period accounting period for the expense line, generated automatically according to the expense date. status status of the expense line. the status is incurred if the expense date is equal to the current date. the status is pro",
    "keywordsLower": [
      "view",
      "expense",
      "line",
      "overview",
      "source",
      "besides",
      "viewing",
      "lines",
      "associated",
      "certain",
      "record",
      "detail",
      "page",
      "all",
      "generated",
      "created",
      "page.",
      "main",
      "menu",
      "select",
      "run",
      "financials",
      "lines.",
      "click",
      "identifier",
      "id",
      "column",
      "display",
      "selected",
      "record.",
      "general",
      "tab",
      "includes",
      "following",
      "sections",
      "field",
      "description",
      "label",
      "external",
      "common",
      "name",
      "line.",
      "amount",
      "currency",
      "cost",
      "center",
      "business",
      "unit",
      "belongs.",
      "type",
      "cost.",
      "example",
      "hardware",
      "maintenance",
      "software.",
      "credit",
      "debit",
      "entry",
      "date",
      "incurred.",
      "accounting",
      "period",
      "automatically",
      "according",
      "date.",
      "status",
      "incurred",
      "equal",
      "current",
      "projected",
      "greater",
      "creation",
      "time",
      "created.",
      "last",
      "update",
      "updated.",
      "parent",
      "displays",
      "applicable.",
      "allocation",
      "rule",
      "rule.",
      "recurring",
      "indicates",
      "changes",
      "updates",
      "made",
      "history",
      "tab.",
      "information",
      "see",
      "history."
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "User operations for service design",
    "content": "User operations are actions configured on resource offerings, component templates, or service components in a design that can be invoked by subscribers in the Service Portal after a subscription has been provisioned. For example, a Restart Server user operation can be configured on a server service component or on an associated resource offering, allowing a subscriber to restart a particular provisioned server after the subscription has been provisioned. User operations can also be invoked on a service instance in the Operations area. Tasks Note If a service design is published, its user operations are read-only. Navigate to (the User Operations tab) — In the left pane of the All Design area, select the tag associated with the design you want to view. Select the service design and, in the Designer canvas, select the service component on which you want to complete the task. In the right pane, click the gear icon, select Edit Component, and select the User Operations tab. From here, you ",
    "url": "mgmtconssdeditcompuserop",
    "filename": "mgmtconssdeditcompuserop",
    "headings": [
      "Tasks",
      "Approvals for user operations in cloud offerings"
    ],
    "keywords": [
      "user",
      "operations",
      "service",
      "design",
      "tasks",
      "approvals",
      "cloud",
      "offerings",
      "actions",
      "configured",
      "resource",
      "component",
      "templates",
      "components",
      "invoked",
      "subscribers",
      "portal",
      "after",
      "subscription",
      "provisioned.",
      "example",
      "restart",
      "server",
      "operation",
      "associated",
      "offering",
      "allowing",
      "subscriber",
      "particular",
      "provisioned",
      "instance",
      "area.",
      "note",
      "published",
      "read-only.",
      "navigate",
      "tab",
      "left",
      "pane",
      "all",
      "area",
      "select",
      "tag",
      "want",
      "view.",
      "designer",
      "canvas",
      "complete",
      "task.",
      "right",
      "click",
      "gear",
      "icon",
      "edit",
      "tab.",
      "here",
      "view",
      "list",
      "component.",
      "add",
      "action",
      "enter",
      "information",
      "described",
      "selection",
      "wizard.",
      "edit.",
      "update",
      "offering.",
      "delete",
      "next",
      "remove",
      "delete.",
      "build",
      "task",
      "approval",
      "plan",
      "catalog",
      "administrator",
      "workflow",
      "operations.",
      "see",
      "offerings."
    ],
    "language": "en",
    "word_count": 97,
    "importance_score": 4.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "user operations for service design",
    "contentLower": "user operations are actions configured on resource offerings, component templates, or service components in a design that can be invoked by subscribers in the service portal after a subscription has been provisioned. for example, a restart server user operation can be configured on a server service component or on an associated resource offering, allowing a subscriber to restart a particular provisioned server after the subscription has been provisioned. user operations can also be invoked on a service instance in the operations area. tasks note if a service design is published, its user operations are read-only. navigate to (the user operations tab) — in the left pane of the all design area, select the tag associated with the design you want to view. select the service design and, in the designer canvas, select the service component on which you want to complete the task. in the right pane, click the gear icon, select edit component, and select the user operations tab. from here, you ",
    "keywordsLower": [
      "user",
      "operations",
      "service",
      "design",
      "tasks",
      "approvals",
      "cloud",
      "offerings",
      "actions",
      "configured",
      "resource",
      "component",
      "templates",
      "components",
      "invoked",
      "subscribers",
      "portal",
      "after",
      "subscription",
      "provisioned.",
      "example",
      "restart",
      "server",
      "operation",
      "associated",
      "offering",
      "allowing",
      "subscriber",
      "particular",
      "provisioned",
      "instance",
      "area.",
      "note",
      "published",
      "read-only.",
      "navigate",
      "tab",
      "left",
      "pane",
      "all",
      "area",
      "select",
      "tag",
      "want",
      "view.",
      "designer",
      "canvas",
      "complete",
      "task.",
      "right",
      "click",
      "gear",
      "icon",
      "edit",
      "tab.",
      "here",
      "view",
      "list",
      "component.",
      "add",
      "action",
      "enter",
      "information",
      "described",
      "selection",
      "wizard.",
      "edit.",
      "update",
      "offering.",
      "delete",
      "next",
      "remove",
      "delete.",
      "build",
      "task",
      "approval",
      "plan",
      "catalog",
      "administrator",
      "workflow",
      "operations.",
      "see",
      "offerings."
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "View configuration option sets and options",
    "content": "The Configuration Options tab is read-only if the service design is published. To view configuration option sets and options: Select the service design version whose configuration options and option sets you want to view. Select the Configuration Options tab to view the option sets and options for the service design. Click Navigate to Option Set to view the options for an option set and add or modify option properties. Click Navigate to Option to view the option set for an option and add or modify its properties. Click View Outline to see a tree view of all of the option sets, options, and properties that have been configured for the design and to navigate directly to an option set or option. A Validation column is added in the Configuration Options Outline view. It displays validation script name (if validation is enabled) like in case of dynamic properties. Only not hidden and not locked property will be semantically validated. If the property is hidden, property validation will be d",
    "url": "mgmtconssdsubsoptionpropview",
    "filename": "mgmtconssdsubsoptionpropview",
    "headings": [],
    "keywords": [
      "view",
      "configuration",
      "option",
      "sets",
      "options",
      "tab",
      "read-only",
      "service",
      "design",
      "published.",
      "select",
      "version",
      "whose",
      "want",
      "view.",
      "design.",
      "click",
      "navigate",
      "set",
      "add",
      "modify",
      "properties.",
      "outline",
      "see",
      "tree",
      "all",
      "properties",
      "configured",
      "directly",
      "option.",
      "validation",
      "column",
      "added",
      "displays",
      "script",
      "name",
      "enabled",
      "like",
      "case",
      "dynamic",
      "hidden",
      "locked",
      "property",
      "semantically",
      "validated.",
      "disabled",
      "warning",
      "changes",
      "saved."
    ],
    "language": "en",
    "word_count": 105,
    "importance_score": 2.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "view configuration option sets and options",
    "contentLower": "the configuration options tab is read-only if the service design is published. to view configuration option sets and options: select the service design version whose configuration options and option sets you want to view. select the configuration options tab to view the option sets and options for the service design. click navigate to option set to view the options for an option set and add or modify option properties. click navigate to option to view the option set for an option and add or modify its properties. click view outline to see a tree view of all of the option sets, options, and properties that have been configured for the design and to navigate directly to an option set or option. a validation column is added in the configuration options outline view. it displays validation script name (if validation is enabled) like in case of dynamic properties. only not hidden and not locked property will be semantically validated. if the property is hidden, property validation will be d",
    "keywordsLower": [
      "view",
      "configuration",
      "option",
      "sets",
      "options",
      "tab",
      "read-only",
      "service",
      "design",
      "published.",
      "select",
      "version",
      "whose",
      "want",
      "view.",
      "design.",
      "click",
      "navigate",
      "set",
      "add",
      "modify",
      "properties.",
      "outline",
      "see",
      "tree",
      "all",
      "properties",
      "configured",
      "directly",
      "option.",
      "validation",
      "column",
      "added",
      "displays",
      "script",
      "name",
      "enabled",
      "like",
      "case",
      "dynamic",
      "hidden",
      "locked",
      "property",
      "semantically",
      "validated.",
      "disabled",
      "warning",
      "changes",
      "saved."
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "View component palettes",
    "content": "To view component palettes In the left pane of the Sequenced Components area, view the available palettes. The list of component types contained in the selected palette displays in the right pane. The details of icons and labels in the Sequenced Components area are given in below table: Item Description Indicates locked items, which you can't edit or delete. However, you can create component types and component templates from a locked component type. Search Box Enter search text to filter the results. Derived Indicates Component Type that's based on or derived from another Component Type. CI Type Indicates Component Type that's derived from a CI Type or its equal. Related topics Service design components",
    "url": "mgmtconscomppaletteview",
    "filename": "mgmtconscomppaletteview",
    "headings": [
      "To view component palettes",
      "Related topics"
    ],
    "keywords": [
      "view",
      "component",
      "palettes",
      "related",
      "topics",
      "left",
      "pane",
      "sequenced",
      "components",
      "area",
      "available",
      "palettes.",
      "list",
      "types",
      "contained",
      "selected",
      "palette",
      "displays",
      "right",
      "pane.",
      "details",
      "icons",
      "labels",
      "given",
      "below",
      "table",
      "item",
      "description",
      "indicates",
      "locked",
      "items",
      "edit",
      "delete.",
      "however",
      "create",
      "templates",
      "type.",
      "search",
      "box",
      "enter",
      "text",
      "filter",
      "results.",
      "derived",
      "type",
      "based",
      "another",
      "ci",
      "equal.",
      "service",
      "design"
    ],
    "language": "en",
    "word_count": 81,
    "importance_score": 4.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "view component palettes",
    "contentLower": "to view component palettes in the left pane of the sequenced components area, view the available palettes. the list of component types contained in the selected palette displays in the right pane. the details of icons and labels in the sequenced components area are given in below table: item description indicates locked items, which you can't edit or delete. however, you can create component types and component templates from a locked component type. search box enter search text to filter the results. derived indicates component type that's based on or derived from another component type. ci type indicates component type that's derived from a ci type or its equal. related topics service design components",
    "keywordsLower": [
      "view",
      "component",
      "palettes",
      "related",
      "topics",
      "left",
      "pane",
      "sequenced",
      "components",
      "area",
      "available",
      "palettes.",
      "list",
      "types",
      "contained",
      "selected",
      "palette",
      "displays",
      "right",
      "pane.",
      "details",
      "icons",
      "labels",
      "given",
      "below",
      "table",
      "item",
      "description",
      "indicates",
      "locked",
      "items",
      "edit",
      "delete.",
      "however",
      "create",
      "templates",
      "type.",
      "search",
      "box",
      "enter",
      "text",
      "filter",
      "results.",
      "derived",
      "type",
      "based",
      "another",
      "ci",
      "equal.",
      "service",
      "design"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "View component types",
    "content": "In the left pane of the Components area, select the palette that contains the component type you want to view. The list of component types contained in the selected palette displays in the right pane. The details of icons and labels in the Sequenced Components area are given in below table: Item Description Indicates locked items, which you can't edit or delete. However, you can create component types and component templates from a locked component type. Search Box Enter search text to filter the results. Derived Indicates Component Type that's based on or derived from another Component Type. CI Type Indicates Component Type that's derived from a CI Type or its equal.",
    "url": "mgmtconscomptypeview",
    "filename": "mgmtconscomptypeview",
    "headings": [],
    "keywords": [
      "view",
      "component",
      "types",
      "left",
      "pane",
      "components",
      "area",
      "select",
      "palette",
      "contains",
      "type",
      "want",
      "view.",
      "list",
      "contained",
      "selected",
      "displays",
      "right",
      "pane.",
      "details",
      "icons",
      "labels",
      "sequenced",
      "given",
      "below",
      "table",
      "item",
      "description",
      "indicates",
      "locked",
      "items",
      "edit",
      "delete.",
      "however",
      "create",
      "templates",
      "type.",
      "search",
      "box",
      "enter",
      "text",
      "filter",
      "results.",
      "derived",
      "based",
      "another",
      "ci",
      "equal."
    ],
    "language": "en",
    "word_count": 76,
    "importance_score": 3.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "view component types",
    "contentLower": "in the left pane of the components area, select the palette that contains the component type you want to view. the list of component types contained in the selected palette displays in the right pane. the details of icons and labels in the sequenced components area are given in below table: item description indicates locked items, which you can't edit or delete. however, you can create component types and component templates from a locked component type. search box enter search text to filter the results. derived indicates component type that's based on or derived from another component type. ci type indicates component type that's derived from a ci type or its equal.",
    "keywordsLower": [
      "view",
      "component",
      "types",
      "left",
      "pane",
      "components",
      "area",
      "select",
      "palette",
      "contains",
      "type",
      "want",
      "view.",
      "list",
      "contained",
      "selected",
      "displays",
      "right",
      "pane.",
      "details",
      "icons",
      "labels",
      "sequenced",
      "given",
      "below",
      "table",
      "item",
      "description",
      "indicates",
      "locked",
      "items",
      "edit",
      "delete.",
      "however",
      "create",
      "templates",
      "type.",
      "search",
      "box",
      "enter",
      "text",
      "filter",
      "results.",
      "derived",
      "based",
      "another",
      "ci",
      "equal."
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "View component type details",
    "content": "In the left pane of the Service Components area, select the component palette that contains the component type whose details you want to view. Click the component type whose details you want to view. In the Overview tab, review details of the component type. For more details, see the topic Create a component type. Related topics Create a component type",
    "url": "mgmtconscomptypeviewdetails",
    "filename": "mgmtconscomptypeviewdetails",
    "headings": [
      "Related topics"
    ],
    "keywords": [
      "view",
      "component",
      "type",
      "details",
      "related",
      "topics",
      "left",
      "pane",
      "service",
      "components",
      "area",
      "select",
      "palette",
      "contains",
      "whose",
      "want",
      "view.",
      "click",
      "overview",
      "tab",
      "review",
      "type.",
      "see",
      "topic",
      "create"
    ],
    "language": "en",
    "word_count": 43,
    "importance_score": 2.5,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "view component type details",
    "contentLower": "in the left pane of the service components area, select the component palette that contains the component type whose details you want to view. click the component type whose details you want to view. in the overview tab, review details of the component type. for more details, see the topic create a component type. related topics create a component type",
    "keywordsLower": [
      "view",
      "component",
      "type",
      "details",
      "related",
      "topics",
      "left",
      "pane",
      "service",
      "components",
      "area",
      "select",
      "palette",
      "contains",
      "whose",
      "want",
      "view.",
      "click",
      "overview",
      "tab",
      "review",
      "type.",
      "see",
      "topic",
      "create"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "View component type properties",
    "content": "Properties for component types provide a base set of attributes that can be used and edited when creating service components in a service design. The value defined for a component type property is the default value exposed in the service design unless the service design uses a template, in which case, the template's property value is set as the default value in the service design. To view the properties of a component type In the left pane of the Sequenced Components area, select the component palette that contains the component type whose properties you want to view. Click the component type whose properties you want to view. Select the Properties tab. Related topics Create component type properties",
    "url": "mgmtconscomptypeviewprop",
    "filename": "mgmtconscomptypeviewprop",
    "headings": [
      "To view the properties of a component type",
      "Related topics"
    ],
    "keywords": [
      "view",
      "component",
      "type",
      "properties",
      "related",
      "topics",
      "types",
      "provide",
      "base",
      "set",
      "attributes",
      "edited",
      "creating",
      "service",
      "components",
      "design.",
      "value",
      "defined",
      "property",
      "default",
      "exposed",
      "design",
      "unless",
      "uses",
      "template",
      "case",
      "left",
      "pane",
      "sequenced",
      "area",
      "select",
      "palette",
      "contains",
      "whose",
      "want",
      "view.",
      "click",
      "tab.",
      "create"
    ],
    "language": "en",
    "word_count": 77,
    "importance_score": 4.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "view component type properties",
    "contentLower": "properties for component types provide a base set of attributes that can be used and edited when creating service components in a service design. the value defined for a component type property is the default value exposed in the service design unless the service design uses a template, in which case, the template's property value is set as the default value in the service design. to view the properties of a component type in the left pane of the sequenced components area, select the component palette that contains the component type whose properties you want to view. click the component type whose properties you want to view. select the properties tab. related topics create component type properties",
    "keywordsLower": [
      "view",
      "component",
      "type",
      "properties",
      "related",
      "topics",
      "types",
      "provide",
      "base",
      "set",
      "attributes",
      "edited",
      "creating",
      "service",
      "components",
      "design.",
      "value",
      "defined",
      "property",
      "default",
      "exposed",
      "design",
      "unless",
      "uses",
      "template",
      "case",
      "left",
      "pane",
      "sequenced",
      "area",
      "select",
      "palette",
      "contains",
      "whose",
      "want",
      "view.",
      "click",
      "tab.",
      "create"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "View constraints of a component type",
    "content": "Service Designers can configure two kinds of constraints for a component type: component type constraints and resource category constraints. These constraints apply to service components within a service design that are created from this component type. Component type constraints limit the types of service components that can be connected to components of this type within a service design. For example, a service component of type Server may be allowed connections only to components of types Application Layer, Network Connection, Software Component, and Storage Volume. Resource category constraints limit the categories of resource offerings that can be bound to service components of this type. For example, a Server service component may be allowed only to resource offerings associated with service components that are assigned the categories Application, Compliance, Compute, Configuration Management, Monitoring, Network, Service Usage, and Storage. A component type can establish constrai",
    "url": "mgmtconscomptypeviewconstraints",
    "filename": "mgmtconscomptypeviewconstraints",
    "headings": [
      "To view the constraints of a component type"
    ],
    "keywords": [
      "view",
      "constraints",
      "component",
      "type",
      "service",
      "designers",
      "configure",
      "two",
      "kinds",
      "resource",
      "category",
      "constraints.",
      "apply",
      "components",
      "design",
      "created",
      "type.",
      "limit",
      "types",
      "connected",
      "design.",
      "example",
      "server",
      "allowed",
      "connections",
      "application",
      "layer",
      "network",
      "connection",
      "software",
      "storage",
      "volume.",
      "categories",
      "offerings",
      "bound",
      "associated",
      "assigned",
      "compliance",
      "compute",
      "configuration",
      "management",
      "monitoring",
      "usage",
      "storage.",
      "establish",
      "following",
      "ways",
      "defined",
      "specified",
      "directly",
      "types.",
      "inherited",
      "hierarchy",
      "derived",
      "from.",
      "list",
      "path",
      "inheritance",
      "listed",
      "next",
      "name",
      "left",
      "pane",
      "sequenced",
      "area",
      "select",
      "palette",
      "contains",
      "whose",
      "want",
      "view.",
      "click",
      "tab.",
      "constraint",
      "categories.",
      "review"
    ],
    "language": "en",
    "word_count": 93,
    "importance_score": 2.5,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "view constraints of a component type",
    "contentLower": "service designers can configure two kinds of constraints for a component type: component type constraints and resource category constraints. these constraints apply to service components within a service design that are created from this component type. component type constraints limit the types of service components that can be connected to components of this type within a service design. for example, a service component of type server may be allowed connections only to components of types application layer, network connection, software component, and storage volume. resource category constraints limit the categories of resource offerings that can be bound to service components of this type. for example, a server service component may be allowed only to resource offerings associated with service components that are assigned the categories application, compliance, compute, configuration management, monitoring, network, service usage, and storage. a component type can establish constrai",
    "keywordsLower": [
      "view",
      "constraints",
      "component",
      "type",
      "service",
      "designers",
      "configure",
      "two",
      "kinds",
      "resource",
      "category",
      "constraints.",
      "apply",
      "components",
      "design",
      "created",
      "type.",
      "limit",
      "types",
      "connected",
      "design.",
      "example",
      "server",
      "allowed",
      "connections",
      "application",
      "layer",
      "network",
      "connection",
      "software",
      "storage",
      "volume.",
      "categories",
      "offerings",
      "bound",
      "associated",
      "assigned",
      "compliance",
      "compute",
      "configuration",
      "management",
      "monitoring",
      "usage",
      "storage.",
      "establish",
      "following",
      "ways",
      "defined",
      "specified",
      "directly",
      "types.",
      "inherited",
      "hierarchy",
      "derived",
      "from.",
      "list",
      "path",
      "inheritance",
      "listed",
      "next",
      "name",
      "left",
      "pane",
      "sequenced",
      "area",
      "select",
      "palette",
      "contains",
      "whose",
      "want",
      "view.",
      "click",
      "tab.",
      "constraint",
      "categories.",
      "review"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "View component templates",
    "content": "A component template is a specialized version of a component type and is used to simplify sequenced design creation. Component templates include customized settings for the properties, lifecycle actions, and resource offerings that provide initial settings for the service design. To view the templates that are based on a component type In the left pane of the Service Components area, select the component palette that contains the component type whose templates you want to view. Click the component type whose templates you want to view. Select the Templates tab. The Templates tab displays the list of templates created from the selected component type. You can also see component template information in the following tabs: Overview tab — See, View component template details. Properties tab —See, View component template properties. Lifecycle tab — See, Lifecycle actions for component templates Resource Offerings tab — See, Associate resource offerings with service components. The details o",
    "url": "comptmpltview",
    "filename": "comptmpltview",
    "headings": [
      "To view the templates that are based on a component type",
      "Related topics"
    ],
    "keywords": [
      "view",
      "component",
      "templates",
      "based",
      "type",
      "related",
      "topics",
      "template",
      "specialized",
      "version",
      "simplify",
      "sequenced",
      "design",
      "creation.",
      "include",
      "customized",
      "settings",
      "properties",
      "lifecycle",
      "actions",
      "resource",
      "offerings",
      "provide",
      "initial",
      "service",
      "design.",
      "left",
      "pane",
      "components",
      "area",
      "select",
      "palette",
      "contains",
      "whose",
      "want",
      "view.",
      "click",
      "tab.",
      "tab",
      "displays",
      "list",
      "created",
      "selected",
      "type.",
      "see",
      "information",
      "following",
      "tabs",
      "overview",
      "details.",
      "properties.",
      "associate",
      "components.",
      "details",
      "icons",
      "labels",
      "given",
      "below",
      "table",
      "item",
      "description",
      "indicates",
      "locked",
      "items",
      "edited",
      "deleted.",
      "however",
      "create",
      "types",
      "search",
      "box",
      "enter",
      "text",
      "filter",
      "results.",
      "derived",
      "another",
      "ci",
      "equivalent."
    ],
    "language": "en",
    "word_count": 105,
    "importance_score": 4.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "view component templates",
    "contentLower": "a component template is a specialized version of a component type and is used to simplify sequenced design creation. component templates include customized settings for the properties, lifecycle actions, and resource offerings that provide initial settings for the service design. to view the templates that are based on a component type in the left pane of the service components area, select the component palette that contains the component type whose templates you want to view. click the component type whose templates you want to view. select the templates tab. the templates tab displays the list of templates created from the selected component type. you can also see component template information in the following tabs: overview tab — see, view component template details. properties tab —see, view component template properties. lifecycle tab — see, lifecycle actions for component templates resource offerings tab — see, associate resource offerings with service components. the details o",
    "keywordsLower": [
      "view",
      "component",
      "templates",
      "based",
      "type",
      "related",
      "topics",
      "template",
      "specialized",
      "version",
      "simplify",
      "sequenced",
      "design",
      "creation.",
      "include",
      "customized",
      "settings",
      "properties",
      "lifecycle",
      "actions",
      "resource",
      "offerings",
      "provide",
      "initial",
      "service",
      "design.",
      "left",
      "pane",
      "components",
      "area",
      "select",
      "palette",
      "contains",
      "whose",
      "want",
      "view.",
      "click",
      "tab.",
      "tab",
      "displays",
      "list",
      "created",
      "selected",
      "type.",
      "see",
      "information",
      "following",
      "tabs",
      "overview",
      "details.",
      "properties.",
      "associate",
      "components.",
      "details",
      "icons",
      "labels",
      "given",
      "below",
      "table",
      "item",
      "description",
      "indicates",
      "locked",
      "items",
      "edited",
      "deleted.",
      "however",
      "create",
      "types",
      "search",
      "box",
      "enter",
      "text",
      "filter",
      "results.",
      "derived",
      "another",
      "ci",
      "equivalent."
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "View component template details",
    "content": "To view the details of a component template In the left pane of the Sequenced Components area, select the component palette that contains the component type whose template details you want to view. Click the component type whose template details you want to view. Select the Templates tab. In the templates list, click the template whose details you want to view. In the Overview tab, see the details of the component template. For descriptions of certain details, see Create component templates. Related topics Create component templates",
    "url": "comptmpltviewdetails",
    "filename": "comptmpltviewdetails",
    "headings": [
      "To view the details of a component template",
      "Related topics"
    ],
    "keywords": [
      "view",
      "component",
      "template",
      "details",
      "related",
      "topics",
      "left",
      "pane",
      "sequenced",
      "components",
      "area",
      "select",
      "palette",
      "contains",
      "type",
      "whose",
      "want",
      "view.",
      "click",
      "templates",
      "tab.",
      "list",
      "overview",
      "tab",
      "see",
      "template.",
      "descriptions",
      "certain",
      "create",
      "templates."
    ],
    "language": "en",
    "word_count": 61,
    "importance_score": 3.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "view component template details",
    "contentLower": "to view the details of a component template in the left pane of the sequenced components area, select the component palette that contains the component type whose template details you want to view. click the component type whose template details you want to view. select the templates tab. in the templates list, click the template whose details you want to view. in the overview tab, see the details of the component template. for descriptions of certain details, see create component templates. related topics create component templates",
    "keywordsLower": [
      "view",
      "component",
      "template",
      "details",
      "related",
      "topics",
      "left",
      "pane",
      "sequenced",
      "components",
      "area",
      "select",
      "palette",
      "contains",
      "type",
      "whose",
      "want",
      "view.",
      "click",
      "templates",
      "tab.",
      "list",
      "overview",
      "tab",
      "see",
      "template.",
      "descriptions",
      "certain",
      "create",
      "templates."
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "View component template properties",
    "content": "A component may have defined properties and inherited properties. Defined Properties — Properties created directly on this component template. You can delete, edit, and update defined properties and their values. New component templates have no defined properties, unless the component type is locked. If the component type is locked, only the property value can be set in the template's properties. Inherited Properties — Indicated by the Inherited label. Properties inherited from the base component type hierarchy. Identified in this list by the Inherited label. You can edit only the values of inherited properties. A property may also have references, which are properties that have been mapped from a resource offering, lifecycle action, or user operation. The value of the mapped property on the referring component gets its value from this property. See the topic on Property mapping. To view references to a component template property, click View References in the properties column. See, V",
    "url": "comptmpltviewproperties",
    "filename": "comptmpltviewproperties",
    "headings": [
      "To view component template properties",
      "Related topics"
    ],
    "keywords": [
      "view",
      "component",
      "template",
      "properties",
      "related",
      "topics",
      "defined",
      "inherited",
      "properties.",
      "created",
      "directly",
      "template.",
      "delete",
      "edit",
      "update",
      "values.",
      "new",
      "templates",
      "unless",
      "type",
      "locked.",
      "locked",
      "property",
      "value",
      "set",
      "indicated",
      "label.",
      "base",
      "hierarchy.",
      "identified",
      "list",
      "values",
      "references",
      "mapped",
      "resource",
      "offering",
      "lifecycle",
      "action",
      "user",
      "operation.",
      "referring",
      "gets",
      "property.",
      "see",
      "topic",
      "mapping.",
      "click",
      "column.",
      "references.",
      "left",
      "pane",
      "sequenced",
      "components",
      "area",
      "select",
      "palette",
      "contains",
      "whose",
      "want",
      "view.",
      "tab.",
      "tab",
      "includes",
      "information",
      "about",
      "details",
      "create",
      "mapping"
    ],
    "language": "en",
    "word_count": 93,
    "importance_score": 4.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "view component template properties",
    "contentLower": "a component may have defined properties and inherited properties. defined properties — properties created directly on this component template. you can delete, edit, and update defined properties and their values. new component templates have no defined properties, unless the component type is locked. if the component type is locked, only the property value can be set in the template's properties. inherited properties — indicated by the inherited label. properties inherited from the base component type hierarchy. identified in this list by the inherited label. you can edit only the values of inherited properties. a property may also have references, which are properties that have been mapped from a resource offering, lifecycle action, or user operation. the value of the mapped property on the referring component gets its value from this property. see the topic on property mapping. to view references to a component template property, click view references in the properties column. see, v",
    "keywordsLower": [
      "view",
      "component",
      "template",
      "properties",
      "related",
      "topics",
      "defined",
      "inherited",
      "properties.",
      "created",
      "directly",
      "template.",
      "delete",
      "edit",
      "update",
      "values.",
      "new",
      "templates",
      "unless",
      "type",
      "locked.",
      "locked",
      "property",
      "value",
      "set",
      "indicated",
      "label.",
      "base",
      "hierarchy.",
      "identified",
      "list",
      "values",
      "references",
      "mapped",
      "resource",
      "offering",
      "lifecycle",
      "action",
      "user",
      "operation.",
      "referring",
      "gets",
      "property.",
      "see",
      "topic",
      "mapping.",
      "click",
      "column.",
      "references.",
      "left",
      "pane",
      "sequenced",
      "components",
      "area",
      "select",
      "palette",
      "contains",
      "whose",
      "want",
      "view.",
      "tab.",
      "tab",
      "includes",
      "information",
      "about",
      "details",
      "create",
      "mapping"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "View component template property references",
    "content": "To view the mappings for a component template property, go to the Properties tab for a component template, and then click View References for a property. Reference types Lifecycle Actions — Go to the Lifecycle tab to view these references. Resource Offerings Measurable Properties — Go to the Resource Offerings tab to view these references. Resource Offering Property Mappings — Go to the Resource Offerings tab to view these references. Resource Offering Provider Selection Actions —Go to the Resource Offerings tab to view these references. User Operations — Go to the User Operations tab to view these references. Related topics Property mapping",
    "url": "comptmpltpropref",
    "filename": "comptmpltpropref",
    "headings": [
      "Reference types",
      "Related topics"
    ],
    "keywords": [
      "view",
      "component",
      "template",
      "property",
      "references",
      "reference",
      "types",
      "related",
      "topics",
      "mappings",
      "go",
      "properties",
      "tab",
      "click",
      "property.",
      "lifecycle",
      "actions",
      "references.",
      "resource",
      "offerings",
      "measurable",
      "offering",
      "provider",
      "selection",
      "user",
      "operations",
      "mapping"
    ],
    "language": "en",
    "word_count": 71,
    "importance_score": 4.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "view component template property references",
    "contentLower": "to view the mappings for a component template property, go to the properties tab for a component template, and then click view references for a property. reference types lifecycle actions — go to the lifecycle tab to view these references. resource offerings measurable properties — go to the resource offerings tab to view these references. resource offering property mappings — go to the resource offerings tab to view these references. resource offering provider selection actions —go to the resource offerings tab to view these references. user operations — go to the user operations tab to view these references. related topics property mapping",
    "keywordsLower": [
      "view",
      "component",
      "template",
      "property",
      "references",
      "reference",
      "types",
      "related",
      "topics",
      "mappings",
      "go",
      "properties",
      "tab",
      "click",
      "property.",
      "lifecycle",
      "actions",
      "references.",
      "resource",
      "offerings",
      "measurable",
      "offering",
      "provider",
      "selection",
      "user",
      "operations",
      "mapping"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "User operations for component templates",
    "content": "User operations are actions configured on resource offerings, component templates, or service components in a design that can be invoked by subscribers in the Service Portal after a subscription has been provisioned. For example, a Restart Server user operation can be configured on a server service component or on an associated resource offering, allowing a subscriber to restart a particular provisioned server after the subscription has been provisioned. User operations can also be invoked on a service instance in the Operations area. Tasks Navigate to (the User Operations tab) — In the left pane of the Sequenced Components area, select the palette associated with the component type of the component template you want to view. Select the component type and then select the Templates tab. Select the template, and then select the User Operations tab. View a list of user operations for this component template. Add Action — Click Add, and enter the information as described in the topic User ",
    "url": "comptmpltuseroperations",
    "filename": "comptmpltuseroperations",
    "headings": [
      "Tasks",
      "Approvals for user operations in cloud offerings",
      "Related topics"
    ],
    "keywords": [
      "user",
      "operations",
      "component",
      "templates",
      "tasks",
      "approvals",
      "cloud",
      "offerings",
      "related",
      "topics",
      "actions",
      "configured",
      "resource",
      "service",
      "components",
      "design",
      "invoked",
      "subscribers",
      "portal",
      "after",
      "subscription",
      "provisioned.",
      "example",
      "restart",
      "server",
      "operation",
      "associated",
      "offering",
      "allowing",
      "subscriber",
      "particular",
      "provisioned",
      "instance",
      "area.",
      "navigate",
      "tab",
      "left",
      "pane",
      "sequenced",
      "area",
      "select",
      "palette",
      "type",
      "template",
      "want",
      "view.",
      "tab.",
      "view",
      "list",
      "template.",
      "add",
      "action",
      "click",
      "enter",
      "information",
      "described",
      "topic",
      "selection",
      "wizard.",
      "edit",
      "gear",
      "icon",
      "edit.",
      "update",
      "all",
      "delete",
      "next",
      "remove",
      "delete.",
      "build",
      "task",
      "approval",
      "plan",
      "catalog",
      "administrator",
      "workflow",
      "operations.",
      "see",
      "offerings.",
      "wizard"
    ],
    "language": "en",
    "word_count": 96,
    "importance_score": 4.5,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "user operations for component templates",
    "contentLower": "user operations are actions configured on resource offerings, component templates, or service components in a design that can be invoked by subscribers in the service portal after a subscription has been provisioned. for example, a restart server user operation can be configured on a server service component or on an associated resource offering, allowing a subscriber to restart a particular provisioned server after the subscription has been provisioned. user operations can also be invoked on a service instance in the operations area. tasks navigate to (the user operations tab) — in the left pane of the sequenced components area, select the palette associated with the component type of the component template you want to view. select the component type and then select the templates tab. select the template, and then select the user operations tab. view a list of user operations for this component template. add action — click add, and enter the information as described in the topic user ",
    "keywordsLower": [
      "user",
      "operations",
      "component",
      "templates",
      "tasks",
      "approvals",
      "cloud",
      "offerings",
      "related",
      "topics",
      "actions",
      "configured",
      "resource",
      "service",
      "components",
      "design",
      "invoked",
      "subscribers",
      "portal",
      "after",
      "subscription",
      "provisioned.",
      "example",
      "restart",
      "server",
      "operation",
      "associated",
      "offering",
      "allowing",
      "subscriber",
      "particular",
      "provisioned",
      "instance",
      "area.",
      "navigate",
      "tab",
      "left",
      "pane",
      "sequenced",
      "area",
      "select",
      "palette",
      "type",
      "template",
      "want",
      "view.",
      "tab.",
      "view",
      "list",
      "template.",
      "add",
      "action",
      "click",
      "enter",
      "information",
      "described",
      "topic",
      "selection",
      "wizard.",
      "edit",
      "gear",
      "icon",
      "edit.",
      "update",
      "all",
      "delete",
      "next",
      "remove",
      "delete.",
      "build",
      "task",
      "approval",
      "plan",
      "catalog",
      "administrator",
      "workflow",
      "operations.",
      "see",
      "offerings.",
      "wizard"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "View service design component property references",
    "content": "To view all references to a service component property, select the component in the Sequenced Designer, click the gear icon to edit the service component, go to the Properties tab, locate the property in that list and then click View References. Reference types Lifecycle Actions — Go to the Lifecycle tab to view these references. Resource Offerings Measurable Properties — Go to the Resource Offerings tab to view these references. Resource Offering Property Mappings — Go to the Resource Offerings tab to view these references. Resource Offering Provider Selection Actions — Go to the Resource Offerings tab to view these references. Subscriber Options — Go to the Subscriber Options tab to view these references. Service Components — The path for the reference shows you which component has this reference. Select the component in the Designer to view its properties. The chain icon indicates a property that has been mapped. User Operations — Go to the User Operations tab to view these referenc",
    "url": "mgmtconssdviewcomppropref",
    "filename": "mgmtconssdviewcomppropref",
    "headings": [
      "Reference types"
    ],
    "keywords": [
      "view",
      "service",
      "design",
      "component",
      "property",
      "references",
      "reference",
      "types",
      "all",
      "select",
      "sequenced",
      "designer",
      "click",
      "gear",
      "icon",
      "edit",
      "go",
      "properties",
      "tab",
      "locate",
      "list",
      "references.",
      "lifecycle",
      "actions",
      "resource",
      "offerings",
      "measurable",
      "offering",
      "mappings",
      "provider",
      "selection",
      "subscriber",
      "options",
      "components",
      "path",
      "shows",
      "reference.",
      "properties.",
      "chain",
      "indicates",
      "mapped.",
      "user",
      "operations"
    ],
    "language": "en",
    "word_count": 104,
    "importance_score": 2.5,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "view service design component property references",
    "contentLower": "to view all references to a service component property, select the component in the sequenced designer, click the gear icon to edit the service component, go to the properties tab, locate the property in that list and then click view references. reference types lifecycle actions — go to the lifecycle tab to view these references. resource offerings measurable properties — go to the resource offerings tab to view these references. resource offering property mappings — go to the resource offerings tab to view these references. resource offering provider selection actions — go to the resource offerings tab to view these references. subscriber options — go to the subscriber options tab to view these references. service components — the path for the reference shows you which component has this reference. select the component in the designer to view its properties. the chain icon indicates a property that has been mapped. user operations — go to the user operations tab to view these referenc",
    "keywordsLower": [
      "view",
      "service",
      "design",
      "component",
      "property",
      "references",
      "reference",
      "types",
      "all",
      "select",
      "sequenced",
      "designer",
      "click",
      "gear",
      "icon",
      "edit",
      "go",
      "properties",
      "tab",
      "locate",
      "list",
      "references.",
      "lifecycle",
      "actions",
      "resource",
      "offerings",
      "measurable",
      "offering",
      "mappings",
      "provider",
      "selection",
      "subscriber",
      "options",
      "components",
      "path",
      "shows",
      "reference.",
      "properties.",
      "chain",
      "indicates",
      "mapped.",
      "user",
      "operations"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "View service design component property references",
    "content": "To view references to a service component property, select the component in the Sequenced Designer and click View References in the properties panel on the right. From this view, you will only see references from other service component properties and subscriber option properties. If there are more references, they can be viewed by clicking the gear icon and editing the component. See View component property references. Reference types Subscriber Options — Go to the Subscriber Options tab view these references. Service Components — Go to the Designer tab to view these references. The chain icon indicates a property that has been mapped.",
    "url": "mgmtconssdservicecompropref",
    "filename": "mgmtconssdservicecompropref",
    "headings": [
      "Reference types"
    ],
    "keywords": [
      "view",
      "service",
      "design",
      "component",
      "property",
      "references",
      "reference",
      "types",
      "select",
      "sequenced",
      "designer",
      "click",
      "properties",
      "panel",
      "right.",
      "see",
      "subscriber",
      "option",
      "properties.",
      "there",
      "viewed",
      "clicking",
      "gear",
      "icon",
      "editing",
      "component.",
      "references.",
      "options",
      "go",
      "tab",
      "components",
      "chain",
      "indicates",
      "mapped."
    ],
    "language": "en",
    "word_count": 65,
    "importance_score": 2.5,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "view service design component property references",
    "contentLower": "to view references to a service component property, select the component in the sequenced designer and click view references in the properties panel on the right. from this view, you will only see references from other service component properties and subscriber option properties. if there are more references, they can be viewed by clicking the gear icon and editing the component. see view component property references. reference types subscriber options — go to the subscriber options tab view these references. service components — go to the designer tab to view these references. the chain icon indicates a property that has been mapped.",
    "keywordsLower": [
      "view",
      "service",
      "design",
      "component",
      "property",
      "references",
      "reference",
      "types",
      "select",
      "sequenced",
      "designer",
      "click",
      "properties",
      "panel",
      "right.",
      "see",
      "subscriber",
      "option",
      "properties.",
      "there",
      "viewed",
      "clicking",
      "gear",
      "icon",
      "editing",
      "component.",
      "references.",
      "options",
      "go",
      "tab",
      "components",
      "chain",
      "indicates",
      "mapped."
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "UCMDB CI components for DND",
    "content": "The following illustration depicts the components hierarchy based on CI types. CI Types CI Types are Component Types specific for creating Service Designs that could be integrated with UCMDB Provider to be created and realized within UCMDB. The CI Types are available in the UD/UCMDB Palette (CI Types based). The available CI Types are listed in the below table: Parent component CI Type Description Configuration item CI Collection Generic logical collection of components that are of type - Infrastructure Element or Running Software. Infrastructure Element Contains infrastructure service components such as, individual servers or server groups that are required in a service design. Business Element Business Element is a basic class for all components that support a particular business function, produce a product or provide a service that's visible to customers. Infrastructure Element Application Resource A base component type that's used to derive component types representing application ",
    "url": "mgmtconssdservicecomucmdblist",
    "filename": "mgmtconssdservicecomucmdblist",
    "headings": [
      "CI Types",
      "CI relationship created in UCMDB by DND"
    ],
    "keywords": [
      "ucmdb",
      "ci",
      "components",
      "dnd",
      "types",
      "relationship",
      "created",
      "following",
      "illustration",
      "depicts",
      "hierarchy",
      "based",
      "types.",
      "component",
      "specific",
      "creating",
      "service",
      "designs",
      "integrated",
      "provider",
      "realized",
      "ucmdb.",
      "available",
      "ud",
      "palette",
      "listed",
      "below",
      "table",
      "parent",
      "type",
      "description",
      "configuration",
      "item",
      "collection",
      "generic",
      "logical",
      "infrastructure",
      "element",
      "running",
      "software.",
      "contains",
      "such",
      "individual",
      "servers",
      "server",
      "groups",
      "required",
      "design.",
      "business",
      "basic",
      "class",
      "all",
      "support",
      "particular",
      "function",
      "produce",
      "product",
      "provide",
      "visible",
      "customers.",
      "application",
      "resource",
      "base",
      "derive",
      "representing",
      "resources.",
      "system",
      "super",
      "complex",
      "systems",
      "like",
      "erp",
      "crm",
      "call-center.",
      "cloud",
      "represent",
      "kinds",
      "services",
      "provided",
      "public",
      "cloud.",
      "node",
      "represents",
      "general",
      "purpose",
      "machine",
      "devices",
      "virtual",
      "machines",
      "derived.",
      "software",
      "runtime",
      "aspects",
      "intended",
      "various",
      "net",
      "device",
      "routers",
      "switches",
      "printers."
    ],
    "language": "en",
    "word_count": 107,
    "importance_score": 4.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "ucmdb ci components for dnd",
    "contentLower": "the following illustration depicts the components hierarchy based on ci types. ci types ci types are component types specific for creating service designs that could be integrated with ucmdb provider to be created and realized within ucmdb. the ci types are available in the ud/ucmdb palette (ci types based). the available ci types are listed in the below table: parent component ci type description configuration item ci collection generic logical collection of components that are of type - infrastructure element or running software. infrastructure element contains infrastructure service components such as, individual servers or server groups that are required in a service design. business element business element is a basic class for all components that support a particular business function, produce a product or provide a service that's visible to customers. infrastructure element application resource a base component type that's used to derive component types representing application ",
    "keywordsLower": [
      "ucmdb",
      "ci",
      "components",
      "dnd",
      "types",
      "relationship",
      "created",
      "following",
      "illustration",
      "depicts",
      "hierarchy",
      "based",
      "types.",
      "component",
      "specific",
      "creating",
      "service",
      "designs",
      "integrated",
      "provider",
      "realized",
      "ucmdb.",
      "available",
      "ud",
      "palette",
      "listed",
      "below",
      "table",
      "parent",
      "type",
      "description",
      "configuration",
      "item",
      "collection",
      "generic",
      "logical",
      "infrastructure",
      "element",
      "running",
      "software.",
      "contains",
      "such",
      "individual",
      "servers",
      "server",
      "groups",
      "required",
      "design.",
      "business",
      "basic",
      "class",
      "all",
      "support",
      "particular",
      "function",
      "produce",
      "product",
      "provide",
      "visible",
      "customers.",
      "application",
      "resource",
      "base",
      "derive",
      "representing",
      "resources.",
      "system",
      "super",
      "complex",
      "systems",
      "like",
      "erp",
      "crm",
      "call-center.",
      "cloud",
      "represent",
      "kinds",
      "services",
      "provided",
      "public",
      "cloud.",
      "node",
      "represents",
      "general",
      "purpose",
      "machine",
      "devices",
      "virtual",
      "machines",
      "derived.",
      "software",
      "runtime",
      "aspects",
      "intended",
      "various",
      "net",
      "device",
      "routers",
      "switches",
      "printers."
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "View resource offerings",
    "content": "From the main menu go to Build > Design > Resource Offerings. You can view Resource Offerings from the Resource Offerings page by selecting either Provider Type or Category. The default options selected are - Provider Type and All Resource Offerings. So, the system displays all Resource Offerings sorted by Provider Type by default. Provider Type - When Provider Type is selected, all Providers in the system will be displayed in the left panel. Select a Provider Type and all Resource Offerings for the selected Provider Type will be displayed. Category - When Category is selected, all categories in the system will be displayed in the left panel. Select a Category and all Resource Offerings for the selected category will be displayed. To view the details of a specific Resource Offering, click on the Resource Offering. For descriptions of the specific properties, see Create a resource offering. Tip You can easily identity if a Resource Offering is referenced with any design from the Resourc",
    "url": "mgmtconsroview",
    "filename": "mgmtconsroview",
    "headings": [
      "Related topics"
    ],
    "keywords": [
      "view",
      "resource",
      "offerings",
      "related",
      "topics",
      "main",
      "menu",
      "go",
      "build",
      "design",
      "offerings.",
      "page",
      "selecting",
      "either",
      "provider",
      "type",
      "category.",
      "default",
      "options",
      "selected",
      "all",
      "system",
      "displays",
      "sorted",
      "default.",
      "providers",
      "displayed",
      "left",
      "panel.",
      "select",
      "displayed.",
      "category",
      "categories",
      "details",
      "specific",
      "offering",
      "click",
      "offering.",
      "descriptions",
      "properties",
      "see",
      "create",
      "tip",
      "easily",
      "identity",
      "referenced",
      "any",
      "page.",
      "banner",
      "below",
      "tabs",
      "number",
      "designs",
      "used."
    ],
    "language": "en",
    "word_count": 100,
    "importance_score": 3.5,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "view resource offerings",
    "contentLower": "from the main menu go to build > design > resource offerings. you can view resource offerings from the resource offerings page by selecting either provider type or category. the default options selected are - provider type and all resource offerings. so, the system displays all resource offerings sorted by provider type by default. provider type - when provider type is selected, all providers in the system will be displayed in the left panel. select a provider type and all resource offerings for the selected provider type will be displayed. category - when category is selected, all categories in the system will be displayed in the left panel. select a category and all resource offerings for the selected category will be displayed. to view the details of a specific resource offering, click on the resource offering. for descriptions of the specific properties, see create a resource offering. tip you can easily identity if a resource offering is referenced with any design from the resourc",
    "keywordsLower": [
      "view",
      "resource",
      "offerings",
      "related",
      "topics",
      "main",
      "menu",
      "go",
      "build",
      "design",
      "offerings.",
      "page",
      "selecting",
      "either",
      "provider",
      "type",
      "category.",
      "default",
      "options",
      "selected",
      "all",
      "system",
      "displays",
      "sorted",
      "default.",
      "providers",
      "displayed",
      "left",
      "panel.",
      "select",
      "displayed.",
      "category",
      "categories",
      "details",
      "specific",
      "offering",
      "click",
      "offering.",
      "descriptions",
      "properties",
      "see",
      "create",
      "tip",
      "easily",
      "identity",
      "referenced",
      "any",
      "page.",
      "banner",
      "below",
      "tabs",
      "number",
      "designs",
      "used."
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "View resource offering property references",
    "content": "To view reference to a resource offering property, go to the Properties tab for a resource offering, and then click View References for the property. Reference Types Service Designs: Click the design link to view the design containing these references. Component Templates: Click the template link to view the template containing these references. Lifecycle Actions: Go to the Lifecycle tab to view these references. User Operations: Go to the User Operations tab to view these references.",
    "url": "mgmtconsropropref",
    "filename": "mgmtconsropropref",
    "headings": [
      "Reference Types"
    ],
    "keywords": [
      "view",
      "resource",
      "offering",
      "property",
      "references",
      "reference",
      "types",
      "go",
      "properties",
      "tab",
      "click",
      "property.",
      "service",
      "designs",
      "design",
      "link",
      "containing",
      "references.",
      "component",
      "templates",
      "template",
      "lifecycle",
      "actions",
      "user",
      "operations"
    ],
    "language": "en",
    "word_count": 54,
    "importance_score": 2.5,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "view resource offering property references",
    "contentLower": "to view reference to a resource offering property, go to the properties tab for a resource offering, and then click view references for the property. reference types service designs: click the design link to view the design containing these references. component templates: click the template link to view the template containing these references. lifecycle actions: go to the lifecycle tab to view these references. user operations: go to the user operations tab to view these references.",
    "keywordsLower": [
      "view",
      "resource",
      "offering",
      "property",
      "references",
      "reference",
      "types",
      "go",
      "properties",
      "tab",
      "click",
      "property.",
      "service",
      "designs",
      "design",
      "link",
      "containing",
      "references.",
      "component",
      "templates",
      "template",
      "lifecycle",
      "actions",
      "user",
      "operations"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "User operations for resource offerings",
    "content": "User operations are actions configured on resource offerings, component templates, or service components in a design that can be invoked by subscribers in the Service Portal after a subscription has been provisioned. For example, a Restart Server user operation can be configured on a server service component or on an associated resource offering, allowing a subscriber to restart a particular provisioned server after the subscription has been provisioned. User operations can also be invoked on a service instance in the Operations area. Tasks Navigate to (the User Operations tab) — In the left pane of the Resource Offerings area, select the category or provider type associated with the resource offering you want to view. Select the resource offering and then select the User Operations tab. View a list of user operations for this resource offering. Add Action — Click Add, and enter the information as described in Action selection wizard. Edit Action — Click the gear icon on the action you",
    "url": "mgmtconsrouseroperations",
    "filename": "mgmtconsrouseroperations",
    "headings": [
      "Tasks",
      "Approvals for user operations in cloud offerings"
    ],
    "keywords": [
      "user",
      "operations",
      "resource",
      "offerings",
      "tasks",
      "approvals",
      "cloud",
      "actions",
      "configured",
      "component",
      "templates",
      "service",
      "components",
      "design",
      "invoked",
      "subscribers",
      "portal",
      "after",
      "subscription",
      "provisioned.",
      "example",
      "restart",
      "server",
      "operation",
      "associated",
      "offering",
      "allowing",
      "subscriber",
      "particular",
      "provisioned",
      "instance",
      "area.",
      "navigate",
      "tab",
      "left",
      "pane",
      "area",
      "select",
      "category",
      "provider",
      "type",
      "want",
      "view.",
      "tab.",
      "view",
      "list",
      "offering.",
      "add",
      "action",
      "click",
      "enter",
      "information",
      "described",
      "selection",
      "wizard.",
      "edit",
      "gear",
      "icon",
      "edit.",
      "update",
      "all",
      "delete",
      "next",
      "remove",
      "delete.",
      "build",
      "task",
      "approval",
      "plan",
      "catalog",
      "administrator",
      "workflow",
      "operations.",
      "see",
      "offerings."
    ],
    "language": "en",
    "word_count": 98,
    "importance_score": 4.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "user operations for resource offerings",
    "contentLower": "user operations are actions configured on resource offerings, component templates, or service components in a design that can be invoked by subscribers in the service portal after a subscription has been provisioned. for example, a restart server user operation can be configured on a server service component or on an associated resource offering, allowing a subscriber to restart a particular provisioned server after the subscription has been provisioned. user operations can also be invoked on a service instance in the operations area. tasks navigate to (the user operations tab) — in the left pane of the resource offerings area, select the category or provider type associated with the resource offering you want to view. select the resource offering and then select the user operations tab. view a list of user operations for this resource offering. add action — click add, and enter the information as described in action selection wizard. edit action — click the gear icon on the action you",
    "keywordsLower": [
      "user",
      "operations",
      "resource",
      "offerings",
      "tasks",
      "approvals",
      "cloud",
      "actions",
      "configured",
      "component",
      "templates",
      "service",
      "components",
      "design",
      "invoked",
      "subscribers",
      "portal",
      "after",
      "subscription",
      "provisioned.",
      "example",
      "restart",
      "server",
      "operation",
      "associated",
      "offering",
      "allowing",
      "subscriber",
      "particular",
      "provisioned",
      "instance",
      "area.",
      "navigate",
      "tab",
      "left",
      "pane",
      "area",
      "select",
      "category",
      "provider",
      "type",
      "want",
      "view.",
      "tab.",
      "view",
      "list",
      "offering.",
      "add",
      "action",
      "click",
      "enter",
      "information",
      "described",
      "selection",
      "wizard.",
      "edit",
      "gear",
      "icon",
      "edit.",
      "update",
      "all",
      "delete",
      "next",
      "remove",
      "delete.",
      "build",
      "task",
      "approval",
      "plan",
      "catalog",
      "administrator",
      "workflow",
      "operations.",
      "see",
      "offerings."
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "View custom resource offering properties",
    "content": "Custom properties for resource offerings are user-defined properties that are used for communicating properties and values to providers to customize the functional service they provide. The custom properties can be used to provide any information that's expected by an Operations Orchestration flow. For example, you can use custom properties for a resource offering to provide a specific VM_TEMPLATE_NAME value to an instance of VMware vCenter. Perform the following steps to view the custom resource offering properties: In the Offerings tab, click the Display Name of the offering whose custom properties you want to view. In the Properties tab, review the custom properties created for the offering.",
    "url": "mgmtconsrocustompropview",
    "filename": "mgmtconsrocustompropview",
    "headings": [],
    "keywords": [
      "view",
      "custom",
      "resource",
      "offering",
      "properties",
      "offerings",
      "user-defined",
      "communicating",
      "values",
      "providers",
      "customize",
      "functional",
      "service",
      "provide.",
      "provide",
      "any",
      "information",
      "expected",
      "operations",
      "orchestration",
      "flow.",
      "example",
      "specific",
      "value",
      "instance",
      "vmware",
      "vcenter.",
      "perform",
      "following",
      "steps",
      "tab",
      "click",
      "display",
      "name",
      "whose",
      "want",
      "view.",
      "review",
      "created",
      "offering."
    ],
    "language": "en",
    "word_count": 67,
    "importance_score": 3.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "view custom resource offering properties",
    "contentLower": "custom properties for resource offerings are user-defined properties that are used for communicating properties and values to providers to customize the functional service they provide. the custom properties can be used to provide any information that's expected by an operations orchestration flow. for example, you can use custom properties for a resource offering to provide a specific vm_template_name value to an instance of vmware vcenter. perform the following steps to view the custom resource offering properties: in the offerings tab, click the display name of the offering whose custom properties you want to view. in the properties tab, review the custom properties created for the offering.",
    "keywordsLower": [
      "view",
      "custom",
      "resource",
      "offering",
      "properties",
      "offerings",
      "user-defined",
      "communicating",
      "values",
      "providers",
      "customize",
      "functional",
      "service",
      "provide.",
      "provide",
      "any",
      "information",
      "expected",
      "operations",
      "orchestration",
      "flow.",
      "example",
      "specific",
      "value",
      "instance",
      "vmware",
      "vcenter.",
      "perform",
      "following",
      "steps",
      "tab",
      "click",
      "display",
      "name",
      "whose",
      "want",
      "view.",
      "review",
      "created",
      "offering."
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Use OO Workflow Designer",
    "content": "This section shows how to set up your OO Workflow Designer workspace and how to use OO Workflow Designer for authoring. View system information You can view a system information report, which displays version and static system information, database connection information, and general system information. To view the system information report, enter the following text into your browser address line: http://<OO designer URL>:<port number>/oo-designer/reports/sysinfo Log in You can access the application using a supported web browser, from any computer with a network connection (intranet or Internet) to the servers. It's recommended to restore your browser to the default settings. Enter the following URL into your browser address bar to launch OO Workflow Designer: https://<Local Host>:8445/oo-designer Enter the OO Workflow Designer credentials created during installation for the User Name and Password fields. The default user is administrator if it was not changed at installation time. Cl",
    "url": "useoodesigner",
    "filename": "useoodesigner",
    "headings": [
      "View system information",
      "Log in",
      "Log out",
      "Related topics"
    ],
    "keywords": [
      "https://<Local",
      "http://<OO",
      "oo",
      "workflow",
      "designer",
      "view",
      "system",
      "information",
      "log",
      "out",
      "related",
      "topics",
      "section",
      "shows",
      "set",
      "workspace",
      "authoring.",
      "report",
      "displays",
      "version",
      "static",
      "database",
      "connection",
      "general",
      "information.",
      "enter",
      "following",
      "text",
      "browser",
      "address",
      "line",
      "http",
      "oo-designer",
      "reports",
      "sysinfo",
      "access",
      "application",
      "supported",
      "web",
      "any",
      "computer",
      "network",
      "intranet",
      "internet",
      "servers.",
      "recommended",
      "restore",
      "default",
      "settings.",
      "url",
      "bar",
      "launch",
      "https",
      "8445",
      "credentials",
      "created",
      "during",
      "installation",
      "user",
      "name",
      "password",
      "fields.",
      "administrator",
      "changed",
      "time.",
      "click",
      "sign",
      "in.",
      "landing",
      "screen",
      "displays.",
      "icon",
      "top",
      "right",
      "corner",
      "application.",
      "ok",
      "confirm",
      "logout.",
      "closes",
      "login",
      "learn",
      "about",
      "interface",
      "see",
      "navigate",
      "designer.",
      "workspace.",
      "work",
      "source",
      "control",
      "management",
      "scm.",
      "project",
      "project.",
      "instructions",
      "import",
      "content",
      "packs",
      "dependencies"
    ],
    "language": "en",
    "word_count": 97,
    "importance_score": 5.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "use oo workflow designer",
    "contentLower": "this section shows how to set up your oo workflow designer workspace and how to use oo workflow designer for authoring. view system information you can view a system information report, which displays version and static system information, database connection information, and general system information. to view the system information report, enter the following text into your browser address line: http://<oo designer url>:<port number>/oo-designer/reports/sysinfo log in you can access the application using a supported web browser, from any computer with a network connection (intranet or internet) to the servers. it's recommended to restore your browser to the default settings. enter the following url into your browser address bar to launch oo workflow designer: https://<local host>:8445/oo-designer enter the oo workflow designer credentials created during installation for the user name and password fields. the default user is administrator if it was not changed at installation time. cl",
    "keywordsLower": [
      "https://<local",
      "http://<oo",
      "oo",
      "workflow",
      "designer",
      "view",
      "system",
      "information",
      "log",
      "out",
      "related",
      "topics",
      "section",
      "shows",
      "set",
      "workspace",
      "authoring.",
      "report",
      "displays",
      "version",
      "static",
      "database",
      "connection",
      "general",
      "information.",
      "enter",
      "following",
      "text",
      "browser",
      "address",
      "line",
      "http",
      "oo-designer",
      "reports",
      "sysinfo",
      "access",
      "application",
      "supported",
      "web",
      "any",
      "computer",
      "network",
      "intranet",
      "internet",
      "servers.",
      "recommended",
      "restore",
      "default",
      "settings.",
      "url",
      "bar",
      "launch",
      "https",
      "8445",
      "credentials",
      "created",
      "during",
      "installation",
      "user",
      "name",
      "password",
      "fields.",
      "administrator",
      "changed",
      "time.",
      "click",
      "sign",
      "in.",
      "landing",
      "screen",
      "displays.",
      "icon",
      "top",
      "right",
      "corner",
      "application.",
      "ok",
      "confirm",
      "logout.",
      "closes",
      "login",
      "learn",
      "about",
      "interface",
      "see",
      "navigate",
      "designer.",
      "workspace.",
      "work",
      "source",
      "control",
      "management",
      "scm.",
      "project",
      "project.",
      "instructions",
      "import",
      "content",
      "packs",
      "dependencies"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Work with SCM",
    "content": "Track local changes Click SCM icon to open the SCM pane. Click the Changes tab to see the changes that were made to the folders and files. Items that were modified, deleted, or added appear in distinct colors. Green - indicates that a new item has been added to the project, locally. Grey - indicates that an item has been removed from the project, locally. Blue - indicates that an item has been edited. Red - indicates that an item is in conflict. Manage changes using Git Stash The Git stash functionality allows you to: Flexibly manage changes on the imported Git repository locally. Save changes on a stack of unfinished changes and reapply at any time. To use stash functionality: Import a Git repository. Make changes such as modify, add, or delete files or folders of your project. The stash icon gets activated for new changes. To view the list of stashes click the Unstash icon . Click Stash icon to stash the changes with an appropriate description. The imported Git repository reverts to ",
    "url": "manageworkscm",
    "filename": "manageworkscm",
    "headings": [
      "Track local changes",
      "Manage changes using Git Stash",
      "Pull the most recent changes from the repository",
      "Commit and push your changes to a remote repository",
      "Resolve conflicts",
      "Revert to a previous version",
      "View the SCM message history",
      "Related topics"
    ],
    "keywords": [
      "work",
      "scm",
      "track",
      "local",
      "changes",
      "manage",
      "git",
      "stash",
      "pull",
      "most",
      "recent",
      "repository",
      "commit",
      "push",
      "remote",
      "resolve",
      "conflicts",
      "revert",
      "previous",
      "version",
      "view",
      "message",
      "history",
      "related",
      "topics",
      "click",
      "icon",
      "open",
      "pane.",
      "tab",
      "see",
      "made",
      "folders",
      "files.",
      "items",
      "modified",
      "deleted",
      "added",
      "appear",
      "distinct",
      "colors.",
      "green",
      "indicates",
      "new",
      "item",
      "project",
      "locally.",
      "grey",
      "removed",
      "blue",
      "edited.",
      "red",
      "conflict.",
      "functionality",
      "allows",
      "flexibly",
      "imported",
      "save",
      "stack",
      "unfinished",
      "reapply",
      "any",
      "time.",
      "import",
      "repository.",
      "make",
      "such",
      "modify",
      "add",
      "delete",
      "files",
      "project.",
      "gets",
      "activated",
      "changes.",
      "list",
      "stashes",
      "unstash",
      "appropriate",
      "description.",
      "reverts",
      "last",
      "state.",
      "visible",
      "select",
      "required",
      "apply",
      "want",
      "stashed",
      "change",
      "applied",
      "drop",
      "checkbox",
      "apply.",
      "stashes.",
      "button",
      "upload",
      "merged",
      "try",
      "again"
    ],
    "language": "en",
    "word_count": 107,
    "importance_score": 6.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "work with scm",
    "contentLower": "track local changes click scm icon to open the scm pane. click the changes tab to see the changes that were made to the folders and files. items that were modified, deleted, or added appear in distinct colors. green - indicates that a new item has been added to the project, locally. grey - indicates that an item has been removed from the project, locally. blue - indicates that an item has been edited. red - indicates that an item is in conflict. manage changes using git stash the git stash functionality allows you to: flexibly manage changes on the imported git repository locally. save changes on a stack of unfinished changes and reapply at any time. to use stash functionality: import a git repository. make changes such as modify, add, or delete files or folders of your project. the stash icon gets activated for new changes. to view the list of stashes click the unstash icon . click stash icon to stash the changes with an appropriate description. the imported git repository reverts to ",
    "keywordsLower": [
      "work",
      "scm",
      "track",
      "local",
      "changes",
      "manage",
      "git",
      "stash",
      "pull",
      "most",
      "recent",
      "repository",
      "commit",
      "push",
      "remote",
      "resolve",
      "conflicts",
      "revert",
      "previous",
      "version",
      "view",
      "message",
      "history",
      "related",
      "topics",
      "click",
      "icon",
      "open",
      "pane.",
      "tab",
      "see",
      "made",
      "folders",
      "files.",
      "items",
      "modified",
      "deleted",
      "added",
      "appear",
      "distinct",
      "colors.",
      "green",
      "indicates",
      "new",
      "item",
      "project",
      "locally.",
      "grey",
      "removed",
      "blue",
      "edited.",
      "red",
      "conflict.",
      "functionality",
      "allows",
      "flexibly",
      "imported",
      "save",
      "stack",
      "unfinished",
      "reapply",
      "any",
      "time.",
      "import",
      "repository.",
      "make",
      "such",
      "modify",
      "add",
      "delete",
      "files",
      "project.",
      "gets",
      "activated",
      "changes.",
      "list",
      "stashes",
      "unstash",
      "appropriate",
      "description.",
      "reverts",
      "last",
      "state.",
      "visible",
      "select",
      "required",
      "apply",
      "want",
      "stashed",
      "change",
      "applied",
      "drop",
      "checkbox",
      "apply.",
      "stashes.",
      "button",
      "upload",
      "merged",
      "try",
      "again"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "View the CloudSlang code",
    "content": "View the CloudSlang code about the inputs, outputs, and results of the step. You can see information about the step's inputs, outputs, and navigation steps in the CloudSlang code for the flow. To view the code, click the Show as Text button in the Authoring pane toolbar.. A text box appears, displaying the code. The details of the steps are displayed in the \"workflow:\" section. Related topics To view the YAML code snippets, see YAML file textual representation",
    "url": "viewcloudslangcode",
    "filename": "viewcloudslangcode",
    "headings": [
      "Related topics"
    ],
    "keywords": [
      "view",
      "cloudslang",
      "code",
      "related",
      "topics",
      "about",
      "inputs",
      "outputs",
      "results",
      "step.",
      "see",
      "information",
      "step",
      "navigation",
      "steps",
      "flow.",
      "click",
      "show",
      "text",
      "button",
      "authoring",
      "pane",
      "toolbar..",
      "box",
      "appears",
      "displaying",
      "code.",
      "details",
      "displayed",
      "workflow",
      "section.",
      "yaml",
      "snippets",
      "file",
      "textual",
      "representation"
    ],
    "language": "en",
    "word_count": 53,
    "importance_score": 2.5,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "view the cloudslang code",
    "contentLower": "view the cloudslang code about the inputs, outputs, and results of the step. you can see information about the step's inputs, outputs, and navigation steps in the cloudslang code for the flow. to view the code, click the show as text button in the authoring pane toolbar.. a text box appears, displaying the code. the details of the steps are displayed in the \"workflow:\" section. related topics to view the yaml code snippets, see yaml file textual representation",
    "keywordsLower": [
      "view",
      "cloudslang",
      "code",
      "related",
      "topics",
      "about",
      "inputs",
      "outputs",
      "results",
      "step.",
      "see",
      "information",
      "step",
      "navigation",
      "steps",
      "flow.",
      "click",
      "show",
      "text",
      "button",
      "authoring",
      "pane",
      "toolbar..",
      "box",
      "appears",
      "displaying",
      "code.",
      "details",
      "displayed",
      "workflow",
      "section.",
      "yaml",
      "snippets",
      "file",
      "textual",
      "representation"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "YAML file textual representation",
    "content": "You can view the YAML file corresponding to a selected flow, operation, decision, or system property, by clicking the Show as Text button in the Authoring pane toolbar. The YAML file includes the textual representation of the UI editor, so that each action done in the UI editor, such as, for example, adding inputs, editing outputs, adding steps, is reflected in the YAML file. It is not recommend to set a default constant value when an input and output is marked as sensitive. The values are displayed as asterisks in the file. Example of a typical file: namespace: newNCPFolder flow: name: newNCPflow inputs: - num_A: required: false - num_B: required: false workflow: - Addition: do_external: 37fbd782-48f2-4f66-b1b9-7f32c2b707bd: - value1: value: '${num_A}' prompt: type: text message: Enter the first number - value2: value: '${num_B}' prompt: type: text message: Enter the second number navigate: - success: SUCCESS - failure: on_failure results: - FAILURE - SUCCESS extensions: graph: steps:",
    "url": "yamlfiletextual",
    "filename": "yamlfiletextual",
    "headings": [
      "Related topics"
    ],
    "keywords": [
      "yaml",
      "file",
      "textual",
      "representation",
      "related",
      "topics",
      "view",
      "corresponding",
      "selected",
      "flow",
      "operation",
      "decision",
      "system",
      "property",
      "clicking",
      "show",
      "text",
      "button",
      "authoring",
      "pane",
      "toolbar.",
      "includes",
      "ui",
      "editor",
      "action",
      "done",
      "such",
      "example",
      "adding",
      "inputs",
      "editing",
      "outputs",
      "steps",
      "reflected",
      "file.",
      "recommend",
      "set",
      "default",
      "constant",
      "value",
      "input",
      "output",
      "marked",
      "sensitive.",
      "values",
      "displayed",
      "asterisks",
      "typical",
      "namespace",
      "newncpfolder",
      "name",
      "newncpflow",
      "required",
      "false",
      "workflow",
      "addition",
      "37fbd782-48f2-4f66-b1b9-7f32c2b707bd",
      "value1",
      "prompt",
      "type",
      "message",
      "enter",
      "first",
      "number",
      "value2",
      "second",
      "navigate",
      "success",
      "failure",
      "results",
      "extensions",
      "graph",
      "148",
      "103",
      "138a1cef-93f8-cbc2-6b21-db2c15547016",
      "targetid",
      "e8982169-eb85-6ce5-d90a-82d01d5f7642",
      "port",
      "290",
      "100",
      "part",
      "starting",
      "displays",
      "contents",
      "description",
      "item",
      "well",
      "result.",
      "provides",
      "cloudsland",
      "code",
      "corresponds",
      "information",
      "about",
      "entered",
      "editor.",
      "third",
      "cloudslang",
      "enables",
      "graphical"
    ],
    "language": "en",
    "word_count": 106,
    "importance_score": 3.5,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "yaml file textual representation",
    "contentLower": "you can view the yaml file corresponding to a selected flow, operation, decision, or system property, by clicking the show as text button in the authoring pane toolbar. the yaml file includes the textual representation of the ui editor, so that each action done in the ui editor, such as, for example, adding inputs, editing outputs, adding steps, is reflected in the yaml file. it is not recommend to set a default constant value when an input and output is marked as sensitive. the values are displayed as asterisks in the file. example of a typical file: namespace: newncpfolder flow: name: newncpflow inputs: - num_a: required: false - num_b: required: false workflow: - addition: do_external: 37fbd782-48f2-4f66-b1b9-7f32c2b707bd: - value1: value: '${num_a}' prompt: type: text message: enter the first number - value2: value: '${num_b}' prompt: type: text message: enter the second number navigate: - success: success - failure: on_failure results: - failure - success extensions: graph: steps:",
    "keywordsLower": [
      "yaml",
      "file",
      "textual",
      "representation",
      "related",
      "topics",
      "view",
      "corresponding",
      "selected",
      "flow",
      "operation",
      "decision",
      "system",
      "property",
      "clicking",
      "show",
      "text",
      "button",
      "authoring",
      "pane",
      "toolbar.",
      "includes",
      "ui",
      "editor",
      "action",
      "done",
      "such",
      "example",
      "adding",
      "inputs",
      "editing",
      "outputs",
      "steps",
      "reflected",
      "file.",
      "recommend",
      "set",
      "default",
      "constant",
      "value",
      "input",
      "output",
      "marked",
      "sensitive.",
      "values",
      "displayed",
      "asterisks",
      "typical",
      "namespace",
      "newncpfolder",
      "name",
      "newncpflow",
      "required",
      "false",
      "workflow",
      "addition",
      "37fbd782-48f2-4f66-b1b9-7f32c2b707bd",
      "value1",
      "prompt",
      "type",
      "message",
      "enter",
      "first",
      "number",
      "value2",
      "second",
      "navigate",
      "success",
      "failure",
      "results",
      "extensions",
      "graph",
      "148",
      "103",
      "138a1cef-93f8-cbc2-6b21-db2c15547016",
      "targetid",
      "e8982169-eb85-6ce5-d90a-82d01d5f7642",
      "port",
      "290",
      "100",
      "part",
      "starting",
      "displays",
      "contents",
      "description",
      "item",
      "well",
      "result.",
      "provides",
      "cloudsland",
      "code",
      "corresponds",
      "information",
      "about",
      "entered",
      "editor.",
      "third",
      "cloudslang",
      "enables",
      "graphical"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Validate flows",
    "content": "There are a number of built-in validation errors and warning in OO Workflow Designer. It is highly recommended to check that your flows are valid before exporting your content to a content pack, as invalid content will not be exported to content packs. This section provides the location of errors and warnings appearing in the UI. View errors If there is an error anywhere in the Project pane or Dependencies pane, (in a flow, operation, or system property), the item with the error is displayed with a red underline. All flows that use this item and the folders above it are also displayed with a red underline. When you fix the error, the red lines disappear under that item and under the folders that contain it or flows that use it. As soon as you add or create a flow, OO Workflow Designer automatically runs the validation and displays all errors underlined. There is no need to do anything to start this process. Authoring pane Flow tabs. If there is any error on the flow\\operation, an error",
    "url": "designervalidateflow",
    "filename": "designervalidateflow",
    "headings": [
      "View errors",
      "Authoring pane",
      "Check for errors in the step properties",
      "View warnings",
      "Related topics"
    ],
    "keywords": [
      "validate",
      "flows",
      "view",
      "errors",
      "authoring",
      "pane",
      "check",
      "step",
      "properties",
      "warnings",
      "related",
      "topics",
      "there",
      "number",
      "built-in",
      "validation",
      "warning",
      "oo",
      "workflow",
      "designer.",
      "highly",
      "recommended",
      "valid",
      "before",
      "exporting",
      "content",
      "pack",
      "invalid",
      "exported",
      "packs.",
      "section",
      "provides",
      "location",
      "appearing",
      "ui.",
      "error",
      "anywhere",
      "project",
      "dependencies",
      "flow",
      "operation",
      "system",
      "property",
      "item",
      "displayed",
      "red",
      "underline.",
      "all",
      "folders",
      "above",
      "fix",
      "lines",
      "disappear",
      "under",
      "contain",
      "it.",
      "soon",
      "add",
      "create",
      "designer",
      "automatically",
      "runs",
      "displays",
      "underlined.",
      "need",
      "anything",
      "start",
      "process.",
      "tabs.",
      "any",
      "flag",
      "appears",
      "tab.",
      "click",
      "display",
      "tooltip",
      "detailed",
      "list",
      "errors.",
      "inner",
      "graph",
      "tabs",
      "top",
      "pane.",
      "includes",
      "representing",
      "indications",
      "step.",
      "left",
      "corner.",
      "tip",
      "information",
      "about",
      "error.",
      "missing",
      "dependency",
      "example",
      "based",
      "deleted",
      "gray"
    ],
    "language": "en",
    "word_count": 100,
    "importance_score": 5.5,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "validate flows",
    "contentLower": "there are a number of built-in validation errors and warning in oo workflow designer. it is highly recommended to check that your flows are valid before exporting your content to a content pack, as invalid content will not be exported to content packs. this section provides the location of errors and warnings appearing in the ui. view errors if there is an error anywhere in the project pane or dependencies pane, (in a flow, operation, or system property), the item with the error is displayed with a red underline. all flows that use this item and the folders above it are also displayed with a red underline. when you fix the error, the red lines disappear under that item and under the folders that contain it or flows that use it. as soon as you add or create a flow, oo workflow designer automatically runs the validation and displays all errors underlined. there is no need to do anything to start this process. authoring pane flow tabs. if there is any error on the flow\\operation, an error",
    "keywordsLower": [
      "validate",
      "flows",
      "view",
      "errors",
      "authoring",
      "pane",
      "check",
      "step",
      "properties",
      "warnings",
      "related",
      "topics",
      "there",
      "number",
      "built-in",
      "validation",
      "warning",
      "oo",
      "workflow",
      "designer.",
      "highly",
      "recommended",
      "valid",
      "before",
      "exporting",
      "content",
      "pack",
      "invalid",
      "exported",
      "packs.",
      "section",
      "provides",
      "location",
      "appearing",
      "ui.",
      "error",
      "anywhere",
      "project",
      "dependencies",
      "flow",
      "operation",
      "system",
      "property",
      "item",
      "displayed",
      "red",
      "underline.",
      "all",
      "folders",
      "above",
      "fix",
      "lines",
      "disappear",
      "under",
      "contain",
      "it.",
      "soon",
      "add",
      "create",
      "designer",
      "automatically",
      "runs",
      "displays",
      "underlined.",
      "need",
      "anything",
      "start",
      "process.",
      "tabs.",
      "any",
      "flag",
      "appears",
      "tab.",
      "click",
      "display",
      "tooltip",
      "detailed",
      "list",
      "errors.",
      "inner",
      "graph",
      "tabs",
      "top",
      "pane.",
      "includes",
      "representing",
      "indications",
      "step.",
      "left",
      "corner.",
      "tip",
      "information",
      "about",
      "error.",
      "missing",
      "dependency",
      "example",
      "based",
      "deleted",
      "gray"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "View AFL flows in OO Workflow Designer",
    "content": "Operations Orchestration (OO) Workflow Designer displays a read-only view of AFL flows authored in OO Studio. In OO Workflow Designer, you can view a graphical representation of AFL flows in the GRAPH tab. You can view flow level Inputs, Outputs, Scriptlet, and other flow properties in the PROPERTIES tab. Note: Debugging for AFL flows isn't yet supported. View AFL flows To view AFL flows in OO Workflow Designer, in the Dependencies pane, navigate to the folder containing the flow, and double-click the flow. The selected flow displays in the authoring pane in read-only mode. The Dependencies pane now displays an icon-based differentiation between AFL Content Packs and CloudSlang Content Packs. UI elements Description Blue folder icon represents the AFL flow. Green folder icon represents the CloudSlang (CS) flow. To view step information of a step in the canvas, see View step details in AFL flows. View flow graphical representation To view the graphical representation of the selected flo",
    "url": "viewaflflowswfd",
    "filename": "viewaflflowswfd",
    "headings": [
      "View AFL flows",
      "View flow graphical representation",
      "View flow properties"
    ],
    "keywords": [
      "view",
      "afl",
      "flows",
      "oo",
      "workflow",
      "designer",
      "flow",
      "graphical",
      "representation",
      "properties",
      "operations",
      "orchestration",
      "displays",
      "read-only",
      "authored",
      "studio.",
      "graph",
      "tab.",
      "level",
      "inputs",
      "outputs",
      "scriptlet",
      "note",
      "debugging",
      "isn",
      "yet",
      "supported.",
      "dependencies",
      "pane",
      "navigate",
      "folder",
      "containing",
      "double-click",
      "flow.",
      "selected",
      "authoring",
      "mode.",
      "now",
      "icon-based",
      "differentiation",
      "between",
      "content",
      "packs",
      "cloudslang",
      "packs.",
      "ui",
      "elements",
      "description",
      "blue",
      "icon",
      "represents",
      "green",
      "cs",
      "step",
      "information",
      "canvas",
      "see",
      "details",
      "flows.",
      "click",
      "default",
      "tab",
      "comes",
      "new",
      "icons",
      "color",
      "schemes",
      "compared",
      "desktop",
      "any",
      "discrepancies",
      "studio",
      "occur",
      "both",
      "steps",
      "transitions",
      "callouts",
      "due",
      "slight",
      "alignment",
      "look",
      "feel.",
      "example",
      "width",
      "height",
      "greater",
      "ones",
      "shorter",
      "thus",
      "closer",
      "all",
      "annotations",
      "however",
      "aren",
      "supported",
      "annotation",
      "definition",
      "missing",
      "such",
      "designer."
    ],
    "language": "en",
    "word_count": 120,
    "importance_score": 3.5,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "view afl flows in oo workflow designer",
    "contentLower": "operations orchestration (oo) workflow designer displays a read-only view of afl flows authored in oo studio. in oo workflow designer, you can view a graphical representation of afl flows in the graph tab. you can view flow level inputs, outputs, scriptlet, and other flow properties in the properties tab. note: debugging for afl flows isn't yet supported. view afl flows to view afl flows in oo workflow designer, in the dependencies pane, navigate to the folder containing the flow, and double-click the flow. the selected flow displays in the authoring pane in read-only mode. the dependencies pane now displays an icon-based differentiation between afl content packs and cloudslang content packs. ui elements description blue folder icon represents the afl flow. green folder icon represents the cloudslang (cs) flow. to view step information of a step in the canvas, see view step details in afl flows. view flow graphical representation to view the graphical representation of the selected flo",
    "keywordsLower": [
      "view",
      "afl",
      "flows",
      "oo",
      "workflow",
      "designer",
      "flow",
      "graphical",
      "representation",
      "properties",
      "operations",
      "orchestration",
      "displays",
      "read-only",
      "authored",
      "studio.",
      "graph",
      "tab.",
      "level",
      "inputs",
      "outputs",
      "scriptlet",
      "note",
      "debugging",
      "isn",
      "yet",
      "supported.",
      "dependencies",
      "pane",
      "navigate",
      "folder",
      "containing",
      "double-click",
      "flow.",
      "selected",
      "authoring",
      "mode.",
      "now",
      "icon-based",
      "differentiation",
      "between",
      "content",
      "packs",
      "cloudslang",
      "packs.",
      "ui",
      "elements",
      "description",
      "blue",
      "icon",
      "represents",
      "green",
      "cs",
      "step",
      "information",
      "canvas",
      "see",
      "details",
      "flows.",
      "click",
      "default",
      "tab",
      "comes",
      "new",
      "icons",
      "color",
      "schemes",
      "compared",
      "desktop",
      "any",
      "discrepancies",
      "studio",
      "occur",
      "both",
      "steps",
      "transitions",
      "callouts",
      "due",
      "slight",
      "alignment",
      "look",
      "feel.",
      "example",
      "width",
      "height",
      "greater",
      "ones",
      "shorter",
      "thus",
      "closer",
      "all",
      "annotations",
      "however",
      "aren",
      "supported",
      "annotation",
      "definition",
      "missing",
      "such",
      "designer."
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Work with AFL multi-instance steps",
    "content": "A multi-instance step can be a single or a group of steps that execute simultaneously. For example, if you want to run the Windows Diagnostic flow on 100 servers, you can create a multi-instance step that runs the flow on all 100 servers at the same time. The targets of the operation (for example, 100 servers) are defined in an input list in the multi-instance step. Inside a multi-instance step, you can include one or more operations or subflows. The operations and subflows in the multi-instance step run once for each element from the list—these runs are known as lanes or instances. Each instance gets, at its beginning, a duplication of the global and local contexts. As it runs, each step in the instance can change the global variables, flow variables, and flow output fields within the multi-instance step. When an exception is thrown in one of the instances, that instance is stopped. The others continue to run because they're running in parallel. If running the multi-instance step agai",
    "url": "aflmiedit",
    "filename": "aflmiedit",
    "headings": [
      "Save flow data",
      "Save data via results",
      "Save data via a scriptlet",
      "Create a multi-instance step",
      "Save output from a multi-instance step",
      "Limit (throttle) the number of instances a multi-instance step can run on simultaneously",
      "Move a multi-instance step",
      "Resize a multi-instance step"
    ],
    "keywords": [
      "scriptletBranchContext.get",
      "scriptletContext.get",
      "work",
      "afl",
      "multi-instance",
      "steps",
      "save",
      "flow",
      "data",
      "via",
      "results",
      "scriptlet",
      "create",
      "step",
      "output",
      "limit",
      "throttle",
      "number",
      "instances",
      "run",
      "simultaneously",
      "move",
      "resize",
      "single",
      "group",
      "execute",
      "simultaneously.",
      "example",
      "want",
      "windows",
      "diagnostic",
      "100",
      "servers",
      "runs",
      "all",
      "same",
      "time.",
      "targets",
      "operation",
      "defined",
      "input",
      "list",
      "step.",
      "inside",
      "include",
      "one",
      "operations",
      "subflows.",
      "subflows",
      "once",
      "element",
      "known",
      "lanes",
      "instances.",
      "instance",
      "gets",
      "beginning",
      "duplication",
      "global",
      "local",
      "contexts.",
      "change",
      "variables",
      "fields",
      "exception",
      "thrown",
      "stopped.",
      "others",
      "continue",
      "because",
      "re",
      "running",
      "parallel.",
      "against",
      "too",
      "many",
      "elements",
      "slow",
      "infrastructure",
      "limiting",
      "values",
      "process",
      "once.",
      "throttling",
      "size",
      "constant",
      "integer",
      "take",
      "value",
      "variable",
      "systemproperty",
      "created",
      "populated.",
      "field",
      "disappear",
      "end",
      "lane",
      "unless",
      "following",
      "ways"
    ],
    "language": "en",
    "word_count": 95,
    "importance_score": 6.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "work with afl multi-instance steps",
    "contentLower": "a multi-instance step can be a single or a group of steps that execute simultaneously. for example, if you want to run the windows diagnostic flow on 100 servers, you can create a multi-instance step that runs the flow on all 100 servers at the same time. the targets of the operation (for example, 100 servers) are defined in an input list in the multi-instance step. inside a multi-instance step, you can include one or more operations or subflows. the operations and subflows in the multi-instance step run once for each element from the list—these runs are known as lanes or instances. each instance gets, at its beginning, a duplication of the global and local contexts. as it runs, each step in the instance can change the global variables, flow variables, and flow output fields within the multi-instance step. when an exception is thrown in one of the instances, that instance is stopped. the others continue to run because they're running in parallel. if running the multi-instance step agai",
    "keywordsLower": [
      "scriptletbranchcontext.get",
      "scriptletcontext.get",
      "work",
      "afl",
      "multi-instance",
      "steps",
      "save",
      "flow",
      "data",
      "via",
      "results",
      "scriptlet",
      "create",
      "step",
      "output",
      "limit",
      "throttle",
      "number",
      "instances",
      "run",
      "simultaneously",
      "move",
      "resize",
      "single",
      "group",
      "execute",
      "simultaneously.",
      "example",
      "want",
      "windows",
      "diagnostic",
      "100",
      "servers",
      "runs",
      "all",
      "same",
      "time.",
      "targets",
      "operation",
      "defined",
      "input",
      "list",
      "step.",
      "inside",
      "include",
      "one",
      "operations",
      "subflows.",
      "subflows",
      "once",
      "element",
      "known",
      "lanes",
      "instances.",
      "instance",
      "gets",
      "beginning",
      "duplication",
      "global",
      "local",
      "contexts.",
      "change",
      "variables",
      "fields",
      "exception",
      "thrown",
      "stopped.",
      "others",
      "continue",
      "because",
      "re",
      "running",
      "parallel.",
      "against",
      "too",
      "many",
      "elements",
      "slow",
      "infrastructure",
      "limiting",
      "values",
      "process",
      "once.",
      "throttling",
      "size",
      "constant",
      "integer",
      "take",
      "value",
      "variable",
      "systemproperty",
      "created",
      "populated.",
      "field",
      "disappear",
      "end",
      "lane",
      "unless",
      "following",
      "ways"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Use Content Generator for REST API",
    "content": "The Content Generator enables you to create a project containing the CloudSlang flows based on URL to Resource Listing or local API Definition files. The Content Generator supports the following formats: Swagger 1.0, 2.0, 3.0 (OpenAPI) Web Application Description Language (WADL) To start generating the content for REST API: On the OO Workflow Designer interface, click PROJECTS tab, and then click Open Content Generator . A new window of the Content Generator displays. Click Swagger or WADL to select your API definition format. In the API DEFINITIONS area, click URL or Upload to choose the API definitions template: If you choose URL, enter the address of the Swagger or WADL Resource Listing in the Enter URL text box. Click BACK if you wish to go back to the earlier screen. If you choose Upload, browse and select a compatible file format from your local file system as listed below: Swagger: .json or .yaml WADL: .wadl Click Get Data. The connection to the resource listing starts and may p",
    "url": "generatecontentrestapi",
    "filename": "generatecontentrestapi",
    "headings": [
      "Related topics"
    ],
    "keywords": [
      "2.0",
      "1.0",
      "3.0",
      "content",
      "generator",
      "rest",
      "api",
      "related",
      "topics",
      "enables",
      "create",
      "project",
      "containing",
      "cloudslang",
      "flows",
      "based",
      "url",
      "resource",
      "listing",
      "local",
      "definition",
      "files.",
      "supports",
      "following",
      "formats",
      "swagger",
      "openapi",
      "web",
      "application",
      "description",
      "language",
      "wadl",
      "start",
      "generating",
      "oo",
      "workflow",
      "designer",
      "interface",
      "click",
      "projects",
      "tab",
      "open",
      "new",
      "window",
      "displays.",
      "select",
      "format.",
      "definitions",
      "area",
      "upload",
      "choose",
      "template",
      "enter",
      "address",
      "text",
      "box.",
      "back",
      "wish",
      "go",
      "earlier",
      "screen.",
      "browse",
      "compatible",
      "file",
      "format",
      "system",
      "listed",
      "below",
      ".json",
      ".yaml",
      ".wadl",
      "get",
      "data.",
      "connection",
      "starts",
      "prompt",
      "extra",
      "configuration",
      "details",
      "setting",
      "proxy",
      "settings",
      "fill",
      "host",
      "hostname",
      "establish",
      "connection.",
      "port",
      "number",
      "hostname.",
      "username",
      "optional",
      "valid",
      "access",
      "host.",
      "password",
      "set",
      "username.",
      "authentication",
      "drop-down"
    ],
    "language": "en",
    "word_count": 117,
    "importance_score": 2.5,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "use content generator for rest api",
    "contentLower": "the content generator enables you to create a project containing the cloudslang flows based on url to resource listing or local api definition files. the content generator supports the following formats: swagger 1.0, 2.0, 3.0 (openapi) web application description language (wadl) to start generating the content for rest api: on the oo workflow designer interface, click projects tab, and then click open content generator . a new window of the content generator displays. click swagger or wadl to select your api definition format. in the api definitions area, click url or upload to choose the api definitions template: if you choose url, enter the address of the swagger or wadl resource listing in the enter url text box. click back if you wish to go back to the earlier screen. if you choose upload, browse and select a compatible file format from your local file system as listed below: swagger: .json or .yaml wadl: .wadl click get data. the connection to the resource listing starts and may p",
    "keywordsLower": [
      "2.0",
      "1.0",
      "3.0",
      "content",
      "generator",
      "rest",
      "api",
      "related",
      "topics",
      "enables",
      "create",
      "project",
      "containing",
      "cloudslang",
      "flows",
      "based",
      "url",
      "resource",
      "listing",
      "local",
      "definition",
      "files.",
      "supports",
      "following",
      "formats",
      "swagger",
      "openapi",
      "web",
      "application",
      "description",
      "language",
      "wadl",
      "start",
      "generating",
      "oo",
      "workflow",
      "designer",
      "interface",
      "click",
      "projects",
      "tab",
      "open",
      "new",
      "window",
      "displays.",
      "select",
      "format.",
      "definitions",
      "area",
      "upload",
      "choose",
      "template",
      "enter",
      "address",
      "text",
      "box.",
      "back",
      "wish",
      "go",
      "earlier",
      "screen.",
      "browse",
      "compatible",
      "file",
      "format",
      "system",
      "listed",
      "below",
      ".json",
      ".yaml",
      ".wadl",
      "get",
      "data.",
      "connection",
      "starts",
      "prompt",
      "extra",
      "configuration",
      "details",
      "setting",
      "proxy",
      "settings",
      "fill",
      "host",
      "hostname",
      "establish",
      "connection.",
      "port",
      "number",
      "hostname.",
      "username",
      "optional",
      "valid",
      "access",
      "host.",
      "password",
      "set",
      "username.",
      "authentication",
      "drop-down"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Use CloudSlang files created outside OO Workflow Designer",
    "content": "Before importing CloudSlang content to OO Workflow Designer, you need to create a content pack. You can also create content packs with OO Shell for Authoring (OOSHA) and use it in OO Workflow Designer as a dependency if it has CloudSlang content. After running OOSHA, you can import the content pack to OO Workflow Designer; the content pack then appears in the Dependencies tab. Before creating the content pack, it is recommended to run the build tool in CloudSlang. The build tool validates the content against failures during import to OO Workflow Designer. Create a folder with the name of your content pack, and create the folder structure inside it, as follows: <Content Pack folder name>\\Content\\Library <Content Pack folder name>\\Lib Place your CloudSlang content in the Library folder. You can organize it into sub-folders inside the Library folder. Create a text file and name it contentpack.properties. Add the following properties to the file: content.pack.name=slang-content-master cont",
    "url": "useexternalcloudslangfiles",
    "filename": "useexternalcloudslangfiles",
    "headings": [
      "Related topics"
    ],
    "keywords": [
      "content.pack",
      "1.0.0",
      "cloudslang",
      "files",
      "created",
      "outside",
      "oo",
      "workflow",
      "designer",
      "related",
      "topics",
      "before",
      "importing",
      "content",
      "need",
      "create",
      "pack.",
      "packs",
      "shell",
      "authoring",
      "oosha",
      "dependency",
      "content.",
      "after",
      "running",
      "import",
      "pack",
      "appears",
      "dependencies",
      "tab.",
      "creating",
      "recommended",
      "run",
      "build",
      "tool",
      "cloudslang.",
      "validates",
      "against",
      "failures",
      "during",
      "designer.",
      "folder",
      "name",
      "structure",
      "inside",
      "follows",
      "library",
      "lib",
      "place",
      "folder.",
      "organize",
      "sub-folders",
      "text",
      "file",
      "contentpack.properties.",
      "add",
      "following",
      "properties",
      "content.pack.name",
      "slang-content-master",
      "content.pack.version",
      "content.pack.description",
      "content.pack.publisher",
      "store",
      "contentpack.properties",
      "top",
      "level",
      "same",
      "folders.",
      ".jar",
      "any",
      "creates",
      "zip",
      "files.",
      "rename",
      "suffix",
      "jar.",
      "continue",
      "steps",
      "workspace",
      "topic.",
      "instructions",
      "see",
      "pane"
    ],
    "language": "en",
    "word_count": 100,
    "importance_score": 2.5,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "use cloudslang files created outside oo workflow designer",
    "contentLower": "before importing cloudslang content to oo workflow designer, you need to create a content pack. you can also create content packs with oo shell for authoring (oosha) and use it in oo workflow designer as a dependency if it has cloudslang content. after running oosha, you can import the content pack to oo workflow designer; the content pack then appears in the dependencies tab. before creating the content pack, it is recommended to run the build tool in cloudslang. the build tool validates the content against failures during import to oo workflow designer. create a folder with the name of your content pack, and create the folder structure inside it, as follows: <content pack folder name>\\content\\library <content pack folder name>\\lib place your cloudslang content in the library folder. you can organize it into sub-folders inside the library folder. create a text file and name it contentpack.properties. add the following properties to the file: content.pack.name=slang-content-master cont",
    "keywordsLower": [
      "content.pack",
      "1.0.0",
      "cloudslang",
      "files",
      "created",
      "outside",
      "oo",
      "workflow",
      "designer",
      "related",
      "topics",
      "before",
      "importing",
      "content",
      "need",
      "create",
      "pack.",
      "packs",
      "shell",
      "authoring",
      "oosha",
      "dependency",
      "content.",
      "after",
      "running",
      "import",
      "pack",
      "appears",
      "dependencies",
      "tab.",
      "creating",
      "recommended",
      "run",
      "build",
      "tool",
      "cloudslang.",
      "validates",
      "against",
      "failures",
      "during",
      "designer.",
      "folder",
      "name",
      "structure",
      "inside",
      "follows",
      "library",
      "lib",
      "place",
      "folder.",
      "organize",
      "sub-folders",
      "text",
      "file",
      "contentpack.properties.",
      "add",
      "following",
      "properties",
      "content.pack.name",
      "slang-content-master",
      "content.pack.version",
      "content.pack.description",
      "content.pack.publisher",
      "store",
      "contentpack.properties",
      "top",
      "level",
      "same",
      "folders.",
      ".jar",
      "any",
      "creates",
      "zip",
      "files.",
      "rename",
      "suffix",
      "jar.",
      "continue",
      "steps",
      "workspace",
      "topic.",
      "instructions",
      "see",
      "pane"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Upgrade fails with \"Ingress should allow https only.\" error on AKS",
    "content": "If your deployment is running on AKS and the policy “Kubernetes clusters should be accessible only over HTTPS”  is enabled, the upgrade process will fail with the following error:Error: UPGRADE FAILED: failed to create resource: admission webhook \"validation.gatekeeper.sh\" denied the request: [azurepolicy-k8sazurev1ingresshttpsonly-<id>] Ingress should allow https only. tls configuration and annotation nginx.ingress.kubernetes.io/force-ssl-redirect=true are required for itom-esm-api-ingress CauseThe issue occurs if TLS is not configured for the ingress deployed in the Suite.SolutionIf the built-in Azure policy Kubernetes clusters should be accessible only over HTTPS is enabled, Suite upgrade on AKS fails with the error 'Ingress should allow HTTPS only'. To fix the error, you must  configure TLS for all the ingress deployed in the Suite. Complete the following steps to configure TLS. Make sure you replace the following placeholders with values from your deployment environment: <release ",
    "url": "upgradefailsingresshttpserr",
    "filename": "upgradefailsingresshttpserr",
    "headings": [
      "Cause",
      "Solution"
    ],
    "keywords": [
      "gatekeeper.sh",
      "kubernetes.io",
      "spec.tls",
      "metadata.name",
      "values.yaml",
      "upgrade",
      "fails",
      "ingress",
      "allow",
      "https",
      "only.",
      "error",
      "aks",
      "cause",
      "solution",
      "deployment",
      "running",
      "policy",
      "kubernetes",
      "clusters",
      "accessible",
      "over",
      "enabled",
      "process",
      "fail",
      "following",
      "failed",
      "create",
      "resource",
      "admission",
      "webhook",
      "validation.gatekeeper.sh",
      "denied",
      "request",
      "azurepolicy-k8sazurev1ingresshttpsonly-",
      "tls",
      "configuration",
      "annotation",
      "nginx.ingress.kubernetes.io",
      "force-ssl-redirect",
      "true",
      "required",
      "itom-esm-api-ingress",
      "causethe",
      "issue",
      "occurs",
      "configured",
      "deployed",
      "suite.solutionif",
      "built-in",
      "azure",
      "suite",
      "fix",
      "configure",
      "all",
      "suite.",
      "complete",
      "steps",
      "tls.",
      "make",
      "sure",
      "replace",
      "placeholders",
      "values",
      "environment",
      "release",
      "name",
      "provided",
      "installed",
      "namespace.",
      "actual",
      "access",
      "host",
      "name.",
      "run",
      "command",
      "fetch",
      "externalaccesshost",
      "parameter",
      "value",
      "file.",
      "corresponds",
      "external",
      "helm",
      "get",
      "-n",
      "-o",
      "json",
      "jq",
      "-r",
      ".global.externalaccesshost",
      "placeholder",
      "retrieved",
      "earlier",
      "step.",
      "kubectl",
      "jsonpath",
      "range",
      ".items",
      ".metadata.name"
    ],
    "language": "en",
    "word_count": 94,
    "importance_score": 2.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "upgrade fails with \"ingress should allow https only.\" error on aks",
    "contentLower": "if your deployment is running on aks and the policy “kubernetes clusters should be accessible only over https”  is enabled, the upgrade process will fail with the following error:error: upgrade failed: failed to create resource: admission webhook \"validation.gatekeeper.sh\" denied the request: [azurepolicy-k8sazurev1ingresshttpsonly-<id>] ingress should allow https only. tls configuration and annotation nginx.ingress.kubernetes.io/force-ssl-redirect=true are required for itom-esm-api-ingress causethe issue occurs if tls is not configured for the ingress deployed in the suite.solutionif the built-in azure policy kubernetes clusters should be accessible only over https is enabled, suite upgrade on aks fails with the error 'ingress should allow https only'. to fix the error, you must  configure tls for all the ingress deployed in the suite. complete the following steps to configure tls. make sure you replace the following placeholders with values from your deployment environment: <release ",
    "keywordsLower": [
      "gatekeeper.sh",
      "kubernetes.io",
      "spec.tls",
      "metadata.name",
      "values.yaml",
      "upgrade",
      "fails",
      "ingress",
      "allow",
      "https",
      "only.",
      "error",
      "aks",
      "cause",
      "solution",
      "deployment",
      "running",
      "policy",
      "kubernetes",
      "clusters",
      "accessible",
      "over",
      "enabled",
      "process",
      "fail",
      "following",
      "failed",
      "create",
      "resource",
      "admission",
      "webhook",
      "validation.gatekeeper.sh",
      "denied",
      "request",
      "azurepolicy-k8sazurev1ingresshttpsonly-",
      "tls",
      "configuration",
      "annotation",
      "nginx.ingress.kubernetes.io",
      "force-ssl-redirect",
      "true",
      "required",
      "itom-esm-api-ingress",
      "causethe",
      "issue",
      "occurs",
      "configured",
      "deployed",
      "suite.solutionif",
      "built-in",
      "azure",
      "suite",
      "fix",
      "configure",
      "all",
      "suite.",
      "complete",
      "steps",
      "tls.",
      "make",
      "sure",
      "replace",
      "placeholders",
      "values",
      "environment",
      "release",
      "name",
      "provided",
      "installed",
      "namespace.",
      "actual",
      "access",
      "host",
      "name.",
      "run",
      "command",
      "fetch",
      "externalaccesshost",
      "parameter",
      "value",
      "file.",
      "corresponds",
      "external",
      "helm",
      "get",
      "-n",
      "-o",
      "json",
      "jq",
      "-r",
      ".global.externalaccesshost",
      "placeholder",
      "retrieved",
      "earlier",
      "step.",
      "kubectl",
      "jsonpath",
      "range",
      ".items",
      ".metadata.name"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Upgrade pre-check fails with \"dial tcp: lookup registry.hub.docker.com\" error",
    "content": "When you try to upgrade to OMT 2022.05, the upgrade fails during the preliminary check, and you receive an error message that resembles the following: Error: dial tcp: lookup registry.hub.docker.com on 10.123.45.67:89: server misbehaving This issue occurs when you use an external registry, such as registry.hub.docker.com. Cause Possible causes: Cause 1: Your DNS server isn't working correctly. Cause 2: Your registry CA for registry.hub.docker.com isn't correct. Solution First, check whether a DNS server problem is causing the issue. Run the following command to check if your DNS server can resolve the registry to the corresponding IP: nslookup <registry> For example, if your external registry is registry.hub.docker.com, run the following command: nslookup registry.hub.docker.com Compare the result with the IP addresses that you obtained through a DNS authority. If they don't match, ask for your IT administrator to fix the DNS problem. You can change to an available nameserver by updati",
    "url": "upgradeprecheckfails",
    "filename": "upgradeprecheckfails",
    "headings": [
      "Cause",
      "Solution"
    ],
    "keywords": [
      "restart.sh",
      "2022.05",
      "45.67",
      "10.123",
      "10.123.45.67",
      "10.123.45",
      "registry.hub",
      "docker.com",
      "resolv.conf",
      "upgrade",
      "pre-check",
      "fails",
      "dial",
      "tcp",
      "lookup",
      "registry.hub.docker.com",
      "error",
      "cause",
      "solution",
      "try",
      "omt",
      "during",
      "preliminary",
      "check",
      "receive",
      "message",
      "resembles",
      "following",
      "89",
      "server",
      "misbehaving",
      "issue",
      "occurs",
      "external",
      "registry",
      "such",
      "registry.hub.docker.com.",
      "possible",
      "causes",
      "dns",
      "isn",
      "working",
      "correctly.",
      "ca",
      "correct.",
      "first",
      "whether",
      "problem",
      "causing",
      "issue.",
      "run",
      "command",
      "resolve",
      "corresponding",
      "ip",
      "nslookup",
      "example",
      "compare",
      "result",
      "addresses",
      "obtained",
      "through",
      "authority.",
      "don",
      "match",
      "ask",
      "administrator",
      "fix",
      "problem.",
      "change",
      "available",
      "nameserver",
      "updating",
      "etc",
      "file.",
      "fixed",
      "openssl",
      "-connect",
      "443",
      "returns",
      "handshake",
      "failure",
      "update",
      "ca.",
      "copy",
      "certificate",
      "directory",
      "cp",
      "pki",
      "ca-trust",
      "source",
      "anchors",
      "load",
      "private",
      "update-ca-trust",
      "extract",
      "restart",
      "kubernetes",
      "services",
      "import"
    ],
    "language": "en",
    "word_count": 105,
    "importance_score": 3.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "upgrade pre-check fails with \"dial tcp: lookup registry.hub.docker.com\" error",
    "contentLower": "when you try to upgrade to omt 2022.05, the upgrade fails during the preliminary check, and you receive an error message that resembles the following: error: dial tcp: lookup registry.hub.docker.com on 10.123.45.67:89: server misbehaving this issue occurs when you use an external registry, such as registry.hub.docker.com. cause possible causes: cause 1: your dns server isn't working correctly. cause 2: your registry ca for registry.hub.docker.com isn't correct. solution first, check whether a dns server problem is causing the issue. run the following command to check if your dns server can resolve the registry to the corresponding ip: nslookup <registry> for example, if your external registry is registry.hub.docker.com, run the following command: nslookup registry.hub.docker.com compare the result with the ip addresses that you obtained through a dns authority. if they don't match, ask for your it administrator to fix the dns problem. you can change to an available nameserver by updati",
    "keywordsLower": [
      "restart.sh",
      "2022.05",
      "45.67",
      "10.123",
      "10.123.45.67",
      "10.123.45",
      "registry.hub",
      "docker.com",
      "resolv.conf",
      "upgrade",
      "pre-check",
      "fails",
      "dial",
      "tcp",
      "lookup",
      "registry.hub.docker.com",
      "error",
      "cause",
      "solution",
      "try",
      "omt",
      "during",
      "preliminary",
      "check",
      "receive",
      "message",
      "resembles",
      "following",
      "89",
      "server",
      "misbehaving",
      "issue",
      "occurs",
      "external",
      "registry",
      "such",
      "registry.hub.docker.com.",
      "possible",
      "causes",
      "dns",
      "isn",
      "working",
      "correctly.",
      "ca",
      "correct.",
      "first",
      "whether",
      "problem",
      "causing",
      "issue.",
      "run",
      "command",
      "resolve",
      "corresponding",
      "ip",
      "nslookup",
      "example",
      "compare",
      "result",
      "addresses",
      "obtained",
      "through",
      "authority.",
      "don",
      "match",
      "ask",
      "administrator",
      "fix",
      "problem.",
      "change",
      "available",
      "nameserver",
      "updating",
      "etc",
      "file.",
      "fixed",
      "openssl",
      "-connect",
      "443",
      "returns",
      "handshake",
      "failure",
      "update",
      "ca.",
      "copy",
      "certificate",
      "directory",
      "cp",
      "pki",
      "ca-trust",
      "source",
      "anchors",
      "load",
      "private",
      "update-ca-trust",
      "extract",
      "restart",
      "kubernetes",
      "services",
      "import"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Upload images script failed after changing the registry password",
    "content": "When upgrading OMT, the logrotate or fluentd pods might get ImagePullBackOff errors and upgrade fails. Cause The issue occurs because you've updated the registry password with the updateLocalRegistryInfo.sh script before upgrading OMT. However, when upgrading OMT, the password was set back to the original one and it's inconsistent with the one in registrypullsecret. Solution Run the following commands in succession to fix the inconsistent registry password issue: source $CDF_HOME/properties/images/k8s_charts.properties REGISTRY_PWD=$(kubectl get secret -n $CDF_NAMESPACE registrypullsecret -ojson | jq -r '.data.\".dockerconfigjson\"' | base64 -d | jq -r '.auths.\"localhost:5000\".\"auth\"' | base64 -d | awk -F: '{print $2}') helm upgrade kube-registry $CDF_HOME/charts/$CHART_ITOM_KUBE_REGISTRY --set credentials.b64encPassword=$(echo -n \"$REGISTRY_PWD\" | base64 -w0) --reuse-values -n $CDF_NAMESPACE Rerun the upgrade commands.",
    "url": "uploadimagefailed",
    "filename": "uploadimagefailed",
    "headings": [
      "Cause",
      "Solution"
    ],
    "keywords": [
      "updateLocalRegistryInfo.sh",
      "upload",
      "images",
      "script",
      "failed",
      "after",
      "changing",
      "registry",
      "password",
      "cause",
      "solution",
      "upgrading",
      "omt",
      "logrotate",
      "fluentd",
      "pods",
      "get",
      "imagepullbackoff",
      "errors",
      "upgrade",
      "fails.",
      "issue",
      "occurs",
      "because",
      "ve",
      "updated",
      "before",
      "omt.",
      "however",
      "set",
      "back",
      "original",
      "one",
      "inconsistent",
      "registrypullsecret.",
      "run",
      "following",
      "commands",
      "succession",
      "fix",
      "source",
      "properties",
      "kubectl",
      "secret",
      "-n",
      "registrypullsecret",
      "-ojson",
      "jq",
      "-r",
      ".data.",
      ".dockerconfigjson",
      "base64",
      "-d",
      ".auths.",
      "localhost",
      "5000",
      "auth",
      "awk",
      "-f",
      "print",
      "helm",
      "kube-registry",
      "charts",
      "--set",
      "credentials.b64encpassword",
      "echo",
      "-w0",
      "--reuse-values",
      "rerun",
      "commands."
    ],
    "language": "en",
    "word_count": 103,
    "importance_score": 3.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "upload images script failed after changing the registry password",
    "contentLower": "when upgrading omt, the logrotate or fluentd pods might get imagepullbackoff errors and upgrade fails. cause the issue occurs because you've updated the registry password with the updatelocalregistryinfo.sh script before upgrading omt. however, when upgrading omt, the password was set back to the original one and it's inconsistent with the one in registrypullsecret. solution run the following commands in succession to fix the inconsistent registry password issue: source $cdf_home/properties/images/k8s_charts.properties registry_pwd=$(kubectl get secret -n $cdf_namespace registrypullsecret -ojson | jq -r '.data.\".dockerconfigjson\"' | base64 -d | jq -r '.auths.\"localhost:5000\".\"auth\"' | base64 -d | awk -f: '{print $2}') helm upgrade kube-registry $cdf_home/charts/$chart_itom_kube_registry --set credentials.b64encpassword=$(echo -n \"$registry_pwd\" | base64 -w0) --reuse-values -n $cdf_namespace rerun the upgrade commands.",
    "keywordsLower": [
      "updatelocalregistryinfo.sh",
      "upload",
      "images",
      "script",
      "failed",
      "after",
      "changing",
      "registry",
      "password",
      "cause",
      "solution",
      "upgrading",
      "omt",
      "logrotate",
      "fluentd",
      "pods",
      "get",
      "imagepullbackoff",
      "errors",
      "upgrade",
      "fails.",
      "issue",
      "occurs",
      "because",
      "ve",
      "updated",
      "before",
      "omt.",
      "however",
      "set",
      "back",
      "original",
      "one",
      "inconsistent",
      "registrypullsecret.",
      "run",
      "following",
      "commands",
      "succession",
      "fix",
      "source",
      "properties",
      "kubectl",
      "secret",
      "-n",
      "registrypullsecret",
      "-ojson",
      "jq",
      "-r",
      ".data.",
      ".dockerconfigjson",
      "base64",
      "-d",
      ".auths.",
      "localhost",
      "5000",
      "auth",
      "awk",
      "-f",
      "print",
      "helm",
      "kube-registry",
      "charts",
      "--set",
      "credentials.b64encpassword",
      "echo",
      "-w0",
      "--reuse-values",
      "rerun",
      "commands."
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Upgrade fails after your session is disconnected",
    "content": "When you are upgrading OMT, your CLI session is disconnected and the upgrade fails. Cause This issue occurs because the session was disconnected. Solution Run the upgrade command or autoUpgrade script again. Note that you must use the same upgrade method that you started with. If you initially ran the autoUpgrade script, you must rerun the autoUpgrade script. If you performed a manual upgrade, you must rerun the ./upgrade.sh command. If the upgrade proceeds as expected, there is no need to do anything else. If you receive the following error message, the upgrade didn’t exit correctly due to external factors, and you should follow the steps below: Error: one instance is already running and only one instance is allowed on this node at a time. Check to see if another instance is running. If the instance stops running, delete /tmp/.upgrade-lock file. On the same node where you ran the upgrade, run the following commands to check if the upgrade process is still running: PID=$(cat /tmp/.upgr",
    "url": "upgradefailsessiondisconnect",
    "filename": "upgradefailsessiondisconnect",
    "headings": [
      "Cause",
      "Solution"
    ],
    "keywords": [
      "upgrade.sh",
      "upgrade",
      "fails",
      "after",
      "session",
      "disconnected",
      "cause",
      "solution",
      "upgrading",
      "omt",
      "cli",
      "fails.",
      "issue",
      "occurs",
      "because",
      "disconnected.",
      "run",
      "command",
      "autoupgrade",
      "script",
      "again.",
      "note",
      "same",
      "method",
      "started",
      "with.",
      "initially",
      "ran",
      "rerun",
      "script.",
      "performed",
      "manual",
      "command.",
      "proceeds",
      "expected",
      "there",
      "need",
      "anything",
      "else.",
      "receive",
      "following",
      "error",
      "message",
      "didn",
      "exit",
      "correctly",
      "due",
      "external",
      "factors",
      "follow",
      "steps",
      "below",
      "one",
      "instance",
      "already",
      "running",
      "allowed",
      "node",
      "time.",
      "check",
      "see",
      "another",
      "running.",
      "stops",
      "delete",
      "tmp",
      ".upgrade-lock",
      "file.",
      "commands",
      "process",
      "still",
      "pid",
      "cat",
      "ps",
      "-ef",
      "grep",
      "show",
      "wait",
      "until",
      "exits",
      "itself.",
      "situation",
      "output",
      "resembles",
      "root",
      "examplevm",
      "21040",
      "18581",
      "12",
      "35",
      "pts",
      "00",
      "bin",
      "bash",
      "returns",
      "results",
      "safety",
      "rm",
      "-f"
    ],
    "language": "en",
    "word_count": 104,
    "importance_score": 3.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "upgrade fails after your session is disconnected",
    "contentLower": "when you are upgrading omt, your cli session is disconnected and the upgrade fails. cause this issue occurs because the session was disconnected. solution run the upgrade command or autoupgrade script again. note that you must use the same upgrade method that you started with. if you initially ran the autoupgrade script, you must rerun the autoupgrade script. if you performed a manual upgrade, you must rerun the ./upgrade.sh command. if the upgrade proceeds as expected, there is no need to do anything else. if you receive the following error message, the upgrade didn’t exit correctly due to external factors, and you should follow the steps below: error: one instance is already running and only one instance is allowed on this node at a time. check to see if another instance is running. if the instance stops running, delete /tmp/.upgrade-lock file. on the same node where you ran the upgrade, run the following commands to check if the upgrade process is still running: pid=$(cat /tmp/.upgr",
    "keywordsLower": [
      "upgrade.sh",
      "upgrade",
      "fails",
      "after",
      "session",
      "disconnected",
      "cause",
      "solution",
      "upgrading",
      "omt",
      "cli",
      "fails.",
      "issue",
      "occurs",
      "because",
      "disconnected.",
      "run",
      "command",
      "autoupgrade",
      "script",
      "again.",
      "note",
      "same",
      "method",
      "started",
      "with.",
      "initially",
      "ran",
      "rerun",
      "script.",
      "performed",
      "manual",
      "command.",
      "proceeds",
      "expected",
      "there",
      "need",
      "anything",
      "else.",
      "receive",
      "following",
      "error",
      "message",
      "didn",
      "exit",
      "correctly",
      "due",
      "external",
      "factors",
      "follow",
      "steps",
      "below",
      "one",
      "instance",
      "already",
      "running",
      "allowed",
      "node",
      "time.",
      "check",
      "see",
      "another",
      "running.",
      "stops",
      "delete",
      "tmp",
      ".upgrade-lock",
      "file.",
      "commands",
      "process",
      "still",
      "pid",
      "cat",
      "ps",
      "-ef",
      "grep",
      "show",
      "wait",
      "until",
      "exits",
      "itself.",
      "situation",
      "output",
      "resembles",
      "root",
      "examplevm",
      "21040",
      "18581",
      "12",
      "35",
      "pts",
      "00",
      "bin",
      "bash",
      "returns",
      "results",
      "safety",
      "rm",
      "-f"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Upgrade fails when you run the \"upgrade --u\" command",
    "content": "The OMT upgrade fails after you run the upgrade --u command. Cause This issue occurs because the value of the CREATE_DATABASE key in the default-database-configmap ConfigMap is empty or null. To find the value of the CREATE_DATABASE key, run the following command: kubectl get cm default-database-configmap -n <OMT namespace> -o json | jq -r \".data.CREATE_DATABASE\" Solution Run the following command to update the value of the CREATE_DATABASE to false, and then run the upgrade again: kubectl patch cm default-database-configmap -n <OMT namespace> -p '{\"data\":{\"CREATE_DATABASE\":\"false\"}}'",
    "url": "upgradefailcreatedatabasenull",
    "filename": "upgradefailcreatedatabasenull",
    "headings": [
      "Cause",
      "Solution"
    ],
    "keywords": [
      "upgrade",
      "fails",
      "run",
      "--u",
      "command",
      "cause",
      "solution",
      "omt",
      "after",
      "command.",
      "issue",
      "occurs",
      "because",
      "value",
      "key",
      "default-database-configmap",
      "configmap",
      "empty",
      "null.",
      "find",
      "following",
      "kubectl",
      "get",
      "cm",
      "-n",
      "-o",
      "json",
      "jq",
      "-r",
      "update",
      "false",
      "again",
      "patch",
      "-p",
      "data"
    ],
    "language": "en",
    "word_count": 62,
    "importance_score": 2.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "upgrade fails when you run the \"upgrade --u\" command",
    "contentLower": "the omt upgrade fails after you run the upgrade --u command. cause this issue occurs because the value of the create_database key in the default-database-configmap configmap is empty or null. to find the value of the create_database key, run the following command: kubectl get cm default-database-configmap -n <omt namespace> -o json | jq -r \".data.create_database\" solution run the following command to update the value of the create_database to false, and then run the upgrade again: kubectl patch cm default-database-configmap -n <omt namespace> -p '{\"data\":{\"create_database\":\"false\"}}'",
    "keywordsLower": [
      "upgrade",
      "fails",
      "run",
      "--u",
      "command",
      "cause",
      "solution",
      "omt",
      "after",
      "command.",
      "issue",
      "occurs",
      "because",
      "value",
      "key",
      "default-database-configmap",
      "configmap",
      "empty",
      "null.",
      "find",
      "following",
      "kubectl",
      "get",
      "cm",
      "-n",
      "-o",
      "json",
      "jq",
      "-r",
      "update",
      "false",
      "again",
      "patch",
      "-p",
      "data"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Upgrade fails with CMP FinOps pods in the \"Pending\" state",
    "content": "Upgrade fails with CMP FinOps pods in the \"Pending\" state. This issue occurs when you have performed performance tuning. Cause This issue occurs because the nodeSelector label of the CMP FinOps pods is reset to the default values during the upgrade. However, you may have changed the nodeSelector label of these pods as part of performance tuning. When the nodeSelector label is reset to the default, the CMP FinOps pods can run on worker nodes that are designated for other pods, which leads to resource issues. Solution Run the following command to update the nodeSelector label in each deployment back to the value you used during performance tuning: kubectl patch deployment <deployment-name> -n <namespace> -p '{\"spec\": {\"template\": {\"spec\": {\"nodeSelector\": {\"<Kubernetes label key name>\": \"<Kubernetes label key value>\"}}}}}' For example, you run the following commands to update the nodeSelector label to cgro: kubectl patch deployment itom-cgro-showback -n itsma-prod -p '{\"spec\": {\"template",
    "url": "upgradefailsshowbackpod",
    "filename": "upgradefailsshowbackpod",
    "headings": [
      "Cause",
      "Solution",
      "Related topics"
    ],
    "keywords": [
      "upgrade",
      "fails",
      "cmp",
      "finops",
      "pods",
      "pending",
      "state",
      "cause",
      "solution",
      "related",
      "topics",
      "state.",
      "issue",
      "occurs",
      "performed",
      "performance",
      "tuning.",
      "because",
      "nodeselector",
      "label",
      "reset",
      "default",
      "values",
      "during",
      "upgrade.",
      "however",
      "changed",
      "part",
      "run",
      "worker",
      "nodes",
      "designated",
      "leads",
      "resource",
      "issues.",
      "following",
      "command",
      "update",
      "deployment",
      "back",
      "value",
      "tuning",
      "kubectl",
      "patch",
      "-n",
      "-p",
      "spec",
      "template",
      "example",
      "commands",
      "cgro",
      "itom-cgro-showback",
      "itsma-prod",
      "itom-cgro-showback-gateway",
      "itom-cgro-costpolicy",
      "itom-cgro-insights",
      "itom-cgro-insights-gateway",
      "itom-cgro-policy-gateway",
      "information",
      "about",
      "see",
      "hardware",
      "requirements",
      "section",
      "plan",
      "deployment."
    ],
    "language": "en",
    "word_count": 95,
    "importance_score": 3.5,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "upgrade fails with cmp finops pods in the \"pending\" state",
    "contentLower": "upgrade fails with cmp finops pods in the \"pending\" state. this issue occurs when you have performed performance tuning. cause this issue occurs because the nodeselector label of the cmp finops pods is reset to the default values during the upgrade. however, you may have changed the nodeselector label of these pods as part of performance tuning. when the nodeselector label is reset to the default, the cmp finops pods can run on worker nodes that are designated for other pods, which leads to resource issues. solution run the following command to update the nodeselector label in each deployment back to the value you used during performance tuning: kubectl patch deployment <deployment-name> -n <namespace> -p '{\"spec\": {\"template\": {\"spec\": {\"nodeselector\": {\"<kubernetes label key name>\": \"<kubernetes label key value>\"}}}}}' for example, you run the following commands to update the nodeselector label to cgro: kubectl patch deployment itom-cgro-showback -n itsma-prod -p '{\"spec\": {\"template",
    "keywordsLower": [
      "upgrade",
      "fails",
      "cmp",
      "finops",
      "pods",
      "pending",
      "state",
      "cause",
      "solution",
      "related",
      "topics",
      "state.",
      "issue",
      "occurs",
      "performed",
      "performance",
      "tuning.",
      "because",
      "nodeselector",
      "label",
      "reset",
      "default",
      "values",
      "during",
      "upgrade.",
      "however",
      "changed",
      "part",
      "run",
      "worker",
      "nodes",
      "designated",
      "leads",
      "resource",
      "issues.",
      "following",
      "command",
      "update",
      "deployment",
      "back",
      "value",
      "tuning",
      "kubectl",
      "patch",
      "-n",
      "-p",
      "spec",
      "template",
      "example",
      "commands",
      "cgro",
      "itom-cgro-showback",
      "itsma-prod",
      "itom-cgro-showback-gateway",
      "itom-cgro-costpolicy",
      "itom-cgro-insights",
      "itom-cgro-insights-gateway",
      "itom-cgro-policy-gateway",
      "information",
      "about",
      "see",
      "hardware",
      "requirements",
      "section",
      "plan",
      "deployment."
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Upgrade fails with \"Fail to delete SMA Service itom-sam\" error",
    "content": "Upgrade fails with the following error under <global-volume>/logs/update/deployer.log file: ERROR 132 --- [DeployerBackend,,,,] [Thread-18] c.h.i.i.service.ItsmaSuite - Fail to delete SMA Service itom-sam Found Exception: io.fabric8.kubernetes.client.KubernetesClientException: Failure executing: DELETE at: https://172.17.17.1/api/v1/namespaces/itsma-xxxxx/services?labelSelector=itsmaService%3Ditom-sam. Message: Forbidden!Configured service account doesn't have access. Service account may have been revoked. services is forbidden: User \"system:serviceaccount:itsma-rzzyj:itom-suite-config\" cannot deletecollection resource \"services\" in API group \"\" in the namespace \"itsma-xxxxx\". Run the following command to confirm the error: kubectl get role -n $(kubectl get namespace |grep itsma | cut -f1 -d \" \") microfocus:cdf:itom-suite-config -o yaml From the output, under resources:services, the deletecollection is missing. Cause: Missing deletecollection permission for role microfocus:cdf:itom-sui",
    "url": "upgradefailstodeletesma",
    "filename": "upgradefailstodeletesma",
    "headings": [
      "Cause:",
      "Solution"
    ],
    "keywords": [
      "172.17",
      "deployer.log",
      "https://172.17.17.1/api/v1/namespaces/itsma-xxxxx/services?labelSelector=itsmaService%3Ditom-sam",
      "172.17.17",
      "upgrade",
      "fails",
      "fail",
      "delete",
      "sma",
      "service",
      "itom-sam",
      "error",
      "cause",
      "solution",
      "following",
      "under",
      "logs",
      "update",
      "file",
      "132",
      "deployerbackend",
      "thread-18",
      "c.h.i.i.service.itsmasuite",
      "found",
      "exception",
      "io.fabric8.kubernetes.client.kubernetesclientexception",
      "failure",
      "executing",
      "https",
      "172.17.17.1",
      "api",
      "v1",
      "namespaces",
      "itsma-xxxxx",
      "services",
      "labelselector",
      "itsmaservice",
      "3ditom-sam.",
      "message",
      "forbidden",
      "configured",
      "account",
      "doesn",
      "access.",
      "revoked.",
      "user",
      "system",
      "serviceaccount",
      "itsma-rzzyj",
      "itom-suite-config",
      "cannot",
      "deletecollection",
      "resource",
      "group",
      "namespace",
      "run",
      "command",
      "confirm",
      "kubectl",
      "get",
      "role",
      "-n",
      "grep",
      "itsma",
      "cut",
      "-f1",
      "-d",
      "microfocus",
      "cdf",
      "-o",
      "yaml",
      "output",
      "resources",
      "missing.",
      "missing",
      "permission",
      "add",
      "patch",
      "--type",
      "json",
      "-p",
      "op",
      "path",
      "rules",
      "value",
      "apigroups",
      "verbs",
      "retry",
      "upgrade."
    ],
    "language": "en",
    "word_count": 106,
    "importance_score": 3.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "upgrade fails with \"fail to delete sma service itom-sam\" error",
    "contentLower": "upgrade fails with the following error under <global-volume>/logs/update/deployer.log file: error 132 --- [deployerbackend,,,,] [thread-18] c.h.i.i.service.itsmasuite - fail to delete sma service itom-sam found exception: io.fabric8.kubernetes.client.kubernetesclientexception: failure executing: delete at: https://172.17.17.1/api/v1/namespaces/itsma-xxxxx/services?labelselector=itsmaservice%3ditom-sam. message: forbidden!configured service account doesn't have access. service account may have been revoked. services is forbidden: user \"system:serviceaccount:itsma-rzzyj:itom-suite-config\" cannot deletecollection resource \"services\" in api group \"\" in the namespace \"itsma-xxxxx\". run the following command to confirm the error: kubectl get role -n $(kubectl get namespace |grep itsma | cut -f1 -d \" \") microfocus:cdf:itom-suite-config -o yaml from the output, under resources:services, the deletecollection is missing. cause: missing deletecollection permission for role microfocus:cdf:itom-sui",
    "keywordsLower": [
      "172.17",
      "deployer.log",
      "https://172.17.17.1/api/v1/namespaces/itsma-xxxxx/services?labelselector=itsmaservice%3ditom-sam",
      "172.17.17",
      "upgrade",
      "fails",
      "fail",
      "delete",
      "sma",
      "service",
      "itom-sam",
      "error",
      "cause",
      "solution",
      "following",
      "under",
      "logs",
      "update",
      "file",
      "132",
      "deployerbackend",
      "thread-18",
      "c.h.i.i.service.itsmasuite",
      "found",
      "exception",
      "io.fabric8.kubernetes.client.kubernetesclientexception",
      "failure",
      "executing",
      "https",
      "172.17.17.1",
      "api",
      "v1",
      "namespaces",
      "itsma-xxxxx",
      "services",
      "labelselector",
      "itsmaservice",
      "3ditom-sam.",
      "message",
      "forbidden",
      "configured",
      "account",
      "doesn",
      "access.",
      "revoked.",
      "user",
      "system",
      "serviceaccount",
      "itsma-rzzyj",
      "itom-suite-config",
      "cannot",
      "deletecollection",
      "resource",
      "group",
      "namespace",
      "run",
      "command",
      "confirm",
      "kubectl",
      "get",
      "role",
      "-n",
      "grep",
      "itsma",
      "cut",
      "-f1",
      "-d",
      "microfocus",
      "cdf",
      "-o",
      "yaml",
      "output",
      "resources",
      "missing.",
      "missing",
      "permission",
      "add",
      "patch",
      "--type",
      "json",
      "-p",
      "op",
      "path",
      "rules",
      "value",
      "apigroups",
      "verbs",
      "retry",
      "upgrade."
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Unable to save updates in the Feature settings page after upgrade",
    "content": "If you had enabled the Enable record creation and actions from email parameter, you will not be able to save any updates on the Feature settings page after you upgrade to 25.1. Cause The Email integration mode field on the Feature settings page was newly introduced in 25.1, but the default value for this field is missing in the database. Due this issue, the  Email integration mode field is marked as mandatory on the UI, preventing you from saving updates on this page. Solution Set the default value for Email integration mode to resolve this issue. complete the following steps to set the default value. Open the  service portal Go to the Feature settings page In the Email integration mode list, choose Agent Click SAVE",
    "url": "saveemailsettingsfailspostupgrade",
    "filename": "saveemailsettingsfailspostupgrade",
    "headings": [
      "Cause",
      "Solution"
    ],
    "keywords": [
      "25.1",
      "unable",
      "save",
      "updates",
      "feature",
      "settings",
      "page",
      "after",
      "upgrade",
      "cause",
      "solution",
      "enabled",
      "enable",
      "record",
      "creation",
      "actions",
      "email",
      "parameter",
      "able",
      "any",
      "25.1.",
      "integration",
      "mode",
      "field",
      "newly",
      "introduced",
      "default",
      "value",
      "missing",
      "database.",
      "due",
      "issue",
      "marked",
      "mandatory",
      "ui",
      "preventing",
      "saving",
      "page.",
      "set",
      "resolve",
      "issue.",
      "complete",
      "following",
      "steps",
      "value.",
      "open",
      "service",
      "portal",
      "go",
      "list",
      "choose",
      "agent",
      "click"
    ],
    "language": "en",
    "word_count": 84,
    "importance_score": 2.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "unable to save updates in the feature settings page after upgrade",
    "contentLower": "if you had enabled the enable record creation and actions from email parameter, you will not be able to save any updates on the feature settings page after you upgrade to 25.1. cause the email integration mode field on the feature settings page was newly introduced in 25.1, but the default value for this field is missing in the database. due this issue, the  email integration mode field is marked as mandatory on the ui, preventing you from saving updates on this page. solution set the default value for email integration mode to resolve this issue. complete the following steps to set the default value. open the  service portal go to the feature settings page in the email integration mode list, choose agent click save",
    "keywordsLower": [
      "25.1",
      "unable",
      "save",
      "updates",
      "feature",
      "settings",
      "page",
      "after",
      "upgrade",
      "cause",
      "solution",
      "enabled",
      "enable",
      "record",
      "creation",
      "actions",
      "email",
      "parameter",
      "able",
      "any",
      "25.1.",
      "integration",
      "mode",
      "field",
      "newly",
      "introduced",
      "default",
      "value",
      "missing",
      "database.",
      "due",
      "issue",
      "marked",
      "mandatory",
      "ui",
      "preventing",
      "saving",
      "page.",
      "set",
      "resolve",
      "issue.",
      "complete",
      "following",
      "steps",
      "value.",
      "open",
      "service",
      "portal",
      "go",
      "list",
      "choose",
      "agent",
      "click"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Websocket error messages after upgrade",
    "content": "After the suite is upgraded to a new version, you may find many websocket error messages in controller.log. The following is an example of such errors. ERROR [SimpleAsyncTaskExecutor-8] (DefaultTransportRequest.java:229) No more fallback transports after TransportRequest[url=https://myhost.mycompany.com:443/ws-gateway/websocket/stomp/422/b62134e66318446aa0e13e12bb28eb1f/xhr] org.springframework.web.client.HttpServerErrorException$InternalServerError: 500 : [{\"timestamp\":\"2022-04-03T11:03:49.278+00:00\",\"status\":500,\"error\":\"Internal Server Error\",\"message\":\"Uncaught failure in SockJS request, uri=https://myhost.mycompany.com/ws-gateway/websocket/... (628 bytes)] at org.springframework.web.client.HttpServerErrorException.create(HttpServerErrorException.java:100) [2022-04-03 11:03:59,445] ERROR [SimpleAsyncTaskExecutor-5] (DefaultTransportRequest.java:225) TransportRequest[url=wss://myhost.mycompany.com:443/ws-gateway/websocket/stomp/341/049969e29a10427583369240c33b46dc/websocket] failed.",
    "url": "websocketerrormessages",
    "filename": "websocketerrormessages",
    "headings": [
      "Cause",
      "Solution"
    ],
    "keywords": [
      "https://myhost.mycompany.com/ws-gateway/websocket",
      "HttpServerErrorException.java",
      "2022.05",
      "mycompany.com",
      "controller.log",
      "wss://myhost.mycompany.com:443/ws-gateway/websocket/stomp/341/049969e29a10427583369240c33b46dc/websocket",
      "49.278",
      "springframework.web",
      "https://myhost.mycompany.com:443/ws-gateway/websocket/stomp/422/b62134e66318446aa0e13e12bb28eb1f/xhr",
      "DefaultTransportRequest.java",
      "websocket",
      "error",
      "messages",
      "after",
      "upgrade",
      "cause",
      "solution",
      "suite",
      "upgraded",
      "new",
      "version",
      "find",
      "many",
      "controller.log.",
      "following",
      "example",
      "such",
      "errors.",
      "simpleasynctaskexecutor-8",
      "229",
      "fallback",
      "transports",
      "transportrequest",
      "url",
      "https",
      "myhost.mycompany.com",
      "443",
      "ws-gateway",
      "stomp",
      "422",
      "b62134e66318446aa0e13e12bb28eb1f",
      "xhr",
      "org.springframework.web.client.httpservererrorexception",
      "internalservererror",
      "500",
      "timestamp",
      "2022-04-03t11",
      "03",
      "00",
      "status",
      "internal",
      "server",
      "message",
      "uncaught",
      "failure",
      "sockjs",
      "request",
      "uri",
      "628",
      "bytes",
      "org.springframework.web.client.httpservererrorexception.create",
      "100",
      "2022-04-03",
      "11",
      "59",
      "445",
      "simpleasynctaskexecutor-5",
      "225",
      "wss",
      "341",
      "049969e29a10427583369240c33b46dc",
      "failed.",
      "falling",
      "back",
      "next",
      "transport.",
      "javax.websocket.deploymentexception",
      "http",
      "response",
      "404",
      "permit",
      "opb",
      "agent",
      "supports",
      "functions.",
      "enabled",
      "any",
      "additional",
      "load",
      "balancer",
      "installed.",
      "occurs",
      "installed",
      "front",
      "balancer.",
      "enable",
      "suite.",
      "apache",
      "nginx",
      "users"
    ],
    "language": "en",
    "word_count": 90,
    "importance_score": 3.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "websocket error messages after upgrade",
    "contentLower": "after the suite is upgraded to a new version, you may find many websocket error messages in controller.log. the following is an example of such errors. error [simpleasynctaskexecutor-8] (defaulttransportrequest.java:229) no more fallback transports after transportrequest[url=https://myhost.mycompany.com:443/ws-gateway/websocket/stomp/422/b62134e66318446aa0e13e12bb28eb1f/xhr] org.springframework.web.client.httpservererrorexception$internalservererror: 500 : [{\"timestamp\":\"2022-04-03t11:03:49.278+00:00\",\"status\":500,\"error\":\"internal server error\",\"message\":\"uncaught failure in sockjs request, uri=https://myhost.mycompany.com/ws-gateway/websocket/... (628 bytes)] at org.springframework.web.client.httpservererrorexception.create(httpservererrorexception.java:100) [2022-04-03 11:03:59,445] error [simpleasynctaskexecutor-5] (defaulttransportrequest.java:225) transportrequest[url=wss://myhost.mycompany.com:443/ws-gateway/websocket/stomp/341/049969e29a10427583369240c33b46dc/websocket] failed.",
    "keywordsLower": [
      "https://myhost.mycompany.com/ws-gateway/websocket",
      "httpservererrorexception.java",
      "2022.05",
      "mycompany.com",
      "controller.log",
      "wss://myhost.mycompany.com:443/ws-gateway/websocket/stomp/341/049969e29a10427583369240c33b46dc/websocket",
      "49.278",
      "springframework.web",
      "https://myhost.mycompany.com:443/ws-gateway/websocket/stomp/422/b62134e66318446aa0e13e12bb28eb1f/xhr",
      "defaulttransportrequest.java",
      "websocket",
      "error",
      "messages",
      "after",
      "upgrade",
      "cause",
      "solution",
      "suite",
      "upgraded",
      "new",
      "version",
      "find",
      "many",
      "controller.log.",
      "following",
      "example",
      "such",
      "errors.",
      "simpleasynctaskexecutor-8",
      "229",
      "fallback",
      "transports",
      "transportrequest",
      "url",
      "https",
      "myhost.mycompany.com",
      "443",
      "ws-gateway",
      "stomp",
      "422",
      "b62134e66318446aa0e13e12bb28eb1f",
      "xhr",
      "org.springframework.web.client.httpservererrorexception",
      "internalservererror",
      "500",
      "timestamp",
      "2022-04-03t11",
      "03",
      "00",
      "status",
      "internal",
      "server",
      "message",
      "uncaught",
      "failure",
      "sockjs",
      "request",
      "uri",
      "628",
      "bytes",
      "org.springframework.web.client.httpservererrorexception.create",
      "100",
      "2022-04-03",
      "11",
      "59",
      "445",
      "simpleasynctaskexecutor-5",
      "225",
      "wss",
      "341",
      "049969e29a10427583369240c33b46dc",
      "failed.",
      "falling",
      "back",
      "next",
      "transport.",
      "javax.websocket.deploymentexception",
      "http",
      "response",
      "404",
      "permit",
      "opb",
      "agent",
      "supports",
      "functions.",
      "enabled",
      "any",
      "additional",
      "load",
      "balancer",
      "installed.",
      "occurs",
      "installed",
      "front",
      "balancer.",
      "enable",
      "suite.",
      "apache",
      "nginx",
      "users"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Unable to add distinct approval policy for same user operations",
    "content": "For an aggregated offering of a DND service design, if you try to add approval policy for user operations and retrieve the user operations in the aggregated offering page, it lists repeated user operation names on components. Because of this, the user is unable to add distinct approval policy for the same user operations defined on different components. Cause This issue occurs if the design has multiple components and they're associated with the same Resource Offering (RO). Solution The following workaround avoids reuse of the same RO on multiple components: Go to Service Designer and select the service design that contains multiple components associated with the same Resource Offering (RO). Click the Resource Offerings tab. Select the Resource Offering associated with multiple components. The Resource Offering page appears. Click the gear icon, select Save As and then click Save. The newly created RO appears. On the newly created RO, click the User Operations tab. The User Operations ",
    "url": "useroperationserror",
    "filename": "useroperationserror",
    "headings": [
      "Cause",
      "Solution"
    ],
    "keywords": [
      "unable",
      "add",
      "distinct",
      "approval",
      "policy",
      "same",
      "user",
      "operations",
      "cause",
      "solution",
      "aggregated",
      "offering",
      "dnd",
      "service",
      "design",
      "try",
      "retrieve",
      "page",
      "lists",
      "repeated",
      "operation",
      "names",
      "components.",
      "because",
      "defined",
      "different",
      "issue",
      "occurs",
      "multiple",
      "components",
      "re",
      "associated",
      "resource",
      "ro",
      "following",
      "workaround",
      "avoids",
      "reuse",
      "go",
      "designer",
      "select",
      "contains",
      "click",
      "offerings",
      "tab.",
      "appears.",
      "gear",
      "icon",
      "save",
      "save.",
      "newly",
      "created",
      "delete",
      "again.",
      "make",
      "sure",
      "mapping",
      "between",
      "properties",
      "remains",
      "before.",
      "attach",
      "component",
      "wants",
      "existing",
      "ro.",
      "repeat",
      "procedure",
      "design."
    ],
    "language": "en",
    "word_count": 113,
    "importance_score": 3.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "unable to add distinct approval policy for same user operations",
    "contentLower": "for an aggregated offering of a dnd service design, if you try to add approval policy for user operations and retrieve the user operations in the aggregated offering page, it lists repeated user operation names on components. because of this, the user is unable to add distinct approval policy for the same user operations defined on different components. cause this issue occurs if the design has multiple components and they're associated with the same resource offering (ro). solution the following workaround avoids reuse of the same ro on multiple components: go to service designer and select the service design that contains multiple components associated with the same resource offering (ro). click the resource offerings tab. select the resource offering associated with multiple components. the resource offering page appears. click the gear icon, select save as and then click save. the newly created ro appears. on the newly created ro, click the user operations tab. the user operations ",
    "keywordsLower": [
      "unable",
      "add",
      "distinct",
      "approval",
      "policy",
      "same",
      "user",
      "operations",
      "cause",
      "solution",
      "aggregated",
      "offering",
      "dnd",
      "service",
      "design",
      "try",
      "retrieve",
      "page",
      "lists",
      "repeated",
      "operation",
      "names",
      "components.",
      "because",
      "defined",
      "different",
      "issue",
      "occurs",
      "multiple",
      "components",
      "re",
      "associated",
      "resource",
      "ro",
      "following",
      "workaround",
      "avoids",
      "reuse",
      "go",
      "designer",
      "select",
      "contains",
      "click",
      "offerings",
      "tab.",
      "appears.",
      "gear",
      "icon",
      "save",
      "save.",
      "newly",
      "created",
      "delete",
      "again.",
      "make",
      "sure",
      "mapping",
      "between",
      "properties",
      "remains",
      "before.",
      "attach",
      "component",
      "wants",
      "existing",
      "ro.",
      "repeat",
      "procedure",
      "design."
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Validation error when publishing an Image Aggregation based Azure offering",
    "content": "You have created an Azure IA Provider and the collection has been completed successfully. However, when you go to Build->Design->Service Designer->Image Aggregation in the agent portal to import an image, you see a \"Validation Failed\" error that resembles the following: After you click Skip Validation, you still see the following error message during the deployment of the offering: Error message: 'You have not accepted the legal terms on this subscription: 'xxxxxxxxxxxxxxxxxxxxxx' for this plan. Before the subscription can be used, you need to accept the legal terms of the image. Cause When you skip validation, there's a chance that some offerings may not be deployed successfully if you haven't accepted their legal terms in the Azure portal. Solution Accept the legal terms in the Azure portal. Additionally, if programmatic deployment is disabled in the portal, enable it to resolve the issue.",
    "url": "validationerrorimportingimagefromazureportal",
    "filename": "validationerrorimportingimagefromazureportal",
    "headings": [
      "Cause",
      "Solution"
    ],
    "keywords": [
      "validation",
      "error",
      "publishing",
      "image",
      "aggregation",
      "based",
      "azure",
      "offering",
      "cause",
      "solution",
      "created",
      "ia",
      "provider",
      "collection",
      "completed",
      "successfully.",
      "however",
      "go",
      "build-",
      "design-",
      "service",
      "designer-",
      "agent",
      "portal",
      "import",
      "see",
      "failed",
      "resembles",
      "following",
      "after",
      "click",
      "skip",
      "still",
      "message",
      "during",
      "deployment",
      "accepted",
      "legal",
      "terms",
      "subscription",
      "xxxxxxxxxxxxxxxxxxxxxx",
      "plan.",
      "before",
      "need",
      "accept",
      "image.",
      "there",
      "chance",
      "offerings",
      "deployed",
      "successfully",
      "haven",
      "portal.",
      "additionally",
      "programmatic",
      "disabled",
      "enable",
      "resolve",
      "issue."
    ],
    "language": "en",
    "word_count": 90,
    "importance_score": 3.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "validation error when publishing an image aggregation based azure offering",
    "contentLower": "you have created an azure ia provider and the collection has been completed successfully. however, when you go to build->design->service designer->image aggregation in the agent portal to import an image, you see a \"validation failed\" error that resembles the following: after you click skip validation, you still see the following error message during the deployment of the offering: error message: 'you have not accepted the legal terms on this subscription: 'xxxxxxxxxxxxxxxxxxxxxx' for this plan. before the subscription can be used, you need to accept the legal terms of the image. cause when you skip validation, there's a chance that some offerings may not be deployed successfully if you haven't accepted their legal terms in the azure portal. solution accept the legal terms in the azure portal. additionally, if programmatic deployment is disabled in the portal, enable it to resolve the issue.",
    "keywordsLower": [
      "validation",
      "error",
      "publishing",
      "image",
      "aggregation",
      "based",
      "azure",
      "offering",
      "cause",
      "solution",
      "created",
      "ia",
      "provider",
      "collection",
      "completed",
      "successfully.",
      "however",
      "go",
      "build-",
      "design-",
      "service",
      "designer-",
      "agent",
      "portal",
      "import",
      "see",
      "failed",
      "resembles",
      "following",
      "after",
      "click",
      "skip",
      "still",
      "message",
      "during",
      "deployment",
      "accepted",
      "legal",
      "terms",
      "subscription",
      "xxxxxxxxxxxxxxxxxxxxxx",
      "plan.",
      "before",
      "need",
      "accept",
      "image.",
      "there",
      "chance",
      "offerings",
      "deployed",
      "successfully",
      "haven",
      "portal.",
      "additionally",
      "programmatic",
      "disabled",
      "enable",
      "resolve",
      "issue."
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Vertica database not reachable",
    "content": "Liquibase stops responding waiting to acquire database change lock when creating the schema. The following failure message is displayed: SQLNonTransientConnectionException: [Vertica][VJDBC](100176) Failed to connect to host.... When the problem occurs, the Budget Quota policies page will be slow to refresh and return on cost data for organizations. The CSA Collector will stop processing new subscription data. The Cost Policy container would contain the following error messages in log file: ... c.m.h.j.rest.RestTemplateFactory : POST 500 https://smax-csa-collector-svc.smax2.svc.cluster.local:9992/csa-collector/v1/organizationspend/?currency=USD&startTime=2017-12-01T00:28:42Z ... c.m.h.u.CostPolicyBudgetEvaluatorService : Failed to retrieve spend for organizations: '[\"...\"]', cost policy: '***'. Error: org.springframework.web.client.HttpServerErrorException: 500 ... c.m.h.u.CostPolicyBudgetEvaluatorService : Organization's spend data: null The CSA Collector container would contain the fo",
    "url": "verticadbnotreachable",
    "filename": "verticadbnotreachable",
    "headings": [
      "Cause",
      "Solution"
    ],
    "keywords": [
      "smax2.svc",
      "microfocus.smax",
      "https://smax-csa-collector-svc.smax2.svc.cluster.local:9992/csa-collector/v1/organizationspend/?currency=USD&startTime=2017-12-01T00:28:42Z",
      "j.rest",
      "springframework.web",
      "vertica",
      "database",
      "reachable",
      "cause",
      "solution",
      "liquibase",
      "stops",
      "responding",
      "waiting",
      "acquire",
      "change",
      "lock",
      "creating",
      "schema.",
      "following",
      "failure",
      "message",
      "displayed",
      "sqlnontransientconnectionexception",
      "vjdbc",
      "100176",
      "failed",
      "connect",
      "host....",
      "problem",
      "occurs",
      "budget",
      "quota",
      "policies",
      "page",
      "slow",
      "refresh",
      "return",
      "cost",
      "data",
      "organizations.",
      "csa",
      "collector",
      "stop",
      "processing",
      "new",
      "subscription",
      "data.",
      "policy",
      "container",
      "contain",
      "error",
      "messages",
      "log",
      "file",
      "c.m.h.j.rest.resttemplatefactory",
      "post",
      "500",
      "https",
      "smax-csa-collector-svc.smax2.svc.cluster.local",
      "9992",
      "csa-collector",
      "v1",
      "organizationspend",
      "currency",
      "usd",
      "starttime",
      "2017-12-01t00",
      "28",
      "42z",
      "c.m.h.u.costpolicybudgetevaluatorservice",
      "retrieve",
      "spend",
      "organizations",
      "org.springframework.web.client.httpservererrorexception",
      "organization",
      "null",
      "c.microfocus.smax.collector.taskexecutor",
      "valid",
      "connection",
      "stopping",
      "further",
      "collection.",
      "c.m.h.e.vertica.verticaclientconnection",
      "create",
      "host",
      "port",
      "5433.",
      "reason",
      "establish",
      "primary",
      "server",
      "any",
      "backup",
      "address.",
      "vertica.",
      "trying",
      "again",
      "seconds",
      "attempts."
    ],
    "language": "en",
    "word_count": 92,
    "importance_score": 4.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "vertica database not reachable",
    "contentLower": "liquibase stops responding waiting to acquire database change lock when creating the schema. the following failure message is displayed: sqlnontransientconnectionexception: [vertica][vjdbc](100176) failed to connect to host.... when the problem occurs, the budget quota policies page will be slow to refresh and return on cost data for organizations. the csa collector will stop processing new subscription data. the cost policy container would contain the following error messages in log file: ... c.m.h.j.rest.resttemplatefactory : post 500 https://smax-csa-collector-svc.smax2.svc.cluster.local:9992/csa-collector/v1/organizationspend/?currency=usd&starttime=2017-12-01t00:28:42z ... c.m.h.u.costpolicybudgetevaluatorservice : failed to retrieve spend for organizations: '[\"...\"]', cost policy: '***'. error: org.springframework.web.client.httpservererrorexception: 500 ... c.m.h.u.costpolicybudgetevaluatorservice : organization's spend data: null the csa collector container would contain the fo",
    "keywordsLower": [
      "smax2.svc",
      "microfocus.smax",
      "https://smax-csa-collector-svc.smax2.svc.cluster.local:9992/csa-collector/v1/organizationspend/?currency=usd&starttime=2017-12-01t00:28:42z",
      "j.rest",
      "springframework.web",
      "vertica",
      "database",
      "reachable",
      "cause",
      "solution",
      "liquibase",
      "stops",
      "responding",
      "waiting",
      "acquire",
      "change",
      "lock",
      "creating",
      "schema.",
      "following",
      "failure",
      "message",
      "displayed",
      "sqlnontransientconnectionexception",
      "vjdbc",
      "100176",
      "failed",
      "connect",
      "host....",
      "problem",
      "occurs",
      "budget",
      "quota",
      "policies",
      "page",
      "slow",
      "refresh",
      "return",
      "cost",
      "data",
      "organizations.",
      "csa",
      "collector",
      "stop",
      "processing",
      "new",
      "subscription",
      "data.",
      "policy",
      "container",
      "contain",
      "error",
      "messages",
      "log",
      "file",
      "c.m.h.j.rest.resttemplatefactory",
      "post",
      "500",
      "https",
      "smax-csa-collector-svc.smax2.svc.cluster.local",
      "9992",
      "csa-collector",
      "v1",
      "organizationspend",
      "currency",
      "usd",
      "starttime",
      "2017-12-01t00",
      "28",
      "42z",
      "c.m.h.u.costpolicybudgetevaluatorservice",
      "retrieve",
      "spend",
      "organizations",
      "org.springframework.web.client.httpservererrorexception",
      "organization",
      "null",
      "c.microfocus.smax.collector.taskexecutor",
      "valid",
      "connection",
      "stopping",
      "further",
      "collection.",
      "c.m.h.e.vertica.verticaclientconnection",
      "create",
      "host",
      "port",
      "5433.",
      "reason",
      "establish",
      "primary",
      "server",
      "any",
      "backup",
      "address.",
      "vertica.",
      "trying",
      "again",
      "seconds",
      "attempts."
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Upgrade fails with [OO RAS] Error: Must define value for all six parameters",
    "content": "When upgrading OO Containerized, the upgrade fails with the following error: [OO RAS] ERROR: Must define value for all six parameters initMemory, maxMemory, cpuRequest, cpuLimit, resource request and limit Cause This happens if the values.yaml file is updated/injected with partial values for OO RAS in OO Containerized in 2022.11. Solution To avoid this error: Locate the path to previous_deployment_values.yaml file (values.yaml file used before upgrading). Or, run the following command: helm get values <oo_install_name> -n <oo_namespace> > /path/to/previous_deployment_values.yaml Where: <oo_install_name> is the name of the OO deployment that you specified when installing OO. <oo_namespace> is the unique namespace of the OO deployment. Remove the partial values to the initMemory, maxMemory, cpuRequest, cpuLimit, resources.requests.memory, and resources.limits.memory parameters in the previous_deployment_values.yaml file. Run the following commands: cpuReq=`yq e '.oocontroller.deployment.",
    "url": "ooraserror",
    "filename": "ooraserror",
    "headings": [
      "Cause",
      "Solution"
    ],
    "keywords": [
      "previous_deployment_values.yaml",
      "values.yaml",
      "2022.11",
      "upgrade",
      "fails",
      "oo",
      "ras",
      "error",
      "define",
      "value",
      "all",
      "six",
      "parameters",
      "cause",
      "solution",
      "upgrading",
      "containerized",
      "following",
      "initmemory",
      "maxmemory",
      "cpurequest",
      "cpulimit",
      "resource",
      "request",
      "limit",
      "happens",
      "file",
      "updated",
      "injected",
      "partial",
      "values",
      "2022.11.",
      "avoid",
      "locate",
      "path",
      "before",
      "run",
      "command",
      "helm",
      "get",
      "-n",
      "name",
      "deployment",
      "specified",
      "installing",
      "oo.",
      "unique",
      "namespace",
      "deployment.",
      "remove",
      "resources.requests.memory",
      "resources.limits.memory",
      "file.",
      "commands",
      "cpureq",
      "yq",
      ".oocontroller.deployment.ooras.cpurequest",
      ".oocontroller.deployment.ooras.cpulimit",
      "initmem",
      ".oocontroller.deployment.ooras.initmemory",
      "maxmem",
      ".oocontroller.deployment.ooras.maxmemory",
      "memlimit",
      ".oocontroller.deployment.ooras.resources.limits.memory",
      "memrequest",
      ".oocontroller.deployment.ooras.resources.requests.memory",
      "null",
      "echo",
      "cpu",
      "set",
      "init",
      "memoery",
      "max",
      "memory",
      "found",
      "provided",
      "previous",
      "version.",
      "removing",
      "ras.",
      "eval",
      "del",
      "-i",
      ".oocontroller.deployment.ooras.resources",
      "fi",
      "rerun",
      "command."
    ],
    "language": "en",
    "word_count": 94,
    "importance_score": 2.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "upgrade fails with [oo ras] error: must define value for all six parameters",
    "contentLower": "when upgrading oo containerized, the upgrade fails with the following error: [oo ras] error: must define value for all six parameters initmemory, maxmemory, cpurequest, cpulimit, resource request and limit cause this happens if the values.yaml file is updated/injected with partial values for oo ras in oo containerized in 2022.11. solution to avoid this error: locate the path to previous_deployment_values.yaml file (values.yaml file used before upgrading). or, run the following command: helm get values <oo_install_name> -n <oo_namespace> > /path/to/previous_deployment_values.yaml where: <oo_install_name> is the name of the oo deployment that you specified when installing oo. <oo_namespace> is the unique namespace of the oo deployment. remove the partial values to the initmemory, maxmemory, cpurequest, cpulimit, resources.requests.memory, and resources.limits.memory parameters in the previous_deployment_values.yaml file. run the following commands: cpureq=`yq e '.oocontroller.deployment.",
    "keywordsLower": [
      "previous_deployment_values.yaml",
      "values.yaml",
      "2022.11",
      "upgrade",
      "fails",
      "oo",
      "ras",
      "error",
      "define",
      "value",
      "all",
      "six",
      "parameters",
      "cause",
      "solution",
      "upgrading",
      "containerized",
      "following",
      "initmemory",
      "maxmemory",
      "cpurequest",
      "cpulimit",
      "resource",
      "request",
      "limit",
      "happens",
      "file",
      "updated",
      "injected",
      "partial",
      "values",
      "2022.11.",
      "avoid",
      "locate",
      "path",
      "before",
      "run",
      "command",
      "helm",
      "get",
      "-n",
      "name",
      "deployment",
      "specified",
      "installing",
      "oo.",
      "unique",
      "namespace",
      "deployment.",
      "remove",
      "resources.requests.memory",
      "resources.limits.memory",
      "file.",
      "commands",
      "cpureq",
      "yq",
      ".oocontroller.deployment.ooras.cpurequest",
      ".oocontroller.deployment.ooras.cpulimit",
      "initmem",
      ".oocontroller.deployment.ooras.initmemory",
      "maxmem",
      ".oocontroller.deployment.ooras.maxmemory",
      "memlimit",
      ".oocontroller.deployment.ooras.resources.limits.memory",
      "memrequest",
      ".oocontroller.deployment.ooras.resources.requests.memory",
      "null",
      "echo",
      "cpu",
      "set",
      "init",
      "memoery",
      "max",
      "memory",
      "found",
      "provided",
      "previous",
      "version.",
      "removing",
      "ras.",
      "eval",
      "del",
      "-i",
      ".oocontroller.deployment.ooras.resources",
      "fi",
      "rerun",
      "command."
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "User information not updated in the tenant",
    "content": "One of the following problems occurs after the system synchronizes the user information to the tenant: When you add a new user in Suite Administration, this user can't log in to the tenant. The updated information of existing users is not reflected in the tenant. Cause You can contact the tenant administrator to check if the user's User Principal Name (UPN) is the same as any user group's UPN. Solution For users with DB authentication type only: If the user's UPN is the same as any user group's UPN, delete this user from Suite Administration and create another user with a different UPN.",
    "url": "usernotupdatedintenant",
    "filename": "usernotupdatedintenant",
    "headings": [
      "Cause",
      "Solution"
    ],
    "keywords": [
      "user",
      "information",
      "updated",
      "tenant",
      "cause",
      "solution",
      "one",
      "following",
      "problems",
      "occurs",
      "after",
      "system",
      "synchronizes",
      "add",
      "new",
      "suite",
      "administration",
      "log",
      "tenant.",
      "existing",
      "users",
      "reflected",
      "contact",
      "administrator",
      "check",
      "principal",
      "name",
      "upn",
      "same",
      "any",
      "group",
      "upn.",
      "db",
      "authentication",
      "type",
      "delete",
      "create",
      "another",
      "different"
    ],
    "language": "en",
    "word_count": 69,
    "importance_score": 3.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "user information not updated in the tenant",
    "contentLower": "one of the following problems occurs after the system synchronizes the user information to the tenant: when you add a new user in suite administration, this user can't log in to the tenant. the updated information of existing users is not reflected in the tenant. cause you can contact the tenant administrator to check if the user's user principal name (upn) is the same as any user group's upn. solution for users with db authentication type only: if the user's upn is the same as any user group's upn, delete this user from suite administration and create another user with a different upn.",
    "keywordsLower": [
      "user",
      "information",
      "updated",
      "tenant",
      "cause",
      "solution",
      "one",
      "following",
      "problems",
      "occurs",
      "after",
      "system",
      "synchronizes",
      "add",
      "new",
      "suite",
      "administration",
      "log",
      "tenant.",
      "existing",
      "users",
      "reflected",
      "contact",
      "administrator",
      "check",
      "principal",
      "name",
      "upn",
      "same",
      "any",
      "group",
      "upn.",
      "db",
      "authentication",
      "type",
      "delete",
      "create",
      "another",
      "different"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Users can't access some system functionalities of certain capabilities",
    "content": "Users can't access some system functionalities of the Cloud Management, UCMDB, and Operations Orchestration capabilities even if they are assigned the corresponding permissions. Cause One possible cause is that the user's role and group information is inconsistent between Service Management and IdM. To confirm that this is the cause of the issue, compare the user's groups and roles in IdM with those in Service Management. If they are not the same, then you can use the following solution to fix the issue. Solution In Service Management, remove groups and roles from the user, save the changes, and then assign them to the user again.",
    "url": "userhavenopermission",
    "filename": "userhavenopermission",
    "headings": [
      "Cause",
      "Solution"
    ],
    "keywords": [
      "cant",
      "users",
      "access",
      "system",
      "functionalities",
      "certain",
      "capabilities",
      "cause",
      "solution",
      "cloud",
      "management",
      "ucmdb",
      "operations",
      "orchestration",
      "even",
      "assigned",
      "corresponding",
      "permissions.",
      "one",
      "possible",
      "user",
      "role",
      "group",
      "information",
      "inconsistent",
      "between",
      "service",
      "idm.",
      "confirm",
      "issue",
      "compare",
      "groups",
      "roles",
      "idm",
      "management.",
      "same",
      "following",
      "fix",
      "issue.",
      "remove",
      "save",
      "changes",
      "assign",
      "again."
    ],
    "language": "en",
    "word_count": 64,
    "importance_score": 3.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "users can't access some system functionalities of certain capabilities",
    "contentLower": "users can't access some system functionalities of the cloud management, ucmdb, and operations orchestration capabilities even if they are assigned the corresponding permissions. cause one possible cause is that the user's role and group information is inconsistent between service management and idm. to confirm that this is the cause of the issue, compare the user's groups and roles in idm with those in service management. if they are not the same, then you can use the following solution to fix the issue. solution in service management, remove groups and roles from the user, save the changes, and then assign them to the user again.",
    "keywordsLower": [
      "cant",
      "users",
      "access",
      "system",
      "functionalities",
      "certain",
      "capabilities",
      "cause",
      "solution",
      "cloud",
      "management",
      "ucmdb",
      "operations",
      "orchestration",
      "even",
      "assigned",
      "corresponding",
      "permissions.",
      "one",
      "possible",
      "user",
      "role",
      "group",
      "information",
      "inconsistent",
      "between",
      "service",
      "idm.",
      "confirm",
      "issue",
      "compare",
      "groups",
      "roles",
      "idm",
      "management.",
      "same",
      "following",
      "fix",
      "issue.",
      "remove",
      "save",
      "changes",
      "assign",
      "again."
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Unable to export Entity Change Model after upgrade",
    "content": "After upgrading to version 25.3.x, 25.4.x, or 26.1.x, you cannot export the Entity Change Model, and you will see a an error similar to the following in the mass_dev2prod.log and mass_error.log log files: Export with id 68e63200e4b0769b7c0b34ec failed com.hp.maas.platform.exception.service.ServiceException: Data records without a UUID were found. Dev2Prod uses the UUID field for record reconciliation between the source and target tenants. Ask your suite administrator to perform a crawling upgrade for the current tenant so that the system automatically generates a UUID for the problematic records, and then retry. Cause Version 25.3 introduces a content data version increment that requires updates to Entity Model UUIDs. However, the upgrade process for versions 25.3, 25.4, and 26.1 does not include a crawling upgrade step to complete these required updates. As a result, the content data version increment is not fully applied, the entity model UUIDs remain outdated, and exporting the Enti",
    "url": "afterupgrade253notexportchangemodel",
    "filename": "afterupgrade253notexportchangemodel",
    "headings": [
      "Cause",
      "Solution",
      "Prepare the script to update the UUID",
      "Update the UUIDs"
    ],
    "keywords": [
      "26.1",
      "file.Copy",
      "environment.Run",
      "25.2",
      "25.3",
      "update_uuid_for_models.sh",
      "25.4",
      "com.hp",
      "mass_error.log",
      "mass_dev2prod.log",
      "tar.gz",
      "unable",
      "export",
      "entity",
      "change",
      "model",
      "after",
      "upgrade",
      "cause",
      "solution",
      "prepare",
      "script",
      "update",
      "uuid",
      "uuids",
      "upgrading",
      "version",
      "25.3.x",
      "25.4.x",
      "26.1.x",
      "cannot",
      "see",
      "error",
      "similar",
      "following",
      "log",
      "files",
      "id",
      "68e63200e4b0769b7c0b34ec",
      "failed",
      "com.hp.maas.platform.exception.service.serviceexception",
      "data",
      "records",
      "found.",
      "dev2prod",
      "uses",
      "field",
      "record",
      "reconciliation",
      "between",
      "source",
      "target",
      "tenants.",
      "ask",
      "suite",
      "administrator",
      "perform",
      "crawling",
      "current",
      "tenant",
      "system",
      "automatically",
      "generates",
      "problematic",
      "retry.",
      "introduces",
      "content",
      "increment",
      "requires",
      "updates",
      "uuids.",
      "however",
      "process",
      "versions",
      "include",
      "step",
      "complete",
      "required",
      "updates.",
      "result",
      "fully",
      "applied",
      "remain",
      "outdated",
      "exporting",
      "fails.",
      "steps",
      "ensure",
      "introduced",
      "correctly.",
      "check",
      "decision",
      "table",
      "figure",
      "out",
      "workaround",
      "path",
      "action",
      "25.2.x",
      "apply"
    ],
    "language": "en",
    "word_count": 101,
    "importance_score": 4.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "unable to export entity change model after upgrade",
    "contentLower": "after upgrading to version 25.3.x, 25.4.x, or 26.1.x, you cannot export the entity change model, and you will see a an error similar to the following in the mass_dev2prod.log and mass_error.log log files: export with id 68e63200e4b0769b7c0b34ec failed com.hp.maas.platform.exception.service.serviceexception: data records without a uuid were found. dev2prod uses the uuid field for record reconciliation between the source and target tenants. ask your suite administrator to perform a crawling upgrade for the current tenant so that the system automatically generates a uuid for the problematic records, and then retry. cause version 25.3 introduces a content data version increment that requires updates to entity model uuids. however, the upgrade process for versions 25.3, 25.4, and 26.1 does not include a crawling upgrade step to complete these required updates. as a result, the content data version increment is not fully applied, the entity model uuids remain outdated, and exporting the enti",
    "keywordsLower": [
      "26.1",
      "file.copy",
      "environment.run",
      "25.2",
      "25.3",
      "update_uuid_for_models.sh",
      "25.4",
      "com.hp",
      "mass_error.log",
      "mass_dev2prod.log",
      "tar.gz",
      "unable",
      "export",
      "entity",
      "change",
      "model",
      "after",
      "upgrade",
      "cause",
      "solution",
      "prepare",
      "script",
      "update",
      "uuid",
      "uuids",
      "upgrading",
      "version",
      "25.3.x",
      "25.4.x",
      "26.1.x",
      "cannot",
      "see",
      "error",
      "similar",
      "following",
      "log",
      "files",
      "id",
      "68e63200e4b0769b7c0b34ec",
      "failed",
      "com.hp.maas.platform.exception.service.serviceexception",
      "data",
      "records",
      "found.",
      "dev2prod",
      "uses",
      "field",
      "record",
      "reconciliation",
      "between",
      "source",
      "target",
      "tenants.",
      "ask",
      "suite",
      "administrator",
      "perform",
      "crawling",
      "current",
      "tenant",
      "system",
      "automatically",
      "generates",
      "problematic",
      "retry.",
      "introduces",
      "content",
      "increment",
      "requires",
      "updates",
      "uuids.",
      "however",
      "process",
      "versions",
      "include",
      "step",
      "complete",
      "required",
      "updates.",
      "result",
      "fully",
      "applied",
      "remain",
      "outdated",
      "exporting",
      "fails.",
      "steps",
      "ensure",
      "introduced",
      "correctly.",
      "check",
      "decision",
      "table",
      "figure",
      "out",
      "workaround",
      "path",
      "action",
      "25.2.x",
      "apply"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "You receive an incorrect error message during Aggregated Offering import or Aggregated Offering import simulation",
    "content": "When you are importing an Aggregated Offering or simulating an Aggregated Offering import, you receive the following error message: \"Cannot import the Aggregated Offering because the Service Design does not exist.\" However, the Service Design does exist. Cause This error message is shown when any one of the following issues is detected: The Service Design does not exist. In this scenario, the error message is precise. The last part of the provider's DND URL is wrong. For example, in a URL https://itom-dnd-controller-svc:8444/dnd12345, the last part dnd12345 is wrong. In this scenario, the same \"Cannot import the Aggregated Offering because the Service Design does not exist\" error message is shown, which is incorrect. Resolution When you receive this error message, please also check the DND URL and make sure it is correct.",
    "url": "packageimporterrormessage",
    "filename": "packageimporterrormessage",
    "headings": [
      "Cause",
      "Resolution"
    ],
    "keywords": [
      "https://itom-dnd-controller-svc:8444/dnd12345",
      "receive",
      "incorrect",
      "error",
      "message",
      "during",
      "aggregated",
      "offering",
      "import",
      "simulation",
      "cause",
      "resolution",
      "importing",
      "simulating",
      "following",
      "cannot",
      "because",
      "service",
      "design",
      "exist.",
      "however",
      "shown",
      "any",
      "one",
      "issues",
      "detected",
      "scenario",
      "precise.",
      "last",
      "part",
      "provider",
      "dnd",
      "url",
      "wrong.",
      "example",
      "https",
      "itom-dnd-controller-svc",
      "8444",
      "dnd12345",
      "same",
      "exist",
      "incorrect.",
      "please",
      "check",
      "make",
      "sure",
      "correct."
    ],
    "language": "en",
    "word_count": 93,
    "importance_score": 2.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "you receive an incorrect error message during aggregated offering import or aggregated offering import simulation",
    "contentLower": "when you are importing an aggregated offering or simulating an aggregated offering import, you receive the following error message: \"cannot import the aggregated offering because the service design does not exist.\" however, the service design does exist. cause this error message is shown when any one of the following issues is detected: the service design does not exist. in this scenario, the error message is precise. the last part of the provider's dnd url is wrong. for example, in a url https://itom-dnd-controller-svc:8444/dnd12345, the last part dnd12345 is wrong. in this scenario, the same \"cannot import the aggregated offering because the service design does not exist\" error message is shown, which is incorrect. resolution when you receive this error message, please also check the dnd url and make sure it is correct.",
    "keywordsLower": [
      "https://itom-dnd-controller-svc:8444/dnd12345",
      "receive",
      "incorrect",
      "error",
      "message",
      "during",
      "aggregated",
      "offering",
      "import",
      "simulation",
      "cause",
      "resolution",
      "importing",
      "simulating",
      "following",
      "cannot",
      "because",
      "service",
      "design",
      "exist.",
      "however",
      "shown",
      "any",
      "one",
      "issues",
      "detected",
      "scenario",
      "precise.",
      "last",
      "part",
      "provider",
      "dnd",
      "url",
      "wrong.",
      "example",
      "https",
      "itom-dnd-controller-svc",
      "8444",
      "dnd12345",
      "same",
      "exist",
      "incorrect.",
      "please",
      "check",
      "make",
      "sure",
      "correct."
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "UCMDB CIs cannot be synchronized to Service Management through Native SACM",
    "content": "With Native SACM enabled, Service Management CIs can be synchronized to UCMDB successfully, however, UCMDB CIs can't be synchronized to Service Management. Cause This issue may be caused by custom business rules that restrict the write permission on SACM fields. Solution To identify and fix this issue, you can use the following method: Update a UCMDB CI and check the cms-gateway logs (Error.log/server.log/subscription.log), if you can find the corresponding update in subscription.log and see no errors in other logs, you can rule out the UCMDB Gateway malfunction. Otherwise, examine the UCMDB settings. Check the Service Management log files (maas_cms-x.log/maas_unhandled_exceptions.log/maas_error.log), search for the update with the global ID, and check if there is an error. If the logs show no error, examine custom business rules. Pay attention to the following rules: Define fields as read-only Define fields as mandatory Restrict editing of field If you have rules that restrict the whi",
    "url": "tsnativesacmsyncfailure",
    "filename": "tsnativesacmsyncfailure",
    "headings": [
      "Cause",
      "Solution"
    ],
    "keywords": [
      "x.log",
      "Error.log",
      "maas_unhandled_exceptions.log",
      "subscription.log",
      "maas_error.log",
      "server.log",
      "ucmdb",
      "cis",
      "cannot",
      "synchronized",
      "service",
      "management",
      "through",
      "native",
      "sacm",
      "cause",
      "solution",
      "enabled",
      "successfully",
      "however",
      "management.",
      "issue",
      "caused",
      "custom",
      "business",
      "rules",
      "restrict",
      "write",
      "permission",
      "fields.",
      "identify",
      "fix",
      "following",
      "method",
      "update",
      "ci",
      "check",
      "cms-gateway",
      "logs",
      "find",
      "corresponding",
      "see",
      "errors",
      "rule",
      "out",
      "gateway",
      "malfunction.",
      "otherwise",
      "examine",
      "settings.",
      "log",
      "files",
      "search",
      "global",
      "id",
      "there",
      "error.",
      "show",
      "error",
      "rules.",
      "pay",
      "attention",
      "define",
      "fields",
      "read-only",
      "mandatory",
      "editing",
      "field",
      "white",
      "try",
      "disable",
      "disappears."
    ],
    "language": "en",
    "word_count": 105,
    "importance_score": 2.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "ucmdb cis cannot be synchronized to service management through native sacm",
    "contentLower": "with native sacm enabled, service management cis can be synchronized to ucmdb successfully, however, ucmdb cis can't be synchronized to service management. cause this issue may be caused by custom business rules that restrict the write permission on sacm fields. solution to identify and fix this issue, you can use the following method: update a ucmdb ci and check the cms-gateway logs (error.log/server.log/subscription.log), if you can find the corresponding update in subscription.log and see no errors in other logs, you can rule out the ucmdb gateway malfunction. otherwise, examine the ucmdb settings. check the service management log files (maas_cms-x.log/maas_unhandled_exceptions.log/maas_error.log), search for the update with the global id, and check if there is an error. if the logs show no error, examine custom business rules. pay attention to the following rules: define fields as read-only define fields as mandatory restrict editing of field if you have rules that restrict the whi",
    "keywordsLower": [
      "x.log",
      "error.log",
      "maas_unhandled_exceptions.log",
      "subscription.log",
      "maas_error.log",
      "server.log",
      "ucmdb",
      "cis",
      "cannot",
      "synchronized",
      "service",
      "management",
      "through",
      "native",
      "sacm",
      "cause",
      "solution",
      "enabled",
      "successfully",
      "however",
      "management.",
      "issue",
      "caused",
      "custom",
      "business",
      "rules",
      "restrict",
      "write",
      "permission",
      "fields.",
      "identify",
      "fix",
      "following",
      "method",
      "update",
      "ci",
      "check",
      "cms-gateway",
      "logs",
      "find",
      "corresponding",
      "see",
      "errors",
      "rule",
      "out",
      "gateway",
      "malfunction.",
      "otherwise",
      "examine",
      "settings.",
      "log",
      "files",
      "search",
      "global",
      "id",
      "there",
      "error.",
      "show",
      "error",
      "rules.",
      "pay",
      "attention",
      "define",
      "fields",
      "read-only",
      "mandatory",
      "editing",
      "field",
      "white",
      "try",
      "disable",
      "disappears."
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Unable to import service design file",
    "content": "The capsule installation fails and you may come across the following error message: Unable to import service design file 'SERVICE_OFFERING_Bulk_Import_Existing_Servers_-_Admin_Only_90cd933950d5f6380151243795f82a7a' with version '16.07.null'. Possible causes Cause 1: Any of the required OO content pack flows are missing in OO Central. Cause 2: Content pack version in OO Central is incompatible with the DND version. Solution Check the Content Store logs. Check if any flows are missing in any content packs in OO Central. If flow/flows are missing, update the content packs with the required flow/flows. Check if the version of the content pack is compatible with the DND version. If the version is incompatible, then update the content pack version.",
    "url": "servicedesignimportfail",
    "filename": "servicedesignimportfail",
    "headings": [
      "Possible causes",
      "Solution"
    ],
    "keywords": [
      "16.07",
      "unable",
      "import",
      "service",
      "design",
      "file",
      "possible",
      "causes",
      "solution",
      "capsule",
      "installation",
      "fails",
      "come",
      "across",
      "following",
      "error",
      "message",
      "version",
      "16.07.null",
      "cause",
      "any",
      "required",
      "oo",
      "content",
      "pack",
      "flows",
      "missing",
      "central.",
      "central",
      "incompatible",
      "dnd",
      "version.",
      "check",
      "store",
      "logs.",
      "packs",
      "flow",
      "update",
      "flows.",
      "compatible"
    ],
    "language": "en",
    "word_count": 80,
    "importance_score": 3.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "unable to import service design file",
    "contentLower": "the capsule installation fails and you may come across the following error message: unable to import service design file 'service_offering_bulk_import_existing_servers_-_admin_only_90cd933950d5f6380151243795f82a7a' with version '16.07.null'. possible causes cause 1: any of the required oo content pack flows are missing in oo central. cause 2: content pack version in oo central is incompatible with the dnd version. solution check the content store logs. check if any flows are missing in any content packs in oo central. if flow/flows are missing, update the content packs with the required flow/flows. check if the version of the content pack is compatible with the dnd version. if the version is incompatible, then update the content pack version.",
    "keywordsLower": [
      "16.07",
      "unable",
      "import",
      "service",
      "design",
      "file",
      "possible",
      "causes",
      "solution",
      "capsule",
      "installation",
      "fails",
      "come",
      "across",
      "following",
      "error",
      "message",
      "version",
      "16.07.null",
      "cause",
      "any",
      "required",
      "oo",
      "content",
      "pack",
      "flows",
      "missing",
      "central.",
      "central",
      "incompatible",
      "dnd",
      "version.",
      "check",
      "store",
      "logs.",
      "packs",
      "flow",
      "update",
      "flows.",
      "compatible"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Usage count for Cloud Management license is missing",
    "content": "From the People UI (Administration > People), the Cloud Management license usage count and the link to download this report are missing after upgrading the suite. Cause This happens because the existing license pools for tenants are not linked to the new license key version. Solution As a suite admin, run the following commands on your control plane node/bastion host. To get the AutoPass auth token, run the following command: export APAUTHTOKEN=$(curl -skX POST 'https://<EXTERNAL ACCESS HOST>:5443/idm-service/v3.0/tokens' -H 'Content-Type: application/json' -d '{\"passwordCredentials\": {\"username\": \"admin\",\"password\": \"<password>\"},\"tenantName\": \"provider\"}' | jq .token.id | tr -d '\"') && echo $APAUTHTOKEN Replace the values within '<>' with values appropriate to your environment. To link the license pools with the new license key, run the following command: curl -skX GET 'https://<EXTERNAL ACCESS HOST>/autopass/services/v10.9/reservation/pool/feature/list?productName=50076_2.0_HCMX_23.",
    "url": "cloudmanagementlicensemissing",
    "filename": "cloudmanagementlicensemissing",
    "headings": [
      "Cause",
      "Solution"
    ],
    "keywords": [
      "v10.9",
      "v3.0",
      "https://<EXTERNAL",
      "token.id",
      "usage",
      "count",
      "cloud",
      "management",
      "license",
      "missing",
      "cause",
      "solution",
      "people",
      "ui",
      "administration",
      "link",
      "download",
      "report",
      "after",
      "upgrading",
      "suite.",
      "happens",
      "because",
      "existing",
      "pools",
      "tenants",
      "linked",
      "new",
      "key",
      "version.",
      "suite",
      "admin",
      "run",
      "following",
      "commands",
      "control",
      "plane",
      "node",
      "bastion",
      "host.",
      "get",
      "autopass",
      "auth",
      "token",
      "command",
      "export",
      "apauthtoken",
      "curl",
      "-skx",
      "post",
      "https",
      "5443",
      "idm-service",
      "tokens",
      "-h",
      "content-type",
      "application",
      "json",
      "-d",
      "passwordcredentials",
      "username",
      "password",
      "tenantname",
      "provider",
      "jq",
      ".token.id",
      "tr",
      "echo",
      "replace",
      "values",
      "appropriate",
      "environment.",
      "services",
      "reservation",
      "pool",
      "feature",
      "list",
      "productname",
      "-w",
      "accept",
      "-o",
      "dev",
      "null",
      "ensure",
      "status",
      "code",
      "printed",
      "console",
      "200"
    ],
    "language": "en",
    "word_count": 106,
    "importance_score": 3.0,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "usage count for cloud management license is missing",
    "contentLower": "from the people ui (administration > people), the cloud management license usage count and the link to download this report are missing after upgrading the suite. cause this happens because the existing license pools for tenants are not linked to the new license key version. solution as a suite admin, run the following commands on your control plane node/bastion host. to get the autopass auth token, run the following command: export apauthtoken=$(curl -skx post 'https://<external access host>:5443/idm-service/v3.0/tokens' -h 'content-type: application/json' -d '{\"passwordcredentials\": {\"username\": \"admin\",\"password\": \"<password>\"},\"tenantname\": \"provider\"}' | jq .token.id | tr -d '\"') && echo $apauthtoken replace the values within '<>' with values appropriate to your environment. to link the license pools with the new license key, run the following command: curl -skx get 'https://<external access host>/autopass/services/v10.9/reservation/pool/feature/list?productname=50076_2.0_hcmx_23.",
    "keywordsLower": [
      "v10.9",
      "v3.0",
      "https://<external",
      "token.id",
      "usage",
      "count",
      "cloud",
      "management",
      "license",
      "missing",
      "cause",
      "solution",
      "people",
      "ui",
      "administration",
      "link",
      "download",
      "report",
      "after",
      "upgrading",
      "suite.",
      "happens",
      "because",
      "existing",
      "pools",
      "tenants",
      "linked",
      "new",
      "key",
      "version.",
      "suite",
      "admin",
      "run",
      "following",
      "commands",
      "control",
      "plane",
      "node",
      "bastion",
      "host.",
      "get",
      "autopass",
      "auth",
      "token",
      "command",
      "export",
      "apauthtoken",
      "curl",
      "-skx",
      "post",
      "https",
      "5443",
      "idm-service",
      "tokens",
      "-h",
      "content-type",
      "application",
      "json",
      "-d",
      "passwordcredentials",
      "username",
      "password",
      "tenantname",
      "provider",
      "jq",
      ".token.id",
      "tr",
      "echo",
      "replace",
      "values",
      "appropriate",
      "environment.",
      "services",
      "reservation",
      "pool",
      "feature",
      "list",
      "productname",
      "-w",
      "accept",
      "-o",
      "dev",
      "null",
      "ensure",
      "status",
      "code",
      "printed",
      "console",
      "200"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "User lock API",
    "content": "The following APIs enable you to get the lock status of a user, and lock or unlock a user. Only suite admin users or the internal integration user (bo-integration@dummy.com) can use this API. Get lock status Enter the following GET request URI: https://<serverAddress>/bo/rest/entities/user/<user-id>/lock where the user-id is the value of the user ID displayed in Suite Administration. The true or false response indicates the lock status of the user: true: The user is locked. false: The user isn't locked. Lock user To avoid locking a user that is already locked, you can use GET method to get the lock status of a user. Enter the following POST request URI to lock a user: https://<serverAddress>/bo/rest/entities/user/<user-id>/lock where the user-id is the value of the user ID displayed in Suite Administration. The true or false response indicates the lock status of the user: true: The user is locked. false: The user isn't locked. Note: This API locks the user only within the suite. It doe",
    "url": "userlockapi",
    "filename": "userlockapi",
    "headings": [
      "Get lock status",
      "Lock user",
      "Unlock user"
    ],
    "keywords": [
      "dummy.com",
      "https://<serverAddress>/bo/rest/entities/user/<user-id>/lock",
      "user",
      "lock",
      "api",
      "get",
      "status",
      "unlock",
      "following",
      "apis",
      "enable",
      "user.",
      "suite",
      "admin",
      "users",
      "internal",
      "integration",
      "bo-integration",
      "api.",
      "enter",
      "request",
      "uri",
      "https",
      "bo",
      "rest",
      "entities",
      "user-id",
      "value",
      "id",
      "displayed",
      "administration.",
      "true",
      "false",
      "response",
      "indicates",
      "locked.",
      "isn",
      "avoid",
      "locking",
      "already",
      "locked",
      "method",
      "post",
      "note",
      "locks",
      "suite.",
      "doesn",
      "update",
      "ldap",
      "saml",
      "oauth",
      "server.",
      "delete",
      "unlocks"
    ],
    "language": "en",
    "word_count": 112,
    "importance_score": 4.5,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "user lock api",
    "contentLower": "the following apis enable you to get the lock status of a user, and lock or unlock a user. only suite admin users or the internal integration user (bo-integration@dummy.com) can use this api. get lock status enter the following get request uri: https://<serveraddress>/bo/rest/entities/user/<user-id>/lock where the user-id is the value of the user id displayed in suite administration. the true or false response indicates the lock status of the user: true: the user is locked. false: the user isn't locked. lock user to avoid locking a user that is already locked, you can use get method to get the lock status of a user. enter the following post request uri to lock a user: https://<serveraddress>/bo/rest/entities/user/<user-id>/lock where the user-id is the value of the user id displayed in suite administration. the true or false response indicates the lock status of the user: true: the user is locked. false: the user isn't locked. note: this api locks the user only within the suite. it doe",
    "keywordsLower": [
      "dummy.com",
      "https://<serveraddress>/bo/rest/entities/user/<user-id>/lock",
      "user",
      "lock",
      "api",
      "get",
      "status",
      "unlock",
      "following",
      "apis",
      "enable",
      "user.",
      "suite",
      "admin",
      "users",
      "internal",
      "integration",
      "bo-integration",
      "api.",
      "enter",
      "request",
      "uri",
      "https",
      "bo",
      "rest",
      "entities",
      "user-id",
      "value",
      "id",
      "displayed",
      "administration.",
      "true",
      "false",
      "response",
      "indicates",
      "locked.",
      "isn",
      "avoid",
      "locking",
      "already",
      "locked",
      "method",
      "post",
      "note",
      "locks",
      "suite.",
      "doesn",
      "update",
      "ldap",
      "saml",
      "oauth",
      "server.",
      "delete",
      "unlocks"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  },
  {
    "title": "Work with CloudSlang content flows",
    "content": "It is also possible to deploy and run content that was authored using CloudSlang 1.0 and 2.0 CloudSlang CloudSlang is a flow-based orchestration tool for managing deployed applications. The CloudSlang project is composed of three main parts: the CloudSlang Orchestration Engine, the CloudSlang language, and the ready-made CloudSlang content. The engine is packaged as a lightweight Java .jar file and can be embedded into existing Java projects. The language is a YAML-based DSL for writing workflows. The workflows can be run by an embedded instance of the engine or the stand-alone CloudSlang CLI. The main types of CloudSlang content are operations, flows, and decisions. An operation contains an action, which can be written in Python or Java. Operations perform the “work” part of the workflow. A flow contains steps, which stitch together the actions performed by operations, navigating and passing data from one to the other based on operation results and outputs. Flows perform the “flow” pa",
    "url": "cloudslangcontentflows",
    "filename": "cloudslangcontentflows",
    "headings": [
      "Related topics"
    ],
    "keywords": [
      "github.com",
      "https://github.com/cloudslang/score",
      "readthedocs.io",
      "1.0",
      "sl.yml",
      "2.0",
      "https://cloudslang-docs.readthedocs.io/en/latest",
      "https://github.com/cloudslang/cloud-slang",
      "sl.yaml",
      "work",
      "cloudslang",
      "content",
      "flows",
      "related",
      "topics",
      "possible",
      "deploy",
      "run",
      "authored",
      "flow-based",
      "orchestration",
      "tool",
      "managing",
      "deployed",
      "applications.",
      "project",
      "composed",
      "three",
      "main",
      "parts",
      "engine",
      "language",
      "ready-made",
      "content.",
      "packaged",
      "lightweight",
      "java",
      ".jar",
      "file",
      "embedded",
      "existing",
      "projects.",
      "yaml-based",
      "dsl",
      "writing",
      "workflows.",
      "workflows",
      "instance",
      "stand-alone",
      "cli.",
      "types",
      "operations",
      "decisions.",
      "operation",
      "contains",
      "action",
      "written",
      "python",
      "java.",
      "perform",
      "part",
      "workflow.",
      "flow",
      "steps",
      "stitch",
      "together",
      "actions",
      "performed",
      "navigating",
      "passing",
      "data",
      "one",
      "based",
      "results",
      "outputs.",
      "decision",
      "provides",
      "capability",
      "select",
      "different",
      "outcomes.",
      "supported",
      "extensions",
      ".sl",
      ".sl.yaml",
      ".sl.yml.",
      "note",
      "information",
      "about",
      "see",
      "https",
      "cloudslang-docs.readthedocs.io",
      "en",
      "latest",
      "cloud-slang",
      "score",
      "all",
      "oo",
      "topologies",
      "central"
    ],
    "language": "en",
    "word_count": 95,
    "importance_score": 3.5,
    "tf_idf_scores": {},
    "ngrams": [],
    "stemmed_words": [],
    "titleLower": "work with cloudslang content flows",
    "contentLower": "it is also possible to deploy and run content that was authored using cloudslang 1.0 and 2.0 cloudslang cloudslang is a flow-based orchestration tool for managing deployed applications. the cloudslang project is composed of three main parts: the cloudslang orchestration engine, the cloudslang language, and the ready-made cloudslang content. the engine is packaged as a lightweight java .jar file and can be embedded into existing java projects. the language is a yaml-based dsl for writing workflows. the workflows can be run by an embedded instance of the engine or the stand-alone cloudslang cli. the main types of cloudslang content are operations, flows, and decisions. an operation contains an action, which can be written in python or java. operations perform the “work” part of the workflow. a flow contains steps, which stitch together the actions performed by operations, navigating and passing data from one to the other based on operation results and outputs. flows perform the “flow” pa",
    "keywordsLower": [
      "github.com",
      "https://github.com/cloudslang/score",
      "readthedocs.io",
      "1.0",
      "sl.yml",
      "2.0",
      "https://cloudslang-docs.readthedocs.io/en/latest",
      "https://github.com/cloudslang/cloud-slang",
      "sl.yaml",
      "work",
      "cloudslang",
      "content",
      "flows",
      "related",
      "topics",
      "possible",
      "deploy",
      "run",
      "authored",
      "flow-based",
      "orchestration",
      "tool",
      "managing",
      "deployed",
      "applications.",
      "project",
      "composed",
      "three",
      "main",
      "parts",
      "engine",
      "language",
      "ready-made",
      "content.",
      "packaged",
      "lightweight",
      "java",
      ".jar",
      "file",
      "embedded",
      "existing",
      "projects.",
      "yaml-based",
      "dsl",
      "writing",
      "workflows.",
      "workflows",
      "instance",
      "stand-alone",
      "cli.",
      "types",
      "operations",
      "decisions.",
      "operation",
      "contains",
      "action",
      "written",
      "python",
      "java.",
      "perform",
      "part",
      "workflow.",
      "flow",
      "steps",
      "stitch",
      "together",
      "actions",
      "performed",
      "navigating",
      "passing",
      "data",
      "one",
      "based",
      "results",
      "outputs.",
      "decision",
      "provides",
      "capability",
      "select",
      "different",
      "outcomes.",
      "supported",
      "extensions",
      ".sl",
      ".sl.yaml",
      ".sl.yml.",
      "note",
      "information",
      "about",
      "see",
      "https",
      "cloudslang-docs.readthedocs.io",
      "en",
      "latest",
      "cloud-slang",
      "score",
      "all",
      "oo",
      "topologies",
      "central"
    ],
    "bm25f_precomputed": true,
    "semantic_vector_available": true,
    "field_weights": {
      "title": 3.0,
      "headings": 2.0,
      "keywords": 2.5,
      "content": 1.0
    }
  }
]